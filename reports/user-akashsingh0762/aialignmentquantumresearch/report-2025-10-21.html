
    
        <h1>ðŸ¤– AI Research News Report</h1>
        <p>Tuesday, October 21, 2025</p>
        <p>Topics: ai alignment research, quantum computing</p>
    
    
        20Research Papers
        2Topics Covered
        YesAI Summary
    
    
    
        <h2>ðŸ¤– AI Summary</h2>
        <h2>ai alignment research</h2>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Advancements in Visual and Multimodal Editing</strong>: There is a clear trend towards improving the precision and consistency of visual and multimodal editing tools. The development of ConsistEdit highlights efforts to refine attention mechanisms within generative models, allowing for more reliable and nuanced image and video editing.</p>
</li>
<li><p><strong>Integration of Multi-Agent Systems in Enterprise Analytics</strong>: The emergence of sophisticated multi-agent systems like Enterprise Deep Research (EDR) shows a push towards leveraging autonomous agents to handle complex enterprise data, emphasizing the need for domain-specific adaptability and integration.</p>
</li>
<li><p><strong>Replication and Knowledge Transfer in AI Research</strong>: Executable Knowledge Graphs (xKG) represent a trend towards enhancing the replicability of AI research through structured knowledge integration, addressing challenges in generating executable code from scientific literature.</p>
</li>
<li><p><strong>Understanding and Mitigating Knowledge Forgetting</strong>: Research on post-training forgetting in language models highlights ongoing efforts to understand how additional training impacts retained knowledge, with frameworks being developed to better quantify these changes.</p>
</li>
<li><p><strong>Combining Traditional and AI-driven Tools for Information Retrieval</strong>: The study on search tool usage by university students points to a trend of combining traditional search engines with AI models to improve information retrieval and academic problem-solving efficiency.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>ConsistEdit for MM-DiT Models</strong>: The introduction of ConsistEdit marks a breakthrough in visual editing by enabling consistent and precise editing across all steps of inference, without handcrafted interventions, which significantly improves reliability in multi-round and multi-region editing tasks.</p>
</li>
<li><p><strong>Enterprise Deep Research Framework</strong>: EDRs integration of specialized agents and an extensible tool ecosystem represents a breakthrough in automating and optimizing enterprise analytics, demonstrating superior performance over existing agentic systems without human guidance.</p>
</li>
<li><p><strong>Executable Knowledge Graphs for AI Replication</strong>: The development of xKG is a breakthrough in AI research replication, offering a modular solution that enhances performance by integrating code snippets and domain knowledge into agent frameworks.</p>
</li>
<li><p><strong>Sample-wise Paradigm for Forgetting Measurement</strong>: The new framework for mapping post-training forgetting in language models provides a breakthrough method for accurately measuring knowledge retention and loss, offering a nuanced understanding of post-training impacts.</p>
</li>
<li><p><strong>MT-Video-Bench for Multimodal Dialogues</strong>: The creation of MT-Video-Bench is a breakthrough in evaluating multimodal large language models, providing a comprehensive benchmark that focuses on multi-turn dialogue understanding, which is essential for real-world applications.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Enhanced Editing Tools for Creative Industries</strong>: The advancements in visual editing tools like ConsistEdit could significantly impact creative industries by providing more reliable and precise editing capabilities, potentially revolutionizing how media content is produced and modified.</p>
</li>
<li><p><strong>Improved Enterprise Decision-Making</strong>: The EDR framework can greatly enhance enterprise decision-making processes by providing more accurate and automated insights, reducing the cognitive load on human analysts and improving overall efficiency.</p>
</li>
<li><p><strong>Increased Research Replicability</strong>: With tools like xKG, the replicability of AI research could see significant improvements, fostering more robust scientific discoveries and facilitating collaboration across the research community.</p>
</li>
<li><p><strong>Better Understanding of AI Learning and Retention</strong>: The insights from post-training forgetting studies can lead to more effective strategies for training AI models, potentially reducing the loss of critical knowledge and improving model reliability.</p>
</li>
<li><p><strong>Hybrid Search Solutions for Academic Use</strong>: The combination of AI-driven models and traditional search engines could lead to the development of hybrid solutions that enhance academic research efficiency, providing more comprehensive and reliable information retrieval systems.</p>
</li>
<li><p><strong>More Realistic Evaluation of AI in Real-world Scenarios</strong>: Tools like MT-Video-Bench emphasize the need for AI models to be evaluated in more interactive and realistic settings, which could drive the development of AI systems that are better suited for practical applications in diverse environments.</p>
</li>
</ol>
<p><em>Based on 10 research papers</em></p>

<h2>quantum computing</h2>
<p>The research papers provided cover a wide array of topics, none of which directly relate to quantum computing. Instead, they focus on advancements in fields such as AI, machine learning, gravitational wave physics, and computational methods. However, summarizing these papers with an emphasis on their general significance and potential indirect relevance to quantum computing might still be insightful. Here is a structured summary of the key findings:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Integration of AI and Computational Methods</strong>: There is a notable trend toward integrating AI with other computational techniques to enhance performance across a range of applications, from visual editing (ConsistEdit) to large language model compression (Glyph).</p>
</li>
<li><p><strong>Focus on Scalability and Efficiency</strong>: Multiple papers address the challenge of scalability, whether in handling large data contexts in language models (Glyph) or improving the efficiency of flow matching techniques (Inference-Time Compute Scaling For Flow Matching).</p>
</li>
<li><p><strong>Automation and Multimodal Approaches</strong>: Automation through multi-agent systems (Enterprise Deep Research) and hybrid action models (UltraCUA) is increasingly being used to handle complex tasks, suggesting a shift toward more integrated and flexible systems.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Training-Free Visual Editing</strong>: ConsistEdit presents a new method for precise visual editing without the need for extensive model training, which could inspire similar approaches in quantum algorithm optimization where precision without retraining is crucial.</p>
</li>
<li><p><strong>Visual-Text Compression for LLMs</strong>: Glyph demonstrates a novel method of compressing text into visual formats, which may influence data encoding strategies in quantum information processing by offering new perspectives on data representation.</p>
</li>
<li><p><strong>Executable Knowledge Graphs</strong>: The introduction of xKG provides a structured way to capture and utilize technical knowledge, which could be adapted for quantum computing research to improve the replication and development of quantum algorithms.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Enhanced Data Processing</strong>: The advancements in data compression and representation could lead to improved methods for handling large datasets in quantum computing, potentially reducing the complexity and cost of quantum computations.</p>
</li>
<li><p><strong>Improved AI-Driven Research and Automation</strong>: The developments in multi-agent systems and automated research tools highlight potential applications in quantum computing for automating tedious simulation and validation tasks, thereby accelerating research.</p>
</li>
<li><p><strong>Cross-Disciplinary Techniques</strong>: The innovative approaches described, such as those for gravitational wave analysis and multimodal agent systems, could inspire cross-disciplinary techniques that leverage both classical and quantum computational strengths, possibly leading to breakthroughs in quantum machine learning.</p>
</li>
</ol>
<p>While these papers do not directly address quantum computing, the methodologies and innovations they present could indirectly support advancements in the field by offering new tools and perspectives applicable to quantum information science.</p>
<p><em>Based on 10 research papers</em></p>

        Generated by OpenAI GPT-4o-mini
    
    
    
    
        <h2>ðŸ“° News</h2>
        
            
                ai alignment research
                
                    
                        
                            <a href="https://www.theguardian.com/p/x3fjtv" target="_blank">Salesforceâ€™s CEO backtracks after saying Trump should send troops into San Francisco</a> â€” Blake Montgomery
                        
                        2025-10-21T13:18:32Z
                        <br>
                        Salesforce CEO Marc Benioff recently suggested that Donald Trump should deploy the US national guard to San Francisco, sparking controversy and resistance from local leaders. His remarks, made just as Salesforces major conference Dreamforce was beginning, surprised many given Benioffs reputation as a liberal influencer and his significant political clout in Democratic circles. The comments divided the tech community, leading to the resignation of a Salesforce board member, though they were praised by Elon Musk. David Sacks, a Trump supporter, suggested a targeted operation could quickly address the citys issues, aligning somewhat with Benioffs initial stance. Benioff later apologized for his comments, acknowledging the backlash they had provoked.
                        <a href="https://www.theguardian.com/p/x3fjtv" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3fkg2" target="_blank">Bryan Cranston thanks OpenAI for cracking down on Sora 2 deepfakes</a> â€” Sian Cain
                        
                        2025-10-21T05:32:21Z
                        <br>
                        Bryan Cranston has expressed gratitude to OpenAI for addressing unauthorized deepfakes of him on its generative AI video platform, Sora 2. Initially, users could generate his voice and likeness without consent, prompting Cranston to contact the actors union Sag-Aftra. The LA Times highlighted a video featuring a synthetic Michael Jackson with Cranstons image, sparking concerns over consent violations. OpenAI claims it implemented measures to ensure public figures likenesses are used with consent, countering reports that the company required individuals to opt out if they didnt want their likenesses used. Cranston thanked OpenAI for enhancing its protective measures, emphasizing concerns for all performers affected by such unauthorized depictions.
                        <a href="https://www.theguardian.com/p/x3fkg2" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3eaf3" target="_blank">â€˜Every kind of creative discipline is in dangerâ€™: Lincoln Lawyer author on the dangers of AI</a> â€” Nadia Khomami Arts and culture correspondent
                        
                        2025-10-20T14:00:42Z
                        <br>
                        Michael Connelly, renowned for his Lincoln Lawyer series, expresses concerns about the rapid advancements of AI as he releases his eighth novel in the series, which involves a lawsuit against an AI company. His new book takes inspiration from real-life incidents where chatbots allegedly influenced harmful human actions, such as a teenagers suicide in Orlando and an attempted intrusion at Windsor Palace. Connelly reflects on the swift evolution of AI technology, fearing his novels plot could become outdated quickly. He highlights the pervasive impact of AI across various sectors, including culture, medicine, and science, and describes the current state of AI as a wild west due to the lack of government oversight. The Lincoln Lawyer series, set in Los Angeles, has previously been adapted into a film and a Netflix series.
                        <a href="https://www.theguardian.com/p/x3eaf3" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3ehq8" target="_blank">Inside San Franciscoâ€™s new AI school: is this the future of US education?</a> â€” Robin Buller
                        
                        2025-10-18T13:00:46Z
                        <br>
                        Alpha School San Francisco, a new AI-powered private school, has attracted attention for integrating artificial intelligence into its K-8 curriculum. The school claims its AI-driven model allows students to learn twice as fast during just two hours of focused academic work daily. AI is a core component of Alphas educational philosophy and is increasingly being adopted by schools across the US to assist with teaching tasks like curriculum development and student engagement. Despite the potential benefits, the high cost of tuition and claims of success have raised concerns among education and technology researchers. Experts like Emma Pierson from UC Berkeley acknowledge AIs potential in education but remain cautious due to past educational experiments that have failed.
                        <a href="https://www.theguardian.com/p/x3ehq8" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3efev" target="_blank">The platform exposing exactly how much copyrighted art is used by AI tools</a> â€” Dan Milmo Global technology editor
                        
                        2025-10-18T11:00:43Z
                        <br>
                        The article discusses the challenges that AI tools like Googles Gemini and OpenAIs Sora 2 face regarding the use of copyrighted material in their generative processes. When these tools create content resembling known works, such as Doctor Who, questions arise about originality and copyright infringement. Creative industries are demanding compensation and permission for using their work to train AI models, highlighting concerns about competition with AI-generated content. Some news organizations have reached licensing agreements with OpenAI, addressing the issue of using proprietary content. The situation underscores significant legal and ethical dilemmas as AI technologies become more integrated into creative fields.
                        <a href="https://www.theguardian.com/p/x3efev" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3cta6" target="_blank">Are we living in a golden age of stupidity?</a> â€” Sophie McBain
                        
                        2025-10-18T10:00:42Z
                        <br>
                        The MIT Media Lab is showcasing innovative technology, including AI-driven prototypes and robotic creations, highlighting the proximity of future advancements. Research scientist Nataliya Kosmyna is developing wearable brain-computer interfaces aimed at helping individuals with neurodegenerative diseases communicate without speech. She is also working on a device that detects confusion or loss of focus, resembling a pair of glasses. Kosmyna has received emails from people claiming that their cognitive abilities have altered due to using large language models like ChatGPT. She has observed a growing reliance on generative AI both in professional settings and in the behavior of prospective researchers.
                        <a href="https://www.theguardian.com/p/x3cta6" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3f22z" target="_blank">Parents will be able to block Meta bots from talking to their children under new safeguards</a> â€” Dan Milmo Global technology editor
                        
                        2025-10-18T09:14:47Z
                        <br>
                        Meta is introducing new safeguards allowing parents to block their childrens interactions with AI character chatbots on platforms like Facebook, Instagram, and the Meta AI app. Parents can disable these chats entirely or block specific AI characters, ensuring more control over their childrens digital interactions. Additionally, they will receive insights into the topics their children discuss with AI characters, enabling informed conversations about AI interactions. The changes are set to roll out early next year in the US, UK, Canada, and Australia. Instagram is also implementing a PG-13-like rating system to enhance parental control and ensure AI characters do not engage in discussions about sensitive topics like self-harm or disordered eating.
                        <a href="https://www.theguardian.com/p/x3f22z" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3f4ay" target="_blank">AI chatbots are hurting children, Australian education minister warns as anti-bullying plan announced</a> â€” Cait Kelly
                        
                        2025-10-18T03:54:42Z
                        <br>
                        The Australian education minister, Jason Clare, has voiced serious concerns over AI chatbots contributing to the bullying of children and encouraging harmful behavior. Clare described this phenomenon as AI supercharging bullying, highlighting instances where chatbots have humiliated children and even suggested self-harm. This issue gained further attention with a lawsuit in California, where parents alleged that OpenAIs ChatGPT played a role in their sons suicide. OpenAI acknowledged the limitations of its models in handling users in mental distress and committed to improving their response systems. In response, Australia announced new anti-bullying measures, including mandatory action within 48 hours of incidents and specialized training for teachers.
                        <a href="https://www.theguardian.com/p/x3f4ay" target="_blank">Read full article</a>
                    
                    
                Source: The Guardian
            
            
            
                quantum computing
                
                    
                        
                            <a href="https://www.theguardian.com/p/x3fjtv" target="_blank">Salesforceâ€™s CEO backtracks after saying Trump should send troops into San Francisco</a> â€” Blake Montgomery
                        
                        2025-10-21T13:18:32Z
                        <br>
                        Salesforces CEO Marc Benioff recently sparked controversy by suggesting that former President Trump should send the national guard into San Francisco, a statement that surprised many, including his own PR team. Known as a significant figure in San Francisco due to his role as CEO of the citys largest private employer, Salesforce, Benioffs comments were unexpected given his liberal reputation. The timing coincided with Salesforces major conference, Dreamforce, which was taking place in the city. His remarks led to a mixed response, with some tech leaders upset and a Salesforce board member resigning, while Elon Musk showed support. Benioff later apologized for his comments, acknowledging the backlash and seeking to address the division they caused.
                        <a href="https://www.theguardian.com/p/x3fjtv" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3fk8f" target="_blank">â€˜Iâ€™m having a great dayâ€™: AWS outage offers some a brief glimpse of a tech-free existence</a> â€” Eva Corlett
                        
                        2025-10-21T03:50:19Z
                        <br>
                        A global outage of Amazon Web Services (AWS) on Monday caused significant disruptions, affecting over 2,000 companies, including major platforms like Snapchat, Roblox, Signal, and Duolingo, while also impacting Amazons own operations. The cloud service glitch led to delays in various activities, such as exams and work schedules, and forced some users to revert to manual operations, like turning on coffee machines. Although many applications and services were restored within hours, some experienced ongoing issues throughout the day. By the evening, Amazon announced that its cloud services had resumed normal operations. The outage unexpectedly provided a brief respite for some Amazon workers, who shared their downtime experiences on social media, but also raised concerns about pay discrepancies for missed work hours.
                        <a href="https://www.theguardian.com/p/x3fk8f" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3fgzx" target="_blank">Amazon Web Services outage shows internet users â€˜at mercyâ€™ of too few providers, experts say</a> â€” Dan Milmo and Graeme Wearden
                        
                        2025-10-20T16:25:56Z
                        <br>
                        An Amazon Web Services (AWS) outage recently highlighted the vulnerabilities of relying on a limited number of providers to operate the global internet infrastructure. The disruption affected numerous platforms, including Snapchat, Roblox, Signal, Duolingo, and several Amazon-owned services, impacting over 2,000 companies worldwide. In the UK, notable disruptions included Lloyds bank and its subsidiaries, as well as the HM Revenue and Customs website. Users reported millions of issues globally; however, most services were restored within a few hours, and Amazon stated that all cloud services returned to normal by Monday evening. The incident underscores the critical dependency on major cloud providers and the widespread impact their outages can have on digital services.
                        <a href="https://www.theguardian.com/p/x3fgzx" target="_blank">Read full article</a>
                    
                    
                Source: The Guardian
            
            
    
    
    
        <h2>ðŸ“„ Research Papers (20)</h2>
        
            
                ConsistEdit: Highly Consistent and Precise Training-free Visual Editing
                
                    <strong>Authors:</strong> Zixin Yin, Ling-Hao Chen, Lionel Ni, Xili Dai
                
                
                    <strong>Abstract:</strong> Recent advances in training-free attention control methods have enabled flexible and efficient text-guided editing capabilities for existing generation models. However, current approaches struggle to simultaneously deliver strong editing strength while preserving consistency with the source. This limitation becomes particularly critical in multi-round and video editing, where visual errors can accumulate over time. Moreover, most existing methods enforce global consistency, which limits their ability to modify individual attributes such as texture while preserving others, thereby hindering fine-grained editing. Recently, the architectural shift from U-Net to MM-DiT has brought significant improvements in generative performance and introduced a novel mechanism for integrating text and vision modalities. These advancements pave the way for overcoming challenges that previous methods failed to resolve. Through an in-depth analysis of MM-DiT, we identify three key insights into its attention mechanisms. Building on these, we propose ConsistEdit, a novel attention control method specifically tailored for MM-DiT. ConsistEdit incorporates vision-only attention control, mask-guided pre-attention fusion, and differentiated manipulation of the query, key, and value tokens to produce consistent, prompt-aligned edits. Extensive experiments demonstrate that ConsistEdit achieves state-of-the-art performance across a wide range of image and video editing tasks, including both structure-consistent and structure-inconsistent scenarios. Unlike prior methods, it is the first approach to perform editing across all inference steps and attention layers without handcraft, significantly enhancing reliability and consistency, which enables robust multi-round and multi-region editing. Furthermore, it supports progressive adjustment of structural consistency, enabling finer control.
                
                
                    <strong>Published:</strong> 2025-10-20T17:59:52Z
                    <a href="http://arxiv.org/abs/2510.17803v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics
                
                    <strong>Authors:</strong> Akshara Prabhakar, Roshan Ram, Zixiang Chen, Silvio Savarese, Frank Wang, Caiming Xiong, Huan Wang, Weiran Yao
                
                
                    <strong>Abstract:</strong> As information grows exponentially, enterprises face increasing pressure to transform unstructured data into coherent, actionable insights. While autonomous agents show promise, they often struggle with domain-specific nuances, intent alignment, and enterprise integration. We present Enterprise Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning Agent for adaptive query decomposition, (2) four specialized search agents (General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a Visualization Agent for data-driven insights, and (5) a reflection mechanism that detects knowledge gaps and updates research direction with optional human-in-the-loop steering guidance. These components enable automated report generation, real-time streaming, and seamless enterprise deployment, as validated on internal datasets. On open-ended benchmarks including DeepResearch Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without any human steering. We release the EDR framework and benchmark trajectories to advance research on multi-agent reasoning applications. Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and Dataset at https://huggingface.co/datasets/Salesforce/EDR-200
                
                
                    <strong>Published:</strong> 2025-10-20T17:55:11Z
                    <a href="http://arxiv.org/abs/2510.17797v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Executable Knowledge Graphs for Replicating AI Research
                
                    <strong>Authors:</strong> Yujie Luo, Zhuoyun Yu, Xuehai Wang, Yuqi Zhu, Ningyu Zhang, Lanning Wei, Lun Du, Da Zheng, Huajun Chen
                
                
                    <strong>Abstract:</strong> Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. Furthermore, previous approaches tend to overlook valuable implementation-level code signals and lack structured knowledge representations that support multi-granular retrieval and reuse. To overcome these challenges, we propose Executable Knowledge Graphs (xKG), a modular and pluggable knowledge base that automatically integrates technical insights, code snippets, and domain-specific knowledge extracted from scientific literature. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication. Code will released at https://github.com/zjunlp/xKG.
                
                
                    <strong>Published:</strong> 2025-10-20T17:53:23Z
                    <a href="http://arxiv.org/abs/2510.17795v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Mapping Post-Training Forgetting in Language Models at Scale
                
                    <strong>Authors:</strong> Jackson Harmon, Andreas Hochlehnert, Matthias Bethge, Ameya Prabhu
                
                
                    <strong>Abstract:</strong> Scaled post-training now drives many of the largest capability gains in language models (LMs), yet its effect on pretrained knowledge remains poorly understood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S. president or an API call) does not average out by recalling another. Hence, we propose a sample-wise paradigm to measure what is forgotten and when backward transfer occurs. Our metric counts 1-0 transitions (correct before post-training, incorrect after) to quantify forgetting and 0-1 transitions to quantify backward transfer. Traditional task averages conflate these effects and obscure large changes. For multiple-choice benchmarks, we add chance-adjusted variants that subtract the expected contribution of random guessing from pre- and post-training accuracies. We apply this framework across post-training stages, model sizes, and data scales. Our large-scale analysis shows that: (1) Domain-continual pretraining induces moderate forgetting with low-to-moderate backward transfer; (2) RL/SFT post-training applied to base models and Instruction tuning yields moderate-to-large backward transfer on math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to instruction-tuned models is sensitive on data scale: at small scales, both forgetting and backward transfer are small; at larger scales, effects are mixed and warrant further study with better controls; (4) Model merging does not reliably mitigate forgetting. Overall, our framework offers a practical yardstick for mapping how post-training alters pretrained knowledge at scale -- enabling progress towards generally capable AI systems.
                
                
                    <strong>Published:</strong> 2025-10-20T17:35:47Z
                    <a href="http://arxiv.org/abs/2510.17776v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Sample Complexity Analysis of Multi-Target Detection via Markovian and Hard-Core Multi-Reference Alignment
                
                    <strong>Authors:</strong> Kweku Abraham, Amnon Balanov, Tamir Bendory, Carlos Esteve-YagÃ¼e
                
                
                    <strong>Abstract:</strong> Motivated by single-particle cryo-electron microscopy, we study the sample complexity of the multi-target detection (MTD) problem, in which an unknown signal appears multiple times at unknown locations within a long, noisy observation. We propose a patching scheme that reduces MTD to a non-i.i.d. multi-reference alignment (MRA) model. In the one-dimensional setting, the latent group elements form a Markov chain, and we show that the convergence rate of any estimator matches that of the corresponding i.i.d. MRA model, up to a logarithmic factor in the number of patches. Moreover, for estimators based on empirical averaging, such as the method of moments, the convergence rates are identical in both settings. We further establish an analogous result in two dimensions, where the latent structure arises from an exponentially mixing random field generated by a hard-core placement model. As a consequence, if the signal in the corresponding i.i.d. MRA model is determined by moments up to order $n_{\min}$, then in the low-SNR regime the number of patches required to estimate the signal in the MTD model scales as $\sigma^{2n_{\min}}$, where $\sigma^2$ denotes the noise variance.
                
                
                    <strong>Published:</strong> 2025-10-20T17:35:19Z
                    <a href="http://arxiv.org/abs/2510.17775v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications
                
                    <strong>Authors:</strong> Xiao Ye, Jacob Dineen, Zhaonan Li, Zhikun Xu, Weiyu Chen, Shijie Lu, Yuxi Huang, Ming Shen, Phu Tran, Ji-Eun Irene Yum, Muhammad Ali Khan, Muhammad Umar Afzal, Irbaz Bin Riaz, Ben Zhou
                
                
                    <strong>Abstract:</strong> Medical Large language models achieve strong scores on standard benchmarks; however, the transfer of those results to safe and reliable performance in clinical workflows remains a challenge. This survey reframes evaluation through a levels-of-autonomy lens (L0-L3), spanning informational tools, information transformation and aggregation, decision support, and supervised agents. We align existing benchmarks and metrics with the actions permitted at each level and their associated risks, making the evaluation targets explicit. This motivates a level-conditioned blueprint for selecting metrics, assembling evidence, and reporting claims, alongside directions that link evaluation to oversight. By centering autonomy, the survey moves the field beyond score-based claims toward credible, risk-aware evidence for real clinical use.
                
                
                    <strong>Published:</strong> 2025-10-20T17:22:32Z
                    <a href="http://arxiv.org/abs/2510.17764v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts
                
                    <strong>Authors:</strong> Celeste Riley, Omar Al-Refai, Yadira Colunga Reyes, Eman Hammad
                
                
                    <strong>Abstract:</strong> As stories of human-AI interactions continue to be highlighted in the news and research platforms, the challenges are becoming more pronounced, including potential risks of overreliance, cognitive offloading, social and emotional manipulation, and the nuanced degradation of human agency and judgment. This paper surveys recent research on these issues through the lens of the psychological triad: cognition, behavior, and emotion. Observations seem to suggest that while AI can substantially enhance memory, creativity, and engagement, it also introduces risks such as diminished critical thinking, skill erosion, and increased anxiety. Emotional outcomes are similarly mixed, with AI systems showing promise for support and stress reduction, but raising concerns about dependency, inappropriate attachments, and ethical oversight. This paper aims to underscore the need for responsible and context-aware AI design, highlighting gaps for longitudinal research and grounded evaluation frameworks to balance benefits with emerging human-centric risks.
                
                
                    <strong>Published:</strong> 2025-10-20T17:06:46Z
                    <a href="http://arxiv.org/abs/2510.17753v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Active polymers translocate faster in confinement
                
                    <strong>Authors:</strong> K. R. Prathyusha, Paulami Sarkar, Justin Xu, Saad Bhamla
                
                
                    <strong>Abstract:</strong> Living organisms employ diverse strategies to navigate confined environments. Inspired by translocation observations on California blackworms (\textit{Lumbriculus variegatus}), we combine biological experiments and active-polymer simulations to examine how confinement and stiffness govern translocation. Active filaments translocate fastest when the channel width is comparable to their diameter, with escape time determined by propulsion speed, filament length, and channel geometry. In wider channels, activity and flexibility induce reorientation-dominated conformational changes that prolong escape. A single dimensionless ratio linking confinement to stiffness captures the transition from axis-aligned escape with short wall deflections for stiffer filaments, to reorientation-controlled motion with blob-like shapes for flexible filaments. These results provide a unified physical framework for active translocation in confinement and suggest design principles for flexible robotic filaments in complex environments.
                
                
                    <strong>Published:</strong> 2025-10-20T17:02:37Z
                    <a href="http://arxiv.org/abs/2510.17747v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Rethinking Search: A Study of University Students Perspectives on Using LLMs and Traditional Search Engines in Academic Problem Solving
                
                    <strong>Authors:</strong> Md. Faiyaz Abdullah Sayeedi, Md. Sadman Haque, Zobaer Ibn Razzaque, Robiul Awoul Robin, Sabila Nawshin
                
                
                    <strong>Abstract:</strong> With the increasing integration of Artificial Intelligence (AI) in academic problem solving, university students frequently alternate between traditional search engines like Google and large language models (LLMs) for information retrieval. This study explores students perceptions of both tools, emphasizing usability, efficiency, and their integration into academic workflows. Employing a mixed-methods approach, we surveyed 109 students from diverse disciplines and conducted in-depth interviews with 12 participants. Quantitative analyses, including ANOVA and chi-square tests, were used to assess differences in efficiency, satisfaction, and tool preference. Qualitative insights revealed that students commonly switch between GPT and Google: using Google for credible, multi-source information and GPT for summarization, explanation, and drafting. While neither tool proved sufficient on its own, there was a strong demand for a hybrid solution. In response, we developed a prototype, a chatbot embedded within the search interface, that combines GPTs conversational capabilities with Googles reliability to enhance academic research and reduce cognitive load.
                
                
                    <strong>Published:</strong> 2025-10-20T16:42:49Z
                    <a href="http://arxiv.org/abs/2510.17726v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues
                
                    <strong>Authors:</strong> Yaning Pan, Zekun Wang, Qianqian Xie, Yongqian Wen, Yuanxing Zhang, Guohui Zhang, Haoxuan Hu, Zhiyu Pan, Yibing Huang, Zhidong Gan, Yonghong Lin, An Ping, Tianhao Peng, Jiaheng Liu
                
                
                    <strong>Abstract:</strong> The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AIs ability to understand visual modalities. However, existing evaluation benchmarks remain limited to single-turn question answering, overlooking the complexity of multi-turn dialogues in real-world scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video understanding benchmark for evaluating MLLMs in multi-turn dialogues. Specifically, our MT-Video-Bench mainly assesses six core competencies that focus on perceptivity and interactivity, encompassing 987 meticulously curated multi-turn dialogues from diverse domains. These capabilities are rigorously aligned with real-world applications, such as interactive sports analysis and multi-turn video-based intelligent tutoring. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. The benchmark will be publicly available to foster future research.
                
                
                    <strong>Published:</strong> 2025-10-20T16:38:40Z
                    <a href="http://arxiv.org/abs/2510.17722v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                ConsistEdit: Highly Consistent and Precise Training-free Visual Editing
                
                    <strong>Authors:</strong> Zixin Yin, Ling-Hao Chen, Lionel Ni, Xili Dai
                
                
                    <strong>Abstract:</strong> Recent advances in training-free attention control methods have enabled flexible and efficient text-guided editing capabilities for existing generation models. However, current approaches struggle to simultaneously deliver strong editing strength while preserving consistency with the source. This limitation becomes particularly critical in multi-round and video editing, where visual errors can accumulate over time. Moreover, most existing methods enforce global consistency, which limits their ability to modify individual attributes such as texture while preserving others, thereby hindering fine-grained editing. Recently, the architectural shift from U-Net to MM-DiT has brought significant improvements in generative performance and introduced a novel mechanism for integrating text and vision modalities. These advancements pave the way for overcoming challenges that previous methods failed to resolve. Through an in-depth analysis of MM-DiT, we identify three key insights into its attention mechanisms. Building on these, we propose ConsistEdit, a novel attention control method specifically tailored for MM-DiT. ConsistEdit incorporates vision-only attention control, mask-guided pre-attention fusion, and differentiated manipulation of the query, key, and value tokens to produce consistent, prompt-aligned edits. Extensive experiments demonstrate that ConsistEdit achieves state-of-the-art performance across a wide range of image and video editing tasks, including both structure-consistent and structure-inconsistent scenarios. Unlike prior methods, it is the first approach to perform editing across all inference steps and attention layers without handcraft, significantly enhancing reliability and consistency, which enables robust multi-round and multi-region editing. Furthermore, it supports progressive adjustment of structural consistency, enabling finer control.
                
                
                    <strong>Published:</strong> 2025-10-20T17:59:52Z
                    <a href="http://arxiv.org/abs/2510.17803v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Glyph: Scaling Context Windows via Visual-Text Compression
                
                    <strong>Authors:</strong> Jiale Cheng, Yusen Liu, Xinyu Zhang, Yulin Fei, Wenyi Hong, Ruiliang Lyu, Weihan Wang, Zhe Su, Xiaotao Gu, Xiao Liu, Yushi Bai, Jie Tang, Hongning Wang, Minlie Huang
                
                
                    <strong>Abstract:</strong> Large language models (LLMs) increasingly rely on long-context modeling for tasks such as document understanding, code analysis, and multi-step reasoning. However, scaling context windows to the million-token level brings prohibitive computational and memory costs, limiting the practicality of long-context LLMs. In this work, we take a different perspective-visual context scaling-to tackle this challenge. Instead of extending token-based sequences, we propose Glyph, a framework that renders long texts into images and processes them with vision-language models (VLMs). This approach substantially compresses textual input while preserving semantic information, and we further design an LLM-driven genetic search to identify optimal visual rendering configurations for balancing accuracy and compression. Through extensive experiments, we demonstrate that our method achieves 3-4x token compression while maintaining accuracy comparable to leading LLMs such as Qwen3-8B on various long-context benchmarks. This compression also leads to around 4x faster prefilling and decoding, and approximately 2x faster SFT training. Furthermore, under extreme compression, a 128K-context VLM could scale to handle 1M-token-level text tasks. In addition, the rendered text data benefits real-world multimodal tasks, such as document understanding. Our code and model are released at https://github.com/thu-coai/Glyph.
                
                
                    <strong>Published:</strong> 2025-10-20T17:58:56Z
                    <a href="http://arxiv.org/abs/2510.17800v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics
                
                    <strong>Authors:</strong> Akshara Prabhakar, Roshan Ram, Zixiang Chen, Silvio Savarese, Frank Wang, Caiming Xiong, Huan Wang, Weiran Yao
                
                
                    <strong>Abstract:</strong> As information grows exponentially, enterprises face increasing pressure to transform unstructured data into coherent, actionable insights. While autonomous agents show promise, they often struggle with domain-specific nuances, intent alignment, and enterprise integration. We present Enterprise Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning Agent for adaptive query decomposition, (2) four specialized search agents (General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a Visualization Agent for data-driven insights, and (5) a reflection mechanism that detects knowledge gaps and updates research direction with optional human-in-the-loop steering guidance. These components enable automated report generation, real-time streaming, and seamless enterprise deployment, as validated on internal datasets. On open-ended benchmarks including DeepResearch Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without any human steering. We release the EDR framework and benchmark trajectories to advance research on multi-agent reasoning applications. Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and Dataset at https://huggingface.co/datasets/Salesforce/EDR-200
                
                
                    <strong>Published:</strong> 2025-10-20T17:55:11Z
                    <a href="http://arxiv.org/abs/2510.17797v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Executable Knowledge Graphs for Replicating AI Research
                
                    <strong>Authors:</strong> Yujie Luo, Zhuoyun Yu, Xuehai Wang, Yuqi Zhu, Ningyu Zhang, Lanning Wei, Lun Du, Da Zheng, Huajun Chen
                
                
                    <strong>Abstract:</strong> Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. Furthermore, previous approaches tend to overlook valuable implementation-level code signals and lack structured knowledge representations that support multi-granular retrieval and reuse. To overcome these challenges, we propose Executable Knowledge Graphs (xKG), a modular and pluggable knowledge base that automatically integrates technical insights, code snippets, and domain-specific knowledge extracted from scientific literature. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication. Code will released at https://github.com/zjunlp/xKG.
                
                
                    <strong>Published:</strong> 2025-10-20T17:53:23Z
                    <a href="http://arxiv.org/abs/2510.17795v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains
                
                    <strong>Authors:</strong> Austin Xu, Xuan-Phi Nguyen, Yilun Zhou, Chien-Sheng Wu, Caiming Xiong, Shafiq Joty
                
                
                    <strong>Abstract:</strong> Finetuning specialized generative evaluators has emerged as a popular paradigm to meet the increasing demand for scalable evaluation during both training and test-time. However, recent work has largely focused on applying new methodology, such as reinforcement learning (RL), to training evaluators, shying away from large-scale, data-driven development. In this work, we focus on data scaling, curating a set of 2.5M samples spanning five unique evaluation tasks (pairwise, step-level, reference-free and reference-based verification, and single rating) and multiple domains focused on reasoning evaluation. With our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges larger specialized RL-trained evaluators and FARE-20B sets the new standard for open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers, FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training, FARE improves the downstream RL-trained model performance by up to 14.1% vs. string-matching verifiers. When initialized from FARE, a continually-finetuned FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.
                
                
                    <strong>Published:</strong> 2025-10-20T17:52:06Z
                    <a href="http://arxiv.org/abs/2510.17793v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Rational Points on a Family of Genus 3 Hyperelliptic Curves
                
                    <strong>Authors:</strong> Roberto Hernandez
                
                
                    <strong>Abstract:</strong> We compute the rational points on certain members of the following family of hyperelliptic curves \[C_a \colon y^2 = x^8 + (4-4a^4) x^6 + (8a^4 + 6)x^4 + (4-4a^4)x^2 + 1\] via the method first developed by Demyanenko \cite{dem1966rational} and then further generalized by Manin \cite{manin1969p}. In particular, we show that the method of Chabauty--Coleman, while applicable to certain members of this family, is not the most efficient way of computing $C_a(\mathbb{Q})$. We adapt the approach of \cite{kulesz1999application}, incorporating root numbers to further restrict the possible ranks of the elliptic curves arising in the Jacobian decomposition.
                
                
                    <strong>Published:</strong> 2025-10-20T17:48:48Z
                    <a href="http://arxiv.org/abs/2510.17791v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action
                
                    <strong>Authors:</strong> Yuhao Yang, Zhen Yang, Zi-Yi Dou, Anh Nguyen, Keen You, Omar Attia, Andrew Szot, Michael Feng, Ram Ramrakhya, Alexander Toshev, Chao Huang, Yinfei Yang, Zhe Gan
                
                
                    <strong>Abstract:</strong> Multimodal agents for computer use rely exclusively on primitive actions (click, type, scroll) that require accurate visual grounding and lengthy execution chains, leading to cascading failures and performance bottlenecks. While other agents leverage rich programmatic interfaces (APIs, MCP servers, tools), computer-use agents (CUAs) remain isolated from these capabilities. We present UltraCUA, a foundation model that bridges this gap through hybrid action -- seamlessly integrating GUI primitives with high-level programmatic tool calls. To achieve this, our approach comprises four key components: (1) an automated pipeline that scales programmatic tools from software documentation, open-source repositories, and code generation; (2) a synthetic data engine producing over 17,000 verifiable tasks spanning real-world computer-use scenarios; (3) a large-scale high-quality hybrid action trajectory collection with both low-level GUI actions and high-level programmatic tool calls; and (4) a two-stage training pipeline combining supervised fine-tuning with online reinforcement learning, enabling strategic alternation between low-level and high-level actions. Experiments with our 7B and 32B models demonstrate substantial improvements over state-of-the-art agents. On OSWorld, UltraCUA models achieve an average 22% relative improvement over base models, while being 11% faster in terms of steps. Out-of-domain evaluation on WindowsAgentArena shows our model reaches 21.7% success rate, outperforming baselines trained on Windows data. The hybrid action mechanism proves critical, reducing error propagation while maintaining execution efficiency.
                
                
                    <strong>Published:</strong> 2025-10-20T17:48:26Z
                    <a href="http://arxiv.org/abs/2510.17790v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Exorcising ghosts with gravitational waves: cases of ghostful and ghost-free fourth-order gravity
                
                    <strong>Authors:</strong> Gaetano Lambiase, Shinji Mukohyama, Tanmay Kumar Poddar, Anna Chiara Rescigno
                
                
                    <strong>Abstract:</strong> General Relativity (GR) is an effective field theory valid in the infrared regime. Quadratic curvature extensions intended to probe ultraviolet physics generically propagate a massive spin-$2$ ghost and are therefore non-unitary. One route to remove ghost is by enlarging the geometric sector (torsion, non-metricity). We investigate the infrared phenomenology of both the standard (ghostful) and ghost-free fourth-order gravity theories by computing Gravitational Wave (GW) emission and confronting the results with observations such as the orbital-period decay of quasi-stable binaries such as PSR B1913+16 and PSR J1738+0333 and the chirp-mass evolution of GW170817. In the ghostful theory, besides the theoretical inconsistency due to non-unitarity, there are also phenomenological problems: the massless spin-$2$ GW flux cancels the combined GW fluxes of the massive spin-$2$ ghost and massive spin-$0$ scalar in the vanishing-mass limit, so the GR quadrupole formula is not recovered at the leading order. As a result, we obtain the GW constraint on the ghostful theory as $m\gtrsim 10^{-11}~\mathrm{eV}$, where $m$ is the mass of the massive modes. By contrast, the ghost-free theory smoothly reproduces the Newtonian potential and GR quadrupole formulae when the two coupling constants $\alpha_1$ and $\alpha_2$ vanish, independently of the mass $m$. Therefore, GW observations put mass-dependent upper bounds on the size of the coupling constants. For example, if we assume $\alpha_1\simeq\alpha_2$ for simplicity, then we obtain $\alpha_{1,2}\lesssim 4.2\times 10^{83}$ for $m\sim 3\times 10^{-16}\,\mathrm{eV}$ and $\alpha_{1,2}\lesssim 1.3\times 10^{75}$ for $m\sim 10^{-11}\,\mathrm{eV}$. To our knowledge, these are the first astrophysical-scale bounds reported for ghostful and ghost-free fourth-order gravity.
                
                
                    <strong>Published:</strong> 2025-10-20T17:47:09Z
                    <a href="http://arxiv.org/abs/2510.17789v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Comprehensive analysis of time-domain overlapping gravitational wave transients: A Lensing Study
                
                    <strong>Authors:</strong> Nishkal Rao, Anuj Mishra, Apratim Ganguly, Anupreeta More
                
                
                    <strong>Abstract:</strong> Next-generation GW detectors will produce a high rate of temporally overlapping signals from unrelated compact binary coalescences. Such overlaps can bias parameter estimation (PE) and mimic signatures of other physical effects, such as gravitational lensing. In this work, we investigate how overlapping signals can be degenerate with gravitational lensing by focusing on two scenarios: Type-II strong lensing and microlensing by an isolated point-mass lens. We simulate quasicircular binary black-hole pairs with chirp-mass ratios $\mathscr{M}_{\rm B}/\mathscr{M}_{\rm A}\in\{0.5,\,1,\,2\}$, SNR ratios $\mathrm{SNR}_{\rm B}/\mathrm{SNR}_{\rm A}\in\{0.5,\,1\}$, and coalescence-time offsets $\Delta t_{\rm c}\in[-0.1,\,0.1]~\mathrm{s}$. Bayesian PE and fitting-factor studies show that the Type-II lensing hypothesis is favored over the unlensed quasicircular hypothesis ($\log_{10}\mathscr{B}^{\rm L}_{\rm U}1$) only in a small region of the overlapping parameter space with $\mathscr{M}_{\rm B}/\mathscr{M}_{\rm A}\gtrsim1$ and $|\Delta t_{\rm c}|\leq0.03~\rm{s}$.. Meanwhile, false evidence for microlensing signatures can arise because, to a reasonable approximation, the model produces two superimposed images whose time delay can closely match $|\Delta t_{\rm c}|$. Overall, the inferred Bayes factor depends on relative chirp-mass ratios, relative loudness, difference in coalescence times, and also the absolute SNRs of the overlapping signals. Cumulatively, our results indicate that overlapping black-hole binaries with nearly equal chirp masses and comparable loudness are likely to be falsely identified as lensed. Such misidentifications are expected to become more common as detector sensitivities improve. While our study focuses on ground-based detectors using appropriate detectability thresholds, the findings naturally extend to next-generation GW observatories.
                
                
                    <strong>Published:</strong> 2025-10-20T17:46:37Z
                    <a href="http://arxiv.org/abs/2510.17787v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Inference-Time Compute Scaling For Flow Matching
                
                    <strong>Authors:</strong> Adam Stecklov, Noah El Rimawi-Fine, Mathieu Blanchette
                
                
                    <strong>Abstract:</strong> Allocating extra computation at inference time has recently improved sample quality in large language models and diffusion-based image generation. In parallel, Flow Matching (FM) has gained traction in language, vision, and scientific domains, but inference-time scaling methods for it remain under-explored. Concurrently, Kim et al., 2025 approach this problem but replace the linear interpolant with a non-linear variance-preserving (VP) interpolant at inference, sacrificing FMs efficient and straight sampling. Additionally, inference-time compute scaling for flow matching has only been applied to visual tasks, like image generation. We introduce novel inference-time scaling procedures for FM that preserve the linear interpolant during sampling. Evaluations of our method on image generation, and for the first time (to the best of our knowledge), unconditional protein generation, show that I) sample quality consistently improves as inference compute increases, and II) flow matching inference-time scaling can be applied to scientific domains.
                
                
                    <strong>Published:</strong> 2025-10-20T17:44:17Z
                    <a href="http://arxiv.org/abs/2510.17786v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
    
    
        <p><em>Generated by AI News Agent</em></p>
    

