
    
        <h1>ü§ñ AI Research News Report</h1>
        <p>Thursday, September 25, 2025</p>
        <p>Topics: ai alignment research, quantum computing</p>
    
    
        20Research Papers
        2Topics Covered
        YesAI Summary
    
    
    
        <h2>ü§ñ AI Summary</h2>
        <h2>ai alignment research</h2>
<p>Certainly! Here is a high-level summary of the research papers, highlighting the most important trends, breakthroughs, and implications for AI alignment research:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Efficiency and Scalability:</strong></p>
<ul>
<li>Models like EmbeddingGemma and SIM-CoT demonstrate advancements in creating more efficient AI systems that maintain high performance with fewer resources. This trend is crucial for deploying AI responsibly across various platforms, including those with limited computational capacity.</li>
<li>The ongoing exploration of lightweight models and efficient data processing frameworks reflects a broader trend towards optimizing AI for real-world applications where resource constraints are a critical factor.</li>
</ul>
</li>
<li><p><strong>Integration of AI and Real-World Applications:</strong></p>
<ul>
<li>Papers like the one on GitHub Copilot and xGFabric illustrate the increasing integration of AI technologies in practical settings, such as software development and agriculture. This trend underscores the need for AI systems that can effectively interact with and enhance human activities.</li>
</ul>
</li>
<li><p><strong>Security and Privacy Concerns:</strong></p>
<ul>
<li>The discussion on RAG systems highlights growing concerns about the security and privacy of AI systems, reflecting a trend towards more comprehensive threat modeling and risk assessment to ensure the safe deployment of AI technologies.</li>
</ul>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Lightweight and Robust Text Embeddings:</strong></p>
<ul>
<li>EmbeddingGemma introduces a novel approach to text representation that offers state-of-the-art performance in a more compact form. This breakthrough demonstrates the potential for creating powerful AI models that are both cost-effective and robust.</li>
</ul>
</li>
<li><p><strong>Implicit Reasoning Stability:</strong></p>
<ul>
<li>SIM-CoT addresses the instability in implicit chain-of-thought reasoning, presenting a new training module that ensures stable and diverse latent representations. This breakthrough is significant for improving the reliability and interpretability of AI systems.</li>
</ul>
</li>
<li><p><strong>Real-Time Data Processing:</strong></p>
<ul>
<li>xGFabrics integration of sensor networks and HPC facilities via private 5G networks marks a significant advancement in real-time data processing capabilities, essential for applications like digital agriculture where timely interventions are crucial.</li>
</ul>
</li>
<li><p><strong>Linguistic Assessment Tools:</strong></p>
<ul>
<li>The introduction of Z-Scores for evaluating disfluency removal offers a new tool for improving speech processing models, providing detailed insights into model performance beyond traditional metrics.</li>
</ul>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Practical Deployment and Accessibility:</strong></p>
<ul>
<li>The focus on efficiency and scalability in models like EmbeddingGemma and SIM-CoT implies that AI technologies can become more accessible and practical for a wider range of applications, including those with limited computational resources.</li>
</ul>
</li>
<li><p><strong>Enhanced Human-AI Collaboration:</strong></p>
<ul>
<li>Tools such as GitHub Copilot and improvements in VTON technology suggest that AI can significantly enhance human productivity and interaction, leading to more seamless collaboration between humans and AI systems.</li>
</ul>
</li>
<li><p><strong>Improved Security Frameworks:</strong></p>
<ul>
<li>The formalization of threat models for RAG systems indicates a move towards more secure and privacy-conscious AI deployment, essential for maintaining trust and integrity in AI applications.</li>
</ul>
</li>
<li><p><strong>Data-Driven Decision Making:</strong></p>
<ul>
<li>Frameworks like GESPI, which leverage synthetic data for statistical inference, highlight the potential for AI to enhance decision-making processes by improving data efficiency and accuracy in various domains.</li>
</ul>
</li>
<li><p><strong>Interdisciplinary Innovation:</strong></p>
<ul>
<li>The application of AI in diverse fields such as agriculture and speech processing, as demonstrated in xGFabric and the Z-Scores paper, underscores the interdisciplinary nature of AI research and its potential to drive innovation across sectors.</li>
</ul>
</li>
</ol>
<p>Overall, these papers collectively advance the field of AI alignment by focusing on efficiency, integration with real-world applications, and addressing security and privacy challenges, paving the way for responsible and effective AI deployment.</p>
<p><em>Based on 10 research papers</em></p>

<h2>quantum computing</h2>
<p>Here is a high-level summary of the provided research papers, focusing on trends, breakthroughs, and implications in the context of quantum computing:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Unified Frameworks and Cross-Modal Learning</strong>: There is a clear trend toward creating models that unify diverse tasks and modalities. For instance, EditVerse integrates image and video generation/editing, demonstrating a shift from task-specific models to comprehensive frameworks that leverage cross-modal capabilities.</p>
</li>
<li><p><strong>Enhanced Physical Realism and Control in Video Generation</strong>: With PhysCtrl, there is a move to incorporate physics-based frameworks into video generation, ensuring that generated content adheres to realistic physical principles and allows for controllable outcomes.</p>
</li>
<li><p><strong>Advanced Text Embedding Models</strong>: Models like EmbeddingGemma are focusing on lightweight architectures that maximize performance-to-cost ratios, indicating a trend towards efficiency and scalability in text representation.</p>
</li>
<li><p><strong>Resilience to Noise in Quantum Systems</strong>: The research on self-testing in noisy quantum environments and noise-induced limits in sensing highlights a growing focus on understanding and mitigating noise, which is crucial for the practical application of quantum technologies.</p>
</li>
<li><p><strong>Sublinear Time Algorithms for Graph Analysis</strong>: There is an ongoing effort to develop efficient algorithms for fundamental graph problems (e.g., counting edges and triangles) that are robust to varying conditions, such as unknown graph arboricity.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>HyLight Model for Hydrogen Emission</strong>: Although not directly related to quantum computing, the HyLight model represents a breakthrough in accurately simulating astrophysical phenomena, which can influence computational models in quantum simulations.</p>
</li>
<li><p><strong>EditVerse Framework</strong>: EditVerse achieves state-of-the-art performance across image and video tasks by unifying these modalities within a single model, showcasing the power of in-context learning and cross-modal transfer.</p>
</li>
<li><p><strong>PhysCtrl Framework</strong>: By integrating physics constraints into video generation, PhysCtrl offers a novel approach to create realistic and controllable video content, leveraging generative physics networks.</p>
</li>
<li><p><strong>Robust Self-Testing in High-Noise Quantum Environments</strong>: The development of self-tests that remain effective in high-noise conditions represents a significant advancement in ensuring the reliability of quantum systems.</p>
</li>
<li><p><strong>Enhanced Quantum Speed Limits</strong>: Introducing new quantum speed limits using novel divergence measures provides deeper insights into the dynamics of quantum systems, offering potential applications in quantum thermodynamics and beyond.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Multi-Modal AI Systems</strong>: The development of unified frameworks like EditVerse suggests a future where AI systems can seamlessly integrate various modalities, leading to more versatile and capable AI applications.</p>
</li>
<li><p><strong>Realistic Simulation and Video Generation</strong>: PhysCtrls physics-grounded approach could lead to more realistic simulations in fields like virtual reality and gaming, where accurate physical interactions are essential.</p>
</li>
<li><p><strong>Scalable Quantum Computing Tools</strong>: Advances in noise resilience and speed limits in quantum systems are crucial for the practical deployment of quantum computers, as they address fundamental challenges in maintaining accuracy and efficiency.</p>
</li>
<li><p><strong>Optimized Text Processing</strong>: With models like EmbeddingGemma, there are significant implications for natural language processing, particularly in contexts requiring efficient, high-throughput processing such as on-device applications.</p>
</li>
<li><p><strong>Efficient Graph Algorithms</strong>: The development of sublinear time algorithms that adapt to unknown graph properties can lead to more efficient data analysis techniques, with potential applications in network analysis and large-scale data processing.</p>
</li>
</ol>
<p>These papers collectively highlight a landscape where the integration of multiple technologies and frameworks is becoming increasingly important, with a strong focus on improving efficiency, scalability, and realism in both classical and quantum domains.</p>
<p><em>Based on 10 research papers</em></p>

        Generated by OpenAI GPT-4o-mini
    
    
    
    
        <h2>üì∞ News</h2>
        
            
                ai alignment research
                
                    
                        
                            <a href="https://www.theguardian.com/p/x3a7j4" target="_blank">From South Park v Trump to AI slopaganda: deepfakes are now part of the news cycle, for better and for worse | Anna Broinowski</a> ‚Äî Anna Broinowski
                        
                        2025-09-25T15:00:44Z
                        <br>
                        The article discusses the impact of AI-generated content, particularly deepfakes, on the media landscape. Salman Rushdie suggests AI is not yet a threat to literary creativity, but deepfakes have become significant in video and news media, challenging our perception of reality. These synthetic audio and video tools have moved from niche to mainstream, illustrating futurist Roy Amaras observation about underestimating long-term impacts of technology. With predictions that AI-generated content could dominate the internet by 2027, the influence of deepfakes raises critical questions about trust in digital media. Initially emerging as disturbing nonconsensual content, deepfakes have evolved into powerful political tools, prompting concerns about their potential to undermine evidentiary systems and fuel misinformation.
                        <a href="https://www.theguardian.com/p/x3a7j4" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39b38" target="_blank">Preparing students for a world shaped by artificial intelligence | Letters</a>
                        
                        2025-09-24T17:25:13Z
                        <br>
                        Professors Leo McCann and Simon Sweeney caution against uncritical reliance on AI, emphasizing the importance of integrating large language models thoughtfully in higher education to enhance teaching and learning. As AI becomes ubiquitous in the workforce, excluding it from educational contexts risks leaving graduates unprepared. The focus should be on teaching students to use AI critically, such as critiquing AI-generated responses against primary sources to highlight both the technologys limitations and the value of deep learning. The underlying issue lies in outdated assessment models, which need redesigning to assess both the process and the product to maintain critical skills. Universities should lead in fostering ethical and creative uses of AI, ensuring it strengthens rather than undermines educational objectives.
                        <a href="https://www.theguardian.com/p/x39b38" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3a42c" target="_blank">Adviser to UK minister claimed AI firms would never have to compensate creatives</a> ‚Äî Robert Booth and Dan Milmo
                        
                        2025-09-24T11:07:45Z
                        <br>
                        A senior aide to the UK government has stated that AI companies are unlikely to ever have to legally compensate creatives for using their work to train AI systems, causing concern among campaigners advocating for fair compensation. Kirsty Innes, adviser to the UK Secretary of State for Science, Innovation, and Technology, made the statement, which was later deleted, on social media. This issue arises amidst a government consultation on how creatives should be compensated and recent calls from prominent British artists for better protection of creators rights. Innes, who has a history with the Tony Blair Institute, commented on the futility of enforcing compensation laws, noting that AI firms could operate outside UK jurisdiction. The controversy highlights ongoing tensions between Labour and the UK creative community, particularly as the government explores potential copyright law reforms.
                        <a href="https://www.theguardian.com/p/x3a42c" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39me5" target="_blank">Tariffs on talent? Trumps‚Äôs visa fees threaten tech‚Äôs most prized employees</a> ‚Äî Blake Montgomery
                        
                        2025-09-23T13:46:03Z
                        <br>
                        In recent developments, the Trump administration has imposed a new $100,000 annual fee on H-1B visa applications, a move that poses significant challenges to the U.S. tech industry, which heavily depends on these visas. This decision has raised concerns among major tech companies like Amazon, Microsoft, and Google, prompting them to urge their employees abroad to return to the U.S. promptly. The H-1B program is crucial for the tech sector, as about two-thirds of its jobs are computer-related, and it also supports roles in engineering, education, and healthcare. Previously, tech giants had contributed millions to Trumps campaign in hopes of favorable industry policies, but the new fee threatens this relationship. The immediate effects of this policy change remain uncertain, leaving human resources departments anxious about potential disruptions.
                        <a href="https://www.theguardian.com/p/x39me5" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39jf6" target="_blank">Pixel 10 Pro XL review: Google‚Äôs superphone gets AI and magnetic upgrades</a> ‚Äî Samuel Gibbs Consumer technology editor
                        
                        2025-09-23T06:00:40Z
                        <br>
                        Googles Pixel 10 Pro XL, a flagship superphone, introduces enhancements including a larger battery, faster charging, and new AI tools, positioning itself against Apples iPhone 17 Pro Max and Samsungs Galaxy S25 Ultra. Priced at ¬£1,199 (‚Ç¨1,299/$1,199/A$1,999), it features a massive OLED screen, ideal for media consumption, and supports Qi2.2 wireless charging with magnetic accessory capabilities. Despite its similarity in dimensions to the previous 9 Pro XL, it is heavier and mostly requires two-handed use. Powered by the Google Tensor G5 chip, it delivers strong performance for general tasks but falls short against Snapdragon-equipped devices for high-end gaming. Its substantial battery offers impressive longevity, lasting up to 52 hours on a single charge.
                        <a href="https://www.theguardian.com/p/x39jf6" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39ye9" target="_blank">AI ‚Äòcarries risks‚Äô but will help tackle global heating, says UN‚Äôs climate chief</a> ‚Äî Fiona Harvey Environment editor
                        
                        2025-09-22T19:54:59Z
                        <br>
                        The UN‚Äôs climate chief, Simon Stiell, emphasized the dual role of artificial intelligence in addressing the climate crisis, advocating for governmental regulation of the technology. AI is currently being utilized to enhance the efficiency of energy systems and innovate carbon reduction methods in industrial processes. However, Stiell highlighted the significant energy demands of large datacentres, urging governments to mitigate these concerns by integrating renewables and improving energy efficiency. He stated that AI should augment human capacity and drive tangible outcomes such as managing microgrids and mapping climate risks. Stiell expressed optimism about global climate efforts, noting alignment with the Paris agreement and the growth of renewable energy, while defending climate diplomacy amid geopolitical tensions.
                        <a href="https://www.theguardian.com/p/x39ye9" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39y87" target="_blank">Nvidia to invest $100bn in OpenAI, bringing the two AI firms together</a> ‚Äî Guardian staff and agencies
                        
                        2025-09-22T18:14:17Z
                        <br>
                        Nvidia has announced a $100 billion investment in OpenAI, involving the provision of data center chips, marking a significant collaboration between the two AI industry leaders. The deal, expected to commence with chip deliveries in late 2026, includes two transactions where OpenAI will purchase chips from Nvidia and Nvidia will receive non-controlling shares in OpenAI. An initial $10 billion of Nvidias investment will activate once a definitive agreement for chip purchases is formalized. This partnership follows Nvidias earlier $6.6 billion investment and builds on OpenAIs strategic financial involvement with Microsoft, which includes a profit-sharing agreement. The collaboration aims to deploy at least 10GW of Nvidia chips to bolster OpenAIs AI infrastructure, emphasizing the critical role of compute power in advancing AI capabilities.
                        <a href="https://www.theguardian.com/p/x39y87" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39429" target="_blank">UK startup Wayve begins testing self-driving tech in Nissan cars on Tokyo‚Äôs streets</a> ‚Äî Jasper Jolly
                        
                        2025-09-22T05:00:05Z
                        <br>
                        British startup Wayve is testing its self-driving technology on Nissans electric Ariya vehicles in Tokyo, aiming for a 2027 consumer launch. This collaboration followed an agreement with Nissan in April, and Wayve is seeking a $500 million investment from chip-maker Nvidia. The startup has already raised $1.3 billion from investors, including SoftBank, to expand its operations in the US, Germany, Japan, and London. Nvidia is considering a significant investment in Wayve, providing essential chips for both the vehicles and the datacenters that train Wayves AI models. Founded by Alex Kendall in 2017, Wayve competes with major players like Tesla, Waymo, and Baidu in the self-driving space.
                        <a href="https://www.theguardian.com/p/x39429" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x394fq" target="_blank">More Britons view AI as economic risk than opportunity, Tony Blair thinktank finds</a> ‚Äî Dan Milmo Global technology editor
                        
                        2025-09-22T05:00:04Z
                        <br>
                        A survey conducted by the Tony Blair Institute reveals that nearly twice as many Britons perceive artificial intelligence as an economic risk rather than an opportunity, with 38% seeing it as a risk and 20% as an opportunity. The findings pose a challenge to Keir Starmers vision of the UK becoming an AI superpower, as public trust emerges as a significant barrier to AI adoption. Jakob M√∂kander from the Institute emphasized that while the UK is unlikely to lead in AI development, it could become a leader in AI adoption if public trust is established. The UK governments economic strategy heavily relies on AI, with Starmer advocating for the UK to be a major player in the field. However, public concerns about AIs impact on the economy and jobs highlight the need for the government to effectively communicate AIs benefits.
                        <a href="https://www.theguardian.com/p/x394fq" target="_blank">Read full article</a>
                    
                    
                Source: The Guardian
            
            
            
                quantum computing
                
                    
                        
                            <a href="https://www.theguardian.com/p/x39ydp" target="_blank">Murdoch, Ellison and China: what we know about the US‚Äôs TikTok deal</a> ‚Äî Dara Kerr and agencies
                        
                        2025-09-22T21:26:12Z
                        <br>
                        The White House has indicated an impending deal to transfer TikToks US ownership to a group of investors, with President Trump expected to sign an executive order to facilitate this transition. Oracle is set to license TikTok‚Äôs recommendation algorithm as part of the agreement, expanding its management of TikTok‚Äôs US user data. President Trump and Chinas President Xi Jinping discussed the TikTok deal over a phone call, which Trump described positively. Earlier discussions in Madrid between US and Chinese leaders also addressed TikToks ownership amidst broader trade talks. The resolution of TikToks future in the US follows legislative and judicial actions mandating a sale to a US entity, with Trump delaying enforcement of a ban pending a finalized agreement.
                        <a href="https://www.theguardian.com/p/x39ydp" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x39y87" target="_blank">Nvidia to invest $100bn in OpenAI, bringing the two AI firms together</a> ‚Äî Guardian staff and agencies
                        
                        2025-09-22T18:14:17Z
                        <br>
                        Nvidia plans to invest up to $100 billion in OpenAI, providing data center chips as part of a strategic partnership between the two prominent AI firms. The agreement includes two intertwined transactions where OpenAI will purchase Nvidia chips, and Nvidia will acquire non-controlling shares in OpenAI. Nvidias initial $10 billion investment will commence upon finalizing an agreement for OpenAIs chip acquisition. Previously, Nvidia invested $6.6 billion in OpenAI, and Microsoft holds a 49% profit stake following a $13 billion investment in 2023. The partnership aims to deploy at least 10GW of Nvidia chips to enhance OpenAIs AI infrastructure, with OpenAI CEO Sam Altman emphasizing the critical role of computing power for future economic development and AI innovation.
                        <a href="https://www.theguardian.com/p/x39y87" target="_blank">Read full article</a>
                    
                    
                Source: The Guardian
            
            
    
    
    
        <h2>üìÑ Research Papers (20)</h2>
        
            
                EmbeddingGemma: Powerful and Lightweight Text Representations
                
                    <strong>Authors:</strong> Henrique Schechter Vera, Sahil Dua, Biao Zhang, Daniel Salz, Ryan Mullins, Sindhu Raghuram Panyam, Sara Smoot, Iftekhar Naim, Joe Zou, Feiyang Chen, Daniel Cer, Alice Lisak, Min Choi, Lucas Gonzalez, Omar Sanseviero, Glenn Cameron, Ian Ballantyne, Kat Black, Kaifeng Chen, Weiyi Wang, Zhe Li, Gus Martins, Jinhyuk Lee, Mark Sherwood, Juyeong Ji, Renjie Wu, Jingxiao Zheng, Jyotinder Singh, Abheesht Sharma, Divya Sreepat, Aashi Jain, Adham Elarabawy, AJ Co, Andreas Doumanoglou, Babak Samari, Ben Hora, Brian Potetz, Dahun Kim, Enrique Alfonseca, Fedor Moiseev, Feng Han, Frank Palma Gomez, Gustavo Hern√°ndez √Åbrego, Hesen Zhang, Hui Hui, Jay Han, Karan Gill, Ke Chen, Koert Chen, Madhuri Shanbhogue, Michael Boratko, Paul Suganthan, Sai Meher Karthik Duddu, Sandeep Mariserla, Setareh Ariafar, Shanfeng Zhang, Shijie Zhang, Simon Baumgartner, Sonam Goenka, Steve Qiu, Tanmaya Dabral, Trevor Walker, Vikram Rao, Waleed Khawaja, Wenlei Zhou, Xiaoqi Ren, Ye Xia, Yichang Chen, Yi-Ting Chen, Zhe Dong, Zhongli Ding, Francesco Visin, Ga√´l Liu, Jiageng Zhang, Kathleen Kenealy, Michelle Casbon, Ravin Kumar, Thomas Mesnard, Zach Gleicher, Cormac Brick, Olivier Lacombe, Adam Roberts, Yunhsuan Sung, Raphael Hoffmann, Tris Warkentin, Armand Joulin, Tom Duerig, Mojtaba Seyedhosseini
                
                
                    <strong>Abstract:</strong> We introduce EmbeddingGemma, a new lightweight, open text embedding model based on the Gemma 3 language model family. Our innovative training recipe strategically captures knowledge from larger models via encoder-decoder initialization and geometric embedding distillation. We improve model robustness and expressiveness with a spread-out regularizer, and ensure generalizability by merging checkpoints from varied, optimized mixtures. Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual, English, and code domains, EmbeddingGemma (300M) achieves state-of-the-art results. Notably, it outperforms prior top models, both proprietary and open, with fewer than 500M parameters, and provides performance comparable to models double its size, offering an exceptional performance-to-cost ratio. Remarkably, this lead persists when quantizing model weights or truncating embedding outputs. This makes EmbeddingGemma particularly well-suited for low-latency and high-throughput use cases such as on-device applications. We provide ablation studies exploring our key design choices. We release EmbeddingGemma to the community to promote further research.
                
                
                    <strong>Published:</strong> 2025-09-24T17:56:51Z
                    <a href="http://arxiv.org/abs/2509.20354v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Developer Productivity With and Without GitHub Copilot: A Longitudinal Mixed-Methods Case Study
                
                    <strong>Authors:</strong> Viktoria Stray, Elias Goldmann Brandtz√¶g, Viggo Tellefsen Wivestad, Astri Barbala, Nils Brede Moe
                
                
                    <strong>Abstract:</strong> This study investigates the real-world impact of the generative AI (GenAI) tool GitHub Copilot on developer activity and perceived productivity. We conducted a mixed-methods case study in NAV IT, a large public sector agile organization. We analyzed 26,317 unique non-merge commits from 703 of NAV ITs GitHub repositories over a two-year period, focusing on commit-based activity metrics from 25 Copilot users and 14 non-users. The analysis was complemented by survey responses on their roles and perceived productivity, as well as 13 interviews. Our analysis of activity metrics revealed that individuals who used Copilot were consistently more active than non-users, even prior to Copilots introduction. We did not find any statistically significant changes in commit-based activity for Copilot users after they adopted the tool, although minor increases were observed. This suggests a discrepancy between changes in commit-based metrics and the subjective experience of productivity.
                
                
                    <strong>Published:</strong> 2025-09-24T17:55:56Z
                    <a href="http://arxiv.org/abs/2509.20353v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees
                
                    <strong>Authors:</strong> Meshi Bashari, Yonghoon Lee, Roy Maor Lotan, Edgar Dobriban, Yaniv Romano
                
                
                    <strong>Abstract:</strong> The rapid proliferation of high-quality synthetic data -- generated by advanced AI models or collected as auxiliary data from related tasks -- presents both opportunities and challenges for statistical inference. This paper introduces a GEneral Synthetic-Powered Inference (GESPI) framework that wraps around any statistical inference procedure to safely enhance sample efficiency by combining synthetic and real data. Our framework leverages high-quality synthetic data to boost statistical power, yet adaptively defaults to the standard inference method using only real data when synthetic data is of low quality. The error of our method remains below a user-specified bound without any distributional assumptions on the synthetic data, and decreases as the quality of the synthetic data improves. This flexibility enables seamless integration with conformal prediction, risk control, hypothesis testing, and multiple testing procedures, all without modifying the base inference method. We demonstrate the benefits of our method on challenging tasks with limited labeled data, including AlphaFold protein structure prediction, and comparing large reasoning models on complex math problems.
                
                
                    <strong>Published:</strong> 2025-09-24T17:37:14Z
                    <a href="http://arxiv.org/abs/2509.20345v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On
                
                    <strong>Authors:</strong> Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee Kiat Koo, Karim Bouyarmane
                
                
                    <strong>Abstract:</strong> As online shopping continues to grow, the demand for Virtual Try-On (VTON) technology has surged, allowing customers to visualize products on themselves by overlaying product images onto their own photos. An essential yet challenging condition for effective VTON is pose control, which ensures accurate alignment of products with the users body while supporting diverse orientations for a more immersive experience. However, incorporating pose conditions into VTON models presents several challenges, including selecting the optimal pose representation, integrating poses without additional parameters, and balancing pose preservation with flexible pose control. In this work, we build upon a baseline VTON model that concatenates the reference image condition without external encoder, control network, or complex attention layers. We investigate methods to incorporate pose control into this pure concatenation paradigm by spatially concatenating pose data, comparing performance using pose maps and skeletons, without adding any additional parameters or module to the baseline model. Our experiments reveal that pose stitching with pose maps yields the best results, enhancing both pose preservation and output realism. Additionally, we introduce a mixed-mask training strategy using fine-grained and bounding box masks, allowing the model to support flexible product integration across varied poses and conditions.
                
                
                    <strong>Published:</strong> 2025-09-24T17:35:23Z
                    <a href="http://arxiv.org/abs/2509.20343v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                xGFabric: Coupling Sensor Networks and HPC Facilities with Private 5G Wireless Networks for Real-Time Digital Agriculture
                
                    <strong>Authors:</strong> Liubov Kurafeeva, Alan Subedi, Ryan Hartung, Michael Fay, Avhishek Biswas, Shantenu Jha, Ozgur O. Kilic, Chandra Krintz, Andre Merzky, Douglas Thain, Mehmet C. Vuran, Rich Wolski
                
                
                    <strong>Abstract:</strong> Advanced scientific applications require coupling distributed sensor networks with centralized high-performance computing facilities. Citrus Under Protective Screening (CUPS) exemplifies this need in digital agriculture, where citrus research facilities are instrumented with numerous sensors monitoring environmental conditions and detecting protective screening damage. CUPS demands access to computational fluid dynamics codes for modeling environmental conditions and guiding real-time interventions like water application or robotic repairs. These computing domains have contrasting properties: sensor networks provide low-performance, limited-capacity, unreliable data access, while high-performance facilities offer enormous computing power through high-latency batch processing. Private 5G networks present novel capabilities addressing this challenge by providing low latency, high throughput, and reliability necessary for near-real-time coupling of edge sensor networks with HPC simulations. This work presents xGFabric, an end-to-end system coupling sensor networks with HPC facilities through Private 5G networks. The prototype connects remote sensors via 5G network slicing to HPC systems, enabling real-time digital agriculture simulation.
                
                
                    <strong>Published:</strong> 2025-09-24T17:33:31Z
                    <a href="http://dx.doi.org/10.1145/3731599.3767589" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Feature Dynamics as Implicit Data Augmentation: A Depth-Decomposed View on Deep Neural Network Generalization
                
                    <strong>Authors:</strong> Tianyu Ruan, Kuo Gai, Shihua Zhang
                
                
                    <strong>Abstract:</strong> Why do deep networks generalize well? In contrast to classical generalization theory, we approach this fundamental question by examining not only inputs and outputs, but the evolution of internal features. Our study suggests a phenomenon of temporal consistency that predictions remain stable when shallow features from earlier checkpoints combine with deeper features from later ones. This stability is not a trivial convergence artifact. It acts as a form of implicit, structured augmentation that supports generalization. We show that temporal consistency extends to unseen and corrupted data, but collapses when semantic structure is destroyed (e.g., random labels). Statistical tests further reveal that SGD injects anisotropic noise aligned with a few principal directions, reinforcing its role as a source of structured variability. Together, these findings suggest a conceptual perspective that links feature dynamics to generalization, pointing toward future work on practical surrogates for measuring temporal feature evolution.
                
                
                    <strong>Published:</strong> 2025-09-24T17:23:56Z
                    <a href="http://arxiv.org/abs/2509.20334v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                RAG Security and Privacy: Formalizing the Threat Model and Attack Surface
                
                    <strong>Authors:</strong> Atousa Arzanipour, Rouzbeh Behnia, Reza Ebrahimi, Kaushik Dutta
                
                
                    <strong>Abstract:</strong> Retrieval-Augmented Generation (RAG) is an emerging approach in natural language processing that combines large language models (LLMs) with external document retrieval to produce more accurate and grounded responses. While RAG has shown strong potential in reducing hallucinations and improving factual consistency, it also introduces new privacy and security challenges that differ from those faced by traditional LLMs. Existing research has demonstrated that LLMs can leak sensitive information through training data memorization or adversarial prompts, and RAG systems inherit many of these vulnerabilities. At the same time, reliance of RAG on an external knowledge base opens new attack surfaces, including the potential for leaking information about the presence or content of retrieved documents, or for injecting malicious content to manipulate model behavior. Despite these risks, there is currently no formal framework that defines the threat landscape for RAG systems. In this paper, we address a critical gap in the literature by proposing, to the best of our knowledge, the first formal threat model for retrieval-RAG systems. We introduce a structured taxonomy of adversary types based on their access to model components and data, and we formally define key threat vectors such as document-level membership inference and data poisoning, which pose serious privacy and integrity risks in real-world deployments. By establishing formal definitions and attack models, our work lays the foundation for a more rigorous and principled understanding of privacy and security in RAG systems.
                
                
                    <strong>Published:</strong> 2025-09-24T17:11:35Z
                    <a href="http://arxiv.org/abs/2509.20324v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Z-Scores: A Metric for Linguistically Assessing Disfluency Removal
                
                    <strong>Authors:</strong> Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee
                
                
                    <strong>Abstract:</strong> Evaluating disfluency removal in speech requires more than aggregate token-level scores. Traditional word-based metrics such as precision, recall, and F1 (E-Scores) capture overall performance but cannot reveal why models succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded evaluation metric that categorizes system behavior across distinct disfluency types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust mapping between generated text and disfluent transcripts, allowing Z-Scores to expose systematic weaknesses that word-level metrics obscure. By providing category-specific diagnostics, Z-Scores enable researchers to identify model failure modes and design targeted interventions -- such as tailored prompts or data augmentation -- yielding measurable performance improvements. A case study with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies hidden in aggregate F1, directly informing model refinement strategies.
                
                
                    <strong>Published:</strong> 2025-09-24T17:02:39Z
                    <a href="http://arxiv.org/abs/2509.20319v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                A Comprehensive Evaluation of YOLO-based Deer Detection Performance on Edge Devices
                
                    <strong>Authors:</strong> Bishal Adhikari, Jiajia Li, Eric S. Michel, Jacob Dykes, Te-Ming Paul Tseng, Mary Love Tagert, Dong Chen
                
                
                    <strong>Abstract:</strong> The escalating economic losses in agriculture due to deer intrusion, estimated to be in the hundreds of millions of dollars annually in the U.S., highlight the inadequacy of traditional mitigation strategies since these methods are often labor-intensive, costly, and ineffective for modern farming systems. To overcome this, there is a critical need for intelligent, autonomous solutions which require accurate and efficient deer detection. But the progress in this field is impeded by a significant gap in the literature, mainly the lack of a domain-specific, practical dataset and limited study on the on-field deployability of deer detection systems. Addressing this gap, this study presents a comprehensive evaluation of state-of-the-art deep learning models for deer detection in challenging real-world scenarios. The contributions of this work are threefold. First, we introduce a curated, publicly available dataset of 3,095 annotated images with bounding-box annotations of deer, derived from the Idaho Cameratraps project. Second, we provide an extensive comparative analysis of 12 model variants across four recent YOLO architectures(v8, v9, v10, and v11). Finally, we benchmarked performance on a high-end NVIDIA RTX 5090 GPU and evaluated on two representative edge computing platforms: Raspberry Pi 5 and NVIDIA Jetson AGX Xavier. Results show that the real-time detection is not feasible in Raspberry Pi without hardware-specific model optimization, while NVIDIA Jetson provides greater than 30 FPS with GPU-accelerated inference on s and n series models. This study also reveals that smaller, architecturally advanced models such as YOLOv11n, YOLOv8s, and YOLOv9s offer the optimal balance of high accuracy (AP@.5  0.85) and computational efficiency (FPS  30). To support further research, both the source code and datasets are publicly available at https://github.com/WinnerBishal/track-the-deer.
                
                
                    <strong>Published:</strong> 2025-09-24T17:01:50Z
                    <a href="http://arxiv.org/abs/2509.20318v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                SIM-CoT: Supervised Implicit Chain-of-Thought
                
                    <strong>Authors:</strong> Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Jiaqi Wang, Xipeng Qiu, Dahua Lin
                
                
                    <strong>Abstract:</strong> Implicit Chain-of-Thought (CoT) methods present a promising, token-efficient alternative to explicit CoT reasoning in Large Language Models (LLMs), but a persistent performance gap has limited the application of implicit CoT. We identify a core latent instability issue by scaling the computational budget of implicit CoT approaches: as we increase the number of implicit reasoning tokens to enhance performance, the training process often becomes unstable and collapses. Our analysis reveals that this instability arises from the latent representations becoming homogeneous and losing their semantic diversity, a failure caused by insufficient step-level supervision in existing implicit CoT approaches. To address this issue, we propose SIM-CoT, a plug-and-play training module that introduces step-level supervision to stabilize and enrich the latent reasoning space. Specifically, SIM-CoT employs an auxiliary decoder during training to align each implicit token with its corresponding explicit reasoning step, ensuring that latent states capture distinct and meaningful information. The proposed auxiliary decoder is removed during inference, preserving the computational efficiency of implicit CoT methods with no added overhead. In addition, the auxiliary decoder affords interpretability of implicit reasoning by projecting each latent token onto an explicit reasoning vocabulary, enabling per-step visualization of semantic roles and diagnosis. SIM-CoT significantly enhances both the in-domain accuracy and out-of-domain stability of various implicit CoT methods, boosting baselines like Coconut by +8.2% on GPT-2 and CODI by +3.0% on LLaMA-3.1 8B. Demonstrating strong scalability, SIM-CoT also surpasses the explicit CoT baseline on GPT-2 by 2.1% with 2.3\times greater token efficiency, while substantially closing the performance gap on larger models like LLaMA-3.1 8B.
                
                
                    <strong>Published:</strong> 2025-09-24T17:01:32Z
                    <a href="http://arxiv.org/abs/2509.20317v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                The HyLight model for hydrogen emission lines in simulated nebulae
                
                    <strong>Authors:</strong> Yuankang Liu, Tom Theuns, Tsang Keung Chan, Alexander J. Richings, Anna F. McLeod
                
                
                    <strong>Abstract:</strong> Hydrogen recombination lines are key diagnostics of ionized gas in the interstellar medium (ISM), particularly within photoionized nebulae. Hydrodynamical simulations, even those that include radiative transfer, do not usually determine the level population of hydrogen required to compute line intensities, but rather interpolate them from pre-computed tables. Here we present the HyLight atomic model, which captures the dominant processes governing the level populations, enabling the calculation of all dipole-allowed hydrogen transitions as well as two-photon transitions from the 2s to 1s state without the need to pre-computed tables. We compare HyLight predictions to those of other codes and published tables, finding differences between the various rates of up to factors of several per cent for common transitions, including those of the Balmer and Brackett series. However, we find sub-per cent agreement between HyLight and the Cloudy spectral synthesis code when enforcing photo-ionisation equilibrium in gas under typical nebular conditions of density and temperature. Importantly, HyLight can also predict emissivities if the gas is not in photo-ionisation equilibrium. As examples, we compute the ratios between the total photoionization rate and line intensities in a nebula, and post-process a snapshot from Sparcs, a hydrodynamical code that combines radiative transfer with non-equilibrium physics, and compute mock hydrogen emission line maps which can be compared directly to observations. Implemented in Python, HyLight is an accurate tool for determining the level population in neutral hydrogen, a crucial step in bridging the gap between simulations and observations in studies of photoionized regions in galaxies.
                
                
                    <strong>Published:</strong> 2025-09-24T17:59:49Z
                    <a href="http://arxiv.org/abs/2509.20361v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning
                
                    <strong>Authors:</strong> Xuan Ju, Tianyu Wang, Yuqian Zhou, He Zhang, Qing Liu, Nanxuan Zhao, Zhifei Zhang, Yijun Li, Yuanhao Cai, Shaoteng Liu, Daniil Pakhomov, Zhe Lin, Soo Ye Kim, Qiang Xu
                
                
                    <strong>Abstract:</strong> Recent advances in foundation models highlight a clear trend toward unification and scaling, showing emergent capabilities across diverse domains. While image generation and editing have rapidly transitioned from task-specific to unified frameworks, video generation and editing remain fragmented due to architectural limitations and data scarcity. In this work, we introduce EditVerse, a unified framework for image and video generation and editing within a single model. By representing all modalities, i.e., text, image, and video, as a unified token sequence, EditVerse leverages self-attention to achieve robust in-context learning, natural cross-modal knowledge transfer, and flexible handling of inputs and outputs with arbitrary resolutions and durations. To address the lack of video editing training data, we design a scalable data pipeline that curates 232K video editing samples and combines them with large-scale image and video datasets for joint training. Furthermore, we present EditVerseBench, the first benchmark for instruction-based video editing covering diverse tasks and resolutions. Extensive experiments and user studies demonstrate that EditVerse achieves state-of-the-art performance, surpassing existing open-source and commercial models, while exhibiting emergent editing and generation abilities across modalities.
                
                
                    <strong>Published:</strong> 2025-09-24T17:59:30Z
                    <a href="http://arxiv.org/abs/2509.20360v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation
                
                    <strong>Authors:</strong> Chen Wang, Chuhao Chen, Yiming Huang, Zhiyang Dou, Yuan Liu, Jiatao Gu, Lingjie Liu
                
                
                    <strong>Abstract:</strong> Existing video generation models excel at producing photo-realistic videos from text or images, but often lack physical plausibility and 3D controllability. To overcome these limitations, we introduce PhysCtrl, a novel framework for physics-grounded image-to-video generation with physical parameters and force control. At its core is a generative physics network that learns the distribution of physical dynamics across four materials (elastic, sand, plasticine, and rigid) via a diffusion model conditioned on physics parameters and applied forces. We represent physical dynamics as 3D point trajectories and train on a large-scale synthetic dataset of 550K animations generated by physics simulators. We enhance the diffusion model with a novel spatiotemporal attention block that emulates particle interactions and incorporates physics-based constraints during training to enforce physical plausibility. Experiments show that PhysCtrl generates realistic, physics-grounded motion trajectories which, when used to drive image-to-video models, yield high-fidelity, controllable videos that outperform existing methods in both visual quality and physical plausibility. Project Page: https://cwchenwang.github.io/physctrl
                
                
                    <strong>Published:</strong> 2025-09-24T17:58:04Z
                    <a href="http://arxiv.org/abs/2509.20358v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Language Models that Think, Chat Better
                
                    <strong>Authors:</strong> Adithya Bhaskar, Xi Ye, Danqi Chen
                
                
                    <strong>Abstract:</strong> Reinforcement learning with verifiable rewards (RLVR) improves language model reasoning by using rule-based rewards in verifiable domains such as mathematics and code. However, RLVR leads to limited generalization for open-ended tasks -- such as writing outline essays or making meal plans -- where humans reason routinely. This paper shows that the RLVR paradigm is effective beyond verifiable domains, and introduces **RL** with **M**odel-rewarded **T**hinking (**RLMT**) for general-purpose chat capabilities. Using diverse real-world prompts, RLMT requires LMs to generate long CoT reasoning before response, and optimizes them with online RL against a preference-based reward model used in RLHF. Across 40 training runs on Llama-3.1-8B and Qwen-2.5-7B (both base and instruct) and multiple optimization algorithms (DPO, PPO, and GRPO), RLMT consistently outperforms standard RLHF pipelines. This includes substantial gains of 3-7 points on three chat benchmarks (AlpacaEval2, WildBench, and ArenaHardV2), along with 1-3 point improvements on other tasks like creative writing and general knowledge. Our best 8B model surpasses GPT-4o in chat and creative writing and rivals Claude-3.7-Sonnet (Thinking). RLMT can also be applied directly to base models without an SFT stage, akin to R1-Zero training. Remarkably, with only 7K prompts, Llama-3.1-8B base trained with our RLMT recipe outperforms Llama-3.1-8B-Instruct post-trained with a complex multi-staged pipeline with 25M+ examples. We close with qualitative and quantitative analyses of how trained models plan their responses. Our results rethink the post-training pipeline and call upon future work to understand and employ thinking more broadly.
                
                
                    <strong>Published:</strong> 2025-09-24T17:57:34Z
                    <a href="http://arxiv.org/abs/2509.20357v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                EmbeddingGemma: Powerful and Lightweight Text Representations
                
                    <strong>Authors:</strong> Henrique Schechter Vera, Sahil Dua, Biao Zhang, Daniel Salz, Ryan Mullins, Sindhu Raghuram Panyam, Sara Smoot, Iftekhar Naim, Joe Zou, Feiyang Chen, Daniel Cer, Alice Lisak, Min Choi, Lucas Gonzalez, Omar Sanseviero, Glenn Cameron, Ian Ballantyne, Kat Black, Kaifeng Chen, Weiyi Wang, Zhe Li, Gus Martins, Jinhyuk Lee, Mark Sherwood, Juyeong Ji, Renjie Wu, Jingxiao Zheng, Jyotinder Singh, Abheesht Sharma, Divya Sreepat, Aashi Jain, Adham Elarabawy, AJ Co, Andreas Doumanoglou, Babak Samari, Ben Hora, Brian Potetz, Dahun Kim, Enrique Alfonseca, Fedor Moiseev, Feng Han, Frank Palma Gomez, Gustavo Hern√°ndez √Åbrego, Hesen Zhang, Hui Hui, Jay Han, Karan Gill, Ke Chen, Koert Chen, Madhuri Shanbhogue, Michael Boratko, Paul Suganthan, Sai Meher Karthik Duddu, Sandeep Mariserla, Setareh Ariafar, Shanfeng Zhang, Shijie Zhang, Simon Baumgartner, Sonam Goenka, Steve Qiu, Tanmaya Dabral, Trevor Walker, Vikram Rao, Waleed Khawaja, Wenlei Zhou, Xiaoqi Ren, Ye Xia, Yichang Chen, Yi-Ting Chen, Zhe Dong, Zhongli Ding, Francesco Visin, Ga√´l Liu, Jiageng Zhang, Kathleen Kenealy, Michelle Casbon, Ravin Kumar, Thomas Mesnard, Zach Gleicher, Cormac Brick, Olivier Lacombe, Adam Roberts, Yunhsuan Sung, Raphael Hoffmann, Tris Warkentin, Armand Joulin, Tom Duerig, Mojtaba Seyedhosseini
                
                
                    <strong>Abstract:</strong> We introduce EmbeddingGemma, a new lightweight, open text embedding model based on the Gemma 3 language model family. Our innovative training recipe strategically captures knowledge from larger models via encoder-decoder initialization and geometric embedding distillation. We improve model robustness and expressiveness with a spread-out regularizer, and ensure generalizability by merging checkpoints from varied, optimized mixtures. Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual, English, and code domains, EmbeddingGemma (300M) achieves state-of-the-art results. Notably, it outperforms prior top models, both proprietary and open, with fewer than 500M parameters, and provides performance comparable to models double its size, offering an exceptional performance-to-cost ratio. Remarkably, this lead persists when quantizing model weights or truncating embedding outputs. This makes EmbeddingGemma particularly well-suited for low-latency and high-throughput use cases such as on-device applications. We provide ablation studies exploring our key design choices. We release EmbeddingGemma to the community to promote further research.
                
                
                    <strong>Published:</strong> 2025-09-24T17:56:51Z
                    <a href="http://arxiv.org/abs/2509.20354v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Superfluid-Mott transition in a frustrated triangular optical lattice
                
                    <strong>Authors:</strong> Mehedi Hasan, Luca Donini, Sompob Shanokprasith, Daniel Braund, Tobias Marozsak, Moritz Epping, Daniel Reed, Max Melchner, Tiffany Harte, Ulrich Schneider
                
                
                    <strong>Abstract:</strong> Geometric frustration can significantly increase the complexity and richness of many-body physics and, for instance, suppress antiferromagnetic order in quantum magnets. Here, we employ ultracold bosonic $^{39}$K atoms in a triangular optical lattice to study geometric frustration by stabilizing the gas at the frustrated upper band edge using negative absolute temperatures. We find that geometric frustration suppresses the critical interaction strength for the (chiral-)superfluid to Mott insulator ($\chi$-SF-MI) quantum phase transition by a factor of 2.7(3) and furthermore changes the critical dynamics of the transition. Although the emergence of coherence during fast ramps from MI to the ($\chi$-)SF regime is continuous in both cases, for ramps longer than a few tunnelling times, significant differences emerge. In the \frs case, no long-range order emerges on the studied timescales, highlighting a significantly reduced rate or even saturation of the emerging coherence. This work opens the door to quantum simulations of frustrated systems that are often intractable by classical simulations.
                
                
                    <strong>Published:</strong> 2025-09-24T17:54:58Z
                    <a href="http://arxiv.org/abs/2509.20352v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Testable algorithms for approximately counting edges and triangles in sublinear time and space
                
                    <strong>Authors:</strong> Talya Eden, Ronitt Rubinfeld, Arsen Vasilyan
                
                
                    <strong>Abstract:</strong> We consider the fundamental problems of approximately counting the numbers of edges and triangles in a graph in sublinear time. Previous algorithms for these tasks are significantly more efficient under a promise that the arboricity of the graph is bounded by some parameter $\overline{\alpha}$. However, when this promise is violated, the estimates given by these algorithms are no longer guaranteed to be correct. For the triangle counting task, we give an algorithm that requires no promise on the input graph $G$, and computes a $(1\pm \epsilon)$-approximation for the number of triangles $t$ in $G$ in time $O^*\left( \frac{m\cdot \alpha(G)}{t} + \frac{m}{t^{2/3}} \right)$, where $\alpha(G)$ is the arboricity of the graph. The algorithm can be used on any graph $G$ (no prior knowledge the arboricity $\alpha(G)$ is required), and the algorithm adapts its run-time on the fly based on the graph $G$. We accomplish this by trying a sequence of candidate values $\tilde{\alpha}$ for $\alpha(G)$ and using a novel algorithm in the framework of testable algorithms. This ensures that wrong candidates $\tilde{\alpha}$ cannot lead to incorrect estimates: as long as the advice is incorrect, the algorithm detects it and continues with a new candidate. Once the algorithm accepts the candidate, its output is guaranteed to be correct with high probability. We prove that this approach preserves - up to an additive overhead - the dramatic efficiency gains obtainable when good arboricity bounds are known in advance, while ensuring robustness against misleading advice. We further complement this result with a lower bound, showing that such an overhead is unavoidable whenever the advice may be faulty. We further demonstrate implications of our results for triangle counting in the streaming model.
                
                
                    <strong>Published:</strong> 2025-09-24T17:52:04Z
                    <a href="http://arxiv.org/abs/2509.20351v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Nonlocal Games and Self-tests in the Presence of Noise
                
                    <strong>Authors:</strong> Honghao Fu, Minglong Qin, Haochen Xu, Penghui Yao
                
                
                    <strong>Abstract:</strong> Self-testing is a key characteristic of certain nonlocal games, which allow one to uniquely determine the underlying quantum state and measurement operators used by the players, based solely on their observed input-output correlations [MY04]. Motivated by the limitations of current quantum devices, we study self-testing in the high-noise regime, where the two players are restricted to sharing many copies of a noisy entangled state with an arbitrary constant noise rate. In this setting, many existing self-tests fail to certify any nontrivial structure. We first characterize the maximal winning probabilities of the CHSH game [CHSH69], the Magic Square game [Mer90a], and the 2-out-of-n CHSH game [CRSV18] as functions of the noise rate, under the assumption that players use traceless observables. These results enable the construction of device-independent protocols for estimating the noise rate. Building on this analysis, we show that these three games--together with an additional test enforcing the tracelessness of binary observables--can self-test one, two, and n pairs of anticommuting Pauli operators, respectively. These are the first known self-tests that are robust in the high-noise regime and remain sound even when the players measurements are noisy. Our proofs rely on Sum-of-Squares (SoS) decompositions and Pauli analysis techniques developed in the contexts of quantum proof systems and quantum learning theory.
                
                
                    <strong>Published:</strong> 2025-09-24T17:45:03Z
                    <a href="http://arxiv.org/abs/2509.20350v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Quantum speed limits based on Jensen-Shannon and Jeffreys divergences for general physical processes
                
                    <strong>Authors:</strong> Jucelino Ferreira de Sousa, Diego Paiva Pires
                
                
                    <strong>Abstract:</strong> We discuss quantum speed limits (QSLs) for finite-dimensional quantum systems undergoing a general physical process. These QSLs were obtained using two families of entropic measures, namely the square root of the Jensen-Shannon divergence, which in turn defines a faithful distance of quantum states, and the square root of the quantum Jeffreys divergence. The results apply to both closed and open quantum systems, and are evaluated in terms of the Schatten speed of the evolved state, as well as cost functions that depend on the smallest and largest eigenvalues of both initial and instantaneous states of the quantum system. To illustrate our findings, we focus on the unitary and nonunitary dynamics of mixed single-qubit states. In the first case, we obtain speed limits $\textit{\`{a} la}$ Mandelstam-Tamm that are inversely proportional to the variance of the Hamiltonian driving the evolution. In the second case, we set the nonunitary dynamics to be described by the noisy operations: depolarizing channel, phase damping channel, and generalized amplitude damping channel. We provide analytical results for the two entropic measures, present numerical simulations to support our results on the speed limits, comment on the tightness of the bounds, and provide a comparison with previous QSLs. Our results may find applications in the study of quantum thermodynamics, entropic uncertainty relations, and also complexity of many-body systems.
                
                
                    <strong>Published:</strong> 2025-09-24T17:39:09Z
                    <a href="http://arxiv.org/abs/2509.20347v1" target="_blank">üìÑ View Paper</a>
                
            
        
            
                Noise-Induced Limits on Responsivity and SNR for Nonlinear Exceptional Point Sensing
                
                    <strong>Authors:</strong> Todd Darcie, J. Stewart Aitchison
                
                
                    <strong>Abstract:</strong> Exceptional points (EPs) have been suggested for ultra-sensitive sensing because the eigenfrequency splitting grows as the nth-root of a perturbation, suggesting divergent responsivity. In ideal linear devices, however, this responsivity gain is reconciled by a matching divergence in the quantum shot-noise floor, so the net signal-to-noise ratio remains unchanged. Recent work has extended this argument to nonlinear devices, such as above-threshold lasers, predicting other divergences at an EP that is shifted by the interplay of noise and saturation effects. Here we analyze a system of two coupled saturable resonators and show analytically that a self-consistent treatment of fluctuation dynamics removes these divergences entirely. Islands of instability arise in the parameter space surrounding the EP due to the coupling of phase noise into the amplitude dynamics, dictating a maximum responsivity and maximum noise that can be experimentally observed. Stochastic Langevin simulations of the full nonlinear system corroborate our analytical results down to zero detuning.
                
                
                    <strong>Published:</strong> 2025-09-24T17:38:41Z
                    <a href="http://arxiv.org/abs/2509.20346v1" target="_blank">üìÑ View Paper</a>
                
            
        
    
    
        <p><em>Generated by AI News Agent</em></p>
    

