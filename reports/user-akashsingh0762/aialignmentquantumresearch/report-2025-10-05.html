
    
        <h1>ðŸ¤– AI Research News Report</h1>
        <p>Sunday, October 5, 2025</p>
        <p>Topics: ai alignment research, quantum computing</p>
    
    
        20Research Papers
        2Topics Covered
        YesAI Summary
    
    
    
        <h2>ðŸ¤– AI Summary</h2>
        <h2>ai alignment research</h2>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Enhancement of Multi-Subject Fidelity in AI Models</strong>: Research is focusing on improving the capability of AI models, particularly text-to-image systems, to accurately represent multiple subjects in a single prompt. This involves addressing common issues like attribute leakage and identity entanglement.</p>
</li>
<li><p><strong>Robustness and Security in AI Systems</strong>: There is a growing emphasis on understanding and mitigating vulnerabilities in AI systems, such as those found in 3D scene representations and large language models, to prevent adversarial attacks and ensure reliability.</p>
</li>
<li><p><strong>Efficient and Scalable AI Techniques</strong>: Efforts are being made to make AI systems more efficient, both in terms of computational resources and response to complex tasks. This includes techniques like KV-cache distillation for reasoning in language models and scalable traffic forecasting methods.</p>
</li>
<li><p><strong>Interactivity and Real-Time Optimization</strong>: AI training and operation are moving towards more interactive frameworks that allow dynamic adjustments during training, which could lead to more stable and adaptable AI systems.</p>
</li>
<li><p><strong>Multimodal and Contextual Understanding</strong>: There is an increasing focus on integrating multiple sensory inputs and contextual information to enhance AIs understanding and interaction capabilities, particularly in video generation and traffic forecasting.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Flow Matching for Multi-Subject Fidelity</strong>: A theoretical framework using stochastic optimal control has been developed to improve multi-subject fidelity in text-to-image models, resulting in architecture-agnostic algorithms that enhance the representation of multiple subjects without compromising style.</p>
</li>
<li><p><strong>StealthAttack for 3D Scene Robustness</strong>: A novel poisoning method using density-guided illusions has been introduced, effectively embedding viewpoint-dependent illusions in 3D Gaussian Splatting models, which represents a significant step in understanding and countering vulnerabilities.</p>
</li>
<li><p><strong>KaVa for Latent Reasoning</strong>: The introduction of a framework that aligns latent reasoning with compressed KV-cache distillation marks a significant advancement, offering a scalable way to supervise and improve latent reasoning in large language models.</p>
</li>
<li><p><strong>Interactive Training Framework</strong>: The development of an open-source framework for real-time, feedback-driven optimization in neural network training allows for more responsive and adaptable AI model development.</p>
</li>
<li><p><strong>VidGuard-R1 for Video Authenticity Detection</strong>: This model achieves state-of-the-art performance in detecting AI-generated videos, providing both accurate judgments and interpretable explanations, crucial for mitigating misinformation risks.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Advancement in AI Model Reliability</strong>: The improvements in multi-subject fidelity and robustness against adversarial attacks will likely lead to more reliable AI systems, enhancing their applicability in diverse, real-world scenarios.</p>
</li>
<li><p><strong>Improved AI Efficiency and Scalability</strong>: Techniques like KV-cache distillation and interactive training can reduce resource demands and increase the scalability of AI systems, making them more accessible and practical for widespread use.</p>
</li>
<li><p><strong>Enhanced Security Measures</strong>: The development of methods like StealthAttack highlights the importance of addressing AI vulnerabilities proactively, which is crucial for maintaining trust in AI systems as they are integrated into sensitive applications.</p>
</li>
<li><p><strong>Broader Applicability and Functionality</strong>: With the integration of multimodal sensing and real-time optimization, AI systems are likely to become more versatile and capable of handling complex, nuanced tasks, opening up new opportunities in fields like robotics and urban planning.</p>
</li>
<li><p><strong>Trust and Transparency in AI Systems</strong>: Models like VidGuard-R1 that provide interpretable explanations alongside accuracy will be essential in fostering trust and transparency, particularly in applications with societal impact, such as media and information dissemination.</p>
</li>
</ol>
<p><em>Based on 10 research papers</em></p>

<h2>quantum computing</h2>
<p>It seems there is a misunderstanding. The research papers listed are not directly related to quantum computing; they cover various topics such as machine learning, image generation, and neural networks. However, I can provide a structured summary of these papers based on the trends, breakthroughs, and implications in their respective fields. Hereâ€™s a high-level summary of the papers:</p>
<ol>
<li><p><strong>Most Important Trends</strong></p>
<ul>
<li><strong>Multi-Subject Fidelity in Models</strong>: There is a growing trend to improve models ability to handle complex inputs with multiple subjects, addressing challenges like attribute leakage and identity entanglement.</li>
<li><strong>Robustness in 3D Scene Representation</strong>: The field is focusing on enhancing the robustness of 3D scene models against adversarial attacks, reflecting the importance of security in novel view synthesis.</li>
<li><strong>Sound Recognition from Real-World Interactions</strong>: There is significant interest in developing models that can learn and identify sounds in context with object interactions, simulating human-like perception.</li>
<li><strong>Latent Reasoning in Language Models</strong>: Efforts are being made to optimize the reasoning capabilities of language models by reducing computational overhead while maintaining accuracy.</li>
<li><strong>Dynamic Property Inference from Videos</strong>: Models are increasingly being trained to infer physical properties from video data, reflecting a trend towards integrating richer, temporal information into AI systems.</li>
</ul>
</li>
<li><p><strong>Breakthroughs</strong></p>
<ul>
<li><strong>Flow Matching in Multi-Subject Alignment</strong>: The introduction of algorithms that improve multi-subject fidelity in models marks a significant advancement, allowing for better alignment and disentanglement of subjects.</li>
<li><strong>Density-Guided Poisoning for 3D Models</strong>: A novel approach to poisoning attacks that strategically uses density estimation, improving attack effectiveness while minimizing impact on unpoisoned views.</li>
<li><strong>Interactive Training Framework</strong>: The development of a framework for real-time intervention in neural network training offers a new paradigm for dynamic optimization, enhancing training stability and adaptability.</li>
<li><strong>Equilibrium Matching in Generative Models</strong>: A new perspective on generative modeling that relies on equilibrium dynamics, providing a more efficient and flexible approach compared to traditional methods.</li>
</ul>
</li>
<li><p><strong>Implications</strong></p>
<ul>
<li><strong>Enhanced Model Fidelity</strong>: Improvements in multi-subject fidelity can lead to more accurate and reliable AI systems, particularly in fields requiring complex input processing, such as healthcare and autonomous systems.</li>
<li><strong>Security in 3D Representations</strong>: By addressing vulnerabilities in 3D scene models, these advancements can lead to more secure applications in virtual reality and augmented reality environments.</li>
<li><strong>Improved Sound Recognition</strong>: The ability to accurately identify sounds in context can enhance applications in robotics, assistive technologies, and surveillance, aligning AI capabilities more closely with human sensory perception.</li>
<li><strong>Efficiency in Language Models</strong>: The shift towards latent reasoning frameworks can significantly reduce the computational demands of language models, making them more accessible and scalable.</li>
<li><strong>Dynamic AI Understanding from Videos</strong>: Advancements in inferring physical properties from videos can improve AIs understanding of the physical world, leading to better decision-making in dynamic environments such as robotics and autonomous vehicles.</li>
</ul>
</li>
</ol>
<p>These summaries reflect the diverse and evolving nature of research in AI and machine learning, highlighting innovations that are not directly related to quantum computing but are significant in their respective domains.</p>
<p><em>Based on 10 research papers</em></p>

        Generated by OpenAI GPT-4o-mini
    
    
    
    
        <h2>ðŸ“° News</h2>
        
            
                ai alignment research
                
                    
                        
                            <a href="https://www.theguardian.com/p/x34da4" target="_blank">Way past its prime: how did Amazon get so rubbish?</a> â€” Cory Doctorow
                        
                        2025-10-05T05:00:28Z
                        <br>
                        Cory Doctorow discusses the rapid decline in quality of internet services, coining the term enshittification to describe this phenomenon. He observes that popular platforms like Facebook are inundated with engagement-bait, AI-generated content, and ads, making user experiences frustrating and disheartening. Enshittification outlines a predictable pattern where platforms initially serve users well, then prioritize business customers, and finally exploit both to maximize their own value, leading to a degraded service. Doctorow compares this decline to a contagious disease, with a clear progression of symptoms and effects. The term has gained significant traction, encapsulating the widespread deterioration of online services.
                        <a href="https://www.theguardian.com/p/x34da4" target="_blank">Read full article</a>
                    
                    
                    
                        
                            <a href="https://www.theguardian.com/p/x3bmed" target="_blank">Elon Musk becomes first person with net worth of $500bn</a> â€” Dan Milmo and agency
                        
                        2025-10-02T09:42:43Z
                        <br>
                        Elon Musk has become the first individual to reach a net worth of $500 billion, driven largely by a surge in Teslas share price, where he holds a 12% stake. Although his wealth briefly crossed this significant threshold before settling at $499 billion, Teslas valuation remains over $1.5 trillion. The increase in Teslas stock followed the companys strong performance in vehicle deliveries, reporting 497,099 units for the July-September period, boosted by a U.S. tax credit for electric vehicles. Musks entrepreneurial ventures extend beyond Tesla, including a 42% stake in SpaceX, which is seeking a $400 billion valuation, and xAI, an AI company valued at $75 billion. Despite previous challenges from competitive pressures and Musks controversial political statements, Teslas stock has rebounded, gaining 13% since early 2025 as investor confidence in Musks leadership has strengthened.
                        <a href="https://www.theguardian.com/p/x3bmed" target="_blank">Read full article</a>
                    
                    
                Source: The Guardian
            
            
            
                quantum computing
                
                Source: The Guardian
            
            
    
    
    
        <h2>ðŸ“„ Research Papers (20)</h2>
        
            
                Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity
                
                    <strong>Authors:</strong> Eric Tillmann Bill, Enis Simsar, Thomas Hofmann
                
                
                    <strong>Abstract:</strong> Text-to-image (T2I) models excel on single-entity prompts but struggle with multi-subject descriptions, often showing attribute leakage, identity entanglement, and subject omissions. We introduce the first theoretical framework with a principled, optimizable objective for steering sampling dynamics toward multi-subject fidelity. Viewing flow matching (FM) through stochastic optimal control (SOC), we formulate subject disentanglement as control over a trained FM sampler. This yields two architecture-agnostic algorithms: (i) a training-free test-time controller that perturbs the base velocity with a single-pass update, and (ii) Adjoint Matching, a lightweight fine-tuning rule that regresses a control network to a backward adjoint signal while preserving base-model capabilities. The same formulation unifies prior attention heuristics, extends to diffusion models via a flow-diffusion correspondence, and provides the first fine-tuning route explicitly designed for multi-subject fidelity. Empirically, on Stable Diffusion 3.5, FLUX, and Stable Diffusion XL, both algorithms consistently improve multi-subject alignment while maintaining base-model style. Test-time control runs efficiently on commodity GPUs, and fine-tuned controllers trained on limited prompts generalize to unseen ones. We further highlight FOCUS (Flow Optimal Control for Unentangled Subjects), which achieves state-of-the-art multi-subject fidelity across models.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:58Z
                    <a href="http://arxiv.org/abs/2510.02315v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions
                
                    <strong>Authors:</strong> Bo-Hsu Ke, You-Zhe Xie, Yu-Lun Liu, Wei-Chen Chiu
                
                
                    <strong>Abstract:</strong> 3D scene representation methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have significantly advanced novel view synthesis. As these methods become prevalent, addressing their vulnerabilities becomes critical. We analyze 3DGS robustness against image-level poisoning attacks and propose a novel density-guided poisoning method. Our method strategically injects Gaussian points into low-density regions identified via Kernel Density Estimation (KDE), embedding viewpoint-dependent illusory objects clearly visible from poisoned views while minimally affecting innocent views. Additionally, we introduce an adaptive noise strategy to disrupt multi-view consistency, further enhancing attack effectiveness. We propose a KDE-based evaluation protocol to assess attack difficulty systematically, enabling objective benchmarking for future research. Extensive experiments demonstrate our methods superior performance compared to state-of-the-art techniques. Project page: https://hentci.github.io/stealthattack/
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:57Z
                    <a href="http://arxiv.org/abs/2510.02314v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                KaVa: Latent Reasoning via Compressed KV-Cache Distillation
                
                    <strong>Authors:</strong> Anna Kuzina, Maciej Pioro, Paul N. Whatmough, Babak Ehteshami Bejnordi
                
                
                    <strong>Abstract:</strong> Large Language Models (LLMs) excel at multi-step reasoning problems with explicit chain-of-thought (CoT), but verbose traces incur significant computational costs and memory overhead, and often carry redundant, stylistic artifacts. Latent reasoning has emerged as an efficient alternative that internalizes the thought process, but it suffers from a critical lack of supervision, limiting its effectiveness on complex, natural-language reasoning traces. In this work, we propose KaVa, the first framework that bridges this gap by distilling knowledge directly from a compressed KV-cache of the teacher into a latent-reasoning student via self-distillation, leveraging the representational flexibility of continuous latent tokens to align stepwise KV trajectories. We show that the abstract, unstructured knowledge within compressed KV-cache, which lacks direct token correspondence, can serve as a rich supervisory signal for a latent reasoning student. Empirically, the approach consistently outperforms strong latent baselines, exhibits markedly smaller degradation from equation-only to natural-language traces, and scales to larger backbones while preserving efficiency. These results establish compressed KV-cache distillation as a scalable supervision signal for latent reasoning, combining the accuracy of CoT-trained teachers with the efficiency and deployability of latent inference.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:51Z
                    <a href="http://arxiv.org/abs/2510.02312v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Robust Tangent Space Estimation via Laplacian Eigenvector Gradient Orthogonalization
                
                    <strong>Authors:</strong> Dhruv Kohli, Sawyer J. Robertson, Gal Mishne, Alexander Cloninger
                
                
                    <strong>Abstract:</strong> Estimating the tangent spaces of a data manifold is a fundamental problem in data analysis. The standard approach, Local Principal Component Analysis (LPCA), struggles in high-noise settings due to a critical trade-off in choosing the neighborhood size. Selecting an optimal size requires prior knowledge of the geometric and noise characteristics of the data that are often unavailable. In this paper, we propose a spectral method, Laplacian Eigenvector Gradient Orthogonalization (LEGO), that utilizes the global structure of the data to guide local tangent space estimation. Instead of relying solely on local neighborhoods, LEGO estimates the tangent space at each data point by orthogonalizing the gradients of low-frequency eigenvectors of the graph Laplacian. We provide two theoretical justifications of our method. First, a differential geometric analysis on a tubular neighborhood of a manifold shows that gradients of the low-frequency Laplacian eigenfunctions of the tube align closely with the manifolds tangent bundle, while an eigenfunction with high gradient in directions orthogonal to the manifold lie deeper in the spectrum. Second, a random matrix theoretic analysis also demonstrates that low-frequency eigenvectors are robust to sub-Gaussian noise. Through comprehensive experiments, we demonstrate that LEGO yields tangent space estimates that are significantly more robust to noise than those from LPCA, resulting in marked improvements in downstream tasks such as manifold learning, boundary detection, and local intrinsic dimension estimation.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:45Z
                    <a href="http://arxiv.org/abs/2510.02308v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Interactive Training: Feedback-Driven Neural Network Optimization
                
                    <strong>Authors:</strong> Wentao Zhang, Yang Young Lu, Yuntian Deng
                
                
                    <strong>Abstract:</strong> Traditional neural network training typically follows fixed, predefined optimization recipes, lacking the flexibility to dynamically respond to instabilities or emerging training issues. In this paper, we introduce Interactive Training, an open-source framework that enables real-time, feedback-driven intervention during neural network training by human experts or automated AI agents. At its core, Interactive Training uses a control server to mediate communication between users or agents and the ongoing training process, allowing users to dynamically adjust optimizer hyperparameters, training data, and model checkpoints. Through three case studies, we demonstrate that Interactive Training achieves superior training stability, reduced sensitivity to initial hyperparameters, and improved adaptability to evolving user needs, paving the way toward a future training paradigm where AI agents autonomously monitor training logs, proactively resolve instabilities, and optimize training dynamics.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:00Z
                    <a href="http://arxiv.org/abs/2510.02297v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                F2LLM Technical Report: Matching SOTA Embedding Performance with 6 Million Open-Source Data
                
                    <strong>Authors:</strong> Ziyin Zhang, Zihan Liao, Hang Yu, Peng Di, Rui Wang
                
                
                    <strong>Abstract:</strong> We introduce F2LLM - Foundation to Feature Large Language Models, a suite of state-of-the-art embedding models in three sizes: 0.6B, 1.7B, and 4B. Unlike previous top-ranking embedding models that require massive contrastive pretraining, sophisticated training pipelines, and costly synthetic training data, F2LLM is directly finetuned from foundation models on 6 million query-document-negative tuples curated from open-source, non-synthetic datasets, striking a strong balance between training cost, model size, and embedding performance. On the MTEB English leaderboard, F2LLM-4B ranks 2nd among models with approximately 4B parameters and 7th overall, while F2LLM-1.7B ranks 1st among models in the 1B-2B size range. To facilitate future research in the field, we release the models, training dataset, and code, positioning F2LLM as a strong, reproducible, and budget-friendly baseline for future works.
                
                
                    <strong>Published:</strong> 2025-10-02T17:58:49Z
                    <a href="http://arxiv.org/abs/2510.02294v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                MultiModal Action Conditioned Video Generation
                
                    <strong>Authors:</strong> Yichen Li, Antonio Torralba
                
                
                    <strong>Abstract:</strong> Current video models fail as world model as they lack fine-graiend control. General-purpose household robots require real-time fine motor control to handle delicate tasks and urgent situations. In this work, we introduce fine-grained multimodal actions to capture such precise control. We consider senses of proprioception, kinesthesia, force haptics, and muscle activation. Such multimodal senses naturally enables fine-grained interactions that are difficult to simulate with text-conditioned generative models. To effectively simulate fine-grained multisensory actions, we develop a feature learning paradigm that aligns these modalities while preserving the unique information each modality provides. We further propose a regularization scheme to enhance causality of the action trajectory features in representing intricate interaction dynamics. Experiments show that incorporating multimodal senses improves simulation accuracy and reduces temporal drift. Extensive ablation studies and downstream applications demonstrate the effectiveness and practicality of our work.
                
                
                    <strong>Published:</strong> 2025-10-02T17:57:06Z
                    <a href="http://arxiv.org/abs/2510.02287v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming Attacks
                
                    <strong>Authors:</strong> Ruohao Guo, Afshin Oroojlooy, Roshan Sridhar, Miguel Ballesteros, Alan Ritter, Dan Roth
                
                
                    <strong>Abstract:</strong> Despite recent rapid progress in AI safety, current large language models remain vulnerable to adversarial attacks in multi-turn interaction settings, where attackers strategically adapt their prompts across conversation turns and pose a more critical yet realistic challenge. Existing approaches that discover safety vulnerabilities either rely on manual red-teaming with human experts or employ automated methods using pre-defined templates and human-curated attack data, with most focusing on single-turn attacks. However, these methods did not explore the vast space of possible multi-turn attacks, failing to consider novel attack trajectories that emerge from complex dialogue dynamics and strategic conversation planning. This gap is particularly critical given recent findings that LLMs exhibit significantly higher vulnerability to multi-turn attacks compared to single-turn attacks. We propose DialTree-RPO, an on-policy reinforcement learning framework integrated with tree search that autonomously discovers diverse multi-turn attack strategies by treating the dialogue as a sequential decision-making problem, enabling systematic exploration without manually curated data. Through extensive experiments, our approach not only achieves more than 25.9% higher ASR across 10 target models compared to previous state-of-the-art approaches, but also effectively uncovers new attack strategies by learning optimal dialogue policies that maximize attack success across multiple turns.
                
                
                    <strong>Published:</strong> 2025-10-02T17:57:05Z
                    <a href="http://arxiv.org/abs/2510.02286v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL
                
                    <strong>Authors:</strong> Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen, Dongqi Han, Caihua Shan, Muhammad Muaz, Lili Qiu
                
                
                    <strong>Abstract:</strong> With the rapid advancement of AI-generated videos, there is an urgent need for effective detection tools to mitigate societal risks such as misinformation and reputational harm. In addition to accurate classification, it is essential that detection models provide interpretable explanations to ensure transparency for regulators and end users. To address these challenges, we introduce VidGuard-R1, the first video authenticity detector that fine-tunes a multi-modal large language model (MLLM) using group relative policy optimization (GRPO). Our model delivers both highly accurate judgments and insightful reasoning. We curate a challenging dataset of 140k real and AI-generated videos produced by state-of-the-art generation models, carefully designing the generation process to maximize discrimination difficulty. We then fine-tune Qwen-VL using GRPO with two specialized reward models that target temporal artifacts and generation complexity. Extensive experiments demonstrate that VidGuard-R1 achieves state-of-the-art zero-shot performance on existing benchmarks, with additional training pushing accuracy above 95%. Case studies further show that VidGuard-R1 produces precise and interpretable rationales behind its predictions. The code is publicly available at https://VidGuard-R1.github.io.
                
                
                    <strong>Published:</strong> 2025-10-02T17:55:37Z
                    <a href="http://arxiv.org/abs/2510.02282v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Fine-Grained Urban Traffic Forecasting on Metropolis-Scale Road Networks
                
                    <strong>Authors:</strong> Fedor Velikonivtsev, Oleg Platonov, Gleb Bazhenov, Liudmila Prokhorenkova
                
                
                    <strong>Abstract:</strong> Traffic forecasting on road networks is a complex task of significant practical importance that has recently attracted considerable attention from the machine learning community, with spatiotemporal graph neural networks (GNNs) becoming the most popular approach. The proper evaluation of traffic forecasting methods requires realistic datasets, but current publicly available benchmarks have significant drawbacks, including the absence of information about road connectivity for road graph construction, limited information about road properties, and a relatively small number of road segments that falls short of real-world applications. Further, current datasets mostly contain information about intercity highways with sparsely located sensors, while city road networks arguably present a more challenging forecasting task due to much denser roads and more complex urban traffic patterns. In this work, we provide a more complete, realistic, and challenging benchmark for traffic forecasting by releasing datasets representing the road networks of two major cities, with the largest containing almost 100,000 road segments (more than a 10-fold increase relative to existing datasets). Our datasets contain rich road features and provide fine-grained data about both traffic volume and traffic speed, allowing for building more holistic traffic forecasting systems. We show that most current implementations of neural spatiotemporal models for traffic forecasting have problems scaling to datasets of our size. To overcome this issue, we propose an alternative approach to neural traffic forecasting that uses a GNN without a dedicated module for temporal sequence processing, thus achieving much better scalability, while also demonstrating stronger forecasting performance. We hope our datasets and modeling insights will serve as a valuable resource for research in traffic forecasting.
                
                
                    <strong>Published:</strong> 2025-10-02T17:53:51Z
                    <a href="http://arxiv.org/abs/2510.02278v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity
                
                    <strong>Authors:</strong> Eric Tillmann Bill, Enis Simsar, Thomas Hofmann
                
                
                    <strong>Abstract:</strong> Text-to-image (T2I) models excel on single-entity prompts but struggle with multi-subject descriptions, often showing attribute leakage, identity entanglement, and subject omissions. We introduce the first theoretical framework with a principled, optimizable objective for steering sampling dynamics toward multi-subject fidelity. Viewing flow matching (FM) through stochastic optimal control (SOC), we formulate subject disentanglement as control over a trained FM sampler. This yields two architecture-agnostic algorithms: (i) a training-free test-time controller that perturbs the base velocity with a single-pass update, and (ii) Adjoint Matching, a lightweight fine-tuning rule that regresses a control network to a backward adjoint signal while preserving base-model capabilities. The same formulation unifies prior attention heuristics, extends to diffusion models via a flow-diffusion correspondence, and provides the first fine-tuning route explicitly designed for multi-subject fidelity. Empirically, on Stable Diffusion 3.5, FLUX, and Stable Diffusion XL, both algorithms consistently improve multi-subject alignment while maintaining base-model style. Test-time control runs efficiently on commodity GPUs, and fine-tuned controllers trained on limited prompts generalize to unseen ones. We further highlight FOCUS (Flow Optimal Control for Unentangled Subjects), which achieves state-of-the-art multi-subject fidelity across models.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:58Z
                    <a href="http://arxiv.org/abs/2510.02315v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions
                
                    <strong>Authors:</strong> Bo-Hsu Ke, You-Zhe Xie, Yu-Lun Liu, Wei-Chen Chiu
                
                
                    <strong>Abstract:</strong> 3D scene representation methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have significantly advanced novel view synthesis. As these methods become prevalent, addressing their vulnerabilities becomes critical. We analyze 3DGS robustness against image-level poisoning attacks and propose a novel density-guided poisoning method. Our method strategically injects Gaussian points into low-density regions identified via Kernel Density Estimation (KDE), embedding viewpoint-dependent illusory objects clearly visible from poisoned views while minimally affecting innocent views. Additionally, we introduce an adaptive noise strategy to disrupt multi-view consistency, further enhancing attack effectiveness. We propose a KDE-based evaluation protocol to assess attack difficulty systematically, enabling objective benchmarking for future research. Extensive experiments demonstrate our methods superior performance compared to state-of-the-art techniques. Project page: https://hentci.github.io/stealthattack/
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:57Z
                    <a href="http://arxiv.org/abs/2510.02314v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions
                
                    <strong>Authors:</strong> Mengyu Yang, Yiming Chen, Haozheng Pei, Siddhant Agarwal, Arun Balajee Vasudevan, James Hays
                
                
                    <strong>Abstract:</strong> Can a model distinguish between the sound of a spoon hitting a hardwood floor versus a carpeted one? Everyday object interactions produce sounds unique to the objects involved. We introduce the sounding object detection task to evaluate a models ability to link these sounds to the objects directly involved. Inspired by human perception, our multimodal object-aware framework learns from in-the-wild egocentric videos. To encourage an object-centric approach, we first develop an automatic pipeline to compute segmentation masks of the objects involved to guide the models focus during training towards the most informative regions of the interaction. A slot attention visual encoder is used to further enforce an object prior. We demonstrate state of the art performance on our new task along with existing multimodal action understanding tasks.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:52Z
                    <a href="http://arxiv.org/abs/2510.02313v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                KaVa: Latent Reasoning via Compressed KV-Cache Distillation
                
                    <strong>Authors:</strong> Anna Kuzina, Maciej Pioro, Paul N. Whatmough, Babak Ehteshami Bejnordi
                
                
                    <strong>Abstract:</strong> Large Language Models (LLMs) excel at multi-step reasoning problems with explicit chain-of-thought (CoT), but verbose traces incur significant computational costs and memory overhead, and often carry redundant, stylistic artifacts. Latent reasoning has emerged as an efficient alternative that internalizes the thought process, but it suffers from a critical lack of supervision, limiting its effectiveness on complex, natural-language reasoning traces. In this work, we propose KaVa, the first framework that bridges this gap by distilling knowledge directly from a compressed KV-cache of the teacher into a latent-reasoning student via self-distillation, leveraging the representational flexibility of continuous latent tokens to align stepwise KV trajectories. We show that the abstract, unstructured knowledge within compressed KV-cache, which lacks direct token correspondence, can serve as a rich supervisory signal for a latent reasoning student. Empirically, the approach consistently outperforms strong latent baselines, exhibits markedly smaller degradation from equation-only to natural-language traces, and scales to larger backbones while preserving efficiency. These results establish compressed KV-cache distillation as a scalable supervision signal for latent reasoning, combining the accuracy of CoT-trained teachers with the efficiency and deployability of latent inference.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:51Z
                    <a href="http://arxiv.org/abs/2510.02312v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Inferring Dynamic Physical Properties from Video Foundation Models
                
                    <strong>Authors:</strong> Guanqi Zhan, Xianzheng Ma, Weidi Xie, Andrew Zisserman
                
                
                    <strong>Abstract:</strong> We study the task of predicting dynamic physical properties from videos. More specifically, we consider physical properties that require temporal information to be inferred: elasticity of a bouncing object, viscosity of a flowing liquid, and dynamic friction of an object sliding on a surface. To this end, we make the following contributions: (i) We collect a new video dataset for each physical property, consisting of synthetic training and testing splits, as well as a real split for real world evaluation. (ii) We explore three ways to infer the physical property from videos: (a) an oracle method where we supply the visual cues that intrinsically reflect the property using classical computer vision techniques; (b) a simple read out mechanism using a visual prompt and trainable prompt vector for cross-attention on pre-trained video generative and self-supervised models; and (c) prompt strategies for Multi-modal Large Language Models (MLLMs). (iii) We show that video foundation models trained in a generative or self-supervised manner achieve a similar performance, though behind that of the oracle, and MLLMs are currently inferior to the other models, though their performance can be improved through suitable prompting.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:50Z
                    <a href="http://arxiv.org/abs/2510.02311v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                NoiseShift: Resolution-Aware Noise Recalibration for Better Low-Resolution Image Generation
                
                    <strong>Authors:</strong> Ruozhen He, Moayed Haji-Ali, Ziyan Yang, Vicente Ordonez
                
                
                    <strong>Abstract:</strong> Text-to-image diffusion models trained on a fixed set of resolutions often fail to generalize, even when asked to generate images at lower resolutions than those seen during training. High-resolution text-to-image generators are currently unable to easily offer an out-of-the-box budget-efficient alternative to their users who might not need high-resolution images. We identify a key technical insight in diffusion models that when addressed can help tackle this limitation: Noise schedulers have unequal perceptual effects across resolutions. The same level of noise removes disproportionately more signal from lower-resolution images than from high-resolution images, leading to a train-test mismatch. We propose NoiseShift, a training-free method that recalibrates the noise level of the denoiser conditioned on resolution size. NoiseShift requires no changes to model architecture or sampling schedule and is compatible with existing models. When applied to Stable Diffusion 3, Stable Diffusion 3.5, and Flux-Dev, quality at low resolutions is significantly improved. On LAION-COCO, NoiseShift improves SD3.5 by 15.89%, SD3 by 8.56%, and Flux-Dev by 2.44% in FID on average. On CelebA, NoiseShift improves SD3.5 by 10.36%, SD3 by 5.19%, and Flux-Dev by 3.02% in FID on average. These results demonstrate the effectiveness of NoiseShift in mitigating resolution-dependent artifacts and enhancing the quality of low-resolution image generation.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:43Z
                    <a href="http://arxiv.org/abs/2510.02307v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Drawing Conclusions from Draws: Rethinking Preference Semantics in Arena-Style LLM Evaluation
                
                    <strong>Authors:</strong> Raphael Tang, Crystina Zhang, Wenyan Li, Carmen Lai, Pontus Stenetorp, Yao Lu
                
                
                    <strong>Abstract:</strong> In arena-style evaluation of large language models (LLMs), two LLMs respond to a user query, and the user chooses the winning response or deems the battle a draw, resulting in an adjustment to the ratings of both models. The prevailing approach for modeling these rating dynamics is to view battles as two-player game matches, as in chess, and apply the Elo rating system and its derivatives. In this paper, we critically examine this paradigm. Specifically, we question whether a draw genuinely means that the two models are equal and hence whether their ratings should be equalized. Instead, we conjecture that draws are more indicative of query difficulty: if the query is too easy, then both models are more likely to succeed equally. On three real-world arena datasets, we show that ignoring rating updates for draws yields a 1-3% relative increase in battle outcome prediction accuracy (which includes draws) for all four rating systems studied. Further analyses suggest that draws occur more for queries rated as very easy and those as highly objective, with risk ratios of 1.37 and 1.35, respectively. We recommend future rating systems to reconsider existing draw semantics and to account for query properties in rating updates.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:41Z
                    <a href="http://arxiv.org/abs/2510.02306v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Knowledge Distillation Detection for Open-weights Models
                
                    <strong>Authors:</strong> Qin Shi, Amber Yijia Zheng, Qifan Song, Raymond A. Yeh
                
                
                    <strong>Abstract:</strong> We propose the task of knowledge distillation detection, which aims to determine whether a student model has been distilled from a given teacher, under a practical setting where only the students weights and the teachers API are available. This problem is motivated by growing concerns about model provenance and unauthorized replication through distillation. To address this task, we introduce a model-agnostic framework that combines data-free input synthesis and statistical score computation for detecting distillation. Our approach is applicable to both classification and generative models. Experiments on diverse architectures for image classification and text-to-image generation show that our method improves detection accuracy over the strongest baselines by 59.6% on CIFAR-10, 71.2% on ImageNet, and 20.0% for text-to-image generation. The code is available at https://github.com/shqii1j/distillation_detection.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:14Z
                    <a href="http://arxiv.org/abs/2510.02302v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models
                
                    <strong>Authors:</strong> Runqian Wang, Yilun Du
                
                
                    <strong>Abstract:</strong> We introduce Equilibrium Matching (EqM), a generative modeling framework built from an equilibrium dynamics perspective. EqM discards the non-equilibrium, time-conditional dynamics in traditional diffusion and flow-based generative models and instead learns the equilibrium gradient of an implicit energy landscape. Through this approach, we can adopt an optimization-based sampling process at inference time, where samples are obtained by gradient descent on the learned landscape with adjustable step sizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation performance of diffusion/flow models empirically, achieving an FID of 1.90 on ImageNet 256$\times$256. EqM is also theoretically justified to learn and sample from the data manifold. Beyond generation, EqM is a flexible framework that naturally handles tasks including partially noised image denoising, OOD detection, and image composition. By replacing time-conditional velocities with a unified equilibrium landscape, EqM offers a tighter bridge between flow and energy-based models and a simple route to optimization-driven inference.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:06Z
                    <a href="http://arxiv.org/abs/2510.02300v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
            
                Interactive Training: Feedback-Driven Neural Network Optimization
                
                    <strong>Authors:</strong> Wentao Zhang, Yang Young Lu, Yuntian Deng
                
                
                    <strong>Abstract:</strong> Traditional neural network training typically follows fixed, predefined optimization recipes, lacking the flexibility to dynamically respond to instabilities or emerging training issues. In this paper, we introduce Interactive Training, an open-source framework that enables real-time, feedback-driven intervention during neural network training by human experts or automated AI agents. At its core, Interactive Training uses a control server to mediate communication between users or agents and the ongoing training process, allowing users to dynamically adjust optimizer hyperparameters, training data, and model checkpoints. Through three case studies, we demonstrate that Interactive Training achieves superior training stability, reduced sensitivity to initial hyperparameters, and improved adaptability to evolving user needs, paving the way toward a future training paradigm where AI agents autonomously monitor training logs, proactively resolve instabilities, and optimize training dynamics.
                
                
                    <strong>Published:</strong> 2025-10-02T17:59:00Z
                    <a href="http://arxiv.org/abs/2510.02297v1" target="_blank">ðŸ“„ View Paper</a>
                
            
        
    
    
        <p><em>Generated by AI News Agent</em></p>
    

