
    
        <h1>ü§ñ AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-30<br>
            <strong>Topics:</strong> ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 100
        
        
        
            
                <h2>ü§ñ AI Summary</h2>
                <h2>ai alignment research</h2>
<p>Certainly! Lets break down the summary of the research papers related to AI alignment research into the specified format:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>AI in Dialogue and Interaction</strong>: Papers like OnGoal and ChatThero highlight the growing trend of using AI to enhance human-AI interactions, particularly in dialogue systems. These systems are being designed to better track and visualize goals, as well as provide therapeutic support.</p>
</li>
<li><p><strong>Robustness and Security</strong>: Research such as FakeParts and AI Agentic Vulnerability Injection show an increasing focus on making AI systems more robust against adversarial and deceptive manipulations, critical for maintaining trust in AI systems.</p>
</li>
<li><p><strong>Generative AI and Efficiency</strong>: Works like CogVLA and OneRec-V2 reflect the continued trend toward optimizing generative AI models for efficiency and scalability, which is essential for broader deployment and real-world applications.</p>
</li>
<li><p><strong>Interdisciplinary Approaches</strong>: Papers like Understanding, Protecting, and Augmenting Human Cognition with Generative AI indicate a strong move towards interdisciplinary research that combines AI with cognitive science to better understand and enhance human cognition.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Conversational Goal Management</strong>: OnGoal introduces a novel interface that significantly enhances the ability of users to manage and track conversation goals with LLMs, improving engagement and communication effectiveness.</p>
</li>
<li><p><strong>Partial Deepfake Detection</strong>: FakeParts presents a breakthrough in deepfake detection by focusing on subtle manipulations, providing a comprehensive dataset and benchmark that highlights detection challenges in AI systems.</p>
</li>
<li><p><strong>Quantum Computing Tools</strong>: The Quantum Economic Advantage Online Calculator offers a significant advancement by providing a tool to predict when quantum computing will outperform classical systems, helping guide future research and investment.</p>
</li>
<li><p><strong>AI in Therapeutic Settings</strong>: ChatThero represents a breakthrough in using AI for mental health support, particularly in addiction recovery, by integrating clinically validated therapeutic strategies with AI dialogue systems.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Enhanced Human-AI Collaboration</strong>: The development of systems like OnGoal and ChatThero could lead to more effective and empathetic human-AI collaboration, especially in complex dialogues and therapeutic contexts.</p>
</li>
<li><p><strong>Improved Security Measures</strong>: As highlighted by FakeParts and AI Agentic Vulnerability Injection, there is a critical need for improved detection and prevention measures against subtle and sophisticated manipulations in AI systems to ensure security and integrity.</p>
</li>
<li><p><strong>Efficiency in AI Deployment</strong>: Advances in models like CogVLA and OneRec-V2 underscore the importance of making AI systems more efficient, which is crucial for their broader application and integration into existing infrastructures.</p>
</li>
<li><p><strong>Cross-Disciplinary Innovation</strong>: The synthesis of AI with cognitive science and quantum computing suggests a future where AI systems are not only more intelligent but also more aligned with human values and needs, potentially transforming various sectors including healthcare, security, and scientific research.</p>
</li>
</ol>
<p>These papers collectively contribute to the field of AI alignment by addressing key challenges in AI interaction, robustness, efficiency, and interdisciplinary collaboration, paving the way for more aligned and effective AI systems in the future.</p>
<p><em>Based on 50 research papers</em></p>

<h2>quantum computing</h2>
<p>Certainly! Below is a structured summary of the provided research papers, focusing on key trends, breakthroughs, and implications in the context of quantum computing:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Quantum Feature Mapping and Machine Learning</strong>: There is a growing trend of applying quantum mechanics, particularly quantum feature maps and quantum annealers, to enhance machine learning tasks. This trend is driven by the potential of quantum systems to identify complex data patterns more efficiently than classical systems.</p>
</li>
<li><p><strong>Quantum Systems and Non-Hermitian Physics</strong>: Research continues to explore the dynamics of quantum systems that do not adhere strictly to Hermitian operators, such as pseudo-Hermitian and non-Hermitian systems, to understand their physical implications and applications.</p>
</li>
<li><p><strong>Quantum Resource Estimation and Economic Advantage</strong>: There is a focus on understanding the resource requirements for quantum computing tasks, including the number of qubits necessary for machine learning problems and the economic advantages of quantum computing over classical systems.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Quenched Quantum Feature Maps</strong>: A significant breakthrough is the development of quantum feature mapping techniques using quench dynamics in quantum spin glasses. This approach showcases quantum advantage by improving machine learning model performance beyond classical capabilities, particularly around the critical points of quantum dynamics.</p>
</li>
<li><p><strong>Quantum Economic Advantage Calculator</strong>: The introduction of an online tool for estimating when quantum computers will economically outperform classical ones represents a practical advancement. This tool allows for dynamic adjustments based on algorithm and hardware assumptions, aiding in strategic decision-making for adopting quantum technology.</p>
</li>
<li><p><strong>Spectral Gap Approximation</strong>: A quantum algorithm has been developed to approximate spectral gaps in Hermitian matrices efficiently. This advancement provides speed-ups over classical methods and demonstrates the potential of quantum computing in complex problem-solving.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Enhanced Machine Learning</strong>: The use of quantum feature maps can significantly enhance machine learning applications in fields such as drug discovery and medical diagnostics. This suggests a future where quantum computing plays a central role in data-intensive industries.</p>
</li>
<li><p><strong>Resource Planning for Quantum Adoption</strong>: Tools like the Quantum Economic Advantage Calculator help organizations plan for quantum adoption by providing insights into when quantum systems will offer cost-effective solutions. This can accelerate the transition from classical to quantum systems in various industries.</p>
</li>
<li><p><strong>New Horizons in Quantum Physics</strong>: Research on non-Hermitian quantum systems and their constraints opens new avenues for theoretical and practical applications, potentially leading to the development of new quantum devices and technologies.</p>
</li>
</ol>
<p>Overall, these papers highlight the rapid advancements and expanding horizons in quantum computing, emphasizing its potential to transform industries through enhanced computational capabilities and improved problem-solving frameworks.</p>
<p><em>Based on 50 research papers</em></p>

            
        
        
        <h2>üìö Research Papers</h2>
        
                
                    <h3><a href="http://dx.doi.org/10.1145/3746059.3747746" target="_blank">OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Adam Coscia, Shunan Guo, Eunyee Koh, Alex Endert</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> As multi-turn dialogues with large language models (LLMs) grow longer and more complex, how can users better evaluate and review progress on their conversational goals? We present OnGoal, an LLM chat interface that helps users better manage goal progress. OnGoal provides real-time feedback on goal alignment through LLM-assisted evaluation, explanations for evaluation results with examples, and overviews of goal progression over time, enabling users to navigate complex dialogues more effectively. Through a study with 20 participants on a writing task, we evaluate OnGoal against a baseline chat interface without goal tracking. Using OnGoal, participants spent less time and effort to achieve their goals while exploring new prompting strategies to overcome miscommunication, suggesting tracking and visualizing goals can enhance engagement and resilience in LLM dialogues. Our findings inspired design implications for future LLM chat interfaces that improve goal communication, reduce cognitive load, enhance interactivity, and enable feedback to improve LLM performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21060v1" target="_blank">Multi-View 3D Point Tracking</a></h3>
                    <p><strong>Authors:</strong> Frano Rajiƒç, Haofei Xu, Marko Mihajlovic, Siyuan Li, Irem Demir, Emircan G√ºndoƒüdu, Lei Ke, Sergey Prokudin, Marc Pollefeys, Siyu Tang</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce the first data-driven multi-view 3D point tracker, designed to track arbitrary points in dynamic scenes using multiple camera views. Unlike existing monocular trackers, which struggle with depth ambiguities and occlusion, or prior multi-camera methods that require over 20 cameras and tedious per-sequence optimization, our feed-forward model directly predicts 3D correspondences using a practical number of cameras (e.g., four), enabling robust and accurate online tracking. Given known camera poses and either sensor-based or estimated multi-view depth, our tracker fuses multi-view features into a unified point cloud and applies k-nearest-neighbors correlation alongside a transformer-based update to reliably estimate long-range 3D correspondences, even under occlusion. We train on 5K synthetic multi-view Kubric sequences and evaluate on two real-world benchmarks: Panoptic Studio and DexYCB, achieving median trajectory errors of 3.1 cm and 2.0 cm, respectively. Our method generalizes well to diverse camera setups of 1-8 views with varying vantage points and video lengths of 24-150 frames. By releasing our tracker alongside training and evaluation datasets, we aim to set a new standard for multi-view 3D tracking research and provide a practical tool for real-world applications. Project page available at https://ethz-vlg.github.io/mvtracker.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21052v1" target="_blank">FakeParts: a New Family of AI-Generated DeepFakes</a></h3>
                    <p><strong>Authors:</strong> Gaetan Brison, Soobash Daiboo, Samy Aimeur, Awais Hussain Sani, Xi Wang, Gianni Franchi, Vicky Kalogeiton</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.MM</p>
                    <p><strong>Summary:</strong> We introduce FakeParts, a new class of deepfakes characterized by subtle, localized manipulations to specific spatial regions or temporal segments of otherwise authentic videos. Unlike fully synthetic content, these partial manipulations, ranging from altered facial expressions to object substitutions and background modifications, blend seamlessly with real elements, making them particularly deceptive and difficult to detect. To address the critical gap in detection capabilities, we present FakePartsBench, the first large-scale benchmark dataset specifically designed to capture the full spectrum of partial deepfakes. Comprising over 25K videos with pixel-level and frame-level manipulation annotations, our dataset enables comprehensive evaluation of detection methods. Our user studies demonstrate that FakeParts reduces human detection accuracy by over 30% compared to traditional deepfakes, with similar performance degradation observed in state-of-the-art detection models. This work identifies an urgent vulnerability in current deepfake detection approaches and provides the necessary resources to develop more robust methods for partial video manipulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21050v1" target="_blank">Dynamics of Gender Bias in Software Engineering</a></h3>
                    <p><strong>Authors:</strong> Thomas J. Misa</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.CY, K.2; K.6.3; K.4; K.7</p>
                    <p><strong>Summary:</strong> The field of software engineering is embedded in both engineering and computer science, and may embody gender biases endemic to both. This paper surveys software engineerings origins and its long-running attention to engineering professionalism, profiling five leaders; it then examines the fields recent attention to gender issues and gender bias. It next quantitatively analyzes womens participation as research authors in the fields leading International Conference of Software Engineering (1976-2010), finding a dozen years with statistically significant gender exclusion. Policy dimensions of research on gender bias in computing are suggested.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21046v1" target="_blank">CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing  Sparsification</a></h3>
                    <p><strong>Authors:</strong> Wei Li, Renshan Zhang, Rui Shao, Jie He, Liqiang Nie</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Recent Vision-Language-Action (VLA) models built on pre-trained Vision-Language Models (VLMs) require extensive post-training, resulting in high computational overhead that limits scalability and deployment.We propose CogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages instruction-driven routing and sparsification to improve both efficiency and performance. CogVLA draws inspiration from human multimodal coordination and introduces a 3-stage progressive architecture. 1) Encoder-FiLM based Aggregation Routing (EFA-Routing) injects instruction information into the vision encoder to selectively aggregate and compress dual-stream visual tokens, forming a instruction-aware latent representation. 2) Building upon this compact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing) introduces action intent into the language model by pruning instruction-irrelevant visually grounded tokens, thereby achieving token-level sparsity. 3) To ensure that compressed perception inputs can still support accurate and coherent action generation, we introduce V-L-A Coupled Attention (CAtten), which combines causal vision-language attention with bidirectional action parallel decoding. Extensive experiments on the LIBERO benchmark and real-world robotic tasks demonstrate that CogVLA achieves state-of-the-art performance with success rates of 97.4% and 70.0%, respectively, while reducing training costs by 2.5-fold and decreasing inference latency by 2.8-fold compared to OpenVLA. CogVLA is open-sourced and publicly available at https://github.com/JiuTian-VL/CogVLA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21040v1" target="_blank">FW-GAN: Frequency-Driven Handwriting Synthesis with Wave-Modulated MLP Generator</a></h3>
                    <p><strong>Authors:</strong> Huynh Tong Dang Khoa, Dang Hoai Nam, Vo Nguyen Le Duy</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Labeled handwriting data is often scarce, limiting the effectiveness of recognition systems that require diverse, style-consistent training samples. Handwriting synthesis offers a promising solution by generating artificial data to augment training. However, current methods face two major limitations. First, most are built on conventional convolutional architectures, which struggle to model long-range dependencies and complex stroke patterns. Second, they largely ignore the crucial role of frequency information, which is essential for capturing fine-grained stylistic and structural details in handwriting. To address these challenges, we propose FW-GAN, a one-shot handwriting synthesis framework that generates realistic, writer-consistent text from a single example. Our generator integrates a phase-aware Wave-MLP to better capture spatial relationships while preserving subtle stylistic cues. We further introduce a frequency-guided discriminator that leverages high-frequency components to enhance the authenticity detection of generated samples. Additionally, we introduce a novel Frequency Distribution Loss that aligns the frequency characteristics of synthetic and real handwriting, thereby enhancing visual fidelity. Experiments on Vietnamese and English handwriting datasets demonstrate that FW-GAN generates high-quality, style-consistent handwriting, making it a valuable tool for augmenting data in low-resource handwriting recognition (HTR) pipelines. Official implementation is available at https://github.com/DAIR-Group/FW-GAN</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21038v1" target="_blank">On the Theoretical Limitations of Embedding-Based Retrieval</a></h3>
                    <p><strong>Authors:</strong> Orion Weller, Michael Boratko, Iftekhar Naim, Jinhyuk Lee</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Vector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following, coding, and more. These new benchmarks push embeddings to work for any query and any notion of relevance that could be given. While prior works have pointed out theoretical limitations of vector embeddings, there is a common assumption that these difficulties are exclusively due to unrealistic queries, and those that are not can be overcome with better training data and larger models. In this work, we demonstrate that we may encounter these theoretical limitations in realistic settings with extremely simple queries. We connect known results in learning theory, showing that the number of top-k subsets of documents capable of being returned as the result of some query is limited by the dimension of the embedding. We empirically show that this holds true even if we restrict to k=2, and directly optimize on the test set with free parameterized embeddings. We then create a realistic dataset called LIMIT that stress tests models based on these theoretical results, and observe that even state-of-the-art models fail on this dataset despite the simple nature of the task. Our work shows the limits of embedding models under the existing single vector paradigm and calls for future research to develop methods that can resolve this fundamental limitation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21037v1" target="_blank">Predicting Trends in $V_{OC}$ Through Rapid, Multimodal Characterization of State-of-the-Art p-i-n Perovskite Devices</a></h3>
                    <p><strong>Authors:</strong> Amy E. Louks, Brandon T. Motes, Anthony T. Troupe, Axel F. Palmstrom, Joseph J. Berry, Dane W. deQuilettes</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, physics.app-ph</p>
                    <p><strong>Summary:</strong> Perovskite photovoltaic technologies are approaching commercial deployment, yet single junction and tandem architectures both still have significant room to improve power conversion efficiency and stability. The ability to perform rapid screening of material quality after altering processing conditions is critical to accelerating the optimization and commercialization of perovskite-based technologies. Currently, researchers utilize a wide range of stand-alone metrology tools to isolate sources of power loss throughout a device stack, which can be slow and labor intensive. Here, we demonstrate the use of a multimodal metrology approach to rapidly determine the maximum achievable and predicted open circuit voltages of  100 perovskite devices during fabrication. Acquisition of these different data are facilitated by combining them into a single integrated measurement platform. We show that these data and automated analysis can be used to rapidly understand and ultimately predict quantitative trends in open circuit voltages of state-of-the-art devices architectures. The data and automated analysis workflow presented provides a reliable approach to quickly identify absorber and charge transport layer combinations that can lead to improved open circuit voltages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21036v1" target="_blank">Understanding, Protecting, and Augmenting Human Cognition with Generative AI: A Synthesis of the CHI 2025 Tools for Thought Workshop</a></h3>
                    <p><strong>Authors:</strong> Lev Tankelevitch, Elena L. Glassman, Jessica He, Aniket Kittur, Mina Lee, Srishti Palani, Advait Sarkar, Gonzalo Ramos, Yvonne Rogers, Hari Subramonyam</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> Generative AI (GenAI) radically expands the scope and capability of automation for work, education, and everyday tasks, a transformation posing both risks and opportunities for human cognition. How will human cognition change, and what opportunities are there for GenAI to augment it? Which theories, metrics, and other tools are needed to address these questions? The CHI 2025 workshop on Tools for Thought aimed to bridge an emerging science of how the use of GenAI affects human thought, from metacognition to critical thinking, memory, and creativity, with an emerging design practice for building GenAI tools that both protect and augment human thought. Fifty-six researchers, designers, and thinkers from across disciplines as well as industry and academia, along with 34 papers and portfolios, seeded a day of discussion, ideation, and community-building. We synthesize this material here to begin mapping the space of research and design opportunities and to catalyze a multidisciplinary community around this pressing area of research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21031v1" target="_blank">Introducing the Quantum Economic Advantage Online Calculator</a></h3>
                    <p><strong>Authors:</strong> Frederick Mejia, Hans Gundlach, Jayson Lynch, Carl Dukatz, Andrew Lucas, Eleanor Crane, Prashant Shukla, Neil Thompson</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph, 81P68, 68Q12, 68W40, 91B55, F.1.2; J.2</p>
                    <p><strong>Summary:</strong> Developing a systematic view of where quantum computers will outperform classical ones is important for researchers, policy makers and business leaders. But developing such a view is challenging because quantum advantage analyses depend not only on algorithm properties, but also on a host of technical characteristics (error correction, gate speeds, etc.). Because various analyses make different assumptions about these technical characteristics, it can be challenging to make comparisons across them. In this paper, we introduce an open-access web-tool designed to make such comparisons easy. Built on the framework introduced by Choi, Moses, and Thompson (2023), it calculates when quantum systems will outperform classical computers for a given algorithmic problem. These estimates can be easily updated based on various assumptions for error correction, overhead, and connectivity. Different hardware roadmaps can also be used and algorithm running times can be customized to particular applications. It can currently be accessed at https://futuretech.mit.edu/quantum-economic-advantage-calculator. This integrated prediction tool also allows us to explore which technical factors are most important for quantum ``economic advantage (outperforming on a cost-equivalent basis). Overall, we find that for some algorithms (e.g. Shors) the timing of advantage is quite robust, whereas for others (e.g. Grovers) it is contingent, with numerous technical characteristics substantially impacting these dates. In the paper, we discuss both why this occurs and what we can learn from it.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21019v1" target="_blank">POSE: Phased One-Step Adversarial Equilibrium for Video Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Jiaxiang Cheng, Bing Ma, Xuhua Ren, Hongyi Jin, Kai Yu, Peng Zhang, Wenyue Li, Yuan Zhou, Tianxiang Zheng, Qinglin Lu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The field of video diffusion generation faces critical bottlenecks in sampling efficiency, especially for large-scale models and long sequences. Existing video acceleration methods adopt image-based techniques but suffer from fundamental limitations: they neither model the temporal coherence of video frames nor provide single-step distillation for large-scale video models. To bridge this gap, we propose POSE (Phased One-Step Equilibrium), a distillation framework that reduces the sampling steps of large-scale video diffusion models, enabling the generation of high-quality videos in a single step. POSE employs a carefully designed two-phase process to distill video models:(i) stability priming: a warm-up mechanism to stabilize adversarial distillation that adapts the high-quality trajectory of the one-step generator from high to low signal-to-noise ratio regimes, optimizing the video quality of single-step mappings near the endpoints of flow trajectories. (ii) unified adversarial equilibrium: a flexible self-adversarial distillation mechanism that promotes stable single-step adversarial training towards a Nash equilibrium within the Gaussian noise space, generating realistic single-step videos close to real videos. For conditional video generation, we propose (iii) conditional adversarial consistency, a method to improve both semantic consistency and frame consistency between conditional frames and generated frames. Comprehensive experiments demonstrate that POSE outperforms other acceleration methods on VBench-I2V by average 7.15% in semantic alignment, temporal conference and frame quality, reducing the latency of the pre-trained model by 100$\times$, from 1000 seconds to 10 seconds, while maintaining competitive performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21016v1" target="_blank">Inference-Time Alignment Control for Diffusion Models with Reinforcement Learning Guidance</a></h3>
                    <p><strong>Authors:</strong> Luozhijie Jin, Zijie Qiu, Jie Liu, Zijie Diao, Lifeng Qiao, Ning Ding, Alex Lamb, Xipeng Qiu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Denoising-based generative models, particularly diffusion and flow matching algorithms, have achieved remarkable success. However, aligning their output distributions with complex downstream objectives, such as human preferences, compositional accuracy, or data compressibility, remains challenging. While reinforcement learning (RL) fine-tuning methods, inspired by advances in RL from human feedback (RLHF) for large language models, have been adapted to these generative frameworks, current RL approaches are suboptimal for diffusion models and offer limited flexibility in controlling alignment strength after fine-tuning. In this work, we reinterpret RL fine-tuning for diffusion models through the lens of stochastic differential equations and implicit reward conditioning. We introduce Reinforcement Learning Guidance (RLG), an inference-time method that adapts Classifier-Free Guidance (CFG) by combining the outputs of the base and RL fine-tuned models via a geometric average. Our theoretical analysis shows that RLGs guidance scale is mathematically equivalent to adjusting the KL-regularization coefficient in standard RL objectives, enabling dynamic control over the alignment-quality trade-off without further training. Extensive experiments demonstrate that RLG consistently improves the performance of RL fine-tuned models across various architectures, RL algorithms, and downstream tasks, including human preferences, compositional control, compressibility, and text rendering. Furthermore, RLG supports both interpolation and extrapolation, thereby offering unprecedented flexibility in controlling generative alignment. Our approach provides a practical and theoretically sound solution for enhancing and controlling diffusion model alignment at inference. The source code for RLG is publicly available at the Github: https://github.com/jinluo12345/Reinforcement-learning-guidance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21005v1" target="_blank">Measuring Ransomware Lateral Movement Susceptibility via Privilege-Weighted Adjacency Matrix Exponentiation</a></h3>
                    <p><strong>Authors:</strong> Satyam Tyagi, Ganesh Murugesan</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.DM, cs.CR, math.CO, 05C50, 05C90, 94C15, G.2.2</p>
                    <p><strong>Summary:</strong> Ransomware impact hinges on how easily an intruder can move laterally and spread to the maximum number of assets. We present a graph-theoretic method to measure lateral-movement susceptibility and estimate blast radius. We build a directed multigraph where vertices represent assets and edges represent reachable services (e.g., RDP/SSH) between them. We model lateral movement as a probabilistic process using a pivot potential factor $\pi(s)$ for each service. This allows us to iteratively compute a $K$-hop compromise probability matrix that captures how compromise propagates through the network. Metrics derived from this model include: (1) Lateral-Movement Susceptibility (LMS$_K$): the average probability of a successful lateral movement between any two assets (0-1 scale); and (2) Blast-Radius Estimate (BRE$_K$): the expected percentage of assets compromised in an average attack scenario. Interactive control (SSH 22, RDP 3389) gets higher $\pi(s)$ than app-only ports (MySQL 3306, MSSQL 1433), which seldom enable pivoting without an RCE. Across anonymized enterprise snapshots, pruning high-$\pi(s)$ edges yields the largest LMS$_K$/BRE$_K$ drop, aligning with CISA guidance, MITRE ATT\CK (TA0008: Lateral Movement), and NIST SP~800-207. The framework evaluates (micro)segmentation and helps prioritize controls that reduce lateral movement susceptibility and shrink blast radius.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20996v1" target="_blank">ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic Support in Addiction Recovery</a></h3>
                    <p><strong>Authors:</strong> Junda Wang, Zonghai Yao, Zhichao Yang, Lingxi Li, Junhui Qian, Hong Yu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Substance use disorders (SUDs) affect over 36 million people worldwide, yet few receive effective care due to stigma, motivational barriers, and limited personalized support. Although large language models (LLMs) show promise for mental-health assistance, most systems lack tight integration with clinically validated strategies, reducing effectiveness in addiction recovery. We present ChatThero, a multi-agent conversational framework that couples dynamic patient modeling with context-sensitive therapeutic dialogue and adaptive persuasive strategies grounded in cognitive behavioral therapy (CBT) and motivational interviewing (MI). We build a high-fidelity synthetic benchmark spanning Easy, Medium, and Hard resistance levels, and train ChatThero with a two-stage pipeline comprising supervised fine-tuning (SFT) followed by direct preference optimization (DPO). In evaluation, ChatThero yields a 41.5\% average gain in patient motivation, a 0.49\% increase in treatment confidence, and resolves hard cases with 26\% fewer turns than GPT-4o, and both automated and human clinical assessments rate it higher in empathy, responsiveness, and behavioral realism. The framework supports rigorous, privacy-preserving study of therapeutic conversation and provides a robust, replicable basis for research and clinical translation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20973v1" target="_blank">ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents</a></h3>
                    <p><strong>Authors:</strong> Tianjian Liu, Fanqi Wan, Jiajian Guo, Xiaojun Quan</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Proactive dialogue has emerged as a critical and challenging research problem in advancing large language models (LLMs). Existing works predominantly focus on domain-specific or task-oriented scenarios, which leads to fragmented evaluations and limits the comprehensive exploration of models proactive conversation abilities. In this work, we propose ProactiveEval, a unified framework designed for evaluating proactive dialogue capabilities of LLMs. This framework decomposes proactive dialogue into target planning and dialogue guidance, establishing evaluation metrics across various domains. Moreover, it also enables the automatic generation of diverse and challenging evaluation data. Based on the proposed framework, we develop 328 evaluation environments spanning 6 distinct domains. Through experiments with 22 different types of LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional performance on target planning and dialogue guidance tasks, respectively. Finally, we investigate how reasoning capabilities influence proactive behaviors and discuss their implications for future model development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20971v1" target="_blank">Cosmo-Learn: code for learning cosmology using different methods and mock data</a></h3>
                    <p><strong>Authors:</strong> Reginald Christian Bernardo, Daniela Grand√≥n, Jackson Levi Said, V√≠ctor H. C√°rdenas, Gene Carlo Belinario, Reinabelle Reyes</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> We present cosmo_learn, an open-source python-based software package designed to simulate cosmological data and perform data-driven inference using a range of modern statistical and machine learning techniques. Motivated by the growing complexity of cosmological models and the emergence of observational tensions, cosmo_learn provides a standardized and flexible framework for benchmarking cosmological inference methods. The package supports realistic noise modeling for key observables in the late Universe, including cosmic chronometers, supernovae Ia, baryon acoustic oscillations, redshift space distortions, and gravitational wave bright sirens. We demonstrate the internal consistency of the simulated data with the input cosmology via residuals and parameter recovery using a fiducial $w$CDM model. Built-in learning and inference modules include traditional Markov Chain Monte Carlo, as well as more recent approaches such as genetic algorithms, Gaussian processes, Bayesian ridge regression, and artificial neural networks. These methods are implemented in a modular and extensible architecture designed to facilitate comparisons across inference strategies in a common pipeline. By providing a flexible and transparent simulation and learning environment, cosmo_learn supports both educational and research efforts at the intersection of cosmology, statistics, and machine learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20963v1" target="_blank">Guarding Against Malicious Biased Threats (GAMBiT) Experiments: Revealing Cognitive Bias in Human-Subjects Red-Team Cyber Range Operations</a></h3>
                    <p><strong>Authors:</strong> Brandon Beltz, Jim Doty, Yvonne Fonken, Nikolos Gurney, Brett Israelsen, Nathan Lau, Stacy Marsella, Rachelle Thomas, Stoney Trent, Peggy Wu, Ya-Ting Yang, Quanyan Zhu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.GT</p>
                    <p><strong>Summary:</strong> We present three large-scale human-subjects red-team cyber range datasets from the Guarding Against Malicious Biased Threats (GAMBiT) project. Across Experiments 1-3 (July 2024-March 2025), 19-20 skilled attackers per experiment conducted two 8-hour days of self-paced operations in a simulated enterprise network (SimSpace Cyber Force Platform) while we captured multi-modal data: self-reports (background, demographics, psychometrics), operational notes, terminal histories, keylogs, network packet captures (PCAP), and NIDS alerts (Suricata). Each participant began from a standardized Kali Linux VM and pursued realistic objectives (e.g., target discovery and data exfiltration) under controlled constraints. Derivative curated logs and labels are included. The combined release supports research on attacker behavior modeling, bias-aware analytics, and method benchmarking. Data are available via IEEE Dataport entries for Experiments 1-3.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20959v1" target="_blank">Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing</a></h3>
                    <p><strong>Authors:</strong> Curtis C. Johnson, Daniel Webb, David Hill, Marc D. Killpack</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.RO, eess.SP</p>
                    <p><strong>Summary:</strong> Scaling tactile sensing for robust whole-body manipulation is a significant challenge, often limited by wiring complexity, data throughput, and system reliability. This paper presents a complete architecture designed to overcome these barriers. Our approach pairs open-source, fabric-based sensors with custom readout electronics that reduce signal crosstalk to less than 3.3% through hardware-based mitigation. Critically, we introduce a novel, daisy-chained SPI bus topology that avoids the practical limitations of common wireless protocols and the prohibitive wiring complexity of USB hub-based systems. This architecture streams synchronized data from over 8,000 taxels across 1 square meter of sensing area at update rates exceeding 50 FPS, confirming its suitability for real-time control. We validate the systems efficacy in a whole-body grasping task where, without feedback, the robots open-loop trajectory results in an uncontrolled application of force that slowly crushes a deformable cardboard box. With real-time tactile feedback, the robot transforms this motion into a gentle, stable grasp, successfully manipulating the object without causing structural damage. This work provides a robust and well-characterized platform to enable future research in advanced whole-body control and physical human-robot interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20955v1" target="_blank">E-ConvNeXt: A Lightweight and Efficient ConvNeXt Variant with Cross-Stage Partial Connections</a></h3>
                    <p><strong>Authors:</strong> Fang Wang, Huitao Li, Wenhan Chao, Zheng Zhuo, Yiran Ji, Chang Peng, Yupeng Sun</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Many high-performance networks were not designed with lightweight application scenarios in mind from the outset, which has greatly restricted their scope of application. This paper takes ConvNeXt as the research object and significantly reduces the parameter scale and network complexity of ConvNeXt by integrating the Cross Stage Partial Connections mechanism and a series of optimized designs. The new network is named E-ConvNeXt, which can maintain high accuracy performance under different complexity configurations. The three core innovations of E-ConvNeXt are : (1) integrating the Cross Stage Partial Network (CSPNet) with ConvNeXt and adjusting the network structure, which reduces the models network complexity by up to 80%; (2) Optimizing the Stem and Block structures to enhance the models feature expression capability and operational efficiency; (3) Replacing Layer Scale with channel attention. Experimental validation on ImageNet classification demonstrates E-ConvNeXts superior accuracy-efficiency balance: E-ConvNeXt-mini reaches 78.3% Top-1 accuracy at 0.9GFLOPs. E-ConvNeXt-small reaches 81.9% Top-1 accuracy at 3.1GFLOPs. Transfer learning tests on object detection tasks further confirm its generalization capability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20954v1" target="_blank">Olive Tree Satellite Image Segmentation Based On SAM and Multi-Phase Refinement</a></h3>
                    <p><strong>Authors:</strong> Amir Jmal, Chaima Chtourou, Mahdi Louati, Abdelaziz Kallel, Houda Khmila</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In the context of proven climate change, maintaining olive biodiversity through early anomaly detection and treatment using remote sensing technology is crucial, offering effective management solutions. This paper presents an innovative approach to olive tree segmentation from satellite images. By leveraging foundational models and advanced segmentation techniques, the study integrates the Segment Anything Model (SAM) to accurately identify and segment olive trees in agricultural plots. The methodology includes SAM segmentation and corrections based on trees alignement in the field and a learanble constraint about the shape and the size. Our approach achieved a 98\% accuracy rate, significantly surpassing the initial SAM performance of 82\%.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20948v1" target="_blank">Sense of Belonging and Intent to Persist: Mediating Role of Motivation and Moderating Role of Gender in Physics and Astronomy Graduate Students</a></h3>
                    <p><strong>Authors:</strong> Swagata Sarkar, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> This study investigates how graduate students sense of belonging (SB) influences their intent to persist (IP) in physics and astronomy programs, and how this relationship is shaped by the basic psychological needs that drive motivation-autonomy, competence, and relatedness-as well as gender. Grounded in self-determination theory, the analysis treats these three needs as mediators and gender as a moderator. A quantitative survey was administered to graduate students in the Department of Physics and Astronomy at a large public land-grant R1 Midwestern university in the USA. Using probit regressions, we found that SB significantly predicts IP. Autonomy may play a compensatory role when SB is high, competence amplifies the effect of SB on IP, and relatedness buffers against low SB. Gender moderates the relationship: women report lower IP at low levels of SB but exceed men when SB is strong. These findings underscore the importance of fostering a sense of belonging, academic confidence, and social connection-particularly for women in male-dominated STEM fields.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20944v1" target="_blank">STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment</a></h3>
                    <p><strong>Authors:</strong> Jiaqian Li, Qisheng Hu, Jing Li, Wenya Wang</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to perform a wide range of tasks without task-specific fine-tuning. However, the effectiveness of ICL heavily depends on the quality of exemplar selection. In particular, for structured prediction tasks such as semantic parsing, existing ICL selection strategies often overlook structural alignment, leading to suboptimal performance and poor generalization. To address this issue, we propose a novel two-stage exemplar selection strategy that achieves a strong balance between efficiency, generalizability, and performance. First, we fine-tune a BERT-based retriever using structure-aware supervision, guiding it to select exemplars that are both semantically relevant and structurally aligned. Then, we enhance the retriever with a plug-in module, which amplifies syntactically meaningful information in the hidden representations. This plug-in is model-agnostic, requires minimal overhead, and can be seamlessly integrated into existing pipelines. Experiments on four benchmarks spanning three semantic parsing tasks demonstrate that our method consistently outperforms existing baselines with multiple recent LLMs as inference-time models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20943v1" target="_blank">DESA: An R Package for Detecting Epidemics using a School-Absenteeism Surveillance Framework</a></h3>
                    <p><strong>Authors:</strong> Vinay Joshy, Zeny Feng, Lorna Deeth, Kayla Vanderkruk, Justin Slater</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> stat.AP</p>
                    <p><strong>Summary:</strong> Absenteeism of elementary school children has been shown to be effective in the early detection of an incoming influenza epidemic within a given population. This paper introduces DESA, an R package designed to: 1) model an epidemic using school absenteeism data, 2) raise an alert for an incoming epidemic using school absenteeism data, 3) evaluate the timeliness of the raised alert using different metrics, and 4) simulate community-level household populations, epidemics, and school absenteeism to facilitate research in related fields. This paper provides an overview of the functions in the package and demonstrates its complete workflow using simulated data generated within the package. DESA offers researchers and public health officials a tool for improving early detection of seasonal influenza epidemics or epidemics of other diseases. The package is available on CRAN, making it readily accessible to the R user community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20941v1" target="_blank">AI Reasoning Models for Problem Solving in Physics</a></h3>
                    <p><strong>Authors:</strong> Amir Bralin, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Reasoning models are the new generation of Large Language Models (LLMs) capable of complex problem solving. Their reliability in solving introductory physics problems was tested by evaluating a sample of n = 5 solutions generated by one such model -- OpenAIs o3-mini -- per each problem from 20 chapters of a standard undergraduate textbook. In total, N = 408 problems were given to the model and N x n = 2,040 generated solutions examined. The model successfully solved 94% of the problems posed, excelling at the beginning topics in mechanics but struggling with the later ones such as waves and thermodynamics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20926v1" target="_blank">PLUME: Procedural Layer Underground Modeling Engine</a></h3>
                    <p><strong>Authors:</strong> Gabriel Manuel Garcia, Antoine Richard, Miguel Olivares-Mendez</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> As space exploration advances, underground environments are becoming increasingly attractive due to their potential to provide shelter, easier access to resources, and enhanced scientific opportunities. Although such environments exist on Earth, they are often not easily accessible and do not accurately represent the diversity of underground environments found throughout the solar system. This paper presents PLUME, a procedural generation framework aimed at easily creating 3D underground environments. Its flexible structure allows for the continuous enhancement of various underground features, aligning with our expanding understanding of the solar system. The environments generated using PLUME can be used for AI training, evaluating robotics algorithms, 3D rendering, and facilitating rapid iteration on developed exploration algorithms. In this paper, it is demonstrated that PLUME has been used along with a robotic simulator. PLUME is open source and has been released on Github. https://github.com/Gabryss/P.L.U.M.E</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20919v1" target="_blank">Classifying Mitotic Figures in the MIDOG25 Challenge with Deep Ensemble Learning and Rule Based Refinement</a></h3>
                    <p><strong>Authors:</strong> Sara Krauss, Ellena Spie√ü, Daniel Hieber, Frank Kramer, Johannes Schobel, Dominik M√ºller</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Mitotic figures (MFs) are relevant biomarkers in tumor grading. Differentiating atypical MFs (AMFs) from normal MFs (NMFs) remains difficult, as manual annotation is time-consuming and subjective. In this work an ensemble of ConvNeXtBase models was trained with AUCMEDI and extend with a rule-based refinement (RBR) module. On the MIDOG25 preliminary test set, the ensemble achieved a balanced accuracy of 84.02%. While the RBR increased specificity, it reduced sensitivity and overall performance. The results show that deep ensembles perform well for AMF classification. RBR can increase specific metrics but requires further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20918v1" target="_blank">Vibe Coding: Is Human Nature the Ghost in the Machine?</a></h3>
                    <p><strong>Authors:</strong> Cory Knobel, Nicole Radziwill</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This exploratory study examined the consistency of human-AI collaboration by analyzing three extensive vibe coding sessions between a human product lead and an AI software engineer. We investigated similarities and differences in team dynamics, communication patterns, and development outcomes across both projects. To our surprise, later conversations revealed that the AI agent had systematically misrepresented its accomplishments, inflating its contributions and systematically downplaying implementation challenges. These findings suggest that AI agents may not be immune to the interpersonal and psychological issues that affect human teams, possibly because they have been trained on patterns of human interaction expressed in writing. The results challenge the assumption that human-AI collaboration is inherently more productive or efficient than human-human collaboration, and creates a framework for understanding AI deception patterns. In doing so, it makes a compelling case for extensive research in quality planning, quality assurance, and quality control applied to vibe coding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20916v1" target="_blank">SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement</a></h3>
                    <p><strong>Authors:</strong> Yuan Ge, Junxiang Zhang, Xiaoqian Liu, Bei Li, Xiangnan Ma, Chenglong Wang, Kaiyang Ye, Yangfan Du, Linfeng Zhang, Yuxin Huang, Tong Xiao, Zhengtao Yu, JingBo Zhu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to natural human-computer interaction, enabling end-to-end spoken dialogue systems. However, evaluating these models remains a fundamental challenge. We propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches that disregard acoustic features, SageLM jointly assesses both semantic and acoustic dimensions. Second, it leverages rationale-based supervision to enhance explainability and guide model learning, achieving superior alignment with evaluation outcomes compared to rule-based reinforcement learning methods. Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset, and employ a two-stage training paradigm to mitigate the scarcity of speech preference data. Trained on both semantic and acoustic dimensions, SageLM achieves an 82.79\% agreement rate with human evaluators, outperforming cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20914v1" target="_blank">Learning Robust Spatial Representations from Binaural Audio through Feature Distillation</a></h3>
                    <p><strong>Authors:</strong> Holger Severin Bovbjerg, Jan √òstergaard, Jesper Jensen, Shinji Watanabe, Zheng-Hua Tan</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.LG, eess.AS, 68T10, I.2.6</p>
                    <p><strong>Summary:</strong> Recently, deep representation learning has shown strong performance in multiple audio tasks. However, its use for learning spatial representations from multichannel audio is underexplored. We investigate the use of a pretraining stage based on feature distillation to learn a robust spatial representation of binaural speech without the need for data labels. In this framework, spatial features are computed from clean binaural speech samples to form prediction labels. These clean features are then predicted from corresponding augmented speech using a neural network. After pretraining, we throw away the spatial feature predictor and use the learned encoder weights to initialize a DoA estimation model which we fine-tune for DoA estimation. Our experiments demonstrate that the pretrained models show improved performance in noisy and reverberant environments after fine-tuning for direction-of-arrival estimation, when compared to fully supervised models and classic signal processing methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20912v1" target="_blank">Research Challenges in Relational Database Management Systems for LLM Queries</a></h3>
                    <p><strong>Authors:</strong> Kerem Akillioglu, Anurag Chakraborty, Sairaj Voruganti, M. Tamer √ñzsu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have become essential for applications such as text summarization, sentiment analysis, and automated question-answering. Recently, LLMs have also been integrated into relational database management systems to enhance querying and support advanced data processing. Companies such as Amazon, Databricks, Google, and Snowflake offer LLM invocation directly within SQL, denoted as LLM queries, to boost data insights. However, open-source solutions currently have limited functionality and poor performance. In this work, we present an early exploration of two open-source systems and one enterprise platform, using five representative queries to expose functional, performance, and scalability limits in todays SQL-invoked LLM integrations. We identify three main issues: enforcing structured outputs, optimizing resource utilization, and improving query planning. We implemented initial solutions and observed improvements in accommodating LLM powered SQL queries. These early gains demonstrate that tighter integration of LLM+DBMS is the key to scalable and efficient processing of LLM queries.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20908v1" target="_blank">Subspace-Protected Topological Phases and Bulk-Boundary Correspondence</a></h3>
                    <p><strong>Authors:</strong> Kenji Shimomura, Ryo Takami, Daichi Nakamura, Masatoshi Sato</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.str-el, hep-th, quant-ph</p>
                    <p><strong>Summary:</strong> While tremendous research has revealed that symmetry enriches topological phases of matter, more general principles that protect topological phases have yet to be explored. In this Letter, we elucidate the roles of subspaces in free-fermionic topological phases. A subspace property for Hamiltonians enables us to define new topological invariants. They result in peculiar topological boundary phenomena, i.e., the emergence of an unpaired zero mode or zero-winding skin modes, characterizing subspace-protected topological phases. We establish and demonstrate the bulk-boundary correspondence in subspace-protected topological phases. We further discuss the interplay of the subspace property and internal symmetries. Toward application, we also propose possible platforms possessing the subspace property.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20907v1" target="_blank">Quantum Verifiable Rewards for Post-Training Qiskit Code Assistant</a></h3>
                    <p><strong>Authors:</strong> Nicolas Dupuis, Adarsh Tiwari, Youssef Mroueh, David Kremer, Ismael Faro, Juan Cruz-Benito</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.AI</p>
                    <p><strong>Summary:</strong> Qiskit is an open-source quantum computing framework that allows users to design, simulate, and run quantum circuits on real quantum hardware. We explore post-training techniques for LLMs to assist in writing Qiskit code. We introduce quantum verification as an effective method for ensuring code quality and executability on quantum hardware. To support this, we developed a synthetic data pipeline that generates quantum problem-unit test pairs and used it to create preference data for aligning LLMs with DPO. Additionally, we trained models using GRPO, leveraging quantum-verifiable rewards provided by the quantum hardware. Our best-performing model, combining DPO and GRPO, surpasses the strongest open-source baselines on the challenging Qiskit-HumanEval-hard benchmark.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20905v1" target="_blank">Real-Time Tracking Antenna System for Moving Targets</a></h3>
                    <p><strong>Authors:</strong> Adham Saad, Aya Sherif Nassef, Mahmoud Mohamed Elshahed, Mohamed Ismail Ahmed</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> This paper presents the design and implementation of a compact, cost-effective phased array antenna system. It is capable of real-time beam-steering for dynamic target-tracking applications. The system employs a 4$\times$4 rectangular microstrip patch array, utilizing advanced beamforming techniques and a Direction of Arrival (DoA) estimation algorithm. It achieves $\pm 42^{\circ}$ wide-angle scanning in both azimuth and elevation planes. The design emphasizes a balance between high angular coverage and consistent gain performance. This makes it suitable for wireless tracking, radar, and satellite communication terminals. Fabricated on Rogers 6010.2LM substrate, the system demonstrates reproducibility and scalability. All components are sourced locally to ensure practical deployment. The system is built using commercially available components, highlighting its affordability for research and prototyping purposes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20900v1" target="_blank">OneRec-V2 Technical Report</a></h3>
                    <p><strong>Authors:</strong> Guorui Zhou, Hengrui Hu, Hongtao Cheng, Huanjie Wang, Jiaxin Deng, Jinghao Zhang, Kuo Cai, Lejian Ren, Lu Ren, Liao Yu, Pengfei Zheng, Qiang Luo, Qianqian Wang, Qigen Hu, Rui Huang, Ruiming Tang, Shiyao Wang, Shujie Yang, Tao Wu, Wuchao Li, Xinchen Luo, Xingmei Wang, Yi Su, Yunfan Wu, Zexuan Cheng, Zhanyu Liu, Zixing Zhang, Bin Zhang, Boxuan Wang, Chaoyi Ma, Chengru Song, Chenhui Wang, Chenglong Chu, Di Wang, Dongxue Meng, Dunju Zang, Fan Yang, Fangyu Zhang, Feng Jiang, Fuxing Zhang, Gang Wang, Guowang Zhang, Han Li, Honghui Bao, Hongyang Cao, Jiaming Huang, Jiapeng Chen, Jiaqiang Liu, Jinghui Jia, Kun Gai, Lantao Hu, Liang Zeng, Qiang Wang, Qidong Zhou, Rongzhou Zhang, Shengzhe Wang, Shihui He, Shuang Yang, Siyang Mao, Sui Huang, Tiantian He, Tingting Gao, Wei Yuan, Xiao Liang, Xiaoxiao Xu, Xugang Liu, Yan Wang, Yang Zhou, Yi Wang, Yiwu Liu, Yue Song, Yufei Zhang, Yunfeng Zhao, Zhixin Ling, Ziming Li</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Recent breakthroughs in generative AI have transformed recommender systems through end-to-end generation. OneRec reformulates recommendation as an autoregressive generation task, achieving high Model FLOPs Utilization. While OneRec-V1 has shown significant empirical success in real-world deployment, two critical challenges hinder its scalability and performance: (1) inefficient computational allocation where 97.66% of resources are consumed by sequence encoding rather than generation, and (2) limitations in reinforcement learning relying solely on reward models. To address these challenges, we propose OneRec-V2, featuring: (1) Lazy Decoder-Only Architecture: Eliminates encoder bottlenecks, reducing total computation by 94% and training resources by 90%, enabling successful scaling to 8B parameters. (2) Preference Alignment with Real-World User Interactions: Incorporates Duration-Aware Reward Shaping and Adaptive Ratio Clipping to better align with user preferences using real-world feedback. Extensive A/B tests on Kuaishou demonstrate OneRec-V2s effectiveness, improving App Stay Time by 0.467%/0.741% while balancing multi-objective recommendations. This work advances generative recommendation scalability and alignment with real-world feedback, representing a step forward in the development of end-to-end recommender systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20892v1" target="_blank">To New Beginnings: A Survey of Unified Perception in Autonomous Vehicle Software</a></h3>
                    <p><strong>Authors:</strong> Lo√Øc Stratil, Felix Fent, Esteban Rivera, Markus Lienkamp</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Autonomous vehicle perception typically relies on modular pipelines that decompose the task into detection, tracking, and prediction. While interpretable, these pipelines suffer from error accumulation and limited inter-task synergy. Unified perception has emerged as a promising paradigm that integrates these sub-tasks within a shared architecture, potentially improving robustness, contextual reasoning, and efficiency while retaining interpretable outputs. In this survey, we provide a comprehensive overview of unified perception, introducing a holistic and systemic taxonomy that categorizes methods along task integration, tracking formulation, and representation flow. We define three paradigms -Early, Late, and Full Unified Perception- and systematically review existing methods, their architectures, training strategies, datasets used, and open-source availability, while highlighting future research directions. This work establishes the first comprehensive framework for understanding and advancing unified perception, consolidates fragmented efforts, and guides future research toward more robust, generalizable, and interpretable perception.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20881v1" target="_blank">Understanding and evaluating computer vision models through the lens of counterfactuals</a></h3>
                    <p><strong>Authors:</strong> Pushkar Shukla</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Counterfactual reasoning -- the practice of asking ``what if by varying inputs and observing changes in model behavior -- has become central to interpretable and fair AI. This thesis develops frameworks that use counterfactuals to explain, audit, and mitigate bias in vision classifiers and generative models. By systematically altering semantically meaningful attributes while holding others fixed, these methods uncover spurious correlations, probe causal dependencies, and help build more robust systems. The first part addresses vision classifiers. CAVLI integrates attribution (LIME) with concept-level analysis (TCAV) to quantify how strongly decisions rely on human-interpretable concepts. With localized heatmaps and a Concept Dependency Score, CAVLI shows when models depend on irrelevant cues like backgrounds. Extending this, ASAC introduces adversarial counterfactuals that perturb protected attributes while preserving semantics. Through curriculum learning, ASAC fine-tunes biased models for improved fairness and accuracy while avoiding stereotype-laden artifacts. The second part targets generative Text-to-Image (TTI) models. TIBET provides a scalable pipeline for evaluating prompt-sensitive biases by varying identity-related terms, enabling causal auditing of how race, gender, and age affect image generation. To capture interactions, BiasConnect builds causal graphs diagnosing intersectional biases. Finally, InterMit offers a modular, training-free algorithm that mitigates intersectional bias via causal sensitivity scores and user-defined fairness goals. Together, these contributions show counterfactuals as a unifying lens for interpretability, fairness, and causality in both discriminative and generative models, establishing principled, scalable methods for socially responsible bias evaluation and mitigation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20877v1" target="_blank">Deep Learning Framework for Early Detection of Pancreatic Cancer Using Multi-Modal Medical Imaging Analysis</a></h3>
                    <p><strong>Authors:</strong> Dennis Slobodzian, Karissa Tilbury, Amir Kordijazi</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Pacreatic ductal adenocarcinoma (PDAC) remains one of the most lethal forms of cancer, with a five-year survival rate below 10% primarily due to late detection. This research develops and validates a deep learning framework for early PDAC detection through analysis of dual-modality imaging: autofluorescence and second harmonic generation (SHG). We analyzed 40 unique patient samples to create a specialized neural network capable of distinguishing between normal, fibrotic, and cancerous tissue. Our methodology evaluated six distinct deep learning architectures, comparing traditional Convolutional Neural Networks (CNNs) with modern Vision Transformers (ViTs). Through systematic experimentation, we identified and overcome significant challenges in medical image analysis, including limited dataset size and class imbalance. The final optimized framework, based on a modified ResNet architecture with frozen pre-trained layers and class-weighted training, achieved over 90% accuracy in cancer detection. This represents a significant improvement over current manual analysis methods an demonstrates potential for clinical deployment. This work establishes a robust pipeline for automated PDAC detection that can augment pathologists capabilities while providing a foundation for future expansion to other cancer types. The developed methodology also offers valuable insights for applying deep learning to limited-size medical imaging datasets, a common challenge in clinical applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20869v1" target="_blank">OLMoASR: Open Models and Data for Training Robust Speech Recognition Models</a></h3>
                    <p><strong>Authors:</strong> Huong Ngo, Matt Deitke, Martijn Bartelds, Sarah Pratt, Josh Gardner, Matt Jordan, Ludwig Schmidt</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CL, cs.LG, eess.AS</p>
                    <p><strong>Summary:</strong> Improvements in training data scale and quality have led to significant advances, yet its influence in speech recognition remains underexplored. In this paper, we present a large-scale dataset, OLMoASR-Pool, and series of models, OLMoASR, to study and develop robust zero-shot speech recognition models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio and 17M transcripts, we design text heuristic filters to remove low-quality or mistranscribed data. Our curation pipeline produces a new dataset containing 1M hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M (tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR achieves comparable average performance to OpenAIs Whisper on short and long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a 12.8\% and 11.0\% word error rate (WER) that is on par with Whispers largest English-only model Whisper-medium.ens 12.4\% and 10.5\% WER for short and long-form recognition respectively (at equivalent parameter count). OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will be made publicly available to further research on robust speech processing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20866v1" target="_blank">AI Agentic Vulnerability Injection And Transformation with Optimized Reasoning</a></h3>
                    <p><strong>Authors:</strong> Amine Lbath, Massih-Reza Amini, Aurelien Delaitre, Vadim Okun</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> The increasing complexity of software systems and the sophistication of cyber-attacks have underscored the critical need for effective automated vulnerability detection and repair systems. Traditional methods, such as static program analysis, face significant challenges related to scalability, adaptability, and high false-positive and false-negative rates. AI-driven approaches, particularly those using machine learning and deep learning models, show promise but are heavily reliant on the quality and quantity of training data. This paper introduces a novel framework designed to automatically introduce realistic, category-specific vulnerabilities into secure C/C++ codebases to generate datasets. The proposed approach coordinates multiple AI agents that simulate expert reasoning, along with function agents and traditional code analysis tools. It leverages Retrieval-Augmented Generation for contextual grounding and employs Low-Rank approximation of weights for efficient model fine-tuning. Our experimental study on 116 code samples from three different benchmarks suggests that our approach outperforms other techniques with regard to dataset accuracy, achieving between 89\% and 95\% success rates in injecting vulnerabilities at function level.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20860v1" target="_blank">Euclid preparation. LXXIV. Euclidised observations of Hubble Frontier Fields and CLASH galaxy clusters</a></h3>
                    <p><strong>Authors:</strong> Euclid Collaboration, P. Bergamini, M. Meneghetti, G. Angora, L. Bazzanini, P. Rosati, C. Grillo, M. Lombardi, D. Abriola, A. Mercurio, F. Calura, G. Despali, J. M. Diego, R. Gavazzi, P. Hudelot, L. Leuzzi, G. Mahler, E. Merlin, C. Scarlata, N. Aghanim, B. Altieri, A. Amara, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, S. Bardelli, R. Bender, A. Biviano, C. Bodendorf, D. Bonino, E. Branchini, M. Brescia, J. Brinchmann, S. Camera, G. Ca√±as-Herrera, V. Capobianco, C. Carbone, J. Carretero, S. Casas, F. J. Castander, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, G. De Lucia, A. M. Di Giorgio, J. Dinis, H. Dole, M. Douspis, F. Dubath, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Farrens, S. Ferriol, F. Finelli, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, B. Garilli, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, L. Guzzo, S. V. H. Haugan, W. Holmes, I. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, E. Keih√§nen, S. Kermiche, A. Kiessling, M. Kilbinger, B. Kubik, M. K√ºmmel, M. Kunz, H. Kurki-Suonio, R. Laureijs, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, O. Marggraf, K. Markovic, M. Martinelli, N. Martinet, F. Marulli, R. Massey, S. Maurogordato, E. Medinaceli, S. Mei, Y. Mellier, G. Meylan, M. Moresco, L. Moscardini, E. Munari, R. Nakajima, C. Neissner, S. -M. Niemi, J. W. Nightingale, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, E. Rossetti, R. Saglia, Z. Sakr, A. G. S√°nchez, D. Sapone, B. Sartoris, M. Schirmer, P. Schneider, A. Secroun, E. Sefusatti, G. Seidel, S. Serrano, P. Simon, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-Cresp√≠, H. I. Teplitz, I. Tereno, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, G. Zamorani, E. Zucca, M. Bolzonella, A. Boucaud, E. Bozzo, C. Burigana, M. Calabrese, D. Di Ferdinando, J. A. Escartin Vigo, N. Mauri, V. Scottez, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, V. Allevato, S. Anselmi, M. Ballardini, M. Bethermin, A. Blanchard, L. Blot, S. Borgani, A. S. Borlaff, S. Bruton, R. Cabanac, A. Calabro, A. Cappi, C. S. Carvalho, T. Castro, S. Contarini, T. Contini, A. R. Cooray, O. Cucciati, B. De Caro, G. Desprez, A. D√≠az-S√°nchez, S. Di Domizio, A. G. Ferrari, I. Ferrero, F. Fornari, L. Gabarra, K. Ganga, J. Garc√≠a-Bellido, V. Gautard, E. Gaztanaga, F. Giacomini, G. Gozaliasl, A. Hall, H. Hildebrandt, J. Hjorth, M. Huertas-Company, A. Jimenez Mu√±oz, J. J. E. Kajava, V. Kansal, D. Karagiannis, C. C. Kirkpatrick, L. Legrand, G. Libet, A. Loureiro, G. Maggio, M. Magliocchetti, C. Mancini, F. Mannucci, R. Maoli, C. J. A. P. Martins, S. Matthew, L. Maurin, R. B. Metcalf, P. Monaco, C. Moretti, G. Morgante, Nicholas A. Walton, J. Odier, L. Patrizii, A. Pezzotta, M. P√∂ntinen, V. Popa, C. Porciani, D. Potter, I. Risso, P. -F. Rocci, M. Sahl√©n, A. Schneider, M. Sereno, S. A. Stanford, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, D. Vergani, G. Verza</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> We present HST2EUCLID, a novel Python code to generate Euclid realistic mock images in the $H_{\rm E}$, $J_{\rm E}$, $Y_{\rm E}$, and $I_{\rm E}$ photometric bands based on panchromatic Hubble Space Telescope observations. The software was used to create a simulated database of Euclid images for the 27 galaxy clusters observed during the Cluster Lensing And Supernova survey with Hubble (CLASH) and the Hubble Frontier Fields (HFF) program. Since the mock images were generated from real observations, they incorporate, by construction, all the complexity of the observed galaxy clusters. The simulated Euclid data of the galaxy cluster MACS J0416.1$-$2403 were then used to explore the possibility of developing strong lensing models based on the Euclid data. In this context, complementary photometric or spectroscopic follow-up campaigns are required to measure the redshifts of multiple images and cluster member galaxies. By Euclidising six parallel blank fields obtained during the HFF program, we provide an estimate of the number of galaxies detectable in Euclid images per ${\rm deg}^2$ per magnitude bin (number counts) and the distribution of the galaxy sizes. Finally, we present a preview of the Chandra Deep Field South that will be observed during the Euclid Deep Survey and two examples of galaxy-scale strong lensing systems residing in regions of the sky covered by the Euclid Wide Survey. The methodology developed in this work lends itself to several additional applications, as simulated Euclid fields based on HST (or JWST) imaging with extensive spectroscopic information can be used to validate the feasibility of legacy science cases or to train deep learning techniques in advance, thus preparing for a timely exploitation of the Euclid Survey data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20851v1" target="_blank">PathMR: Multimodal Visual Reasoning for Interpretable Pathology Diagnosis</a></h3>
                    <p><strong>Authors:</strong> Ye Zhang, Yu Zhou, Jingwen Qi, Yongbing Zhang, Simon Puettmann, Finn Wichmann, Larissa Pereira Ferreira, Lara Sichward, Julius Keyl, Sylvia Hartmann, Shuo Zhao, Hongxiao Wang, Xiaowei Xu, Jianxu Chen</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep learning based automated pathological diagnosis has markedly improved diagnostic efficiency and reduced variability between observers, yet its clinical adoption remains limited by opaque model decisions and a lack of traceable rationale. To address this, recent multimodal visual reasoning architectures provide a unified framework that generates segmentation masks at the pixel level alongside semantically aligned textual explanations. By localizing lesion regions and producing expert style diagnostic narratives, these models deliver the transparent and interpretable insights necessary for dependable AI assisted pathology. Building on these advancements, we propose PathMR, a cell-level Multimodal visual Reasoning framework for Pathological image analysis. Given a pathological image and a textual query, PathMR generates expert-level diagnostic explanations while simultaneously predicting cell distribution patterns. To benchmark its performance, we evaluated our approach on the publicly available PathGen dataset as well as on our newly developed GADVR dataset. Extensive experiments on these two datasets demonstrate that PathMR consistently outperforms state-of-the-art visual reasoning methods in text generation quality, segmentation accuracy, and cross-modal alignment. These results highlight the potential of PathMR for improving interpretability in AI-driven pathological diagnosis. The code will be publicly available in https://github.com/zhangye-zoe/PathMR.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20850v1" target="_blank">Encoding Tactile Stimuli for Organoid Intelligence in Braille Recognition</a></h3>
                    <p><strong>Authors:</strong> Tianyi Liu, Hemma Philamore, Benjamin Ward-Cherrier</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.NE, cs.ET, cs.RO</p>
                    <p><strong>Summary:</strong> This study proposes a generalizable encoding strategy that maps tactile sensor data to electrical stimulation patterns, enabling neural organoids to perform an open-loop artificial tactile Braille classification task. Human forebrain organoids cultured on a low-density microelectrode array (MEA) are systematically stimulated to characterize the relationship between electrical stimulation parameters (number of pulse, phase amplitude, phase duration, and trigger delay) and organoid responses, measured as spike activity and spatial displacement of the center of activity. Implemented on event-based tactile inputs recorded from the Evetac sensor, our system achieved an average Braille letter classification accuracy of 61 percent with a single organoid, which increased significantly to 83 percent when responses from a three-organoid ensemble were combined. Additionally, the multi-organoid configuration demonstrated enhanced robustness against various types of artificially introduced noise. This research demonstrates the potential of organoids as low-power, adaptive bio-hybrid computational elements and provides a foundational encoding framework for future scalable bio-hybrid computing architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20840v1" target="_blank">Learning Primitive Embodied World Models: Towards Scalable Robotic Learning</a></h3>
                    <p><strong>Authors:</strong> Qiao Sun, Liujia Yang, Wei Tang, Wei Huang, Kaixin Xu, Yongchao Chen, Mingyu Liu, Jiange Yang, Haoyi Zhu, Yating Wang, Tong He, Yilun Chen, Xili Dai, Nanyang Ye, Qinying Gu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.MM</p>
                    <p><strong>Summary:</strong> While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a GPT moment in the embodied domain. There is a naive observation: the diversity of embodied data far exceeds the relatively small space of possible primitive motions. Based on this insight, we propose a novel paradigm for world modeling--Primitive Embodied World Models (PEWM). By restricting video generation to fixed short horizons, our approach 1) enables fine-grained alignment between linguistic concepts and visual representations of robotic actions, 2) reduces learning complexity, 3) improves data efficiency in embodied data collection, and 4) decreases inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20835v1" target="_blank">PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification</a></h3>
                    <p><strong>Authors:</strong> Hao Yang, Qianyu Zhou, Haijia Sun, Xiangtai Li, Xuequan Lu, Lizhuang Ma, Shuicheng Yan</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Domain Generalization (DG) has been recently explored to enhance the generalizability of Point Cloud Classification (PCC) models toward unseen domains. Prior works are based on convolutional networks, Transformer or Mamba architectures, either suffering from limited receptive fields or high computational cost, or insufficient long-range dependency modeling. RWKV, as an emerging architecture, possesses superior linear complexity, global receptive fields, and long-range dependency. In this paper, we present the first work that studies the generalizability of RWKV models in DG PCC. We find that directly applying RWKV to DG PCC encounters two significant challenges: RWKVs fixed direction token shift methods, like Q-Shift, introduce spatial distortions when applied to unstructured point clouds, weakening local geometric modeling and reducing robustness. In addition, the Bi-WKV attention in RWKV amplifies slight cross-domain differences in key distributions through exponential weighting, leading to attention shifts and degraded generalization. To this end, we propose PointDGRWKV, the first RWKV-based framework tailored for DG PCC. It introduces two key modules to enhance spatial modeling and cross-domain robustness, while maintaining RWKVs linear efficiency. In particular, we present Adaptive Geometric Token Shift to model local neighborhood structures to improve geometric context awareness. In addition, Cross-Domain key feature Distribution Alignment is designed to mitigate attention drift by aligning key feature distributions across domains. Extensive experiments on multiple benchmarks demonstrate that PointDGRWKV achieves state-of-the-art performance on DG PCC.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20830v1" target="_blank">Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation</a></h3>
                    <p><strong>Authors:</strong> Krit Duangprom, Tryphon Lambrou, Binod Bhattarai</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper presents a novel pipeline for 2D keypoint estima- tion of surgical tools by leveraging Vision Language Models (VLMs) fine- tuned using a low rank adjusting (LoRA) technique. Unlike traditional Convolutional Neural Network (CNN) or Transformer-based approaches, which often suffer from overfitting in small-scale medical datasets, our method harnesses the generalization capabilities of pre-trained VLMs. We carefully design prompts to create an instruction-tuning dataset and use them to align visual features with semantic keypoint descriptions. Experimental results show that with only two epochs of fine tuning, the adapted VLM outperforms the baseline models, demonstrating the ef- fectiveness of LoRA in low-resource scenarios. This approach not only improves keypoint detection performance, but also paves the way for future work in 3D surgical hands and tools pose estimation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20828v1" target="_blank">GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction</a></h3>
                    <p><strong>Authors:</strong> Jie Zhao, Wanting Ning, Yuxiao Fei, Yubo Feng, Lishuang Li</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> In Natural Language Processing(NLP), Event Temporal Relation Extraction (ETRE) is to recognize the temporal relations of two events. Prior studies have noted the importance of language models for ETRE. However, the restricted pre-trained knowledge of Small Language Models(SLMs) limits their capability to handle minority class relations in imbalanced classification datasets. For Large Language Models(LLMs), researchers adopt manually designed prompts or instructions, which may introduce extra noise, leading to interference with the models judgment of the long-distance dependencies between events. To address these issues, we propose GDLLM, a Global Distance-aware modeling approach based on LLMs. We first present a distance-aware graph structure utilizing Graph Attention Network(GAT) to assist the LLMs in capturing long-distance dependency features. Additionally, we design a temporal feature learning paradigm based on soft inference to augment the identification of relations with a short-distance proximity band, which supplements the probabilistic information generated by LLMs into the multi-head attention mechanism. Since the global feature can be captured effectively, our framework substantially enhances the performance of minority relation classes and improves the overall learning ability. Experiments on two publicly available datasets, TB-Dense and MATRES, demonstrate that our approach achieves state-of-the-art (SOTA) performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20820v1" target="_blank">Apparatus for quantum-mixture research in microgravity</a></h3>
                    <p><strong>Authors:</strong> Baptist Piest, Jonas B√∂hm, Timoth√© Estrampes, Annie Pichery, Pawe≈Ç Arciszewski, Wolfgang Bartosch, S√∂ren Boles, Klaus D√∂ringshoff, Michael Elsen, Priyanka Guggilam, Ortwin Hellmig, Christian K√ºrbis, Dorthe Leopoldt, Gabriel M√ºller, Alexandros Papakonstantinou, Christian Reichelt, Andr√© Wenzlawski, Thijs Wendrich, √âric Charron, Achim Peters, Klaus Sengstock, Andreas Wicht, Patrick Windpassinger, Jens Grosse, Naceur Gaaloul, Ernst Maria Rasel</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas, physics.atom-ph, quant-ph</p>
                    <p><strong>Summary:</strong> Experiments with ultracold quantum gases are a rapidly advancing research field with many applications in fundamental physics and quantum technology. Here, we report on a high-flux generation of Bose-Einstein condensate mixtures of $^{41}$K and $^{87}$Rb, using a fully integrated sounding rocket setup. We investigate the release and the free expansion of the quantum mixtures for different orientations to gravity. The release dynamics are governed by the mixture interactions as well as the decaying magnetic field during the release. The latter can be minimized by a dedicated switch-off protocol of the trap generating currents where an exact model enabled us to characterize the interaction effects. Our results establish a new benchmark for generating ultracold mixtures on mobile platforms, with direct relevance for future experiments on interacting quantum gases and tests of the equivalence principle in space.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20816v1" target="_blank">Multi-Agent Penetration Testing AI for the Web</a></h3>
                    <p><strong>Authors:</strong> Isaac David, Arthur Gervais</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> AI-powered development platforms are making software creation accessible to a broader audience, but this democratization has triggered a scalability crisis in security auditing. With studies showing that up to 40% of AI-generated code contains vulnerabilities, the pace of development now vastly outstrips the capacity for thorough security assessment. We present MAPTA, a multi-agent system for autonomous web application security assessment that combines large language model orchestration with tool-grounded execution and end-to-end exploit validation. On the 104-challenge XBOW benchmark, MAPTA achieves 76.9% overall success with perfect performance on SSRF and misconfiguration vulnerabilities, 83% success on broken authorization, and strong results on injection attacks including server-side template injection (85%) and SQL injection (83%). Cross-site scripting (57%) and blind SQL injection (0%) remain challenging. Our comprehensive cost analysis across all challenges totals $21.38 with a median cost of $0.073 for successful attempts versus $0.357 for failures. Success correlates strongly with resource efficiency, enabling practical early-stopping thresholds at approximately 40 tool calls or $0.30 per challenge. MAPTAs real-world findings are impactful given both the popularity of the respective scanned GitHub repositories (8K-70K stars) and MAPTAs low average operating cost of $3.67 per open-source assessment: MAPTA discovered critical vulnerabilities including RCEs, command injections, secret exposure, and arbitrary file write vulnerabilities. Findings are responsibly disclosed, 10 findings are under CVE review.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20811v1" target="_blank">When technology is not enough: Insights from a pilot cybersecurity culture assessment in a safety-critical industrial organisation</a></h3>
                    <p><strong>Authors:</strong> Tita Alissa Bach, Linn Pedersen, Maria Kinck Bor√©n‚Ä†, Lisa Christoffersen Temte‚Ä†</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> As cyber threats increasingly exploit human behaviour, technical controls alone cannot ensure organisational cybersecurity (CS). Strengthening cybersecurity culture (CSC) is vital in safety-critical industries, yet empirical research in real-world industrial setttings is scarce. This paper addresses this gap through a pilot mixed-methods CSC assessment in a global safety-critical organisation. We examined employees CS knowledge, attitudes, behaviours, and organisational factors shaping them. A survey and semi-structured interviews were conducted at a global organisation in safety-critical industries, across two countries chosen for contrasting phishing simulation performance: Country 1 stronger, Country 2 weaker. In Country 1, 258 employees were invited (67%), in Country 2, 113 were invited (30%). Interviews included 20 and 10 participants respectively. Overall CSC profiles were similar but revealed distinct challenges. Both showed strong phishing awareness and prioritised CS, yet most viewed phishing as the main risk and lacked clarity on handling other incidents. Line managers were default contacts, but follow-up on reported concerns was unclear. Participants emphasized aligning CS expectations with job relevance and workflows. Key contributors to differences emerged: Country 1 had external employees with limited access to CS training and policies, highlighting monitoring gaps. In Country 2, low survey response stemmed from a no-link in email policy. While this policy may have boosted phishing performance, it also underscored inconsistencies in CS practices. Findings show that resilient CSC requires leadership involvement, targeted communication, tailored measures, policy-practice alignment, and regular assessments. Embedding these into strategy complements technical defences and strengthens sustainable CS in safety-critical settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20809v1" target="_blank">On the Spectral Properties of a Class of Planar Sierpinski Self-Affine Measures</a></h3>
                    <p><strong>Authors:</strong> Jia-Long Chen, Wen-Hui Ai</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> math.FA, 28A80, 42C05, 46C05</p>
                    <p><strong>Summary:</strong> We investigate the spectral properties of a class of Sierpinski-type self-affine measures defined by \[ \mu_{M,D}(\cdot) = p^{-1} \sum_{d \in D} \mu_{M,D}(M(\cdot) - d), \] where \( p \) is a prime number, \( M = \begin{bmatrix} \rho_1^{-1}  c 0  \rho_2^{-1} \end{bmatrix} \) is a real upper triangular expanding matrix, and \( D = \{d_0, d_1, \cdots, d_{p-1}\} \subset \mathbb{Z}^2 \) satisfying \( \mathcal{Z}(\widehat{\delta}_{D}) = \cup_{j=1}^{p-1} \left( \frac{j \bm{a}}{p} + \mathbb{Z}^2 \right) \) for some \( \bm{a} \in \mathcal{E}_{p}= \{ (i_1, i_2)^* : i_1, i_2 \in [1, p-1] \cap \mathbb{Z} \} \), where \( \mathcal{Z}(\widehat{\delta}_{D}) \) denotes the set of zeros of \( \widehat{\delta}_{D} \) with \( \delta_{D} = \frac{1}{\# D} \sum_{d \in D} \delta_d \). When $\rho_1 = \rho_2$, we derive necessary and sufficient conditions for $\mu_{M,D}$ to both: $(i)$ possess an infinite orthogonal set of exponential functions, and $(ii)$ be a spectral measure. When no infinite orthogonal exponential system exists in $L^{2}(\mu_{M,D})$, we quantify the maximum number of orthogonal exponentials and provide precise estimates. For $\rho_1 \neq \rho_2$, with restricted digit sets $D$, we obtain a necessary and sufficient condition for $\mu_{M,D}$ to be a spectral measure.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21072v1" target="_blank">First-Place Solution to NeurIPS 2024 Invisible Watermark Removal Challenge</a></h3>
                    <p><strong>Authors:</strong> Fahad Shamshad, Tameem Bakr, Yahia Shaaban, Noor Hussein, Karthik Nandakumar, Nils Lukas</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Content watermarking is an important tool for the authentication and copyright protection of digital media. However, it is unclear whether existing watermarks are robust against adversarial attacks. We present the winning solution to the NeurIPS 2024 Erasing the Invisible challenge, which stress-tests watermark robustness under varying degrees of adversary knowledge. The challenge consisted of two tracks: a black-box and beige-box track, depending on whether the adversary knows which watermarking method was used by the provider. For the beige-box track, we leverage an adaptive VAE-based evasion attack, with a test-time optimization and color-contrast restoration in CIELAB space to preserve the images quality. For the black-box track, we first cluster images based on their artifacts in the spatial or frequency-domain. Then, we apply image-to-image diffusion models with controlled noise injection and semantic priors from ChatGPT-generated captions to each cluster with optimized parameter settings. Empirical evaluations demonstrate that our method successfully achieves near-perfect watermark removal (95.7%) with negligible impact on the residual images quality. We hope that our attacks inspire the development of more robust image watermarking methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21070v1" target="_blank">DressDance: Dress up and Dance as You Like It - Technical Preview</a></h3>
                    <p><strong>Authors:</strong> Jun-Kun Chen, Aayush Bansal, Minh Phuoc Vo, Yu-Xiong Wang</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> We present DressDance, a video diffusion framework that generates high quality 5-second-long 24 FPS virtual try-on videos at 1152x720 resolution of a user wearing desired garments while moving in accordance with a given reference video. Our approach requires a single user image and supports a range of tops, bottoms, and one-piece garments, as well as simultaneous tops and bottoms try-on in a single pass. Key to our framework is CondNet, a novel conditioning network that leverages attention to unify multi-modal inputs (text, images, and videos), thereby enhancing garment registration and motion fidelity. CondNet is trained on heterogeneous training data, combining limited video data and a larger, more readily available image dataset, in a multistage progressive manner. DressDance outperforms existing open source and commercial solutions and enables a high quality and flexible try-on experience.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21066v1" target="_blank">OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning</a></h3>
                    <p><strong>Authors:</strong> Yuan Gong, Xionghui Wang, Jie Wu, Shiyin Wang, Yitong Wang, Xinglong Wu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this paper, we introduce OneReward, a unified reinforcement learning framework that enhances the models generative capabilities across multiple tasks under different evaluation criteria using only \textit{One Reward} model. By employing a single vision-language model (VLM) as the generative reward model, which can distinguish the winner and loser for a given task and a given evaluation criterion, it can be effectively applied to multi-task generation models, particularly in contexts with varied data and diverse task objectives. We utilize OneReward for mask-guided image generation, which can be further divided into several sub-tasks such as image fill, image extend, object removal, and text rendering, involving a binary mask as the edit area. Although these domain-specific tasks share same conditioning paradigm, they differ significantly in underlying data distributions and evaluation metrics. Existing methods often rely on task-specific supervised fine-tuning (SFT), which limits generalization and training efficiency. Building on OneReward, we develop Seedream 3.0 Fill, a mask-guided generation model trained via multi-task reinforcement learning directly on a pre-trained base model, eliminating the need for task-specific SFT. Experimental results demonstrate that our unified edit model consistently outperforms both commercial and open-source competitors, such as Ideogram, Adobe Photoshop, and FLUX Fill [Pro], across multiple evaluation dimensions. Code and model are available at: https://one-reward.github.io</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21067v1" target="_blank">Physical constraints on effective non-Hermitian systems</a></h3>
                    <p><strong>Authors:</strong> Aaron Kleger, Rufus Boyack</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Interacting and open quantum systems can be formulated in terms of an effective non-Hermitian Hamiltonian (NHH), however, there are important constraints that must be satisfied by the effective action and the associated Greens functions. One common approach to many-body non-Hermitian (NH) systems is to incorporate the anti-Hermitian part of the Hamiltonian directly in the Matsubara Greens function. Here, we show that such an approach is incompatible with the standard framework for systems with interactions. Furthermore, we furnish a consistent physical description for such systems by determining their distinction from conventional interacting physics, and find that they are described by pseudo-Hermitian quantum mechanics. Furthermore, we characterize the zero-temperature distribution functions within several frameworks for NH systems. As an application of our results, we consider the electromagnetic response of a NH quasiparticle Hamiltonian based on the (1+1)-dimensional NH Dirac model subject to various physical descriptions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21060v1" target="_blank">Multi-View 3D Point Tracking</a></h3>
                    <p><strong>Authors:</strong> Frano Rajiƒç, Haofei Xu, Marko Mihajlovic, Siyuan Li, Irem Demir, Emircan G√ºndoƒüdu, Lei Ke, Sergey Prokudin, Marc Pollefeys, Siyu Tang</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce the first data-driven multi-view 3D point tracker, designed to track arbitrary points in dynamic scenes using multiple camera views. Unlike existing monocular trackers, which struggle with depth ambiguities and occlusion, or prior multi-camera methods that require over 20 cameras and tedious per-sequence optimization, our feed-forward model directly predicts 3D correspondences using a practical number of cameras (e.g., four), enabling robust and accurate online tracking. Given known camera poses and either sensor-based or estimated multi-view depth, our tracker fuses multi-view features into a unified point cloud and applies k-nearest-neighbors correlation alongside a transformer-based update to reliably estimate long-range 3D correspondences, even under occlusion. We train on 5K synthetic multi-view Kubric sequences and evaluate on two real-world benchmarks: Panoptic Studio and DexYCB, achieving median trajectory errors of 3.1 cm and 2.0 cm, respectively. Our method generalizes well to diverse camera setups of 1-8 views with varying vantage points and video lengths of 24-150 frames. By releasing our tracker alongside training and evaluation datasets, we aim to set a new standard for multi-view 3D tracking research and provide a practical tool for real-world applications. Project page available at https://ethz-vlg.github.io/mvtracker.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21059v1" target="_blank">Dynamics of the Fermion-Rotor System</a></h3>
                    <p><strong>Authors:</strong> Vazha Loladze, Takemichi Okui, David Tong</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> hep-th, cond-mat.str-el, hep-ph</p>
                    <p><strong>Summary:</strong> We explore the dynamics of the fermion-rotor system, a simple impurity model in d=1+1 dimensions that consists of a collection of purely right-moving fermions interacting with a quantum mechanical rotor localised at the origin. This was first introduced by Polchinski as a toy model for monopole-fermion scattering and is surprisingly subtle, with ingoing and outgoing fermions carrying different quantum numbers. We show that the rotor acts as a twist operator in the low-energy theory, changing the quantum numbers of excitations that have previously passed through the origin to ensure scattering consistent with all symmetries. We further show how generalisations of this model with multiple rotors and unequal charges can be viewed as a UV-completion of boundary states for chiral theories, including the well-studied 3450 model. We compute correlation functions between ingoing and outgoing fermions and show that fermions dressed with the rotor degree of freedom act as local operators and create single-particle states, generalising an earlier result obtained in a theory with a single rotor and equal charges. Finally, we point out a mod 2 anomaly in these models that descends from the Witten anomaly in 4d</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21058v1" target="_blank">Mixture of Contexts for Long Video Generation</a></h3>
                    <p><strong>Authors:</strong> Shengqu Cai, Ceyuan Yang, Lvmin Zhang, Yuwei Guo, Junfei Xiao, Ziyan Yang, Yinghao Xu, Zhenheng Yang, Alan Yuille, Leonidas Guibas, Maneesh Agrawala, Lu Jiang, Gordon Wetzstein</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Long video generation is fundamentally a long context memory problem: models must retain and retrieve salient events across a long range without collapsing or drifting. However, scaling diffusion transformers to generate long-context videos is fundamentally limited by the quadratic cost of self-attention, which makes memory and computation intractable and difficult to optimize for long sequences. We recast long-context video generation as an internal information retrieval task and propose a simple, learnable sparse attention routing module, Mixture of Contexts (MoC), as an effective long-term memory retrieval engine. In MoC, each query dynamically selects a few informative chunks plus mandatory anchors (caption, local windows) to attend to, with causal routing that prevents loop closures. As we scale the data and gradually sparsify the routing, the model allocates compute to salient history, preserving identities, actions, and scenes over minutes of content. Efficiency follows as a byproduct of retrieval (near-linear scaling), which enables practical training and synthesis, and the emergence of memory and consistency at the scale of minutes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21056v1" target="_blank">Altermagnetic Shastry-Sutherland fullerene networks</a></h3>
                    <p><strong>Authors:</strong> Jiaqi Wu, Alaric Sanders, Rundong Yuan, Bo Peng</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, cond-mat.mes-hall, physics.atm-clus, physics.chem-ph, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Molecular building blocks provide a versatile platform for realising exotic quantum phases. Using charge neutral, pure carbon fullerene molecules as an example, we design altermagnetic C$_{40}$ monolayers in Shastry-Sutherland lattice. The resonance structure of one unpaired electron leads to an effective spin-1/2 cluster on both long sides of the molecule, which, after rotating into a 2D rutile-like crystal structure, forms altermagnetic ground state. We show $d$-wave spitting of the spin-polarised electronic band structure and strong chiral-split magnon bands. Most interestingly, the effective spin-1/2 clusters form the Shastry-Sutherland model with a rich phase diagram including altermagenti, quantum spin liquid, plaquette, and dimer phases, which can be easily accessed to via moderate bi-axial strains. Our findings present magnetic fullerene monolayers as a tunable platform for exotic quantum magnetism and spintronic applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21054v1" target="_blank">Constraints on Logarithmic Model Extensions of Symmetric Teleparallel Gravity</a></h3>
                    <p><strong>Authors:</strong> Purnendu Karmakar, Sandeep Haridasu, Atsushi Nishizawa</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc, hep-ph</p>
                    <p><strong>Summary:</strong> We address various cosmological phenomenologies in the symmetric teleparallel framework both in background and perturbation such as cosmic expansion, gravitational coupling constant, gravitational waves propagation. Focusing on logarithmic extensions of $f(Q)$ models, we performed Bayesian analysis using the most-recent cosmological data, DESI DR2, Pantheon+. We also utilized a compilation of redshift space distortions ($f \sigma_8$) dataset to constrain the growth of structures in each of the models modulated by the effective gravitational coupling. We find that our extended Logarithmic $f(Q)$ models are well-constrained by the current cosmological data and are able to describe the late-time cosmic acceleration. The inverse Logarithmic model we introduce is also able to accommodate a phantom-like dark energy equation of state at late times, which is consistent with the recent DESI DR2 observations. We report explicitly predictions for the effective gravitational coupling ($\mu$), and the amplitude damping parameter of gravitational wave ($\nu$) solely based on the background data, which can be tested against future observations. While the two Log-based extensions we have introduced here perform equivalently on the background level, they provide contrasting predictions for the evolution of effective Gravitational constant and propagation of gravitational waves, which should be constrained against the future perturbation data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21052v1" target="_blank">FakeParts: a New Family of AI-Generated DeepFakes</a></h3>
                    <p><strong>Authors:</strong> Gaetan Brison, Soobash Daiboo, Samy Aimeur, Awais Hussain Sani, Xi Wang, Gianni Franchi, Vicky Kalogeiton</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.MM</p>
                    <p><strong>Summary:</strong> We introduce FakeParts, a new class of deepfakes characterized by subtle, localized manipulations to specific spatial regions or temporal segments of otherwise authentic videos. Unlike fully synthetic content, these partial manipulations, ranging from altered facial expressions to object substitutions and background modifications, blend seamlessly with real elements, making them particularly deceptive and difficult to detect. To address the critical gap in detection capabilities, we present FakePartsBench, the first large-scale benchmark dataset specifically designed to capture the full spectrum of partial deepfakes. Comprising over 25K videos with pixel-level and frame-level manipulation annotations, our dataset enables comprehensive evaluation of detection methods. Our user studies demonstrate that FakeParts reduces human detection accuracy by over 30% compared to traditional deepfakes, with similar performance degradation observed in state-of-the-art detection models. This work identifies an urgent vulnerability in current deepfake detection approaches and provides the necessary resources to develop more robust methods for partial video manipulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21051v1" target="_blank">Enabling Equitable Access to Trustworthy Financial Reasoning</a></h3>
                    <p><strong>Authors:</strong> William Jurayj, Nils Holzenberger, Benjamin Van Durme</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> According to the United States Internal Revenue Service, the average American spends $\$270$ and 13 hours filing their taxes. Even beyond the U.S., tax filing requires complex reasoning, combining application of overlapping rules with numerical calculations. Because errors can incur costly penalties, any automated system must deliver high accuracy and auditability, making modern large language models (LLMs) poorly suited for this task. We propose an approach that integrates LLMs with a symbolic solver to calculate tax obligations. We evaluate variants of this system on the challenging StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for estimating the cost of deploying such a system based on real-world penalties for tax errors. We further show how combining up-front translation of plain-text rules into formal logic programs, combined with intelligently retrieved exemplars for formal case representations, can dramatically improve performance on this task and reduce costs to well below real-world averages. Our results demonstrate the promise and economic feasibility of neuro-symbolic architectures for increasing equitable access to reliable tax assistance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21050v1" target="_blank">Dynamics of Gender Bias in Software Engineering</a></h3>
                    <p><strong>Authors:</strong> Thomas J. Misa</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.CY, K.2; K.6.3; K.4; K.7</p>
                    <p><strong>Summary:</strong> The field of software engineering is embedded in both engineering and computer science, and may embody gender biases endemic to both. This paper surveys software engineerings origins and its long-running attention to engineering professionalism, profiling five leaders; it then examines the fields recent attention to gender issues and gender bias. It next quantitatively analyzes womens participation as research authors in the fields leading International Conference of Software Engineering (1976-2010), finding a dozen years with statistically significant gender exclusion. Policy dimensions of research on gender bias in computing are suggested.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21049v1" target="_blank">Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm</a></h3>
                    <p><strong>Authors:</strong> Ramazan Ali Bahrami, Ramin Yahyapour</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Sentential relation extraction (RE) is an important task in natural language processing (NLP). In this paper we propose to do sentential RE with dynamic routing in capsules. We first show that the proposed approach outperform state of the art on common sentential relation extraction datasets Tacred, Tacredrev, Retacred, and Conll04. We then investigate potential reasons for its good performance on the mentioned datasets, and yet low performance on another similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise in Wikidata labels as one of the reasons that can hinder performance. Additionally, we show associativity of better performance with better re-representation, a term from neuroscience referred to change of representation in human brain to improve the match at comparison time. As example, in the given analogous terms King:Queen::Man:Woman, at comparison time, and as a result of re-representation, the similarity between related head terms (King,Man), and tail terms (Queen,Woman) increases. As such, our observation show that our proposed model can do re-representation better than the vanilla model compared with. To that end, beside noise in the labels of the distantly supervised RE datasets, we propose re-representation as a challenge in sentential RE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21048v1" target="_blank">Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning</a></h3>
                    <p><strong>Authors:</strong> Hao Tan, Jun Lan, Zichang Tan, Ajian Liu, Chuanbiao Song, Senyuan Shi, Huijia Zhu, Weiqiang Wang, Jun Wan, Zhen Lei</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Deepfake detection remains a formidable challenge due to the complex and evolving nature of fake content in real-world scenarios. However, existing academic benchmarks suffer from severe discrepancies from industrial practice, typically featuring homogeneous training sources and low-quality testing images, which hinder the practical deployments of current detectors. To mitigate this gap, we introduce HydraFake, a dataset that simulates real-world challenges with hierarchical generalization testing. Specifically, HydraFake involves diversified deepfake techniques and in-the-wild forgeries, along with rigorous training and evaluation protocol, covering unseen model architectures, emerging forgery techniques and novel data domains. Building on this resource, we propose Veritas, a multi-modal large language model (MLLM) based deepfake detector. Different from vanilla chain-of-thought (CoT), we introduce pattern-aware reasoning that involves critical reasoning patterns such as planning and self-reflection to emulate human forensic process. We further propose a two-stage training pipeline to seamlessly internalize such deepfake reasoning capacities into current MLLMs. Experiments on HydraFake dataset reveal that although previous detectors show great generalization on cross-model scenarios, they fall short on unseen forgeries and data domains. Our Veritas achieves significant gains across different OOD scenarios, and is capable of delivering transparent and faithful detection outputs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21046v1" target="_blank">CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing  Sparsification</a></h3>
                    <p><strong>Authors:</strong> Wei Li, Renshan Zhang, Rui Shao, Jie He, Liqiang Nie</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Recent Vision-Language-Action (VLA) models built on pre-trained Vision-Language Models (VLMs) require extensive post-training, resulting in high computational overhead that limits scalability and deployment.We propose CogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages instruction-driven routing and sparsification to improve both efficiency and performance. CogVLA draws inspiration from human multimodal coordination and introduces a 3-stage progressive architecture. 1) Encoder-FiLM based Aggregation Routing (EFA-Routing) injects instruction information into the vision encoder to selectively aggregate and compress dual-stream visual tokens, forming a instruction-aware latent representation. 2) Building upon this compact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing) introduces action intent into the language model by pruning instruction-irrelevant visually grounded tokens, thereby achieving token-level sparsity. 3) To ensure that compressed perception inputs can still support accurate and coherent action generation, we introduce V-L-A Coupled Attention (CAtten), which combines causal vision-language attention with bidirectional action parallel decoding. Extensive experiments on the LIBERO benchmark and real-world robotic tasks demonstrate that CogVLA achieves state-of-the-art performance with success rates of 97.4% and 70.0%, respectively, while reducing training costs by 2.5-fold and decreasing inference latency by 2.8-fold compared to OpenVLA. CogVLA is open-sourced and publicly available at https://github.com/JiuTian-VL/CogVLA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21044v1" target="_blank">MMG-Vid: Maximizing Marginal Gains at Segment-level and Token-level for Efficient Video LLMs</a></h3>
                    <p><strong>Authors:</strong> Junpeng Ma, Qizhe Zhang, Ming Lu, Zhibin Wang, Qiang Zhou, Jun Song, Shanghang Zhang</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video Large Language Models (VLLMs) excel in video understanding, but their excessive visual tokens pose a significant computational challenge for real-world applications. Current methods aim to enhance inference efficiency by visual token pruning. However, they do not consider the dynamic characteristics and temporal dependencies of video frames, as they perceive video understanding as a multi-frame task. To address these challenges, we propose MMG-Vid, a novel training-free visual token pruning framework that removes redundancy by Maximizing Marginal Gains at both segment-level and token-level. Specifically, we first divide the video into segments based on frame similarity, and then dynamically allocate the token budget for each segment to maximize the marginal gain of each segment. Subsequently, we propose a temporal-guided DPC algorithm that jointly models inter-frame uniqueness and intra-frame diversity, thereby maximizing the marginal gain of each token. By combining both stages, MMG-Vid can maximize the utilization of the limited token budget, significantly improving efficiency while maintaining strong performance. Extensive experiments demonstrate that MMG-Vid can maintain over 99.5% of the original performance, while effectively reducing 75% visual tokens and accelerating the prefilling stage by 3.9x on LLaVA-OneVision-7B. Code will be released soon.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21042v1" target="_blank">The power of binaries on stripped-envelope supernovae across metallicity: uniform progenitor parameter space and persistently low ejecta masses, but subtype diversity</a></h3>
                    <p><strong>Authors:</strong> D. Souropanis, E. Zapartas, T. Pessi, M. Briel, M. Renzo, C. P. Guti√©rrez, J. J. Andrews, S. Gossage, M. U. Kruckow, C. Liotine, P. M. Srivastava, E. Teng</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR, astro-ph.HE</p>
                    <p><strong>Summary:</strong> Stripped-envelope supernovae (SESNe) originate from massive stars that lose their envelopes through binary interactions or stellar winds. The connection between SESN subtypes and their progenitors remains poorly understood, as does the influence of initial mass, binarity, explodability, and metallicity on their evolutionary pathways, relative rates, ejecta masses, and progenitor ages. Here, we investigate these properties across a wide metallicity range (0.01-2 $Z_{\odot}$) using POSYDON, a state-of-the-art population synthesis code that incorporates detailed single- and binary-star model grids. We find that the common-envelope channel contributes less than 6% of SESNe, since unstable mass transfer is found less frequent than previously thought and rarely leads to CE survival when envelope binding energies are computed from detailed stellar models. The secondary channel accounts for less than 11%, while the vast majority of SESNe originate from primary stars in binaries undergoing stable mass-transfer episodes. These interactions maintain a largely metallicity-independent SESN parameter space, making the overall SESN rate almost insensitive to metallicity. In contrast, subtype fractions exhibit strong metallicity dependence, though their exact values remain affected by classification thresholds. The age distributions and therefore the progenitor masses of different SESN types also vary significantly with metallicity, revealing metallicity-dependent trends that can be tested observationally. Predicted SESN ejecta masses remain nearly constant across metallicity, in contrast to single-star models, and fall within observed ranges. Future transient surveys, combined with statistical environmental studies that constrain metallicity dependence, will provide decisive tests of these predictions and of the dominant role of binary interactions in shaping SESNe.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21041v1" target="_blank">Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification in MIDOG 2025</a></h3>
                    <p><strong>Authors:</strong> Guillaume Balezo, Rapha√´l Bourgade, Thomas Walter</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Atypical mitotic figures (AMFs) are markers of abnormal cell division associated with poor prognosis, yet their detection remains difficult due to low prevalence, subtle morphology, and inter-observer variability. The MIDOG 2025 challenge introduces a benchmark for AMF classification across multiple domains. In this work, we evaluate the recently published DINOv3-H+ vision transformer, pretrained on natural images, which we fine-tuned using low-rank adaptation (LoRA, 650k trainable parameters) and extensive augmentation. Despite the domain gap, DINOv3 transfers effectively to histopathology, achieving a balanced accuracy of 0.8871 on the preliminary test set. These results highlight the robustness of DINOv3 pretraining and show that, when combined with parameter-efficient fine-tuning, it provides a strong baseline for atypical mitosis classification in MIDOG 2025.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21040v1" target="_blank">FW-GAN: Frequency-Driven Handwriting Synthesis with Wave-Modulated MLP Generator</a></h3>
                    <p><strong>Authors:</strong> Huynh Tong Dang Khoa, Dang Hoai Nam, Vo Nguyen Le Duy</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Labeled handwriting data is often scarce, limiting the effectiveness of recognition systems that require diverse, style-consistent training samples. Handwriting synthesis offers a promising solution by generating artificial data to augment training. However, current methods face two major limitations. First, most are built on conventional convolutional architectures, which struggle to model long-range dependencies and complex stroke patterns. Second, they largely ignore the crucial role of frequency information, which is essential for capturing fine-grained stylistic and structural details in handwriting. To address these challenges, we propose FW-GAN, a one-shot handwriting synthesis framework that generates realistic, writer-consistent text from a single example. Our generator integrates a phase-aware Wave-MLP to better capture spatial relationships while preserving subtle stylistic cues. We further introduce a frequency-guided discriminator that leverages high-frequency components to enhance the authenticity detection of generated samples. Additionally, we introduce a novel Frequency Distribution Loss that aligns the frequency characteristics of synthetic and real handwriting, thereby enhancing visual fidelity. Experiments on Vietnamese and English handwriting datasets demonstrate that FW-GAN generates high-quality, style-consistent handwriting, making it a valuable tool for augmenting data in low-resource handwriting recognition (HTR) pipelines. Official implementation is available at https://github.com/DAIR-Group/FW-GAN</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21038v1" target="_blank">On the Theoretical Limitations of Embedding-Based Retrieval</a></h3>
                    <p><strong>Authors:</strong> Orion Weller, Michael Boratko, Iftekhar Naim, Jinhyuk Lee</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Vector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following, coding, and more. These new benchmarks push embeddings to work for any query and any notion of relevance that could be given. While prior works have pointed out theoretical limitations of vector embeddings, there is a common assumption that these difficulties are exclusively due to unrealistic queries, and those that are not can be overcome with better training data and larger models. In this work, we demonstrate that we may encounter these theoretical limitations in realistic settings with extremely simple queries. We connect known results in learning theory, showing that the number of top-k subsets of documents capable of being returned as the result of some query is limited by the dimension of the embedding. We empirically show that this holds true even if we restrict to k=2, and directly optimize on the test set with free parameterized embeddings. We then create a realistic dataset called LIMIT that stress tests models based on these theoretical results, and observe that even state-of-the-art models fail on this dataset despite the simple nature of the task. Our work shows the limits of embedding models under the existing single vector paradigm and calls for future research to develop methods that can resolve this fundamental limitation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21035v1" target="_blank">A multi-task neural network for atypical mitosis recognition under domain shift</a></h3>
                    <p><strong>Authors:</strong> Gennaro Percannella, Mattia Sarno, Francesco Tortorella, Mario Vento</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recognizing atypical mitotic figures in histopathology images allows physicians to correctly assess tumor aggressiveness. Although machine learning models could be exploited for automatically performing such a task, under domain shift these models suffer from significative performance drops. In this work, an approach based on multi-task learning is proposed for addressing this problem. By exploiting auxiliary tasks, correlated to the main classification task, the proposed approach, submitted to the track 2 of the MItosis DOmain Generalization (MIDOG) challenge, aims to aid the model to focus only on the object to classify, ignoring the domain varying background of the image. The proposed approach shows promising performance in a preliminary evaluation conducted on three distinct datasets, i.e., the MIDOG 2025 Atypical Training Set, the Ami-Br dataset, as well as the preliminary test set of the MIDOG25 challenge.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21033v1" target="_blank">Mitosis detection in domain shift scenarios: a Mamba-based approach</a></h3>
                    <p><strong>Authors:</strong> Gennaro Percannella, Mattia Sarno, Francesco Tortorella, Mario Vento</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Mitosis detection in histopathology images plays a key role in tumor assessment. Although machine learning algorithms could be exploited for aiding physicians in accurately performing such a task, these algorithms suffer from significative performance drop when evaluated on images coming from domains that are different from the training ones. In this work, we propose a Mamba-based approach for mitosis detection under domain shift, inspired by the promising performance demonstrated by Mamba in medical imaging segmentation tasks. Specifically, our approach exploits a VM-UNet architecture for carrying out the addressed task, as well as stain augmentation operations for further improving model robustness against domain shift. Our approach has been submitted to the track 1 of the MItosis DOmain Generalization (MIDOG) challenge. Preliminary experiments, conducted on the MIDOG++ dataset, show large room for improvement for the proposed method.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21032v1" target="_blank">Reusing Computation in Text-to-Image Diffusion for Efficient Generation of Image Sets</a></h3>
                    <p><strong>Authors:</strong> Dale Decatur, Thibault Groueix, Wang Yifan, Rana Hanocka, Vladimir Kim, Matheus Gadelha</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-image diffusion models enable high-quality image generation but are computationally expensive. While prior work optimizes per-inference efficiency, we explore an orthogonal approach: reducing redundancy across correlated prompts. Our method leverages the coarse-to-fine nature of diffusion models, where early denoising steps capture shared structures among similar prompts. We propose a training-free approach that clusters prompts based on semantic similarity and shares computation in early diffusion steps. Experiments show that for models trained conditioned on image embeddings, our approach significantly reduces compute cost while improving image quality. By leveraging UnClips text-to-image prior, we enhance diffusion step allocation for greater efficiency. Our method seamlessly integrates with existing pipelines, scales with prompt sets, and reduces the environmental and financial burden of large-scale text-to-image generation. Project page: https://ddecatur.github.io/hierarchical-diffusion/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21031v1" target="_blank">Introducing the Quantum Economic Advantage Online Calculator</a></h3>
                    <p><strong>Authors:</strong> Frederick Mejia, Hans Gundlach, Jayson Lynch, Carl Dukatz, Andrew Lucas, Eleanor Crane, Prashant Shukla, Neil Thompson</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph, 81P68, 68Q12, 68W40, 91B55, F.1.2; J.2</p>
                    <p><strong>Summary:</strong> Developing a systematic view of where quantum computers will outperform classical ones is important for researchers, policy makers and business leaders. But developing such a view is challenging because quantum advantage analyses depend not only on algorithm properties, but also on a host of technical characteristics (error correction, gate speeds, etc.). Because various analyses make different assumptions about these technical characteristics, it can be challenging to make comparisons across them. In this paper, we introduce an open-access web-tool designed to make such comparisons easy. Built on the framework introduced by Choi, Moses, and Thompson (2023), it calculates when quantum systems will outperform classical computers for a given algorithmic problem. These estimates can be easily updated based on various assumptions for error correction, overhead, and connectivity. Different hardware roadmaps can also be used and algorithm running times can be customized to particular applications. It can currently be accessed at https://futuretech.mit.edu/quantum-economic-advantage-calculator. This integrated prediction tool also allows us to explore which technical factors are most important for quantum ``economic advantage (outperforming on a cost-equivalent basis). Overall, we find that for some algorithms (e.g. Shors) the timing of advantage is quite robust, whereas for others (e.g. Grovers) it is contingent, with numerous technical characteristics substantially impacting these dates. In the paper, we discuss both why this occurs and what we can learn from it.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21024v1" target="_blank">An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs</a></h3>
                    <p><strong>Authors:</strong> Mathieu Bourdin, Anas Neumann, Thomas Paviot, Robert Pellerin, Samir Lamouri</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to mitigate the limitations of Large Language Models (LLMs), such as hallucinations and outdated knowledge. However, deploying RAG-based tools in Small and Medium Enterprises (SMEs) remains a challenge due to their limited resources and lack of expertise in natural language processing (NLP). This paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a structured, agile method designed to facilitate the deployment of RAG systems in industrial SME contexts. EASI-RAG is based on method engineering principles and comprises well-defined roles, activities, and techniques. The method was validated through a real-world case study in an environmental testing laboratory, where a RAG tool was implemented to answer operators queries using data extracted from operational procedures. The system was deployed in under a month by a team with no prior RAG experience and was later iteratively improved based on user feedback. Results demonstrate that EASI-RAG supports fast implementation, high user adoption, delivers accurate answers, and enhances the reliability of underlying data. This work highlights the potential of RAG deployment in industrial SMEs. Future works include the need for generalization across diverse use cases and further integration with fine-tuned models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21023v1" target="_blank">Topotactic phase transition in epitaxial La0.7Sr0.3MnO3-Œ¥ films induced by oxygen getter assisted thermal annealing</a></h3>
                    <p><strong>Authors:</strong> Chenyang Yin, Lei Cao, Xue Bai, Suqin He, Hengbo Zhang, Tomas Duchon, Felix Gunkel, Yunxia Zhou, Mao Wang, Anton Kaus, Janghyun Jo, Rafal E. Dunin-Borkowski, Shengqiang Zhou, Thomas Br√ºckel, Oleg Petracic</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Oxygen vacancies play a crucial role in controlling the physical properties of complex oxides. In La0.7Sr0.3MnO3-{\delta}, the topotactic phase transition from Perovskite (PV) to Brownmillerite (BM) can be triggered e.g. via oxygen removal during thermal annealing. Here we report on a very efficient thermal vacuum annealing method using aluminum as an oxygen getter material. The topotactic phase transition is characterized by X-ray Diffraction which confirms a successful transition from PV to BM in La0.7Sr0.3MnO3-{\delta} thin films grown via physical vapor deposition. The efficiency of this method is confirmed using La0.7Sr0.3MnO3-{\delta} micron-sized bulk powder. The accompanying transition from the original Ferromagnetic (FM) to an Antiferromagnetic (AF) state and the simultaneous transition from a metallic to an insulating state is characterized using Superconducting Quantum Interference Device (SQUID)-magnetometry and Alternating Current (AC) resistivity measurements, respectively. The near surface manganese oxidation states are probed by synchrotron X-ray Absorption Spectroscopy. Moreover, X-ray Reflectivity, Atomic Force Microscopy and Scanning Transmission Electron Microscopy reveal surface segregation and cation redistribution during the oxygen getter assisted annealing process.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21020v1" target="_blank">QIP $ \subseteq $ AM(2QCFA)</a></h3>
                    <p><strong>Authors:</strong> Abuzer Yakaryƒ±lmaz</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.CC, cs.FL</p>
                    <p><strong>Summary:</strong> The class of languages having polynomial-time classical or quantum interactive proof systems ($\mathsf{IP}$ or $\mathsf{QIP}$, respectively) is identical to $\mathsf{PSPACE}$. We show that $\mathsf{PSPACE}$ (and so $\mathsf{QIP}$) is subset of $\mathsf{AM(2QCFA)}$, the class of languages having Arthur-Merlin proof systems where the verifiers are two-way finite automata with quantum and classical states (2QCFAs) communicating with the provers classically. Our protocols use only rational-valued quantum transitions and run in double-exponential expected time. Moreover, the member strings are accepted with probability 1 (i.e., perfect-completeness).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21019v1" target="_blank">POSE: Phased One-Step Adversarial Equilibrium for Video Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Jiaxiang Cheng, Bing Ma, Xuhua Ren, Hongyi Jin, Kai Yu, Peng Zhang, Wenyue Li, Yuan Zhou, Tianxiang Zheng, Qinglin Lu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The field of video diffusion generation faces critical bottlenecks in sampling efficiency, especially for large-scale models and long sequences. Existing video acceleration methods adopt image-based techniques but suffer from fundamental limitations: they neither model the temporal coherence of video frames nor provide single-step distillation for large-scale video models. To bridge this gap, we propose POSE (Phased One-Step Equilibrium), a distillation framework that reduces the sampling steps of large-scale video diffusion models, enabling the generation of high-quality videos in a single step. POSE employs a carefully designed two-phase process to distill video models:(i) stability priming: a warm-up mechanism to stabilize adversarial distillation that adapts the high-quality trajectory of the one-step generator from high to low signal-to-noise ratio regimes, optimizing the video quality of single-step mappings near the endpoints of flow trajectories. (ii) unified adversarial equilibrium: a flexible self-adversarial distillation mechanism that promotes stable single-step adversarial training towards a Nash equilibrium within the Gaussian noise space, generating realistic single-step videos close to real videos. For conditional video generation, we propose (iii) conditional adversarial consistency, a method to improve both semantic consistency and frame consistency between conditional frames and generated frames. Comprehensive experiments demonstrate that POSE outperforms other acceleration methods on VBench-I2V by average 7.15% in semantic alignment, temporal conference and frame quality, reducing the latency of the pre-trained model by 100$\times$, from 1000 seconds to 10 seconds, while maintaining competitive performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21015v1" target="_blank">Investigating the Performance of Adaptive Optics on Different Bases of Spatial Modes in Turbulent Channels</a></h3>
                    <p><strong>Authors:</strong> Rojan Abolhassani, Lukas Scarfe, Francesco Di Colandrea, Alessio DErrico, Khabat Heshami, Ebrahim Karimi</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum key distribution (QKD) allows secure key exchange based on the principles of quantum mechanics, with higher-dimensional photonic states offering enhanced channel capacity and resilience to noise. Free-space QKD is crucial for global networks where fibres are impractical, but atmospheric turbulence introduces severe states distortions, particularly for spatial modes. Adaptive optics (AO) provides a pathway to correct these errors, though its effectiveness depends on the encoding basis. Here, we experimentally evaluate a high-speed AO system for orbital angular momentum (OAM) modes, mutually unbiased bases (MUB), and symmetric, informationally complete, positive operator-valued measures (SIC-POVM) up to dimension $d=8$ in a turbulent free-space channel. While OAM states are strongly distorted, their cylindrical symmetry makes them optimally corrected by AO, yielding error rates below QKD security thresholds. MUB and SIC-POVM exhibit greater intrinsic robustness to turbulence but are less precisely corrected, though their performance remains within protocol tolerances. These results establish AO as a key enabler of secure, high-dimensional QKD and highlight the role of basis choice in optimizing resilience and correction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21013v1" target="_blank">Bohr--Sommerfeld rules for systems</a></h3>
                    <p><strong>Authors:</strong> Simon Becker, Setsuro Fujii√©, Jens Wittsten</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> math-ph, cond-mat.mes-hall, math.AP, math.MP, math.SP, quant-ph</p>
                    <p><strong>Summary:</strong> We present a complete, self-contained formulation of the Bohr--Sommerfeld quantization rule for a semiclassical self-adjoint $2 \times 2$ system on the real line, arising from a simple closed curve in phase space. We focus on the case where the principal symbol exhibits eigenvalue crossings within the domain enclosed by the curve -- a situation commonly encountered in Dirac-type operators. Building on earlier work on scalar Bohr--Sommerfeld rules and semiclassical treatments of the Harper operator near rational flux quanta, we identify additional contributions to the quantization condition, and derive concise expressions for general self-adjoint $2 \times 2$ systems. The resulting formulas give explicit geometric phase corrections and clarify when these phases take quantized values.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21012v1" target="_blank">Spectral density characteristics of self-organized structuring in phase-synchronized oscillator ensembles</a></h3>
                    <p><strong>Authors:</strong> Magnus F Ivarsen</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph, nlin.CD</p>
                    <p><strong>Summary:</strong> Self-organized turbulence represents a way for structuring in nature to arise through sheer complexity rather than through linear instability theory. Simulating ensembles of oscillators that undergo phase synchronization through a propagating Kuramoto-interaction field, we present the spectral characteristics of spontaneous, self-organized structures of locally coupled oscillators. We demonstrate that the spectral density of emergent structures can exhibit universal scaling laws, in line with expectations from nature, indicating that observed statistical outcomes of complex physical interactions can be achieved through a more general principle of self-organization. We suggest that spontaneously generated structures may provide nuance to the reigning reductionist explanations for the observed structure in coupled systems of astrophysical and geophysical plasmas.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21010v1" target="_blank">ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering</a></h3>
                    <p><strong>Authors:</strong> Paritosh Parmar, Eric Peh, Basura Fernando</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Existing Causal-Why Video Question Answering (VideoQA) models often struggle with higher-order reasoning, relying on opaque, monolithic pipelines that entangle video understanding, causal inference, and answer generation. These black-box approaches offer limited interpretability and tend to depend on shallow heuristics. We propose a novel, modular framework that explicitly decouples causal reasoning from answer generation, introducing natural language causal chains as interpretable intermediate representations. Inspired by human cognitive models, these structured cause-effect sequences bridge low-level video content with high-level causal reasoning, enabling transparent and logically coherent inference. Our two-stage architecture comprises a Causal Chain Extractor (CCE) that generates causal chains from video-question pairs, and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in these chains. To address the lack of annotated reasoning traces, we introduce a scalable method for generating high-quality causal chains from existing datasets using large language models. We also propose CauCo, a new evaluation metric for causality-oriented captioning. Experiments on three large-scale benchmarks demonstrate that our approach not only outperforms state-of-the-art models, but also yields substantial gains in explainability, user trust, and generalization -- positioning the CCE as a reusable causal reasoning engine across diverse domains. Project page: https://paritoshparmar.github.io/chainreaction/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21005v1" target="_blank">Measuring Ransomware Lateral Movement Susceptibility via Privilege-Weighted Adjacency Matrix Exponentiation</a></h3>
                    <p><strong>Authors:</strong> Satyam Tyagi, Ganesh Murugesan</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.DM, cs.CR, math.CO, 05C50, 05C90, 94C15, G.2.2</p>
                    <p><strong>Summary:</strong> Ransomware impact hinges on how easily an intruder can move laterally and spread to the maximum number of assets. We present a graph-theoretic method to measure lateral-movement susceptibility and estimate blast radius. We build a directed multigraph where vertices represent assets and edges represent reachable services (e.g., RDP/SSH) between them. We model lateral movement as a probabilistic process using a pivot potential factor $\pi(s)$ for each service. This allows us to iteratively compute a $K$-hop compromise probability matrix that captures how compromise propagates through the network. Metrics derived from this model include: (1) Lateral-Movement Susceptibility (LMS$_K$): the average probability of a successful lateral movement between any two assets (0-1 scale); and (2) Blast-Radius Estimate (BRE$_K$): the expected percentage of assets compromised in an average attack scenario. Interactive control (SSH 22, RDP 3389) gets higher $\pi(s)$ than app-only ports (MySQL 3306, MSSQL 1433), which seldom enable pivoting without an RCE. Across anonymized enterprise snapshots, pruning high-$\pi(s)$ edges yields the largest LMS$_K$/BRE$_K$ drop, aligning with CISA guidance, MITRE ATT\CK (TA0008: Lateral Movement), and NIST SP~800-207. The framework evaluates (micro)segmentation and helps prioritize controls that reduce lateral movement susceptibility and shrink blast radius.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21004v1" target="_blank">Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution</a></h3>
                    <p><strong>Authors:</strong> Chen Chen, Yuchen Sun, Jiaxin Gao, Xueluan Gong, Qian Wang, Ziyao Wang, Yongsen Zheng, Kwok-Yan Lam</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have seen significant advancements, achieving superior performance in various Natural Language Processing (NLP) tasks. However, they remain vulnerable to backdoor attacks, where models behave normally for standard queries but generate harmful responses or unintended output when specific triggers are activated. Existing backdoor defenses either lack comprehensiveness, focusing on narrow trigger settings, detection-only mechanisms, and limited domains, or fail to withstand advanced scenarios like model-editing-based, multi-trigger, and triggerless attacks. In this paper, we present LETHE, a novel method to eliminate backdoor behaviors from LLMs through knowledge dilution using both internal and external mechanisms. Internally, LETHE leverages a lightweight dataset to train a clean model, which is then merged with the backdoored model to neutralize malicious behaviors by diluting the backdoor impact within the models parametric memory. Externally, LETHE incorporates benign and semantically relevant evidence into the prompt to distract LLMs attention from backdoor features. Experimental results on classification and generation domains across 5 widely used LLMs demonstrate that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor attacks. LETHE reduces the attack success rate of advanced backdoor attacks by up to 98% while maintaining model utility. Furthermore, LETHE has proven to be cost-efficient and robust against adaptive backdoor attacks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21002v1" target="_blank">Spectral Gaps with Quantum Counting Queries and Oblivious State Preparation</a></h3>
                    <p><strong>Authors:</strong> Almudena Carrera Vazquez, Aleksandros Sobczyk</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.DS, cs.NA, math.NA</p>
                    <p><strong>Summary:</strong> Approximating the $k$-th spectral gap $\Delta_k=|\lambda_k-\lambda_{k+1}|$ and the corresponding midpoint $\mu_k=\frac{\lambda_k+\lambda_{k+1}}{2}$ of an $N\times N$ Hermitian matrix with eigenvalues $\lambda_1\geq\lambda_2\geq\ldots\geq\lambda_N$, is an important special case of the eigenproblem with numerous applications in science and engineering. In this work, we present a quantum algorithm which approximates these values up to additive error $\epsilon\Delta_k$ using a logarithmic number of qubits. Notably, in the QRAM model, its total complexity (queries and gates) is bounded by $O\left( \frac{N^2}{\epsilon^{2}\Delta_k^2}\mathrm{polylog}\left( N,\frac{1}{\Delta_k},\frac{1}{\epsilon},\frac{1}{\delta}\right)\right)$, where $\epsilon,\delta\in(0,1)$ are the accuracy and the success probability, respectively. For large gaps $\Delta_k$, this provides a speed-up against the best-known complexities of classical algorithms, namely, $O \left( N^{\omega}\mathrm{polylog} \left( N,\frac{1}{\Delta_k},\frac{1}{\epsilon}\right)\right)$, where $\omega\lesssim 2.371$ is the matrix multiplication exponent. A key technical step in the analysis is the preparation of a suitable random initial state, which ultimately allows us to efficiently count the number of eigenvalues that are smaller than a threshold, while maintaining a quadratic complexity in $N$. In the black-box access model, we also report an $\Omega(N^2)$ query lower bound for deciding the existence of a spectral gap in a binary (albeit non-symmetric) matrix.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21001v1" target="_blank">Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees</a></h3>
                    <p><strong>Authors:</strong> Yaniv Hassidof, Tom Jurgenson, Kiril Solovey</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.RO</p>
                    <p><strong>Summary:</strong> Kinodynamic motion planning is concerned with computing collision-free trajectories while abiding by the robots dynamic constraints. This critical problem is often tackled using sampling-based planners (SBPs) that explore the robots high-dimensional state space by constructing a search tree via action propagations. Although SBPs can offer global guarantees on completeness and solution quality, their performance is often hindered by slow exploration due to uninformed action sampling. Learning-based approaches can yield significantly faster runtimes, yet they fail to generalize to out-of-distribution (OOD) scenarios and lack critical guarantees, e.g., safety, thus limiting their deployment on physical robots. We present Diffusion Tree (DiTree): a \emph{provably-generalizable} framework leveraging diffusion policies (DPs) as informed samplers to efficiently guide state-space search within SBPs. DiTree combines DPs ability to model complex distributions of expert trajectories, conditioned on local observations, with the completeness of SBPs to yield \emph{provably-safe} solutions within a few action propagation iterations for complex dynamical systems. We demonstrate DiTrees power with an implementation combining the popular RRT planner with a DP action sampler trained on a \emph{single environment}. In comprehensive evaluations on OOD scenarios, % DiTree has comparable runtimes to a standalone DP (3x faster than classical SBPs), while improving the average success rate over DP and SBPs. DiTree is on average 3x faster than classical SBPs, and outperforms all other approaches by achieving roughly 30\% higher success rate. Project webpage: https://sites.google.com/view/ditree.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.21000v1" target="_blank">Quantum melting a Wigner crystal into Hall liquids</a></h3>
                    <p><strong>Authors:</strong> Aidan P. Reddy, Liang Fu</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Recent experiments have shown that, counterintuitively, applying a magnetic field to a Wigner crystal can induce quantum Hall effects. In this work, using variational Monte Carlo, we show that magnetic fields can melt zero-field Wigner crystals into integer quantum Hall liquids. This melting originates from quantum oscillations in the liquids ground state energy, which develops downward cusps at integer filling factors due to incompressibility. Our calculations establish a range of densities in which this quantum melting transition occurs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20998v1" target="_blank">First-Order Viscous Relativistic Hydrodynamics on the Two-Sphere</a></h3>
                    <p><strong>Authors:</strong> Lennox S. Keeble, Frans Pretorius</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> A few years ago, Bemfica, Disconzi, Noronha, and Kovtun (BDNK) formulated the first causal, stable, strongly hyperbolic, and locally well-posed theory of first-order viscous relativistic hydrodynamics. Since their inception, there have been several numerical and analytic studies of the BDNK equations which have revealed their promise in modeling relativistic flows when viscous, first-order corrections to ideal hydrodynamics are important. In this paper, we present numerical solutions to the BDNK equations for a $4$D conformal fluid in Minkowski spacetime constrained to the surface of a geometric sphere. We numerically solve the underlying equations of motion by use of finite difference methods applied in cubed-sphere coordinates -- a multi-block grid structure which regularly and continuously covers the surface of a sphere. We present three test cases of our code: linearized fluid perturbations of equilibrium states, a smooth, stationary initial Gaussian pulse of energy density, and Kelvin-Helmholtz-unstable initial data. In the Gaussian test case with sufficiently large entropy-normalized shear viscosity, the flow, though initialized in equilibrium, dynamically diverges away from equilibrium and the regime of validity of first-order hydrodynamics as very steep gradients form in the solution, causing convergence to be lost in the numerical simulation. This behavior persists at all grid resolutions we have considered, and also occurs at much higher resolutions in simulations of planar-symmetric ($1+1$)D conformal flows. These solutions provide numerical evidence that singularities in solutions to the BDNK equations can form in finite time from smooth initial data. The numerical methods we employ on the two-sphere can be readily extended to include variations in the radial direction, allowing for full ($3+1$)D simulations of the BDNK equations in astrophysical applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20995v1" target="_blank">Bottomonium transport in a strongly coupled quark-gluon plasma</a></h3>
                    <p><strong>Authors:</strong> Biaogang Wu, Ralf Rapp</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> nucl-th</p>
                    <p><strong>Summary:</strong> Quarkonium production in high-energy heavy-ion collisions remains a key probe of the quark-gluon plasma formed in these reactions, but the development of a fully integrated nonperturbative approach remains a challenge. Toward this end, we set up a semiclassical transport approach that combines nonperturbative reaction rates rooted in lattice-constrained $T$-matrix interactions with a viscous hydrodynamic medium evolution. Bottomonium suppression is computed along trajectories in the hydrodynamic evolution while regeneration is evaluated via a rate equation extended to a medium with spatial gradients. The much larger reaction rates compared to previous calculations markedly enhance both dissociation and regeneration processes. This, in particular, requires a reliable assessment of bottomonium equilibrium limits and of the non-thermal distributions of the bottom quarks transported through the expanding medium. Within current uncertainties our approach can describe the centrality dependence of bottomonium yields measured in Pb-Pb ($\sqrt{s_{_{\rm NN}}}$=5.02\,TeV) collisions at the LHC, while discrepancies are found at large transverse momenta.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20994v1" target="_blank">GW emission and relativistic dynamical friction in intermediate mass ratio inspirals</a></h3>
                    <p><strong>Authors:</strong> P. Di Cintio, G. Bertone, C. Chiari, T. K. Karydas, B. J. Kavanagh, M. Pasquato, A. A. Trani</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA, astro-ph.HE, gr-qc</p>
                    <p><strong>Summary:</strong> We present a set of preliminary simulations of intermediate mass ratio inspirals (IMRIs) inside dark matter (DM) spikes accounting for post-Newtonian corrections the interaction between the two black holes up to the order 2.5 in $c^2$, as well as relativistic corrections to the dynamical friction (DF) force exerted by the DM distribution. We find that, incorporating relativity reduces of a factor $1/2$ the inspiral time, for equivalent initial orbital parameters, with respect to the purely classical estimates. Vice versa, neglecting the DF of the spike systematically yields longer inspiral times.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20993v1" target="_blank">Unstable mode and the Unruh-DeWitt detector</a></h3>
                    <p><strong>Authors:</strong> Bruno S. Felipe, Jo√£o P. M. Pitelli</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> We investigate the quantization of a single unstable mode in a real scalar field subject to a Robin boundary condition in (1+1)-dimensional half-Minkowski spacetime. The instability arises from an imaginary frequency mode - analogous to that of the inverted harmonic oscillator - requiring the rigged Hilbert space formalism for consistent quantization. Within this framework, the unstable mode is naturally described as a well-defined decaying (or growing) quantum state with a characteristic mean lifetime. We investigate its physical consequences via the response of an Unruh-DeWitt detector along static, inertial, and uniformly accelerated trajectories. For static and inertial observers, the detector response exhibits a Breit-Wigner resonance profile, with a decay width determined by the unstable frequency and a Doppler factor. In the Neumann limit, infrared divergences emerge from arbitrarily low-frequency modes. Interestingly, for accelerated detectors, the response acquires a nontrivial dependence on acceleration, and the Neumann limit yields a finite, oscillatory signal rather than a divergence, suggesting that acceleration can act as an effective infrared regulator.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20992v1" target="_blank">How many qubits does a machine learning problem require?</a></h3>
                    <p><strong>Authors:</strong> Sydney Leither, Michael Kubal, Sonika Johri</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> For a machine learning paradigm to be generally applicable, it should have the property of universal approximation, that is, it should be able to approximate any target function to any desired degree of accuracy. In variational quantum machine learning, the class of functions that can be learned depend on both the data encoding scheme as well as the architecture of the optimizable part of the model. Here, we show that the property of universal approximation is constructively and efficiently realized by the recently proposed bit-bit encoding scheme. Further, we show that this construction allows us to calculate the number of qubits required to solve a learning problem on a dataset to a target accuracy, giving rise to the first resource estimation framework for variational quantum machine learning. We apply bit-bit encoding to a number of medium-sized datasets from OpenML and find that they require only $20$ qubits on average for encoding. Further, we extend the basic bit-bit encoding scheme to one that can handle batching very large datasets. As a demonstration, we apply this new scheme to the giga-scale transcriptomic Tahoe-100M dataset, concluding that the number of qubits required for encoding it lies beyond classical simulation capabilities. Remarkably, we find that the number of qubits does not necessarily increase with the number of features of a dataset, but may sometimes even decrease.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20991v1" target="_blank">ExpertSim: Fast Particle Detector Simulation Using Mixture-of-Generative-Experts</a></h3>
                    <p><strong>Authors:</strong> Patryk Bƒôdkowski, Jan Dubi≈Ñski, Filip Szatkowski, Kamil Deja, Przemys≈Çaw Rokita, Tomasz Trzci≈Ñski</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Simulating detector responses is a crucial part of understanding the inner workings of particle collisions in the Large Hadron Collider at CERN. Such simulations are currently performed with statistical Monte Carlo methods, which are computationally expensive and put a significant strain on CERNs computational grid. Therefore, recent proposals advocate for generative machine learning methods to enable more efficient simulations. However, the distribution of the data varies significantly across the simulations, which is hard to capture with out-of-the-box methods. In this study, we present ExpertSim - a deep learning simulation approach tailored for the Zero Degree Calorimeter in the ALICE experiment. Our method utilizes a Mixture-of-Generative-Experts architecture, where each expert specializes in simulating a different subset of the data. This allows for a more precise and efficient generation process, as each expert focuses on a specific aspect of the calorimeter response. ExpertSim not only improves accuracy, but also provides a significant speedup compared to the traditional Monte-Carlo methods, offering a promising solution for high-efficiency detector simulations in particle physics experiments at CERN. We make the code available at https://github.com/patrick-bedkowski/expertsim-mix-of-generative-experts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20990v1" target="_blank">A Correction for the Paper Symplectic geometry mode decomposition and its application to rotating machinery compound fault diagnosis</a></h3>
                    <p><strong>Authors:</strong> Hong-Yan Zhang, Haoting Liu, Rui-Jia Lin, Yu Zhou</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> The symplectic geometry mode decomposition (SGMD) is a powerful method for decomposing time series, which is based on the diagonal averaging principle (DAP) inherited from the singular spectrum analysis (SSA). Although the authors of SGMD method generalized the form of the trajectory matrix in SSA, the DAP is not updated simultaneously. In this work, we pointed out the limitations of the SGMD method and fixed the bugs with the pulling back theorem for computing the given component of time series from the corresponding component of trajectory matrix.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20989v1" target="_blank">Microscopic and collective signatures of feature learning in neural networks</a></h3>
                    <p><strong>Authors:</strong> Andrea Corti, Rosalba Pacelli, Pietro Rotondo, Marco Gherardi</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cond-mat.dis-nn, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> Feature extraction - the ability to identify relevant properties of data - is a key factor underlying the success of deep learning. Yet, it has proved difficult to elucidate its nature within existing predictive theories, to the extent that there is no consensus on the very definition of feature learning. A promising hint in this direction comes from previous phenomenological observations of quasi-universal aspects in the training dynamics of neural networks, displayed by simple properties of feature geometry. We address this problem within a statistical-mechanics framework for Bayesian learning in one hidden layer neural networks with standard parameterization. Analytical computations in the proportional limit (when both the network width and the size of the training set are large) can quantify fingerprints of feature learning, both collective ones (related to manifold geometry) and microscopic ones (related to the weights). In particular, (i) the distance between different class manifolds in feature space is a nonmonotonic function of the temperature, which we interpret as the equilibrium counterpart of a phenomenon observed under gradient descent (GD) dynamics, and (ii) the microscopic learnable parameters in the network undergo a finite data-dependent displacement with respect to the infinite-width limit, and develop correlations. These results indicate that nontrivial feature learning is at play in a regime where the posterior predictive distribution is that of Gaussian process regression with a trivially rescaled prior.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20987v1" target="_blank">Webly-Supervised Image Manipulation Localization via Category-Aware Auto-Annotation</a></h3>
                    <p><strong>Authors:</strong> Chenfan Qu, Yiwu Zhong, Bin Li, Lianwen Jin</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Images manipulated using image editing tools can mislead viewers and pose significant risks to social security. However, accurately localizing the manipulated regions within an image remains a challenging problem. One of the main barriers in this area is the high cost of data acquisition and the severe lack of high-quality annotated datasets. To address this challenge, we introduce novel methods that mitigate data scarcity by leveraging readily available web data. We utilize a large collection of manually forged images from the web, as well as automatically generated annotations derived from a simpler auxiliary task, constrained image manipulation localization. Specifically, we introduce a new paradigm CAAAv2, which automatically and accurately annotates manipulated regions at the pixel level. To further improve annotation quality, we propose a novel metric, QES, which filters out unreliable annotations. Through CAAA v2 and QES, we construct MIMLv2, a large-scale, diverse, and high-quality dataset containing 246,212 manually forged images with pixel-level mask annotations. This is over 120x larger than existing handcrafted datasets like IMD20. Additionally, we introduce Object Jitter, a technique that further enhances model training by generating high-quality manipulation artifacts. Building on these advances, we develop a new model, Web-IML, designed to effectively leverage web-scale supervision for the image manipulation localization task. Extensive experiments demonstrate that our approach substantially alleviates the data scarcity problem and significantly improves the performance of various models on multiple real-world forgery benchmarks. With the proposed web supervision, Web-IML achieves a striking performance gain of 31% and surpasses previous SOTA TruFor by 24.1 average IoU points. The dataset and code will be made publicly available at https://github.com/qcf-568/MIML.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20981v1" target="_blank">ActLoc: Learning to Localize on the Move via Active Viewpoint Selection</a></h3>
                    <p><strong>Authors:</strong> Jiajie Li, Boyang Sun, Luca Di Giammarino, Hermann Blum, Marc Pollefeys</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Reliable localization is critical for robot navigation, yet most existing systems implicitly assume that all viewing directions at a location are equally informative. In practice, localization becomes unreliable when the robot observes unmapped, ambiguous, or uninformative regions. To address this, we present ActLoc, an active viewpoint-aware planning framework for enhancing localization accuracy for general robot navigation tasks. At its core, ActLoc employs a largescale trained attention-based model for viewpoint selection. The model encodes a metric map and the camera poses used during map construction, and predicts localization accuracy across yaw and pitch directions at arbitrary 3D locations. These per-point accuracy distributions are incorporated into a path planner, enabling the robot to actively select camera orientations that maximize localization robustness while respecting task and motion constraints. ActLoc achieves stateof-the-art results on single-viewpoint selection and generalizes effectively to fulltrajectory planning. Its modular design makes it readily applicable to diverse robot navigation and inspection tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20980v1" target="_blank">On Secrecy Capacity of Binary Beampointing Channels with Block Memory and Feedback</a></h3>
                    <p><strong>Authors:</strong> Siyao Li, Mingzhe Chen, Shuangyang Li, Giuseppe Caire</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> This paper investigates the secrecy capacity of the binary beampointing (BBP) channel with block memory and feedback, a simplified yet insightful model for millimeter-wave (mmWave) systems with beamformed transmissions and backscatter feedback. We consider a system where a legitimate receiver and a passive eavesdropper experience independent and uniformly distributed angular directions over transmission blocks, with the base station receiving noiseless, unit-delayed feedback from both, under the per-symbol input cost constraints. We establish a closed-form upper bound on the secrecy capacity, which is based on the main channel between the base station and the legitimate receiver. Moreover, we propose a joint communication and adaptive sensing (JCAS) scheme and derive its achievable secrecy rate. Simulation results show that the gap between the inner and outer bounds narrows as the number of block length increases. This reveals the efficiency of this JCAS scheme, which strategically leverages feedback to balance the demands of sensing the legitimate user and preventing information leakage to the eavesdropper.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20978v1" target="_blank">Efficient Neuro-Symbolic Learning of Constraints and Objective</a></h3>
                    <p><strong>Authors:</strong> Marianne Defresne, Romain Gambardella, Sophie Barbe, Thomas Schiex</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LO, cs.SC</p>
                    <p><strong>Summary:</strong> In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs, a task that Large Language Models seem to struggle with. Objectives: We introduce a differentiable neuro-symbolic architecture and a loss function dedicated to learning how to solve NP-hard reasoning problems. Methods: Our new probabilistic loss allows for learning both the constraints and the objective, thus delivering a complete model that can be scrutinized and completed with side constraints. By pushing the combinatorial solver out of the training loop, our architecture also offers scalable training while exact inference gives access to maximum accuracy. Results: We empirically show that it can efficiently learn how to solve NP-hard reasoning problems from natural inputs. On three variants of the Sudoku benchmark -- symbolic, visual, and many-solution --, our approach requires a fraction of training time of other hybrid methods. On a visual Min-Cut/Max-cut task, it optimizes the regret better than a Decision-Focused-Learning regret-dedicated loss. Finally, it efficiently learns the energy optimization formulation of the large real-world problem of designing proteins.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.20975v1" target="_blank">Quenched Quantum Feature Maps</a></h3>
                    <p><strong>Authors:</strong> Anton Simen, Carlos Flores-Garrigos, Murilo Henrique De Oliveira, Gabriel Dario Alvarado Barrios, Juan F. R. Hern√°ndez, Qi Zhang, Alejandro Gomez Cadavid, Yolanda Vives-Gilabert, Jos√© D. Mart√≠n-Guerrero, Enrique Solano, Narendra N. Hegade, Archismita Dalal</p>
                    <p><strong>Published:</strong> 8/28/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We propose a quantum feature mapping technique that leverages the quench dynamics of a quantum spin glass to extract complex data patterns at the quantum-advantage level for academic and industrial applications. We demonstrate that encoding a dataset information into disordered quantum many-body spin-glass problems, followed by a nonadiabatic evolution and feature extraction via measurements of expectation values, significantly enhances machine learning (ML) models. By analyzing the performance of our protocol over a range of evolution times, we empirically show that ML models benefit most from feature representations obtained in the fast coherent regime of a quantum annealer, particularly near the critical point of the quantum dynamics. We demonstrate the generalization of our technique by benchmarking on multiple high-dimensional datasets, involving over a hundred features, in applications including drug discovery and medical diagnostics. Moreover, we compare against a comprehensive suite of state-of-the-art classical ML models and show that our quantum feature maps can enhance the performance metrics of the baseline classical models up to 210%. Our work presents the first quantum ML demonstrations at the quantum-advantage level, bridging the gap between quantum supremacy and useful real-world academic and industrial applications.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

