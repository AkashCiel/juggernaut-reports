
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-09-09<br>
            <strong>Topics:</strong> ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 100
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <h2>ai alignment research</h2>
<p>Certainly! Heres a structured summary of the key findings from the research papers related to AI alignment:</p>
<h3>Most Important Trends</h3>
<ol>
<li><strong>Integration of Vision, Language, and Action</strong>: Models like F1 are advancing the field by integrating visual foresight into decision-making, enhancing robustness and generalization in dynamic environments.</li>
<li><strong>Diffusion Models in Language Processing</strong>: TraceRL and Direct-Align demonstrate improved performance in language models through diffusion-based frameworks and alignment with human preferences.</li>
<li><strong>AI Alignment and Human Preferences</strong>: Studies are focusing on aligning AI outputs with fine-grained human preferences to improve realism and ethical alignment.</li>
<li><strong>Trustworthiness in AI Systems</strong>: Evaluating AI models against culturally informed benchmarks, such as the EPT metric for Persian language models, highlights the ongoing efforts to ensure AI systems respect cultural and ethical values.</li>
<li><strong>Exploration of Model Interpretability</strong>: Research is increasingly focusing on understanding and improving the interpretability of AI models, particularly in complex systems like galaxy clusters and cybersecurity.</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><strong>F1 Models Integration of Visual Foresight</strong>: By synthesizing goal-conditioned visual foresight, F1 model significantly outperforms existing VLA models, offering a more robust framework for task execution in complex environments.</li>
<li><strong>TraceRLs Trajectory-Aware Framework</strong>: The introduction of a trajectory-aware reinforcement learning framework in language models has led to state-of-the-art performance in tasks like mathematical reasoning.</li>
<li><strong>Direct Preference Optimization in Diffusion Models</strong>: Direct-Align offers a novel method for improving model outputs by directly aligning them with human preferences, enhancing aesthetic quality and realism.</li>
<li><strong>Paper2Agent for AI Knowledge Dissemination</strong>: This framework transforms static research papers into interactive AI agents, potentially revolutionizing how scientific knowledge is shared and utilized.</li>
<li><strong>Efficient Pruning Techniques with COMPACT</strong>: The COMPACT method introduces an efficient pruning technique that maintains standard transformer architecture, reducing memory usage while maintaining performance.</li>
</ol>
<h3>Implications</h3>
<ol>
<li><strong>Enhanced AI Robustness and Generalization</strong>: The integration of foresight and preference alignment in AI models could lead to more reliable and adaptable AI systems capable of operating in dynamic and complex settings.</li>
<li><strong>Improved Trust and Ethical Standards</strong>: Efforts to align AI systems with human preferences and cultural values could lead to more socially responsible AI technologies, crucial for broader acceptance and trust.</li>
<li><strong>Advancements in AI Safety</strong>: The development of frameworks like RÂ²AI for resistant and resilient AI systems highlights a proactive approach to maintaining AI safety in evolving environments.</li>
<li><strong>Potential for Knowledge Sharing in AI</strong>: Transforming research papers into interactive agents could significantly reduce barriers to scientific knowledge dissemination, facilitating faster innovation and application.</li>
<li><strong>Efficient Resource Usage in AI Models</strong>: Techniques like COMPACTs pruning approach demonstrate the potential for AI systems to become more resource-efficient, enabling broader deployment across various applications.</li>
</ol>
<p>These papers contribute to the broader field of AI alignment by addressing key challenges related to model generalization, ethical alignment, interpretability, and efficient resource usage, paving the way for more robust and trustworthy AI systems.</p>
<p><em>Based on 50 research papers</em></p>

<h2>quantum computing</h2>
<p>The provided research papers cover a variety of fields and do not focus specifically on quantum computing. However, I will summarize the key trends, breakthroughs, and implications from these papers as they relate to broader themes in computational research, with some potential connections to quantum computing where applicable.</p>
<h3>Most Important Trends</h3>
<ul>
<li><strong>Efficiency in Computation</strong>: Across the papers, there is a clear trend toward improving computational efficiency, whether through new algorithms (e.g., BIR-Adapter for image restoration) or novel frameworks (e.g., PowerBin for data binning). This is particularly relevant for quantum computing, where optimizing resource use is crucial.</li>
<li><strong>Integration of AI and Classical Techniques</strong>: Several papers highlight the integration of AI with classical computational methods, such as using deep learning for dynamic environments in robotics or employing tensor networks for gene regulatory network inference. This trend is significant for quantum computing as it explores hybrid approaches to solve complex problems.</li>
<li><strong>Handling Complex Systems</strong>: There is an emphasis on managing complexity, whether in dynamic environments (e.g., in robotics) or in understanding biological systems (e.g., gene regulatory networks). Quantum computing could leverage these insights to handle complex quantum systems more efficiently.</li>
</ul>
<h3>Breakthroughs</h3>
<ul>
<li><strong>Novel Computational Frameworks</strong>: Papers like Deep Reactive Policy and TraceRL introduce innovative frameworks that enhance computational capabilities and efficiency, which are essential for scaling quantum algorithms.</li>
<li><strong>Enhanced Model Accuracy and Performance</strong>: Several papers report significant improvements in model accuracy and efficiency, such as F1 in vision-language-action models and PowerBin in data binning. These breakthroughs could inform quantum algorithm design to ensure accurate and efficient computation.</li>
<li><strong>Quantum-Inspired Techniques</strong>: The use of quantum-inspired techniques, such as tensor networks for gene network inference, showcases the potential of quantum principles in classical computing domains, suggesting a reciprocal influence where classical insights might benefit quantum computing.</li>
</ul>
<h3>Implications</h3>
<ul>
<li><strong>Scalability and Practicality</strong>: The development of scalable, efficient, and practical computational methods has direct implications for quantum computing, particularly as it moves from theoretical exploration to practical application.</li>
<li><strong>Cross-Disciplinary Applications</strong>: The integration of AI, classical computing, and quantum-inspired methods highlights the potential for quantum computing to impact various fields, from robotics and AI to biology and beyond.</li>
<li><strong>Future Research Directions</strong>: The innovative approaches and frameworks discussed in these papers suggest new avenues for research in quantum computing, particularly in developing efficient, hybrid computational models that can leverage quantum mechanics principles.</li>
</ul>
<p>In summary, while these papers do not directly address quantum computing, they reflect broader computational trends that could influence the field. The emphasis on efficiency, integration of AI, and managing complexity are all relevant to advancing quantum computing technology and its applications.</p>
<p><em>Based on 50 research papers</em></p>

            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2509.06951v1" target="_blank">F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions</a></h3>
                    <p><strong>Authors:</strong> Qi Lv, Weijie Kong, Hao Li, Jia Zeng, Zherui Qiu, Delin Qu, Haoming Song, Qizhi Chen, Xiang Deng, Jiangmiao Pang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Executing language-conditioned tasks in dynamic visual environments remains a central challenge in embodied AI. Existing Vision-Language-Action (VLA) models predominantly adopt reactive state-to-action mappings, often leading to short-sighted behaviors and poor robustness in dynamic scenes. In this paper, we introduce F1, a pretrained VLA framework which integrates the visual foresight generation into decision-making pipeline. F1 adopts a Mixture-of-Transformer architecture with dedicated modules for perception, foresight generation, and control, thereby bridging understanding, generation, and actions. At its core, F1 employs a next-scale prediction mechanism to synthesize goal-conditioned visual foresight as explicit planning targets. By forecasting plausible future visual states, F1 reformulates action generation as a foresight-guided inverse dynamics problem, enabling actions that implicitly achieve visual goals. To endow F1 with robust and generalizable capabilities, we propose a three-stage training recipe on an extensive dataset comprising over 330k trajectories across 136 diverse tasks. This training scheme enhances modular reasoning and equips the model with transferable visual foresight, which is critical for complex and dynamic environments. Extensive evaluations on real-world tasks and simulation benchmarks demonstrate F1 consistently outperforms existing approaches, achieving substantial gains in both task success rate and generalization ability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06949v1" target="_blank">Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it can also be applied to adapt block-specific models to larger blocks, which improves sampling flexibility. Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still consistently outperforms them across complex math reasoning tasks. TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical reasoning benchmarks. Through curriculum learning, we also derive the first long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1% relative accuracy gain. To facilitate reproducible research and practical applications, we release a comprehensive open-source framework for building, training, and deploying diffusion LLMs across diverse architectures. The framework integrates accelerated KV-cache techniques and inference engines for both inference and reinforcement learning, and includes implementations of various supervised fine-tuning and RL methods for mathematics, coding, and general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06942v1" target="_blank">Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference</a></h3>
                    <p><strong>Authors:</strong> Xiangwei Shen, Zhimin Li, Zhantao Yang, Shiyi Zhang, Yingfang Zhang, Donghao Li, Chunyu Wang, Qinglin Lu, Yansong Tang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Recent studies have demonstrated the effectiveness of directly aligning diffusion models with human preferences using differentiable reward. However, they exhibit two primary challenges: (1) they rely on multistep denoising with gradient computation for reward scoring, which is computationally expensive, thus restricting optimization to only a few diffusion steps; (2) they often need continuous offline adaptation of reward models in order to achieve desired aesthetic quality, such as photorealism or precise lighting effects. To address the limitation of multistep denoising, we propose Direct-Align, a method that predefines a noise prior to effectively recover original images from any time steps via interpolation, leveraging the equation that diffusion states are interpolations between noise and target images, which effectively avoids over-optimization in late timesteps. Furthermore, we introduce Semantic Relative Preference Optimization (SRPO), in which rewards are formulated as text-conditioned signals. This approach enables online adjustment of rewards in response to positive and negative prompt augmentation, thereby reducing the reliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model with optimized denoising and online reward adjustment, we improve its human-evaluated realism and aesthetic quality by over 3x.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06938v1" target="_blank">From Noise to Narrative: Tracing the Origins of Hallucinations in Transformers</a></h3>
                    <p><strong>Authors:</strong> Praneet Suresh, Jack Stanley, Sonia Joseph, Luca Scimeca, Danilo Bzdok</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinations arise in pre-trained transformer models through concept representations captured by sparse autoencoders, under scenarios with experimentally controlled uncertainty in the input space. Our systematic experiments reveal that the number of semantic concepts used by the transformer model grows as the input information becomes increasingly unstructured. In the face of growing uncertainty in the input space, the transformer model becomes prone to activate coherent yet input-insensitive semantic features, leading to hallucinated output. At its extreme, for pure-noise inputs, we identify a wide variety of robustly triggered and meaningful concepts in the intermediate activations of pre-trained transformer models, whose functional integrity we confirm through targeted steering. We also show that hallucinations in the output of a transformer model can be reliably predicted from the concept patterns embedded in transformer layer activations. This collection of insights on transformer internal processing mechanics has immediate consequences for aligning AI models with human values, AI safety, opening the attack surface for potential adversarial attacks, and providing a basis for automatic quantification of a models hallucination risk.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06936v1" target="_blank">Benchmarking Music Autotagging with MGPHot Expert Annotations vs. Generic Tag Datasets</a></h3>
                    <p><strong>Authors:</strong> Pedro Ramoneda, Pablo Alonso-JimÃ©nez, Sergio Oramas, Xavier Serra, Dmitry Bogdanov</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> Music autotagging aims to automatically assign descriptive tags, such as genre, mood, or instrumentation, to audio recordings. Due to its challenges, diversity of semantic descriptions, and practical value in various applications, it has become a common downstream task for evaluating the performance of general-purpose music representations learned from audio data. We introduce a new benchmarking dataset based on the recently published MGPHot dataset, which includes expert musicological annotations, allowing for additional insights and comparisons with results obtained on common generic tag datasets. While MGPHot annotations have been shown to be useful for computational musicology, the original dataset neither includes audio nor provides evaluation setups for its use as a standardized autotagging benchmark. To address this, we provide a curated set of YouTube URLs with retrievable audio, and propose a train/val/test split for standardized evaluation, and precomputed representations for seven state-of-the-art models. Using these resources, we evaluated these models in MGPHot and standard reference tag datasets, highlighting key differences between expert and generic tag annotations. Altogether, our contributions provide a more advanced benchmarking framework for future research in music understanding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06933v1" target="_blank">Black-hole mass estimation through accretion disk spectral fitting for high-redshift blazars</a></h3>
                    <p><strong>Authors:</strong> G. Kyriopoulos, M. Petropoulou, G. Vasilopoulos, D. Hatzidimitriou</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, astro-ph.GA</p>
                    <p><strong>Summary:</strong> High-redshift ($z2$) blazars, with relativistic jets aligned toward us, probe the most powerful end of the active galactic nuclei (AGN) population. We aim at determining the black hole masses and mass accretion rates of high-$z$ blazars in a common framework that utilizes a Markov Chain Monte Carlo (MCMC) fitting method and the Shakura-Sunayev multi-temperature accretion disk model, accounting also for attenuation due to neutral hydrogen gas in the intergalactic medium (IGM). We compiled a sample of 23 high-redshift blazars from the literature with publicly available infrared-to-ultraviolet photometric data. We performed a Bayesian fit to the spectral energy distribution (SED) of the accretion disk, accounting for upper limits, and determined the black hole masses and mass accretion rates with their uncertainties. We also examined the impact of optical-ultraviolet attenuation due to gas in the IGM. We find that neglecting IGM attenuation in SED fits leads to systematically larger black-hole mass estimates and correspondingly lower Eddington ratios, with the bias becoming more severe at higher redshift. Our MCMC fits yield median black-hole masses in the range $\sim (10^{8}-10^{10})\,M_{\odot}$ and a broad distribution of median Eddington ratios ($\lambda_{\rm Edd}\sim 0.04 - 1$). Comparison with previous literature shows no clear method-dependent systematic offsets, although individual mass estimates can differ by up to a factor of a few. We also demonstrate that assumptions about black-hole spin introduce a systematic degeneracy. This work is to our knowledge the first systematic study to model the accretion-disk emission of a large sample of high-$z$ blazars within a single, consistent statistical framework. Our results emphasize the importance of accounting for IGM attenuation and of using uniform fitting methods when comparing disk-based black hole estimates across samples.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06928v1" target="_blank">On the Bit Size of Sum-of-Squares Proofs for Symmetric Formulations</a></h3>
                    <p><strong>Authors:</strong> Alex Bortolotti, Monaldo Mastrolilli, Marilena Palomba, Luis Felipe Vargas</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CC</p>
                    <p><strong>Summary:</strong> The Sum-of-Squares (SoS) hierarchy is a powerful framework for polynomial optimization and proof complexity, offering tight semidefinite relaxations that capture many classical algorithms. Despite its broad applicability, several works have revealed fundamental limitations to SoS automatability. (i) While low-degree SoS proofs are often desirable for tractability, recent works have revealed they may require coefficients of prohibitively large bit size, rendering them computationally infeasible. (ii) Prior works have shown that SoS proofs for seemingly easy problems require high-degree. In particular, this phenomenon also arises in highly symmetric problems. Instances of symmetric problems-particularly those with a small number of constraints-have repeatedly served as benchmarks for establishing high-degree lower bounds in the SoS hierarchy. It has remained unclear whether symmetry can also lead to large bit sizes in SoS proofs, potentially making low-degree proofs computationally infeasible even in symmetric settings. In this work, we resolve this question by proving that symmetry alone does not lead to large bit size SoS proofs. Focusing on symmetric Archimedean instances, we show that low-degree SoS proofs for such systems admit compact, low bit size representations. Together, these results provide a conceptual separation between two sources of SoS hardness-degree and bit size-by showing they do not necessarily align, even in highly symmetric instances. This insight guides future work on automatability and lower bounds: symmetry may necessitate high-degree proofs, but it does not by itself force large coefficients.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06927v1" target="_blank">NeedForHeat DataGear: An Open Monitoring System to Accelerate the Residential Heating Transition</a></h3>
                    <p><strong>Authors:</strong> Henri ter Hofte, Nick van Ravenzwaaij</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> We introduce NeedForHeat DataGear: an open hardware and open software data collection system designed to accelerate the residential heating transition. NeedForHeat DataGear collects time series monitoring data in homes that have not yet undergone a heating transition, enabling assessment of real-life thermal characteristics, heating system efficiency, and residents comfort needs. This paper outlines its architecture and functionalities, emphasizing its modularity, adaptability, and cost-effectiveness for field data acquisition. Unlike conventional domestic monitoring solutions focused on home automation, direct feedback, or post-installation heat pump monitoring, it prioritizes time series data we deemed essential to evaluate the current situation in existing homes before the heating transition. Designed for seamless deployment across diverse households, NeedForHeat DataGear combines openness, security, and privacy with a low-cost, user-friendly approach, making it a valuable tool for researchers, energy professionals, and energy coaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06923v1" target="_blank">Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding</a></h3>
                    <p><strong>Authors:</strong> Ziheng Li, Zexu Sun, Jinman Zhao, Erxue Min, Yongcheng Zeng, Hui Wu, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Xu Chen, Zhi-Hong Deng</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success in enhancing the reasoning capabilities of large language models (LLMs). However, existing RLVR methods often suffer from exploration inefficiency due to mismatches between the training datas difficulty and the models capability. LLMs fail to discover viable reasoning paths when problems are overly difficult, while learning little new capability when problems are too simple. In this work, we formalize the impact of problem difficulty by quantifying the relationship between loss descent speed and rollout accuracy. Building on this analysis, we propose SEELE, a novel supervision-aided RLVR framework that dynamically adjusts problem difficulty to stay within the high-efficiency region. SEELE augments each training sample by appending a hint (part of a full solution) after the original problem. Unlike previous hint-based approaches, SEELE deliberately and adaptively adjusts the hint length for each problem to achieve an optimal difficulty. To determine the optimal hint length, SEELE employs a multi-round rollout sampling strategy. In each round, it fits an item response theory model to the accuracy-hint pairs collected in preceding rounds to predict the required hint length for the next round. This instance-level, real-time difficulty adjustment aligns problem difficulty with the evolving model capability, thereby improving exploration efficiency. Experimental results show that SEELE outperforms Group Relative Policy Optimization (GRPO) and Supervised Fine-tuning (SFT) by +11.8 and +10.5 points, respectively, and surpasses the best previous supervision-aided approach by +3.6 points on average across six math reasoning benchmarks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06921v1" target="_blank">Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities</a></h3>
                    <p><strong>Authors:</strong> Safayat Bin Hakim, Muhammad Adil, Alvaro Velasquez, Shouhuai Xu, Houbing Herbert Song</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit fundamental limitations: inadequate conceptual grounding leading to non-robustness against novel attacks; limited instructibility impeding analyst-guided adaptation; and misalignment with cybersecurity objectives. Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize cybersecurity AI. However, there is no systematic understanding of this emerging approach. These hybrid systems address critical cybersecurity challenges by combining neural pattern recognition with symbolic reasoning, enabling enhanced threat understanding while introducing concerning autonomous offensive capabilities that reshape threat landscapes. In this survey, we systematically characterize this field by analyzing 127 publications spanning 2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A) framework to evaluate these systems, focusing on both cyber defense and cyber offense across network security, malware analysis, and cyber operations. Our analysis shows advantages of multi-agent NeSy architectures and identifies critical implementation challenges including standardization gaps, computational complexity, and human-AI collaboration requirements that constrain deployment. We show that causal reasoning integration is the most transformative advancement, enabling proactive defense beyond correlation-based approaches. Our findings highlight dual-use implications where autonomous systems demonstrate substantial capabilities in zero-day exploitation while achieving significant cost reductions, altering threat dynamics. We provide insights and future research directions, emphasizing the urgent need for community-driven standardization frameworks and responsible development practices that ensure advancement serves defensive cybersecurity objectives while maintaining societal alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06920v1" target="_blank">An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection</a></h3>
                    <p><strong>Authors:</strong> Haywood Gelman, John D. Hastings, David Kenley</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.CL, cs.CY, C.2.0; I.2.7; K.4.1; H.3.3</p>
                    <p><strong>Summary:</strong> Insider threats are a growing organizational problem due to the complexity of identifying their technical and behavioral elements. A large research body is dedicated to the study of insider threats from technological, psychological, and educational perspectives. However, research in this domain has been generally dependent on datasets that are static and limited access which restricts the development of adaptive detection models. This study introduces a novel, ethically grounded approach that uses the large language model (LLM) Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which contain indicators of insider threat scenarios. The messages reflect real-world data distributions by being highly imbalanced (1% insider threats). The syslogs were analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with their performance evaluated through statistical metrics including precision, recall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across nearly all metrics, particularly in reducing false alarms and improving detection accuracy. The results show strong promise for the use of LLMs in synthetic dataset generation and insider threat detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06918v1" target="_blank">Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition</a></h3>
                    <p><strong>Authors:</strong> Tarhib Al Azad, Shahana Ibrahim</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature--with both post hoc and training-based approaches--its effectiveness under noisy training labels remains underexplored. Recent studies suggest that label noise can significantly degrade OOD performance, yet principled solutions to this issue are lacking. In this work, we demonstrate that directly combining existing label noise-robust methods with OOD detection strategies is insufficient to address this critical challenge. To overcome this, we propose a robust OOD detection framework that integrates loss correction techniques from the noisy label learning literature with low-rank and sparse decomposition methods from signal processing. Extensive experiments on both synthetic and real-world datasets demonstrate that our method significantly outperforms the state-of-the-art OOD detection techniques, particularly under severe noisy label settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06917v1" target="_blank">Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents</a></h3>
                    <p><strong>Authors:</strong> Jiacheng Miao, Joe R. Davis, Jonathan K. Pritchard, James Zou</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a papers code, data, and methods to their own work, creating barriers to dissemination and reuse. Paper2Agent addresses this challenge by automatically converting a paper into an AI agent that acts as a knowledgeable research assistant. It systematically analyzes the paper and the associated codebase using multiple agents to construct a Model Context Protocol (MCP) server, then iteratively generates and runs tests to refine and robustify the resulting MCP. These paper MCPs can then be flexibly connected to a chat agent (e.g. Claude Code) to carry out complex scientific queries through natural language while invoking tools and workflows from the original paper. We demonstrate Paper2Agents effectiveness in creating reliable and capable paper agents through in-depth case studies. Paper2Agent created an agent that leverages AlphaGenome to interpret genomic variants and agents based on ScanPy and TISSUE to carry out single-cell and spatial transcriptomics analyses. We validate that these paper agents can reproduce the original papers results and can correctly carry out novel user queries. By turning static papers into dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for knowledge dissemination and a foundation for the collaborative ecosystem of AI co-scientists.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06898v1" target="_blank">BatStation: Toward In-Situ Radar Sensing on 5G Base Stations with Zero-Shot Template Generation</a></h3>
                    <p><strong>Authors:</strong> Zhihui Gao, Zhecun Liu, Tingjun Chen</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.NI, eess.SP</p>
                    <p><strong>Summary:</strong> The coexistence between incumbent radar signals and commercial 5G signals necessitates a versatile and ubiquitous radar sensing for efficient and adaptive spectrum sharing. In this context, leveraging the densely deployed 5G base stations (BS) for radar sensing is particularly promising, offering both wide coverage and immediate feedback to 5G scheduling. However, the targeting radar signals are superimposed with concurrent 5G uplink transmissions received by the BS, and practical deployment also demands a lightweight, portable radar sensing model. This paper presents BatStation, a lightweight, in-situ radar sensing framework seamlessly integrated into 5G BSs. BatStation leverages uplink resource grids to extract radar signals through three key components: (i) radar signal separation to cancel concurrent 5G transmissions and reveal the radar signals, (ii) resource grid reshaping to align time-frequency resolution with radar pulse characteristics, and (iii) zero-shot template correlation based on a portable model trained purely on synthetic data that supports detection, classification, and localization of radar pulses without fine-tuning using experimental data. We implement BatStation on a software-defined radio (SDR) testbed and evaluate its performance with real 5G traffic in the CBRS band. Results show robust performance across diverse radar types, achieving detection probabilities of 97.02% (PUCCH) and 79.23% (PUSCH), classification accuracy up to 97.00%, and median localization errors of 2.68-6.20 MHz (frequency) and 24.6-32.4 microseconds (time). Notably, BatStation achieves this performance with a runtime latency of only 0.11/0.94 ms on GPU/CPU, meeting the real-time requirement of 5G networks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06890v1" target="_blank">Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization</a></h3>
                    <p><strong>Authors:</strong> Minheng Chen, Youyong Kong</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> Intraoperative 2D/3D registration aligns preoperative 3D volumes with real-time 2D radiographs, enabling accurate localization of instruments and implants. A recent fully differentiable similarity learning framework approximates geodesic distances on SE(3), expanding the capture range of registration and mitigating the effects of substantial disturbances, but existing Euclidean approximations distort manifold structure and slow convergence. To address these limitations, we explore similarity learning in non-Euclidean spherical feature spaces to better capture and fit complex manifold structure. We extract feature embeddings using a CNN-Transformer encoder, project them into spherical space, and approximate their geodesic distances with Riemannian distances in the bi-invariant SO(4) space. This enables a more expressive and geometrically consistent deep similarity metric, enhancing the ability to distinguish subtle pose differences. During inference, we replace gradient descent with fully differentiable Levenberg-Marquardt optimization to accelerate convergence. Experiments on real and synthetic datasets show superior accuracy in both patient-specific and patient-agnostic scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06888v1" target="_blank">mmBERT: A Modern Multilingual Encoder with Annealed Language Learning</a></h3>
                    <p><strong>Authors:</strong> Marc Marone, Orion Weller, William Fleshman, Eugene Yang, Dawn Lawrie, Benjamin Van Durme</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR, cs.LG</p>
                    <p><strong>Summary:</strong> Encoder-only languages models are frequently used for a variety of standard machine learning tasks, including classification and retrieval. However, there has been a lack of recent research for encoder models, especially with respect to multilingual models. We introduce mmBERT, an encoder-only language model pretrained on 3T tokens of multilingual text in over 1800 languages. To build mmBERT we introduce several novel elements, including an inverse mask ratio schedule and an inverse temperature sampling ratio. We add over 1700 low-resource languages to the data mix only during the decay phase, showing that it boosts performance dramatically and maximizes the gains from the relatively small amount of training data. Despite only including these low-resource languages in the short decay phase we achieve similar classification performance to models like OpenAIs o3 and Googles Gemini 2.5 Pro. Overall, we show that mmBERT significantly outperforms the previous generation of models on classification and retrieval tasks -- on both high and low-resource languages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06887v1" target="_blank">UniSearch: Rethinking Search System with a Unified Generative Architecture</a></h3>
                    <p><strong>Authors:</strong> Jiahui Chen, Xiaoze Jiang, Zhibo Wang, Quanzhi Zhu, Junyao Zhao, Feng Hu, Kang Pan, Ao Xie, Maohua Pei, Zhiheng Qin, Hongjing Zhang, Zhixin Zhai, Xiaobo Guo, Runbin Zhou, Kefeng Wang, Mingyang Geng, Cheng Chen, Jingshan Lv, Yupeng Huang, Xiao Liang, Han Li</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Modern search systems play a crucial role in facilitating information acquisition. Traditional search engines typically rely on a cascaded architecture, where results are retrieved through recall, pre-ranking, and ranking stages. The complexity of designing and maintaining multiple modules makes it difficult to achieve holistic performance gains. Recent advances in generative recommendation have motivated the exploration of unified generative search as an alternative. However, existing approaches are not genuinely end-to-end: they typically train an item encoder to tokenize candidates first and then optimize a generator separately, leading to objective inconsistency and limited generalization. To address these limitations, we propose UniSearch, a unified generative search framework for Kuaishou Search. UniSearch replaces the cascaded pipeline with an end-to-end architecture that integrates a Search Generator and a Video Encoder. The Generator produces semantic identifiers of relevant items given a user query, while the Video Encoder learns latent item embeddings and provides their tokenized representations. A unified training framework jointly optimizes both components, enabling mutual enhancement and improving representation quality and generation accuracy. Furthermore, we introduce Search Preference Optimization (SPO), which leverages a reward model and real user feedback to better align generation with user preferences. Extensive experiments on industrial-scale datasets, together with online A/B testing in both short-video and live search scenarios, demonstrate the strong effectiveness and deployment potential of UniSearch. Notably, its deployment in live search yields the largest single-experiment improvement in recent years of our products history, highlighting its practical value for real-world applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06867v1" target="_blank">Are international happiness rankings reliable?</a></h3>
                    <p><strong>Authors:</strong> Christopher P Barrington-Leigh</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Global comparisons of wellbeing increasingly rely on survey questions that ask respondents to evaluate their lives, most commonly in the form of life satisfaction and Cantril ladder items. These measures underpin international rankings such as the World Happiness Report and inform policy initiatives worldwide, yet their comparability has not been established with contemporary global data. Using the Gallup World Poll, Global Flourishing Study, and World Values Survey, I show that the two question formats yield divergent distributions, rankings, and response patterns that vary across countries and surveys, defying simple explanations. To explore differences in respondents cognitive interpretations, I compare regression coefficients from the Global Flourishing Study, analyzing how each question wording relates to life circumstances. While international rankings of wellbeing are unstable, the scientific study of the determinants of life evaluations appears more robust. Together, the findings underscore the need for a renewed research agenda on critical limitations to cross-country comparability of wellbeing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06862v1" target="_blank">Matching Shapes Under Different Topologies: A Topology-Adaptive Deformation Guided Approach</a></h3>
                    <p><strong>Authors:</strong> Aymen Merrouche, Stefanie Wuhrer, Edmond Boyer</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Non-rigid 3D mesh matching is a critical step in computer vision and computer graphics pipelines. We tackle matching meshes that contain topological artefacts which can break the assumption made by current approaches. While Functional Maps assume the deformation induced by the ground truth correspondences to be near-isometric, ARAP-like deformation-guided approaches assume the latter to be ARAP. Neither assumption holds in certain topological configurations of the input shapes. We are motivated by real-world scenarios such as per-frame multi-view reconstructions, often suffering from topological artefacts. To this end, we propose a topology-adaptive deformation model allowing changes in shape topology to align shape pairs under ARAP and bijective association constraints. Using this model, we jointly optimise for a template mesh with adequate topology and for its alignment with the shapes to be matched to extract correspondences. We show that, while not relying on any data-driven prior, our approach applies to highly non-isometric shapes and shapes with topological artefacts, including noisy per-frame multi-view reconstructions, even outperforming methods trained on large datasets in 3D alignment quality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06855v1" target="_blank">Seeing the Forest Through the Trees: Knowledge Retrieval for Streamlining Particle Physics Analysis</a></h3>
                    <p><strong>Authors:</strong> James McGreivy, Blaise Delaney, Anja Beck, Mike Williams</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> Generative Large Language Models (LLMs) are a promising approach to structuring knowledge contained within the corpora of research literature produced by large-scale and long-running scientific collaborations. Within experimental particle physics, such structured knowledge bases could expedite methodological and editorial review. Complementarily, within the broader scientific community, generative LLM systems grounded in published work could make for reliable companions allowing non-experts to analyze open-access data. Techniques such as Retrieval Augmented Generation (RAG) rely on semantically matching localized text chunks, but struggle to maintain coherent context when relevant information spans multiple segments, leading to a fragmented representation devoid of global cross-document information. Here, we utilize the hierarchical organization of experimental physics articles to build a tree representation of the corpus, and present the SciTreeRAG system that uses this structure to create contexts that are more focused and contextually rich than standard RAG. Additionally, we develop methods for using LLMs to transform the unstructured corpus into a structured knowledge graph representation. We then implement SciGraphRAG, a retrieval system that leverages this knowledge graph to access global cross-document relationships eluding standard RAG, thereby encapsulating domain-specific connections and expertise. We demonstrate proof-of-concept implementations using the corpus of the LHCb experiment at CERN.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06854v1" target="_blank">Automated Radiographic Total Sharp Score (ARTSS) in Rheumatoid Arthritis: A Solution to Reduce Inter-Intra Reader Variation and Enhancing Clinical Practice</a></h3>
                    <p><strong>Authors:</strong> Hajar Moradmand, Lei Ren</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming and subjective. This study introduces an Automated Radiographic Sharp Scoring (ARTSS) framework that leverages deep learning to analyze full-hand X-ray images, aiming to reduce inter- and intra-observer variability. The research uniquely accommodates patients with joint disappearance and variable-length image sequences. We developed ARTSS using data from 970 patients, structured into four stages: I) Image pre-processing and re-orientation using ResNet50, II) Hand segmentation using UNet.3, III) Joint identification using YOLOv7, and IV) TSS prediction using models such as VGG16, VGG19, ResNet50, DenseNet201, EfficientNetB0, and Vision Transformer (ViT). We evaluated model performance with Intersection over Union (IoU), Mean Average Precision (MAP), mean absolute error (MAE), Root Mean Squared Error (RMSE), and Huber loss. The average TSS from two radiologists was used as the ground truth. Model training employed 3-fold cross-validation, with each fold consisting of 452 training and 227 validation samples, and external testing included 291 unseen subjects. Our joint identification model achieved 99% accuracy. The best-performing model, ViT, achieved a notably low Huber loss of 0.87 for TSS prediction. Our results demonstrate the potential of deep learning to automate RA scoring, which can significantly enhance clinical practice. Our approach addresses the challenge of joint disappearance and variable joint numbers, offers timesaving benefits, reduces inter- and intra-reader variability, improves radiologist accuracy, and aids rheumatologists in making more informed decisions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06849v1" target="_blank">Canonicalization of the E value from BLAST similarity search -- dissimilarity measure and distance function for a metric space of protein sequences</a></h3>
                    <p><strong>Authors:</strong> Boryeu Mao</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> q-bio.BM, q-bio.QM</p>
                    <p><strong>Summary:</strong> Sequence matching algorithms such as BLAST and FASTA have been widely used in searching for evolutionary origin and biological functions of newly discovered nucleic acid and protein sequences. As parts of these search tools, alignment scores and E values are useful indicators of the quality of search results from querying a database of annotated sequences, whereby a high alignment score (and inversely a low E value) reflects significant similarity between the query and the subject (target) sequences. For cross-comparison of results from sufficiently different queries however, the interpretation of alignment score as a similarity measure and E value a dissimilarity measure becomes somewhat nuanced, and prompts herein a judicious distinction of different types of similarity. We show that an adjustment of E value to account for self-matching of query and subject sequences corrects for certain ostensibly anomalous similarity comparisons, resulting in canonical dissimilarity and similarity measures that would be more appropriate for database applications, such as all-on-all sequence alignment or selection of diverse subsets. In actual practice, the canonicalization of E value dissimilarity improves clustering and the diversity of subset selection. While both E value and the canonical E value share positivity and symmetry, two of the four axiomatic properties of a metric space, the canonical E value itself is also reflexive and meets the condition of triangle inequality, thus an appropriate distance function for a metric space of protein sequences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06838v1" target="_blank">EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Mohammad Reza Mirbagheri, Mohammad Mahdi Mirkamali, Zahra Motoshaker Arani, Ali Javeri, Amir Mahdi Sadeghzadeh, Rasool Jalili</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CR</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cultural, and social values. Careful alignment of training data and culturally grounded evaluation criteria are vital for developing responsible AI systems. In this study, we introduce the EPT (Evaluation of Persian Trustworthiness) metric, a culturally informed benchmark specifically designed to assess the trustworthiness of LLMs across six key aspects: truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We curated a labeled dataset and evaluated the performance of several leading models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and Qwen - using both automated LLM-based and human assessments. Our results reveal significant deficiencies in the safety dimension, underscoring the urgent need for focused attention on this critical aspect of model behavior. Furthermore, our findings offer valuable insights into the alignment of these models with Persian ethical-cultural values and highlight critical gaps and opportunities for advancing trustworthy and culturally responsible AI. The dataset is publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06836v1" target="_blank">COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens</a></h3>
                    <p><strong>Authors:</strong> Eugene Kwek, Wenpeng Yin</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Making LLMs more efficient in memory, latency, and serving cost is crucial for edge deployment, interactive applications, and sustainable inference at scale. Pruning is a key technique toward this goal. However, prior pruning methods are limited: width pruning often breaks the standard transformer layout or requires custom inference code, while depth pruning removes entire layers and can cause abrupt accuracy drops. In this work, we propose COMPACT, which jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii) prunes FFN intermediate channels using common-token-weighted activations, aligning importance with the post-pruning token distribution. COMPACT enjoys merits of both depth and width pruning, such as: deployment-friendliness (keeps a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN pruning), training-free operation with competitive pruning time, and strong memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and Gemma families (0.5B-70B) show state-of-the-art downstream task performance at similar or higher pruning ratios, with substantial reductions in parameters, GPU memory, and end-to-end latency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06834v1" target="_blank">Unlocking 21cm Cosmology with SBI: A Beginner friendly NRE for Inference of Astrophysical Parameters</a></h3>
                    <p><strong>Authors:</strong> Bisweswar Sen, Abhirup Datta</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, astro-ph.GA, astro-ph.IM</p>
                    <p><strong>Summary:</strong> The 21-cm line of neutral hydrogen is a promising probe of the early Universe, yet extracting astrophysical parameters from its power spectrum remains a major challenge. We present a beginner-friendly PyTorch pipeline for Marginal Neural Ratio Estimation (MNRE), a Simulation-Based Inference (SBI) method that bypasses explicit likelihoods. Using 21cmFAST simulations, we show that MNRE can recover key astrophysical parameters such as the ionizing efficiency $\zeta$ and X-ray luminosity $L_X$ directly from power spectra. Our implementation prioritizes transparency and accessibility, offering a practical entry point for new researchers in 21-cm cosmology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06833v1" target="_blank">$\ell_0$-Norm Multiobjective Optimization Models Motivated by Applications to Proton Therapy</a></h3>
                    <p><strong>Authors:</strong> Xiaoda Cong, Xuanfeng Ding, Boris Mordukhovich, Anh Vu Nguyen, Lewei Zhao</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> math.OC, 90C26, 90C29, 49J52</p>
                    <p><strong>Summary:</strong> The paper is devoted to investigating single-objective and multiobjective optimization problems involving the $\ell_0$-norm function, which is nonconvex and nondifferentiable. Our motivation comes from proton beam therapy models in cancer research. The developed approach uses subdifferential tools of variational analysis and the Gerstewitz (Tammer) scalarization function in multiobjective optimization. Based on this machinery, we propose several algorithms of the subgradient type and conduct their convergence analysis. The obtained results are illustrated by numerical examples, which reveal some characteristic features of the proposed algorithms and their interactions with the gradient descent.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06832v1" target="_blank">Strongly tilted field induced fractional quantized-drift in non-interacting system</a></h3>
                    <p><strong>Authors:</strong> Bo Zhu, Zhi Tan, Huilin Gong, Honghua Zhong, Xin-You LÃ¼, Xiaoguang Wang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas</p>
                    <p><strong>Summary:</strong> Fractional quantized response appears to be a distinctive characteristic in interacting topological systems. Here, we discover a novel phenomenon of tilt-induced fractional quantize drift in non-interacting system constructed by a time-modulated superlattice subjected to a external time-independent gradient potential. Depending on the tilt strength, Rabi oscillations between adjacent lowest enegy bands caused by Landau-Zener tunneling, can induce that the one-cycle-averaged drift displacement is fraction, which is relate to the ratio of the sum of Chern numbers of multiple bands to the number of energy bands involved in Landau Zener tunneling. As representative examples, we construct fractional (1/3, 1/2) quantize drift only via adjusting period of lattice. The numerical simulations allow us to consider a realistic setup amenable of an experimental realization. Our findings will expand the research implications of both fractional quantize response and topological materials.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06831v1" target="_blank">Leveraging Generic Foundation Models for Multimodal Surgical Data Analysis</a></h3>
                    <p><strong>Authors:</strong> Simon Pezold, JÃ©rÃ´me A. Kurylec, Jan S. Liechti, Beat P. MÃ¼ller, JoÃ«l L. Lavanchy</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We investigate how both the adaptation of a generic foundation model via transfer learning and the integration of complementary modalities from the operating room (OR) can support surgical data science. To this end, we use V-JEPA as the single-modality foundation of a multimodal model for minimally invasive surgery support. We analyze how the models downstream performance can benefit (a) from finetuning on unlabeled surgical video data and (b) from providing additional time-resolved data streams from the OR in a multimodal setup. In an in-house dataset of liver surgery videos, we analyze the tasks of predicting hospital length of stay and postoperative complications. In videos of the public HeiCo dataset, we analyze the task of surgical phase recognition. As a baseline, we apply pretrained V-JEPA to all tasks. We then finetune it on unlabeled, held-out videos to investigate its change in performance after domain adaptation. Following the idea of modular decision support networks, we integrate additional data streams from the OR by training a separate encoder to form a shared representation space with V-JEPAs embeddings. Our experiments show that finetuning on domain-specific data increases model performance. On the in-house data, integrating additional time-resolved data likewise benefits the model. On the HeiCo data, accuracy of the pretrained video-only, single-modality baseline setup is on par with the top-performing submissions of the EndoVis2017 challenge, while finetuning on domain-specific data increases accuracy further. Our results thus demonstrate how surgical data science can leverage public, generic foundation models. Likewise, they indicate the potential of domain adaptation and of integrating suitable complementary data streams from the OR. To support further research, we release our code and model weights at https://github.com/DigitalSurgeryLab-Basel/ML-CDS-2025.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06830v1" target="_blank">Curia: A Multi-Modal Foundation Model for Radiology</a></h3>
                    <p><strong>Authors:</strong> Corentin Dancette, Julien Khlaut, Antoine Saporta, Helene Philippe, Elodie Ferreres, Baptiste Callard, ThÃ©o Danielou, LÃ©o Alberge, LÃ©o Machado, Daniel Tordjman, Julie Dupuis, Korentin Le Floch, Jean Du Terrail, Mariam Moshiri, Laurent Dercle, Tom Boeken, Jules Gregory, Maxime Ronot, FranÃ§ois Legou, Pascal Roux, Marc Sapoval, Pierre Manceron, Paul HÃ©rent</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> AI-assisted radiological interpretation is based on predominantly narrow, single-task models. This approach is impractical for covering the vast spectrum of imaging modalities, diseases, and radiological findings. Foundation models (FMs) hold the promise of broad generalization across modalities and in low-data settings. However, this potential has remained largely unrealized in radiology. We introduce Curia, a foundation model trained on the entire cross-sectional imaging output of a major hospital over several years, which to our knowledge is the largest such corpus of real-world data-encompassing 150,000 exams (130 TB). On a newly curated 19-task external validation benchmark, Curia accurately identifies organs, detects conditions like brain hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging. Curia meets or surpasses the performance of radiologists and recent foundation models, and exhibits clinically significant emergent properties in cross-modality, and low-data regimes. To accelerate progress, we release our base models weights at https://huggingface.co/raidium/curia.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06813v1" target="_blank">A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs</a></h3>
                    <p><strong>Authors:</strong> Max Malyi, Jonathan Shek, Alasdair McDonald, Andre Biscaya</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Effective Operation and Maintenance (OM) is critical to reducing the Levelised Cost of Energy (LCOE) from wind power, yet the unstructured, free-text nature of turbine maintenance logs presents a significant barrier to automated analysis. Our paper addresses this by presenting a novel and reproducible framework for benchmarking Large Language Models (LLMs) on the task of classifying these complex industrial records. To promote transparency and encourage further research, this framework has been made publicly available as an open-source tool. We systematically evaluate a diverse suite of state-of-the-art proprietary and open-source LLMs, providing a foundational assessment of their trade-offs in reliability, operational efficiency, and model calibration. Our results quantify a clear performance hierarchy, identifying top models that exhibit high alignment with a benchmark standard and trustworthy, well-calibrated confidence scores. We also demonstrate that classification performance is highly dependent on the tasks semantic ambiguity, with all models showing higher consensus on objective component identification than on interpretive maintenance actions. Given that no model achieves perfect accuracy and that calibration varies dramatically, we conclude that the most effective and responsible near-term application is a Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate and standardise data labelling for human experts, thereby enhancing OM data quality and downstream reliability analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06809v1" target="_blank">Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem</a></h3>
                    <p><strong>Authors:</strong> Valentin Quesnel, Damien Sileo</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The scarcity of high-quality, logically sound data is a critical bottleneck for advancing the mathematical reasoning of Large Language Models (LLMs). Our work confronts this challenge by turning decades of automated theorem proving research into a scalable data engine. Rather than relying on error-prone LLMs or complex proof-assistant syntax like Lean and Isabelle, our framework leverages E-provers saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems. Our pipeline is principled and simple: saturate axioms, filter for interesting theorems, and generate tasks. With no LLMs in the loop, we eliminate factual errors by construction. This purely symbolic data is then transformed into three difficulty-controlled challenges: entailment verification, premise selection, and proof reconstruction. Our zero-shot experiments on frontier models reveal a clear weakness: performance collapses on tasks requiring deep, structural reasoning. Our framework provides both the diagnostic tool to measure this gap and a scalable source of symbolic training data to address it. We make the code and data publicly available. https://github.com/sileod/reasoning_core https://hf.co/datasets/reasoning-core/rc1</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06805v1" target="_blank">Euclid preparation. Methodology for validating the Euclid Catalogue of Galaxy Clusters using external data</a></h3>
                    <p><strong>Authors:</strong> Euclid Collaboration, J. -B. Melin, S. A. Stanford, A. Widmer, P. TarrÃ­o, J. G. Bartlett, T. Sadibekova, G. W. Pratt, M. Arnaud, F. Pacaud, T. H. Reiprich, A. Biviano, S. Bardelli, S. Borgani, P. -S. Corasaniti, S. Ettori, A. Finoguenov, Z. Ghaffari, P. A. Giles, M. Girardi, J. B. Golden-Marx, A. H. Gonzalez, M. Klein, G. F. Lesci, M. Maturi, B. J. Maughan, L. Moscardini, M. Pierre, M. Radovich, P. Rosati, J. G. Sorce, E. Tsaprazi, B. Altieri, A. Amara, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, E. Branchini, M. Brescia, S. Camera, G. CaÃ±as-Herrera, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, A. Da Silva, H. Degaudenzi, G. De Lucia, H. Dole, M. Douspis, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Fabricius, M. Farina, S. Farrens, F. Faustini, S. Ferriol, F. Finelli, P. Fosalba, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, E. KeihÃ¤nen, S. Kermiche, A. Kiessling, M. Kilbinger, B. Kubik, M. KÃ¼mmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, S. Maurogordato, E. Medinaceli, S. Mei, M. Melchior, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, E. Munari, R. Nakajima, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, V. Pettorino, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, E. Rossetti, R. Saglia, Z. Sakr, A. G. SÃ¡nchez, D. Sapone, B. Sartoris, P. Schneider, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, P. Simon, C. Sirignano, G. Sirri, L. Stanco, J. Steinwagner, P. Tallada-CrespÃ­, D. Tavagnacco, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, G. Zamorani, F. M. Zerbi, E. Zucca, V. Allevato, M. Ballardini, M. Bolzonella, E. Bozzo, C. Burigana, R. Cabanac, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, J. MartÃ­n-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. Pezzotta, M. PÃ¶ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, S. Alvi, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, C. Benoist, P. Bergamini, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, H. BÃ¶hringer, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, M. Costanzi, O. Cucciati, S. Davini, G. Desprez, A. DÃ­az-SÃ¡nchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, A. Enia, Y. Fang, A. G. Ferrari, A. Fontana, A. Franco, K. Ganga, J. GarcÃ­a-Bellido, T. Gasparetto, V. Gautard, R. Gavazzi, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Guidi, C. M. Gutierrez, A. Hall, S. Hemmati, C. HernÃ¡ndez-Monteagudo, H. Hildebrandt, J. Hjorth, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, C. C. Kirkpatrick, S. Kruk, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, S. J. Liu, A. Loureiro, J. Macias-Perez, G. Maggio, M. Magliocchetti, G. A. Mamon, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Miluzio, P. Monaco, A. Montoro, C. Moretti, G. Morgante, C. Murray, K. Naidoo, A. Navarro-Alsina, S. Nesseris, F. Passalacqua, K. Paterson, A. Pisani, D. Potter, S. Quai, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. SahlÃ©n, D. B. Sanders, E. Sarpa, A. Schneider, M. Schultheis, D. Sciotti, E. Sellentin, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, G. Verza, P. Vielzeuf, N. A. Walton</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> We present our methodology for identifying known clusters as counterparts to objects in the Euclid Catalogue of Galaxy Clusters (ECGC). Euclid is expected to detect a large number of optically-selected galaxy clusters over the approximately 14000 square degrees of its extragalactic sky survey. Extending out well beyond redshift unity, the catalogue will contain many new high-redshift clusters, while at lower redshifts a fraction of the clusters will have been observed in other surveys. Identifying these known clusters as counterparts to the Euclid-detected clusters is an important step in the validation and construction of the ECGC to augment information with external observables. We present a set of catalogues and meta-catalogues of known clusters that we have assembled for this step, and we illustrate their application and our methodology using the Dark Energy Survey Year 1 RedMaPPer cluster catalogue in lieu of the future ECGC. In the process of this work, we have constructed and deliver an updated EC-RedMaPPer catalogue with multi-wavelength counterparts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06803v1" target="_blank">MIORe  VAR-MIORe: Benchmarks to Push the Boundaries of Restoration</a></h3>
                    <p><strong>Authors:</strong> George Ciubotariu, Zhuyun Zhou, Zongwei Wu, Radu Timofte</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce MIORe and VAR-MIORe, two novel multi-task datasets that address critical limitations in current motion restoration benchmarks. Designed with high-frame-rate (1000 FPS) acquisition and professional-grade optics, our datasets capture a broad spectrum of motion scenarios, which include complex ego-camera movements, dynamic multi-subject interactions, and depth-dependent blur effects. By adaptively averaging frames based on computed optical flow metrics, MIORe generates consistent motion blur, and preserves sharp inputs for video frame interpolation and optical flow estimation. VAR-MIORe further extends by spanning a variable range of motion magnitudes, from minimal to extreme, establishing the first benchmark to offer explicit control over motion amplitude. We provide high-resolution, scalable ground truths that challenge existing algorithms under both controlled and adverse conditions, paving the way for next-generation research of various image and video restoration tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06795v1" target="_blank">Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint</a></h3>
                    <p><strong>Authors:</strong> Yanrui Du, Fenglei Fan, Sendong Zhao, Jiawei Cao, Qika Lin, Kai He, Ting Liu, Bing Qin, Mengling Feng</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Instruction Fine-Tuning (IFT) has been widely adopted as an effective post-training strategy to enhance various abilities of Large Language Models (LLMs). However, prior studies have shown that IFT can significantly compromise LLMs safety, particularly their ability to refuse malicious instructions, raising significant concerns. Recent research into the internal mechanisms of LLMs has identified the refusal direction (r-direction) in the hidden states, which plays a pivotal role in governing refusal behavior. Building on this insight, our study reveals that the r-direction tends to drift during training, which we identify as one of the causes of the associated safety risks. To mitigate such drift, our proposed ProCon method introduces a projection-constrained loss term that regularizes the projection magnitude of each training samples hidden state onto the r-direction. Our initial analysis shows that applying an appropriate constraint can effectively mitigate the refusal direction drift and associated safety risks, but remains limited by overall performance barriers. To overcome this barrier, informed by our observation of early-stage sharp drift and a data-driven perspective, we introduce a warm-up strategy that emphasizes early-stage strong constraints and broaden the data distribution to strengthen constraint signals, leading to an enhanced ProCon method. Experimental results under various datasets, scenarios, and LLMs demonstrate that our method can significantly mitigate safety risks posed by IFT while preserving task performance gains. Even compared with strong baselines, our method consistently delivers superior overall performance. Crucially, our analysis indicates that ProCon can contribute to stabilizing the r-direction during training, while such an interpretability-driven exploration of LLMs internal mechanisms lays a solid foundation for future safety research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06794v1" target="_blank">Dato: A Task-Based Programming Model for Dataflow Accelerators</a></h3>
                    <p><strong>Authors:</strong> Shihan Fang, Hongzheng Chen, Niansong Zhang, Jiajie Li, Han Meng, Adrian Liu, Zhiru Zhang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.PL, cs.AR, cs.LG</p>
                    <p><strong>Summary:</strong> Recent deep learning workloads increasingly push computational demand beyond what current memory systems can sustain, with many kernels stalling on data movement rather than computation. While modern dataflow accelerators incorporate on-chip streaming to mitigate off-chip bandwidth limitations, existing programming models struggle to harness these capabilities effectively. Low-level interfaces provide fine-grained control but impose significant development overhead, whereas high-level tile-based languages abstract away communication details, restricting optimization and forcing compilers to reconstruct the intended dataflow. We present Dato, a Python-embedded, task-based programming model for dataflow accelerators that elevates data communication and sharding to first-class type constructs. Developers write programs as a graph of tasks connected via explicit stream types, with sharded inputs specified using layout types. These tasks are first mapped virtually onto the accelerators spatial fabric, and the compiler then generates a physical mapping that respects hardware constraints. Experimental results on both AMD Ryzen AI NPU and Alveo FPGA devices demonstrate that Dato achieves high performance while significantly reducing the burden of writing optimized code. On the NPU, Dato attains up to 84% hardware utilization for GEMM and delivers a 2.81x speedup on attention kernels compared to a state-of-the-art commercial framework. On the FPGA, Dato surpasses leading frameworks in performance when generating custom systolic arrays, achieving 98% of the theoretical peak performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06788v1" target="_blank">An Interpretable AI Framework to Disentangle Self-Interacting and Cold Dark Matter in Galaxy Clusters: The CKAN Approach</a></h3>
                    <p><strong>Authors:</strong> Zhenyang Huang, Haihao Shi, Zhiyong Liu, Na Wang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM, astro-ph.CO</p>
                    <p><strong>Summary:</strong> Convolutional neural networks have shown their ability to differentiate between self-interacting dark matter (SIDM) and cold dark matter (CDM) on galaxy cluster scales. However, their large parameter counts and black-box nature make it difficult to assess whether their decisions adhere to physical principles. To address this issue, we have built a Convolutional Kolmogorov-Arnold Network (CKAN) that reduces parameter count and enhances interpretability, and propose a novel analytical framework to understand the networks decision-making process. With this framework, we leverage our network to qualitatively assess the offset between the dark matter distribution center and the galaxy cluster center, as well as the size of heating regions in different models. These findings are consistent with current theoretical predictions and show the reliability and interpretability of our network. By combining network interpretability with unseen test results, we also estimate that for SIDM in galaxy clusters, the minimum cross-section $(\sigma/m)_{\mathrm{th}}$ required to reliably identify its collisional nature falls between $0.1\,\mathrm{cm}^2/\mathrm{g}$ and $0.3\,\mathrm{cm}^2/\mathrm{g}$. Moreover, CKAN maintains robust performance under simulated JWST and Euclid noise, highlighting its promise for application to forthcoming observational surveys.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06786v1" target="_blank">\texttt{R$^\textbf{2}$AI}: Towards Resistant and Resilient AI in an Evolving World</a></h3>
                    <p><strong>Authors:</strong> Youbang Sun, Xiang Wang, Jie Fu, Chaochao Lu, Bowen Zhou</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In this position paper, we address the persistent gap between rapidly growing AI capabilities and lagging safety progress. Existing paradigms divide into ``Make AI Safe, which applies post-hoc alignment and guardrails but remains brittle and reactive, and ``Make Safe AI, which emphasizes intrinsic safety but struggles to address unforeseen risks in open-ended environments. We therefore propose \textit{safe-by-coevolution} as a new formulation of the ``Make Safe AI paradigm, inspired by biological immunity, in which safety becomes a dynamic, adversarial, and ongoing learning process. To operationalize this vision, we introduce \texttt{R$^2$AI} -- \textit{Resistant and Resilient AI} -- as a practical framework that unites resistance against known threats with resilience to unforeseen risks. \texttt{R$^2$AI} integrates \textit{fast and slow safe models}, adversarial simulation and verification through a \textit{safety wind tunnel}, and continual feedback loops that guide safety and capability to coevolve. We argue that this framework offers a scalable and proactive path to maintain continual safety in dynamic environments, addressing both near-term vulnerabilities and long-term existential risks as AI advances toward AGI and ASI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06782v1" target="_blank">Physics-informed Value Learner for Offline Goal-Conditioned Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Vittorio Giammarino, Ruiqi Ni, Ahmed H. Qureshi</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Offline Goal-Conditioned Reinforcement Learning (GCRL) holds great promise for domains such as autonomous navigation and locomotion, where collecting interactive data is costly and unsafe. However, it remains challenging in practice due to the need to learn from datasets with limited coverage of the state-action space and to generalize across long-horizon tasks. To improve on these challenges, we propose a Physics-informed (Pi) regularized loss for value learning, derived from the Eikonal Partial Differential Equation (PDE) and which induces a geometric inductive bias in the learned value function. Unlike generic gradient penalties that are primarily used to stabilize training, our formulation is grounded in continuous-time optimal control and encourages value functions to align with cost-to-go structures. The proposed regularizer is broadly compatible with temporal-difference-based value learning and can be integrated into existing Offline GCRL algorithms. When combined with Hierarchical Implicit Q-Learning (HIQL), the resulting method, Physics-informed HIQL (Pi-HIQL), yields significant improvements in both performance and generalization, with pronounced gains in stitching regimes and large-scale navigation tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06781v1" target="_blank">UrbanTwin: High-Fidelity Synthetic Replicas of Roadside Lidar Datasets</a></h3>
                    <p><strong>Authors:</strong> Muhammad Shahbaz, Shaurya Agarwal</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This article presents UrbanTwin datasets - high-fidelity, realistic replicas of three public roadside lidar datasets: LUMPI, V2X-Real-IC, and TUMTraf-I. Each UrbanTwin dataset contains 10K annotated frames corresponding to one of the public datasets. Annotations include 3D bounding boxes, instance segmentation labels, and tracking IDs for six object classes, along with semantic segmentation labels for nine classes. These datasets are synthesized using emulated lidar sensors within realistic digital twins, modeled based on surrounding geometry, road alignment at lane level, and the lane topology and vehicle movement patterns at intersections of the actual locations corresponding to each real dataset. Due to the precise digital twin modeling, the synthetic datasets are well aligned with their real counterparts, offering strong standalone and augmentative value for training deep learning models on tasks such as 3D object detection, tracking, and semantic and instance segmentation. We evaluate the alignment of the synthetic replicas through statistical and structural similarity analysis with real data, and further demonstrate their utility by training 3D object detection models solely on synthetic data and testing them on real, unseen data. The high similarity scores and improved detection performance, compared to the models trained on real data, indicate that the UrbanTwin datasets effectively enhance existing benchmark datasets by increasing sample size and scene diversity. In addition, the digital twins can be adapted to test custom scenarios by modifying the design and dynamics of the simulations. To our knowledge, these are the first digitally synthesized datasets that can replace in-domain real-world datasets for lidar perception tasks. UrbanTwin datasets are publicly available at https://dataverse.harvard.edu/dataverse/ucf-ut.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06779v1" target="_blank">A nutritionally informed model for Bayesian variable selection with metabolite response variables</a></h3>
                    <p><strong>Authors:</strong> Dylan Clark-Boucher, Brent A Coull, Harrison T Reeder, Fenglei Wang, Qi Sun, Jacqueline R Starr, Kyu Ha Lee</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> Understanding the pathways through which diet affects human metabolism is a central task in nutritional epidemiology. This article proposes novel methodology to identify food items associated with blood metabolites in two cohorts of healthcare professionals. We analyze 30 food intake variables that exhibit relationship structure through their correlations and nutritional attributes. The metabolic responses include 244 compounds measured by mass spectrometry, presenting substantial challenges that include missingness, left-censoring, and skewness. While existing methods can address such factors in low-dimensional settings, they are not designed for high-dimensional regression involving strongly correlated predictors and non-normal outcomes. To address these challenges, we propose a novel Bayesian variable selection framework for metabolite response variables based on a skew-normal censored mixture model. To exploit substantive information on the nutritional similarities among dietary factors, we employ a Markov random field prior that encourages joint selection of related predictors, while introducing a new, efficient strategy for its hyperparameter specification. Applying this methodology to the cohort data identifies multiple metabolite-diet associations that are consistent with previous research as well as several potentially novel associations that were not detected using standard methods. The proposed approach is implemented in the R package multimetab, facilitating its use in high-dimensional metabolomic analyses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06775v1" target="_blank">Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks</a></h3>
                    <p><strong>Authors:</strong> Po-Heng Chou, Pin-Qi Fu, Walid Saad, Li-Chun Wang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> This paper presents an agentic artificial intelligence (AI)-driven double deep Q-network (DDQN) scheduling framework for licensed and unlicensed band allocation in New Radio (NR) sidelink (SL) networks. SL must share licensed spectrum with cellular communications (CC) and unlicensed bands with Wi-Fi, posing significant challenges for coexistence. Unlike prior rule-based or threshold-based methods, the proposed agentic scheduler autonomously perceives queueing dynamics, channel conditions, and coexistence states, and adapts its policy to maintain quality-of-service (QoS). Simulation results show that our framework reduces the blocking rate by up to 87.5% compared to threshold-based scheduling under limited licensed bandwidth. These findings demonstrate the potential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling for future NR SL systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06774v1" target="_blank">OpenCoderRank: AI-Driven Technical Assessments Made Easy</a></h3>
                    <p><strong>Authors:</strong> Hridoy Sankar Dutta, Sana Ansari, Swati Kumari, Shounak Ravi Bhalerao</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Organizations and educational institutions use time-bound assessment tasks to evaluate coding and problem-solving skills. These assessments measure not only the correctness of the solutions, but also their efficiency. Problem setters (educator/interviewer) are responsible for crafting these challenges, carefully balancing difficulty and relevance to create meaningful evaluation experiences. Conversely, problem solvers (student/interviewee) apply coding efficiency and logical thinking to arrive at correct solutions. In the era of Large Language Models (LLMs), LLMs assist problem setters in generating diverse and challenging questions, but they can undermine assessment integrity for problem solvers by providing easy access to solutions. This paper introduces OpenCoderRank, an easy-to-use platform designed to simulate technical assessments. It acts as a bridge between problem setters and problem solvers, helping solvers prepare for time constraints and unfamiliar problems while allowing setters to self-host assessments, offering a no-cost and customizable solution for technical assessments in resource-constrained environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06771v1" target="_blank">D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning</a></h3>
                    <p><strong>Authors:</strong> Sai Kartheek Reddy Kasu, Mohammad Zia Ur Rehman, Shahid Shafi Dar, Rishi Bharat Junghare, Dhanvin Sanjay Namboodiri, Nagendra Kumar</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Dark humor in online memes poses unique challenges due to its reliance on implicit, sensitive, and culturally contextual cues. To address the lack of resources and methods for detecting dark humor in multimodal content, we introduce a novel dataset of 4,379 Reddit memes annotated for dark humor, target category (gender, mental health, violence, race, disability, and other), and a three-level intensity rating (mild, moderate, severe). Building on this resource, we propose a reasoning-augmented framework that first generates structured explanations for each meme using a Large Vision-Language Model (VLM). Through a Role-Reversal Self-Loop, VLM adopts the authors perspective to iteratively refine its explanations, ensuring completeness and alignment. We then extract textual features from both the OCR transcript and the self-refined reasoning via a text encoder, while visual features are obtained using a vision transformer. A Tri-stream Cross-Reasoning Network (TCRNet) fuses these three streams, text, image, and reasoning, via pairwise attention mechanisms, producing a unified representation for classification. Experimental results demonstrate that our approach outperforms strong baselines across three tasks: dark humor detection, target identification, and intensity prediction. The dataset, annotations, and code are released to facilitate further research in multimodal humor understanding and content moderation. Code and Dataset are available at: https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06768v1" target="_blank">Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots</a></h3>
                    <p><strong>Authors:</strong> Oluwadamilola Sotomi, Devika Kodi, Kiruthiga Chandra Shekar, Aliasghar Arab</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Autonomous robots operating in dynamic environments should identify and report anomalies. Embodying proactive mitigation improves safety and operational continuity. This paper presents a multimodal anomaly detection and mitigation system that integrates vision-language models and large language models to identify and report hazardous situations and conflicts in real-time. The proposed system enables robots to perceive, interpret, report, and if possible respond to urban and environmental anomalies through proactive detection mechanisms and automated mitigation actions. A key contribution in this paper is the integration of Hazardous and Conflict states into the robots decision-making framework, where each anomaly type can trigger specific mitigation strategies. User studies (n = 30) demonstrated the effectiveness of the system in anomaly detection with 91.2% prediction accuracy and relatively low latency response times using edge-ai architecture.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06767v1" target="_blank">Raw2Event: Converting Raw Frame Camera into Event Camera</a></h3>
                    <p><strong>Authors:</strong> Zijie Ning, Enmin Lin, Sudarshan R. Iyengar, Patrick Vandewalle</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Event cameras offer unique advantages such as high temporal resolution, low latency, and high dynamic range, making them more and more popular for vision tasks under challenging light conditions. However, their high cost, limited resolution, and lack of features such as autofocus hinder their broad adoption, particularly for early-stage development and prototyping. In this work, we present Raw2Event, a complete hardware-software system that enables real-time event generation from low-cost raw frame-based cameras. By leveraging direct access to raw Bayer data and bypassing traditional image signal processors (ISP), our system is able to utilize the full potential of camera hardware, delivering higher dynamic range, higher resolution, and more faithful output than RGB-based frame-to-event converters. Built upon the DVS-Voltmeter model, Raw2Event features a configurable simulation framework optimized for deployment on embedded platforms. We further design a data acquisition pipeline that supports synchronized recording of raw, RGB, and event streams, facilitating downstream evaluation and dataset creation. Experimental results show that Raw2Event can generate event streams closely resembling those from real event cameras, while benefiting from higher resolution and autofocus capabilities. The system also supports user-intuitive parameter tuning, enabling flexible adaptation to various application requirements. Finally, we deploy the system on a Raspberry Pi for real-time operation, providing a scalable and cost-effective solution for event-based vision research and early-stage system development. The codes are available online: https://anonymous.4open.science/r/raw2event-BFF2/README.md.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06765v1" target="_blank">Rates of convergence in long time asymptotics of an alignment model with symmetry breaking</a></h3>
                    <p><strong>Authors:</strong> Alexandre Surin</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> math.AP</p>
                    <p><strong>Summary:</strong> We consider a nonlinear Fokker-Planck equation derived from a Cucker-Smale model for flocking with noise. There is a known phase transition depending on the noise between a regime with a unique stationary solution which is isotropic (symmetry) and a regime with a continuum of polarized stationary solutions (symmetry breaking). If the value of the noise is larger than the threshold value, the solution of the evolution equation converges to the unique radial stationary solution. This solution is linearly unstable in the symmetry-breaking range, while polarized stationary solutions attract all solutions with sufficiently low entropy. We prove that the convergence measured in a weighted $L^2$ norm occurs with an exponential rate and that the average speed also converges with exponential rate to a unique limit which determines a single polarized stationary solution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06759v1" target="_blank">Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization</a></h3>
                    <p><strong>Authors:</strong> Thanh Thi Nguyen, Campbell Wilson, Janis Dalins</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Large Vision-Language Models (LVLMs) or multimodal large language models represent a significant advancement in artificial intelligence, enabling systems to understand and generate content across both visual and textual modalities. While large-scale pretraining has driven substantial progress, fine-tuning these models for aligning with human values or engaging in specific tasks or behaviors remains a critical challenge. Deep Reinforcement Learning (DRL) and Direct Preference Optimization (DPO) offer promising frameworks for this aligning process. While DRL enables models to optimize actions using reward signals instead of relying solely on supervised preference data, DPO directly aligns the policy with preferences, eliminating the need for an explicit reward model. This overview explores paradigms for fine-tuning LVLMs, highlighting how DRL and DPO techniques can be used to align models with human preferences and values, improve task performance, and enable adaptive multimodal interaction. We categorize key approaches, examine sources of preference data, reward signals, and discuss open challenges such as scalability, sample efficiency, continual learning, generalization, and safety. The goal is to provide a clear understanding of how DRL and DPO contribute to the evolution of robust and human-aligned LVLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06751v1" target="_blank">RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator</a></h3>
                    <p><strong>Authors:</strong> Weicheng Gao</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> eess.SP, 68T45, I.5.4</p>
                    <p><strong>Summary:</strong> Radar-based human activity recognition (HAR) is a pivotal research area for applications requiring non-invasive monitoring. However, the acquisition of diverse and high-fidelity radar datasets for robust algorithm development remains a significant challenge. To overcome this bottleneck, a model-based frequency-modulated continuous wave (FMCW) radar HAR simulator is developed. The simulator integrates an anthropometrically scaled $13$-scatterer kinematic model to simulate $12$ distinct activities. The FMCW radar echo model is employed, which incorporates dynamic radar cross-section (RCS), free-space or through-the-wall propagation, and a calibrated noise floor to ensure signal fidelity. The simulated raw data is then processed through a complete pipeline, including moving target indication (MTI), bulk Doppler compensation, and Savitzky-Golay denoising, culminating in the generation of high-resolution range-time map (RTM) and Doppler-time maps (DTMs) via both short-time Fourier transform (STFT) and Fourier synchrosqueezed transform (FSST). Finally, a novel neural network method is proposed to validate the effectiveness of the radar HAR. Numerical experiments demonstrate that the simulator successfully generates high-fidelity and distinct micro-Doppler signature, which provides a valuable tool for radar HAR algorithm design and validation. The installer of this simulator is released at: \href{https://github.com/JoeyBGOfficial/RadHARSimulatorV1-Model-Based-FMCW-Radar-Human-Activity-Recognition-Simulator}{Github/JoeyBGOfficial/RadHARSimulatorV1}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06735v1" target="_blank">Data-driven discovery of dynamical models in biology</a></h3>
                    <p><strong>Authors:</strong> Bartosz Prokop, Lendert Gelens</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> q-bio.QM</p>
                    <p><strong>Summary:</strong> Dynamical systems theory describes how interacting quantities change over time and space, from molecular oscillators to large-scale biological patterns. Such systems often involve nonlinear feedbacks, delays, and interactions across scales. Classical modeling derives explicit governing equations, often systems of differential equations, by combining mechanistic assumptions, experimental observations, and known physical laws. The growing complexity of biological processes has, however, motivated complementary data-driven methods that aim to infer model structure directly from measurements, often without specifying equations a priori. In this review, we survey approaches for model discovery in biological dynamical systems, focusing on three methodological families: regression-based methods, network-based architectures, and decomposition techniques. We compare their ability to address three core goals: forecasting future states, identifying interactions, and characterizing system states. Representative methods are applied to a common benchmark, the Oregonator model, a minimal nonlinear oscillator that captures shared design principles of chemical and biological systems. By highlighting strengths, limitations, and interpretability, we aim to guide researchers in selecting tools for analyzing complex, nonlinear, and high-dimensional dynamics in the life sciences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06734v1" target="_blank">Intelligent Manufacturing Support: Specialized LLMs for Composite Material Processing and Equipment Operation</a></h3>
                    <p><strong>Authors:</strong> Gunnika Kapoor, Komal Chawla, Tirthankar Ghosal, Kris Villez, Dan Coughlin, Tyden Rucker, Vincent Paquit, Soydan Ozcan, Seokpum Kim</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> stat.AP</p>
                    <p><strong>Summary:</strong> Engineering educational curriculum and standards cover many material and manufacturing options. However, engineers and designers are often unfamiliar with certain composite materials or manufacturing techniques. Large language models (LLMs) could potentially bridge the gap. Their capacity to store and retrieve data from large databases provides them with a breadth of knowledge across disciplines. However, their generalized knowledge base can lack targeted, industry-specific knowledge. To this end, we present two LLM-based applications based on the GPT-4 architecture: (1) The Composites Guide: a system that provides expert knowledge on composites material and connects users with research and industry professionals who can provide additional support and (2) The Equipment Assistant: a system that provides guidance for manufacturing tool operation and material characterization. By combining the knowledge of general AI models with industry-specific knowledge, both applications are intended to provide more meaningful information for engineers. In this paper, we discuss the development of the applications and evaluate it through a benchmark and two informal user studies. The benchmark analysis uses the Rouge and Bertscore metrics to evaluate our model performance against GPT-4o. The results show that GPT-4o and the proposed models perform similarly or better on the ROUGE and BERTScore metrics. The two user studies supplement this quantitative evaluation by asking experts to provide qualitative and open-ended feedback about our model performance on a set of domain-specific questions. The results of both studies highlight a potential for more detailed and specific responses with the Composites Guide and the Equipment Assistant.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06956v1" target="_blank">H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers</a></h3>
                    <p><strong>Authors:</strong> Wenhao Li, Mengyuan Liu, Hong Liu, Pichao Wang, Shijian Lu, Nicu Sebe</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a hierarchical plug-and-play pruning-and-recovering framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with progressively pruning pose tokens of redundant frames and ends with recovering full-length sequences, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. It works with two key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module (TRM). TPM dynamically selects a few representative tokens to eliminate the redundancy of video frames, while TRM restores the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Our method is general-purpose: it can be easily incorporated into common VPT models on both seq2seq and seq2frame pipelines while effectively accommodating different token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that maintaining the full pose sequence is unnecessary, and a few pose tokens of representative frames can achieve both high efficiency and estimation accuracy. Extensive experiments on multiple benchmark datasets demonstrate both the effectiveness and efficiency of the proposed method. Code and models are available at https://github.com/NationalGAILab/HoT.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06953v1" target="_blank">Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments</a></h3>
                    <p><strong>Authors:</strong> Jiahui Yang, Jason Jingzhou Liu, Yulong Li, Youssef Khaky, Kenneth Shaw, Deepak Pathak</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CV, cs.LG, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs but often struggle to generalize in complex or dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural motion policy designed for reactive motion generation in diverse dynamic environments, operating directly on point cloud sensory input. At its core is IMPACT, a transformer-based neural motion policy pretrained on 10 million generated expert trajectories across diverse simulation scenarios. We further improve IMPACTs static obstacle avoidance through iterative student-teacher finetuning. We additionally enhance the policys dynamic obstacle avoidance at inference time using DCP-RMP, a locally reactive goal-proposal module. We evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving obstacles, and goal obstructions. DRP achieves strong generalization, outperforming prior classical and neural methods in success rate across both simulated and real-world settings. Video results and code available at https://deep-reactive-policy.com</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06952v1" target="_blank">On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts</a></h3>
                    <p><strong>Authors:</strong> Linlu Qiu, Cedegao E. Zhang, Joshua B. Tenenbaum, Yoon Kim, Roger P. Levy</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Language use is shaped by pragmatics -- i.e., reasoning about communicative goals and norms in context. As language models (LMs) are increasingly used as conversational agents, it becomes ever more important to understand their pragmatic reasoning abilities. We propose an evaluation framework derived from Wavelength, a popular communication game where a speaker and a listener communicate about a broad range of concepts in a granular manner. We study a range of LMs on both language comprehension and language production using direct and Chain-of-Thought (CoT) prompting, and further explore a Rational Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM inference. We find that state-of-the-art LMs, but not smaller ones, achieve strong performance on language comprehension, obtaining similar-to-human accuracy and exhibiting high correlations with human judgments even without CoT prompting or RSA. On language production, CoT can outperform direct prompting, and using RSA provides significant improvements over both approaches. Our study helps identify the strengths and limitations in LMs pragmatic reasoning abilities and demonstrates the potential for improving them with RSA, opening up future avenues for understanding conceptual representation, language understanding, and social reasoning in LMs and humans.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06951v1" target="_blank">F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions</a></h3>
                    <p><strong>Authors:</strong> Qi Lv, Weijie Kong, Hao Li, Jia Zeng, Zherui Qiu, Delin Qu, Haoming Song, Qizhi Chen, Xiang Deng, Jiangmiao Pang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Executing language-conditioned tasks in dynamic visual environments remains a central challenge in embodied AI. Existing Vision-Language-Action (VLA) models predominantly adopt reactive state-to-action mappings, often leading to short-sighted behaviors and poor robustness in dynamic scenes. In this paper, we introduce F1, a pretrained VLA framework which integrates the visual foresight generation into decision-making pipeline. F1 adopts a Mixture-of-Transformer architecture with dedicated modules for perception, foresight generation, and control, thereby bridging understanding, generation, and actions. At its core, F1 employs a next-scale prediction mechanism to synthesize goal-conditioned visual foresight as explicit planning targets. By forecasting plausible future visual states, F1 reformulates action generation as a foresight-guided inverse dynamics problem, enabling actions that implicitly achieve visual goals. To endow F1 with robust and generalizable capabilities, we propose a three-stage training recipe on an extensive dataset comprising over 330k trajectories across 136 diverse tasks. This training scheme enhances modular reasoning and equips the model with transferable visual foresight, which is critical for complex and dynamic environments. Extensive evaluations on real-world tasks and simulation benchmarks demonstrate F1 consistently outperforms existing approaches, achieving substantial gains in both task success rate and generalization ability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06949v1" target="_blank">Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it can also be applied to adapt block-specific models to larger blocks, which improves sampling flexibility. Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still consistently outperforms them across complex math reasoning tasks. TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical reasoning benchmarks. Through curriculum learning, we also derive the first long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1% relative accuracy gain. To facilitate reproducible research and practical applications, we release a comprehensive open-source framework for building, training, and deploying diffusion LLMs across diverse architectures. The framework integrates accelerated KV-cache techniques and inference engines for both inference and reinforcement learning, and includes implementations of various supervised fine-tuning and RL methods for mathematics, coding, and general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06950v1" target="_blank">Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data</a></h3>
                    <p><strong>Authors:</strong> Nithin Gopalakrishnan Nair, Srinivas Kaza, Xuan Luo, Vishal M. Patel, Stephen Lombardi, Jungyeon Park</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV</p>
                    <p><strong>Summary:</strong> Large transformer-based models have made significant progress in generalizable novel view synthesis (NVS) from sparse input views, generating novel viewpoints without the need for test-time optimization. However, these models are constrained by the limited diversity of publicly available scene datasets, making most real-world (in-the-wild) scenes out-of-distribution. To overcome this, we incorporate synthetic training data generated from diffusion models, which improves generalization across unseen domains. While synthetic data offers scalability, we identify artifacts introduced during data generation as a key bottleneck affecting reconstruction quality. To address this, we propose a token disentanglement process within the transformer architecture, enhancing feature separation and ensuring more effective learning. This refinement not only improves reconstruction quality over standard transformers but also enables scalable training with synthetic data. As a result, our method outperforms existing models on both in-dataset and cross-dataset evaluations, achieving state-of-the-art results across multiple benchmarks while significantly reducing computational costs. Project page: https://scaling3dnvs.github.io/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06948v1" target="_blank">Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning</a></h3>
                    <p><strong>Authors:</strong> Liang Chen, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this decoupled two-stage approach limits interaction between SFT and RL, thereby constraining overall effectiveness. This study introduces a novel method for learning reasoning models that employs bilevel optimization to facilitate better cooperation between these training paradigms. By conditioning the SFT objective on the optimal RL policy, our approach enables SFT to meta-learn how to guide RLs optimization process. During training, the lower level performs RL updates while simultaneously receiving SFT supervision, and the upper level explicitly maximizes the cooperative gain-the performance advantage of joint SFT-RL training over RL alone. Empirical evaluations on five reasoning benchmarks demonstrate that our method consistently outperforms baselines and achieves a better balance between effectiveness and efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06947v1" target="_blank">Towards effective models for low-dimensional cuprates: From ground state Hamiltonian reconstruction to spectral functions</a></h3>
                    <p><strong>Authors:</strong> Hannah Lange, Tizian Blatz, Ulrich SchollwÃ¶ck, Sebastian Paeckel, Annabelle Bohrdt</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.quant-gas, cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> Understanding which minimal effective model captures the essential physics of cuprates is a key step towards unraveling the mechanism behind high-$T_c$ superconductivity. Recent measurements of the dynamical spin structure factor (DSF) in cuprate ladder compounds have indicated the presence of a large effective attraction in the single-band Hubbard model, possibly mediated by phonons. Here, we demonstrate that similar DSF features can also be captured by $t$-$J$ descriptions with or even without any attractive term. Motivated by this observation, we systematically investigate the strength and origin of different contributions to the single-band Hamiltonians by downfolding either from the three-band Emery model or the electron-phonon coupled Hubbard-Holstein model. For one-dimensional systems, we find that the extended versions of both single-band descriptions can reproduce the experimentally observed DSF signatures. Finally, we extend our analysis to two dimensions by comparing two-hole correlation functions for the different single-band models. Our results provide new insights into the long-standing question of which single-band Hamiltonian can capture the essential physics of cuprates.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06946v1" target="_blank">Mechanisms of Anomalous Three-Body Loss in a Population Imbalanced Three-Component Fermi Gas</a></h3>
                    <p><strong>Authors:</strong> Kajsa-My Tempest, Chris H. Greene</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas, physics.atom-ph</p>
                    <p><strong>Summary:</strong> Achieving precise control of ultracold atomic gases requires a detailed understanding of atom loss mechanisms. Motivated by the anomalous three-body decay in a three-component Fermi gas reported in Ref. [1], this work investigates mechanisms that possibly contribute to the observed loss. The three-body Schr\odinger equation is solved in the hyperspherical adiabatic representation with pairwise van der Waals interactions, and the $S$-matrix is obtained via the eigenchannel $R$-matrix method to compute recombination rate coefficients $K_3$ and two-body cross sections. At the magnetic field strength where the anomalous decay occurs, $K_3$ is unitary limited, exhibiting the threshold energy scaling $K_3(E)\propto E^{-1}$. Consequently, the thermally averaged $\langle K_3 \rangle$ acquires a temperature dependence. Because the experiment is performed in the degenerate regime, $\langle K_3 \rangle$ also explicitly depends on the per-spin densities through the per-spin Fermi energies $E_{F}^{(i)}\propto n_i^{2/3}$. As the gas is diluted and degeneracy is reduced, $\langle K_3 \rangle$ approaches the non-degenerate value and becomes a function of temperature only. Channel-resolved branching ratios and cross sections are folded into a Monte Carlo cascade simulation of secondary collisions and trap escape. The analysis indicates that typical three-body recombination events remove fewer than three atoms on average, and that the atom losses are primarily due to the ejection of secondary collision products, rather than the initial three-body recombination products. Therefore, a significant fraction of the released binding energy remains in the trapped ensemble as kinetic energy. Retained energy drives evaporative loss, offering a plausible, partial explanation for the anomalous decay.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06945v1" target="_blank">Interleaving Reasoning for Better Text-to-Image Generation</a></h3>
                    <p><strong>Authors:</strong> Wenxuan Huang, Shuang Chen, Zheyong Xie, Shaosheng Cao, Shixiang Tang, Yufan Shen, Qingyu Yin, Wenbo Hu, Xiaoman Wang, Yuntian Tang, Junbo Qiao, Yue Guo, Yao Hu, Zhenfei Yin, Philip Torr, Yu Cheng, Wanli Ouyang, Shaohui Lin</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Unified multimodal understanding and generation models recently have achieve significant improvement in image generation capability, yet a large gap remains in instruction following and detail preservation compared to systems that tightly couple comprehension with generation such as GPT-4o. Motivated by recent advances in interleaving reasoning, we explore whether such reasoning can further improve Text-to-Image (T2I) generation. We introduce Interleaving Reasoning Generation (IRG), a framework that alternates between text-based thinking and image synthesis: the model first produces a text-based thinking to guide an initial image, then reflects on the result to refine fine-grained details, visual quality, and aesthetics while preserving semantics. To train IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL), which targets two sub-goals: (1) strengthening the initial think-and-generate stage to establish core content and base quality, and (2) enabling high-quality textual reflection and faithful implementation of those refinements in a subsequent image. We curate IRGL-300K, a dataset organized into six decomposed learning modes that jointly cover learning text-based thinking, and full thinking-image trajectories. Starting from a unified foundation model that natively emits interleaved text-image outputs, our two-stage training first builds robust thinking and reflection, then efficiently tunes the IRG pipeline in the full thinking-image trajectory data. Extensive experiments show SoTA performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF, GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality and fine-grained fidelity. The code, model weights and datasets will be released in: https://github.com/Osilly/Interleaving-Reasoning-Generation .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06944v1" target="_blank">Tropical Toeplitz matrices and parametrisations</a></h3>
                    <p><strong>Authors:</strong> Konstanze Rietsch</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> math.RT</p>
                    <p><strong>Summary:</strong> The set of infinite upper-triangular totally positive Toeplitz matrices has a classical parametrisation proved by Edrei et al and originally conjectured by Schoenberg, that involves pairs of sequences of positive real parameters. These matrices (and their parameters) are central for understanding characters of the infinite symmetric group by work of Thoma. On the other hand there is a very different parametrisation theorem that applies to the finite analogue of this set. These finite Toeplitz matrices and their parameters relate to quantum cohomology of flag varieties and mirror symmetry. In this paper we replace the positive reals by a semifield with valuation to then construct tropical analogues for both parametrisation theorems. In the finite case we tropicalise using positive generalised Puiseaux series. This builds on work of Judd and L\udenbach. In the infinite case we use a new valued semifield of continuous functions. We arrive at different natural infinite analogues of totally positive Toeplitz matrices, depending on a choice of topology on our valued semifield. We then prove an asymptotic result relating the tropical parameters from the finite case to the tropicalisations of the Schoenberg parameters. Moreover, we show that our finite type tropical parametrisation map is given by Lusztigs weight map from the theory of canonical bases. This results in a surprising connection between the classical Edrei theorem with its Schoenberg parameters and Lusztigs canonical basis parametrisation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06942v1" target="_blank">Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference</a></h3>
                    <p><strong>Authors:</strong> Xiangwei Shen, Zhimin Li, Zhantao Yang, Shiyi Zhang, Yingfang Zhang, Donghao Li, Chunyu Wang, Qinglin Lu, Yansong Tang</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Recent studies have demonstrated the effectiveness of directly aligning diffusion models with human preferences using differentiable reward. However, they exhibit two primary challenges: (1) they rely on multistep denoising with gradient computation for reward scoring, which is computationally expensive, thus restricting optimization to only a few diffusion steps; (2) they often need continuous offline adaptation of reward models in order to achieve desired aesthetic quality, such as photorealism or precise lighting effects. To address the limitation of multistep denoising, we propose Direct-Align, a method that predefines a noise prior to effectively recover original images from any time steps via interpolation, leveraging the equation that diffusion states are interpolations between noise and target images, which effectively avoids over-optimization in late timesteps. Furthermore, we introduce Semantic Relative Preference Optimization (SRPO), in which rewards are formulated as text-conditioned signals. This approach enables online adjustment of rewards in response to positive and negative prompt augmentation, thereby reducing the reliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model with optimized denoising and online reward adjustment, we improve its human-evaluated realism and aesthetic quality by over 3x.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06941v1" target="_blank">Outcome-based Exploration for LLM Reasoning</a></h3>
                    <p><strong>Authors:</strong> Yuda Song, Julia Kempe, Remi Munos</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement learning (RL) has emerged as a powerful method for improving the reasoning abilities of large language models (LLMs). Outcome-based RL, which rewards policies solely for the correctness of the final answer, yields substantial accuracy gains but also induces a systematic loss in generation diversity. This collapse undermines real-world performance, where diversity is critical for test-time scaling. We analyze this phenomenon by viewing RL post-training as a sampling process and show that, strikingly, RL can reduce effective diversity even on the training set relative to the base model. Our study highlights two central findings: (i) a transfer of diversity degradation, where reduced diversity on solved problems propagates to unsolved ones, and (ii) the tractability of the outcome space, since reasoning tasks admit only a limited set of distinct answers. Motivated by these insights, we propose outcome-based exploration, which assigns exploration bonuses according to final outcomes. We introduce two complementary algorithms: historical exploration, which encourages rarely observed answers via UCB-style bonuses, and batch exploration, which penalizes within-batch repetition to promote test-time diversity. Experiments on standard competition math with Llama and Qwen models demonstrate that both methods improve accuracy while mitigating diversity collapse. On the theoretical side, we formalize the benefit of outcome-based exploration through a new model of outcome-based bandits. Together, these contributions chart a practical path toward RL methods that enhance reasoning without sacrificing the diversity essential for scalable deployment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06940v1" target="_blank">The Linear System Package of Magma</a></h3>
                    <p><strong>Authors:</strong> Carlos Rito</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> math.AG, Primary 14-04, Secondary 14Q05, 14Q10, 14Q15</p>
                    <p><strong>Summary:</strong> We present a complete reimplementation of the LinearSystem package of Magma, with substantial improvements in design and performance. The resulting efficiency enables computations that were previously out of reach. We briefly describe the design principles, capabilities, and algorithms of the new implementation and illustrate them with examples that showcase its power. Rather than comparing speeds, our goal is to advertise the package by demonstrating what can now be achieved in practice. We also add one core capability: computing linear systems of plane curves with prescribed non-ordinary singularities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06937v1" target="_blank">Quantum Mpemba effect in a four-site Bose-Hubbard model</a></h3>
                    <p><strong>Authors:</strong> Asad Ali, M. I. Hussain, Hamid Arian Zad, H. Kuniyil, M. T. Rahim, Saif Al-Kuwari, Saeed Haddadi</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas, quant-ph</p>
                    <p><strong>Summary:</strong> We investigated the quantum Mpemba effect (QME) in a one-dimensional Bose-Hubbard model across clean and disordered regimes using exact numerical technique of a four-site lattice under Lindblad dynamics with local dephasing noise. By systematically varying hopping strength, onsite interactions, Stark potentials, and random disorder, we probe relaxation dynamics toward a common steady state using trace distance, relative entropy, entanglement asymmetry, and $\ell_1$-norm of coherence metrics. Our results reveal that QME emerges prominently in the clean-interacting regime, where many-body correlations drive nonlinear relaxation pathways, enabling initially distant states to overtake closer ones. In contrast, non-interacting systems exhibit conventional thermalization, whereas Stark potentials and random disorder suppress QME by inducing localization barriers, with disorder causing milder delays compared to the pronounced effects of Stark fields. Entanglement asymmetry proves to be particularly sensitive to the symmetry restoration dynamics underlying QME. These findings elucidate the critical role of interactions in anomalous relaxation and provide insights for controlling quantum thermalization in experimental platforms such as ultra-cold atomic systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06936v1" target="_blank">Benchmarking Music Autotagging with MGPHot Expert Annotations vs. Generic Tag Datasets</a></h3>
                    <p><strong>Authors:</strong> Pedro Ramoneda, Pablo Alonso-JimÃ©nez, Sergio Oramas, Xavier Serra, Dmitry Bogdanov</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> Music autotagging aims to automatically assign descriptive tags, such as genre, mood, or instrumentation, to audio recordings. Due to its challenges, diversity of semantic descriptions, and practical value in various applications, it has become a common downstream task for evaluating the performance of general-purpose music representations learned from audio data. We introduce a new benchmarking dataset based on the recently published MGPHot dataset, which includes expert musicological annotations, allowing for additional insights and comparisons with results obtained on common generic tag datasets. While MGPHot annotations have been shown to be useful for computational musicology, the original dataset neither includes audio nor provides evaluation setups for its use as a standardized autotagging benchmark. To address this, we provide a curated set of YouTube URLs with retrievable audio, and propose a train/val/test split for standardized evaluation, and precomputed representations for seven state-of-the-art models. Using these resources, we evaluated these models in MGPHot and standard reference tag datasets, highlighting key differences between expert and generic tag annotations. Altogether, our contributions provide a more advanced benchmarking framework for future research in music understanding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06932v1" target="_blank">LLaDA-VLA: Vision Language Diffusion Action Models</a></h3>
                    <p><strong>Authors:</strong> Yuqing Wen, Hebei Li, Kefan Gu, Yucheng Zhao, Tiancai Wang, Xiaoyan Sun</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> The rapid progress of auto-regressive vision-language models (VLMs) has inspired growing interest in vision-language-action models (VLA) for robotic manipulation. Recently, masked diffusion models, a paradigm distinct from autoregressive models, have begun to demonstrate competitive performance in text generation and multimodal applications, leading to the development of a series of diffusion-based VLMs (d-VLMs). However, leveraging such models for robot policy learning remains largely unexplored. In this work, we present LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to robotic domain, we introduce two key designs: (1) a localized special-token classification strategy that replaces full-vocabulary classification with special action token classification, reducing adaptation difficulty; (2) a hierarchical action-structured decoding strategy that decodes action sequences hierarchically considering the dependencies within and across actions. Extensive experiments demonstrate that LLaDA-VLA significantly outperforms state-of-the-art VLAs on both simulation and real-world robots.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06928v1" target="_blank">On the Bit Size of Sum-of-Squares Proofs for Symmetric Formulations</a></h3>
                    <p><strong>Authors:</strong> Alex Bortolotti, Monaldo Mastrolilli, Marilena Palomba, Luis Felipe Vargas</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CC</p>
                    <p><strong>Summary:</strong> The Sum-of-Squares (SoS) hierarchy is a powerful framework for polynomial optimization and proof complexity, offering tight semidefinite relaxations that capture many classical algorithms. Despite its broad applicability, several works have revealed fundamental limitations to SoS automatability. (i) While low-degree SoS proofs are often desirable for tractability, recent works have revealed they may require coefficients of prohibitively large bit size, rendering them computationally infeasible. (ii) Prior works have shown that SoS proofs for seemingly easy problems require high-degree. In particular, this phenomenon also arises in highly symmetric problems. Instances of symmetric problems-particularly those with a small number of constraints-have repeatedly served as benchmarks for establishing high-degree lower bounds in the SoS hierarchy. It has remained unclear whether symmetry can also lead to large bit sizes in SoS proofs, potentially making low-degree proofs computationally infeasible even in symmetric settings. In this work, we resolve this question by proving that symmetry alone does not lead to large bit size SoS proofs. Focusing on symmetric Archimedean instances, we show that low-degree SoS proofs for such systems admit compact, low bit size representations. Together, these results provide a conceptual separation between two sources of SoS hardness-degree and bit size-by showing they do not necessarily align, even in highly symmetric instances. This insight guides future work on automatability and lower bounds: symmetry may necessitate high-degree proofs, but it does not by itself force large coefficients.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06927v1" target="_blank">NeedForHeat DataGear: An Open Monitoring System to Accelerate the Residential Heating Transition</a></h3>
                    <p><strong>Authors:</strong> Henri ter Hofte, Nick van Ravenzwaaij</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> We introduce NeedForHeat DataGear: an open hardware and open software data collection system designed to accelerate the residential heating transition. NeedForHeat DataGear collects time series monitoring data in homes that have not yet undergone a heating transition, enabling assessment of real-life thermal characteristics, heating system efficiency, and residents comfort needs. This paper outlines its architecture and functionalities, emphasizing its modularity, adaptability, and cost-effectiveness for field data acquisition. Unlike conventional domestic monitoring solutions focused on home automation, direct feedback, or post-installation heat pump monitoring, it prioritizes time series data we deemed essential to evaluate the current situation in existing homes before the heating transition. Designed for seamless deployment across diverse households, NeedForHeat DataGear combines openness, security, and privacy with a low-cost, user-friendly approach, making it a valuable tool for researchers, energy professionals, and energy coaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06926v1" target="_blank">Continuous Audio Language Models</a></h3>
                    <p><strong>Authors:</strong> Rouard Simon, Orsini Manu, Roebel Axel, Zeghidour Neil, DÃ©fossez Alexandre</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> Audio Language Models (ALM) have emerged as the dominant paradigm for speech and music generation by representing audio as sequences of discrete tokens. Yet, unlike text tokens, which are invertible, audio tokens are extracted from lossy codecs with a limited bitrate. As a consequence, increasing audio quality requires generating more tokens, which imposes a trade-off between fidelity and computational cost. We address this issue by studying Continuous Audio Language Models (CALM). These models instantiate a large Transformer backbone that produces a contextual embedding at every timestep. This sequential information then conditions an MLP that generates the next continuous frame of an audio VAE through consistency modeling. By avoiding lossy compression, CALM achieves higher quality at lower computational cost than their discrete counterpart. Experiments on speech and music demonstrate improved efficiency and fidelity over state-of-the-art discrete audio language models, facilitating lightweight, high-quality audio generation. Samples are available at https://continuous-audio-language-models.github.io</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06921v1" target="_blank">Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities</a></h3>
                    <p><strong>Authors:</strong> Safayat Bin Hakim, Muhammad Adil, Alvaro Velasquez, Shouhuai Xu, Houbing Herbert Song</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit fundamental limitations: inadequate conceptual grounding leading to non-robustness against novel attacks; limited instructibility impeding analyst-guided adaptation; and misalignment with cybersecurity objectives. Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize cybersecurity AI. However, there is no systematic understanding of this emerging approach. These hybrid systems address critical cybersecurity challenges by combining neural pattern recognition with symbolic reasoning, enabling enhanced threat understanding while introducing concerning autonomous offensive capabilities that reshape threat landscapes. In this survey, we systematically characterize this field by analyzing 127 publications spanning 2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A) framework to evaluate these systems, focusing on both cyber defense and cyber offense across network security, malware analysis, and cyber operations. Our analysis shows advantages of multi-agent NeSy architectures and identifies critical implementation challenges including standardization gaps, computational complexity, and human-AI collaboration requirements that constrain deployment. We show that causal reasoning integration is the most transformative advancement, enabling proactive defense beyond correlation-based approaches. Our findings highlight dual-use implications where autonomous systems demonstrate substantial capabilities in zero-day exploitation while achieving significant cost reductions, altering threat dynamics. We provide insights and future research directions, emphasizing the urgent need for community-driven standardization frameworks and responsible development practices that ensure advancement serves defensive cybersecurity objectives while maintaining societal alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06920v1" target="_blank">An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection</a></h3>
                    <p><strong>Authors:</strong> Haywood Gelman, John D. Hastings, David Kenley</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.CL, cs.CY, C.2.0; I.2.7; K.4.1; H.3.3</p>
                    <p><strong>Summary:</strong> Insider threats are a growing organizational problem due to the complexity of identifying their technical and behavioral elements. A large research body is dedicated to the study of insider threats from technological, psychological, and educational perspectives. However, research in this domain has been generally dependent on datasets that are static and limited access which restricts the development of adaptive detection models. This study introduces a novel, ethically grounded approach that uses the large language model (LLM) Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which contain indicators of insider threat scenarios. The messages reflect real-world data distributions by being highly imbalanced (1% insider threats). The syslogs were analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with their performance evaluated through statistical metrics including precision, recall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across nearly all metrics, particularly in reducing false alarms and improving detection accuracy. The results show strong promise for the use of LLMs in synthetic dataset generation and insider threat detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06917v1" target="_blank">Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents</a></h3>
                    <p><strong>Authors:</strong> Jiacheng Miao, Joe R. Davis, Jonathan K. Pritchard, James Zou</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a papers code, data, and methods to their own work, creating barriers to dissemination and reuse. Paper2Agent addresses this challenge by automatically converting a paper into an AI agent that acts as a knowledgeable research assistant. It systematically analyzes the paper and the associated codebase using multiple agents to construct a Model Context Protocol (MCP) server, then iteratively generates and runs tests to refine and robustify the resulting MCP. These paper MCPs can then be flexibly connected to a chat agent (e.g. Claude Code) to carry out complex scientific queries through natural language while invoking tools and workflows from the original paper. We demonstrate Paper2Agents effectiveness in creating reliable and capable paper agents through in-depth case studies. Paper2Agent created an agent that leverages AlphaGenome to interpret genomic variants and agents based on ScanPy and TISSUE to carry out single-cell and spatial transcriptomics analyses. We validate that these paper agents can reproduce the original papers results and can correctly carry out novel user queries. By turning static papers into dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for knowledge dissemination and a foundation for the collaborative ecosystem of AI co-scientists.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06916v1" target="_blank">Renormalizable quantum field theory in curved spacetime with external two-form field</a></h3>
                    <p><strong>Authors:</strong> Ioseph L. Buchbinder, Thomas M. Sangy, Ilya L. Shapiro</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> We argue that the renormalizability of interacting quantum field theory on the curved-space background with an additional external antisymmetric tensor (two-form) field requires nonminimal interaction of the antisymmetric field with quantum fermions and scalars. The situation is qualitatively similar to the metric and torsion background. In both cases, one can explore the renormalization group running for the parameters of nonminimal interaction and see how this interaction behaves in the UV limit. General considerations are confirmed by the one-loop calculations in the well-known gauge model based on the $SU(2)$ gauge group.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06907v1" target="_blank">FoMo4Wheat: Toward reliable crop vision foundation models with globally curated data</a></h3>
                    <p><strong>Authors:</strong> Bing Han, Chen Zhu, Dong Han, Rui Yu, Songliang Cao, Jianhui Wu, Scott Chapman, Zijian Wang, Bangyou Zheng, Wei Guo, Marie Weiss, Benoit de Solan, Andreas Hund, Lukas Roth, Kirchgessner Norbert, Andrea Visioni, Yufeng Ge, Wenjuan Li, Alexis Comar, Dong Jiang, Dejun Han, Fred Baret, Yanfeng Ding, Hao Lu, Shouyang Liu</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Vision-driven field monitoring is central to digital agriculture, yet models built on general-domain pretrained backbones often fail to generalize across tasks, owing to the interaction of fine, variable canopy structures with fluctuating field conditions. We present FoMo4Wheat, one of the first crop-domain vision foundation model pretrained with self-supervision on ImAg4Wheat, the largest and most diverse wheat image dataset to date (2.5 million high-resolution images collected over a decade at 30 global sites, spanning 2,000 genotypes and 500 environmental conditions). This wheat-specific pretraining yields representations that are robust for wheat and transferable to other crops and weeds. Across ten in-field vision tasks at canopy and organ levels, FoMo4Wheat models consistently outperform state-of-the-art models pretrained on general-domain dataset. These results demonstrate the value of crop-specific foundation models for reliable in-field perception and chart a path toward a universal crop foundation model with cross-species and cross-task capabilities. FoMo4Wheat models and the ImAg4Wheat dataset are publicly available online: https://github.com/PheniX-Lab/FoMo4Wheat and https://huggingface.co/PheniX-Lab/FoMo4Wheat. The demonstration website is: https://fomo4wheat.phenix-lab.com/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06905v1" target="_blank">Yet another exponential Hopfield model</a></h3>
                    <p><strong>Authors:</strong> Linda Albanese, Andrea Alessandrelli, Adriano Barra, Peter Sollich</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cond-mat.dis-nn</p>
                    <p><strong>Summary:</strong> We propose and analyze a new variation of the so-called {\em exponential Hopfield model}, a recently introduced family of associative neural networks with unprecedented storage capacity. Our construction is based on a cost function defined through exponentials of standard quadratic loss functions, which naturally favors configurations corresponding to perfect recall. Despite not being a mean-field system, the model admits a tractable mathematical analysis of its dynamics and retrieval properties that agree with those for the original exponential model introduced by Ramsauer and coworkers. By means of a signal-to-noise approach, we demonstrate that stored patterns remain stable fixed points of the zero-temperature dynamics up to an exponentially large number of patterns in the system size. We further quantify the basins of attraction of the retrieved memories, showing that while enlarging their radius reduces the overall load, the storage capacity nonetheless retains its exponential scaling. An independent derivation within the perfect recall regime confirms these results and provides an estimate of the relevant prefactors. Our findings thus complement and extend previous studies on exponential Hopfield networks, establishing that even under robustness constraints these models preserve their exceptional storage capabilities. Beyond their theoretical interest, such networks point towards principled mechanisms for massively scalable associative memory, with potential implications for both neuroscience-inspired computation and high-capacity machine learning architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06904v1" target="_blank">BIR-Adapter: A Low-Complexity Diffusion Model Adapter for Blind Image Restoration</a></h3>
                    <p><strong>Authors:</strong> Cem Eteke, Alexander Griessel, Wolfgang Kellerer, Eckehard Steinbach</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper introduces BIR-Adapter, a low-complexity blind image restoration adapter for diffusion models. The BIR-Adapter enables the utilization of the prior of pre-trained large-scale diffusion models on blind image restoration without training any auxiliary feature extractor. We take advantage of the robustness of pretrained models. We extract features from degraded images via the model itself and extend the self-attention mechanism with these degraded features. We introduce a sampling guidance mechanism to reduce hallucinations. We perform experiments on synthetic and real-world degradations and demonstrate that BIR-Adapter achieves competitive or better performance compared to state-of-the-art methods while having significantly lower complexity. Additionally, its adapter-based design enables integration into other diffusion models, enabling broader applications in image restoration tasks. We showcase this by extending a super-resolution-only model to perform better under additional unknown degradations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06903v1" target="_blank">PowerBin: Fast Adaptive Data Binning with Centroidal Power Diagrams</a></h3>
                    <p><strong>Authors:</strong> Michele Cappellari</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM</p>
                    <p><strong>Summary:</strong> Adaptive binning is a crucial step in the analysis of large astronomical datasets, such as those from integral-field spectroscopy, to ensure a sufficient signal-to-noise ratio (S/N) for reliable model fitting. However, the widely used Voronoi-binning method and its variants suffer from two key limitations: they scale poorly with data size, often as O(N^2), creating a computational bottleneck for modern surveys, and they can produce undesirable non-convex or disconnected bins. I introduce PowerBin, a new algorithm that overcomes these issues. I frame the binning problem within the theory of optimal transport, for which the solution is a Centroidal Power Diagram (CPD), guaranteeing convex bins. Instead of formal CPD solvers, which are unstable with real data, I develop a fast and robust heuristic based on a physical analogy of packed soap bubbles. This method reliably enforces capacity constraints even for non-additive measures like S/N with correlated noise. I also present a new bin-accretion algorithm with O(N log N) complexity, removing the previous bottleneck. The combined PowerBin algorithm scales as O(N log N), making it about two orders of magnitude faster than previous methods on million-pixel datasets. I demonstrate its performance on a range of simulated and real data, showing it produces high-quality, convex tessellations with excellent S/N uniformity. The public Python implementation provides a fast, robust, and scalable tool for the analysis of modern astronomical data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06902v1" target="_blank">Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification</a></h3>
                    <p><strong>Authors:</strong> Aivin V. Solatorio</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CR, cs.DB, cs.LG</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) as stochastic systems may generate numbers that deviate from available data, a failure known as \emph{numeric hallucination}. Existing safeguards -- retrieval-augmented generation, citations, and uncertainty estimation -- improve transparency but cannot guarantee fidelity: fabricated or misquoted values may still be displayed as if correct. We propose \textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that enforces numeric fidelity through mechanical verification. Under PCN, numeric spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a verifier checks each token under a declared policy (e.g., exact equality, rounding, aliases, or tolerance with qualifiers). Crucially, PCN places verification in the \emph{renderer}, not the model: only claim-checked numbers are marked as verified, and all others default to unverified. This separation prevents spoofing and guarantees fail-closed behavior. We formalize PCN and prove soundness, completeness under honest tokens, fail-closed behavior, and monotonicity under policy refinement. PCN is lightweight and model-agnostic, integrates seamlessly into existing applications, and can be extended with cryptographic commitments. By enforcing verification as a mandatory step before display, PCN establishes a simple contract for numerically sensitive settings: \emph{trust is earned only by proof}, while the absence of a mark communicates uncertainty.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06901v1" target="_blank">Machine Learning Assisted Parameter-Space Searches for Lensed Gravitational Waves</a></h3>
                    <p><strong>Authors:</strong> Giulia Campailla, Marco Raveri, Wayne Hu, Jose MarÃ­a Ezquiaga</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.CO</p>
                    <p><strong>Summary:</strong> When a gravitational wave encounters a massive object along the line of sight, repeated copies of the original signal may be produced due to gravitational lensing. In this paper, we develop a series of new machine-learning based statistical methods to identify promising strong lensing candidates in gravitational wave catalogs. We employ state-of-the-art normalizing flow generative models to perform statistical calculations on the posterior distributions of gravitational wave events that would otherwise be computationally unfeasible. Our lensing identification strategy, developed on two simulated gravitational wave catalogs that test noise realization and event signal variations, selects event pairs with low parameter differences in the optimal detector basis that also have a high information content and favorable likelihood for coincident parameters. We then apply our method to the GWTC-3 catalog and find a single pair still consistent with the lensing hypothesis. This pair has been previously identified through more costly evidence ratio techniques, but rejected on astrophysical grounds, which further validates our technique.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06897v1" target="_blank">Flux Switching Floquet Engineering</a></h3>
                    <p><strong>Authors:</strong> Ian Powell, Louis Buchalter</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cond-mat.other, quant-ph</p>
                    <p><strong>Summary:</strong> We present an analysis of a square-lattice Harper-Hofstadter model with a periodically varying magnetic flux with time. By switching the dimensionless flux per plaquette between a set of values $\{p_j/q_j\}$ the Floquet quasienergy spectrum is folded into Q = lcm$\{q_j\}$ bands. We determine closed form analytical solutions for the quasienergy spectrum and Chern numbers for the -1/2 $\to$ 1/2 flux switching case, as well as the Rudner-Lindner-Berg-Levin (RLBL) winding invariants W numerically, and construct the corresponding topological phase diagram for arbitrary driving period. We find that generic flux-switching drives feature interlaced Hofstadter butterfly quasienergy spectra, and the gaps in the spectrum may be labeled according to a Diophantine equation which relates the quasienergy gap index to the fluxes attained in the drive and their associated per-step windings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06891v1" target="_blank">Tensor Network based Gene Regulatory Network Inference for Single-Cell Transcriptomic Data</a></h3>
                    <p><strong>Authors:</strong> Olatz Sanz Larrarte, Borja Aizpurua, Reza Dastbasteh, Ruben M. Otxoa, Josu Etxezarreta Martinez</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> q-bio.MN, quant-ph</p>
                    <p><strong>Summary:</strong> Deciphering complex gene-gene interactions remains challenging in transcriptomics as traditional methods often miss higher-order and nonlinear dependencies. This study introduces a quantum-inspired framework leveraging tensor networks (TNs) to optimally map expression data into a lower dimensional representation preserving biological locality. Using Quantum Mutual Information (QMI), a nonparametric measure natural for tensor networks, we quantify gene dependencies and establish statistical significance via permutation testing. This constructs robust interaction networks where the edges reflect biologically meaningful relationships that are resilient to random chance. The approach effectively distinguishes true regulatory patterns from experimental noise and biological stochasticity. To test the proposed method, we recover a gene regulatory network consisted of six pathway genes from single-cell RNA sequencing data comprising over $28.000$ lymphoblastoid cells. Furthermore, we unveil several triadic regulatory mechanisms. By merging quantum physics inspired techniques with computational biology, our method provides novel insights into gene regulation, with applications in disease mechanisms and precision medicine.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06890v1" target="_blank">Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization</a></h3>
                    <p><strong>Authors:</strong> Minheng Chen, Youyong Kong</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> Intraoperative 2D/3D registration aligns preoperative 3D volumes with real-time 2D radiographs, enabling accurate localization of instruments and implants. A recent fully differentiable similarity learning framework approximates geodesic distances on SE(3), expanding the capture range of registration and mitigating the effects of substantial disturbances, but existing Euclidean approximations distort manifold structure and slow convergence. To address these limitations, we explore similarity learning in non-Euclidean spherical feature spaces to better capture and fit complex manifold structure. We extract feature embeddings using a CNN-Transformer encoder, project them into spherical space, and approximate their geodesic distances with Riemannian distances in the bi-invariant SO(4) space. This enables a more expressive and geometrically consistent deep similarity metric, enhancing the ability to distinguish subtle pose differences. During inference, we replace gradient descent with fully differentiable Levenberg-Marquardt optimization to accelerate convergence. Experiments on real and synthetic datasets show superior accuracy in both patient-specific and patient-agnostic scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06888v1" target="_blank">mmBERT: A Modern Multilingual Encoder with Annealed Language Learning</a></h3>
                    <p><strong>Authors:</strong> Marc Marone, Orion Weller, William Fleshman, Eugene Yang, Dawn Lawrie, Benjamin Van Durme</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR, cs.LG</p>
                    <p><strong>Summary:</strong> Encoder-only languages models are frequently used for a variety of standard machine learning tasks, including classification and retrieval. However, there has been a lack of recent research for encoder models, especially with respect to multilingual models. We introduce mmBERT, an encoder-only language model pretrained on 3T tokens of multilingual text in over 1800 languages. To build mmBERT we introduce several novel elements, including an inverse mask ratio schedule and an inverse temperature sampling ratio. We add over 1700 low-resource languages to the data mix only during the decay phase, showing that it boosts performance dramatically and maximizes the gains from the relatively small amount of training data. Despite only including these low-resource languages in the short decay phase we achieve similar classification performance to models like OpenAIs o3 and Googles Gemini 2.5 Pro. Overall, we show that mmBERT significantly outperforms the previous generation of models on classification and retrieval tasks -- on both high and low-resource languages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06885v1" target="_blank">Barlow-Swin: Toward a novel siamese-based segmentation architecture using Swin-Transformers</a></h3>
                    <p><strong>Authors:</strong> Morteza Kiani Haftlang, Mohammadhossein Malmir, Foroutan Parand, Umberto Michelucci, Safouane El Ghazouali</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Medical image segmentation is a critical task in clinical workflows, particularly for the detection and delineation of pathological regions. While convolutional architectures like U-Net have become standard for such tasks, their limited receptive field restricts global context modeling. Recent efforts integrating transformers have addressed this, but often result in deep, computationally expensive models unsuitable for real-time use. In this work, we present a novel end-to-end lightweight architecture designed specifically for real-time binary medical image segmentation. Our model combines a Swin Transformer-like encoder with a U-Net-like decoder, connected via skip pathways to preserve spatial detail while capturing contextual information. Unlike existing designs such as Swin Transformer or U-Net, our architecture is significantly shallower and competitively efficient. To improve the encoders ability to learn meaningful features without relying on large amounts of labeled data, we first train it using Barlow Twins, a self-supervised learning method that helps the model focus on important patterns by reducing unnecessary repetition in the learned features. After this pretraining, we fine-tune the entire model for our specific task. Experiments on benchmark binary segmentation tasks demonstrate that our model achieves competitive accuracy with substantially reduced parameter count and faster inference, positioning it as a practical alternative for deployment in real-time and resource-limited clinical environments. The code for our method is available at Github repository: https://github.com/mkianih/Barlow-Swin.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06884v1" target="_blank">Characterization of low-nitrogen quantum diamond for pulsed magnetometry applications</a></h3>
                    <p><strong>Authors:</strong> Jiashen Tang, Connor A. Roncaioli, Andrew M. Edmonds, Atli Davidsson, Connor A. Hart, Matthew L. Markham, Ronald L. Walsworth</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Ensembles of nitrogen-vacancy (NV) centers in diamond are versatile quantum sensors with broad applications in the physical and life sciences. The concentration of neutral substitutional nitrogen ([N$_\text{s}^0$]) strongly influences coherence times, sensitivity, and optimal sensing strategies. Diamonds with [N$_\text{s}^0$] $\sim\,1-10\,\text{ppm}$ are a focus of recent material engineering efforts, with higher concentrations being favorable for continuous-wave optically detected magnetic resonance (CW-ODMR) and lower concentrations expected to benefit pulsed magnetometry techniques through extended NV electronic spin coherence times and improved sensing duty cycles. In this work, we synthesize and characterize low-[N$_\text{s}^0$] ($\sim\,0.8\,\text{ppm}$), NV-enriched diamond material, engineered through low-strain chemical vapor deposition (CVD) growth on high-quality substrates, $^{12}$C isotopic purification, and controlled electron irradiation and annealing. Our results demonstrate good strain homogeneity in diamonds grown on CVD substrates and spin-bath-limited NV dephasing times. By measuring NV spin and charge properties across a wide range of optical NV excitation intensity, we provide direct comparisons of photon-shot-noise-limited magnetic sensitivity between the current low-[$\text{N}_\text{s}^0$] and previously studied higher-[$\text{N}_\text{s}^0$] ($\sim\,14\,\text{ppm}$) NV-diamond sensors. We show that low-[N$_\text{s}^0$] diamond can outperform higher-[N$_\text{s}^0$] diamond at moderate and low optical NV excitation intensity. Our results provide practical benchmarks and guidance for selecting NV-diamond sensors tailored to specific experimental constraints and sensing requirements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06883v1" target="_blank">UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction</a></h3>
                    <p><strong>Authors:</strong> Joe Wilder, Nikhil Kadapala, Benji Xu, Mohammed Alsaadi, Aiden Parsons, Mitchell Rogers, Palash Agarwal, Adam Hassick, Laura Dietz</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted using other methods, even when their METEOR scores are lower.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06881v1" target="_blank">Benchmarking Single-Qubit Gates on a Neutral Atom Quantum Processor</a></h3>
                    <p><strong>Authors:</strong> Artem Rozanov, Boris Bantysh, Ivan Bobrov, Gleb Struchalin, Stanislav Straupe</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> quant-ph, physics.atom-ph</p>
                    <p><strong>Summary:</strong> We present benchmarking results for single-qubit gates implemented on a neutral atom quantum processor using Direct Randomized Benchmarking (DRB) and Gate Set Tomography (GST). The DRB protocol involves preparing stabilizer states, applying $m$ layers of native single-qubit gates, and measuring in the computational basis, providing an efficient error characterization under a stochastic Pauli noise model. GST enables the full, self-consistent reconstruction of quantum processes, including gates, input states, and measurements. Both protocols provide robust to state preparation and measurement (SPAM) errors estimations of gate performance, offering complementary perspectives on quantum gate fidelity. For single-qubit gates, DRB yields an average fidelity of $99.963 \pm 0.016\%$. The protocol was further applied to a 25-qubit array under global single-qubit control. GST results are consistent with those obtained via DRB. We also introduce a gauge optimization procedure for GST that brings the reconstructed gates, input states, and measurements into a canonical frame, enabling meaningful fidelity comparisons while preserving physical constraints. These constraints of the operators -- such as complete positivity and trace preservation -- are enforced by performing the optimization over the Stiefel manifold. The combined analysis supports the use of complementary benchmarking techniques for characterizing scalable quantum architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06880v1" target="_blank">The Parameter Report: An Orientation Guide for Data-Driven Parameterization</a></h3>
                    <p><strong>Authors:</strong> Christian Komusiewicz, Nils Morawietz, Frank Sommer, Luca Pascal Staus</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CC</p>
                    <p><strong>Summary:</strong> A strength of parameterized algorithmics is that each problem can be parameterized by an essentially inexhaustible set of parameters. Usually, the choice of the considered parameter is informed by the theoretical relations between parameters with the general goal of achieving FPT-algorithms for smaller and smaller parameters. However, the FPT-algorithms for smaller parameters usually have higher running times and it is unclear whether the decrease in the parameter value or the increase in the running time bound dominates in real-world data. This question cannot be answered from purely theoretical considerations and any answer requires knowledge on typical parameter values. To provide a data-driven guideline for parameterized complexity studies of graph problems, we present the first comprehensive comparison of parameter values for a set of benchmark graphs originating from real-world applications. Our study covers degree-related parameters, such as maximum degree or degeneracy, neighborhood-based parameters such as neighborhood diversity and modular-width, modulator-based parameters such as vertex cover number and feedback vertex set number, and the treewidth of the graphs. Our results may help assess the significance of FPT-running time bounds on the solvability of real-world instances. For example, the vertex cover number $vc$ of $n$-vertex graphs is often only slightly below $n/2$. Thus, a running time bound of $O(2^{vc})$ is only slightly better than a running time bound of $O(1.4^{n})$. In contrast, the treewidth $tw$ is almost always below $n/3$ and often close to $n/9$, making a running time of $O(2^{tw})$ much more practical on real-world instances. We make our implementation and full experimental data openly available. In particular, this provides the first implementations for several graph parameters such as 4-path vertex cover number and vertex integrity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06879v1" target="_blank">Intrinsic non-Hermitian topological phases</a></h3>
                    <p><strong>Authors:</strong> Ken Shiozaki</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> We study the interplay of non-Hermitian topological phases under point- and line-gap conditions. Using natural homomorphisms from line-gap to point-gap phases, we distinguish extrinsic phases, reducible to Hermitian or anti-Hermitian line-gapped phases, from intrinsic phases, which are genuinely non-Hermitian without Hermitian counterparts. Although classification tables for all symmetry classes were already presented in earlier work, the present paper develops a unified formulation and provides explicit computations for all internal symmetries.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06875v1" target="_blank">AxelSMOTE: An Agent-Based Oversampling Algorithm for Imbalanced Classification</a></h3>
                    <p><strong>Authors:</strong> Sukumar Kishanthan, Asela Hevapathige</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Class imbalance in machine learning poses a significant challenge, as skewed datasets often hinder performance on minority classes. Traditional oversampling techniques, which are commonly used to alleviate class imbalance, have several drawbacks: they treat features independently, lack similarity-based controls, limit sample diversity, and fail to manage synthetic variety effectively. To overcome these issues, we introduce AxelSMOTE, an innovative agent-based approach that views data instances as autonomous agents engaging in complex interactions. Based on Axelrods cultural dissemination model, AxelSMOTE implements four key innovations: (1) trait-based feature grouping to preserve correlations; (2) a similarity-based probabilistic exchange mechanism for meaningful interactions; (3) Beta distribution blending for realistic interpolation; and (4) controlled diversity injection to avoid overfitting. Experiments on eight imbalanced datasets demonstrate that AxelSMOTE outperforms state-of-the-art sampling methods while maintaining computational efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06873v1" target="_blank">Behind the scenes of the Quantum Extreme Learning Machines</a></h3>
                    <p><strong>Authors:</strong> A. De Lorenzis, M. P. Casado, N. Lo Gullo, T. Lux, F. Plastina, A. Riera</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> In recent years, Quantum Machine Learning (QML) has grown rapidly, emerging as a promising approach to make quantum computing implementation competitive. In this work, we investigate Quantum Extreme Learning Machines (QELM), a quantum variant of Extreme Learning Machines where training is restricted to the output layer. The proposed architecture combines dimensionality reduction (via PCA or Autoencoders), quantum state encoding, evolution under an XX Hamiltonian, and measurement, providing features for a single-layer classifier. By analyzing the performance of QELMs as a function of the evolution time, we identify a relatively sharp transition from a low-accuracy to a high-accuracy regime, after which the accuracy saturates. Remarkably, the saturation value matches that achieved with random unitaries, which induce maximally complex dynamics and optimally scramble information across the system. Across all cases studied, the critical transition time is sufficient for information to reach nearest neighbors, enabling feature extraction for learning, and is independent of the system size (i.e., the number of qubits). This independence implies that QELMs can be efficiently simulated classically for a broad class of tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06872v1" target="_blank">Mechanized Metatheory of Forward Reasoning for End-to-End Linearizability Proofs</a></h3>
                    <p><strong>Authors:</strong> Zachary Kent, Ugur Y. Yavuz, Siddhartha Jayanti, Stephanie Balzer, Guy Blelloch</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.PL</p>
                    <p><strong>Summary:</strong> In the past decade, many techniques have been developed to prove linearizability, the gold standard of correctness for concurrent data structures. Intuitively, linearizability requires that every operation on a concurrent data structure appears to take place instantaneously, even when interleaved with other operations. Most recently, Jayanti et al. presented the first sound and complete forward reasoning technique for proving linearizability that relates the behavior of a concurrent data structure to a reference atomic data structure as time moves forward. This technique can be used to produce machine-checked proofs of linearizability in TLA+. However, while Jayanti et al.s approach is shown to be sound and complete, a mechanization of this important metatheoretic result is still outstanding. As a result, it is not possible to produce verified end-to-end proofs of linearizability. To reduce the size of this trusted computing base, we formalize this forward reasoning technique and mechanize proofs of its soundness and completeness in Rocq. As a case study, we use the approach to produce a verified end-to-end proof of linearizability for a simple concurrent register.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06871v1" target="_blank">Learning spatially structured open quantum dynamics with regional-attention transformers</a></h3>
                    <p><strong>Authors:</strong> Dounan Du, Eden Figueroa</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.LG, physics.atom-ph</p>
                    <p><strong>Summary:</strong> Simulating the dynamics of open quantum systems with spatial structure and external control is an important challenge in quantum information science. Classical numerical solvers for such systems require integrating coupled master and field equations, which is computationally demanding for simulation and optimization tasks and often precluding real-time use in network-scale simulations or feedback control. We introduce a regional attention-based neural architecture that learns the spatiotemporal dynamics of structured open quantum systems. The model incorporates translational invariance of physical laws as an inductive bias to achieve scalable complexity, and supports conditioning on time-dependent global control parameters. We demonstrate learning on two representative systems: a driven dissipative single qubit and an electromagnetically induced transparency (EIT) quantum memory. The model achieves high predictive fidelity under both in-distribution and out-of-distribution control protocols, and provides substantial acceleration up to three orders of magnitude over numerical solvers. These results demonstrate that the architecture establishes a general surrogate modeling framework for spatially structured open quantum dynamics, with immediate relevance to large-scale quantum network simulation, quantum repeater and protocol design, real-time experimental optimization, and scalable device modeling across diverse light-matter platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06870v1" target="_blank">The Majority is not always right: RL training for solution aggregation</a></h3>
                    <p><strong>Authors:</strong> Wenting Zhao, Pranjal Aggarwal, Swarnadeep Saha, Asli Celikyilmaz, Jason Weston, Ilia Kulikov</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Scaling up test-time compute, by generating multiple independent solutions and selecting or aggregating among them, has become a central paradigm for improving large language models (LLMs) on challenging reasoning tasks. While most prior work relies on simple majority voting or reward model ranking to aggregate solutions, these approaches may only yield limited benefits. In this work, we propose to learn aggregation as an explicit reasoning skill: given a set of candidate solutions, we train an aggregator model to review, reconcile, and synthesize a final, correct answer using reinforcement learning from verifiable rewards. A key ingredient is careful balancing of easy and hard training examples, allowing the model to learn both to recover minority-but-correct answers as well as easy majority-correct answers. Empirically, we find our method, AggLM, outperforms both strong rule-based and reward-model baselines, across multiple benchmarks. Furthermore, it generalizes effectively to solutions from differing models, including stronger ones than contained in the training data, all while requiring substantially fewer tokens than majority voting with larger numbers of solutions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06868v1" target="_blank">A New Hybrid Model of Generative Adversarial Network and You Only Look Once Algorithm for Automatic License-Plate Recognition</a></h3>
                    <p><strong>Authors:</strong> Behnoud Shafiezadeh, Amir Mashmool, Farshad Eshghi, Manoochehr Kelarestaghi</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Automatic License-Plate Recognition (ALPR) plays a pivotal role in Intelligent Transportation Systems (ITS) as a fundamental element of Smart Cities. However, due to its high variability, ALPR faces challenging issues more efficiently addressed by deep learning techniques. In this paper, a selective Generative Adversarial Network (GAN) is proposed for deblurring in the preprocessing step, coupled with the state-of-the-art You-Only-Look-Once (YOLO)v5 object detection architectures for License-Plate Detection (LPD), and the integrated Character Segmentation (CS) and Character Recognition (CR) steps. The selective preprocessing bypasses unnecessary and sometimes counter-productive input manipulations, while YOLOv5 LPD/CS+CR delivers high accuracy and low computing cost. As a result, YOLOv5 achieves a detection time of 0.026 seconds for both LP and CR detection stages, facilitating real-time applications with exceptionally rapid responsiveness. Moreover, the proposed model achieves accuracy rates of 95\% and 97\% in the LPD and CR detection phases, respectively. Furthermore, the inclusion of the Deblur-GAN pre-processor significantly improves detection accuracy by nearly 40\%, especially when encountering blurred License Plates (LPs).To train and test the learning components, we generated and publicly released our blur and ALPR datasets (using Iranian license plates as a use-case), which are more representative of close-to-real-life ad-hoc situations. The findings demonstrate that employing the state-of-the-art YOLO model results in excellent overall precision and detection time, making it well-suited for portable applications. Additionally, integrating the Deblur-GAN model as a preliminary processing step enhances the overall effectiveness of our comprehensive model, particularly when confronted with blurred scenes captured by the camera as input.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06865v1" target="_blank">A Class of Cyclic Quantum Codes</a></h3>
                    <p><strong>Authors:</strong> Matthew B. Hastings</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We introduce a class of cyclic quantum codes, basing the construction not on the simplicity of the stabilizers, but rather on the simplicity of preparation of a code state (at least in the absence of noise). We show how certain known codes, such as a certain family of rotated two-dimensional toric codes, fall into this class, and we also give certain other examples at small sizes found by computer search. We finally discuss fault tolerant preparation of these codes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06863v1" target="_blank">floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL</a></h3>
                    <p><strong>Authors:</strong> Bhavya Agrawalla, Michal Nauman, Khush Agarwal, Aviral Kumar</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> A hallmark of modern large-scale machine learning techniques is the use of training objectives that provide dense supervision to intermediate computations, such as teacher forcing the next token in language models or denoising step-by-step in diffusion models. This enables models to learn complex functions in a generalizable manner. Motivated by this observation, we investigate the benefits of iterative computation for temporal difference (TD) methods in reinforcement learning (RL). Typically they represent value functions in a monolithic fashion, without iterative compute. We introduce floq (flow-matching Q-functions), an approach that parameterizes the Q-function using a velocity field and trains it using techniques from flow-matching, typically used in generative modeling. This velocity field underneath the flow is trained using a TD-learning objective, which bootstraps from values produced by a target velocity field, computed by running multiple steps of numerical integration. Crucially, floq allows for more fine-grained control and scaling of the Q-function capacity than monolithic architectures, by appropriately setting the number of integration steps. Across a suite of challenging offline RL benchmarks and online fine-tuning tasks, floq improves performance by nearly 1.8x. floq scales capacity far better than standard TD-learning architectures, highlighting the potential of iterative computation for value learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06862v1" target="_blank">Matching Shapes Under Different Topologies: A Topology-Adaptive Deformation Guided Approach</a></h3>
                    <p><strong>Authors:</strong> Aymen Merrouche, Stefanie Wuhrer, Edmond Boyer</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Non-rigid 3D mesh matching is a critical step in computer vision and computer graphics pipelines. We tackle matching meshes that contain topological artefacts which can break the assumption made by current approaches. While Functional Maps assume the deformation induced by the ground truth correspondences to be near-isometric, ARAP-like deformation-guided approaches assume the latter to be ARAP. Neither assumption holds in certain topological configurations of the input shapes. We are motivated by real-world scenarios such as per-frame multi-view reconstructions, often suffering from topological artefacts. To this end, we propose a topology-adaptive deformation model allowing changes in shape topology to align shape pairs under ARAP and bijective association constraints. Using this model, we jointly optimise for a template mesh with adequate topology and for its alignment with the shapes to be matched to extract correspondences. We show that, while not relying on any data-driven prior, our approach applies to highly non-isometric shapes and shapes with topological artefacts, including noisy per-frame multi-view reconstructions, even outperforming methods trained on large datasets in 3D alignment quality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.06861v1" target="_blank">Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet</a></h3>
                    <p><strong>Authors:</strong> James Xu Zhao, Bryan Hooi, See-Kiong Ng</p>
                    <p><strong>Published:</strong> 9/8/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using 12 reasoning models on two knowledge-intensive benchmarks. Our results reveal that increasing test-time computation does not consistently improve accuracy and, in many cases, it even leads to more hallucinations. We then analyze how extended reasoning affects hallucination behavior. We find that reduced hallucinations often result from the model choosing to abstain after thinking more, rather than from improved factual recall. Conversely, for some models, longer reasoning encourages attempts on previously unanswered questions, many of which result in hallucinations. Case studies show that extended reasoning can induce confirmation bias, leading to overconfident hallucinations. Despite these limitations, we observe that compared to non-thinking, enabling thinking remains beneficial. Code and data are available at https://github.com/XuZhao0/tts-knowledge</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

