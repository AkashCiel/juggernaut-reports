
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-09-04<br>
            <strong>Topics:</strong> ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 100
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <h2>ai alignment research</h2>
<p>To provide a summary focused on AI alignment research, its important to note that not all of the given papers directly address AI alignment. However, several papers touch on related themes, such as AI ethics, robustness, trustworthiness, and the behavior of AI systems. Here is a structured summary based on these themes:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Trustworthiness and Ethical Considerations in AI</strong>: Papers such as Can LLMs Lie? and More AI Assistance Reduces Cognitive Engagement highlight the growing concern around AI systems trustworthiness and ethical behavior. These papers emphasize the need to differentiate between unintentional errors and intentional deceit in AI outputs, as well as the balance between AI assistance and user cognitive engagement.</p>
</li>
<li><p><strong>Improving AI Robustness and Generalization</strong>: Research like Multi-level SSL Feature Gating for Audio Deepfake Detection and Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning showcases efforts to enhance AI robustness and generalization, especially in detecting and responding to deepfake threats and handling missing data in multimodal settings.</p>
</li>
<li><p><strong>AI in Real-World Applications and Accountability</strong>: Studies such as Accountability Framework for Healthcare AI Systems and AI-Driven Drug Repurposing through miRNA-mRNA Relation reflect the trend of integrating AI into critical areas like healthcare, emphasizing the need for accountable and transparent AI systems.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Understanding and Controlling Deceptive AI Behavior</strong>: The paper Can LLMs Lie? provides insights into the mechanisms of deception in AI and develops techniques for identifying and controlling such behavior, contributing significantly to AI ethics and alignment discourse.</p>
</li>
<li><p><strong>Development of Frameworks for AI Accountability</strong>: The Accountability Framework for Healthcare AI Systems introduces a structured approach to implementing accountability mechanisms in AI systems, which is crucial for aligning AI operations with ethical and regulatory standards.</p>
</li>
<li><p><strong>Enhanced Detection of AI-Generated Content</strong>: Multi-level SSL Feature Gating for Audio Deepfake Detection presents novel gating mechanisms and similarity metrics that improve the detection and classification of synthetic audio, thus advancing security and trust in AI-generated media.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Ethical AI Deployment</strong>: As AI systems become more autonomous, the findings underline the importance of robust ethical frameworks to ensure these systems act in alignment with human values and societal norms, particularly in high-stakes environments like healthcare.</p>
</li>
<li><p><strong>Need for Comprehensive AI Evaluation</strong>: The trend towards understanding the ethical and deceptive behaviors of AI models suggests a need for comprehensive evaluation frameworks that can assess AI systems reliability and alignment with human expectations across different applications.</p>
</li>
<li><p><strong>Balancing AI Assistance and Human Agency</strong>: With AI tools becoming integral to tasks such as note-taking, there is a crucial need to design AI systems that enhance human cognitive engagement rather than diminish it, ensuring that AI assistance does not lead to over-reliance or reduced critical thinking.</p>
</li>
</ol>
<p>These findings collectively emphasize the ongoing efforts and challenges in aligning AI systems with ethical standards and human values, highlighting the importance of robust frameworks and methodologies to ensure trustworthy, accountable, and beneficial AI deployment.</p>
<p><em>Based on 50 research papers</em></p>

<h2>quantum computing</h2>
<p>Certainly! Heres a high-level summary of the key trends, breakthroughs, and implications from the provided papers, focusing on the context of quantum computing:</p>
<h3>Most Important Trends</h3>
<ol>
<li><strong>Integration with Other Technologies</strong>: Several papers, such as those on Rydberg atoms and quantum Tsallis entropy, emphasize the integration of quantum computing with other scientific domains like atomic physics and information theory, showcasing a multidisciplinary approach.</li>
<li><strong>Benchmarking and Evaluation</strong>: The development of benchmarks, such as T2I-CoReBench for text-to-image models, reflects a growing trend in quantum computing and related AI fields to establish comprehensive benchmarks that assess both existing capabilities and limitations.</li>
<li><strong>Quantum-Enhanced Methods</strong>: Papers like those exploring quantum sensors for sub-Rayleigh imaging and quantum circuits for solving power flow problems highlight the trend of using quantum methods to enhance or surpass classical solutions.</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><strong>Control of Quantum Systems</strong>: The paper on controlling single spin-flips in Rydberg atomic fractals presents a novel method for managing quantum states in complex geometries, which could have significant implications for quantum information processing.</li>
<li><strong>Quantum Sensing Advancements</strong>: Achievements in overcoming the Rayleigh diffraction limit with quantum sensing techniques, such as SPADE, demonstrate breakthroughs in enhancing optical resolution beyond classical limits.</li>
<li><strong>Quantum Error Correction</strong>: The development of new error correction protocols for quantum insertion errors using angular momentum approaches indicates progress in making quantum systems more robust and reliable.</li>
</ol>
<h3>Implications</h3>
<ol>
<li><strong>Quantum Information Processing</strong>: The ability to control quantum states and transitions in complex systems, as demonstrated by the Rydberg atomic fractal study, expands the potential for quantum computing applications in information processing and storage.</li>
<li><strong>Improvements in Imaging and Metrology</strong>: The advancements in quantum sensing and imaging techniques suggest that quantum computing could significantly improve precision in fields like astronomy and medical imaging.</li>
<li><strong>Robustness and Scalability</strong>: Developments in error correction and efficient quantum algorithms, such as those for entropy estimation, point to a future where quantum systems are more resilient to errors, facilitating larger and more complex quantum computations.</li>
</ol>
<p>These summaries reflect the significant strides being made in leveraging quantum computing principles across various fields, highlighting the potential for transformative impacts on technology and science.</p>
<p><em>Based on 50 research papers</em></p>

            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2509.03519v1" target="_blank">Dynamically Controlled Transport of GeV Cosmic Rays in Diverse Galactic Environments</a></h3>
                    <p><strong>Authors:</strong> Ronan Hix, Lucia Armillotta, Eve Ostriker, Chang-Goo Kim</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> We study transport of GeV cosmic rays (CRs) in a set of high-resolution TIGRESS magnetohydrodynamic simulations of the star-forming interstellar medium (ISM). Our local disk patch models sample a wide range of gas surface densities, gravitational potentials, and star formation rates (SFRs), and include a spiral arm simulation. Our approach incorporates CR advection by the background gas, streaming along the magnetic field limited by the local ion Alfv\en speed, and diffusion relative to the Alfv\en wave frame, with the diffusion coefficient set by the balance between streaming-driven Alfv\en wave excitation and damping mediated by local gas properties. We find that dynamical transport mechanisms (streaming and advection) are almost solely responsible for GeV CR transport in the extra-planar regions of galaxies, while diffusion along the magnetic field dominates within the primarily-neutral ISM of galactic disks. We develop a simple 1D predictive model for the CR pressure $P_\mathrm{c}$, dependent only on injected CR flux and gas parameters. We demonstrate that the CR transport efficiency increases with increasing SFR, and provide a fit for the CR feedback yield $\Upsilon_\mathrm{c}~\equiv~P_\mathrm{c}/\Sigma_\mathrm{SFR}$ as a function of $\Sigma_\mathrm{SFR}$, the SFR surface density. We analyze lateral CR transport within the galactic disk, showing that CRs propagate away from feedback regions in spiral arms into interarm regions by a combination of gas advection and field-aligned transport. Lastly, we develop an empirical subgrid model for the CR scattering rate that captures the impacts of the multiphase ISM on CR transport without the numerical burden of full simulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03518v1" target="_blank">Can LLMs Lie? Investigation beyond Hallucination</a></h3>
                    <p><strong>Authors:</strong> Haoran Huan, Mihir Prabhudesai, Mengning Wu, Shantanu Jaiswal, Deepak Pathak</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have demonstrated impressive capabilities across a variety of tasks, but their increasing autonomy in real-world applications raises concerns about their trustworthiness. While hallucinations-unintentional falsehoods-have been widely studied, the phenomenon of lying, where an LLM knowingly generates falsehoods to achieve an ulterior objective, remains underexplored. In this work, we systematically investigate the lying behavior of LLMs, differentiating it from hallucinations and testing it in practical scenarios. Through mechanistic interpretability techniques, we uncover the neural mechanisms underlying deception, employing logit lens analysis, causal interventions, and contrastive activation steering to identify and control deceptive behavior. We study real-world lying scenarios and introduce behavioral steering vectors that enable fine-grained manipulation of lying tendencies. Further, we explore the trade-offs between lying and end-task performance, establishing a Pareto frontier where dishonesty can enhance goal optimization. Our findings contribute to the broader discourse on AI ethics, shedding light on the risks and potential safeguards for deploying LLMs in high-stakes environments. Code and more illustrations are available at https://llm-liar.github.io/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03512v1" target="_blank">Bayesian Multivariate Sparse Functional PCA</a></h3>
                    <p><strong>Authors:</strong> Joseph Sartini, Scott Zeger, Ciprian Crainiceanu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> Functional Principal Components Analysis (FPCA) provides a parsimonious, semi-parametric model for multivariate, sparsely-observed functional data. Frequentist FPCA approaches estimate principal components (PCs) from the data, then condition on these estimates in subsequent analyses. As an alternative, we propose a fully Bayesian inferential framework for multivariate, sparse functional data (MSFAST) which explicitly models the PCs and incorporates their uncertainty. MSFAST builds upon the FAST approach to FPCA for univariate, densely-observed functional data. Like FAST, MSFAST represents PCs using orthonormal splines, samples the orthonormal spline coefficients using parameter expansion, and enforces eigenvalue ordering during model fit. MSFAST extends FAST to multivariate, sparsely-observed data by (1) standardizing each functional covariate to mitigate poor posterior conditioning due to disparate scales; (2) using a better-suited orthogonal spline basis; (3) parallelizing likelihood calculations over covariates; (4) updating parameterizations and priors for computational stability; (5) using a Procrustes-based posterior alignment procedure; and (6) providing efficient prediction routines. We evaluated MSFAST alongside existing implementations using simulations. MSFAST produces uniquely valid inferences and accurate estimates, particularly for smaller signals. MSFAST is motivated by and applied to a study of child growth, with an accompanying vignette illustrating the implementation step-by-step.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03510v1" target="_blank">A comprehensive Persian offline handwritten database for investigating the effects of heritability and family relationships on handwriting</a></h3>
                    <p><strong>Authors:</strong> Abbas Zohrevand, Javad Sadri, Zahra Imani</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper introduces a comprehensive database for research and investigation on the effects of inheritance on handwriting. A database has been created that can be used to answer questions such as: Is there a genetic component to handwriting? Is handwriting inherited? Do family relationships affect handwriting? Varieties of samples of handwritten components such as: digits, letters, shapes and free paragraphs of 210 families including (grandparents, parents, uncles, aunts, siblings, cousins, nephews and nieces) have been collected using specially designed forms, and family relationships of all writers are captured. To the best of our knowledge, no such database is presently available. Based on comparisons and investigation of features of handwritings of family members, similarities among their features and writing styles are detected. Our database is freely available to the pattern recognition community and hope it will pave the way for investigations on the effects of inheritance and family relationships on handwritings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03501v1" target="_blank">Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data</a></h3>
                    <p><strong>Authors:</strong> Honglu Zhou, Xiangyu Peng, Shrikant Kendre, Michael S. Ryoo, Silvio Savarese, Caiming Xiong, Juan Carlos Niebles</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Next-generation AI companions must go beyond general video understanding to resolve spatial and temporal references in dynamic, real-world environments. Existing Video Large Language Models (Video LLMs), while capable of coarse-level comprehension, struggle with fine-grained, spatiotemporal reasoning, especially when user queries rely on time-based event references for temporal anchoring, or gestural cues for spatial anchoring to clarify object references and positions. To bridge this critical gap, we introduce Strefer, a synthetic instruction data generation framework designed to equip Video LLMs with spatiotemporal referring and reasoning capabilities. Strefer produces diverse instruction-tuning data using a data engine that pseudo-annotates temporally dense, fine-grained video metadata, capturing rich spatial and temporal information in a structured manner, including subjects, objects, their locations as masklets, and their action descriptions and timelines. Our approach enhances the ability of Video LLMs to interpret spatial and temporal references, fostering more versatile, space-time-aware reasoning essential for real-world AI companions. Without using proprietary models, costly human annotation, or the need to annotate large volumes of new videos, experimental evaluations show that models trained with data produced by Strefer outperform baselines on tasks requiring spatial and temporal disambiguation. Additionally, these models exhibit enhanced space-time-aware reasoning, establishing a new foundation for perceptually grounded, instruction-tuned Video LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03499v1" target="_blank">DeepSea MOT: A benchmark dataset for multi-object tracking on deep-sea video</a></h3>
                    <p><strong>Authors:</strong> Kevin Barnard, Elaine Liu, Kristine Walz, Brian Schlining, Nancy Jacobsen Stout, Lonny Lundsten</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Benchmarking multi-object tracking and object detection model performance is an essential step in machine learning model development, as it allows researchers to evaluate model detection and tracker performance on human-generated test data, facilitating consistent comparisons between models and trackers and aiding performance optimization. In this study, a novel benchmark video dataset was developed and used to assess the performance of several Monterey Bay Aquarium Research Institute object detection models and a FathomNet single-class object detection model together with several trackers. The dataset consists of four video sequences representing midwater and benthic deep-sea habitats. Performance was evaluated using Higher Order Tracking Accuracy, a metric that balances detection, localization, and association accuracy. To the best of our knowledge, this is the first publicly available benchmark for multi-object tracking in deep-sea video footage. We provide the benchmark data, a clearly documented workflow for generating additional benchmark videos, as well as example Python notebooks for computing metrics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03494v1" target="_blank">Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual Prompts for NR-IQA</a></h3>
                    <p><strong>Authors:</strong> Yahya Benmahane, Mohammed El Hassouni</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this paper, we propose a novel parameter-efficient adaptation method for No- Reference Image Quality Assessment (NR-IQA) using visual prompts optimized in pixel-space. Unlike full fine-tuning of Multimodal Large Language Models (MLLMs), our approach trains only 600K parameters at most ( 0.01% of the base model), while keeping the underlying model fully frozen. During inference, these visual prompts are combined with images via addition and processed by mPLUG-Owl2 with the textual query Rate the technical quality of the image. Evaluations across distortion types (synthetic, realistic, AI-generated) on KADID- 10k, KonIQ-10k, and AGIQA-3k demonstrate competitive performance against full finetuned methods and specialized NR-IQA models, achieving 0.93 SRCC on KADID-10k. To our knowledge, this is the first work to leverage pixel-space visual prompts for NR-IQA, enabling efficient MLLM adaptation for low-level vision tasks. The source code is publicly available at https: // github. com/ yahya-ben/ mplug2-vp-for-nriqa .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03491v1" target="_blank">Enhanced second-harmonic generation from WS$_2$/ReSe$_2$ heterostructure</a></h3>
                    <p><strong>Authors:</strong> Kanchan Shaikh, Taejun Yoo, Zeyuan Zhu, Qiuyang Li, Amalya C. Johnson, Hui Deng, Fang Liu, Yuki Kobayashi</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Van der Waals stacking presents new opportunities for nonlinear optics with its remarkable tunability and scalability. However, the fundamental role of interlayer interactions in modifying the overall nonlinear optical susceptibilities remains elusive. In this letter, we report an anisotropic enhancement of second-harmonic generation (SHG) from a WS$_2$/ReSe$_2$ heterobilayer, where the individual composite layers possess distinctive crystal phases. We investigate polarization-resolved response and twist-angle dependence in SHG and reveal that band alignment alone is insufficient to explain the observed anisotropy in the modified SHG response. Spectral shifts in excitonic features highlight band renormalization, supporting the role of hybridization between the two layers. Furthermore, SHG enhancement is highly anisotropic and can even be suppressed in some orientations, suggesting possible intensity-borrowing mechanisms within the heterostructure. Our work demonstrates the ability to tune both the intensity and polarization dependence of nonlinear optical responses with van der Waals stacking of distinctive crystal phases.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.62051/ijcsit.v5n2.02" target="_blank">Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games</a></h3>
                    <p><strong>Authors:</strong> Haonan Wang, Mingjia Zhao, Junfeng Sun, Wei Liu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> As AI technology advances, research in playing text-based games with agents has becomeprogressively popular. In this paper, a novel approach to agent design and agent learning ispresented with the context of reinforcement learning. A model of deep learning is first applied toprocess game text and build a world model. Next, the agent is learned through a policy gradient-based deep reinforcement learning method to facilitate conversion from state value to optimal policy.The enhanced agent works better in several text-based game experiments and significantlysurpasses previous agents on game completion ratio and win rate. Our study introduces novelunderstanding and empirical ground for using reinforcement learning for text games and sets thestage for developing and optimizing reinforcement learning agents for more general domains andproblems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03477v1" target="_blank">Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning</a></h3>
                    <p><strong>Authors:</strong> Duy A. Nguyen, Abhi Kamboj, Minh N. Do</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Addressing missing modalities and limited labeled data is crucial for advancing robust multimodal learning. We propose Robult, a scalable framework designed to mitigate these challenges by preserving modality-specific information and leveraging redundancy through a novel information-theoretic approach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled (PU) contrastive loss that maximizes task-relevant feature alignment while effectively utilizing limited labeled data in semi-supervised settings, and (2) a latent reconstruction loss that ensures unique modality-specific information is retained. These strategies, embedded within a modular design, enhance performance across various downstream tasks and ensure resilience to incomplete modalities during inference. Experimental results across diverse datasets validate that Robult achieves superior performance over existing approaches in both semi-supervised learning and missing modality contexts. Furthermore, its lightweight design promotes scalability and seamless integration with existing architectures, making it suitable for real-world multimodal applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03471v1" target="_blank">Linear Relaxation Schemes with Asymptotically Compatible Energy Law for Time-Fractional Phase-Field Models</a></h3>
                    <p><strong>Authors:</strong> Hui Yu, Zhaoyang Wang, Ping Lin</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> In this paper, we propose a variable time-step linear relaxation scheme for time-fractional phase-field equations with a free energy density in general polynomial form. The $L1^{+}$-CN formula is used to discretize the fractional derivative, and an auxiliary variable is introduced to approximate the nonlinear term by directly solving algebraic equations rather than differential-algebraic equations as in the invariant energy quadratization (IEQ) and the scalar auxiliary variable (SAV) approaches. The developed semi-discrete scheme is second-order accurate in time, and the inconsistency between the auxiliary and the original variables does not deteriorate over time. Furthermore, we take the time-fractional volume-conserved Allen-Cahn equation, the time-fractional Cahn-Hilliard equation, and the time-fractional Swift-Hohenberg equation as examples to demonstrate that the constructed schemes are energy stable and that the discrete energy dissipation law is asymptotically compatible with the classical one when the fractional-order parameter $\alpha\rightarrow 1^{-}$. Several numerical examples demonstrate the effectiveness of the proposed scheme. In particular, numerical results confirm that the auxiliary variable remains well aligned with the original variable, and the error between them does not continue to increase over time before the system reaches steady state.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03469v1" target="_blank">Signatures of emergent surface states across a displacive topological phase transition in Bi$_4$I$_4$</a></h3>
                    <p><strong>Authors:</strong> Deep Singha Roy, Sk Kalimuddin, Subrata Pachhal, Saikat Mondal, Soham Das, Sukanya Jana, Arnab Bera, Satyabrata Bera, Tuhin Debnath, Ankan Bag, Souvik Pramanik, Sudipta Chatterjee, Sanjib Naskar, Shishir Kumar Pandey, Adhip Agarwala, Mintu Mondal</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mes-hall, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Topological phase transitions involving crystalline symmetry breaking provide a fertile ground to explore the interplay between symmetry, topology, and emergent quantum phenomena. Recently discovered quasi-one-dimensional topological material, Bi$_4$I$_4$, has been predicted to host topologically non-trivial gapless surfaces at high temperature, which undergo a finite temperature phase transition to a low temperature gapped phase. Here we present experimental signatures of this room temperature phase transition from a high-temperature $\beta$-phase with a surface state to a gapped $\alpha$-phase hosting hinge states. Using real-space current mapping and resistance fluctuation spectroscopy, we identify signatures of a displacive topological phase transition mediated by a first-order thermodynamic structural change. Near the emergence of $\beta$-phase, we observe pronounced telegraphic noise, indicating fluctuating phase domains with topological surface states. The spatially resolved current map reveals electron transport via the gapless surface states in the $\beta$-phase, which vanishes upon transitioning to the $\alpha$-phase with localized conduction channels (or hinge modes). Our experimental results, supported by first principles estimates and effective theory of a topological displacive phase transition, establish Bi$_4$I$_4$ as a candidate material showing intricate interplay of classical thermodynamic phase transitions with topological quantum phenomena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03467v1" target="_blank">Continuous Saudi Sign Language Recognition: A Vision Transformer Approach</a></h3>
                    <p><strong>Authors:</strong> Soukeina Elhassen, Lama Al Khuzayem, Areej Alhothali, Ohoud Alzamzami, Nahed Alowaidi</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Sign language (SL) is an essential communication form for hearing-impaired and deaf people, enabling engagement within the broader society. Despite its significance, limited public awareness of SL often leads to inequitable access to educational and professional opportunities, thereby contributing to social exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend on Saudi Sign Language (SSL) as their primary form of communication. Although certain technological approaches have helped to improve communication for individuals with hearing impairments, there continues to be an urgent requirement for more precise and dependable translation techniques, especially for Arabic sign language variants like SSL. Most state-of-the-art solutions have primarily focused on non-Arabic sign languages, resulting in a considerable absence of resources dedicated to Arabic sign language, specifically SSL. The complexity of the Arabic language and the prevalence of isolated sign language datasets that concentrate on individual words instead of continuous speech contribute to this issue. To address this gap, our research represents an important step in developing SSL resources. To address this, we introduce the first continuous Saudi Sign Language dataset called KAU-CSSL, focusing on complete sentences to facilitate further research and enable sophisticated recognition systems for SSL recognition and translation. Additionally, we propose a transformer-based model, utilizing a pretrained ResNet-18 for spatial feature extraction and a Transformer Encoder with Bidirectional LSTM for temporal dependencies, achieving 99.02\% accuracy at signer dependent mode and 77.71\% accuracy at signer independent mode. This development leads the way to not only improving communication tools for the SSL community but also making a substantial contribution to the wider field of sign language.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03463v1" target="_blank">The Impact of Critique on LLM-Based Model Generation from Natural Language: The Case of Activity Diagrams</a></h3>
                    <p><strong>Authors:</strong> Parham Khamsepour, Mark Cole, Ish Ashraf, Sandeep Puri, Mehrdad Sabetzadeh, Shiva Nejati</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) show strong potential for automating the generation of models from natural-language descriptions. A common approach is an iterative generate-critique-refine loop, where candidate models are produced, evaluated, and updated based on detected issues. This process needs to address: (1) structural correctness - compliance with well-formedness rules - and (2) semantic alignment - accurate reflection of the intended meaning in the source text. We present LADEX (LLM-based Activity Diagram Extractor), a pipeline for deriving activity diagrams from natural-language process descriptions using an LLM-driven critique-refine process. Structural checks in LADEX can be performed either algorithmically or by an LLM, while alignment checks are always performed by an LLM. We design five ablated variants of LADEX to study: (i) the impact of the critique-refine loop itself, (ii) the role of LLM-based semantic checks, and (iii) the comparative effectiveness of algorithmic versus LLM-based structural checks. To evaluate LADEX, we compare the generated activity diagrams with expert-created ground truths using trace-based operational semantics. This enables automated measurement of correctness and completeness. Experiments on two datasets indicate that: (1) the critique-refine loop improves structural validity, correctness, and completeness compared to single-pass generation; (2) algorithmic structural checks eliminate inconsistencies that LLM-based checks fail to detect, improving correctness by an average of 17.81% and completeness by 13.24% over LLM-only checks; and (3) combining algorithmic structural checks with LLM-based semantic checks, implemented using the reasoning-focused O4 Mini, achieves the best overall performance - yielding average correctness of up to 86.37% and average completeness of up to 88.56% - while requiring fewer than five LLM calls on average.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03442v1" target="_blank">Evaluating Diverse Feature Extraction Techniques of Multifaceted IoT Malware Analysis: A Survey</a></h3>
                    <p><strong>Authors:</strong> Zhuoyun Qian, Hongyi Miao, Yili Jiang, Qin Hu, Jiaqi Huang, Cheng Zhang, Fangtian Zhong</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> As IoT devices continue to proliferate, their reliability is increasingly constrained by security concerns. In response, researchers have developed diverse malware analysis techniques to detect and classify IoT malware. These techniques typically rely on extracting features at different levels from IoT applications, giving rise to a wide range of feature extraction methods. However, current approaches still face significant challenges when applied in practice. This survey provides a comprehensive review of feature extraction techniques for IoT malware analysis from multiple perspectives. We first examine static and dynamic feature extraction methods, followed by hybrid approaches. We then explore feature representation strategies based on graph learning. Finally, we compare the strengths and limitations of existing techniques, highlight open challenges, and outline promising directions for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03436v1" target="_blank">Cost-Optimized Systems Engineering for IoT-Enabled Robot Nurse in Infectious Pandemic Management</a></h3>
                    <p><strong>Authors:</strong> Md Mhamud Hussen Sifat, Md Maruf, Md Rokunuzzaman</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.HC, cs.SY, eess.SY, I.2.9; C.3; J.3</p>
                    <p><strong>Summary:</strong> The utilization of robotic technology has gained traction in healthcare facilities due to progress in the field that enables time and cost savings, minimizes waste, and improves patient care. Digital healthcare technologies that leverage automation, such as robotics and artificial intelligence, have the potential to enhance the sustainability and profitability of healthcare systems in the long run. However, the recent COVID-19 pandemic has amplified the need for cyber-physical robots to automate check-ups and medication administration. A robot nurse is controlled by the Internet of Things (IoT) and can serve as an automated medical assistant while also allowing supervisory control based on custom commands. This system helps reduce infection risk and improves outcomes in pandemic settings. This research presents a test case with a nurse robot that can assess a patients health status and take action accordingly. We also evaluate the systems performance in medication administration, health-status monitoring, and life-cycle considerations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03433v1" target="_blank">Decoding Visual Neural Representations by Multimodal with Dynamic Balancing</a></h3>
                    <p><strong>Authors:</strong> Kaili sun, Xingyu Miao, Bing Zhai, Haoran Duan, Yang Long</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this work, we propose an innovative framework that integrates EEG, image, and text data, aiming to decode visual neural representations from low signal-to-noise ratio EEG signals. Specifically, we introduce text modality to enhance the semantic correspondence between EEG signals and visual content. With the explicit semantic labels provided by text, image and EEG features of the same category can be more closely aligned with the corresponding text representations in a shared multimodal space. To fully utilize pre-trained visual and textual representations, we propose an adapter module that alleviates the instability of high-dimensional representation while facilitating the alignment and fusion of cross-modal features. Additionally, to alleviate the imbalance in multimodal feature contributions introduced by the textual representations, we propose a Modal Consistency Dynamic Balance (MCDB) strategy that dynamically adjusts the contribution weights of each modality. We further propose a stochastic perturbation regularization (SPR) term to enhance the generalization ability of semantic perturbation-based models by introducing dynamic Gaussian noise in the modality optimization process. The evaluation results on the ThingsEEG dataset show that our method surpasses previous state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by 2.0\% and 4.7\% respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03425v1" target="_blank">LINKER: Learning Interactions Between Functional Groups and Residues With Chemical Knowledge-Enhanced Reasoning and Explainability</a></h3>
                    <p><strong>Authors:</strong> Phuc Pham, Viet Thanh Duy Nguyen, Truong-Son Hy</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG, q-bio.QM</p>
                    <p><strong>Summary:</strong> Accurate identification of interactions between protein residues and ligand functional groups is essential to understand molecular recognition and guide rational drug design. Existing deep learning approaches for protein-ligand interpretability often rely on 3D structural input or use distance-based contact labels, limiting both their applicability and biological relevance. We introduce LINKER, the first sequence-based model to predict residue-functional group interactions in terms of biologically defined interaction types, using only protein sequences and the ligand SMILES as input. LINKER is trained with structure-supervised attention, where interaction labels are derived from 3D protein-ligand complexes via functional group-based motif extraction. By abstracting ligand structures into functional groups, the model focuses on chemically meaningful substructures while predicting interaction types rather than mere spatial proximity. Crucially, LINKER requires only sequence-level input at inference time, enabling large-scale application in settings where structural data is unavailable. Experiments on the LP-PDBBind benchmark demonstrate that structure-informed supervision over functional group abstractions yields interaction predictions closely aligned with ground-truth biochemical annotations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03424v1" target="_blank">Beyond the Clouds: S3 as the most distant extended Milky Way stream, not of LMC origin</a></h3>
                    <p><strong>Authors:</strong> Ã“. JimÃ©nez-Arranz, S. Lilleengen, M. S. Petersen</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Context: While the LMCs influence on MW stellar streams has been extensively studied, streams associated with the Clouds have received far less attention. Beyond the Magellanic Stream, only four stream candidates (S1-S4) have been reported. Aims: We focus on the S3 stream, a long ($\sim30^\circ$) and narrow ($\sim1.2^\circ$) structure at 60-80 kpc, nearly aligned with the LMC. Our goals are: 1) to validate the stream through a kinematic analysis of S3 candidates with Gaia DR3 data; 2) to enlarge the sample of potential members; and 3) to model the stream in order to test its association with either the MW or the LMC. Methods: We selected new S3 candidates with a neural network classifier trained on Gaia DR3 data, and further reduced contamination through a cut in the proper-motion space. To investigate the origin of S3, we evolve stream models within time-dependent, deforming MW and LMC haloes, thereby accounting for possible effects of the MW-LMC interaction. Results: We identify 1,542 high-confidence new S3 stream candidates and find that the streams apparent width has grown from $\sim1.2^\circ$ to $\sim3$-$4^\circ$ compared to previous studies. We also present a list of 440 potential S3 red clump stars, which are valuable targets for spectroscopic follow-up thanks to their well-defined luminosities and ability to yield precise distances. Both modelling and a comparison of S3 stars closest approach distance and velocity with the LMCs escape velocity indicate that S3 is unlikely to originate from the LMC, instead representing a distant ($\sim75$ kpc) MW stream. Conclusions: S3 is the most distant ($\sim75$ kpc) extended ($\sim30^\circ$ long, $\sim3$-$4^\circ$ thick) MW stream known, offering a unique probe of the outer halo and the LMCs recent influence. Its angular width corresponds to a physical thickness of $\sim4$-5 kpc, making S3 among the thickest streams discovered.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03420v1" target="_blank">Image-Guided Surgery: Technology, Quality, Innovation, and Opportunities for Medical Physics</a></h3>
                    <p><strong>Authors:</strong> Jeffrey H. Siewerdsen</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> physics.med-ph, eess.IV</p>
                    <p><strong>Summary:</strong> The science and clinical practice of medical physics has been integral to the advancement of radiology and radiation therapy for over a century. In parallel, advances in surgery - including intraoperative imaging, registration, and other technologies within the expertise of medical physicists - have advanced primarily in connection to other disciplines, such as biomedical engineering and computer science, and via somewhat distinct translational paths. This review article briefly traces the parallel and convergent evolution of such scientific, engineering, and clinical domains with an eye to a potentially broader, more impactful role of medical physics in research and clinical practice of surgery. A review of image-guided surgery technologies is offered, including intraoperative imaging, tracking / navigation, image registration, visualization, and surgical robotics across a spectrum of surgical applications. Trends and drivers for research and innovation are traced, including federal funding and academic-industry partnership, and some of the major challenges to achieving major clinical impact are described. Opportunities for medical physicists to expand expertise and contribute to the advancement of surgery in the decade ahead are outlined, including research and innovation, data science approaches, improving efficiency through operations research and optimization, improving patient safety, and bringing rigorous quality assurance to technologies and processes in the circle of care for surgery. Challenges abound but appear tractable, including domain knowledge, professional qualifications, and the need for investment and clinical partnership.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03413v1" target="_blank">An angular momentum approach to quantum insertion errors</a></h3>
                    <p><strong>Authors:</strong> Lewis Bulled, Yingkai Ouyang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum insertion errors are a class of errors that increase the number of qubits in a quantum system. Despite a wealth of research on classical insertion errors, there has been limited progress towards a general framework for correcting quantum insertion errors. We detail a quantum error correction protocol that can correct single insertion errors on a class of gapped permutation-invariant codes. We provide a simple two-stage syndrome extraction protocol that yields a two-bit syndrome, by measuring the total angular momentum and its projection along the $z$-axis (modulo the code gap) of the post-insertion state. We demonstrate that these measurements project the state onto a new codespace, and we detail a teleportation protocol to map the projected state back to a permutation-invariant code on the desired number of qubits.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03409v1" target="_blank">Multi-level SSL Feature Gating for Audio Deepfake Detection</a></h3>
                    <p><strong>Authors:</strong> Hoan My Tran, Damien Lolive, Aghilas Sini, Arnaud Delhay, Pierre-FranÃ§ois Marteau, David Guennec</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.AI, cs.MM, I.2.7</p>
                    <p><strong>Summary:</strong> Recent advancements in generative AI, particularly in speech synthesis, have enabled the generation of highly natural-sounding synthetic speech that closely mimics human voices. While these innovations hold promise for applications like assistive technologies, they also pose significant risks, including misuse for fraudulent activities, identity theft, and security threats. Current research on spoofing detection countermeasures remains limited by generalization to unseen deepfake attacks and languages. To address this, we propose a gating mechanism extracting relevant feature from the speech foundation XLS-R model as a front-end feature extractor. For downstream back-end classifier, we employ Multi-kernel gated Convolution (MultiConv) to capture both local and global speech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as a similarity metric to enforce diversity in learned features across different MultiConv layers. By integrating CKA with our gating mechanism, we hypothesize that each component helps improving the learning of distinct synthetic speech patterns. Experimental results demonstrate that our approach achieves state-of-the-art performance on in-domain benchmarks while generalizing robustly to out-of-domain datasets, including multilingual speech samples. This underscores its potential as a versatile solution for detecting evolving speech deepfake threats.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3757632" target="_blank">More AI Assistance Reduces Cognitive Engagement: Examining the AI Assistance Dilemma in AI-Supported Note-Taking</a></h3>
                    <p><strong>Authors:</strong> Xinyue Chen, Kunlin Ruan, Kexin Phyllis Ju, Nathan Yap, Xu Wang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> As AI tools become increasingly embedded in cognitively demanding tasks such as note-taking, questions remain about whether they enhance or undermine cognitive engagement. This paper examines the AI Assistance Dilemma in note-taking, investigating how varying levels of AI support affect user engagement and comprehension. In a within-subject experiment, we asked participants (N=30) to take notes during lecture videos under three conditions: Automated AI (high assistance with structured notes), Intermediate AI (moderate assistance with real-time summary, and Minimal AI (low assistance with transcript). Results reveal that Intermediate AI yields the highest post-test scores and Automated AI the lowest. Participants, however, preferred the automated setup due to its perceived ease of use and lower cognitive effort, suggesting a discrepancy between preferred convenience and cognitive benefits. Our study provides insights into designing AI assistance that preserves cognitive engagement, offering implications for designing moderate AI support in cognitive tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03391v1" target="_blank">More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research</a></h3>
                    <p><strong>Authors:</strong> Trent D. Buskirk, Florian Keusch, Leah von der Heyde, Adam Eck</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.DL, cs.CY</p>
                    <p><strong>Summary:</strong> Survey research has a long-standing history of being a human-powered field, but one that embraces various technologies for the collection, processing, and analysis of various behavioral, political, and social outcomes of interest, among others. At the same time, Large Language Models (LLMs) bring new technological challenges and prerequisites in order to fully harness their potential. In this paper, we report work-in-progress on a systematic literature review based on keyword searches from multiple large-scale databases as well as citation networks that assesses how LLMs are currently being applied within the survey research process. We synthesize and organize our findings according to the survey research process to include examples of LLM usage across three broad phases: pre-data collection, data collection, and post-data collection. We discuss selected examples of potential use cases for LLMs as well as its pitfalls based on examples from existing literature. Considering survey research has rich experience and history regarding data quality, we discuss some opportunities and describe future outlooks for survey research to contribute to the continued development and refinement of LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03385v1" target="_blank">Human Preference-Aligned Concept Customization Benchmark via Decomposed Evaluation</a></h3>
                    <p><strong>Authors:</strong> Reina Ishikawa, Ryo Fujii, Hideo Saito, Ryo Hachiuma</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Evaluating concept customization is challenging, as it requires a comprehensive assessment of fidelity to generative prompts and concept images. Moreover, evaluating multiple concepts is considerably more difficult than evaluating a single concept, as it demands detailed assessment not only for each individual concept but also for the interactions among concepts. While humans can intuitively assess generated images, existing metrics often provide either overly narrow or overly generalized evaluations, resulting in misalignment with human preference. To address this, we propose Decomposed GPT Score (D-GPTScore), a novel human-aligned evaluation method that decomposes evaluation criteria into finer aspects and incorporates aspect-wise assessments using Multimodal Large Language Model (MLLM). Additionally, we release Human Preference-Aligned Concept Customization Benchmark (CC-AlignBench), a benchmark dataset containing both single- and multi-concept tasks, enabling stage-wise evaluation across a wide difficulty range -- from individual actions to multi-person interactions. Our method significantly outperforms existing approaches on this benchmark, exhibiting higher correlation with human preferences. This work establishes a new standard for evaluating concept customization and highlights key challenges for future research. The benchmark and associated materials are available at https://github.com/ReinaIshikawa/D-GPTScore.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03383v1" target="_blank">ANNIE: Be Careful of Your Robots</a></h3>
                    <p><strong>Authors:</strong> Yiyang Huang, Zixuan Wang, Zishen Wan, Yapeng Tian, Haobo Xu, Yinhe Han, Yiming Gan</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.RO</p>
                    <p><strong>Summary:</strong> The integration of vision-language-action (VLA) models into embodied AI (EAI) robots is rapidly advancing their ability to perform complex, long-horizon tasks in humancentric environments. However, EAI systems introduce critical security risks: a compromised VLA model can directly translate adversarial perturbations on sensory input into unsafe physical actions. Traditional safety definitions and methodologies from the machine learning community are no longer sufficient. EAI systems raise new questions, such as what constitutes safety, how to measure it, and how to design effective attack and defense mechanisms in physically grounded, interactive settings. In this work, we present the first systematic study of adversarial safety attacks on embodied AI systems, grounded in ISO standards for human-robot interactions. We (1) formalize a principled taxonomy of safety violations (critical, dangerous, risky) based on physical constraints such as separation distance, velocity, and collision boundaries; (2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with 2,400 video-action sequences for evaluating embodied safety; and (3) ANNIE-Attack, a task-aware adversarial framework with an attack leader model that decomposes long-horizon goals into frame-level perturbations. Our evaluation across representative EAI models shows attack success rates exceeding 50% across all safety categories. We further demonstrate sparse and adaptive attack strategies and validate the real-world impact through physical robot experiments. These results expose a previously underexplored but highly consequential attack surface in embodied AI systems, highlighting the urgent need for security-driven defenses in the physical AI era. Code is available at https://github.com/RLCLab/Annie.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03380v1" target="_blank">Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems</a></h3>
                    <p><strong>Authors:</strong> Peter J. Bentley, Soo Ling Lim, Fuyuki Ishikawa</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, 93A16, I.2.11</p>
                    <p><strong>Summary:</strong> Agentic LLM AI agents are often little more than autonomous chatbots: actors following scripts, often controlled by an unreliable director. This work introduces a bottom-up framework that situates AI agents in their environment, with all behaviors triggered by changes in their environments. It introduces the notion of aspects, similar to the idea of umwelt, where sets of agents perceive their environment differently to each other, enabling clearer control of information. We provide an illustrative implementation and show that compared to a typical architecture, which leaks up to 83% of the time, aspective agentic AI enables zero information leakage. We anticipate that this concept of specialist agents working efficiently in their own information niches can provide improvements to both security and efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03377v1" target="_blank">Amplifying Effective CXL Memory Bandwidth for LLM Inference via Transparent Near-Data Processing</a></h3>
                    <p><strong>Authors:</strong> Rui Xie, Asad Ul Haq, Linsen Ma, Yunhua Fang, Zirak Burzin Engineer, Liu Liu, Tong Zhang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> Large language model (LLM) inference is bottlenecked by the limited bandwidth of CXL-based memory used for capacity expansion. We introduce CXL-NDP, a transparent near-data processing architecture that amplifies effective CXL bandwidth without requiring changes to the CXL.mem interface or AI models. CXL-NDP integrates a precision-scalable bit-plane layout for dynamic quantization with transparent lossless compression of weights and KV caches directly within the CXL device. In end-to-end serving, CXL-NDP improves throughput by 43%, extends the maximum context length by 87%, and reduces the KV cache footprint by 46.9% without accuracy loss. Hardware synthesis confirms its practicality with a modest silicon footprint, lowering the barrier for adopting efficient, scalable CXL-based memory in generative AI infrastructure.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03357v1" target="_blank">On Optimality of Private Information in Bayesian Routing Games</a></h3>
                    <p><strong>Authors:</strong> Alexia Ambrogio, Leonardo Cianfanelli, Giacomo Como</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> math.OC</p>
                    <p><strong>Summary:</strong> We study an information design problem in transportation networks, in the presence of a random state that affects the travel times on the links. An omniscient system planner -- aiming at reducing congestion -- observes the network state realization and sends private messages to the users -- who share a common prior on the network state but do not observe it directly -- in order to nudge them towards a socially desirable behavior. The desired effect of these private signals is to correlate the users selfish decisions with the network state and align the resulting Bayesian Wardrop equilibrium with the system optimum flow. Our main contribution is to provide sufficient and necessary conditions under which optimality may be achieved by a fair private signal policy in transportation networks with injective link-path incidence matrix and affine travel time functions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03356v1" target="_blank">Tailored Thermal Transport in Phase Change Materials-Based Nanocomposites through Interfacial Structuring</a></h3>
                    <p><strong>Authors:</strong> Viktor Mandrolko, Mykola Isaiev</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, physics.app-ph</p>
                    <p><strong>Summary:</strong> Interfacial thermal transport is a critical bottleneck in nanoscale systems, where heat dissipation and energy efficiency are strongly modulated by molecular ordering at solid-liquid boundaries. Here, using atomistic simulations of hexadecane confined by structured silica substrates, we reveal how interfacial geometry, specifically curvature, governs the density distribution and thermal transport across the interface. At flat and mildly curved surfaces, the liquid exhibits surface-templated layering, promoting efficient heat transfer, which is enhanced with increasing contact surface area. As curvature increases, this ordering breaks down, giving rise to interference-like density patterns, reduced molecular packing, and localized depletion zones. This structural reorganization leads to a systematic increase in interfacial thermal resistance (ITR), even when the contact area is kept constant. By decomposing the interface into convex (hill of solid) and concave (valley of solid) regions, we find that valleys consistently offer lower thermal resistance. In contrast, hills act as bottlenecks to heat flow. Remarkably, we show that the work of adhesion and entropy-related energy losses scale non-trivially with curvature: while adhesion increases with contact area, the entropic penalty dominates the total energy change, reflecting curvature-induced frustration of molecular alignment. These findings unveil a direct link between surface geometry, thermodynamic dissipation, and heat transport, offering new design principles for thermally tunable nanostructured materials, thermal interface coatings, and phase-change systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03350v1" target="_blank">Exposing Privacy Risks in Anonymizing Clinical Data: Combinatorial Refinement Attacks on k-Anonymity Without Auxiliary Information</a></h3>
                    <p><strong>Authors:</strong> Somiya Chhillar, Mary K. Righi, Rebecca E. Sutter, Evgenios M. Kornaropoulos</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Despite longstanding criticism from the privacy community, k-anonymity remains a widely used standard for data anonymization, mainly due to its simplicity, regulatory alignment, and preservation of data utility. However, non-experts often defend k-anonymity on the grounds that, in the absence of auxiliary information, no known attacks can compromise its protections. In this work, we refute this claim by introducing Combinatorial Refinement Attacks (CRA), a new class of privacy attacks targeting k-anonymized datasets produced using local recoding. This is the first method that does not rely on external auxiliary information or assumptions about the underlying data distribution. CRA leverages the utility-optimizing behavior of local recoding anonymization of ARX, which is a widely used open-source software for anonymizing data in clinical settings, to formulate a linear program that significantly reduces the space of plausible sensitive values. To validate our findings, we partnered with a network of free community health clinics, an environment where (1) auxiliary information is indeed hard to find due to the population they serve and (2) open-source k-anonymity solutions are attractive due to regulatory obligations and limited resources. Our results on real-world clinical microdata reveal that even in the absence of external information, established anonymization frameworks do not deliver the promised level of privacy, raising critical privacy concerns.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03348v1" target="_blank">Generative Auto-Bidding in Large-Scale Competitive Auctions via Diffusion Completer-Aligner</a></h3>
                    <p><strong>Authors:</strong> Yewen Li, Jingtong Gao, Nan Jiang, Shuai Mao, Ruyi An, Fei Pan, Xiangyu Zhao, Bo An, Qingpeng Cai, Peng Jiang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.GT, cs.LG</p>
                    <p><strong>Summary:</strong> Auto-bidding is central to computational advertising, achieving notable commercial success by optimizing advertisers bids within economic constraints. Recently, large generative models show potential to revolutionize auto-bidding by generating bids that could flexibly adapt to complex, competitive environments. Among them, diffusers stand out for their ability to address sparse-reward challenges by focusing on trajectory-level accumulated rewards, as well as their explainable capability, i.e., planning a future trajectory of states and executing bids accordingly. However, diffusers struggle with generation uncertainty, particularly regarding dynamic legitimacy between adjacent states, which can lead to poor bids and further cause significant loss of ad impression opportunities when competing with other advertisers in a highly competitive auction environment. To address it, we propose a Causal auto-Bidding method based on a Diffusion completer-aligner framework, termed CBD. Firstly, we augment the diffusion training process with an extra random variable t, where the model observes t-length historical sequences with the goal of completing the remaining sequence, thereby enhancing the generated sequences dynamic legitimacy. Then, we employ a trajectory-level return model to refine the generated trajectories, aligning more closely with advertisers objectives. Experimental results across diverse settings demonstrate that our approach not only achieves superior performance on large-scale auto-bidding benchmarks, such as a 29.9% improvement in conversion value in the challenging sparse-reward auction setting, but also delivers significant improvements on the Kuaishou online advertising platform, including a 2.0% increase in target cost.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03347v1" target="_blank">Physics-informed machine learning for combustion: A review</a></h3>
                    <p><strong>Authors:</strong> Jiahao Wu, Xutun Wang, Yuxin Wu, Guihua Zhang, Jiayue Liu, Xin Li</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph</p>
                    <p><strong>Summary:</strong> Physics-informed machine learning (PIML) represents an emerging paradigm that integrates various forms of physical knowledge into machine learning (ML) components, thereby enhancing the physical consistency of ML models compared to purely data-driven paradigms. The field of combustion, characterized by a rich foundation of physical laws and abundant data, is undergoing a transformation due to PIML. This paper aims to provide a comprehensive overview of PIML for combustion, systematically outlining fundamental principles, significant contributions, key advancements, and available resources. The application of PIML in combustion is categorized into three domains: combustion chemical kinetics, combustion reacting flows, and other combustion-related problems. Additionally, current challenges, potential solutions, and practical guidelines for researchers and engineers will be discussed. A primary focus of this review is to demonstrate how combustion laws can be integrated into ML, either through soft or hard constraints, via loss functions or representation models, and within coordinate-to-variable or field-to-field paradigms. This paper shows that PIML offers a unified framework linking physics, model, and data in combustion--integrating physical knowledge in model-to-data simulation and reconstruction tasks, as well as data-to-model modeling tasks--resulting in enhanced data, improved physical models, and more reliable ML models. PIML for combustion presents significant opportunities for both the combustion and ML communities, encouraging greater collaboration and cross-disciplinary engagement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03342v1" target="_blank">Quantifying many-body contributions to depletion forces</a></h3>
                    <p><strong>Authors:</strong> Gabriel PÃ©rez-Angel, Marco A. RamÃ­rez-GuÃ­zar, NÃ©stor M. De Los Santos-LÃ³pez, JosÃ© M. MÃ©ndez-Alcaraz, RamÃ³n CastaÃ±eda-Priego</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft</p>
                    <p><strong>Summary:</strong> Effective interactions inherently encompass many-body effects that appear unified. Analyzing these in reverse, that is, separating them into contributions from pairs, triples, or larger groups, is typically intricate and seldom pursued. However, this could offer essential insights into the structural architecture of complex systems, such as soft materials. This contribution tackles this issue employing a new simulation-based approach to accurately determine effective interactions. The approach is sufficiently sensitive to assess the effects of higher-order terms in the depletion potentials between large particles. Previous research has primarily focused on the role of small particles, and this work expands on these findings. However, understanding the contributions of large particles on the effective forces, particularly beyond the dilute limit, remains challenging and is not yet fully grasped, leading us to primarily focus on exploring this topic. Within the range of particle concentrations examined here, while maintaining a constant chemical potential for smaller particles, we have observed that the concentration of larger particles has no impact on the entropic potential between large colloids, as long as the size ratio remains below $q=0.15$. This confirms a long-established prediction founded on purely geometric considerations, which we have confirmed by means of direct observation. In contrast, for mixtures with less size asymmetry, such effects become considerably influential. Specifically, we have conducted an in-depth examination of scenarios with size asymmetries of $q=0.45$ and $0.60$. Our results for the depletion forces were directly compared with those obtained from the integral equation theory, which has also enabled us to improve and refine the approaches involved.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03340v1" target="_blank">Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems</a></h3>
                    <p><strong>Authors:</strong> Fleur Hendriks, OndÅ™ej RokoÅ¡, Martin DoÅ¡kÃ¡Å™, Marc G. D. Geers, Vlado Menkovski</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CE, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models struggle to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we propose a generative framework based on flow matching to model the full probability distribution over bifurcation outcomes. Our method enables direct sampling of multiple valid solutions while preserving system symmetries through equivariant modeling. We introduce a symmetric matching strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from toy models to complex physical problems such as buckling beams and the Allen-Cahn equation. Our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations, offering a principled and scalable solution for modeling multistability in high-dimensional systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03336v1" target="_blank">AI-Driven Drug Repurposing through miRNA-mRNA Relation</a></h3>
                    <p><strong>Authors:</strong> Sharanya Manoharan, Balu Bhasuran, Oviya Ramalakshmi Iyyappan, Mohamed Saleem Abdul Shukkoor, Malathi Sellapan, Kalpana Raja</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> q-bio.MN, cs.IR, q-bio.QM</p>
                    <p><strong>Summary:</strong> miRNA mRNA relations are closely linked to several biological processes and disease mechanisms In a recent study we tested the performance of large language models LLMs on extracting miRNA mRNA relations from PubMed PubMedBERT achieved the best performance of 0.783 F1 score for miRNA mRNA Interaction Corpus MMIC Here we first applied the finetuned PubMedBERT model to extract miRNA mRNA relations from PubMed for chronic obstructive pulmonary disease COPD Alzheimers disease AD stroke type 2 diabetes mellitus T2DM chronic liver disease and cancer Next we retrieved miRNA drug relations using KinderMiner a literature mining tool for relation extraction Then we constructed three interaction networks 1 disease centric network 2 drug centric network and 3 miRNA centric network comprising 3497 nodes and 16417 edges organized as a directed graph to capture complex biological relationships Finally we validated the drugs using MIMIC IV Our integrative approach revealed both established and novel candidate drugs for diseases under study through 595 miRNA drug relations extracted from PubMed To the best of our knowledge this is the first study to systematically extract and visualize relationships among four distinct biomedical entities miRNA mRNA drug and disease</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03335v1" target="_blank">EvolveSignal: A Large Language Model Powered Coding Agent for Discovering Traffic Signal Control Algorithms</a></h3>
                    <p><strong>Authors:</strong> Leizhen Wang, Peibo Duan, Hao Wang, Yue Wang, Jian Xu, Nan Zheng, Zhenliang Ma</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In traffic engineering, the fixed-time traffic signal control remains widely used for its low cost, stability, and interpretability. However, its design depends on hand-crafted formulas (e.g., Webster) and manual re-timing by engineers to adapt to demand changes, which is labor-intensive and often yields suboptimal results under heterogeneous or congested conditions. This paper introduces the EvolveSignal, a large language models (LLMs) powered coding agent to automatically discover new traffic signal control algorithms. We formulate the problem as program synthesis, where candidate algorithms are represented as Python functions with fixed input-output structures, and iteratively optimized through external evaluations (e.g., a traffic simulator) and evolutionary search. Experiments on a signalized intersection demonstrate that the discovered algorithms outperform Websters baseline, reducing average delay by 20.1% and average stops by 47.1%. Beyond performance, ablation and incremental analyses reveal that EvolveSignal modifications-such as adjusting cycle length bounds, incorporating right-turn demand, and rescaling green allocations-can offer practically meaningful insights for traffic engineers. This work opens a new research direction by leveraging AI for algorithm design in traffic signal control, bridging program synthesis with transportation engineering.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03329v1" target="_blank">SESGO: Spanish Evaluation of Stereotypical Generative Outputs</a></h3>
                    <p><strong>Authors:</strong> Melissa Robles, Catalina Bernal, Denniss Raigoso, Mateo Dulce Rubio</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.CL</p>
                    <p><strong>Summary:</strong> This paper addresses the critical gap in evaluating bias in multilingual Large Language Models (LLMs), with a specific focus on Spanish language within culturally-aware Latin American contexts. Despite widespread global deployment, current evaluations remain predominantly US-English-centric, leaving potential harms in other linguistic and cultural contexts largely underexamined. We introduce a novel, culturally-grounded framework for detecting social biases in instruction-tuned LLMs. Our approach adapts the underspecified question methodology from the BBQ dataset by incorporating culturally-specific expressions and sayings that encode regional stereotypes across four social categories: gender, race, socioeconomic class, and national origin. Using more than 4,000 prompts, we propose a new metric that combines accuracy with the direction of error to effectively balance model performance and bias alignment in both ambiguous and disambiguated contexts. To our knowledge, our work presents the first systematic evaluation examining how leading commercial LLMs respond to culturally specific bias in the Spanish language, revealing varying patterns of bias manifestation across state-of-the-art models. We also contribute evidence that bias mitigation techniques optimized for English do not effectively transfer to Spanish tasks, and that bias patterns remain largely consistent across different sampling temperatures. Our modular framework offers a natural extension to new stereotypes, bias categories, or languages and cultural contexts, representing a significant step toward more equitable and culturally-aware evaluation of AI systems in the diverse linguistic environments where they operate.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03324v1" target="_blank">InfraDiffusion: zero-shot depth map restoration with diffusion models and prompted segmentation from sparse infrastructure point clouds</a></h3>
                    <p><strong>Authors:</strong> Yixiong Jing, Cheng Zhang, Haibing Wu, Guangming Wang, Olaf Wysocki, Brian Sheil</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Point clouds are widely used for infrastructure monitoring by providing geometric information, where segmentation is required for downstream tasks such as defect detection. Existing research has automated semantic segmentation of structural components, while brick-level segmentation (identifying defects such as spalling and mortar loss) has been primarily conducted from RGB images. However, acquiring high-resolution images is impractical in low-light environments like masonry tunnels. Point clouds, though robust to dim lighting, are typically unstructured, sparse, and noisy, limiting fine-grained segmentation. We present InfraDiffusion, a zero-shot framework that projects masonry point clouds into depth maps using virtual cameras and restores them by adapting the Denoising Diffusion Null-space Model (DDNM). Without task-specific training, InfraDiffusion enhances visual clarity and geometric consistency of depth maps. Experiments on masonry bridge and tunnel point cloud datasets show significant improvements in brick-level segmentation using the Segment Anything Model (SAM), underscoring its potential for automated inspection of masonry assets. Our code and data is available at https://github.com/Jingyixiong/InfraDiffusion-official-implement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03320v1" target="_blank">Investigation of non-Hermitian and Hermitian models of Altermagnets</a></h3>
                    <p><strong>Authors:</strong> Partha Goswami</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Insulating altermagnets like MnTe exhibit spin configurations where opposing spins are not only aligned antiparallel but also rotated relative to each other. This is an arrangement reminiscent of antiferromagnetism with a twist of spin canting. This study investigates a model Hamiltonian that captures the essential physics of such systems, incorporating key interactions including Dzyaloshinskii-Moriya and conventional exchange terms, relativistic spin-orbit coupling, and d-wave and g-wave orderings. Non-Hermitian dynamics are introduced through complex potentials that simulate energy dissipation and amplification. The paper delves into the behavior of the quantum geometric tensor and the emergence of the quantum anomalous Hall effect within the topologically insulating regime. It also broadens the scope to encompass non-Hermitian metallic altermagnets, focusing on phases characterized by symmetry-breaking d-wave and g-wave order parameters.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03319v1" target="_blank">Temporal social network modeling of mobile connectivity data with graph neural networks</a></h3>
                    <p><strong>Authors:</strong> Joel Jaskari, Chandreyee Roy, Fumiko Ogushi, Mikko Saukkoriipi, Jaakko Sahlsten, Kimmo Kaski</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.SI, cs.LG</p>
                    <p><strong>Summary:</strong> Graph neural networks (GNNs) have emerged as a state-of-the-art data-driven tool for modeling connectivity data of graph-structured complex networks and integrating information of their nodes and edges in space and time. However, as of yet, the analysis of social networks using the time series of peoples mobile connectivity data has not been extensively investigated. In the present study, we investigate four snapshot - based temporal GNNs in predicting the phone call and SMS activity between users of a mobile communication network. In addition, we develop a simple non - GNN baseline model using recently proposed EdgeBank method. Our analysis shows that the ROLAND temporal GNN outperforms the baseline model in most cases, whereas the other three GNNs perform on average worse than the baseline. The results show that GNN based approaches hold promise in the analysis of temporal social networks through mobile connectivity data. However, due to the relatively small performance margin between ROLAND and the baseline model, further research is required on specialized GNN architectures for temporal social network analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03312v1" target="_blank">AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?</a></h3>
                    <p><strong>Authors:</strong> Guibin Zhang, Junhao Wang, Junjie Chen, Wangchunshu Zhou, Kun Wang, Shuicheng Yan</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.MA</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM)-based agentic systems, often comprising multiple models, complex tool invocations, and orchestration protocols, substantially outperform monolithic agents. Yet this very sophistication amplifies their fragility, making them more prone to system failure. Pinpointing the specific agent or step responsible for an error within long execution traces defines the task of agentic system failure attribution. Current state-of-the-art reasoning LLMs, however, remain strikingly inadequate for this challenge, with accuracy generally below 10%. To address this gap, we propose AgenTracer, the first automated framework for annotating failed multi-agent trajectories via counterfactual replay and programmed fault injection, producing the curated dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a lightweight failure tracer trained with multi-granular reinforcement learning, capable of efficiently diagnosing errors in verbose multi-agent interactions. On the WhoWhen benchmark, AgenTracer-8B outperforms giant proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS with 4.8-14.2% performance gains, empowering self-correcting and self-evolving agentic AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03310v1" target="_blank">app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding</a></h3>
                    <p><strong>Authors:</strong> Evgenii Kniazev, Arseny Kravchenko, Igor Rekun, James Broadhead, Nikita Shamgunov, Pranav Sah, Pratik Nichite, Ivan Yamshchikov</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.SE</p>
                    <p><strong>Summary:</strong> We present app.build (https://github.com/appdotbuild/agent/), an open-source framework that improves LLM-based application generation through systematic validation and structured environments. Our approach combines multi-layered validation pipelines, stack-specific orchestration, and model-agnostic architecture, implemented across three reference stacks. Through evaluation on 30 generation tasks, we demonstrate that comprehensive validation achieves 73.3% viability rate with 30% reaching perfect quality scores, while open-weights models achieve 80.8% of closed-model performance when provided structured environments. The open-source framework has been adopted by the community, with over 3,000 applications generated to date. This work demonstrates that scaling reliable AI agents requires scaling environments, not just models -- providing empirical insights and complete reference implementations for production-oriented agent systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03308v1" target="_blank">$\widetilde{W}^{1+}$ subclass: Extending the topological classification of black hole thermodynamics</a></h3>
                    <p><strong>Authors:</strong> Wangyu Ai, Di Wu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> In this paper, we identify a novel topological subclass, dubbed $\widetilde{W}^{1+}$, in the thermodynamics of higher odd-dimensional, multiply rotating Kerr-AdS black holes. This discovery extends the established topological classification beyond the five classes and two subclasses previously known. The $\widetilde{W}^{1+}$ subclass exhibits a unique and previously unreported stability profile: it admits a thermodynamically stable small black hole state in the low-temperature limit, while in the high-temperature limit, the phase space simultaneously contains one stable large black hole, one stable small black hole, and one unstable small black hole state. Our analysis, which treats black hole solutions as topological defects, reveals a richer landscape of black hole thermodynamics than previously understood and necessitates an expansion of the topological classification scheme to accommodate this new phenomenology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03300v1" target="_blank">LatPhon: Lightweight Multilingual G2P for Romance Languages and English</a></h3>
                    <p><strong>Authors:</strong> Luis Felipe Chary, Miguel Arjona Ramirez</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Grapheme-to-phoneme (G2P) conversion is a key front-end for text-to-speech (TTS), automatic speech recognition (ASR), speech-to-speech translation (S2ST) and alignment systems, especially across multiple Latin-script languages.We present LatPhon, a 7.5 M - parameter Transformer jointly trained on six such languages--English, Spanish, French, Italian, Portuguese, and Romanian. On the public ipa-dict corpus, it attains a mean phoneme error rate (PER) of 3.5%, outperforming the byte-level ByT5 baseline (5.4%) and approaching language-specific WFSTs (3.2%) while occupying 30 MB of memory, which makes on-device deployment feasible when needed. These results indicate that compact multilingual G2P can serve as a universal front-end for Latin-language speech pipelines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03298v1" target="_blank">Machine learning reconstruction of cosmic ray parameters in EAS at HAWC</a></h3>
                    <p><strong>Authors:</strong> J. Jaimes, T. CapistrÃ¡n, I. Torres</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, astro-ph.IM</p>
                    <p><strong>Summary:</strong> The High-Altitude Water Cherenkov (HAWC) Observatory comprises 300 water Cherenkov detectors, each equipped with four photomultipliers, located on the Volc\{a}n Sierra Negra in Mexico at 4,100 masl. This observatory can detect gamma rays in an energy range from 300 GeV to 100 TeV and cosmic rays from 100 GeV to 1 PeV. One of HAWCs primary challenges is characterizing air showers and estimate their physical parameters, a highly complex task due to the nature of the data and the processes involved. Currently, HAWC employs two energy estimators for gamma rays: the ground parameter method and a neural network-based approach. However, for cosmic rays, only the likelihood-based estimator is available. In this work, we leverage machine learning techniques to achieve more accurate estimation of the physical parameters of cosmic rays. These techniques are explored as an alternative for reconstructing the physical properties of extensive air showers using simulated data aligned with the observatorys configuration. Various models were trained and evaluated through an optimized pipeline and the most effective one was selected as the final implementation after a comprehensive comparison. This approach improves the accuracy of physical parameter estimation, contributing significantly to the detailed characterization of cosmic ray events.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03294v1" target="_blank">A Comprehensive Guide to Differential Privacy: From Theory to User Expectations</a></h3>
                    <p><strong>Authors:</strong> Napsu Karmitsa, Antti Airola, Tapio Pahikkala, Tinja PitkÃ¤mÃ¤ki</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.LG, 68P27, 68T09, 94A60</p>
                    <p><strong>Summary:</strong> The increasing availability of personal data has enabled significant advances in fields such as machine learning, healthcare, and cybersecurity. However, this data abundance also raises serious privacy concerns, especially in light of powerful re-identification attacks and growing legal and ethical demands for responsible data use. Differential privacy (DP) has emerged as a principled, mathematically grounded framework for mitigating these risks. This review provides a comprehensive survey of DP, covering its theoretical foundations, practical mechanisms, and real-world applications. It explores key algorithmic tools and domain-specific challenges - particularly in privacy-preserving machine learning and synthetic data generation. The report also highlights usability issues and the need for improved communication and transparency in DP systems. Overall, the goal is to support informed adoption of DP by researchers and practitioners navigating the evolving landscape of data privacy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03290v1" target="_blank">Machine Learning-Driven Anomaly Detection for 5G O-RAN Performance Metrics</a></h3>
                    <p><strong>Authors:</strong> Babak Azkaei, Kishor Chandra Joshi, George Exarchakos</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.LG, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> The ever-increasing reliance of critical services on network infrastructure coupled with the increased operational complexity of beyond-5G/6G networks necessitate the need for proactive and automated network fault management. The provision for open interfaces among different radio access network\,(RAN) elements and the integration of AI/ML into network architecture enabled by the Open RAN\,(O-RAN) specifications bring new possibilities for active network health monitoring and anomaly detection. In this paper we leverage these advantages and develop an anomaly detection framework that proactively detect the possible throughput drops for a UE and minimize the post-handover failures. We propose two actionable anomaly detection algorithms tailored for real-world deployment. The first algorithm identifies user equipment (UE) at risk of severe throughput degradation by analyzing key performance indicators (KPIs) such as resource block utilization and signal quality metrics, enabling proactive handover initiation. The second algorithm evaluates neighbor cell radio coverage quality, filtering out cells with anomalous signal strength or interference levels. This reduces candidate targets for handover by 41.27\% on average. Together, these methods mitigate post-handover failures and throughput drops while operating much faster than the near-real-time latency constraints. This paves the way for self-healing 6G networks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03286v1" target="_blank">Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making</a></h3>
                    <p><strong>Authors:</strong> Prachi Bagave, Marcus Westberg, Marijn Janssen, Aaron Yi Ding</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> AI is transforming the healthcare domain and is increasingly helping practitioners to make health-related decisions. Therefore, accountability becomes a crucial concern for critical AI-driven decisions. Although regulatory bodies, such as the EU commission, provide guidelines, they are highlevel and focus on the what that should be done and less on the how, creating a knowledge gap for actors. Through an extensive analysis, we found that the term accountability is perceived and dealt with in many different ways, depending on the actors expertise and domain of work. With increasing concerns about AI accountability issues and the ambiguity around this term, this paper bridges the gap between the what and how of AI accountability, specifically for AI systems in healthcare. We do this by analysing the concept of accountability, formulating an accountability framework, and providing a three-tier structure for handling various accountability mechanisms. Our accountability framework positions the regulations of healthcare AI systems and the mechanisms adopted by the actors under a consistent accountability regime. Moreover, the three-tier structure guides the actors of the healthcare AI system to categorise the mechanisms based on their conduct. Through our framework, we advocate that decision-making in healthcare AI holds shared dependencies, where accountability should be dealt with jointly and should foster collaborations. We highlight the role of explainability in instigating communication and information sharing between the actors to further facilitate the collaborative process.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03280v1" target="_blank">An experience-based classification of quantum bugs in quantum software</a></h3>
                    <p><strong>Authors:</strong> Nils Quetschlich, Olivia Di Matteo</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.SE</p>
                    <p><strong>Summary:</strong> As quantum computers continue to improve in quality and scale, there is a growing need for accessible software frameworks for programming them. However, the unique behavior of quantum systems means specialized approaches, beyond traditional software development, are required. This is particularly true for debugging due to quantum bugs, i.e., bugs that occur precisely because an algorithm is a quantum algorithm. Pinpointing a quantum bugs root cause often requires significant developer time, as there is little established guidance for quantum debugging techniques. Developing such guidance is the main challenge we sought to address. In this work, we describe a set of 14 quantum bugs, sourced primarily from our experience as quantum software developers, and supplemented by analysis of open-source GitHub repositories. We detail their context, symptoms, and the techniques applied to identify and fix them. While classifying these bugs based on existing schemes, we observed that most emerged due to unique interactions between multiple aspects of an algorithm or workflow. In other words, they occurred because more than one thing went wrong, which provided important insight into why quantum debugging is more challenging. Furthermore, based on this clustering, we found that - unexpectedly - there is no clear relationship between debugging strategies and bug classes. Further research is needed to develop effective and systematic quantum debugging strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03516v1" target="_blank">Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?</a></h3>
                    <p><strong>Authors:</strong> Ouxiang Li, Yuan Wang, Xinting Hu, Huijuan Huang, Rui Chen, Jiarong Ou, Xin Tao, Pengfei Wan, Fuli Feng</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-image (T2I) generation aims to synthesize images from textual prompts, which jointly specify what must be shown and imply what can be inferred, thereby corresponding to two core capabilities: composition and reasoning. However, with the emerging advances of T2I models in reasoning beyond composition, existing benchmarks reveal clear limitations in providing comprehensive evaluations across and within these capabilities. Meanwhile, these advances also enable models to handle more complex prompts, whereas current benchmarks remain limited to low scene density and simplified one-to-one reasoning. To address these limitations, we propose T2I-CoReBench, a comprehensive and complex benchmark that evaluates both composition and reasoning capabilities of T2I models. To ensure comprehensiveness, we structure composition around scene graph elements (instance, attribute, and relation) and reasoning around the philosophical framework of inference (deductive, inductive, and abductive), formulating a 12-dimensional evaluation taxonomy. To increase complexity, driven by the inherent complexities of real-world scenarios, we curate each prompt with high compositional density for composition and multi-step inference for reasoning. We also pair each prompt with a checklist that specifies individual yes/no questions to assess each intended element independently to facilitate fine-grained and reliable evaluation. In statistics, our benchmark comprises 1,080 challenging prompts and around 13,500 checklist questions. Experiments across 27 current T2I models reveal that their composition capability still remains limited in complex high-density scenarios, while the reasoning capability lags even further behind as a critical bottleneck, with all models struggling to infer implicit elements from prompts. Our project page: https://t2i-corebench.github.io/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03514v1" target="_blank">Control of single spin-flips in a Rydberg atomic fractal</a></h3>
                    <p><strong>Authors:</strong> Robin C. Verstraten, Ivo H. A. Knottnerus, Yu Chih Tseng, Alexander Urech, Tiago Santiago do Espirito Santo, Vinicius Zampronio, Florian Schreck, Robert J. C. Spreeuw, Cristiane Morais Smith</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas, cond-mat.dis-nn, quant-ph</p>
                    <p><strong>Summary:</strong> Rydberg atoms trapped by optical tweezers have emerged as a versatile platform to emulate lattices with different geometries, in which long-range interacting spins lead to fascinating phenomena, ranging from spin liquids to topological states of matter. Here, we show that when the lattice has a fractal geometry with Hausdorff dimension 1.58, additional surprises appear. The system is described by a transverse-field Ising model with long-range van der Waals interactions in a Sierpi\`nski gasket fractal. We investigate the problem theoretically using exact diagonalization, variational mean field, quantum Monte Carlo, and a graph-based numerical technique, SIM-GRAPH, which we developed. We find that in the quantum regime, the phase diagram exhibits phases in which the spins flip one-by-one. The theoretical results are in excellent agreement with experiments performed with single 88Sr atoms trapped by optical tweezers arranged in a fractal geometry. The magnetization and von Neumann entanglement entropy reveal several regimes in which single spin-flips are delocalized over many sites of one sublattice, thus allowing for an unprecedented control of a cascade of phase transitions in a manybody system. These results expand the possibilities of Rydberg atoms for quantum information processing and may have profound implications in quantum technology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03513v1" target="_blank">On Charge Conjugation, Correlations, Elitzurs Theorem and the Mass Gap Problem in Lattice $SU(N)$ Yang-Mills Models in $d=4$ Dimensions</a></h3>
                    <p><strong>Authors:</strong> Paulo A. Faria da Veiga, Michael OCarroll</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> hep-th, hep-lat, math-ph, math.MP, 70S15</p>
                    <p><strong>Summary:</strong> We consider a four-dimensional Euclidean Wilson lattice Yang-Mills model with gauge group $SU(N)$, and the associated lattice Euclidean quantum field theory constructed by Osterwalder-Schrader-Seiler via a Feynman-Kac formula. In this model, to each lattice bond $b$ there is assigned a bond variable $U_b\in SU(N)$. Gluon fields are parameters in the Lie algebra of $SU(N)$. We define a charge conjugation operator $\mathcal C$ in the physical Hilbert space $H$ and prove that, for $N\not=2$, $H$ admits an orthogonal decomposition into two sectors with charge conjugation $\pm1$. There is only one sector for $N=2$. In the space of correlations, a charge conjugation operator $C_E$ is defined and a similar decomposition holds. Besides, a version of Elitzurs theorem is shown; applications are given. It is proven that the expectation averages of two distinct lattice vector potential correlators is zero. Surprisingly, the expectation of two distinct field strength tensors is also zero. In the gluon field parametrization it is known that Wilson action is bounded quadratically in the gluon fields. Towards solving the mass gap problem, in the gluon field expansion of the action, we show there are no local terms, such as a mass term. However, the action associated with the exponent of the exponentiated Haar measure density has a positive local mass term which is proportional to the square of the gauge coupling $\beta=g^{-2}0$ and the $SU(N)$ quadratic Casimir operator eigenvalue. Our results also hold in dimension three. Of course, the orthogonal decomposition of the Hilbert space $H$ has consequences in the analysis of the truncated two-point plaquette field correlation and the Yang-Mills mass gap problem: for $N\not=2$ and at least for small $\beta$, a multiplicity-two one-particle glueball state (two mass gaps) is expected to be present in the energy-momentum spectrum of the Yang-Mills model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03512v1" target="_blank">Bayesian Multivariate Sparse Functional PCA</a></h3>
                    <p><strong>Authors:</strong> Joseph Sartini, Scott Zeger, Ciprian Crainiceanu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> Functional Principal Components Analysis (FPCA) provides a parsimonious, semi-parametric model for multivariate, sparsely-observed functional data. Frequentist FPCA approaches estimate principal components (PCs) from the data, then condition on these estimates in subsequent analyses. As an alternative, we propose a fully Bayesian inferential framework for multivariate, sparse functional data (MSFAST) which explicitly models the PCs and incorporates their uncertainty. MSFAST builds upon the FAST approach to FPCA for univariate, densely-observed functional data. Like FAST, MSFAST represents PCs using orthonormal splines, samples the orthonormal spline coefficients using parameter expansion, and enforces eigenvalue ordering during model fit. MSFAST extends FAST to multivariate, sparsely-observed data by (1) standardizing each functional covariate to mitigate poor posterior conditioning due to disparate scales; (2) using a better-suited orthogonal spline basis; (3) parallelizing likelihood calculations over covariates; (4) updating parameterizations and priors for computational stability; (5) using a Procrustes-based posterior alignment procedure; and (6) providing efficient prediction routines. We evaluated MSFAST alongside existing implementations using simulations. MSFAST produces uniquely valid inferences and accurate estimates, particularly for smaller signals. MSFAST is motivated by and applied to a study of child growth, with an accompanying vignette illustrating the implementation step-by-step.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03511v1" target="_blank">Achieving quantum-limited sub-Rayleigh identification of incoherent sources with arbitrary intensities</a></h3>
                    <p><strong>Authors:</strong> Danilo Triggiani, Cosmo Lupo</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> The Rayleigh diffraction limit imposes a fundamental restriction on the resolution of direct imaging systems, hindering the identification of incoherent optical sources, such as celestial bodies in astronomy and fluorophores in bioimaging. Recent advances in quantum sensing have shown that this limit can be circumvented through spatial demultiplexing (SPADE) and photon detection. Notably, the latter is a semi-classical detection strategy, being SPADE a linear transformation of the field and photon detection a measurement of intensity. However, the general optimality for arbitrary intensity distributions and bright sources remains unproven. In this work, we develop a general model for incoherent light with arbitrary intensity collected by passive, linear optical systems. We employ this framework to compute the quantum Chernoff exponent for generic incoherent-source discrimination problems, and we analyze several special cases, with particular focus on the subdiffraction regime for Gaussian point-spread functions. We show that, surprisingly, SPADE measurements do not always saturate the quantum Chernoff bound in the subdiffraction regime; the quantum optimality holds only when certain compatibility conditions, such as covariance matrix commutativity, are met. These findings suggest that collective measurements may actually be needed to achieve the ultimate quantum Chernoff bound for the discrimination of specific incoherent sources. For the fully general case, our analysis can still be used to find the best SPADE configurations, generally achieved through a hypotheses-dependent rotation of the SPADE modes. Our results advance the theory of quantum-limited optical discrimination, with possible applications in diagnostics, automated image interpretation, and galaxy identification.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03510v1" target="_blank">A comprehensive Persian offline handwritten database for investigating the effects of heritability and family relationships on handwriting</a></h3>
                    <p><strong>Authors:</strong> Abbas Zohrevand, Javad Sadri, Zahra Imani</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper introduces a comprehensive database for research and investigation on the effects of inheritance on handwriting. A database has been created that can be used to answer questions such as: Is there a genetic component to handwriting? Is handwriting inherited? Do family relationships affect handwriting? Varieties of samples of handwritten components such as: digits, letters, shapes and free paragraphs of 210 families including (grandparents, parents, uncles, aunts, siblings, cousins, nephews and nieces) have been collected using specially designed forms, and family relationships of all writers are captured. To the best of our knowledge, no such database is presently available. Based on comparisons and investigation of features of handwritings of family members, similarities among their features and writing styles are detected. Our database is freely available to the pattern recognition community and hope it will pave the way for investigations on the effects of inheritance and family relationships on handwritings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03508v1" target="_blank">Bouncing Cosmologies in modified gravity with space time torsion</a></h3>
                    <p><strong>Authors:</strong> Sonej Alam, Somasri Sen, Soumitra Sengupta</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.CO</p>
                    <p><strong>Summary:</strong> We explore the possibility of realizing a non-singular bounce in the early universe within the framework of modified gravity with spacetime torsion. In Einstein Cartan theory, torsion is embedded in the spacetime by adding an antisymmetric part in affine connection . We consider generalized version of the framework as $f(\bar{R})$, $\bar{R}$ being the scalar of the modified curvature tensor. $f(\bar{R})$ gravity is recast in Einstein frame as non-minimally coupled scalar tensor theory where the scalar field gets coupled with a rank 2 antisymmetric torsion field through derivative couplings. We investigate whether the introduction of three additional torsion-dependent terms in Einstein frame help to realize a bounce. We first explore this cosmological system in the background of a homogeneous and isotropic FRW spacetime but inclusion of the torsion terms are insufficient to produce a bounce in this symmetric setting. Motivated by this limitation, we relax the symmetry and generalize the background to include inhomogeneity and anisotropy. In this setup, the dynamics is modified in such a way that a bouncing solution is possible without invoking phantom fields or energy condition violations. We have also found the exact solutions of all the fields and reconstructed the modified gravity form.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03507v1" target="_blank">Influence of Perfect Fluid Dark Matter on Shadow Observables of Yang-Mills modified charged black holes</a></h3>
                    <p><strong>Authors:</strong> Md Sabir Ali, Abhishek Negi, Sanjay Pant</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We investigate the influence of perfect fluid dark matter (PFDM) on Yang--Mills--inspired charged black holes, with a particular focus on the resulting modifications to key black hole observables. By embedding a PFDM term into the spacetime geometry, we examine the alterations in shadow morphology, photon geodesics, and the associated energy emission spectra. Our analysis reveals that PFDM induces notable deviations in the shadow size, shape, and circularity, and significantly impacts the stability of circular orbits. Furthermore, the energy emission rate exhibits a strong dependence on both the Yang--Mills charge and the dark matter distribution. These results indicate that environmental effects arising from dark matter can imprint observable signatures on black hole shadows and radiation processes, offering a potential pathway to constrain dark matter models and probe non-Kerr geometries with forthcoming high-precision observations such as those from the Event Horizon Telescope and next-generation interferometers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03505v1" target="_blank">LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence</a></h3>
                    <p><strong>Authors:</strong> Xingxuan Zhang, Gang Ren, Han Yu, Hao Yuan, Hui Wang, Jiansheng Li, Jiayun Wu, Lang Mo, Li Mao, Mingchao Hao, Ningbo Dai, Renzhe Xu, Shuyang Li, Tianyang Zhang, Yue He, Yuanrui Wang, Yunjia Zhang, Zijing Xu, Dongzhe Li, Fang Gao, Hao Zou, Jiandong Liu, Jiashuo Liu, Jiawei Xu, Kaijie Cheng, Kehan Li, Linjun Zhou, Qing Li, Shaohua Fan, Xiaoyu Lin, Xinyan Han, Xuanyue Li, Yan Lu, Yuan Xue, Yuanyuan Jiang, Zimu Wang, Zhenlei Wang, Peng Cui</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> We argue that progress toward general intelligence requires complementary foundation models grounded in language, the physical world, and structured data. This report presents LimiX, the first installment of our large structured-data models (LDMs). LimiX treats structured data as a joint distribution over variables and missingness, thus capable of addressing a wide range of tabular tasks through query-based conditional prediction via a single model. LimiX is pretrained using masked joint-distribution modeling with an episodic, context-conditional objective, where the model predicts for query subsets conditioned on dataset-specific contexts, supporting rapid, training-free adaptation at inference. We evaluate LimiX across 10 large structured-data benchmarks with broad regimes of sample size, feature dimensionality, class number, categorical-to-numerical feature ratio, missingness, and sample-to-feature ratios. With a single model and a unified interface, LimiX consistently surpasses strong baselines including gradient-boosting trees, deep tabular networks, recent tabular foundation models, and automated ensembles, as shown in Figure 1 and Figure 2. The superiority holds across a wide range of tasks, such as classification, regression, missing value imputation, and data generation, often by substantial margins, while avoiding task-specific architectures or bespoke training per task. All LimiX models are publicly accessible under Apache 2.0.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03501v1" target="_blank">Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data</a></h3>
                    <p><strong>Authors:</strong> Honglu Zhou, Xiangyu Peng, Shrikant Kendre, Michael S. Ryoo, Silvio Savarese, Caiming Xiong, Juan Carlos Niebles</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Next-generation AI companions must go beyond general video understanding to resolve spatial and temporal references in dynamic, real-world environments. Existing Video Large Language Models (Video LLMs), while capable of coarse-level comprehension, struggle with fine-grained, spatiotemporal reasoning, especially when user queries rely on time-based event references for temporal anchoring, or gestural cues for spatial anchoring to clarify object references and positions. To bridge this critical gap, we introduce Strefer, a synthetic instruction data generation framework designed to equip Video LLMs with spatiotemporal referring and reasoning capabilities. Strefer produces diverse instruction-tuning data using a data engine that pseudo-annotates temporally dense, fine-grained video metadata, capturing rich spatial and temporal information in a structured manner, including subjects, objects, their locations as masklets, and their action descriptions and timelines. Our approach enhances the ability of Video LLMs to interpret spatial and temporal references, fostering more versatile, space-time-aware reasoning essential for real-world AI companions. Without using proprietary models, costly human annotation, or the need to annotate large volumes of new videos, experimental evaluations show that models trained with data produced by Strefer outperform baselines on tasks requiring spatial and temporal disambiguation. Additionally, these models exhibit enhanced space-time-aware reasoning, establishing a new foundation for perceptually grounded, instruction-tuned Video LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03500v1" target="_blank">Real-Time Instrument Planning and Perception for Novel Measurements of Dynamic Phenomena</a></h3>
                    <p><strong>Authors:</strong> Itai Zilberstein, Alberto Candela, Steve Chien</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI</p>
                    <p><strong>Summary:</strong> Advancements in onboard computing mean remote sensing agents can employ state-of-the-art computer vision and machine learning at the edge. These capabilities can be leveraged to unlock new rare, transient, and pinpoint measurements of dynamic science phenomena. In this paper, we present an automated workflow that synthesizes the detection of these dynamic events in look-ahead satellite imagery with autonomous trajectory planning for a follow-up high-resolution sensor to obtain pinpoint measurements. We apply this workflow to the use case of observing volcanic plumes. We analyze classification approaches including traditional machine learning algorithms and convolutional neural networks. We present several trajectory planning algorithms that track the morphological features of a plume and integrate these algorithms with the classifiers. We show through simulation an order of magnitude increase in the utility return of the high-resolution instrument compared to baselines while maintaining efficient runtimes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03499v1" target="_blank">DeepSea MOT: A benchmark dataset for multi-object tracking on deep-sea video</a></h3>
                    <p><strong>Authors:</strong> Kevin Barnard, Elaine Liu, Kristine Walz, Brian Schlining, Nancy Jacobsen Stout, Lonny Lundsten</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Benchmarking multi-object tracking and object detection model performance is an essential step in machine learning model development, as it allows researchers to evaluate model detection and tracker performance on human-generated test data, facilitating consistent comparisons between models and trackers and aiding performance optimization. In this study, a novel benchmark video dataset was developed and used to assess the performance of several Monterey Bay Aquarium Research Institute object detection models and a FathomNet single-class object detection model together with several trackers. The dataset consists of four video sequences representing midwater and benthic deep-sea habitats. Performance was evaluated using Higher Order Tracking Accuracy, a metric that balances detection, localization, and association accuracy. To the best of our knowledge, this is the first publicly available benchmark for multi-object tracking in deep-sea video footage. We provide the benchmark data, a clearly documented workflow for generating additional benchmark videos, as well as example Python notebooks for computing metrics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03498v1" target="_blank">OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and Generation</a></h3>
                    <p><strong>Authors:</strong> Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang Weng, Jingang Wang, Xunliang Cai, Wenrui Dai, Hongkai Xiong</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce OneCAT, a unified multimodal model that seamlessly integrates understanding, generation, and editing within a novel, pure decoder-only transformer architecture. Our framework uniquely eliminates the need for external components such as Vision Transformers (ViT) or vision tokenizer during inference, leading to significant efficiency gains, especially for high-resolution inputs. This is achieved through a modality-specific Mixture-of-Experts (MoE) structure trained with a single autoregressive (AR) objective, which also natively supports dynamic resolutions. Furthermore, we pioneer a multi-scale visual autoregressive mechanism within the Large Language Model (LLM) that drastically reduces decoding steps compared to diffusion-based methods while maintaining state-of-the-art performance. Our findings demonstrate the powerful potential of pure autoregressive modeling as a sufficient and elegant foundation for unified multimodal intelligence. As a result, OneCAT sets a new performance standard, outperforming existing open-source unified multimodal models across benchmarks for multimodal generation, editing, and understanding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03496v1" target="_blank">Information-Theoretic Lower Bounds for Approximating Monomials via Optimal Quantum Tsallis Entropy Estimation</a></h3>
                    <p><strong>Authors:</strong> Qisheng Wang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.CC, cs.IT, math.CA, math.IT</p>
                    <p><strong>Summary:</strong> This paper reveals a conceptually new connection from information theory to approximation theory via quantum algorithms for entropy estimation. Specifically, we provide an information-theoretic lower bound $\Omega(\sqrt{n})$ on the approximate degree of the monomial $x^n$, compared to the analytic lower bounds shown in Newman and Rivlin (Aequ. Math. 1976) via Fourier analysis and in Sachdeva and Vishnoi (Found. Trends Theor. Comput. Sci. 2014) via the Markov brothers inequality. This is done by relating the polynomial approximation of monomials to quantum Tsallis entropy estimation. This further implies a quantum algorithm that estimates to within additive error $\varepsilon$ the Tsallis entropy of integer order $q \geq 2$ of an unknown probability distribution $p$ or an unknown quantum state $\rho$, using $\widetilde \Theta(\frac{1}{\sqrt{q}\varepsilon})$ queries to the quantum oracle that produces a sample from $p$ or prepares a copy of $\rho$, improving the prior best $O(\frac{1}{\varepsilon})$ via the Shift test due to Ekert, Alves, Oi, Horodecki, Horodecki and Kwek (Phys. Rev. Lett. 2002). To the best of our knowledge, this is the first quantum entropy estimator with optimal query complexity (up to polylogarithmic factors) for all parameters simultaneously.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03495v1" target="_blank">Learning AC Power Flow Solutions using a Data-Dependent Variational Quantum Circuit</a></h3>
                    <p><strong>Authors:</strong> Thinh Viet Le, Md Obaidur Rahman, Vassilis Kekatos</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.LG, cs.SY, eess.SY, math.OC</p>
                    <p><strong>Summary:</strong> Interconnection studies require solving numerous instances of the AC load or power flow (AC PF) problem to simulate diverse scenarios as power systems navigate the ongoing energy transition. To expedite such studies, this work leverages recent advances in quantum computing to find or predict AC PF solutions using a variational quantum circuit (VQC). VQCs are trainable models that run on modern-day noisy intermediate-scale quantum (NISQ) hardware to accomplish elaborate optimization and machine learning (ML) tasks. Our first contribution is to pose a single instance of the AC PF as a nonlinear least-squares fit over the VQC trainable parameters (weights) and solve it using a hybrid classical/quantum computing approach. The second contribution is to feed PF specifications as features into a data-embedded VQC and train the resultant quantum ML (QML) model to predict general PF solutions. The third contribution is to develop a novel protocol to efficiently measure AC-PF quantum observables by exploiting the graph structure of a power network. Preliminary numerical tests indicate that the proposed VQC models attain enhanced prediction performance over a deep neural network despite using much fewer weights. The proposed quantum AC-PF framework sets the foundations for addressing more elaborate grid tasks via quantum computing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03494v1" target="_blank">Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual Prompts for NR-IQA</a></h3>
                    <p><strong>Authors:</strong> Yahya Benmahane, Mohammed El Hassouni</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this paper, we propose a novel parameter-efficient adaptation method for No- Reference Image Quality Assessment (NR-IQA) using visual prompts optimized in pixel-space. Unlike full fine-tuning of Multimodal Large Language Models (MLLMs), our approach trains only 600K parameters at most ( 0.01% of the base model), while keeping the underlying model fully frozen. During inference, these visual prompts are combined with images via addition and processed by mPLUG-Owl2 with the textual query Rate the technical quality of the image. Evaluations across distortion types (synthetic, realistic, AI-generated) on KADID- 10k, KonIQ-10k, and AGIQA-3k demonstrate competitive performance against full finetuned methods and specialized NR-IQA models, achieving 0.93 SRCC on KADID-10k. To our knowledge, this is the first work to leverage pixel-space visual prompts for NR-IQA, enabling efficient MLLM adaptation for low-level vision tasks. The source code is publicly available at https: // github. com/ yahya-ben/ mplug2-vp-for-nriqa .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03482v1" target="_blank">Programmable control of the spatiotemporal quantum noise of light</a></h3>
                    <p><strong>Authors:</strong> Jamison Sloan, Michael Horodynski, Shiekh Zia Uddin, Yannick Salamin, Michael Birk, Pavel Sidorenko, Ido Kaminer, Marin SoljaÄiÄ‡, Nicholas Rivera</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> physics.optics</p>
                    <p><strong>Summary:</strong> Optoelectronic systems based on multiple modes of light can often exceed the performance of their single-mode counterparts. However, multimode nonlinear interactions often introduce considerable amounts of noise, limiting the ultimate performance of these systems. It is therefore crucial to develop ways to simultaneously control complex nonlinear interactions while also gaining control over their noise. Here, we show that noise buildup in nonlinear multimode systems can be strongly suppressed by controlling the input wavefront. We demonstrate this approach in a multimode fiber by using an active wavefront-shaping protocol to focus a region of high intensity - yet low intensity noise - at the output. Our programmable control of both the input and output reduces the beam noise by 12 dB beyond what linear attenuation achieves, reaching levels near the quantum shot-noise limit. We show that this is possible because the optimally shaped wavefront maximally decouples the output intensity fluctuations from the input laser fluctuations. These findings are supported by a new theoretical and simulation framework that efficiently captures spatiotemporal quantum noise dynamics in highly multimode nonlinear systems. Our results highlight the potential of programmable wavefront shaping to enable nonlinear multimode technologies that overcome noise buildup to operate at quantum-noise limits.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03481v1" target="_blank">PoolPy: Flexible Group Testing Design for Large-Scale Screening</a></h3>
                    <p><strong>Authors:</strong> Lorenzo Talamanca, Julian Trouillon</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> In large screening campaigns, group testing can greatly reduce the number of tests needed when compared to testing each sample individually. However, choosing and applying an appropriate group testing method remains challenging due to the wide variety in design and performance across methods, and the lack of accessible tools. Here, we present PoolPy, a unified framework for designing and selecting optimal group testing strategies across ten different methods according to user-defined constraints, such as time, cost or sample dilution. By computing over 10,000 group testing designs made available through a web interface, we identified key trade-offs, such as minimizing test number or group size, that define applicability to specific use cases. Overall, we show that no single method is universally optimal, and provide clear indications for method choice on a case-by-case basis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03480v1" target="_blank">Verification of the Black Hole Area Law with GW230814</a></h3>
                    <p><strong>Authors:</strong> Shao-Peng Tang, Hai-Tian Wang, Yin-Jie Li, Yi-Zhong Fan</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We present observational confirmation of Hawkings black-hole area theorem using the newly released gravitational-wave data from the GWTC-4 catalog. We have analyzed two high signal-to-noise ratio binary black hole (BBH) merger events, including GW230814 and GW231226, from the first part of the LIGO-Virgo-KAGRA O4 run, and measured the (total) horizon area of the black holes before and after merger. For both events, the horizon area of the remnant black hole is found to be greater than the total horizon area of the two pre-merger black holes at a high possibility (effectively $\gtrsim 99\%$), and particularly with GW230814 we have a significance level of $\gtrsim 5\sigma$ for the {\it first} time. These results provide the direct convincing verification of the black-hole area law, further bolstering the validity of classical general relativity in the dynamical, strong-field regime.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.62051/ijcsit.v5n2.02" target="_blank">Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games</a></h3>
                    <p><strong>Authors:</strong> Haonan Wang, Mingjia Zhao, Junfeng Sun, Wei Liu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> As AI technology advances, research in playing text-based games with agents has becomeprogressively popular. In this paper, a novel approach to agent design and agent learning ispresented with the context of reinforcement learning. A model of deep learning is first applied toprocess game text and build a world model. Next, the agent is learned through a policy gradient-based deep reinforcement learning method to facilitate conversion from state value to optimal policy.The enhanced agent works better in several text-based game experiments and significantlysurpasses previous agents on game completion ratio and win rate. Our study introduces novelunderstanding and empirical ground for using reinforcement learning for text games and sets thestage for developing and optimizing reinforcement learning agents for more general domains andproblems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03478v1" target="_blank">Local Well-Posedness for the Bartnik Stationary Extension Problem near Schwarzschild Spheres</a></h3>
                    <p><strong>Authors:</strong> Ahmed Ellithy</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> gr-qc, math.AP, math.DG</p>
                    <p><strong>Summary:</strong> We investigate the Bartnik stationary extension conjecture, which arises from the definition of the spacetime Bartnik mass for a compact region in a general initial data set satisfying the dominant energy condition. This conjecture posits the existence and uniqueness (up to isometry) of an asymptotically flat stationary vacuum spacetime containing an initial data set $(M, \mathfrak{g}, \Pi)$ that realizes prescribed Bartnik boundary data on $\partial M$, consisting of the induced metric, mean curvature, and appropriate components of the spacetime extrinsic curvature $\Pi$. Building on the analytic framework developed in arXiv:2411.02801 for the static case, we show that, in a double geodesic gauge, the stationary vacuum Einstein equations reduce to a coupled system comprising elliptic and transport-type equations, with the genuinely stationary contributions encoded in an additional boundary value problem for a $1$-form $\theta$. Our approach employs both a geodesic gauge for the quotient metric $g$ in the quotient formalism and a $\theta$-geodesic gauge for the $1$-form $\theta$. We establish local well-posedness for the Bartnik stationary metric extension problem for Bartnik data sufficiently close to that of any coordinate sphere in a Schwarzschild ${t=0}$ slice, including data with arbitrarily small mean curvature. A key feature of our framework is that the linearized equations decouple: the equations for the metric and potential reduce to the previously solved static case, while the boundary value problem for $\theta$ is treated independently. We prove solvability of this boundary value problem in the Bochner-measurable function spaces adapted to the coupled system developed in arXiv:2411.02801, establishing uniform estimates for the vector spherical harmonic decomposition of $\theta$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03477v1" target="_blank">Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning</a></h3>
                    <p><strong>Authors:</strong> Duy A. Nguyen, Abhi Kamboj, Minh N. Do</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Addressing missing modalities and limited labeled data is crucial for advancing robust multimodal learning. We propose Robult, a scalable framework designed to mitigate these challenges by preserving modality-specific information and leveraging redundancy through a novel information-theoretic approach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled (PU) contrastive loss that maximizes task-relevant feature alignment while effectively utilizing limited labeled data in semi-supervised settings, and (2) a latent reconstruction loss that ensures unique modality-specific information is retained. These strategies, embedded within a modular design, enhance performance across various downstream tasks and ensure resilience to incomplete modalities during inference. Experimental results across diverse datasets validate that Robult achieves superior performance over existing approaches in both semi-supervised learning and missing modality contexts. Furthermore, its lightweight design promotes scalability and seamless integration with existing architectures, making it suitable for real-world multimodal applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03473v1" target="_blank">Painted loading: a toolkit for loading spatially large optical tweezer arrays</a></h3>
                    <p><strong>Authors:</strong> Mitchell J. Walker, Ryuji Moriya, Jack D. Segal, Liam A. P. Gallagher, Matthew Hill, FrÃ©dÃ©ric Leroux, Zhongxiao Xu, Matthew P. A. Jones</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph</p>
                    <p><strong>Summary:</strong> Arrays of neutral atoms in optical tweezers are widely used in quantum simulation and computation, and precision frequency metrology. The capabilities of these arrays are enhanced by maximising the number of available sites. Here we increase the spatial extent of a two-dimensional array of strontium-88 atoms by sweeping the frequency of the cooling light to move the atomic reservoir across the array. We load arrays with vertical heights of 100 {\mu}m, exceeding the height of an array loaded from a static reservoir by a factor of 3. We investigate the site-to-site atom number distribution, tweezer lifetime, and temperature, achieving an average temperature across the array of 1.49(3) {\mu}K. By controlling the frequency sweep we show it is possible to control the distribution of atoms across the array, including uniform and non-uniformly loaded arrays, and arrays with selectively loaded regions. We explain our results using a rate equation model which is in good qualitative agreement with the data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03472v1" target="_blank">DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling</a></h3>
                    <p><strong>Authors:</strong> Yubo Gao, Renbo Tu, Gennady Pekhimenko, Nandita Vijaykumar</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.DC</p>
                    <p><strong>Summary:</strong> Differentially-Private SGD (DP-SGD) is a powerful technique to protect user privacy when using sensitive data to train neural networks. During training, converting model weights and activations into low-precision formats, i.e., quantization, can drastically reduce training times, energy consumption, and cost, and is thus a widely used technique. In this work, we demonstrate that quantization causes significantly higher accuracy degradation in DP-SGD compared to regular SGD. We observe that this is caused by noise injection in DP-SGD, which amplifies quantization variance, leading to disproportionately large accuracy degradation. To address this challenge, we present QPQuant, a dynamic quantization framework that adaptively selects a changing subset of layers to quantize at each epoch. Our method combines two key ideas that effectively reduce quantization variance: (i) probabilistic sampling of the layers that rotates which layers are quantized every epoch, and (ii) loss-aware layer prioritization, which uses a differentially private loss sensitivity estimator to identify layers that can be quantized with minimal impact on model quality. This estimator consumes a negligible fraction of the overall privacy budget, preserving DP guarantees. Empirical evaluations on ResNet18, ResNet50, and DenseNet121 across a range of datasets demonstrate that DPQuant consistently outperforms static quantization baselines, achieving near Pareto-optimal accuracy-compute trade-offs and up to 2.21x theoretical throughput improvements on low-precision hardware, with less than 2% drop in validation accuracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03470v1" target="_blank">Modified Unruh Thermodynamics in Emergent Gravity: Finite Heat Capacity and RÃ©nyi Entropy</a></h3>
                    <p><strong>Authors:</strong> F. Barzi, H. El Moumni, K. Masmar</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> We show that Jacobsons thermodynamic derivation of Einsteins equations remains valid when local Rindler horizons are treated as finite heat-capacity systems, resolving the unphysical infinite-bath assumption of standard Unruh thermodynamics. The resulting entropy takes the form of R\enyi entropy with nonextensivity parameter $\lambda\sim C^{-1}$, or equivalently, a new Einstein entropy that exactly preserves the Einstein equations for all heat capacities. In both cases, the Unruh temperature is modified as \begin{equation*} T_\text{mod}=\frac{\hbar\kappa}{2\pi}\left(1+\frac{S}{C}\right), \end{equation*} establishing a universal link between finite-capacity thermodynamics and nonextensive entropy. We further obtain a corrected scalar Einstein equation with an upper bound on horizon energy flux, pointing to testable signatures in heavy-ion collisions, accelerator spin polarization, and analog gravity experiments. These results reinforce the robustness of the emergent-gravity paradigm and connect spacetime dynamics to generalized entropies of quantum information theory.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03469v1" target="_blank">Signatures of emergent surface states across a displacive topological phase transition in Bi$_4$I$_4$</a></h3>
                    <p><strong>Authors:</strong> Deep Singha Roy, Sk Kalimuddin, Subrata Pachhal, Saikat Mondal, Soham Das, Sukanya Jana, Arnab Bera, Satyabrata Bera, Tuhin Debnath, Ankan Bag, Souvik Pramanik, Sudipta Chatterjee, Sanjib Naskar, Shishir Kumar Pandey, Adhip Agarwala, Mintu Mondal</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mes-hall, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Topological phase transitions involving crystalline symmetry breaking provide a fertile ground to explore the interplay between symmetry, topology, and emergent quantum phenomena. Recently discovered quasi-one-dimensional topological material, Bi$_4$I$_4$, has been predicted to host topologically non-trivial gapless surfaces at high temperature, which undergo a finite temperature phase transition to a low temperature gapped phase. Here we present experimental signatures of this room temperature phase transition from a high-temperature $\beta$-phase with a surface state to a gapped $\alpha$-phase hosting hinge states. Using real-space current mapping and resistance fluctuation spectroscopy, we identify signatures of a displacive topological phase transition mediated by a first-order thermodynamic structural change. Near the emergence of $\beta$-phase, we observe pronounced telegraphic noise, indicating fluctuating phase domains with topological surface states. The spatially resolved current map reveals electron transport via the gapless surface states in the $\beta$-phase, which vanishes upon transitioning to the $\alpha$-phase with localized conduction channels (or hinge modes). Our experimental results, supported by first principles estimates and effective theory of a topological displacive phase transition, establish Bi$_4$I$_4$ as a candidate material showing intricate interplay of classical thermodynamic phase transitions with topological quantum phenomena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03467v1" target="_blank">Continuous Saudi Sign Language Recognition: A Vision Transformer Approach</a></h3>
                    <p><strong>Authors:</strong> Soukeina Elhassen, Lama Al Khuzayem, Areej Alhothali, Ohoud Alzamzami, Nahed Alowaidi</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Sign language (SL) is an essential communication form for hearing-impaired and deaf people, enabling engagement within the broader society. Despite its significance, limited public awareness of SL often leads to inequitable access to educational and professional opportunities, thereby contributing to social exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend on Saudi Sign Language (SSL) as their primary form of communication. Although certain technological approaches have helped to improve communication for individuals with hearing impairments, there continues to be an urgent requirement for more precise and dependable translation techniques, especially for Arabic sign language variants like SSL. Most state-of-the-art solutions have primarily focused on non-Arabic sign languages, resulting in a considerable absence of resources dedicated to Arabic sign language, specifically SSL. The complexity of the Arabic language and the prevalence of isolated sign language datasets that concentrate on individual words instead of continuous speech contribute to this issue. To address this gap, our research represents an important step in developing SSL resources. To address this, we introduce the first continuous Saudi Sign Language dataset called KAU-CSSL, focusing on complete sentences to facilitate further research and enable sophisticated recognition systems for SSL recognition and translation. Additionally, we propose a transformer-based model, utilizing a pretrained ResNet-18 for spatial feature extraction and a Transformer Encoder with Bidirectional LSTM for temporal dependencies, achieving 99.02\% accuracy at signer dependent mode and 77.71\% accuracy at signer independent mode. This development leads the way to not only improving communication tools for the SSL community but also making a substantial contribution to the wider field of sign language.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03465v1" target="_blank">Joint Training of Image Generator and Detector for Road Defect Detection</a></h3>
                    <p><strong>Authors:</strong> Kuan-Chuan Peng</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Road defect detection is important for road authorities to reduce the vehicle damage caused by road defects. Considering the practical scenarios where the defect detectors are typically deployed on edge devices with limited memory and computational resource, we aim at performing road defect detection without using ensemble-based methods or test-time augmentation (TTA). To this end, we propose to Jointly Train the image Generator and Detector for road defect detection (dubbed as JTGD). We design the dual discriminators for the generative model to enforce both the synthesized defect patches and overall images to look plausible. The synthesized image quality is improved by our proposed CLIP-based Fr\echet Inception Distance loss. The generative model in JTGD is trained jointly with the detector to encourage the generative model to synthesize harder examples for the detector. Since harder synthesized images of better quality caused by the aforesaid design are used in the data augmentation, JTGD outperforms the state-of-the-art method in the RDD2022 road defect detection benchmark across various countries under the condition of no ensemble and TTA. JTGD only uses less than 20% of the number of parameters compared with the competing baseline, which makes it more suitable for deployment on edge devices in practice.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03462v1" target="_blank">sam-llm: interpretable lane change trajectoryprediction via parametric finetuning</a></h3>
                    <p><strong>Authors:</strong> Zhuo Cao, Yunxiao Shi, Min Xu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> This work introduces SAM-LLM, a novel hybrid architecture that bridges the gap between the contextual reasoning of Large Language Models (LLMs) and the physical precision of kinematic lane change models for autonomous driving. The system is designed for interpretable lane change trajectory prediction by finetuning an LLM to output the core physical parameters of a trajectory model instead of raw coordinates. For lane-keeping scenarios, the model predicts discrete coordinates, but for lane change maneuvers, it generates the parameters for an enhanced Sinusoidal Acceleration Model (SAM), including lateral displacement, maneuver duration, initial lateral velocity, and longitudinal velocity change. This parametric approach yields a complete, continuous, and physically plausible trajectory model that is inherently interpretable and computationally efficient, achieving an 80% reduction in output size compared to coordinate-based methods. The SAM-LLM achieves a state-of-the-art overall intention prediction accuracy of 98.73%, demonstrating performance equivalent to traditional LLM predictors while offering significant advantages in explainability and resource efficiency.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3586183.3606821" target="_blank">SmartPoser: Arm Pose Estimation with a Smartphone and Smartwatch Using UWB and IMU Data</a></h3>
                    <p><strong>Authors:</strong> Nathan DeVrio, Vimal Mollyn, Chris Harrison</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CV, cs.GR, cs.RO</p>
                    <p><strong>Summary:</strong> The ability to track a users arm pose could be valuable in a wide range of applications, including fitness, rehabilitation, augmented reality input, life logging, and context-aware assistants. Unfortunately, this capability is not readily available to consumers. Systems either require cameras, which carry privacy issues, or utilize multiple worn IMUs or markers. In this work, we describe how an off-the-shelf smartphone and smartwatch can work together to accurately estimate arm pose. Moving beyond prior work, we take advantage of more recent ultra-wideband (UWB) functionality on these devices to capture absolute distance between the two devices. This measurement is the perfect complement to inertial data, which is relative and suffers from drift. We quantify the performance of our software-only approach using off-the-shelf devices, showing it can estimate the wrist and elbow joints with a \hl{median positional error of 11.0~cm}, without the user having to provide training data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03445v1" target="_blank">Phase Diagram and dynamical phases of self organization of a Bose--Einstein condensate in a transversely pumped red-detuned cavity</a></h3>
                    <p><strong>Authors:</strong> Julian Mayr, Maria Laura Staffini, Simon B. JÃ¤ger, Corinna Kollath, Jonathan Keeling</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas, quant-ph</p>
                    <p><strong>Summary:</strong> We study a transversely pumped atomic Bose--Einstein Condensate coupled to a single-mode optical cavity, where effective atom--atom interactions are mediated by pump and cavity photons. A number of experiments and theoretical works have shown the formation of a superradiant state in this setup, where interference of pump and cavity light leads to an optical lattice in which atoms self-consistently organize. This self-organization has been extensively studied using the approximate Dicke model (truncating to two momentum states), as well as through numerical Gross--Pitaevskii simulations in one and two dimensions. Here, we perform a full mean-field analysis of the system, including all relevant atomic momentum states and the cavity field. We map out the steady-state phase diagram vs pump strength and cavity detuning, and provide an in-depth understanding of the instabilities that are linked to the emergence of spatio-temporal patterns. We find and describe parameter regimes where mean-field predicts bistability, regimes where the dynamics form chaotic trajectories, instabilities caused by resonances between normal mode excitations, and states with atomic dynamics but vanishing cavity field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03444v1" target="_blank">The stability of the de-Sitter universe in nonlocal gravity</a></h3>
                    <p><strong>Authors:</strong> Haiyuan Feng, Rong-Jia Yang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We constructed the ghost-free condition for nonlocal gravity using de-Sitter background field expansion and identified the structure of the nontrivial form factors. Our analysis shows that the particle spectrum of this model is nearly equivalent to general relativity (GR), with the potential addition of a scalar particle with positive mass m. Additionally, by employing recursion relations, we established the equivalence between nonlocal gravity and higher-derivative gravity. Moreover, we provided a comprehensive non-perturbative proof of the stability of de-Sitter solution within the nonlocal framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03440v1" target="_blank">Wigner function of a rigidly rotating and magnetized QED plasma</a></h3>
                    <p><strong>Authors:</strong> M. Kiamari, N. Sadooghi</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-ph, hep-th, nucl-th</p>
                    <p><strong>Summary:</strong> We determine the Wigner function of a rigidly rotating quantum electrodynamics (QED) plasma in the presence of a constant magnetic field by utilizing the Riemannian normal coordinate approximation, which has been previously proposed in the literature. In this approach, the angular velocity appears only in a specific phase factor, allowing us to compute the point-split fermion two-point correlation function in flat spacetime. To ensure that the fermion correlation function is gauge invariant, we introduce a background gauge field that is fixed to produce a constant magnetic field. Using this Wigner function, we derive the energy-momentum tensor for this medium, which consists of both diagonal and off-diagonal components. By comparing our results with the energy-momentum tensor of an ideal spinful and vortical magnetized fluid, we establish a connection between these components and thermodynamic quantities, such as energy density and different types of pressure. We demonstrate that rigid rotation leads to pressure anisotropy in plasma. Additionally, we compute the associated vector and axial vector currents for this medium, utilizing the previously presented Wigner function. Our results are consistent with existing literature on the subject.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03433v1" target="_blank">Decoding Visual Neural Representations by Multimodal with Dynamic Balancing</a></h3>
                    <p><strong>Authors:</strong> Kaili sun, Xingyu Miao, Bing Zhai, Haoran Duan, Yang Long</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this work, we propose an innovative framework that integrates EEG, image, and text data, aiming to decode visual neural representations from low signal-to-noise ratio EEG signals. Specifically, we introduce text modality to enhance the semantic correspondence between EEG signals and visual content. With the explicit semantic labels provided by text, image and EEG features of the same category can be more closely aligned with the corresponding text representations in a shared multimodal space. To fully utilize pre-trained visual and textual representations, we propose an adapter module that alleviates the instability of high-dimensional representation while facilitating the alignment and fusion of cross-modal features. Additionally, to alleviate the imbalance in multimodal feature contributions introduced by the textual representations, we propose a Modal Consistency Dynamic Balance (MCDB) strategy that dynamically adjusts the contribution weights of each modality. We further propose a stochastic perturbation regularization (SPR) term to enhance the generalization ability of semantic perturbation-based models by introducing dynamic Gaussian noise in the modality optimization process. The evaluation results on the ThingsEEG dataset show that our method surpasses previous state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by 2.0\% and 4.7\% respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03430v1" target="_blank">EclipseTouch: Touch Segmentation on Ad Hoc Surfaces using Worn Infrared Shadow Casting</a></h3>
                    <p><strong>Authors:</strong> Vimal Mollyn, Nathan DeVrio, Chris Harrison</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CV, cs.GR, cs.RO</p>
                    <p><strong>Summary:</strong> The ability to detect touch events on uninstrumented, everyday surfaces has been a long-standing goal for mixed reality systems. Prior work has shown that virtual interfaces bound to physical surfaces offer performance and ergonomic benefits over tapping at interfaces floating in the air. A wide variety of approaches have been previously developed, to which we contribute a new headset-integrated technique called \systemname. We use a combination of a computer-triggered camera and one or more infrared emitters to create structured shadows, from which we can accurately estimate hover distance (mean error of 6.9~mm) and touch contact (98.0\% accuracy). We discuss how our technique works across a range of conditions, including surface material, interaction orientation, and environmental lighting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03428v1" target="_blank">Ultrafast single-photon interference with a dipole qubit in a nanocavity</a></h3>
                    <p><strong>Authors:</strong> Athul S. Rema, AdriÃ¡n E. Rubio LÃ³pez, Felipe Herrera</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.mes-hall, physics.atom-ph</p>
                    <p><strong>Summary:</strong> The stationary spectrum of individual dipole emitters in plasmonic nanocavities has been studied for a range of cavity geometries and dipole configurations. Less is known about the coherent dynamics of single photon creation in the nanocavity near field by an excited dipole. We address this gap by developing a Lorentzian kernel approximation that solves the time-dependent Schr\odinger equation that describes the coupled dipole-photon dynamics in the single-excitation manifold. Our approach encodes the broadband nature of the nanocavity field through a non-Markovian memory kernel, derived from macroscopic QED theory. For a two-level dipole near a metallic nanosphere, we show that the single photon probability density in frequency space evolves in strong coupling from an initially localized source at the qubit frequency into a Rabi doublet over a timescale governed by the kernel spectrum. This dynamical crossover is accompanied by the formation of single-photon interference patterns in frequency and time, propagating coherently over a timescale limited by the shape of kernel spectrum to $\sim 100-150$ fs, which is accessible to ultrafast spectroscopy. We also show that the stationary spectrum of the coupled system can be manipulated by driving the nanocavity field using coherent pulses with variable spectral bandwidth. Using single-photon pulses narrower than the kernel spectrum, the Rabi splitting in a system that supports strong coupling can be effectively removed. The applicability of our results to other dipole-nanocavity configurations is discussed and a general strong coupling criterion for nanocavities is formulated.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03427v1" target="_blank">Federated Learning: An approach with Hybrid Homomorphic Encryption</a></h3>
                    <p><strong>Authors:</strong> Pedro Correia, Ivan Silva, Ivone Amorim, Eva Maia, Isabel PraÃ§a</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CR, E.3; C.2.0; C.2.4</p>
                    <p><strong>Summary:</strong> Federated Learning (FL) is a distributed machine learning approach that promises privacy by keeping the data on the device. However, gradient reconstruction and membership-inference attacks show that model updates still leak information. Fully Homomorphic Encryption (FHE) can address those privacy concerns but it suffers from ciphertext expansion and requires prohibitive overhead on resource-constrained devices. We propose the first Hybrid Homomorphic Encryption (HHE) framework for FL that pairs the PASTA symmetric cipher with the BFV FHE scheme. Clients encrypt local model updates with PASTA and send both the lightweight ciphertexts and the PASTA key (itself BFV-encrypted) to the server, which performs a homomorphic evaluation of the decryption circuit of PASTA and aggregates the resulting BFV ciphertexts. A prototype implementation, developed on top of the Flower FL framework, shows that on independently and identically distributed MNIST dataset with 12 clients and 10 training rounds, the proposed HHE system achieves 97.6% accuracy, just 1.3% below plaintext, while reducing client upload bandwidth by over 2,000x and cutting client runtime by 30% compared to a system based solely on the BFV FHE scheme. However, server computational cost increases by roughly 15621x for each client participating in the training phase, a challenge to be addressed in future work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03426v1" target="_blank">Time-Scaling State-Space Models for Dense Video Captioning</a></h3>
                    <p><strong>Authors:</strong> AJ Piergiovanni, Ganesh Satish Mallya, Dahun Kim, Anelia Angelova</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Dense video captioning is a challenging video understanding task which aims to simultaneously segment the video into a sequence of meaningful consecutive events and to generate detailed captions to accurately describe each event. Existing methods often encounter difficulties when working with the long videos associated with dense video captioning, due to the computational complexity and memory limitations. Furthermore, traditional approaches require the entire video as input, in order to produce an answer, which precludes online processing of the video. We address these challenges by time-scaling State-Space Models (SSMs) to even longer sequences than before. Our approach, State-Space Models with Transfer State, combines both the long-sequence and recurrent properties of SSMs and addresses the main limitation of SSMs which are otherwise not able to sustain their state for very long contexts, effectively scaling SSMs further in time. The proposed model is particularly suitable for generating captions on-the-fly, in an online or streaming manner, without having to wait for the full video to be processed, which is more beneficial in practice. When applied to dense video captioning, our approach scales well with video lengths and uses 7x fewer FLOPs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03422v1" target="_blank">Universal representation of the long-range entanglement in the family of Toric Code states</a></h3>
                    <p><strong>Authors:</strong> Mohammad Hossein Zarei, Mohsen Rahmani Haghighi</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Since the long range entanglement is a universal characteristic of topological quantum states belonging to the same class, a suitable mathematical representation of the long range entanglement has to be also universal. In this Letter, we introduce such a representation for the family of Toric Code states by using Kitaevs Ladders as building blocks. We consider Toric Code states corresponding to various planar graphs and apply non-local dientanglers to qubits corresponding to non-contractible cycles that satisfy a topological constraint. We demonstrate that, independent of the geometry of the underlying graph, disentanglers convert Toric Code states into a tensor product of Kitaevs Ladder states. Since Kitaevs Ladders with arbitrary geometric configurations include the short-range entanglements, we conclude that the above universal and non-local pattern of entanglement between ladders is responsible of the long-range entanglement inherent in Toric Code states. Our result emphasizes in the capability of such non-local representations to describe topological order in ground-state wave functions of topological quantum systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03421v1" target="_blank">Generalist versus Specialist Vision Foundation Models for Ocular Disease and Oculomics</a></h3>
                    <p><strong>Authors:</strong> Yukun Zhou, Paul Nderitu, Jocelyn Hui Lin Goh, Justin Engelmann, Siegfried K. Wagner, Anran Ran, Hongyang Jiang, Lie Ju, Ke Zou, Sahana Srinivasan, Hyunmin Kim, Takahiro Ninomiya, Zheyuan Wang, Gabriel Dawei Yang, Eden Ruffell, Dominic Williamson, Rui Santos, Gabor Mark Somfai, Carol Y. Cheung, Tien Yin Wong, Daniel C. Alexander, Yih Chung Tham, Pearse A. Keane</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, J.3; I.2.10</p>
                    <p><strong>Summary:</strong> Medical foundation models, pre-trained with large-scale clinical data, demonstrate strong performance in diverse clinically relevant applications. RETFound, trained on nearly one million retinal images, exemplifies this approach in applications with retinal images. However, the emergence of increasingly powerful and multifold larger generalist foundation models such as DINOv2 and DINOv3 raises the question of whether domain-specific pre-training remains essential, and if so, what gap persists. To investigate this, we systematically evaluated the adaptability of DINOv2 and DINOv3 in retinal image applications, compared to two specialist RETFound models, RETFound-MAE and RETFound-DINOv2. We assessed performance on ocular disease detection and systemic disease prediction using two adaptation strategies: fine-tuning and linear probing. Data efficiency and adaptation efficiency were further analysed to characterise trade-offs between predictive performance and computational cost. Our results show that although scaling generalist models yields strong adaptability across diverse tasks, RETFound-DINOv2 consistently outperforms these generalist foundation models in ocular-disease detection and oculomics tasks, demonstrating stronger generalisability and data efficiency. These findings suggest that specialist retinal foundation models remain the most effective choice for clinical applications, while the narrowing gap with generalist foundation models suggests that continued data and model scaling can deliver domain-relevant gains and position them as strong foundations for future medical foundation models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03419v1" target="_blank">Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges</a></h3>
                    <p><strong>Authors:</strong> Weiyuan Li, Xintao Wang, Siyu Yuan, Rui Xu, Jiangjie Chen, Qingqing Dong, Yanghua Xiao, Deqing Yang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) grow more capable, they face increasingly diverse and complex tasks, making reliable evaluation challenging. The paradigm of LLMs as judges has emerged as a scalable solution, yet prior work primarily focuses on simple settings. Their reliability in complex tasks--where multi-faceted rubrics, unstructured reference answers, and nuanced criteria are critical--remains understudied. In this paper, we constructed ComplexEval, a challenge benchmark designed to systematically expose and quantify Auxiliary Information Induced Biases. We systematically investigated and validated 6 previously unexplored biases across 12 basic and 3 advanced scenarios. Key findings reveal: (1) all evaluated models exhibit significant susceptibility to these biases, with bias magnitude scaling with task complexity; (2) notably, Large Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth analysis offers crucial insights for improving the accuracy and verifiability of evaluation signals, paving the way for more general and robust evaluation models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03420v1" target="_blank">Image-Guided Surgery: Technology, Quality, Innovation, and Opportunities for Medical Physics</a></h3>
                    <p><strong>Authors:</strong> Jeffrey H. Siewerdsen</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> physics.med-ph, eess.IV</p>
                    <p><strong>Summary:</strong> The science and clinical practice of medical physics has been integral to the advancement of radiology and radiation therapy for over a century. In parallel, advances in surgery - including intraoperative imaging, registration, and other technologies within the expertise of medical physicists - have advanced primarily in connection to other disciplines, such as biomedical engineering and computer science, and via somewhat distinct translational paths. This review article briefly traces the parallel and convergent evolution of such scientific, engineering, and clinical domains with an eye to a potentially broader, more impactful role of medical physics in research and clinical practice of surgery. A review of image-guided surgery technologies is offered, including intraoperative imaging, tracking / navigation, image registration, visualization, and surgical robotics across a spectrum of surgical applications. Trends and drivers for research and innovation are traced, including federal funding and academic-industry partnership, and some of the major challenges to achieving major clinical impact are described. Opportunities for medical physicists to expand expertise and contribute to the advancement of surgery in the decade ahead are outlined, including research and innovation, data science approaches, improving efficiency through operations research and optimization, improving patient safety, and bringing rigorous quality assurance to technologies and processes in the circle of care for surgery. Challenges abound but appear tractable, including domain knowledge, professional qualifications, and the need for investment and clinical partnership.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.18452/33769" target="_blank">Integrable systems: From the ice rule to supersymmetric fishnet Feynman diagrams</a></h3>
                    <p><strong>Authors:</strong> Moritz Kade</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> This thesis examines the correspondence between models of statistical physics and Feynman graphs of quantum field theories (QFTs) by a common property: integrability. We review integrable structures for periodic boundary conditions on both sides, while focusing on the eight- and six-vertex model and the bi-scalar fishnet theory. The latter is a double-scaled $\gamma$-deformation of $\mathcal{N} = 4$ super Yang-Mills theory. Interesting applications of integrability existing in the literature that we reconsider are the computation of the free energy in the thermodynamic limit and its QFT counterpart, the critical coupling. In addition, we provide a detailed overview of the calculation of exact anomalous dimensions and operator product expansion (OPE) coefficients in the conformal bi-scalar fishnet theory. The original contributions of this work comprise the results of the critical coupling for models with fermions, the brick wall theory, and the fermionic fishnet theory. Additionally, we extend the study of integrable Feynman graphs to supersymmetric diagrams in superspace. By establishing an efficient graphical formalism, we obtain the critical coupling of double-scaled $\beta$-deformations of $\mathcal{N} = 4$ super Yang-Mills theory and Aharony-Bergman-Jafferis-Maldacena theory, the super brick wall and superfishnet theory, respectively. Moreover, we apply superspace methods to the superfishnet theory and find results for anomalous dimensions and an OPE coefficient, which are all-loop exact in the coupling. In addition, we study boundary integrability in the six-vertex model and for Feynman diagrams. We present new box-shaped boundary conditions for the six-vertex model and conjecture a closed form for its partition function at any lattice size. On the QFT side, we find integrable boundary scattering matrices in the form of generalized Feynman diagrams by graphical methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03414v1" target="_blank">The frustrated Ising model on the honeycomb lattice: Metastability and universality</a></h3>
                    <p><strong>Authors:</strong> Denis Gessert, Martin Weigel, Wolfhard Janke</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cond-mat.stat-mech, physics.comp-ph</p>
                    <p><strong>Summary:</strong> We study the Ising model with competing ferromagnetic nearest- and antiferromagnetic next-nearest-neighbor interactions of strengths $J_1  0$ and $J_2  - J_1 / 4$ it has a ferromagnetic ground state, and previous work has shown that at least for $J_2 \gtrsim -0.2 J_1$ the transition is in the Ising universality class. For even lower $J_2$ some indicators pointing towards a first-order transition were reported. By utilizing population annealing Monte Carlo simulations together with a rejection-free and adaptive update, we can equilibrate systems with $J_2$ as low as $-0.23 J_1$. By means of a finite-size scaling analysis we show that the system undergoes a second-order phase transition within the Ising universality class at least down to $J_2 =-0.23 J_1$ and, most likely, for all $J_2  - J_1 / 4$. As we show here, there exist very long-lived metastable states in this system explaining the first-order like behavior seen in only partially equilibrated systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03413v1" target="_blank">An angular momentum approach to quantum insertion errors</a></h3>
                    <p><strong>Authors:</strong> Lewis Bulled, Yingkai Ouyang</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum insertion errors are a class of errors that increase the number of qubits in a quantum system. Despite a wealth of research on classical insertion errors, there has been limited progress towards a general framework for correcting quantum insertion errors. We detail a quantum error correction protocol that can correct single insertion errors on a class of gapped permutation-invariant codes. We provide a simple two-stage syndrome extraction protocol that yields a two-bit syndrome, by measuring the total angular momentum and its projection along the $z$-axis (modulo the code gap) of the post-insertion state. We demonstrate that these measurements project the state onto a new codespace, and we detail a teleportation protocol to map the projected state back to a permutation-invariant code on the desired number of qubits.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03408v1" target="_blank">Scalable and Loosely-Coupled Multimodal Deep Learning for Breast Cancer Subtyping</a></h3>
                    <p><strong>Authors:</strong> Mohammed Amer, Mohamed A. Suliman, Tu Bui, Nuria Garcia, Serban Georgescu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Healthcare applications are inherently multimodal, benefiting greatly from the integration of diverse data sources. However, the modalities available in clinical settings can vary across different locations and patients. A key area that stands to gain from multimodal integration is breast cancer molecular subtyping, an important clinical task that can facilitate personalized treatment and improve patient prognosis. In this work, we propose a scalable and loosely-coupled multimodal framework that seamlessly integrates data from various modalities, including copy number variation (CNV), clinical records, and histopathology images, to enhance breast cancer subtyping. While our primary focus is on breast cancer, our framework is designed to easily accommodate additional modalities, offering the flexibility to scale up or down with minimal overhead without requiring re-training of existing modalities, making it applicable to other types of cancers as well. We introduce a dual-based representation for whole slide images (WSIs), combining traditional image-based and graph-based WSI representations. This novel dual approach results in significant performance improvements. Moreover, we present a new multimodal fusion strategy, demonstrating its ability to enhance performance across a range of multimodal conditions. Our comprehensive results show that integrating our dual-based WSI representation with CNV and clinical health records, along with our pipeline and fusion strategy, outperforms state-of-the-art methods in breast cancer subtyping.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03407v1" target="_blank">Learning Mechanism Underlying NLP Pre-Training and Fine-Tuning</a></h3>
                    <p><strong>Authors:</strong> Yarden Tzach, Ronit D. Gross, Ella Koresh, Shalom Rosner, Or Shpringer, Tal Halevi, Ido Kanter</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Natural language processing (NLP) enables the understanding and generation of meaningful human language, typically using a pre-trained complex architecture on a large dataset to learn the language and next fine-tune its weights to implement a specific task. Twofold goals are examined; to understand the mechanism underlying successful pre-training and to determine the interplay between the pre-training accuracy and the fine-tuning of classification tasks. The following main results were obtained; the accuracy per token (APT) increased with its appearance frequency in the dataset, and its average over all tokens served as an order parameter to quantify pre-training success, which increased along the transformer blocks. Pre-training broke the symmetry among tokens and grouped them into finite, small, strong match token clusters, as inferred from the presented token confusion matrix. This feature was sharpened along the transformer blocks toward the output layer, enhancing its performance considerably compared with that of the embedding layer. Consequently, higher-order language structures were generated by pre-training, even though the learning cost function was directed solely at identifying a single token. These pre-training findings were reflected by the improved fine-tuning accuracy along the transformer blocks. Additionally, the output label prediction confidence was found to be independent of the average input APT, as the input meaning was preserved since the tokens are replaced primarily by strong match tokens. Finally, although pre-training is commonly absent in image classification tasks, its underlying mechanism is similar to that used in fine-tuning NLP classification tasks, hinting at its universality. The results were based on the BERT-6 architecture pre-trained on the Wikipedia dataset and fine-tuned on the FewRel and DBpedia classification tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03406v1" target="_blank">Bayesian analysis of properties of nuclear matter with the FOPI experimental data</a></h3>
                    <p><strong>Authors:</strong> Guojun Wei, Manzi Nan, Pengcheng Li, Yongjia Wang, Qingfeng Li, Gaochan Yong, Fuhu Liu</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> nucl-th</p>
                    <p><strong>Summary:</strong> Based on the ultra-relativistic quantum molecular dynamics (UrQMD) transport model, combined with experimental data of directed flow, elliptic flow, and nuclear stopping power measured by FOPI in $\rm ^{197}Au+^{197}Au$ collisions at beam energies ($E_{lab}$) of 0.25 and 0.4 GeV/nucleon, the incompressibility of the nuclear equation of state $K_0$, the nucleon effective mass $m^*$, and the in-medium correction factor ($F$, with respect to free-space values) on the nucleon-nucleon elastic cross sections are studied by Bayesian analysis. It is found that both $m^*$ and $F$ can be tightly constrained with the uncertainty $\le$ 15\%, however, $K_0$ cannot be constrained tightly. We deduce $m^*/m_0 = 0.78^{+0.09}_{-0.10}$ and $F = 0.75^{+0.08}_{-0.07}$ with experimental data at $E_{lab}$ = 0.25 GeV/nucleon, and the obtained values increased to $m^*/m_0 = 0.88^{+0.03}_{-0.03}$ and $F = 0.88^{+0.06}_{-0.07}$ at $E_{lab}$ = 0.4 GeV/nucleon. The obtained results are further verified with rapidity-dependent flow data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03405v1" target="_blank">LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations</a></h3>
                    <p><strong>Authors:</strong> Daniela Gottesman, Alon Gilae-Dotan, Ido Cohen, Yoav Gur-Arieh, Marius Mosbach, Ori Yoran, Mor Geva</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Language models (LMs) increasingly drive real-world applications that require world knowledge. However, the internal processes through which models turn data into representations of knowledge and beliefs about the world, are poorly understood. Insights into these processes could pave the way for developing LMs with knowledge representations that are more consistent, robust, and complete. To facilitate studying these questions, we present LMEnt, a suite for analyzing knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a knowledge-rich pretraining corpus, fully annotated with entity mentions, based on Wikipedia, (2) an entity-based retrieval method over pretraining data that outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained models with up to 1B parameters and 4K intermediate checkpoints, with comparable performance to popular open-sourced models on knowledge benchmarks. Together, these resources provide a controlled environment for analyzing connections between entity mentions in pretraining and downstream performance, and the effects of causal interventions in pretraining data. We show the utility of LMEnt by studying knowledge acquisition across checkpoints, finding that fact frequency is key, but does not fully explain learning trends. We release LMEnt to support studies of knowledge in LMs, including knowledge representations, plasticity, editing, attribution, and learning dynamics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.03404v1" target="_blank">J-PLUS: The stellar mass function of quiescent and star forming galaxies at 0.05 = z = 0.2</a></h3>
                    <p><strong>Authors:</strong> F. D. Arizo-Borillo, C. Lopez-Sanjuan, I. Pintos-Castro, J. A. Fernandez-Ontiveros, T. Kuutma, A. Lumbreras-Calle, A. Hernan-Caballero, H. Dominguez-Sanchez, G. De Lucia, F. Fontanot, L. A. Diaz-Garcia, J. M. Vilchez, P. T. Rahna, A. J. Cenarro, D. Cristobal-Hornillos, C. Hernandez-Monteagudo, A. Marin-Franch, M. Moles, J. Varela, H. Vazquez Ramio, J. Alcaniz, R. A. Dupke, A. Ederoclite, L. Sodre Jr., R. E. Angulo</p>
                    <p><strong>Published:</strong> 9/3/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Aims. We derive the stellar mass function (SMF) of quiescent and star-forming galaxies at z  0.95 at log(M*/Msun)  11. Comparisons with the GAEA semi-analytic model reveal an excess of star-forming galaxies at intermediate masses. Conclusions. J-PLUS DR3 stellar mass functions and quiescent fractions are consistent with the literature and provide robust constraints for galaxy formation models. Quiescent galaxies represent 45 percent of number density above log(M*)  9, but 75 percent of stellar mass density. The use of 12 optical bands, including 7 narrow filters, improves redshift precision by 20 percent, enabling more accurate SED fitting and galaxy classification.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

