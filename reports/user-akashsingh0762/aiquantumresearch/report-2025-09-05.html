
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-09-05<br>
            <strong>Topics:</strong> ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 100
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <h2>ai alignment research</h2>
<p>Certainly! Here is a high-level summary of the key findings and their significance in the context of AI alignment research from the provided research papers:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Integration of Multimodal and Multivariate Data</strong>: Research is increasingly focused on integrating various data types, such as textual, visual, and multivariate time series, to enhance AI models understanding and prediction capabilities. This trend is evident in the development of datasets like ChronoGraph and models like TRUST-VL.</p>
</li>
<li><p><strong>Human-Centric AI Models</strong>: There is a significant trend towards aligning AI models with human preferences and values. This includes efforts to improve decision-making processes to reflect human cognitive models and ensure AI systems act in ways that are beneficial and interpretable to users.</p>
</li>
<li><p><strong>Enhancing AIs Responsiveness to Real-World Dynamics</strong>: AI systems are being developed to better handle real-world dynamics, such as changing environmental conditions or evolving user interests, evident in models like TIMGen and frameworks like EvoEmo.</p>
</li>
<li><p><strong>Improving AIs Generalization and Robustness</strong>: Researchers are working on improving AIs ability to generalize knowledge across different domains and scenarios, as seen in efforts like GeoArena and the development of ZooCast for time series forecasting.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Structure-Aware Forecasting and Anomaly Detection</strong>: ChronoGraph provides a novel dataset that combines multivariate time series data with explicit dependency graphs, aiding in better forecasting and anomaly detection in microservice systems.</p>
</li>
<li><p><strong>Unified Multimodal Misinformation Detection</strong>: TRUST-VL represents a breakthrough in misinformation detection by integrating various data modalities into a single model, enhancing knowledge sharing and task-specific skills across different misinformation types.</p>
</li>
<li><p><strong>Cognitively-Faithful Decision-Making Models</strong>: A new approach has been proposed to align AI decision-making models with human cognitive processes, potentially leading to more accurate and interpretable AI systems that better reflect human decision-making.</p>
</li>
<li><p><strong>Semantic Drift Evaluation in Unified Models</strong>: The Unified Consistency Framework for Unified Models (UCF-UM) introduces a method to evaluate semantic drift in AI models, crucial for ensuring consistency in multimodal AI applications.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Enhanced AI Alignment with Human Values</strong>: The development of human-centric AI models and frameworks suggests that future AI systems will be better aligned with human values, potentially increasing trust and adoption in critical sectors like healthcare and finance.</p>
</li>
<li><p><strong>Improved Multimodal AI Applications</strong>: The integration of multimodal data processing will likely lead to more robust AI applications in areas such as misinformation detection, personalized content generation, and real-time decision-making, addressing complex societal challenges.</p>
</li>
<li><p><strong>Better AI Response to Dynamic Environments</strong>: As AI models become more adept at handling dynamic user interests and environmental conditions, they will be more effective in applications requiring adaptability, such as autonomous vehicles and personalized recommendations.</p>
</li>
<li><p><strong>Increased Focus on Privacy and Security</strong>: The recognition of privacy risks in AI applications, such as in time series forecasting, highlights the need for continued research into safeguarding user data while maintaining model performance.</p>
</li>
<li><p><strong>New Evaluation Metrics and Benchmarks</strong>: The creation of new evaluation frameworks, like Inverse IFEval and UCF-UM, will drive advancements in AI robustness and alignment, ensuring models are not only accurate but also adaptable to diverse real-world scenarios.</p>
</li>
</ol>
<p>These trends, breakthroughs, and implications underscore the ongoing efforts to ensure AI systems are safe, reliable, and aligned with human values, which are critical aspects of AI alignment research.</p>
<p><em>Based on 50 research papers</em></p>

<h2>quantum computing</h2>
<p>The collection of research papers provided does not focus explicitly on quantum computing. Instead, they cover a wide range of topics including virtual fitting rooms, misinformation detection, panoramic vision, robotic manipulation, language models, and gravitational wave studies, among others. While a few papers touch on quantum-related themes, such as quantum entanglement and quantum key distribution, they are not central to the majority of the papers listed.</p>
<p>However, to address the request as closely as possible, heres a high-level summary focusing on the quantum computing-related aspects, specifically from the papers that mention quantum concepts:</p>
<h3>Most Important Trends</h3>
<ul>
<li><strong>Quantum Entanglement and Time</strong>: Investigations into how time ordering affects entanglement experiments with unstable particles, highlighting the robustness of quantum correlations irrespective of measurement order.</li>
<li><strong>Quantum Key Distribution (QKD)</strong>: Emphasis on the security and robustness of QKD using photonics, which is an area of growing interest as it offers theoretically unbreakable channels for secure communication.</li>
</ul>
<h3>Breakthroughs</h3>
<ul>
<li><strong>Entanglement and Measurement Interpretation</strong>: The analysis of entanglement with unstable particles supports the idea that quantum measurement is more of a mathematical framework rather than a direct depiction of reality.</li>
<li><strong>Photonics in Quantum Communication</strong>: Demonstrations of implementing QKD in laboratory settings using photonics to ensure secure quantum communication channels.</li>
</ul>
<h3>Implications</h3>
<ul>
<li><strong>Fundamental Quantum Understanding</strong>: The studies reinforce the foundational principles of quantum mechanics, such as the Copenhagen interpretation, suggesting that classical interpretations of time may not apply in all quantum contexts.</li>
<li><strong>Secure Communications</strong>: The advancements in QKD highlight the potential for quantum technologies to revolutionize secure communications, making them impervious to future computational advancements, including those potentially offered by quantum computers.</li>
</ul>
<p>In summary, while the majority of the papers do not directly relate to quantum computing, those that do emphasize the ongoing exploration and validation of quantum principles in both theoretical and practical domains, particularly in secure communications through QKD. These insights contribute to a deeper understanding of quantum mechanics and its applications, reinforcing its role in shaping future technologies.</p>
<p><em>Based on 50 research papers</em></p>

            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2509.04449v1" target="_blank">ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset</a></h3>
                    <p><strong>Authors:</strong> Adrian Catalin Lutu, Ioana Pintilie, Elena Burceanu, Andrei Manolache</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> We present ChronoGraph, a graph-structured multivariate time series forecasting dataset built from real-world production microservices. Each node is a service that emits a multivariate stream of system-level performance metrics, capturing CPU, memory, and network usage patterns, while directed edges encode dependencies between services. The primary task is forecasting future values of these signals at the service level. In addition, ChronoGraph provides expert-annotated incident windows as anomaly labels, enabling evaluation of anomaly detection methods and assessment of forecast robustness during operational disruptions. Compared to existing benchmarks from industrial control systems or traffic and air-quality domains, ChronoGraph uniquely combines (i) multivariate time series, (ii) an explicit, machine-readable dependency graph, and (iii) anomaly labels aligned with real incidents. We report baseline results spanning forecasting models, pretrained time-series foundation models, and standard anomaly detectors. ChronoGraph offers a realistic benchmark for studying structure-aware forecasting and incident-aware evaluation in microservice systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04448v1" target="_blank">TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection</a></h3>
                    <p><strong>Authors:</strong> Zehong Yan, Peng Qi, Wynne Hsu, Mong Li Lee</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.MM</p>
                    <p><strong>Summary:</strong> Multimodal misinformation, encompassing textual, visual, and cross-modal distortions, poses an increasing societal threat that is amplified by generative AI. Existing methods typically focus on a single type of distortion and struggle to generalize to unseen scenarios. In this work, we observe that different distortion types share common reasoning capabilities while also requiring task-specific skills. We hypothesize that joint training across distortion types facilitates knowledge sharing and enhances the models ability to generalize. To this end, we introduce TRUST-VL, a unified and explainable vision-language model for general multimodal misinformation detection. TRUST-VL incorporates a novel Question-Aware Visual Amplifier module, designed to extract task-specific visual features. To support training, we also construct TRUST-Instruct, a large-scale instruction dataset containing 198K samples featuring structured reasoning chains aligned with human fact-checking workflows. Extensive experiments on both in-domain and zero-shot benchmarks demonstrate that TRUST-VL achieves state-of-the-art performance, while also offering strong generalization and interpretability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04445v1" target="_blank">Towards Cognitively-Faithful Decision-Making Models to Improve AI Alignment</a></h3>
                    <p><strong>Authors:</strong> Cyrus Cousins, Vijay Keswani, Vincent Conitzer, Hoda Heidari, Jana Schaich Borg, Walter Sinnott-Armstrong</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Recent AI work trends towards incorporating human-centric objectives, with the explicit goal of aligning AI models to personal preferences and societal values. Using standard preference elicitation methods, researchers and practitioners build models of human decisions and judgments, which are then used to align AI behavior with that of humans. However, models commonly used in such elicitation processes often do not capture the true cognitive processes of human decision making, such as when people use heuristics to simplify information associated with a decision problem. As a result, models learned from peoples decisions often do not align with their cognitive processes, and can not be used to validate the learning framework for generalization to other decision-making tasks. To address this limitation, we take an axiomatic approach to learning cognitively faithful decision processes from pairwise comparisons. Building on the vast literature characterizing the cognitive processes that contribute to human decision-making, and recent work characterizing such processes in pairwise comparison tasks, we define a class of models in which individual features are first processed and compared across alternatives, and then the processed features are then aggregated via a fixed rule, such as the Bradley-Terry rule. This structured processing of information ensures such models are realistic and feasible candidates to represent underlying human decision-making processes. We demonstrate the efficacy of this modeling approach in learning interpretable models of human decision making in a kidney allocation task, and show that our proposed models match or surpass the accuracy of prior models of human pairwise decision-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04444v1" target="_blank">One Flight Over the Gap: A Survey from Perspective to Panoramic Vision</a></h3>
                    <p><strong>Authors:</strong> Xin Lin, Xian Ge, Dizhe Zhang, Zhaoliang Wan, Xianshun Wang, Xiangtai Li, Wenjie Jiang, Bo Du, Dacheng Tao, Ming-Hsuan Yang, Lu Qi</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Driven by the demand for spatial intelligence and holistic scene perception, omnidirectional images (ODIs), which provide a complete 360\textdegree{} field of view, are receiving growing attention across diverse applications such as virtual reality, autonomous driving, and embodied robotics. Despite their unique characteristics, ODIs exhibit remarkable differences from perspective images in geometric projection, spatial distribution, and boundary continuity, making it challenging for direct domain adaption from perspective methods. This survey reviews recent panoramic vision techniques with a particular emphasis on the perspective-to-panorama adaptation. We first revisit the panoramic imaging pipeline and projection methods to build the prior knowledge required for analyzing the structural disparities. Then, we summarize three challenges of domain adaptation: severe geometric distortions near the poles, non-uniform sampling in Equirectangular Projection (ERP), and periodic boundary continuity. Building on this, we cover 20+ representative tasks drawn from more than 300 research papers in two dimensions. On one hand, we present a cross-method analysis of representative strategies for addressing panoramic specific challenges across different tasks. On the other hand, we conduct a cross-task comparison and classify panoramic vision into four major categories: visual quality enhancement and assessment, visual understanding, multimodal understanding, and visual generation. In addition, we discuss open challenges and future directions in data, models, and applications that will drive the advancement of panoramic vision research. We hope that our work can provide new insight and forward looking perspectives to advance the development of panoramic vision technologies. Our project page is https://insta360-research-team.github.io/Survey-of-Panorama</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04438v1" target="_blank">The Telephone Game: Evaluating Semantic Drift in Unified Models</a></h3>
                    <p><strong>Authors:</strong> Sabbir Mollah, Rohit Gupta, Sirnam Swetha, Qingyang Liu, Ahnaf Munir, Mubarak Shah</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL</p>
                    <p><strong>Summary:</strong> Employing a single, unified model (UM) for both visual understanding (image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened a new direction in Visual Language Model (VLM) research. While UMs can also support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus on the core cross-modal pair T2I and I2T, as consistency between understanding and generation is critical for downstream use. Existing evaluations consider these capabilities in isolation: FID and GenEval for T2I, and benchmarks such as MME, MMBench for I2T. These single-pass metrics do not reveal whether a model that understands a concept can also render it, nor whether meaning is preserved when cycling between image and text modalities. To address this, we introduce the Unified Consistency Framework for Unified Models (UCF-UM), a cyclic evaluation protocol that alternates I2T and T2I over multiple generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean Cumulative Drift (MCD), an embedding-based measure of overall semantic loss; (ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii) Multi-Generation GenEval (MGG), an object-level compliance score extending GenEval. To assess generalization beyond COCO, which is widely used in training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and evaluate on seven recent models. UCF-UM reveals substantial variation in cross-modal stability: some models like BAGEL maintain semantics over many alternations, whereas others like Vila-u drift quickly despite strong single-pass scores. Our results highlight cyclic consistency as a necessary complement to standard I2T and T2I evaluations, and provide practical metrics to consistently assess unified models cross-modal stability and strength of their shared representations. Code: https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04430v1" target="_blank">Unveiling the Role of Data Uncertainty in Tabular Deep Learning</a></h3>
                    <p><strong>Authors:</strong> Nikolay Kartashev, Ivan Rubachev, Artem Babenko</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Recent advancements in tabular deep learning have demonstrated exceptional practical performance, yet the field often lacks a clear understanding of why these techniques actually succeed. To address this gap, our paper highlights the importance of the concept of data uncertainty for explaining the effectiveness of the recent tabular DL methods. In particular, we reveal that the success of many beneficial design choices in tabular DL, such as numerical feature embeddings, retrieval-augmented models and advanced ensembling strategies, can be largely attributed to their implicit mechanisms for managing high data uncertainty. By dissecting these mechanisms, we provide a unifying understanding of the recent performance improvements. Furthermore, the insights derived from this data-uncertainty perspective directly allowed us to develop more effective numerical feature embeddings as an immediate practical outcome of our analysis. Overall, our work paves the way to foundational understanding of the benefits introduced by modern tabular methods that results in the concrete advancements of existing techniques and outlines future research directions for tabular DL.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.3847/1538-3881/ae01a2" target="_blank">Extreme Starlight Polarization Efficiency Toward $Î¶$ Ophiuchi: A Case for Line-of-Sight Foreground Subtraction</a></h3>
                    <p><strong>Authors:</strong> Jordan A. Bartlett, Henry A. Kobulnicky</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Despite the pervasive nature of interstellar dust and its impact on nearly all observations, most dust corrections employ line-of-sight averages over large angular scales. This neglects real variations on small angular and distance scales from discrete components of the ISM. We use $V$ band polarimetry, public dust maps, and Gaia DR3 distances of 25 stars along a 50 radius sight line towards the O9.5IV star $\zeta$ Ophiuchi ($d \approx $ 182 pc) to examine both dust and magnetic structures over the range $d = $ 36--1176 pc and angular scales of $ 1$\degr. Polarization and reddening data indicate two discrete dust populations having different magnetic field orientations along the sight line, one at $d \simeq$ 86--127 pc and another at $d\simeq$ 252--287 pc. After removal of the foreground, the more distant component exhibits alignment in polarization angle with 12 $\mu$m PAH striations seen in the field. This more distant dust population exhibits evidence of extreme starlight polarization efficiency with an average of 14.1% mag$^{-1}$, greater than the canonical Serkowski limit of 9% mag$^{-1}$. The spatial coincidence with the PAH striations indicates the PAH-emitting grains and those responsible for the high polarization efficiency may be components of the same dust population. We find no evidence that $\zeta$ Ophs radiative influence affects the polarizing or reddening properties of the surrounding dust. Our study demonstrates that accurate distance-based foreground subtraction is vital to properly understanding superimposed dust and the magnetic field components in the ISM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04408v1" target="_blank">Chiral Graviton Theory of Fractional Quantum Hall States</a></h3>
                    <p><strong>Authors:</strong> Yi-Hsien Du</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mes-hall, hep-th</p>
                    <p><strong>Summary:</strong> Recent polarized Raman scattering experiments indicate that fractional quantum Hall systems host a chiral spin-2 neutral collective mode, the long-wavelength limit of the magnetoroton, which behaves as a condensed-matter graviton. We present a nonlinear, gauge-invariant effective theory by gauging area-preserving diffeomorphisms (APDs) with a unimodular spatial metric as the gauge field. A Stueckelberg construction introduces an APD-invariant local potential that aligns the dynamical metric with a reference geometry, opening a tunable gap while preserving gauge redundancy. Together with a geometric Maxwell kinetic sector and the Wen-Zee and gravitational Chern-Simons terms, the theory yields a gapped chiral spin-2 excitation consistent with universal long-wavelength constraints. The tunable gap emerges naturally from symmetry and provides a route to an isotropic-nematic quantum critical point where the spin-2 mode softens. We further establish a linear dictionary to quadrupolar deformations in composite Fermi liquid bosonization, and outline applications to fractional Chern insulators as well as higher-dimensional generalizations. Finally, the approach can be extended to non-Abelian fractional quantum Hall states, capturing both spin-2 and spin-3/2 neutral modes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04404v1" target="_blank">No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening</a></h3>
                    <p><strong>Authors:</strong> Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, Aylin Caliskan</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.CL, cs.HC, K.4.2</p>
                    <p><strong>Summary:</strong> In this study, we conduct a resume-screening experiment (N=528) where people collaborate with simulated AI models exhibiting race-based preferences (bias) to evaluate candidates for 16 high and low status occupations. Simulated AI bias approximates factual and counterfactual estimates of racial bias in real-world AI systems. We investigate peoples preferences for White, Black, Hispanic, and Asian candidates (represented through names and affinity groups on quality-controlled resumes) across 1,526 scenarios and measure their unconscious associations between race and status using implicit association tests (IATs), which predict discriminatory hiring decisions but have not been investigated in human-AI collaboration. When making decisions without AI or with AI that exhibits no race-based preferences, people select all candidates at equal rates. However, when interacting with AI favoring a particular group, people also favor those candidates up to 90% of the time, indicating a significant behavioral shift. The likelihood of selecting candidates whose identities do not align with common race-status stereotypes can increase by 13% if people complete an IAT before conducting resume screening. Finally, even if people think AI recommendations are low quality or not important, their decisions are still vulnerable to AI bias under certain circumstances. This work has implications for peoples autonomy in AI-HITL scenarios, AI and work, design and evaluation of AI hiring systems, and strategies for mitigating bias in collaborative decision-making tasks. In particular, organizational and regulatory policy should acknowledge the complex nature of AI-HITL decision making when implementing these systems, educating people who use them, and determining which are subject to oversight.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04388v1" target="_blank">Impact on transient stability of self-synchronisation control strategies in grid-forming VSC-based generators</a></h3>
                    <p><strong>Authors:</strong> Regulo E. Avila-Martinez, Xavier Guillaud, Javier Renedo, Luis Rouco, Aurelio Garcia-Cerrada, Lukas Sigrist</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Grid-forming voltage source converters (GFM-VSCs) are emerging as a solution for integrating renewable energy resources (RERs) into power systems. GFM-VSCs need a self-synchronisation strategy to ensure that all converters and generators in the power system are in synchronism and they reach the same frequency in steady state. The self-synchronisation strategy in GFM-VSCs that has received most attention in previous research is virtual synchronous machine (VSM) control. However, no systematic study of the effects on transient stability of different variants of this strategy has been carried out in previous work. This paper analyses and compares transient stability of four self-synchronisation strategies for GFM-VSCs: VSM without phase-locked loop (PLL), VSM with PLL, VSM without PLL using wash-out filter and integral-proportional (IP) controller. The paper also analyses two different methods that can \color{black} be applied to GFM-VSC self-synchronisation strategies to improve transient stability: the concept of virtual unsaturated active-power controller (VAPC), proposed in previous work, and an algorithm for frequency limitation in the GFM-VSC (FLC), which is proposed in this paper.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04383v1" target="_blank">On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs</a></h3>
                    <p><strong>Authors:</strong> Serafino Cicerone, Alessia Di Fonso, Gabriele Di Stefano, Alfredo Navarra</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> The OBLOT model has been extensively studied in theoretical swarm robotics. It assumes weak capabilities for the involved mobile robots, such as they are anonymous, disoriented, no memory of past events (oblivious), and silent. Their only means of (implicit) communication is transferred to their positioning, i.e., stigmergic information. These limited capabilities make the design of distributed algorithms a challenging task. Over the last two decades, numerous research papers have addressed the question of which tasks can be accomplished within this model. Nevertheless, as it usually happens in distributed computing, also in OBLOT the computational power available to the robots is neglected as the main cost measures for the designed algorithms refer to the number of movements or the number of rounds required. In this paper, we prove that for synchronous robots moving on finite graphs, the unlimited computational power (other than finite time) has a significant impact. In fact, by exploiting it, we provide a definitive resolution algorithm that applies to a wide class of problems while guaranteeing the minimum number of moves and rounds.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04380v1" target="_blank">Aligning load flexibility with emissions reduction: empirical insights from a multi-site study of cryptocurrency data centers</a></h3>
                    <p><strong>Authors:</strong> Veronica M. Paez, Neda Mohammadi, John E. Taylor</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> stat.AP</p>
                    <p><strong>Summary:</strong> The power sector is responsible for 32 percent of global greenhouse gas emissions. Data centers and cryptocurrencies use significant amounts of electricity and contribute to these emissions. Demand-side flexibility of data centers is one possible approach for reducing greenhouse gas emissions from these industries. To explore this, we use novel data collected from the Bitcoin mining industry to investigate the impact of load flexibility on power system decarbonization. Employing engineered metrics to explore curtailment dynamics and emissions alignment, we provide the first empirical analysis of cryptocurrency data centers capability for reducing greenhouse gas emissions in response to real-time grid signals. Our results highlight the importance of strategically aligning operational behaviors with emissions signals to maximize avoided emissions. These findings offer insights for policymakers and industry stakeholders to enhance load flexibility and meet climate goals in these otherwise energy intensive data centers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04379v1" target="_blank">SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer</a></h3>
                    <p><strong>Authors:</strong> Jimin Xu, Bosheng Qin, Tao Jin, Zhou Zhao, Zhenhui Ye, Jun Yu, Fei Wu</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advancements in neural representations, such as Neural Radiance Fields and 3D Gaussian Splatting, have increased interest in applying style transfer to 3D scenes. While existing methods can transfer style patterns onto 3D-consistent neural representations, they struggle to effectively extract and transfer high-level style semantics from the reference style image. Additionally, the stylized results often lack structural clarity and separation, making it difficult to distinguish between different instances or objects within the 3D scene. To address these limitations, we propose a novel 3D style transfer pipeline that effectively integrates prior knowledge from pretrained 2D diffusion models. Our pipeline consists of two key stages: First, we leverage diffusion priors to generate stylized renderings of key viewpoints. Then, we transfer the stylized key views onto the 3D representation. This process incorporates two innovative designs. The first is cross-view style alignment, which inserts cross-view attention into the last upsampling block of the UNet, allowing feature interactions across multiple key views. This ensures that the diffusion model generates stylized key views that maintain both style fidelity and instance-level consistency. The second is instance-level style transfer, which effectively leverages instance-level consistency across stylized key views and transfers it onto the 3D representation. This results in a more structured, visually coherent, and artistically enriched stylization. Extensive qualitative and quantitative experiments demonstrate that our 3D style transfer pipeline significantly outperforms state-of-the-art methods across a wide range of scenes, from forward-facing to challenging 360-degree environments. Visit our project page https://jm-xu.github.io/SSGaussian for immersive visualization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04378v1" target="_blank">Aesthetic Image Captioning with Saliency Enhanced MLLMs</a></h3>
                    <p><strong>Authors:</strong> Yilin Tao, Jiashui Huang, Huaze Xu, Ling Shao</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Aesthetic Image Captioning (AIC) aims to generate textual descriptions of image aesthetics, becoming a key research direction in the field of computational aesthetics. In recent years, pretrained Multimodal Large Language Models (MLLMs) have advanced rapidly, leading to a significant increase in image aesthetics research that integrates both visual and textual modalities. However, most existing studies on image aesthetics primarily focus on predicting aesthetic ratings and have shown limited application in AIC. Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods without specifically adapting MLLMs to focus on target aesthetic content. To address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal Large Language Model (ASE-MLLM), an end-to-end framework that explicitly incorporates aesthetic saliency into MLLMs. Within this framework, we introduce the Image Aesthetic Saliency Module (IASM), which efficiently and effectively extracts aesthetic saliency features from images. Additionally, we design IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency features with original image features via a cross-attention mechanism. To the best of our knowledge, ASE-MLLM is the first framework to integrate image aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments demonstrated that our approach significantly outperformed traditional methods and generic MLLMs on current mainstream AIC benchmarks, achieving state-of-the-art (SOTA) performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04376v1" target="_blank">AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search</a></h3>
                    <p><strong>Authors:</strong> Hao Ju, Hu Zhang, Zhedong Zheng</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With growing public safety demands, text-based person anomaly search has emerged as a critical task, aiming to retrieve individuals with abnormal behaviors via natural language descriptions. Unlike conventional person search, this task presents two unique challenges: (1) fine-grained cross-modal alignment between textual anomalies and visual behaviors, and (2) anomaly recognition under sparse real-world samples. While Large Multi-modal Models (LMMs) excel in multi-modal understanding, their potential for fine-grained anomaly retrieval remains underexplored, hindered by: (1) a domain gap between generative knowledge and discriminative retrieval, and (2) the absence of efficient adaptation strategies for deployment. In this work, we propose AnomalyLMM, the first framework that harnesses LMMs for text-based person anomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline integrating LMMs to bridge generative world knowledge with retrieval-centric anomaly detection; (2) A training-free adaptation cookbook featuring masked cross-modal prompting, behavioral saliency prediction, and knowledge-aware re-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study to explore LMMs for this task, we conduct a rigorous evaluation on the PAB dataset, the only publicly available benchmark for text-based person anomaly search, with its curated real-world anomalies covering diverse scenarios (e.g., falling, collision, and being hit). Experiments show the effectiveness of the proposed method, surpassing the competitive baseline by +0.96% Recall@1 accuracy. Notably, our method reveals interpretable alignment between textual anomalies and visual behaviors, validated via qualitative analysis. Our code and models will be released for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04372v1" target="_blank">Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology</a></h3>
                    <p><strong>Authors:</strong> Yuchen Jiao, Yuxin Chen, Gen Li</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.GL, cs.LG, math.ST, stat.TH</p>
                    <p><strong>Summary:</strong> In this note, we reflect on several fundamental connections among widely used post-training techniques. We clarify some intimate connections and equivalences between reinforcement learning with human feedback, reinforcement learning with internal feedback, and test-time scaling (particularly soft best-of-$N$ sampling), while also illuminating intrinsic links between diffusion guidance and test-time scaling. Additionally, we introduce a resampling approach for alignment and reward-directed diffusion models, sidestepping the need for explicit reinforcement learning techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04369v1" target="_blank">3HDM with softly broken $Î”(54)$ and $Î£(36)$</a></h3>
                    <p><strong>Authors:</strong> GonÃ§alo Barreto, Ivo de Medeiros Varzielas</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-ph</p>
                    <p><strong>Summary:</strong> We perform an analysis of the scalar sector of 3-Higgs doublet models with softly broken $\Delta(54)$ and $\Sigma(36)$ symmetries. We consider the various vacuum expectation value alignments and consider, for each, softly broken terms that deviate the alignment. We check the evolution of the minima, present analytical and numerical results for the lifting of degeneracies of the physical eigenstates, and describe the decays of the states considering any residual symmetries.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04358v1" target="_blank">Privacy Perceptions in Robot-Assisted Well-Being Coaching: Examining the Roles of Information Transparency, User Control, and Proactivity</a></h3>
                    <p><strong>Authors:</strong> Atikkhan Faridkhan Nilgar, Manuel Dietrich, Kristof Van Laerhoven</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.RO</p>
                    <p><strong>Summary:</strong> Social robots are increasingly recognized as valuable supporters in the field of well-being coaching. They can function as independent coaches or provide support alongside human coaches, and healthcare professionals. In coaching interactions, these robots often handle sensitive information shared by users, making privacy a relevant issue. Despite this, little is known about the factors that shape users privacy perceptions. This research aims to examine three key factors systematically: (1) the transparency about information usage, (2) the level of specific user control over how the robot uses their information, and (3) the robots behavioral approach - whether it acts proactively or only responds on demand. Our results from an online study (N = 200) show that even when users grant the robot general access to personal data, they additionally expect the ability to explicitly control how that information is interpreted and shared during sessions. Experimental conditions that provided such control received significantly higher ratings for perceived privacy appropriateness and trust. Compared to user control, the effects of transparency and proactivity on privacy appropriateness perception were low, and we found no significant impact. The results suggest that merely informing users or proactive sharing is insufficient without accompanying user control. These insights underscore the need for further research on mechanisms that allow users to manage robots information processing and sharing, especially when social robots take on more proactive roles alongside humans.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04356v1" target="_blank">SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars</a></h3>
                    <p><strong>Authors:</strong> Atikkhan Faridkhan Nilgar, Kristof Van Laerhoven, Ayub Kinoti</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.RO</p>
                    <p><strong>Summary:</strong> We present SRWToolkit, an open-source Wizard of Oz toolkit designed to facilitate the rapid prototyping of social robotic avatars powered by local large language models (LLMs). Our web-based toolkit enables multimodal interaction through text input, button-activated speech, and wake-word command. The toolkit offers real-time configuration of avatar appearance, behavior, language, and voice via an intuitive control panel. In contrast to prior works that rely on cloud-based LLM services, SRWToolkit emphasizes modularity and ensures on-device functionality through local LLM inference. In our small-scale user study ($n=11$), participants created and interacted with diverse robotic roles (hospital receptionist, mathematics teacher, and driving assistant), which demonstrated positive outcomes in the toolkits usability, trust, and user experience. The toolkit enables rapid and efficient development of robot characters customized to researchers needs, supporting scalable research in human-robot interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04343v1" target="_blank">Psychologically Enhanced AI Agents</a></h3>
                    <p><strong>Authors:</strong> Maciej Besta, Shriram Chandran, Robert Gerstenberger, Mathis Lindner, Marcin Chrapek, Sebastian Hermann Martschat, Taraneh Ghandi, Patrick Iff, Hubert Niewiadomski, Piotr Nyczyk, JÃ¼rgen MÃ¼ller, Torsten Hoefler</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CY, cs.HC, cs.MA</p>
                    <p><strong>Summary:</strong> We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of Large Language Model (LLM) agents through psychologically grounded personality conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology, cognition and affect. We show that such personality priming yields consistent, interpretable behavioral biases across diverse tasks: emotionally expressive agents excel in narrative generation, while analytically primed agents adopt more stable strategies in game-theoretic settings. Our framework supports experimenting with structured multi-agent communication protocols and reveals that self-reflection prior to interaction improves cooperation and reasoning quality. To ensure trait persistence, we integrate the official 16Personalities test for automated verification. While our focus is on MBTI, we show that our approach generalizes seamlessly to other psychological frameworks such as Big Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior design, we establish a foundation for psychologically enhanced AI agents without any fine-tuning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04340v1" target="_blank">Write on Paper, Wrong in Practice: Why LLMs Still Struggle with Writing Clinical Notes</a></h3>
                    <p><strong>Authors:</strong> Kristina L. Kupferschmidt, Kieran ODoherty, Joshua A. Skorburg</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) are often proposed as tools to streamline clinical documentation, a task viewed as both high-volume and low-risk. However, even seemingly straightforward applications of LLMs raise complex sociotechnical considerations to translate into practice. This case study, conducted at KidsAbility, a pediatric rehabilitation facility in Ontario, Canada examined the use of LLMs to support occupational therapists in reducing documentation burden.We conducted a qualitative study involving 20 clinicians who participated in pilot programs using two AI technologies: a general-purpose proprietary LLM and a bespoke model fine-tuned on proprietary historical documentation. Our findings reveal that documentation challenges are sociotechnical in nature, shaped by clinical workflows, organizational policies, and system constraints. Four key themes emerged: (1) the heterogeneity of workflows, (2) the documentation burden is systemic and not directly linked to the creation of any single type of documentation, (3) the need for flexible tools and clinician autonomy, and (4) effective implementation requires mutual learning between clinicians and AI systems. While LLMs show promise in easing documentation tasks, their success will depend on flexible, adaptive integration that supports clinician autonomy. Beyond technical performance, sustained adoption will require training programs and implementation strategies that reflect the complexity of clinical environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04336v1" target="_blank">Gravitational-wave inference at GPU speed: A bilby-like nested sampling kernel within blackjax-ns</a></h3>
                    <p><strong>Authors:</strong> Metha Prathaban, David Yallup, James Alvey, Ming Yang, Will Templeton, Will Handley</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.HE, astro-ph.IM</p>
                    <p><strong>Summary:</strong> We present a GPU-accelerated implementation of the gravitational-wave Bayesian inference pipeline for parameter estimation and model comparison. Specifically, we implement the `acceptance-walk sampling method, a cornerstone algorithm for gravitational-wave inference within the bilby and dynesty framework. By integrating this trusted kernel with the vectorized blackjax-ns framework, we achieve typical speedups of 20-40x for aligned spin binary black hole analyses, while recovering posteriors and evidences that are statistically identical to the original CPU implementation. This faithful re-implementation of a community-standard algorithm establishes a foundational benchmark for gravitational-wave inference. It quantifies the performance gains attributable solely to the architectural shift to GPUs, creating a vital reference against which future parallel sampling algorithms can be rigorously assessed. This allows for a clear distinction between algorithmic innovation and the inherent speedup from hardware. Our work provides a validated community tool for performing GPU-accelerated nested sampling in gravitational-wave data analyses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04334v1" target="_blank">GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization</a></h3>
                    <p><strong>Authors:</strong> Pengyue Jia, Yingyi Zhang, Xiangyu Zhao, Yixuan Li</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Image geolocalization aims to predict the geographic location of images captured anywhere on Earth, but its global nature presents significant challenges. Current evaluation methodologies suffer from two major limitations. First, data leakage: advanced approaches often rely on large vision-language models (LVLMs) to predict image locations, yet these models are frequently pretrained on the test datasets, compromising the accuracy of evaluating a models actual geolocalization capability. Second, existing metrics primarily rely on exact geographic coordinates to assess predictions, which not only neglects the reasoning process but also raises privacy concerns when user-level location data is required. To address these issues, we propose GeoArena, a first open platform for evaluating LVLMs on worldwide image geolocalization tasks, offering true in-the-wild and human-centered benchmarking. GeoArena enables users to upload in-the-wild images for a more diverse evaluation corpus, and it leverages pairwise human judgments to determine which model output better aligns with human expectations. Our platform has been deployed online for two months, during which we collected over thousands voting records. Based on this data, we conduct a detailed analysis and establish a leaderboard of different LVLMs on the image geolocalization task.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04330v1" target="_blank">Temporal Interest-Driven Multimodal Personalized Content Generation</a></h3>
                    <p><strong>Authors:</strong> Tian Miao</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> With the dynamic evolution of user interests and the increasing multimodal demands in internet applications, personalized content generation strategies based on static interest preferences struggle to meet practical application requirements. The proposed TIMGen (Temporal Interest-driven Multimodal Generation) model addresses this challenge by modeling the long-term temporal evolution of users interests and capturing dynamic interest representations with strong temporal dependencies. This model also supports the fusion of multimodal features, such as text, images, video, and audio, and delivers customized content based on multimodal preferences. TIMGen jointly learns temporal dependencies and modal preferences to obtain a unified interest representation, which it then generates to meet users personalized content needs. TIMGen overcomes the shortcomings of personalized content recommendation methods based on static preferences, enabling flexible and dynamic modeling of users multimodal interests, better understanding and capturing their interests and preferences. It can be extended to a variety of practical application scenarios, including e-commerce, advertising, online education, and precision medicine, providing insights for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04324v1" target="_blank">OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection</a></h3>
                    <p><strong>Authors:</strong> Chen Hu, Shan Luo, Letizia Gionfrida</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Grasping assistance is essential for restoring autonomy in individuals with motor impairments, particularly in unstructured environments where object categories and user intentions are diverse and unpredictable. We present OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp assistance that integrates RGB-D vision, open-vocabulary prompts, and voice commands to enable robust multimodal interaction. To enhance generalization in open environments, OVGrasp incorporates a vision-language foundation model with an open-vocabulary mechanism, allowing zero-shot detection of previously unseen objects without retraining. A multimodal decision-maker further fuses spatial and linguistic cues to infer user intent, such as grasp or release, in multi-object scenarios. We deploy the complete framework on a custom egocentric-view wearable exoskeleton and conduct systematic evaluations on 15 objects across three grasp types. Experimental results with ten participants demonstrate that OVGrasp achieves a grasping ability score (GAS) of 87.00%, outperforming state-of-the-art baselines and achieving improved kinematic alignment with natural hand motion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04313v1" target="_blank">Ultrasound-Triggered Release of Anticancer Nanoparticles from Electrospun Fabrics Integrated with Soft Robotic Tentacles</a></h3>
                    <p><strong>Authors:</strong> Samuel C. T. Moorcroft, Benjamin CalmÃ©, Charles Brooker, Pietro Valdastri, Russell Harris, Stephen J. Russell, Giuseppe Tronci</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> The prompt identification of pancreatic cancer symptoms is an ongoing clinical challenge, often leading to late diagnosis and poor prognosis. Tumor hijacking of the pancreatic stromal structure limits the uptake of systemic chemotherapeutics. Localized drug delivery systems (DDS) using endoluminal techniques are widely utilized, with positive early results for improved control over tumor growth. There is a need for technologies that integrate endoluminal resources and intelligent material systems to better control the spatiotemporal delivery of chemotherapeutics. We demonstrate the ultrasound (US)-triggered localized release of therapeutics through the design of solvent traceless drug-loaded vinylbenzyl-functionalized gelatin (gel4vbc) nanoparticles (NPs) integrated with an electrospun fabric. Albumin-loaded NPs encapsulated into a poly(vinyl alcohol) (PVA) coating of a poly(epsilon-caprolactone) fabric evidence tunable triggered NP delivery controlled by regulating PVA concentration (0-1 wt.%) and US intensity (0-3 W/cm2). The fixation of the NP-coated fabric to a magnetic tentacle robot (MTR) enables the automated manipulation into a phantom pancreatic duct before the US-triggered release of NP-loaded albumin and MTR retraction. Albumin release is controlled by varying the surface area of the NP-loaded MTR-coating fabric. Herein we have designed a novel DDS capable of facile integration into soft robotics and US-triggered delivery of therapeutic-loaded NPs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04310v1" target="_blank">EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation</a></h3>
                    <p><strong>Authors:</strong> Yunbo Long, Liming Xu, Lukas Beckenbauer, Yuhan Liu, Alexandra Brintrup</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \textit{complex}, \textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines -- vanilla strategies and fixed-emotion strategies -- for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04304v1" target="_blank">Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Juraj Vladika, Mahdi Dhaini, Florian Matthes</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The growing capabilities of Large Language Models (LLMs) show significant potential to enhance healthcare by assisting medical researchers and physicians. However, their reliance on static training data is a major risk when medical recommendations evolve with new research and developments. When LLMs memorize outdated medical knowledge, they can provide harmful advice or fail at clinical reasoning tasks. To investigate this problem, we introduce two novel question-answering (QA) datasets derived from systematic reviews: MedRevQA (16,501 QA pairs covering general biomedical knowledge) and MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over time). Our evaluation of eight prominent LLMs on the datasets reveals consistent reliance on outdated knowledge across all models. We additionally analyze the influence of obsolete pre-training data and training strategies to explain this phenomenon and propose future directions for mitigation, laying the groundwork for developing more current and reliable medical AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04303v1" target="_blank">HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Georgios Makridis, Georgios Fragiadakis, Jorge Oliveira, Tomaz Saraiva, Philip Mavrepis, Georgios Fatouros, Dimosthenis Kyriazis</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04297v1" target="_blank">The changing transit shape of TOI-3884 b</a></h3>
                    <p><strong>Authors:</strong> Hritam Chakraborty, Jose M. Almenara, Monika Lendl, David Ehrenreich, FranÃ§ois Bouchy, Xavier Bonfils, Radmila Dancikova, Adrien Deline, Saniya Khan, Henryka Netzel, Muskan Shinde, AurÃ©lien Verdier</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.EP</p>
                    <p><strong>Summary:</strong> TOI-3884 b is a sub-Saturn transiting a fully convective M-dwarf. Observations indicate that the transit shape is chromatic and asymmetric as a result of persistent starspot crossings. This, along with the lack of photometric variability of the host star, indicates that the rotational axis of the star is tilted along our line of sight and the planet-occulted starspot is located close to the stellar pole. We acquired photometric transits over a period of three years with the Swiss 1.2-meter Euler telescope to track changes in the starspot configuration and detect any signs of decay or growth. The shape of the transit changes over time, and so far no two observations match perfectly. We conclude that the observed variability is likely not caused by changes in the temperature and size of the spot, but due to a slight (5.64 $\pm$ 0.64$^{\circ}$) misalignment between the spot center and the stellar pole, i.e., a small spin-spot angle ($\Theta$). In addition, we were able to obtain precise measurements of the sky-projected spin-orbit angle ($\lambda$) of 37.3 $\pm$ 1.5\degree, and the true spin-orbit angle ($\psi$) of 54.3 $\pm$ 1.4\degree. The precise alignment measurements along with future atmospheric characterisation with the James Webb Space Telescope will be vital for understanding the formation and evolution of close-in, massive planets around fully convective stars.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04292v1" target="_blank">Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?</a></h3>
                    <p><strong>Authors:</strong> Qinyan Zhang, Xinping Lei, Ruijie Miao, Yu Fu, Haojie Fan, Le Chang, Jiafan Hou, Dingling Zhang, Zhongfei Hou, Ziqiang Yang, Changxin Pu, Fei Hu, Jingkai Liu, Mengyun Liu, Yang Liu, Xiang Gao, Jiaheng Liu, Tong Yang, Zaiyuan Wang, Ge Zhang, Wenhao Huang</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04266v1" target="_blank">Foundations of photonic quantum computation</a></h3>
                    <p><strong>Authors:</strong> Martin Bombardelli, GÃ©rard Fleury, Philippe Lacomme, Bogdan Vulpescu</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> This work aims to introduce the fundamental concepts required to perform computations on photonic quantum computers by presenting the gates specific to this architecture and highlighting the connections between standard Pauli gates and those available in photonic systems. The introduction navigates between physical considerations related to the optical components used, theoretical aspects concerning quantum operators, and a more applied section introducing implementations using the Perceval library developed by Quandela. This paper is intended for engineers and researchers familiar with Pauli gates and standard quantum concepts, looking at a clear and compact introduction to photonic components. A second part aims to introduce the concept of polarization, not from a theoretical perspective, but through its practical applications. To do so, we compare the similarities and differences between the original Grovers algorithm formulation and a version that leverages polarization. Gates specific to polarization are introduced and described in the context of the computations involved in Grovers algorithm. The description provided is as mathematical as possible and deliberately avoids physical considerations, in order to allow researchers familiar with conventional quantum circuits to more easily grasp the concepts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04258v1" target="_blank">Safe Navigation in the Presence of Range-Limited Pursuers</a></h3>
                    <p><strong>Authors:</strong> Thomas Chapman, Alexander Von Moll, Isaac E. Weintraub</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.OC</p>
                    <p><strong>Summary:</strong> This paper examines the degree to which an evader seeking a safe and efficient path to a target location can benefit from increasing levels of knowledge regarding one or more range-limited pursuers seeking to intercept it. Unlike previous work, this research considers the time of flight of the pursuers actively attempting interception. It is shown that additional knowledge allows the evader to safely steer closer to the threats, shortening paths without accepting additional risk of capture. A control heuristic is presented, suitable for real time implementation, which capitalizes on all knowledge available to the evader.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04245v1" target="_blank">Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models</a></h3>
                    <p><strong>Authors:</strong> Chanon Puttanawarut, Natcha Fongsrisin, Porntep Amornritvanich, Cholatid Ratanatharathorn, Panu Looareesuwan</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Background: Heart failure (HF) research is constrained by limited access to large, shareable datasets due to privacy regulations and institutional barriers. Synthetic data generation offers a promising solution to overcome these challenges while preserving patient confidentiality. Methods: We generated synthetic HF datasets from institutional data comprising 12,552 unique patients using five deep learning models: tabular variational autoencoder (TVAE), normalizing flow, ADSGAN, SurvivalGAN, and tabular denoising diffusion probabilistic models (TabDDPM). We comprehensively evaluated synthetic data utility through statistical similarity metrics, survival prediction using machine learning and privacy assessments. Results: SurvivalGAN and TabDDPM demonstrated high fidelity to the original dataset, exhibiting similar variable distributions and survival curves after applying histogram equalization. SurvivalGAN (C-indices: 0.71-0.76) and TVAE (C-indices: 0.73-0.76) achieved the strongest performance in survival prediction evaluation, closely matched real data performance (C-indices: 0.73-0.76). Privacy evaluation confirmed protection against re-identification attacks. Conclusions: Deep learning-based synthetic data generation can produce high-fidelity, privacy-preserving HF datasets suitable for research applications. This publicly available synthetic dataset addresses critical data sharing barriers and provides a valuable resource for advancing HF research and predictive modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04241v1" target="_blank">Would I regret being different? The influence of social norms on attitudes toward AI usage</a></h3>
                    <p><strong>Authors:</strong> Jaroslaw Kornowicz, Maurice Pape, Kirsten Thommes</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Prior research shows that social norms can reduce algorithm aversion, but little is known about how such norms become established. Most accounts emphasize technological and individual determinants, yet AI adoption unfolds within organizational social contexts shaped by peers and supervisors. We ask whether the source of the norm-peers or supervisors-shapes AI usage behavior. This question is practically relevant for organizations seeking to promote effective AI adoption. We conducted an online vignette experiment, complemented by qualitative data on participants feelings and justifications after (counter-)normative behavior. In line with the theory, counter-normative choices elicited higher regret than norm-adherent choices. On average, choosing AI increased regret compared to choosing an human. This aversion was weaker when AI use was presented as the prevailing norm, indicating a statistically significant interaction between AI use and an AI-favoring norm. Participants also attributed less blame to technology than to humans, which increased regret when AI was chosen over human expertise. Both peer and supervisor influence emerged as relevant factors, though contrary to expectations they did not significantly affect regret. Our findings suggest that regret aversion, embedded in social norms, is a central mechanism driving imitation in AI-related decision-making.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/CoG64752.2025.11114354" target="_blank">Evaluating Quality of Gaming Narratives Co-created with AI</a></h3>
                    <p><strong>Authors:</strong> Arturo Valdivia, Paolo Burelli</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This paper proposes a structured methodology to evaluate AI-generated game narratives, leveraging the Delphi study structure with a panel of narrative design experts. Our approach synthesizes story quality dimensions from literature and expert insights, mapping them into the Kano model framework to understand their impact on player satisfaction. The results can inform game developers on prioritizing quality aspects when co-creating game narratives with generative AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04234v1" target="_blank">Simple harmonic oscillators from non-semisimple walled Brauer algebras</a></h3>
                    <p><strong>Authors:</strong> Sanjaye Ramgoolam, MichaÅ‚ StudziÅ„ski</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-th, math.CO, math.RT, quant-ph</p>
                    <p><strong>Summary:</strong> Walled Brauer algebras $B_N ( m , n ) $ illuminate the combinatorics of mixed tensor representations of $U(N)$, with $m$ copies of the fundamental and $n$ copies of the anti-fundamental representation. They lie at the intersection of research in representation theory, AdS/CFT and quantum information theory. They have been used to study of correlators in multi-matrix models motivated by brane-anti-brane physics in AdS/CFT. They have been applied in computing and optimising fidelities of port-based quantum teleportation. There is a large $N$ regime, specifically $ N \ge (m+n)$ where the algebras are semi-simple and their representation theory more tractable. There are known combinatorial formulae for dimensions of irreducible representations and associated reduction multiplicities. The large $N$ regime has a stability property whereby these formulae are independent of $N$. In this paper we initiate a systematic study of the combinatorics in the non-semisimple regime of $ N = m +n - l $, with positive $l$. We introduce restricted Bratteli diagrams (RBD) which are useful as an instrument to process known data from the large $N$ regime to calculate representation theory data in the non-semisimple regime. We identify within the non-semisimple regime, a region of $(m,n)$-stability, where $ \min ( m, n ) \ge ( 2l -3) $ and the RBD take a stable form depending on $l$ only and not the choice of $ m,n$ within the region. In this regime, several aspects of the combinatorics of the RBD are controlled by a universal partition function for an infinite tower of simple harmonic oscillators closely related, but not identical, to the partition function of 2D non-chiral free scalar field theory.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04226v1" target="_blank">Rethinking the long-range dependency in Mamba/SSM and transformer models</a></h3>
                    <p><strong>Authors:</strong> Cong Ma, Kayvan Najarian</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Long-range dependency is one of the most desired properties of recent sequence models such as state-space models (particularly Mamba) and transformer models. New model architectures are being actively developed and benchmarked for prediction tasks requiring long-range dependency. However, the capability of modeling long-range dependencies of these models has not been investigated from a theoretical perspective, which hinders a systematic improvement on this aspect. In this work, we mathematically define long-range dependency using the derivative of hidden states with respect to past inputs and compare the capability of SSM and transformer models of modeling long-range dependency based on this definition. We showed that the long-range dependency of SSM decays exponentially with the sequence length, which aligns with the exponential decay of memory function in RNN. But the attention mechanism used in transformers is more flexible and is not constrained to exponential decay, which could in theory perform better at modeling long-range dependency with sufficient training data, computing resources, and proper training. To combine the flexibility of long-range dependency of attention mechanism and computation efficiency of SSM, we propose a new formulation for hidden state update in SSM and prove its stability under a standard Gaussian distribution of the input data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04222v1" target="_blank">Why Cant I See My Clusters? A Precision-Recall Approach to Dimensionality Reduction Validation</a></h3>
                    <p><strong>Authors:</strong> Diede P. M. van der Hoorn, Alessio Arleo, Fernando V. Paulovich</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Dimensionality Reduction (DR) is widely used for visualizing high-dimensional data, often with the goal of revealing expected cluster structure. However, such a structure may not always appear in the projections. Existing DR quality metrics assess projection reliability (to some extent) or cluster structure quality, but do not explain why expected structures are missing. Visual Analytics solutions can help, but are often time-consuming due to the large hyperparameter space. This paper addresses this problem by leveraging a recent framework that divides the DR process into two phases: a relationship phase, where similarity relationships are modeled, and a mapping phase, where the data is projected accordingly. We introduce two supervised metrics, precision and recall, to evaluate the relationship phase. These metrics quantify how well the modeled relationships align with an expected cluster structure based on some set of labels representing this structure. We illustrate their application using t-SNE and UMAP, and validate the approach through various usage scenarios. Our approach can guide hyperparameter tuning, uncover projection artifacts, and determine if the expected structure is captured in the relationships, making the DR process faster and more reliable.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1007/978-3-031-85960-1_12" target="_blank">Analyzing the Effect of an Extreme Weather Event on Telecommunications and Information Technology: Insights from 30 Days of Flooding</a></h3>
                    <p><strong>Authors:</strong> Leandro MÃ¡rcio Bertholdo, Renan Barreto Paredes, Gabriela de Lima Marin, Cesar A. H. Loureiro, Milton Kaoru Kashiwakura Pedro de Botelho Marcos</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> In May 2024, weeks of severe rainfall in Rio Grande do Sul, Brazil caused widespread damage to infrastructure, impacting over 400 cities and 2.3 million people. This study presents the construction of comprehensive telecommunications datasets during this climatic event, encompassing Internet measurements, fiber cut reports, and Internet Exchange routing data. By correlating network disruptions with hydrological and operational factors, the dataset offers insights into the resilience of fiber networks, data centers, and Internet traffic during critical events. For each scenario, we investigate failures related to the Information and Communication Technology infrastructure and highlight the challenges faced when its resilience is critically tested. Preliminary findings reveal trends in connectivity restoration, infrastructure vulnerabilities, and user behavior changes. These datasets and pre-analysis aim to support future research on disaster recovery strategies and the development of robust telecommunications systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04213v1" target="_blank">Sailing Towards Zero-Shot State Estimation using Foundation Models Combined with a UKF</a></h3>
                    <p><strong>Authors:</strong> Tobin Holtmann, David Stenger, Andres Posada-Moreno, Friedrich Solowjow, Sebastian Trimpe</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.LG, cs.SY</p>
                    <p><strong>Summary:</strong> State estimation in control and systems engineering traditionally requires extensive manual system identification or data-collection effort. However, transformer-based foundation models in other domains have reduced data requirements by leveraging pre-trained generalist models. Ultimately, developing zero-shot foundation models of system dynamics could drastically reduce manual deployment effort. While recent work shows that transformer-based end-to-end approaches can achieve zero-shot performance on unseen systems, they are limited to sensor models seen during training. We introduce the foundation model unscented Kalman filter (FM-UKF), which combines a transformer-based model of system dynamics with analytically known sensor models via an UKF, enabling generalization across varying dynamics without retraining for new sensor configurations. We evaluate FM-UKF on a new benchmark of container ship models with complex dynamics, demonstrating a competitive accuracy, effort, and robustness trade-off compared to classical methods with approximate system knowledge and to an end-to-end approach. The benchmark and dataset are open sourced to further support future research in zero-shot state estimation via foundation models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04208v1" target="_blank">One-Embedding-Fits-All: Efficient Zero-Shot Time Series Forecasting by a Model Zoo</a></h3>
                    <p><strong>Authors:</strong> Hao-Nan Shi, Ting-Ji Huang, Lu Han, De-Chuan Zhan, Han-Jia Ye</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> The proliferation of Time Series Foundation Models (TSFMs) has significantly advanced zero-shot forecasting, enabling predictions for unseen time series without task-specific fine-tuning. Extensive research has confirmed that no single TSFM excels universally, as different models exhibit preferences for distinct temporal patterns. This diversity suggests an opportunity: how to take advantage of the complementary abilities of TSFMs. To this end, we propose ZooCast, which characterizes each models distinct forecasting strengths. ZooCast can intelligently assemble current TSFMs into a model zoo that dynamically selects optimal models for different forecasting tasks. Our key innovation lies in the One-Embedding-Fits-All paradigm that constructs a unified representation space where each model in the zoo is represented by a single embedding, enabling efficient similarity matching for all tasks. Experiments demonstrate ZooCasts strong performance on the GIFT-Eval zero-shot forecasting benchmark while maintaining the efficiency of a single TSFM. In real-world scenarios with sequential model releases, the framework seamlessly adds new models for progressive accuracy gains with negligible overhead.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04206v1" target="_blank">Two-dimensional magnetic tunnel p-n junctions for low-power electronics</a></h3>
                    <p><strong>Authors:</strong> Wenkai Zhu, Ziao Wang, Tiangui Hu, Zakhar R. Kudrynskyi, Tong Zhou, Zakhar D. Kovalyuk, Ce Hu, Hailong Lin, Xiaodong Li, Yongcheng Deng, Quanshan Lv, Lixia Zhao, Amalia Patane, Igor Zutic, Houzhi Zheng, Kaiyou Wang</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.other</p>
                    <p><strong>Summary:</strong> For decades, semiconductors and their heterostructures have underpinned both fundamental and applied research across all areas of electronics. Two-dimensional, 2D (atomically thin) semiconductors have now the potential to push further the miniaturization of electronic components, enabling the development of more efficient electronics. Here, we report on a giant anomalous zero-bias spin voltage in magnetic tunnel junctions based on 2D materials. The generation, manipulation and detection of electron spin across a nanometer-thick magnetic tunnel junction do not require any applied bias. It is achieved by exploiting high-quality ferromagnetic/semiconductor interfaces and the asymmetric diffusion of spin-up/spin-down electrons across a semiconductor p-n junction. The large spin-voltage signal exceeds 30,000% and is far greater than the highest magnetoresistance signals reported to date. Our findings reveal unexplored opportunities to transform and amplify spin information for low-power electronics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04203v1" target="_blank">Bayesian Stacking via Proper Scoring Rule Optimization using a Gibbs Posterior</a></h3>
                    <p><strong>Authors:</strong> Spencer Wadsworth, Jarad Niemi</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> In collaborative forecast projects, the combining of multiple probabilistic forecasts into an ensemble is standard practice, with linear pooling being a common combination method. The weighting scheme of a linear pool should be tailored to the specific research question, and weight selection is often performed via optimizing a proper scoring rule. This is known as optimal linear pooling. Besides optimal linear pooling, Bayesian predictive synthesis has emerged as a model probability updating scheme which is more flexible than standard Bayesian model averaging and which provides a Bayesian solution to selecting model weights for a linear pool. In many problems, equally weighted linear pool forecasts often outperform forecasts constructed using sophisticated weight selection methods. Thus regularization to an equal weighting of forecasts may be a valuable addition to any weight selection method. In this manuscript, we introduce an optimal linear pool based on a Gibbs posterior over stacked model weights optimized over a proper scoring rule. The Gibbs posterior extends stacking into a Bayesian framework by allowing for optimal weight solutions to be influenced by a prior distribution, and it also provides uncertainty quantification of weights in the form of a probability distribution. We compare ensemble forecast performance with model averaging methods and equal weighted models in simulation studies and in a real data example from the 2023-24 US Centers for Disease Control FluSight competition. In both the simulation studies and the FluSight analysis, the stacked Gibbs posterior produces ensemble forecasts which often outperform the ensembles of other methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04198v1" target="_blank">Are LLM Agents the New RPA? A Comparative Study with RPA Across Enterprise Workflows</a></h3>
                    <p><strong>Authors:</strong> Petr PrÅ¯cha, Michaela MatouÅ¡kovÃ¡, Jan Strnad</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.MA</p>
                    <p><strong>Summary:</strong> The emergence of large language models (LLMs) has introduced a new paradigm in automation: LLM agents or Agentic Automation with Computer Use (AACU). Unlike traditional Robotic Process Automation (RPA), which relies on rule-based workflows and scripting, AACU enables intelligent agents to perform tasks through natural language instructions and autonomous interaction with user interfaces. This study investigates whether AACU can serve as a viable alternative to RPA in enterprise workflow automation. We conducted controlled experiments across three standard RPA challenges data entry, monitoring, and document extraction comparing RPA (via UiPath) and AACU (via Anthropics Computer Use Agent) in terms of speed, reliability, and development effort. Results indicate that RPA outperforms AACU in execution speed and reliability, particularly in repetitive, stable environments. However, AACU significantly reduces development time and adapts more flexibly to dynamic interfaces. While current AACU implementations are not yet production-ready, their promise in rapid prototyping and lightweight automation is evident. Future research should explore multi-agent orchestration, hybrid RPA-AACU architectures, and more robust evaluation across industries and platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04193v1" target="_blank">DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval</a></h3>
                    <p><strong>Authors:</strong> Ruohong Yang, Peng Hu, Yunfan Li, Xi Peng</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of the same category across diverse domains without relying on annotations. Existing UCIR methods, which align cross-domain features for the entire image, often struggle with the domain gap, as the object features critical for retrieval are frequently entangled with domain-specific styles. To address this challenge, we propose DUDE, a novel UCIR method building upon feature disentanglement. In brief, DUDE leverages a text-to-image generative model to disentangle object features from domain-specific styles, thus facilitating semantical image retrieval. To further achieve reliable alignment of the disentangled object features, DUDE aligns mutual neighbors from within domains to across domains in a progressive manner. Extensive experiments demonstrate that DUDE achieves state-of-the-art performance across three benchmark datasets over 13 domains. The code will be released.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04183v1" target="_blank">MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions</a></h3>
                    <p><strong>Authors:</strong> Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The growing demand for scalable psychological counseling highlights the need for fine-tuning open-source Large Language Models (LLMs) with high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. In addition, we address inconsistencies in prior evaluation protocols by proposing a unified evaluation framework integrating diverse automatic and expert metrics. Furthermore, we expand the expert evaluations from four aspects of counseling in previous works to nine aspects, enabling a more thorough and robust assessment of data quality. Empirical results show that MAGneT significantly outperforms existing methods in quality, diversity, and therapeutic alignment of the generated counseling sessions, improving general counseling skills by 3.2% and CBT-specific skills by 4.3% on average on cognitive therapy rating scale (CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases on average across all aspects. Moreover, fine-tuning an open-source model on MAGneT-generated sessions shows better performance, with improvements of 6.3% on general counseling skills and 7.3% on CBT-specific skills on average on CTRS over those fine-tuned with sessions generated by baseline methods. We also make our code and data public.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04180v1" target="_blank">VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision</a></h3>
                    <p><strong>Authors:</strong> Safouane El Ghazouali, Umberto Michelucci</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> AI models rely on annotated data to learn pattern and perform prediction. Annotation is usually a labor-intensive step that require associating labels ranging from a simple classification label to more complex tasks such as object detection, oriented bounding box estimation, and instance segmentation. Traditional tools often require extensive manual input, limiting scalability for large datasets. To address this, we introduce VisioFirm, an open-source web application designed to streamline image labeling through AI-assisted automation. VisioFirm integrates state-of-the-art foundation models into an interface with a filtering pipeline to reduce human-in-the-loop efforts. This hybrid approach employs CLIP combined with pre-trained detectors like Ultralytics models for common classes and zero-shot models such as Grounding DINO for custom labels, generating initial annotations with low-confidence thresholding to maximize recall. Through this framework, when tested on COCO-type of classes, initial prediction have been proven to be mostly correct though the users can refine these via interactive tools supporting bounding boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has on-the-fly segmentation powered by Segment Anything accelerated through WebGPU for browser-side efficiency. The tool supports multiple export formats (YOLO, COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing accessibility. VisioFirm demonstrates up to 90\% reduction in manual effort through benchmarks on diverse datasets, while maintaining high annotation accuracy via clustering of connected CLIP-based disambiguate components and IoU-graph for redundant detection suppression. VisioFirm can be accessed from \href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04173v1" target="_blank">Real-time Object Detection and Associated Hardware Accelerators Targeting Autonomous Vehicles: A Review</a></h3>
                    <p><strong>Authors:</strong> Safa Sali, Anis Meribout, Ashiyana Majeed, Mahmoud Meribout, Juan Pablo, Varun Tiwari, Asma Baobaid</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> The efficiency of object detectors depends on factors like detection accuracy, processing time, and computational resources. Processing time is crucial for real-time applications, particularly for autonomous vehicles (AVs), where instantaneous responses are vital for safety. This review paper provides a concise yet comprehensive survey of real-time object detection (OD) algorithms for autonomous cars delving into their hardware accelerators (HAs). Non-neural network-based algorithms, which use statistical image processing, have been entirely substituted by AI algorithms, such as different models of convolutional neural networks (CNNs). Their intrinsically parallel features led them to be deployable into edge-based HAs of various types, where GPUs and, to a lesser extent, ASIC (application-specific integrated circuit) remain the most widely used. Throughputs of hundreds of frames/s (fps) could be reached; however, handling object detection for all the cameras available in a typical AV requires further hardware and algorithmic improvements. The intensive competition between AV providers has limited the disclosure of algorithms, firmware, and even hardware platform details. This remains a hurdle for researchers, as commercial systems provide valuable insights while academics undergo lengthy training and testing on restricted datasets and road scenarios. Consequently, many AV research papers may not be reflected in end products, being developed under limited conditions. This paper surveys state-of-the-art OD algorithms and aims to bridge the gap with technologies in commercial AVs. To our knowledge, this aspect has not been addressed in earlier surveys. Hence, the paper serves as a tangible reference for researchers designing future generations of vehicles, expected to be fully autonomous for comfort and safety.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04169v1" target="_blank">Privacy Risks in Time Series Forecasting: User- and Record-Level Membership Inference</a></h3>
                    <p><strong>Authors:</strong> Nicolas Johansson, Tobias Olsson, Daniel Nilsson, Johan Ã–stman, Fazeleh Hoseini</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Membership inference attacks (MIAs) aim to determine whether specific data were used to train a model. While extensively studied on classification models, their impact on time series forecasting remains largely unexplored. We address this gap by introducing two new attacks: (i) an adaptation of multivariate LiRA, a state-of-the-art MIA originally developed for classification models, to the time-series forecasting setting, and (ii) a novel end-to-end learning approach called Deep Time Series (DTS) attack. We benchmark these methods against adapted versions of other leading attacks from the classification setting. We evaluate all attacks in realistic settings on the TUH-EEG and ELD datasets, targeting two strong forecasting architectures, LSTM and the state-of-the-art N-HiTS, under both record- and user-level threat models. Our results show that forecasting models are vulnerable, with user-level attacks often achieving perfect detection. The proposed methods achieve the strongest performance in several settings, establishing new baselines for privacy risk assessment in time series forecasting. Furthermore, vulnerability increases with longer prediction horizons and smaller training populations, echoing trends observed in large language models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04450v1" target="_blank">Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview</a></h3>
                    <p><strong>Authors:</strong> Jun-Kun Chen, Aayush Bansal, Minh Phuoc Vo, Yu-Xiong Wang</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> We introduce the Virtual Fitting Room (VFR), a novel video generative model that produces arbitrarily long virtual try-on videos. Our VFR models long video generation tasks as an auto-regressive, segment-by-segment generation process, eliminating the need for resource-intensive generation and lengthy video data, while providing the flexibility to generate videos of arbitrary length. The key challenges of this task are twofold: ensuring local smoothness between adjacent segments and maintaining global temporal consistency across different segments. To address these challenges, we propose our VFR framework, which ensures smoothness through a prefix video condition and enforces consistency with the anchor video -- a 360-degree video that comprehensively captures the humans wholebody appearance. Our VFR generates minute-scale virtual try-on videos with both local smoothness and global temporal consistency under various motions, making it a pioneering work in long virtual try-on video generation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04448v1" target="_blank">TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection</a></h3>
                    <p><strong>Authors:</strong> Zehong Yan, Peng Qi, Wynne Hsu, Mong Li Lee</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.MM</p>
                    <p><strong>Summary:</strong> Multimodal misinformation, encompassing textual, visual, and cross-modal distortions, poses an increasing societal threat that is amplified by generative AI. Existing methods typically focus on a single type of distortion and struggle to generalize to unseen scenarios. In this work, we observe that different distortion types share common reasoning capabilities while also requiring task-specific skills. We hypothesize that joint training across distortion types facilitates knowledge sharing and enhances the models ability to generalize. To this end, we introduce TRUST-VL, a unified and explainable vision-language model for general multimodal misinformation detection. TRUST-VL incorporates a novel Question-Aware Visual Amplifier module, designed to extract task-specific visual features. To support training, we also construct TRUST-Instruct, a large-scale instruction dataset containing 198K samples featuring structured reasoning chains aligned with human fact-checking workflows. Extensive experiments on both in-domain and zero-shot benchmarks demonstrate that TRUST-VL achieves state-of-the-art performance, while also offering strong generalization and interpretability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04446v1" target="_blank">Plotn Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Kiymet Akdemir, Jing Shi, Kushal Kafle, Brian Price, Pinar Yanardag</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-image diffusion models have demonstrated significant capabilities to generate diverse and detailed visuals in various domains, and story visualization is emerging as a particularly promising application. However, as their use in real-world creative domains increases, the need for providing enhanced control, refinement, and the ability to modify images post-generation in a consistent manner becomes an important challenge. Existing methods often lack the flexibility to apply fine or coarse edits while maintaining visual and narrative consistency across multiple frames, preventing creators from seamlessly crafting and refining their visual stories. To address these challenges, we introduce Plotn Polish, a zero-shot framework that enables consistent story generation and provides fine-grained control over story visualizations at various levels of detail.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04444v1" target="_blank">One Flight Over the Gap: A Survey from Perspective to Panoramic Vision</a></h3>
                    <p><strong>Authors:</strong> Xin Lin, Xian Ge, Dizhe Zhang, Zhaoliang Wan, Xianshun Wang, Xiangtai Li, Wenjie Jiang, Bo Du, Dacheng Tao, Ming-Hsuan Yang, Lu Qi</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Driven by the demand for spatial intelligence and holistic scene perception, omnidirectional images (ODIs), which provide a complete 360\textdegree{} field of view, are receiving growing attention across diverse applications such as virtual reality, autonomous driving, and embodied robotics. Despite their unique characteristics, ODIs exhibit remarkable differences from perspective images in geometric projection, spatial distribution, and boundary continuity, making it challenging for direct domain adaption from perspective methods. This survey reviews recent panoramic vision techniques with a particular emphasis on the perspective-to-panorama adaptation. We first revisit the panoramic imaging pipeline and projection methods to build the prior knowledge required for analyzing the structural disparities. Then, we summarize three challenges of domain adaptation: severe geometric distortions near the poles, non-uniform sampling in Equirectangular Projection (ERP), and periodic boundary continuity. Building on this, we cover 20+ representative tasks drawn from more than 300 research papers in two dimensions. On one hand, we present a cross-method analysis of representative strategies for addressing panoramic specific challenges across different tasks. On the other hand, we conduct a cross-task comparison and classify panoramic vision into four major categories: visual quality enhancement and assessment, visual understanding, multimodal understanding, and visual generation. In addition, we discuss open challenges and future directions in data, models, and applications that will drive the advancement of panoramic vision research. We hope that our work can provide new insight and forward looking perspectives to advance the development of panoramic vision technologies. Our project page is https://insta360-research-team.github.io/Survey-of-Panorama</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04442v1" target="_blank">Delta Activations: A Representation for Finetuned Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Zhiqiu Xu, Amish Sethi, Mayur Naik, Ser-Nam Lim</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collection of post-trained models adapted to specific tasks and domains. However, navigating and understanding these models remains challenging due to inconsistent metadata and unstructured repositories. We introduce Delta Activations, a method to represent finetuned models as vector embeddings by measuring shifts in their internal activations relative to a base model. This representation allows for effective clustering by domain and task, revealing structure in the model landscape. Delta Activations also demonstrate desirable properties: it is robust across finetuning settings and exhibits an additive property when finetuning datasets are mixed. In addition, we show that Delta Activations can embed tasks via few-shot finetuning, and further explore its use for model selection and merging. We hope Delta Activations can facilitate the practice of reusing publicly available models. Code is available at https://github.com/OscarXZQ/delta_activations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04441v1" target="_blank">DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation</a></h3>
                    <p><strong>Authors:</strong> Hao-Shu Fang, Branden Romero, Yichen Xie, Arthur Hu, Bo-Ruei Huang, Juan Alvarez, Matthew Kim, Gabriel Margolis, Kavya Anbarasu, Masayoshi Tomizuka, Edward Adelson, Pulkit Agrawal</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CV, cs.HC</p>
                    <p><strong>Summary:</strong> We introduce perioperation, a paradigm for robotic data collection that sensorizes and records human manipulation while maximizing the transferability of the data to real robots. We implement this paradigm in DEXOP, a passive hand exoskeleton designed to maximize human ability to collect rich sensory (vision + tactile) data for diverse dexterous manipulation tasks in natural environments. DEXOP mechanically connects human fingers to robot fingers, providing users with direct contact feedback (via proprioception) and mirrors the human hand pose to the passive robot hand to maximize the transfer of demonstrated skills to the robot. The force feedback and pose mirroring make task demonstrations more natural for humans compared to teleoperation, increasing both speed and accuracy. We evaluate DEXOP across a range of dexterous, contact-rich tasks, demonstrating its ability to collect high-quality demonstration data at scale. Policies learned with DEXOP data significantly improve task performance per unit time of data collection compared to teleoperation, making DEXOP a powerful tool for advancing robot dexterity. Our project page is at https://dex-op.github.io.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04440v1" target="_blank">Low-rank matrix and tensor approximations: advancing efficiency of machine-learning interatomic potentials</a></h3>
                    <p><strong>Authors:</strong> Igor Vorotnikov, Fedor Romashov, Nikita Rybin, Maxim Rakhuba, Ivan S. Novikov</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph</p>
                    <p><strong>Summary:</strong> Machine-learning interatomic potentials (MLIPs) have become a mainstay in computationally-guided materials science, surpassing traditional force fields due to their flexible functional form and superior accuracy in reproducing physical properties of materials. This flexibility is achieved through mathematically-rigorous basis sets that describe interatomic interactions within a local atomic environment. The number of parameters in these basis sets influences both the size of the training dataset required and the computational speed of the MLIP. Consequently, compressing MLIPs by reducing the number of parameters is a promising route to more efficient simulations. In this work, we use low-rank matrix and tensor factorizations under fixed-rank constraints to achieve this compression. In addition, we demonstrate that an algorithm with automatic rank augmentation helps to find a deeper local minimum of the fitted potential. The methodology is verified using the Moment Tensor Potential (MTP) model and benchmarked on multi-component systems: a Mo-Nb-Ta-W medium-entropy alloy, molten LiF-NaF-KF, and a glycine molecular crystal. The proposed approach achieves up to 50% compression without any loss of MTP accuracy and can be applied to compress other MLIPs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04439v1" target="_blank">ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory</a></h3>
                    <p><strong>Authors:</strong> Matthew Ho, Chen Si, Zhaoxiang Feng, Fangxu Yu, Zhijian Liu, Zhiting Hu, Lianhui Qin</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> While inference-time scaling enables LLMs to carry out increasingly long and capable reasoning traces, the patterns and insights uncovered during these traces are immediately discarded once the context window is reset for a new query. External memory is a natural way to persist these discoveries, and recent work has shown clear benefits for reasoning-intensive tasks. We see an opportunity to make such memories more broadly reusable and scalable by moving beyond instance-based memory entries (e.g. exact query/response pairs, or summaries tightly coupled with the original problem context) toward concept-level memory: reusable, modular abstractions distilled from solution traces and stored in natural language. For future queries, relevant concepts are selectively retrieved and integrated into the prompt, enabling test-time continual learning without weight updates. Our design introduces new strategies for abstracting takeaways from rollouts and retrieving entries for new queries, promoting reuse and allowing memory to expand with additional experiences. On the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over a strong no-memory baseline with performance continuing to scale with inference compute. We find abstract concepts to be the most consistent memory design, outscoring the baseline at all tested inference compute scales. Moreover, we confirm that dynamically updating memory during test-time outperforms an otherwise identical fixed memory setting with additional attempts, supporting the hypothesis that solving more problems and abstracting more patterns to memory enables further solutions in a form of self-improvement. Code available at https://github.com/matt-seb-ho/arc_memo.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04438v1" target="_blank">The Telephone Game: Evaluating Semantic Drift in Unified Models</a></h3>
                    <p><strong>Authors:</strong> Sabbir Mollah, Rohit Gupta, Sirnam Swetha, Qingyang Liu, Ahnaf Munir, Mubarak Shah</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL</p>
                    <p><strong>Summary:</strong> Employing a single, unified model (UM) for both visual understanding (image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened a new direction in Visual Language Model (VLM) research. While UMs can also support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus on the core cross-modal pair T2I and I2T, as consistency between understanding and generation is critical for downstream use. Existing evaluations consider these capabilities in isolation: FID and GenEval for T2I, and benchmarks such as MME, MMBench for I2T. These single-pass metrics do not reveal whether a model that understands a concept can also render it, nor whether meaning is preserved when cycling between image and text modalities. To address this, we introduce the Unified Consistency Framework for Unified Models (UCF-UM), a cyclic evaluation protocol that alternates I2T and T2I over multiple generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean Cumulative Drift (MCD), an embedding-based measure of overall semantic loss; (ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii) Multi-Generation GenEval (MGG), an object-level compliance score extending GenEval. To assess generalization beyond COCO, which is widely used in training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and evaluate on seven recent models. UCF-UM reveals substantial variation in cross-modal stability: some models like BAGEL maintain semantics over many alternations, whereas others like Vila-u drift quickly despite strong single-pass scores. Our results highlight cyclic consistency as a necessary complement to standard I2T and T2I evaluations, and provide practical metrics to consistently assess unified models cross-modal stability and strength of their shared representations. Code: https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04437v1" target="_blank">From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray Collimators via Hough Transform</a></h3>
                    <p><strong>Authors:</strong> Benjamin El-Zein, Dominik Eckert, Andreas Fieselmann, Christopher Syben, Ludwig Ritschl, Steffen Kappler, Sebastian Stober</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, physics.med-ph</p>
                    <p><strong>Summary:</strong> Collimation in X-ray imaging restricts exposure to the region-of-interest (ROI) and minimizes the radiation dose applied to the patient. The detection of collimator shadows is an essential image-based preprocessing step in digital radiography posing a challenge when edges get obscured by scattered X-ray radiation. Regardless, the prior knowledge that collimation forms polygonal-shaped shadows is evident. For this reason, we introduce a deep learning-based segmentation that is inherently constrained to its geometry. We achieve this by incorporating a differentiable Hough transform-based network to detect the collimation borders and enhance its capability to extract the information about the ROI center. During inference, we combine the information of both tasks to enable the generation of refined, line-constrained segmentation masks. We demonstrate robust reconstruction of collimated regions achieving median Hausdorff distances of 4.3-5.0mm on diverse test sets of real Xray images. While this application involves at most four shadow borders, our method is not fundamentally limited by a specific number of edges.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04436v1" target="_blank">Time, quantum entanglement, and particle decay</a></h3>
                    <p><strong>Authors:</strong> J. A. Aguilar-Saavedra</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-ex, quant-ph</p>
                    <p><strong>Summary:</strong> We investigate the role of time ordering in entanglement experiments involving unstable particles, focusing on $\mu^+ \mu^-$ pairs produced in a maximally-entangled spin state. We analyse the correlations between measurements performed by two experimenters, Alice (who measures $\mu^-$ spin) and Bob (who measures $\mu^+$ decay products). Remarkably, the observed correlations persist irrespective of whether Bobs muon decays before or after Alices spin measurement. We further discuss different interpretations of the same empirical results depending on the observers reference frame. The findings reinforce the viewpoint that the Copenhagen interpretation of measurement is a mathematical tool rather than a literal account of physical reality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04434v1" target="_blank">Durian: Dual Reference-guided Portrait Animation with Attribute Transfer</a></h3>
                    <p><strong>Authors:</strong> Hyunsoo Cha, Byungjun Kim, Hanbyul Joo</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We present Durian, the first method for generating portrait animation videos with facial attribute transfer from a given reference image to a target portrait in a zero-shot manner. To enable high-fidelity and spatially consistent attribute transfer across frames, we introduce dual reference networks that inject spatial features from both the portrait and attribute images into the denoising process of a diffusion model. We train the model using a self-reconstruction formulation, where two frames are sampled from the same portrait video: one is treated as the attribute reference and the other as the target portrait, and the remaining frames are reconstructed conditioned on these inputs and their corresponding masks. To support the transfer of attributes with varying spatial extent, we propose a mask expansion strategy using keypoint-conditioned image generation for training. In addition, we further augment the attribute and portrait images with spatial and appearance-level transformations to improve robustness to positional misalignment between them. These strategies allow the model to effectively generalize across diverse attributes and in-the-wild reference combinations, despite being trained without explicit triplet supervision. Durian achieves state-of-the-art performance on portrait animation with attribute transfer, and notably, its dual reference design enables multi-attribute composition in a single generation pass without additional training.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04432v1" target="_blank">Can Language Models Handle a Non-Gregorian Calendar?</a></h3>
                    <p><strong>Authors:</strong> Mutsumi Sasaki, Go Kamoda, Ryosuke Takahashi, Kosuke Sato, Kentaro Inui, Keisuke Sakaguchi, Benjamin Heinzerling</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Temporal reasoning and knowledge are essential capabilities for language models (LMs). While much prior work has analyzed and improved temporal reasoning in LMs, most studies have focused solely on the Gregorian calendar. However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew calendars, are in active use and reflect culturally grounded conceptions of time. If and how well current LMs can accurately handle such non-Gregorian calendars has not been evaluated so far. Here, we present a systematic evaluation of how well open-source LMs handle one such non-Gregorian system: the Japanese calendar. For our evaluation, we create datasets for four tasks that require both temporal knowledge and temporal reasoning. Evaluating a range of English-centric and Japanese-centric LMs, we find that some models can perform calendar conversions, but even Japanese-centric models struggle with Japanese-calendar arithmetic and with maintaining consistency across calendars. Our results highlight the importance of developing LMs that are better equipped for culture-specific calendar understanding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04426v1" target="_blank">Solving Zero-Sum Games with Fewer Matrix-Vector Products</a></h3>
                    <p><strong>Authors:</strong> Ishani Karmarkar, Liam OCarroll, Aaron Sidford</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.OC, cs.DS, cs.GT</p>
                    <p><strong>Summary:</strong> In this paper we consider the problem of computing an $\epsilon$-approximate Nash Equilibrium of a zero-sum game in a payoff matrix $A \in \mathbb{R}^{m \times n}$ with $O(1)$-bounded entries given access to a matrix-vector product oracle for $A$ and its transpose $A^\top$. We provide a deterministic algorithm that solves the problem using $\tilde{O}(\epsilon^{-8/9})$-oracle queries, where $\tilde{O}(\cdot)$ hides factors polylogarithmic in $m$, $n$, and $\epsilon^{-1}$. Our result improves upon the state-of-the-art query complexity of $\tilde{O}(\epsilon^{-1})$ established by [Nemirovski, 2004] and [Nesterov, 2005]. We obtain this result through a general framework that yields improved deterministic query complexities for solving a broader class of minimax optimization problems which includes computing a linear classifier (hard-margin support vector machine) as well as linear regression.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04425v1" target="_blank">Hidden simplicity in the scattering for neutron stars and black holes</a></h3>
                    <p><strong>Authors:</strong> Rafael Aoude, Andreas Helset</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> Heavy particle effective theory applied to spinning black holes provides a natural framework in which propagators linearize and numerators exponentiate. In this work, we exploit these two features to introduce Kerr generating functions, which describe the scattering of any probe on a Kerr black hole background to all loop orders. These generating functions can be used to perform the tensor reduction of multi-loop integrands simply by differentiation with respect to the spin. As a first application of the Kerr generating functions, we study a neutron star in a Kerr black hole background. We organize the integrand by the helicity configuration of the exchanged gravitons and provide compact all-loop-order results for several helicity sectors and a full four-loop $\mathcal{O}(G^5)$ result.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04422v1" target="_blank">Echo State Networks as State-Space Models: A Systems Perspective</a></h3>
                    <p><strong>Authors:</strong> Pradeep Singh, Balasubramanian Raman</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, 93C10, 68T07, 93C05, 93E11, 93B30, 93B05, 93B07, 62M10, I.2.6; I.5.1; I.6.5; I.6.4; G.3</p>
                    <p><strong>Summary:</strong> Echo State Networks (ESNs) are typically presented as efficient, readout-trained recurrent models, yet their dynamics and design are often guided by heuristics rather than first principles. We recast ESNs explicitly as state-space models (SSMs), providing a unified systems-theoretic account that links reservoir computing with classical identification and modern kernelized SSMs. First, we show that the echo-state property is an instance of input-to-state stability for a contractive nonlinear SSM and derive verifiable conditions in terms of leak, spectral scaling, and activation Lipschitz constants. Second, we develop two complementary mappings: (i) small-signal linearizations that yield locally valid LTI SSMs with interpretable poles and memory horizons; and (ii) lifted/Koopman random-feature expansions that render the ESN a linear SSM in an augmented state, enabling transfer-function and convolutional-kernel analyses. This perspective yields frequency-domain characterizations of memory spectra and clarifies when ESNs emulate structured SSM kernels. Third, we cast teacher forcing as state estimation and propose Kalman/EKF-assisted readout learning, together with EM for hyperparameters (leak, spectral radius, process/measurement noise) and a hybrid subspace procedure for spectral shaping under contraction constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04419v1" target="_blank">Towards a Unified View of Large Language Model Post-Training</a></h3>
                    <p><strong>Authors:</strong> Xingtai Lv, Yuxin Zuo, Youbang Sun, Hongyi Liu, Yuntian Wei, Zhekai Chen, Lixuan He, Xuekai Zhu, Kaiyan Zhang, Bingning Wang, Ning Ding, Bowen Zhou</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Two major sources of training data exist for post-training modern language models: online (model-generated rollouts) data, and offline (human or other-model demonstrations) data. These two types of data are typically used by approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT), respectively. In this paper, we show that these approaches are not in contradiction, but are instances of a single optimization process. We derive a Unified Policy Gradient Estimator, and present the calculations of a wide spectrum of post-training approaches as the gradient of a common objective under different data distribution assumptions and various bias-variance tradeoffs. The gradient estimator is constructed with four interchangeable parts: stabilization mask, reference policy denominator, advantage estimate, and likelihood gradient. Motivated by our theoretical findings, we propose Hybrid Post-Training (HPT), an algorithm that dynamically selects different training signals. HPT is designed to yield both effective exploitation of demonstration and stable exploration without sacrificing learned reasoning patterns. We provide extensive experiments and ablation studies to verify the effectiveness of our unified theoretical framework and HPT. Across six mathematical reasoning benchmarks and two out-of-distribution suites, HPT consistently surpasses strong baselines across models of varying scales and families.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04416v1" target="_blank">$^{171}$Yb Reference Data</a></h3>
                    <p><strong>Authors:</strong> Ronen M. Kroeze, Sofus Laguna Kristensen, Sebastian Pucher</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph, cond-mat.quant-gas, quant-ph</p>
                    <p><strong>Summary:</strong> Ytterbium-171 is a versatile atomic species often used in quantum optics, precision metrology, and quantum computing. Consolidated atomic data is essential for the planning, execution, and evaluation of experiments. In this reference, we present physical and optical properties of neutral $^{171}$Yb relevant to these applications. We emphasize experimental results and supplement these with theoretical estimates. We present equations to convert values and derive important parameters. Tabulated results include key parameters for commonly used transitions in $^{171}$Yb (${}^1\mathrm{S}_0\rightarrow{}^1\mathrm{P}_1$, ${}^1\mathrm{S}_0\rightarrow{}^3\mathrm{P}_{0,1,2}\,$, ${}^3\mathrm{P}_{0,2}\rightarrow{}^3\mathrm{S}_1$, and ${}^3\mathrm{P}_0\rightarrow{}^3\mathrm{D}_1$). This dataset serves as an up-to-date reference for studies involving fermionic $^{171}$Yb.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04412v1" target="_blank">Relative Localization of UAV Swarms in GNSS-Denied Conditions</a></h3>
                    <p><strong>Authors:</strong> Guangyu Lei, Yuqi Ping, Tianhao Liang, Huahao Ding, Tingting Zhang</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> eess.SP, cs.SY, eess.SY, Primary 93C85, Secondary 68T42, 94A12, 90C90, H.4.3</p>
                    <p><strong>Summary:</strong> Relative localization of unmanned aerial vehicle (UAV) swarms in global navigation satellite system (GNSS) denied environments is essential for emergency rescue and battlefield reconnaissance. Existing methods suffer from significant localization errors among UAVs due to packet loss and high computational complexity in large swarms. This paper proposes a clustering-based framework where the UAVs simultaneously use communication signals for channel estimation and ranging. Firstly, the spectral clustering is utilized to divide the UAV swarm into different sub-clusters, where matrix completion and multidimensional scaling yield high-precision relative coordinates. Subsequently, a global map is created by the inter-cluster anchor fusion. A case study of UAV integrated communication and sensing (ISAC) system is presented, where the Orthogonal Time Frequency Space (OTFS) is adopted for ranging and communication. Experimental results show that the proposed method reduces localization errors in large swarms and loss of range information. It also explores the impact of signal parameters on communication and localization, highlighting the interplay between communication and localization performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04410v1" target="_blank">Infinite temperature at zero energy</a></h3>
                    <p><strong>Authors:</strong> Matteo Ippoliti, David M. Long</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We construct a family of static, geometrically local Hamiltonians that inherit eigenstate properties of periodically-driven (Floquet) systems. Our construction is a variation of the Feynman-Kitaev clock -- a well-known mapping between quantum circuits and local Hamiltonians -- where the clock register is given periodic boundary conditions. Assuming the eigenstate thermalization hypothesis (ETH) holds for the input circuit, our construction yields Hamiltonians whose eigenstates have properties characteristic of infinite temperature, like volume-law entanglement entropy, across the whole spectrum -- including the ground state. We then construct a family of exactly solvable Floquet quantum circuits whose eigenstates are shown to obey the ETH at infinite temperature. Combining the two constructions yields a new family of local Hamiltonians with provably volume-law-entangled ground states, and the first such construction where the volume law holds for all contiguous subsystems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04409v1" target="_blank">An Arbitrary-Order Moving-Mesh Finite Element Algorithm for One-Dimensional Implicit Moving Boundary Problems</a></h3>
                    <p><strong>Authors:</strong> Matthew E Hubbard, Thomas J Radley</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, 35K61, 35R37, 65M60, G.1.8</p>
                    <p><strong>Summary:</strong> We present a one-dimensional high-order moving-mesh finite element method for moving boundary problems where the boundary velocity depends implicitly on the solution in the interior of the domain. The method employs a conservative arbitrary Lagrangian-Eulerian approach to predict the evolution of the approximate solution. It retains the order of accuracy of the underlying fixed-mesh method by (i) computing the boundary velocities using a high-order approximation to a distributed local conservation principle which generates a Lagrangian `flow velocity and (ii) assuming a continuous piecewise linear variation of the mesh velocity field in the interior of the computational domain. Within each time-step the algorithm consists of two stages: the computation of a velocity field with which to move both the domain boundary and the internal mesh, and the approximation of the solution to the PDE on the updated mesh. Both internal and boundary velocities are generated within the same framework, though it would be simple to replace the internal mesh velocity field by applying a more traditional mesh movement strategy (for example, one which seeks to equidistribute an error indicator at each time-step): the high-order accuracy should be retained as long the discrete velocity which is used in the solution update is assumed to vary linearly within mesh elements. The proposed method is explicit in time, requires only the inversion of linear systems of equations within each time-step, and is implemented fully in the physical domain, so no mapping to a reference domain is employed. It attains arbitrary-order accuracy in both space and time without the need to satisfy a discrete geometric conservation law.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04408v1" target="_blank">Chiral Graviton Theory of Fractional Quantum Hall States</a></h3>
                    <p><strong>Authors:</strong> Yi-Hsien Du</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mes-hall, hep-th</p>
                    <p><strong>Summary:</strong> Recent polarized Raman scattering experiments indicate that fractional quantum Hall systems host a chiral spin-2 neutral collective mode, the long-wavelength limit of the magnetoroton, which behaves as a condensed-matter graviton. We present a nonlinear, gauge-invariant effective theory by gauging area-preserving diffeomorphisms (APDs) with a unimodular spatial metric as the gauge field. A Stueckelberg construction introduces an APD-invariant local potential that aligns the dynamical metric with a reference geometry, opening a tunable gap while preserving gauge redundancy. Together with a geometric Maxwell kinetic sector and the Wen-Zee and gravitational Chern-Simons terms, the theory yields a gapped chiral spin-2 excitation consistent with universal long-wavelength constraints. The tunable gap emerges naturally from symmetry and provides a route to an isotropic-nematic quantum critical point where the spin-2 mode softens. We further establish a linear dictionary to quadrupolar deformations in composite Fermi liquid bosonization, and outline applications to fractional Chern insulators as well as higher-dimensional generalizations. Finally, the approach can be extended to non-Abelian fractional quantum Hall states, capturing both spin-2 and spin-3/2 neutral modes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04406v1" target="_blank">Few-step Flow for 3D Generation via Marginal-Data Transport Distillation</a></h3>
                    <p><strong>Authors:</strong> Zanwei Zhou, Taoran Yi, Jiemin Fang, Chen Yang, Lingxi Xie, Xinggang Wang, Wei Shen, Qi Tian</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04404v1" target="_blank">No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening</a></h3>
                    <p><strong>Authors:</strong> Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, Aylin Caliskan</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.CL, cs.HC, K.4.2</p>
                    <p><strong>Summary:</strong> In this study, we conduct a resume-screening experiment (N=528) where people collaborate with simulated AI models exhibiting race-based preferences (bias) to evaluate candidates for 16 high and low status occupations. Simulated AI bias approximates factual and counterfactual estimates of racial bias in real-world AI systems. We investigate peoples preferences for White, Black, Hispanic, and Asian candidates (represented through names and affinity groups on quality-controlled resumes) across 1,526 scenarios and measure their unconscious associations between race and status using implicit association tests (IATs), which predict discriminatory hiring decisions but have not been investigated in human-AI collaboration. When making decisions without AI or with AI that exhibits no race-based preferences, people select all candidates at equal rates. However, when interacting with AI favoring a particular group, people also favor those candidates up to 90% of the time, indicating a significant behavioral shift. The likelihood of selecting candidates whose identities do not align with common race-status stereotypes can increase by 13% if people complete an IAT before conducting resume screening. Finally, even if people think AI recommendations are low quality or not important, their decisions are still vulnerable to AI bias under certain circumstances. This work has implications for peoples autonomy in AI-HITL scenarios, AI and work, design and evaluation of AI hiring systems, and strategies for mitigating bias in collaborative decision-making tasks. In particular, organizational and regulatory policy should acknowledge the complex nature of AI-HITL decision making when implementing these systems, educating people who use them, and determining which are subject to oversight.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04403v1" target="_blank">Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios</a></h3>
                    <p><strong>Authors:</strong> Jingen Qu, Lijun Li, Bo Zhang, Yichen Yan, Jing Shao</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.CR</p>
                    <p><strong>Summary:</strong> Multimodal large language models (MLLMs) are rapidly evolving, presenting increasingly complex safety challenges. However, current dataset construction methods, which are risk-oriented, fail to cover the growing complexity of real-world multimodal safety scenarios (RMS). And due to the lack of a unified evaluation metric, their overall effectiveness remains unproven. This paper introduces a novel image-oriented self-adaptive dataset construction method for RMS, which starts with images and end constructing paired text and guidance responses. Using the image-oriented method, we automatically generate an RMS dataset comprising 35k image-text pairs with guidance responses. Additionally, we introduce a standardized safety dataset evaluation metric: fine-tuning a safety judge model and evaluating its capabilities on other safety datasets.Extensive experiments on various tasks demonstrate the effectiveness of the proposed image-oriented pipeline. The results confirm the scalability and effectiveness of the image-oriented approach, offering a new perspective for the construction of real-world multimodal safety datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04402v1" target="_blank">Learning neural representations for X-ray ptychography reconstruction with unknown probes</a></h3>
                    <p><strong>Authors:</strong> Tingyou Li, Zixin Xu, Zirui Gao, Hanfei Yan, Xiaojing Huang, Jizhou Li</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> X-ray ptychography provides exceptional nanoscale resolution and is widely applied in materials science, biology, and nanotechnology. However, its full potential is constrained by the critical challenge of accurately reconstructing images when the illuminating probe is unknown. Conventional iterative methods and deep learning approaches are often suboptimal, particularly under the low-signal conditions inherent to low-dose and high-speed experiments. These limitations compromise reconstruction fidelity and restrict the broader adoption of the technique. In this work, we introduce the Ptychographic Implicit Neural Representation (PtyINR), a self-supervised framework that simultaneously addresses the object and probe recovery problem. By parameterizing both as continuous neural representations, PtyINR performs end-to-end reconstruction directly from raw diffraction patterns without requiring any pre-characterization of the probe. Extensive evaluations demonstrate that PtyINR achieves superior reconstruction quality on both simulated and experimental data, with remarkable robustness under challenging low-signal conditions. Furthermore, PtyINR offers a generalizable, physics-informed framework for addressing probe-dependent inverse problems, making it applicable to a wide range of computational microscopy problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04401v1" target="_blank">Monte Carlo simulation of random circuit sampling in quantum computing</a></h3>
                    <p><strong>Authors:</strong> Andreas Raab</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph, math-ph, math.MP, I.6.3; J.2</p>
                    <p><strong>Summary:</strong> We develop Monte Carlo methods for sampling random states and corresponding bit strings in qubit systems. To this end, we derive exact probability density functions that yield the Porter-Thomas distribution in the limit of large systems. We apply these functions in importance sampling algorithms and demonstrate efficiency for qubit systems with 70, 105, 1000, and more than one million ($2^{20}$) qubits. In particular, we simulate the output of recent quantum computations without noise on a PC with minimal computational cost. I would therefore argue that random circuit sampling can be conveniently performed on classical computers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04399v1" target="_blank">Leveraging Equivariances and Symmetries in the Control Barrier Function Synthesis</a></h3>
                    <p><strong>Authors:</strong> Adrian Wiltz, Dimos V. Dimarogonas</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.RO, cs.SY</p>
                    <p><strong>Summary:</strong> The synthesis of Control Barrier Functions (CBFs) often involves demanding computations or a meticulous construction. However, structural properties of the system dynamics and constraints have the potential to mitigate these challenges. In this paper, we explore how equivariances in the dynamics, loosely speaking a form of symmetry, can be leveraged in the CBF synthesis. Although CBFs are generally not inherently symmetric, we show how equivariances in the dynamics and symmetries in the constraints induce symmetries in CBFs derived through reachability analysis. This insight allows us to infer their CBF values across the entire domain from their values on a subset, leading to significant computational savings. Interestingly, equivariances can be even leveraged to the CBF synthesis for non-symmetric constraints. Specifically, we show how a partially known CBF can be leveraged together with equivariances to construct a CBF for various new constraints. Throughout the paper, we provide examples illustrating the theoretical findings. Furthermore, a numerical study investigates the computational gains from invoking equivariances into the CBF synthesis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04397v1" target="_blank">Quantum carrollian bosonic strings</a></h3>
                    <p><strong>Authors:</strong> JosÃ© Figueroa-OFarrill, Emil Have, Niels A. Obers</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-th, math.RT</p>
                    <p><strong>Summary:</strong> We study a recently discovered carrollian bosonic string, described classically by a sigma model where both the worldsheet and the target spacetime are carrollian. After fixing the carrollian analogue of the conformal gauge, we determine the Lie algebra of residual gauge symmetries and show it is isomorphic to the three-dimensional extended BMS algebra. We quantise the sigma model \`a la BRST and determine the spectrum of the corresponding string theory by computing the BRST cohomology. In contrast with the usual bosonic string, the spectrum of the carrollian string is finite-dimensional. The cohomology displays Poincar\e duality and can be interpreted, for a given momentum, as inducing representations for unitary irreducible representations of the 26-dimensional Carroll group. Furthermore we interpret (most of) the cohomology as deformations of the spacetime carrollian structure augmented by the Kalb--Ramond field to which the carrollian string couples.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04396v1" target="_blank">Revealing the origin of supermassive black holes with Taiji-TianQin network</a></h3>
                    <p><strong>Authors:</strong> Ping Shen, Wen-Biao Han, Wen-Xin Zhong</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> The origin of supermassive black holes (SMBHs) is a pivotal problem in modern cosmology. This work explores the potential of the Taiji-TianQin space-borne gravitational-wave (GW) detector network to identify the formation channels of massive black hole binaries (MBHBs) at high redshifts ($z \gtrsim 10$). The network substantially improves detection capability, boosting the signal-to-noise ratio by a factor of 2.2-3.0 (1.06-1.14) relative to TianQin (Taiji) alone. It increases the detection rate of MBHBs formed from light seeds (LS) by more than 2.2 times and achieves over 96\% detection efficiency for those originating from heavy seeds (HS). Furthermore, the network enables component mass estimation with relative uncertainties as low as $\sim 10^{-4}$ at the $2\sigma$ level. These improvements facilitate the assembly of a well-constrained population sample, allowing robust measurement of the fractional contributions from different formation pathways. The network achieves high precision in distinguishing between LS and HS origins (7.4\% relative uncertainty at $2\sigma$) and offers moderate discrimination between delay and no-delay channels in HS-origin binaries (24\%). However, classification remains challenging for delay versus no-delay scenarios in LS-origin systems (58\%) due to significant population overlap. In conclusion, the Taiji-TianQin network will serve as a powerful tool for unveiling the origins of SMBHs through GW population studies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04394v1" target="_blank">Transition Models: Rethinking the Generative Learning Objective</a></h3>
                    <p><strong>Authors:</strong> Zidong Wang, Yiyuan Zhang, Xiaoyu Yue, Xiangyu Yue, Yangguang Li, Wanli Ouyang, Lei Bai</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> A fundamental dilemma in generative modeling persists: iterative diffusion models achieve outstanding fidelity, but at a significant computational cost, while efficient few-step alternatives are constrained by a hard quality ceiling. This conflict between generation steps and output quality arises from restrictive training objectives that focus exclusively on either infinitesimal dynamics (PF-ODEs) or direct endpoint prediction. We address this challenge by introducing an exact, continuous-time dynamics equation that analytically defines state transitions across any finite time interval. This leads to a novel generative paradigm, Transition Models (TiM), which adapt to arbitrary-step transitions, seamlessly traversing the generative trajectory from single leaps to fine-grained refinement with more steps. Despite having only 865M parameters, TiM achieves state-of-the-art performance, surpassing leading models such as SD3.5 (8B parameters) and FLUX.1 (12B parameters) across all evaluated step counts. Importantly, unlike previous few-step generators, TiM demonstrates monotonic quality improvement as the sampling budget increases. Additionally, when employing our native-resolution strategy, TiM delivers exceptional fidelity at resolutions up to 4096x4096.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04393v1" target="_blank">Contextualized Token Discrimination for Speech Search Query Correction</a></h3>
                    <p><strong>Authors:</strong> Junyu Lu, Di Jiang, Mengze Hong, Victor Junqiu Wei, Qintian Guo, Zhiyang Su</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CL</p>
                    <p><strong>Summary:</strong> Query spelling correction is an important function of modern search engines since it effectively helps users express their intentions clearly. With the growing popularity of speech search driven by Automated Speech Recognition (ASR) systems, this paper introduces a novel method named Contextualized Token Discrimination (CTD) to conduct effective speech query correction. In CTD, we first employ BERT to generate token-level contextualized representations and then construct a composition layer to enhance semantic information. Finally, we produce the correct query according to the aggregated token representation, correcting the incorrect tokens by comparing the original token representations and the contextualized representations. Extensive experiments demonstrate the superior performance of our proposed method across all metrics, and we further present a new benchmark dataset with erroneous ASR transcriptions to offer comprehensive evaluations for audio query correction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04391v1" target="_blank">Unilateral Criticality and Phase Transition in the Cavity-Ising Model</a></h3>
                    <p><strong>Authors:</strong> Zeyu Rao, Xiaoshui Lin, Xiwang Luo, Guangcan Guo, Han Pu, Ming Gong</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> Superradiant phase transitions from cavity light-matter coupling have been widely explored across platforms. Here, we report a unilateral critical endpoint (UCEP) and a tricritical point (TCP) in the phase diagram of the cavity-coupled transverse Ising model with $\mathbb{Z}_2$ symmetry. At zero temperature, we demonstrate that this model hosts three phases separated by two second-order and one first-order transitions. These lines intersect at a TCP and a UCEP, the latter not captured by existing phase-transition paradigms. The UCEP displays one-sided criticality: approaching the point from one side, the system behaves as a second-order transition, while from the other side it is first-order. Correspondingly, two order parameters, respectively, undergo the first- and the second-order phase transitions at the same point. We construct a minimal description of UCEP with the density of the free energy $f = c_{1}(\tilde{\alpha}^{2}+c_{2})+(\tilde{\alpha}^{2}+c_{2})^{2}\ln{\vert\tilde{\alpha}^{2}+c_{2}\vert}$, with the UCEP at $(c_{1},c_{2})=(1/e,0)$ and $\tilde{\alpha}$ being the order parameter. We further map the finite-temperature phase diagram and perform a symmetry analysis. By unifying first- and second-order signatures in a single, direction-dependent endpoint, the UCEP introduces a qualitatively new class of phase transition and may have applications in fields such as quantum measurement and quantum sensing. This work also provides an intriguing platform for exploring novel critical phenomena in cavity-coupled many-body systems with or without dissipation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04389v1" target="_blank">Constructing a Photonic Implementation of Quantum Key Distribution</a></h3>
                    <p><strong>Authors:</strong> Alec L. Riso, Karthik Thyagarajan, Connor Whiting, Katherine Jimenez, Mark Hannum</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph, physics.ed-ph, physics.optics</p>
                    <p><strong>Summary:</strong> Quantum Key Distribution (QKD) stands as a revolutionary approach to secure communication, using the principles of quantum mechanics to establish unbreakable channels. Unlike traditional cryptography, which relies on the computational difficulty of mathematical problems, QKD utilizes the inherent properties of quantum states to achieve information-theoretic security. This means that the security of the key exchange is guaranteed by the laws of physics, making it theoretically unbreakable even by an adversary with unlimited computational power. Currently, one of the most viable ways to implement QKD for communication is via photonics, namely, using phase-preserving long-distance optical fibers. The objective of this project is to implement photonic QKD in a laboratory setting. This will help demonstrate the protocols robustness and provide a feasible implementation for educational demonstrations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04386v1" target="_blank">Randomized biorthogonalization through a two-sided Gram-Schmidt process</a></h3>
                    <p><strong>Authors:</strong> Laura Grigori, Lorenzo Piccinini, Igor Simunec</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, 65F25 (Primary) 65F15 (Secondary)</p>
                    <p><strong>Summary:</strong> We propose and analyze a randomized two-sided Gram-Schmidt process for the biorthogonalization of two given matrices $X, Y \in\mathbb{R}^{n\times m}$. The algorithm aims to find two matrices $Q, P \in\mathbb{R}^{n\times m}$ such that ${\rm range}(X) = {\rm range}(Q)$, ${\rm range}(Y) = {\rm range}(P)$ and $(\Omega Q)^T \Omega P = I$, where $\Omega \in\mathbb{R}^{s \times n}$ is a sketching matrix satisfying an oblivious subspace $\varepsilon$-embedding property; in other words, the biorthogonality condition on the columns of $Q$ and $P$ is replaced by an equivalent condition on their sketches. This randomized approach is computationally less expensive than the classical two-sided Gram-Schmidt process, has better numerical stability, and the condition number of the computed bases $Q, P$ is often smaller than in the deterministic case. Several different implementations of the randomized algorithm are analyzed and compared numerically. The randomized two-sided Gram-Schmidt process is applied to the nonsymmetric Lancozs algorithm for the approximation of eigenvalues and both left and right eigenvectors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04385v1" target="_blank">Numerical investigation of the interior geometry of semiclassical evaporating spherical charged black holes</a></h3>
                    <p><strong>Authors:</strong> Gil Arad</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We developed a numerical code which evolves the semiclassical Einsteins equation (with the quantum stress-energy contribution added as a source term) for the spherically symmetric metric inside an evaporating semiclassical charged black hole. An analytical approximation for the evolving semiclassical metric was recently developed by Ori and Zilberman (and will be briefly overviewed here). We seek to numerically check the validity of this analytical approximation. The Einstein equations in this case are partial differential equations for the two unknown metric functions which fully describe the spherically symmetric metric. We begin our numerical simulation close to the event horizon with regular initial data specified by a variant of the charged Vaidya metric. We then evolve the metric functions deep into the neighborhood of the inner horizon. We explore the results of running this numerical code in several representative cases. Our numerical simulations confirm the validity of the above mentioned analytical approximation in all these cases.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04384v1" target="_blank">Prominence: A discriminator of gravitational wave signals</a></h3>
                    <p><strong>Authors:</strong> JoÃ£o GonÃ§alves, Danny Marfatia, AntÃ³nio P. Morais</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-ph, gr-qc</p>
                    <p><strong>Summary:</strong> The concept of prominence is familiar to signal engineers, topographers and mountaineers. We introduce Prominence $\mathcal P$ as a discriminator of gravitational wave (GW) signals. We treat black hole and neutron star binaries as astrophysical background sources, and show how $\mathcal P$ can be used to distinguish between GW spectra produced by first-order phase transitions, domain walls and cosmic strings, and combinations thereof. Prominence can also be used to discriminate between these and off-piste sources of GWs. The uncertainty in the measured energy density in GWs at Pulsar Timing Arrays needs to be smaller than $\sim 4\%$ for $\mathcal{P}$ to achieve discrimination at 3$\sigma$. LISA and ET data are expected to have sufficiently small uncertainties that Prominence can play a central role in their analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04383v1" target="_blank">On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs</a></h3>
                    <p><strong>Authors:</strong> Serafino Cicerone, Alessia Di Fonso, Gabriele Di Stefano, Alfredo Navarra</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> The OBLOT model has been extensively studied in theoretical swarm robotics. It assumes weak capabilities for the involved mobile robots, such as they are anonymous, disoriented, no memory of past events (oblivious), and silent. Their only means of (implicit) communication is transferred to their positioning, i.e., stigmergic information. These limited capabilities make the design of distributed algorithms a challenging task. Over the last two decades, numerous research papers have addressed the question of which tasks can be accomplished within this model. Nevertheless, as it usually happens in distributed computing, also in OBLOT the computational power available to the robots is neglected as the main cost measures for the designed algorithms refer to the number of movements or the number of rounds required. In this paper, we prove that for synchronous robots moving on finite graphs, the unlimited computational power (other than finite time) has a significant impact. In fact, by exploiting it, we provide a definitive resolution algorithm that applies to a wide class of problems while guaranteeing the minimum number of moves and rounds.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04379v1" target="_blank">SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer</a></h3>
                    <p><strong>Authors:</strong> Jimin Xu, Bosheng Qin, Tao Jin, Zhou Zhao, Zhenhui Ye, Jun Yu, Fei Wu</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advancements in neural representations, such as Neural Radiance Fields and 3D Gaussian Splatting, have increased interest in applying style transfer to 3D scenes. While existing methods can transfer style patterns onto 3D-consistent neural representations, they struggle to effectively extract and transfer high-level style semantics from the reference style image. Additionally, the stylized results often lack structural clarity and separation, making it difficult to distinguish between different instances or objects within the 3D scene. To address these limitations, we propose a novel 3D style transfer pipeline that effectively integrates prior knowledge from pretrained 2D diffusion models. Our pipeline consists of two key stages: First, we leverage diffusion priors to generate stylized renderings of key viewpoints. Then, we transfer the stylized key views onto the 3D representation. This process incorporates two innovative designs. The first is cross-view style alignment, which inserts cross-view attention into the last upsampling block of the UNet, allowing feature interactions across multiple key views. This ensures that the diffusion model generates stylized key views that maintain both style fidelity and instance-level consistency. The second is instance-level style transfer, which effectively leverages instance-level consistency across stylized key views and transfers it onto the 3D representation. This results in a more structured, visually coherent, and artistically enriched stylization. Extensive qualitative and quantitative experiments demonstrate that our 3D style transfer pipeline significantly outperforms state-of-the-art methods across a wide range of scenes, from forward-facing to challenging 360-degree environments. Visit our project page https://jm-xu.github.io/SSGaussian for immersive visualization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04378v1" target="_blank">Aesthetic Image Captioning with Saliency Enhanced MLLMs</a></h3>
                    <p><strong>Authors:</strong> Yilin Tao, Jiashui Huang, Huaze Xu, Ling Shao</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Aesthetic Image Captioning (AIC) aims to generate textual descriptions of image aesthetics, becoming a key research direction in the field of computational aesthetics. In recent years, pretrained Multimodal Large Language Models (MLLMs) have advanced rapidly, leading to a significant increase in image aesthetics research that integrates both visual and textual modalities. However, most existing studies on image aesthetics primarily focus on predicting aesthetic ratings and have shown limited application in AIC. Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods without specifically adapting MLLMs to focus on target aesthetic content. To address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal Large Language Model (ASE-MLLM), an end-to-end framework that explicitly incorporates aesthetic saliency into MLLMs. Within this framework, we introduce the Image Aesthetic Saliency Module (IASM), which efficiently and effectively extracts aesthetic saliency features from images. Additionally, we design IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency features with original image features via a cross-attention mechanism. To the best of our knowledge, ASE-MLLM is the first framework to integrate image aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments demonstrated that our approach significantly outperformed traditional methods and generic MLLMs on current mainstream AIC benchmarks, achieving state-of-the-art (SOTA) performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04376v1" target="_blank">AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search</a></h3>
                    <p><strong>Authors:</strong> Hao Ju, Hu Zhang, Zhedong Zheng</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With growing public safety demands, text-based person anomaly search has emerged as a critical task, aiming to retrieve individuals with abnormal behaviors via natural language descriptions. Unlike conventional person search, this task presents two unique challenges: (1) fine-grained cross-modal alignment between textual anomalies and visual behaviors, and (2) anomaly recognition under sparse real-world samples. While Large Multi-modal Models (LMMs) excel in multi-modal understanding, their potential for fine-grained anomaly retrieval remains underexplored, hindered by: (1) a domain gap between generative knowledge and discriminative retrieval, and (2) the absence of efficient adaptation strategies for deployment. In this work, we propose AnomalyLMM, the first framework that harnesses LMMs for text-based person anomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline integrating LMMs to bridge generative world knowledge with retrieval-centric anomaly detection; (2) A training-free adaptation cookbook featuring masked cross-modal prompting, behavioral saliency prediction, and knowledge-aware re-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study to explore LMMs for this task, we conduct a rigorous evaluation on the PAB dataset, the only publicly available benchmark for text-based person anomaly search, with its curated real-world anomalies covering diverse scenarios (e.g., falling, collision, and being hit). Experiments show the effectiveness of the proposed method, surpassing the competitive baseline by +0.96% Recall@1 accuracy. Notably, our method reveals interpretable alignment between textual anomalies and visual behaviors, validated via qualitative analysis. Our code and models will be released for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04373v1" target="_blank">Measuring Bias or Measuring the Task: Understanding the Brittle Nature of LLM Gender Biases</a></h3>
                    <p><strong>Authors:</strong> Bufan Gao, Elisa Kreiss</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> As LLMs are increasingly applied in socially impactful settings, concerns about gender bias have prompted growing efforts both to measure and mitigate such bias. These efforts often rely on evaluation tasks that differ from natural language distributions, as they typically involve carefully constructed task prompts that overtly or covertly signal the presence of gender bias-related content. In this paper, we examine how signaling the evaluative purpose of a task impacts measured gender bias in LLMs. Concretely, we test models under prompt conditions that (1) make the testing context salient, and (2) make gender-focused content salient. We then assess prompt sensitivity across four task formats with both token-probability and discrete-choice metrics. We find that even minor prompt changes can substantially alter bias outcomes, sometimes reversing their direction entirely. Discrete-choice metrics further tend to amplify bias relative to probabilistic measures. These findings do not only highlight the brittleness of LLM gender bias evaluations but open a new puzzle for the NLP benchmarking and development community: To what extent can well-controlled testing designs trigger LLM ``testing mode performance, and what does this mean for the ecological validity of future benchmarks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04370v1" target="_blank">Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage</a></h3>
                    <p><strong>Authors:</strong> Dor Cohen, Inga Efrosman, Yehudit Aperstein, Alexander Apartsin</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> First responders widely adopt body-worn cameras to document incident scenes and support post-event analysis. However, reviewing lengthy video footage is impractical in time-critical situations. Effective situational awareness demands a concise visual summary that can be quickly interpreted. This work presents a computer vision pipeline that transforms body-camera footage into informative panoramic images summarizing the incident scene. Our method leverages monocular Simultaneous Localization and Mapping (SLAM) to estimate camera trajectories and reconstruct the spatial layout of the environment. Key viewpoints are identified by clustering camera poses along the trajectory, and representative frames from each cluster are selected. These frames are fused into spatially coherent panoramic images using multi-frame stitching techniques. The resulting summaries enable rapid understanding of complex environments and facilitate efficient decision-making and incident review.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04365v1" target="_blank">Nonrelativistic meson masses from the Curci-Ferrari model</a></h3>
                    <p><strong>Authors:</strong> Anaclara Alvez, Nahuel Barrios, Florencia BenÃ­tez, Marcela PelÃ¡ez</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-th</p>
                    <p><strong>Summary:</strong> We study the mass spectrum of nonrelativistic mesons composed of charm and bottom quarks within the framework of the Curci-Ferrari model in the Landau gauge, focusing on the influence of the gluon mass on our results. We derive the Hamiltonian from the scattering amplitude of a single massive gluon exchange. By incorporating a confining Cornell potential we solve the Schr\odinger equation for the dominant terms of the Hamiltonian, which include the kinetic energy and a Yukawa-type potential. Corrections to the energy are then introduced perturbatively. By studying the parameter space of the model we fit the experimental mass spectrum of charmonium, bottomonium and charm-bottom mesons. From the five parameters of our approach, we allow the gluon mass and the gauge coupling to run with the energy scale according to the ultraviolet one-loop renormalization flows, computed in [1]. Our results show very good agreement with the data, suggesting that a nonvanishing gluon mass provides a better description of the spectrum of heavy mesons than the massless case.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04359v1" target="_blank">Assessing time-dependent temperature profile predictions using reduced transport models for high performing NSTX plasmas</a></h3>
                    <p><strong>Authors:</strong> J. B. Lestz, G. Avdeeva, T. F. Neiser, M. V. Gorelenkova, F. D. Halpern, S. M. Kaye, J. McClenaghan, A. Y. Pankin, K. E. Thome</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.plasm-ph</p>
                    <p><strong>Summary:</strong> Time-dependent, predictive simulations were performed with the 1.5D tokamak integrated modeling code TRANSP on a large set of well-analyzed, high performing discharges from the National Spherical Torus Experiment (NSTX) in order to evaluate how well modern reduced transport models can reproduce experimentally observed temperature profiles in spherical tokamaks. Overall, it is found that simulations using the Multi-Mode Model (MMM) more consistently agree with the NSTX observations than those using the Trapped Gyro-Landau Fluid (TGLF) model, despite TGLF requiring orders of magnitude greater computational cost. When considering all examined discharges, MMM has median overpredictions of electron temperature ($T_e$) and ion temperature ($T_i$) profiles of 28% and 27%, respectively, relative to the experiment. TGLF overpredicts $T_e$ by 46%, with much larger variance than MMM, and underpredicts $T_i$ by 25%. As $\beta$ is increased across NSTX discharges, TGLF predicts lower $T_e$ and significant flattening of the $T_i$ profile, conflicting with NSTX observations. When using an electrostatic version of TGLF, both $T_e$ and $T_i$ are substantially overpredicted, underscoring the importance of electromagnetic turbulence in the high $\beta$ spherical tokamak regime. Additionally, calculations with neural net surrogate models for TGLF were performed outside of TRANSP with a time slice flux matching transport solver, finding better agreement with experiment than the TRANSP simulations, highlighting the impact of different transport solvers and simulation techniques. Altogether, the reasonable agreement with experiment of temperature profiles predicted by MMM motivates a more detailed examination of the sensitivities of the TRANSP simulations with MMM to different NSTX plasma regimes in a companion paper, in preparation for self-consistent, time-dependent predictive modeling of NSTX-U scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04357v1" target="_blank">PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation</a></h3>
                    <p><strong>Authors:</strong> Jiajun He, Naoki Sawada, Koichi Miyazaki, Tomoki Toda</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG, cs.SD</p>
                    <p><strong>Summary:</strong> Automatic speech recognition (ASR) systems struggle with domain-specific named entities, especially homophones. Contextual ASR improves recognition but often fails to capture fine-grained phoneme variations due to limited entity diversity. Moreover, prior methods treat entities as independent tokens, leading to incomplete multi-token biasing. To address these issues, we propose Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation (PARCO), which integrates phoneme-aware encoding, contrastive entity disambiguation, entity-level supervision, and hierarchical entity filtering. These components enhance phonetic discrimination, ensure complete entity retrieval, and reduce false positives under uncertainty. Experiments show that PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO also demonstrates robust gains on out-of-domain datasets like THCHS-30 and LibriSpeech.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04354v1" target="_blank">On the Homogeneous Space of a Pair of Associative Composition Algebras</a></h3>
                    <p><strong>Authors:</strong> Mahir Bilen, Ana Casimiro, Ferruh Ã–zbudak</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.AG, 17A75, 57T20, 55N91, 55N15</p>
                    <p><strong>Summary:</strong> The relationship between associative composition algebras of dimensions 2 and 4 within the context of homogeneous spaces, with a particular focus on Hamiltonian quaternions, is explored. In the special case of Hamiltonian quaternions, the equivariant cohomology rings of the homogeneous spaces are computed to gain a deeper understanding of their topological structure. In the general case, equivariant K-theory is utilized to examine the categories of vector bundles on these spaces. Taking this one step further, the Grothendieck ring of the category of locally free modules on the variety of singular matrices of size $n$ with entries from an associative composition algebra is determined. As a natural extension of these ideas, to define and study determinantal varieties of matrices with entries from a composition algebra, a notion of rank with respect to the base composition algebra is introduced, and criteria are established for the spanning set of a finite set of matrices with entries from the associative composition algebra to contain elements of certain ranks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04353v1" target="_blank">Statistics of multi-electron states and $J$-levels in atomic configurations</a></h3>
                    <p><strong>Authors:</strong> Jean-Christophe Pain, Xavier Blanc</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph</p>
                    <p><strong>Summary:</strong> The number and nature of atomic configurations are cornerstones of atomic spectroscopy, especially for the calculation of hot-plasma radiative properties. The knowledge of the distributions of magnetic quantum number $M$ and angular momentum $J$ for $N$ identical fermions in a subshell with half-integer spin $j$ is a prerequisite to the determination of the structure of such configurations. The problem is rather complicated, since the possible occurrence of a specific values of $J$ is governed by the Pauli exclusion principle. Several methods, such as generating functions, recurrence relations or algebraic number theory, for instance via Gaussian polynomials, have proven effective in addressing this issue. However, up to now, no general formula was known. In the present work, we present exact and compact explicit formulas for the number of atomic configurations and for the distributions of the total magnetic quantum number $M$ and angular momentum $J$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04351v1" target="_blank">Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking</a></h3>
                    <p><strong>Authors:</strong> Dror Aiger, Bingyi Cao, Kaifeng Chen, Andre Araujo</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CV</p>
                    <p><strong>Summary:</strong> The dominant paradigm in image retrieval systems today is to search large databases using global image features, and re-rank those initial results with local image feature matching techniques. This design, dubbed global-to-local, stems from the computational cost of local matching approaches, which can only be afforded for a small number of retrieved images. However, emerging efficient local feature search approaches have opened up new possibilities, in particular enabling detailed retrieval at large scale, to find partial matches which are often missed by global feature search. In parallel, global feature-based re-ranking has shown promising results with high computational efficiency. In this work, we leverage these building blocks to introduce a local-to-global retrieval paradigm, where efficient local feature search meets effective global feature re-ranking. Critically, we propose a re-ranking method where global features are computed on-the-fly, based on the local feature retrieval similarities. Such re-ranking-only global features leverage multidimensional scaling techniques to create embeddings which respect the local similarities obtained during search, enabling a significant re-ranking boost. Experimentally, we demonstrate solid retrieval performance, setting new state-of-the-art results on the Revisited Oxford and Paris datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04350v1" target="_blank">Computability of dimension groups</a></h3>
                    <p><strong>Authors:</strong> Maria Sabitova</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.LO</p>
                    <p><strong>Summary:</strong> We investigate the computability of the isomorphism set $\operatorname{Iso}(G_A,G_B)$ between $G_A$ and $G_B$, where $G_A$ is a subgroup of $\mathbb{Q}^n$ generated by columns of integer powers of a non-singular $n \times n$-matrix $A$ with integer entries. Assuming that the characteristic polynomial of $A$ is irreducible -- and under an additional condition when $n$ is not prime -- we prove that $\operatorname{Iso}(G_A,G_B)$ is computable; that is, there exists an algorithm that determines the structure in finitely many steps. We also present illustrative examples.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

