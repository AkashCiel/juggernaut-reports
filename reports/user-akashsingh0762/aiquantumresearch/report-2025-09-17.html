
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-09-17<br>
            <strong>Topics:</strong> ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 100
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <h2>ai alignment research</h2>
<h3>Summary of AI Alignment Research Papers</h3>
<h4>Most Important Trends</h4>
<ol>
<li><p><strong>Context Management in AI Systems</strong>: Papers like ReSum and WebWeaver highlight a trend towards improving AIs handling of context limitations by employing techniques like context summarization and dynamic evidence structuring. These approaches aim to enable AI agents to perform more efficiently on complex, long-horizon tasks without being constrained by context window sizes.</p>
</li>
<li><p><strong>Integration of Human-like Processes</strong>: Theres a growing trend of designing AI systems that emulate human cognitive processes, as seen in WebResearcher and Shapes of Cognition. These systems use iterative, human-like reasoning and pattern recognition to handle complex tasks, suggesting a shift towards more biologically inspired AI design.</p>
</li>
<li><p><strong>Scalability and Robustness in AI Models</strong>: Papers such as Scaling Agents via Continual Pre-training and Towards General Agentic Intelligence via Environment Scaling focus on the scalability of AI models, emphasizing the need for robust training in diverse environments to enhance generalization and agentic capabilities.</p>
</li>
<li><p><strong>Alignment with Human Attention and Interaction</strong>: Research like ChartGaze and Evaluating LLM Alignment on Personality Inference explores aligning AI models with human attention patterns and psychological constructs, aiming to improve AI interpretability and interaction quality.</p>
</li>
<li><p><strong>Utilization of Multimodal Data</strong>: Studies like Image Realness Assessment and Localization with Multimodal Features and Simulating Clinical AI Assistance using Multimodal LLMs demonstrate the increasing use of multimodal data to enhance AIs understanding and performance across different domains.</p>
</li>
</ol>
<h4>Breakthroughs</h4>
<ol>
<li><p><strong>Enhanced Context Summarization Techniques</strong>: ReSum introduces a novel paradigm for context summarization that allows AI to maintain awareness of prior discoveries while bypassing context limitations, representing a significant advance in enabling long-horizon reasoning for AI agents.</p>
</li>
<li><p><strong>Human-Centric Research Methodologies</strong>: WebWeaver establishes a new state-of-the-art framework for open-ended deep research, demonstrating that adaptive planning and evidence synthesis are crucial for producing high-quality, reliable reports.</p>
</li>
<li><p><strong>Advanced Agentic Intelligence Frameworks</strong>: Scaling Agents via Continual Pre-training and Towards General Agentic Intelligence via Environment Scaling contribute frameworks that scale training environments and endow agents with both foundational and specialized capabilities, enhancing their performance in real-world scenarios.</p>
</li>
<li><p><strong>Incorporation of Human Gaze in AI Models</strong>: ChartGaze leverages eye-tracking data to align AI model attention with human gaze patterns, improving both the accuracy and interpretability of AI models in chart-focused tasks.</p>
</li>
<li><p><strong>Efficient Multimodal Integration</strong>: Simulating Clinical AI Assistance using Multimodal LLMs showcases the potential of multimodal LLMs in improving clinical AI assistance, providing a scalable solution for enhancing clinician-AI collaboration.</p>
</li>
</ol>
<h4>Implications</h4>
<ol>
<li><p><strong>Improved AI Alignment with Human Processes</strong>: The integration of human-like cognitive processes and attention patterns in AI systems suggests a move towards more intuitive and user-friendly AI interactions, potentially increasing trust and adoption in various domains.</p>
</li>
<li><p><strong>Scalability and Robustness for Real-World Applications</strong>: The emphasis on scalability and robustness in AI training indicates a future where AI systems can reliably operate in diverse and dynamic real-world environments, enhancing their practical utility.</p>
</li>
<li><p><strong>Enhanced Contextual Reasoning</strong>: Advances in context management and summarization could lead to AI systems capable of tackling more complex and nuanced tasks, such as long-term planning and strategic decision-making.</p>
</li>
<li><p><strong>Cross-Domain Applicability</strong>: The use of multimodal data and alignment techniques suggests that AI systems will become more versatile, with applications extending across fields like healthcare, finance, and autonomous systems.</p>
</li>
<li><p><strong>Ethical and Transparent AI</strong>: The focus on aligning AI with human attention and psychological constructs highlights the importance of developing AI systems that are not only effective but also ethical and transparent, fostering greater societal trust.</p>
</li>
</ol>
<p><em>Based on 50 research papers</em></p>

<h2>quantum computing</h2>
<p>Here is a high-level summary of the research papers related to quantum computing:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Integration of Quantum and Classical Techniques</strong>: Many papers highlight the trend of integrating quantum computing with classical methods to enhance computational capabilities and address complex problems, such as using quantum models for simulating molecular dynamics (DeepJump) and employing quantum resource theories for classical-quantum channels (Generalized Quantum Steins Lemma).</p>
</li>
<li><p><strong>Quantum Architecture Innovations</strong>: There is ongoing exploration into new quantum computing architectures to improve efficiency and reliability. For instance, the introduction of robust modular quantum processors and logical architectures that minimize qubit motion highlight efforts to optimize quantum operations and reduce errors.</p>
</li>
<li><p><strong>Application-Specific Quantum Development</strong>: Researchers are tailoring quantum computing approaches to specific scientific and industrial applications, such as developing effective conduction-band models for semiconductors under strain or employing quantum algorithms in high-dimensional Bayesian model comparisons in cosmology.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Robust Quantum Architectures</strong>: The development of a robust modular quantum processor that integrates motion and in-place entanglement marks a significant step forward. This architecture allows for more efficient quantum operations, particularly in high-error-rate environments.</p>
</li>
<li><p><strong>Quantum Simulation of Complex Systems</strong>: Significant progress has been made in simulating complex systems like molecular dynamics and semiconductor properties using quantum computing. These advancements facilitate faster and more accurate modeling of phenomena that are challenging for classical computers.</p>
</li>
<li><p><strong>Quantum Algorithms for Specific Problems</strong>: Novel quantum algorithms have been developed to address specific computational problems, such as using a logical architecture for Shorâ€™s algorithm and employing single-stream policy optimization for large language models.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Enhanced Computational Power</strong>: The integration of quantum computing with classical techniques and the development of robust architectures imply a future where complex computations can be performed more efficiently, potentially revolutionizing fields like materials science, cryptography, and data analysis.</p>
</li>
<li><p><strong>Broader Accessibility and Practicality</strong>: The creation of application-specific quantum models and algorithms suggests a move towards more practical and accessible quantum computing solutions for various industries, enabling advancements in technology and research.</p>
</li>
<li><p><strong>Foundation for Future Innovations</strong>: These breakthroughs provide a foundation for future innovations in quantum computing, offering insights that could lead to new quantum algorithms and architectures capable of solving even more challenging problems.</p>
</li>
</ol>
<p>Overall, these papers collectively indicate significant progress in making quantum computing more practical and effective for a range of applications, from scientific research to industrial processes.</p>
<p><em>Based on 50 research papers</em></p>

            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2509.13313v1" target="_blank">ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization</a></h3>
                    <p><strong>Authors:</strong> Xixi Wu, Kuan Li, Yida Zhao, Liwen Zhang, Litu Ou, Huifeng Yin, Zhongwang Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Minhao Cheng, Shuai Wang, Hong Cheng, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web agents.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13312v1" target="_blank">WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research</a></h3>
                    <p><strong>Authors:</strong> Zijian Li, Xin Guan, Bo Zhang, Shen Huang, Houquan Zhou, Shaopeng Lai, Ming Yan, Yong Jiang, Pengjun Xie, Fei Huang, Jun Zhang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents must synthesize vast web-scale information into insightful reports. Current approaches are plagued by dual-fold limitations: static research pipelines that decouple planning from evidence acquisition and one-shot generation paradigms that easily suffer from long-context failure issues like loss in the middle and hallucinations. To address these challenges, we introduce WebWeaver, a novel dual-agent framework that emulates the human research process. The planner operates in a dynamic cycle, iteratively interleaving evidence acquisition with outline optimization to produce a comprehensive, source-grounded outline linking to a memory bank of evidence. The writer then executes a hierarchical retrieval and writing process, composing the report section by section. By performing targeted retrieval of only the necessary evidence from the memory bank for each part, it effectively mitigates long-context issues. Our framework establishes a new state-of-the-art across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym. These results validate our human-centric, iterative methodology, demonstrating that adaptive planning and focused synthesis are crucial for producing high-quality, reliable, and well-structured reports.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13311v1" target="_blank">Towards General Agentic Intelligence via Environment Scaling</a></h3>
                    <p><strong>Authors:</strong> Runnan Fang, Shihao Cai, Baixuan Li, Jialong Wu, Guangyu Li, Wenbiao Yin, Xinyu Wang, Xiaobin Wang, Liangcai Su, Zhen Zhang, Shibin Wu, Zhengwei Tao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practical, real-world applications. Diverse real-world APIs demand precise, robust function-calling intelligence, which needs agents to develop these capabilities through interaction in varied environments. The breadth of function-calling competence is closely tied to the diversity of environments in which agents are trained. In this work, we scale up environments as a step towards advancing general agentic intelligence. This gives rise to two central challenges: (i) how to scale environments in a principled manner, and (ii) how to effectively train agentic capabilities from experiences derived through interactions with these environments. To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated, systematically broadening the space of function-calling scenarios. We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts. Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13310v1" target="_blank">Scaling Agents via Continual Pre-training</a></h3>
                    <p><strong>Authors:</strong> Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang, Kuan Li, Jialong Wu, Xuanzhong Chen, Zile Qiao, Zhongwang Zhang, Huifeng Yin, Shihao Cai, Runnan Fang, Zhengwei Tao, Wenbiao Yin, Chenxiong Qian, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13309v1" target="_blank">WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents</a></h3>
                    <p><strong>Authors:</strong> Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, Rui Min, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent advances in deep-research systems have demonstrated the potential for AI agents to autonomously discover and synthesize knowledge from external sources. In this paper, we introduce WebResearcher, a novel framework for building such agents through two key components: (1) WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, where agents periodically consolidate findings into evolving reports while maintaining focused workspaces, overcoming the context suffocation and noise contamination that plague existing mono-contextual approaches; and (2) WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation, enabling systematic creation of research tasks that bridge the gap between passive knowledge recall and active knowledge construction. Notably, we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods. Furthermore, our paradigm naturally scales through parallel thinking, enabling concurrent multi-agent exploration for more comprehensive conclusions. Extensive experiments across 6 challenging benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, even surpassing frontier proprietary systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13305v1" target="_blank">WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, Xinyu Wang, Zile Qiao, Zhen Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CL</p>
                    <p><strong>Summary:</strong> Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents performance and closing the capability gap.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13298v1" target="_blank">QDFlow: A Python package for physics simulations of quantum dot devices</a></h3>
                    <p><strong>Authors:</strong> Donovan L. Buterakos, Sandesh S. Kalantre, Joshua Ziegler, Jacob M Taylor, Justyna P. Zwolak</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cs.CV, cs.LG, quant-ph</p>
                    <p><strong>Summary:</strong> Recent advances in machine learning (ML) have accelerated progress in calibrating and operating quantum dot (QD) devices. However, most ML approaches rely on access to large, high-quality labeled datasets for training, benchmarking, and validation, with labels capturing key features in the data. Obtaining such datasets experimentally is challenging due to limited data availability and the labor-intensive nature of labeling. QDFlow is an open-source physics simulator for multi-QD arrays that generates realistic synthetic data with ground-truth labels. QDFlow combines a self-consistent Thomas-Fermi solver, a dynamic capacitance model, and flexible noise modules to produce charge stability diagrams and ray-based data closely resembling experiments. With extensive tunable parameters and customizable noise models, QDFlow supports the creation of large, diverse datasets for ML development, benchmarking, and quantum device research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13289v1" target="_blank">Image Realness Assessment and Localization with Multimodal Features</a></h3>
                    <p><strong>Authors:</strong> Lovish Kaushik, Agnij Biswas, Somdyuti Paul</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> A reliable method of quantifying the perceptual realness of AI-generated images and identifying visually inconsistent regions is crucial for practical use of AI-generated images and for improving photorealism of generative AI via realness feedback during training. This paper introduces a framework that accomplishes both overall objective realness assessment and local inconsistency identification of AI-generated images using textual descriptions of visual inconsistencies generated by vision-language models trained on large datasets that serve as reliable substitutes for human annotations. Our results demonstrate that the proposed multimodal approach improves objective realness prediction performance and produces dense realness maps that effectively distinguish between realistic and unrealistic spatial regions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13288v1" target="_blank">Shapes of Cognition for Computational Cognitive Modeling</a></h3>
                    <p><strong>Authors:</strong> Marjorie McShane, Sergei Nirenburg, Sanjay Oruganti, Jesse English</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.RO</p>
                    <p><strong>Summary:</strong> Shapes of cognition is a new conceptual paradigm for the computational cognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are remembered constellations of sensory, linguistic, conceptual, episodic, and procedural knowledge that allow agents to cut through the complexity of real life the same way as people do: by expecting things to be typical, recognizing patterns, acting by habit, reasoning by analogy, satisficing, and generally minimizing cognitive load to the degree situations permit. Atypical outcomes are treated using shapes-based recovery methods, such as learning on the fly, asking a human partner for help, or seeking an actionable, even if imperfect, situational understanding. Although shapes is an umbrella term, it is not vague: shapes-based modeling involves particular objectives, hypotheses, modeling strategies, knowledge bases, and actual models of wide-ranging phenomena, all implemented within a particular cognitive architecture. Such specificity is needed both to vet our hypotheses and to achieve our practical aims of building useful agent systems that are explainable, extensible, and worthy of our trust, even in critical domains. However, although the LEIA example of shapes-based modeling is specific, the principles can be applied more broadly, giving new life to knowledge-based and hybrid AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13282v1" target="_blank">ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement</a></h3>
                    <p><strong>Authors:</strong> Ali Salamatian, Amirhossein Abaskohi, Wan-Cyuan Fan, Mir Rayat Imtiaz Hossain, Leonid Sigal, Giuseppe Carenini</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Charts are a crucial visual medium for communicating and representing information. While Large Vision-Language Models (LVLMs) have made progress on chart question answering (CQA), the task remains challenging, particularly when models attend to irrelevant regions of the chart. In this work, we present ChartGaze, a new eye-tracking dataset that captures human gaze patterns during chart reasoning tasks. Through a systematic comparison of human and model attention, we find that LVLMs often diverge from human gaze, leading to reduced interpretability and accuracy. To address this, we propose a gaze-guided attention refinement that aligns image-text attention with human fixations. Our approach improves both answer accuracy and attention alignment, yielding gains of up to 2.56 percentage points across multiple models. These results demonstrate the promise of incorporating human gaze to enhance both the reasoning quality and interpretability of chart-focused LVLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13281v1" target="_blank">RepIt: Representing Isolated Targets to Steer Language Models</a></h3>
                    <p><strong>Authors:</strong> Vincent Siu, Nathan W. Henry, Nicholas Crispino, Yang Liu, Dawn Song, Chenguang Wang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> While activation steering in large language models (LLMs) is a growing area of research, methods can often incur broader effects than desired. This motivates isolation of purer concept vectors to enable targeted interventions and understand LLM behavior at a more granular level. We present RepIt, a simple and data-efficient framework for isolating concept-specific representations. Across five frontier LLMs, RepIt enables precise interventions: it selectively suppresses refusal on targeted concepts while preserving refusal elsewhere, producing models that answer WMD-related questions while still scoring as safe on standard benchmarks. We further show that the corrective signal localizes to just 100-200 neurons and that robust target representations can be extracted from as few as a dozen examples on a single A6000. This efficiency raises a dual concern: manipulations can be performed with modest compute and data to extend to underrepresented data-scarce topics while evading existing benchmarks. By disentangling refusal vectors with RepIt, this work demonstrates that targeted interventions can counteract overgeneralization, laying the foundation for more granular control of model behavior.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13272v1" target="_blank">Ionization and temperature measurements in warm dense copper using x-ray absorption spectroscopy</a></h3>
                    <p><strong>Authors:</strong> T. Cordova, E. V. Marley, D. A. Chin, R. A. London, H. A. Scott, T. DÃ¶ppner, F. N. Beg, F. Coppari, M. Millot, J. Emig, S. B. Hansen, P. M. Nilson, P. Sterne, M. J. MacDonald</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> hep-ex, physics.plasm-ph</p>
                    <p><strong>Summary:</strong> We detail experimental results inferring ionization and temperature for warm dense copper plasmas at several times solid density (15 to 25 g/cm$^3$) and temperatures of 10 to 21 eV. Experiments performed at the OMEGA Laser Facility generate uniform warm dense matter conditions via symmetric shock compression of a buried copper layer. The plasma is probed with a laser-generated x-ray source to collect the K-shell x-ray absorption spectrum. Fitting bound-bound absorption contributions from constituent charge states of copper provides an estimated $\overline{Z}$ of approximately 4 to 7 for these warm dense copper plasmas. We find that these partially ionized plasmas have K-edge shifts of 12 to 30 eV and bound-bound resonance 1s$\rightarrow$3p absorption shifts of 4 to 26 eV with respect to the cold K-edge. This study provides necessary experimental data to improve ionization and opacity models in the warm dense matter regime.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13270v1" target="_blank">RadGame: An AI-Powered Platform for Radiology Education</a></h3>
                    <p><strong>Authors:</strong> Mohammed Baharoon, Siavash Raissi, John S. Jun, Thibault Heintz, Mahmoud Alabbad, Ali Alburkani, Sung Eun Kim, Kent Kleinschmidt, Abdulrahman O. Alhumaydhi, Mohannad Mohammed G. Alghamdi, Jeremy Francis Palacio, Mohammed Bukhaytan, Noah Michael Prudlo, Rithvik Akula, Brady Chrisler, Benjamin Galligos, Mohammed O. Almutairi, Mazeen Mohammed Alanazi, Nasser M. Alrashdi, Joel Jihwan Hwang, Sri Sai Dinesh Jaliparthi, Luke David Nelson, Nathaniel Nguyen, Sathvik Suryadevara, Steven Kim, Mohammed F. Mohammed, Yevgeniy R. Semenov, Kun-Hsing Yu, Abdulrhman Aljouie, Hassan AlOmaish, Adam Rodman, Pranav Rajpurkar</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> We introduce RadGame, an AI-powered gamified platform for radiology education that targets two core skills: localizing findings and generating reports. Traditional radiology training is based on passive exposure to cases or active practice with real-time input from supervising radiologists, limiting opportunities for immediate and scalable feedback. RadGame addresses this gap by combining gamification with large-scale public datasets and automated, AI-driven feedback that provides clear, structured guidance to human learners. In RadGame Localize, players draw bounding boxes around abnormalities, which are automatically compared to radiologist-drawn annotations from public datasets, and visual explanations are generated by vision-language models for user missed findings. In RadGame Report, players compose findings given a chest X-ray, patient age and indication, and receive structured AI feedback based on radiology report generation metrics, highlighting errors and omissions compared to a radiologists written ground truth report from public datasets, producing a final performance and style score. In a prospective evaluation, participants using RadGame achieved a 68% improvement in localization accuracy compared to 17% with traditional passive methods and a 31% improvement in report-writing accuracy compared to 4% with traditional methods after seeing the same cases. RadGame highlights the potential of AI-driven gamification to deliver scalable, feedback-rich radiology training and reimagines the application of medical AI resources in education.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13266v1" target="_blank">JANUS: A Dual-Constraint Generative Framework for Stealthy Node Injection Attacks</a></h3>
                    <p><strong>Authors:</strong> Jiahao Zhang, Xiaobing Pei, Zhaokun Zhong, Wenqiang Hao, Zhenghao Tang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Graph Neural Networks (GNNs) have demonstrated remarkable performance across various applications, yet they are vulnerable to sophisticated adversarial attacks, particularly node injection attacks. The success of such attacks heavily relies on their stealthiness, the ability to blend in with the original graph and evade detection. However, existing methods often achieve stealthiness by relying on indirect proxy metrics, lacking consideration for the fundamental characteristics of the injected content, or focusing only on imitating local structures, which leads to the problem of local myopia. To overcome these limitations, we propose a dual-constraint stealthy node injection framework, called Joint Alignment of Nodal and Universal Structures (JANUS). At the local level, we introduce a local feature manifold alignment strategy to achieve geometric consistency in the feature space. At the global level, we incorporate structured latent variables and maximize the mutual information with the generated structures, ensuring the injected structures are consistent with the semantic patterns of the original graph. We model the injection attack as a sequential decision process, which is optimized by a reinforcement learning agent. Experiments on multiple standard datasets demonstrate that the JANUS framework significantly outperforms existing methods in terms of both attack effectiveness and stealthiness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13265v1" target="_blank">Beyond Private or Public: Large Language Models as Quasi-Public Goods in the AI Economy</a></h3>
                    <p><strong>Authors:</strong> Yukun Zhang, TianYang Zhang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This paper conceptualizes Large Language Models (LLMs) as a form of mixed public goods within digital infrastructure, analyzing their economic properties through a comprehensive theoretical framework. We develop mathematical models to quantify the non-rivalry characteristics, partial excludability, and positive externalities of LLMs. Through comparative analysis of open-source and closed-source development paths, we identify systematic differences in resource allocation efficiency, innovation trajectories, and access equity. Our empirical research evaluates the spillover effects and network externalities of LLMs across different domains, including knowledge diffusion, innovation acceleration, and industry transformation. Based on these findings, we propose policy recommendations for balancing innovation incentives with equitable access, including public-private partnership mechanisms, computational resource democratization, and governance structures that optimize social welfare. This interdisciplinary approach contributes to understanding the economic nature of foundation AI models and provides policy guidance for their development as critical digital infrastructure</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.4204/EPTCS.428" target="_blank">Proceedings of the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification</a></h3>
                    <p><strong>Authors:</strong> Giorgio Bacci, Adrian Francalanza</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LO</p>
                    <p><strong>Summary:</strong> This volume contains the proceedings of GandALF 2025, the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification. GandALF 2025 took place on 16-17th September 2025, in Valletta, Malta. The aim of GandALF 2025 is to bring together researchers from academia and industry who are actively working in the fields of Games, Automata, Logics, and Formal Verification. The idea is to cover an ample spectrum of themes, ranging from theory to applications, and stimulate cross-fertilisation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13253v1" target="_blank">Evolution of Programmers Trust in Generative AI Programming Assistants</a></h3>
                    <p><strong>Authors:</strong> Anshul Shah, Thomas Rexin, Elena Tomson, Leo Porter, William G. Griswold, Adalbert Gerald Soosai Raj</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.SE</p>
                    <p><strong>Summary:</strong> Motivation. Trust in generative AI programming assistants is a vital attitude that impacts how programmers use those programming assistants. Programmers that are over-trusting may be too reliant on their tools, leading to incorrect or vulnerable code; programmers that are under-trusting may avoid using tools that can improve their productivity and well-being. Methods. Since trust is a dynamic attitude that may change over time, this study aims to understand programmers evolution of trust after immediate (one hour) and extended (10 days) use of GitHub Copilot. We collected survey data from 71 upper-division computer science students working on a legacy code base, representing a population that is about to enter the workforce. In this study, we quantitatively measure student trust levels and qualitatively uncover why student trust changes. Findings. Student trust, on average, increased over time. After completing a project with Copilot, however, students felt that Copilot requires a competent programmer to complete some tasks manually. Students mentioned that seeing Copilots correctness, understanding how Copilot uses context from the code base, and learning some basics of natural language processing contributed to their elevated trust. Implications. Our study helps instructors and industry managers understand the factors that influence how students calibrate their trust with AI assistants. We make four pedagogical recommendations, which are that CS educators should 1) provide opportunities for students to work with Copilot on challenging software engineering tasks to calibrate their trust, 2) teach traditional skills of comprehending, debugging, and testing so students can verify output, 3) teach students about the basics of natural language processing, and 4) explicitly introduce and demonstrate the range of features available in Copilot.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13251v1" target="_blank">Large Language Model-assisted Meta-optimizer for Automated Design of Constrained Evolutionary Algorithm</a></h3>
                    <p><strong>Authors:</strong> Xu Yang, Rui Wang, Kaiwen Li, Wenhua Li, Weixiong Huang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.NE</p>
                    <p><strong>Summary:</strong> Meta-black-box optimization has been significantly advanced through the use of large language models (LLMs), yet in fancy on constrained evolutionary optimization. In this work, AwesomeDE is proposed that leverages LLMs as the strategy of meta-optimizer to generate update rules for constrained evolutionary algorithm without human intervention. On the meanwhile, $RTO^2H$ framework is introduced for standardize prompt design of LLMs. The meta-optimizer is trained on a diverse set of constrained optimization problems. Key components, including prompt design and iterative refinement, are systematically analyzed to determine their impact on design quality. Experimental results demonstrate that the proposed approach outperforms existing methods in terms of computational efficiency and solution accuracy. Furthermore, AwesomeDE is shown to generalize well across distinct problem domains, suggesting its potential for broad applicability. This research contributes to the field by providing a scalable and data-driven methodology for automated constrained algorithm design, while also highlighting limitations and directions for future work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13250v1" target="_blank">Intelligent Vacuum Thermoforming Process</a></h3>
                    <p><strong>Authors:</strong> Andi Kuswoyo, Christos Margadji, Sebastian W. Pattinson</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG, I.2.10; I.4.9</p>
                    <p><strong>Summary:</strong> Ensuring consistent quality in vacuum thermoforming presents challenges due to variations in material properties and tooling configurations. This research introduces a vision-based quality control system to predict and optimise process parameters, thereby enhancing part quality with minimal data requirements. A comprehensive dataset was developed using visual data from vacuum-formed samples subjected to various process parameters, supplemented by image augmentation techniques to improve model training. A k-Nearest Neighbour algorithm was subsequently employed to identify adjustments needed in process parameters by mapping low-quality parts to their high-quality counterparts. The model exhibited strong performance in adjusting heating power, heating time, and vacuum time to reduce defects and improve production efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13244v1" target="_blank">Evaluating LLM Alignment on Personality Inference from Real-World Interview Data</a></h3>
                    <p><strong>Authors:</strong> Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) are increasingly deployed in roles requiring nuanced psychological understanding, such as emotional support agents, counselors, and decision-making assistants. However, their ability to interpret human personality traits, a critical aspect of such applications, remains unexplored, particularly in ecologically valid conversational settings. While prior work has simulated LLM personas using discrete Big Five labels on social media data, the alignment of LLMs with continuous, ground-truth personality assessments derived from natural interactions is largely unexamined. To address this gap, we introduce a novel benchmark comprising semi-structured interview transcripts paired with validated continuous Big Five trait scores. Using this dataset, we systematically evaluate LLM performance across three paradigms: (1) zero-shot and chain-of-thought prompting with GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA architectures, and (3) regression using static embeddings from pretrained BERT and OpenAIs text-embedding-3-small. Our results reveal that all Pearson correlations between model predictions and ground-truth personality traits remain below 0.26, highlighting the limited alignment of current LLMs with validated psychological constructs. Chain-of-thought prompting offers minimal gains over zero-shot, suggesting that personality inference relies more on latent semantic representation than explicit reasoning. These findings underscore the challenges of aligning LLMs with complex human attributes and motivate future work on trait-specific prompting, context-aware modeling, and alignment-oriented fine-tuning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13236v1" target="_blank">Layout-Aware OCR for Black Digital Archives with Unsupervised Evaluation</a></h3>
                    <p><strong>Authors:</strong> Fitsum Sileshi Beyene, Christopher L. Dancy</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.DL, cs.AI</p>
                    <p><strong>Summary:</strong> Despite their cultural and historical significance, Black digital archives continue to be a structurally underrepresented area in AI research and infrastructure. This is especially evident in efforts to digitize historical Black newspapers, where inconsistent typography, visual degradation, and limited annotated layout data hinder accurate transcription, despite the availability of various systems that claim to handle optical character recognition (OCR) well. In this short paper, we present a layout-aware OCR pipeline tailored for Black newspaper archives and introduce an unsupervised evaluation framework suited to low-resource archival contexts. Our approach integrates synthetic layout generation, model pretraining on augmented data, and a fusion of state-of-the-art You Only Look Once (YOLO) detectors. We used three annotation-free evaluation metrics, the Semantic Coherence Score (SCS), Region Entropy (RE), and Textual Redundancy Score (TRS), which quantify linguistic fluency, informational diversity, and redundancy across OCR regions. Our evaluation on a 400-page dataset from ten Black newspaper titles demonstrates that layout-aware OCR improves structural diversity and reduces redundancy compared to full-page baselines, with modest trade-offs in coherence. Our results highlight the importance of respecting cultural layout logic in AI-driven document understanding and lay the foundation for future community-driven and ethically grounded archival AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13235v1" target="_blank">A Scenario-Driven Cognitive Approach to Next-Generation AI Memory</a></h3>
                    <p><strong>Authors:</strong> Linyue Cai, Yuyang Cheng, Xiaoding Shao, Huiming Wang, Yong Zhao, Wei Zhang, Kang Li</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> As artificial intelligence advances toward artificial general intelligence (AGI), the need for robust and human-like memory systems has become increasingly evident. Current memory architectures often suffer from limited adaptability, insufficient multimodal integration, and an inability to support continuous learning. To address these limitations, we propose a scenario-driven methodology that extracts essential functional requirements from representative cognitive scenarios, leading to a unified set of design principles for next-generation AI memory systems. Based on this approach, we introduce the \textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that integrates cognitive scenarios, memory processes, and storage mechanisms into a cohesive design. COLMA provides a structured foundation for developing AI systems capable of lifelong learning and human-like reasoning, thereby contributing to the pragmatic development of AGI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13234v1" target="_blank">Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy</a></h3>
                    <p><strong>Authors:</strong> Nadim Barakat, William Lotter</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV, cs.HC</p>
                    <p><strong>Summary:</strong> Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI systems can expand access to fundus photography screening. Current FDA-cleared systems primarily provide binary referral outputs, where this minimal output may limit clinical trust and utility. Yet, determining the most effective output format to enhance clinician-AI performance is an empirical challenge that is difficult to assess at scale. We evaluated multimodal large language models (MLLMs) for DR detection and their ability to simulate clinical AI assistance across different output types. Two models were tested on IDRiD and Messidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source medical model. Experiments included: (1) baseline evaluation, (2) simulated AI assistance with synthetic predictions, and (3) actual AI-to-AI collaboration where GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at baseline, achieving higher sensitivity and AUROC, while GPT-4o showed near-perfect specificity but low sensitivity. Both models adjusted predictions based on simulated AI inputs, but GPT-4os performance collapsed with incorrect ones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o achieved strong results when guided by MedGemmas descriptive outputs, even without direct image access (AUROC up to 0.96). These findings suggest MLLMs may improve DR screening pipelines and serve as scalable simulators for studying clinical AI assistance across varying output configurations. Open, lightweight models such as MedGemma may be especially valuable in low-resource settings, while descriptive outputs could enhance explainability and clinician trust in clinical workflows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13219v1" target="_blank">On the Out-of-Distribution Backdoor Attack for Federated Learning</a></h3>
                    <p><strong>Authors:</strong> Jiahao Xu, Zikai Zhang, Rui Hu</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CR</p>
                    <p><strong>Summary:</strong> Traditional backdoor attacks in federated learning (FL) operate within constrained attack scenarios, as they depend on visible triggers and require physical modifications to the target object, which limits their practicality. To address this limitation, we introduce a novel backdoor attack prototype for FL called the out-of-distribution (OOD) backdoor attack ($\mathtt{OBA}$), which uses OOD data as both poisoned samples and triggers simultaneously. Our approach significantly broadens the scope of backdoor attack scenarios in FL. To improve the stealthiness of $\mathtt{OBA}$, we propose $\mathtt{SoDa}$, which regularizes both the magnitude and direction of malicious local models during local training, aligning them closely with their benign versions to evade detection. Empirical results demonstrate that $\mathtt{OBA}$ effectively circumvents state-of-the-art defenses while maintaining high accuracy on the main task. To address this security vulnerability in the FL system, we introduce $\mathtt{BNGuard}$, a new server-side defense method tailored against $\mathtt{SoDa}$. $\mathtt{BNGuard}$ leverages the observation that OOD data causes significant deviations in the running statistics of batch normalization layers. This allows $\mathtt{BNGuard}$ to identify malicious model updates and exclude them from aggregation, thereby enhancing the backdoor robustness of FL. Extensive experiments across various settings show the effectiveness of $\mathtt{BNGuard}$ on defending against $\mathtt{SoDa}$. The code is available at https://github.com/JiiahaoXU/SoDa-BNGuard.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13215v1" target="_blank">Importance-Weighted Domain Adaptation for Sound Source Tracking</a></h3>
                    <p><strong>Authors:</strong> Bingxiang Zhong, Thomas Dietzen</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> eess.AS</p>
                    <p><strong>Summary:</strong> In recent years, deep learning has significantly advanced sound source localization (SSL). However, training such models requires large labeled datasets, and real recordings are costly to annotate in particular if sources move. While synthetic data using simulated room impulse responses (RIRs) and noise offers a practical alternative, models trained on synthetic data suffer from domain shift in real environments. Unsupervised domain adaptation (UDA) can address this by aligning synthetic and real domains without relying on labels from the latter. The few existing UDA approaches however focus on static SSL and do not account for the problem of sound source tracking (SST), which presents two specific domain adaptation challenges. First, variable-length input sequences create mismatches in feature dimensionality across domains. Second, the angular coverages of the synthetic and the real data may not be well aligned either due to partial domain overlap or due to batch size constraints, which we refer to as directional diversity mismatch. To address these, we propose a novel UDA approach tailored for SST based on two key features. We employ the final hidden state of a recurrent neural network as a fixed-dimensional feature representation to handle variable-length sequences. Further, we use importance-weighted adversarial training to tackle directional diversity mismatch by prioritizing synthetic samples similar to the real domain. Experimental results demonstrate that our approach successfully adapts synthetic-trained models to real environments, improving SST performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13214v1" target="_blank">End4: End-to-end Denoising Diffusion for Diffusion-Based Inpainting Detection</a></h3>
                    <p><strong>Authors:</strong> Fei Wang, Xuecheng Wu, Zheng Zhang, Danlei Huang, Yuheng Huang, BoWang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The powerful generative capabilities of diffusion models have significantly advanced the field of image synthesis, enhancing both full image generation and inpainting-based image editing. Despite their remarkable advancements, diffusion models also raise concerns about potential misuse for malicious purposes. However, existing approaches struggle to identify images generated by diffusion-based inpainting models, even when similar inpainted images are included in their training data. To address this challenge, we propose a novel detection method based on End-to-end denoising diffusion (End4). Specifically, End4 designs a denoising reconstruction model to improve the alignment degree between the latent spaces of the reconstruction and detection processes, thus reconstructing features that are more conducive to detection. Meanwhile, it leverages a Scale-aware Pyramid-like Fusion Module (SPFM) that refines local image features under the guidance of attention pyramid layers at different scales, enhancing feature discriminability. Additionally, to evaluate detection performance on inpainted images, we establish a comprehensive benchmark comprising images generated from five distinct masked regions. Extensive experiments demonstrate that our End4 effectively generalizes to unseen masking patterns and remains robust under various perturbations. Our code and dataset will be released soon.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13212v1" target="_blank">Extending the BEND Framework to Webgraphs</a></h3>
                    <p><strong>Authors:</strong> Evan M. Williams, Peter Carragher, Kathleen M. Carley</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.SI</p>
                    <p><strong>Summary:</strong> Attempts to manipulate webgraphs can have many downstream impacts, but analysts lack shared quantitative metrics to characterize actions taken to manipulate information environments at this level. We demonstrate how the BEND framework can be used to characterize attempts to manipulate webgraph information environments, and propose quantitative metrics for BEND community maneuvers. We demonstrate the face validity of our proposed Webgraph BEND metrics by using them to characterize two small web-graphs containing SEO-boosted Kremlin-aligned websites. We demonstrate how our proposed metrics improve BEND scores in webgraph settings and demonstrate the usefulness of our metrics in characterizing webgraph information environments. These metrics offer analysts a systematic and standardized way to characterize attempts to manipulate webgraphs using common Search Engine Optimization tactics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13209v1" target="_blank">Cardinality-Constrained Bilevel Capacity Expansion</a></h3>
                    <p><strong>Authors:</strong> Lei Guo, Jiayang Li</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> math.OC</p>
                    <p><strong>Summary:</strong> As a fundamental problem in transportation and operations research, the bilevel capacity expansion problem (BCEP) has been extensively studied for decades. In practice, BCEPs are commonly addressed in two stages: first, pre-select a small set of links for expansion; then, optimize their capacities. However, this sequential and separable approach can lead to suboptimal solutions as it neglects the critical interdependence between link selection and capacity allocation. In this paper, we propose to introduce a cardinality constraint into the BCEP to limit the number of expansion locations rather than fixing such locations beforehand. This allows us to search over all possible link combinations within the prescribed limit, thereby enabling the joint optimization of both expansion locations and capacity levels. The resulting cardinality-constrained BCEP (CCBCEP) is computationally challenging due to the combination of a nonconvex equilibrium constraint and a nonconvex and discontinuous cardinality constraint. To address this challenge, we develop a penalized difference-of-convex (DC) approach that transforms the original problem into a sequence of tractable subproblems by exploiting its inherent DC structure and the special properties of the cardinality constraint. We prove that the method converges to approximate Karush-Kuhn-Tucker (KKT) solutions with arbitrarily prescribed accuracy. Numerical experiments further show that the proposed approach consistently outperforms alternative methods for identifying practically feasible expansion plans investing only a few links, both in solution quality and computational efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13202v1" target="_blank">B-TGAT: A Bi-directional Temporal Graph Attention Transformer for Clustering Multivariate Spatiotemporal Data</a></h3>
                    <p><strong>Authors:</strong> Francis Ndikum Nji, Vandana Janaja, Jianwu Wang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Clustering high-dimensional multivariate spatiotemporal climate data is challenging due to complex temporal dependencies, evolving spatial interactions, and non-stationary dynamics. Conventional clustering methods, including recurrent and convolutional models, often struggle to capture both local and global temporal relationships while preserving spatial context. We present a time-distributed hybrid U-Net autoencoder that integrates a Bi-directional Temporal Graph Attention Transformer (B-TGAT) to guide efficient temporal clustering of multidimensional spatiotemporal climate datasets. The encoder and decoder are equipped with ConvLSTM2D modules that extract joint spatial--temporal features by modeling localized dynamics and spatial correlations over time, and skip connections that preserve multiscale spatial details during feature compression and reconstruction. At the bottleneck, B-TGAT integrates graph-based spatial modeling with attention-driven temporal encoding, enabling adaptive weighting of temporal neighbors and capturing both short and long-range dependencies across regions. This architecture produces discriminative latent embeddings optimized for clustering. Experiments on three distinct spatiotemporal climate datasets demonstrate superior cluster separability, temporal stability, and alignment with known climate transitions compared to state-of-the-art baselines. The integration of ConvLSTM2D, U-Net skip connections, and B-TGAT enhances temporal clustering performance while providing interpretable insights into complex spatiotemporal variability, advancing both methodological development and climate science applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13197v1" target="_blank">Podcasts as a Medium for Participation in Collective Action: A Case Study of Black Lives Matter</a></h3>
                    <p><strong>Authors:</strong> Theodora Moldovan, Arianna Pera, Davide Vega, Luca Maria Aiello</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.SI, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> We study how participation in collective action is articulated in podcast discussions, using the Black Lives Matter (BLM) movement as a case study. While research on collective action discourse has primarily focused on text-based content, this study takes a first step toward analyzing audio formats by using podcast transcripts. Using the Structured Podcast Research Corpus (SPoRC), we investigated spoken language expressions of participation in collective action, categorized as problem-solution, call-to-action, intention, and execution. We identified podcast episodes discussing racial justice after important BLM-related events in May and June of 2020, and extracted participatory statements using a layered framework adapted from prior work on social media. We examined the emotional dimensions of these statements, detecting eight key emotions and their association with varying stages of activism. We found that emotional profiles vary by stage, with different positive emotions standing out during calls-to-action, intention, and execution. We detected negative associations between collective action and negative emotions, contrary to theoretical expectations. Our work contributes to a better understanding of how activism is expressed in spoken digital discourse and how emotional framing may depend on the format of the discussion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13192v1" target="_blank">TRUST-FS: Tensorized Reliable Unsupervised Multi-View Feature Selection for Incomplete Data</a></h3>
                    <p><strong>Authors:</strong> Minghui Lu, Yanyong Huang, Minbo Ma, Dongjie Wang, Xiuwen Yi, Tianrui Li</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Multi-view unsupervised feature selection (MUFS), which selects informative features from multi-view unlabeled data, has attracted increasing research interest in recent years. Although great efforts have been devoted to MUFS, several challenges remain: 1) existing methods for incomplete multi-view data are limited to handling missing views and are unable to address the more general scenario of missing variables, where some features have missing values in certain views; 2) most methods address incomplete data by first imputing missing values and then performing feature selection, treating these two processes independently and overlooking their interactions; 3) missing data can result in an inaccurate similarity graph, which reduces the performance of feature selection. To solve this dilemma, we propose a novel MUFS method for incomplete multi-view data with missing variables, termed Tensorized Reliable UnSupervised mulTi-view Feature Selection (TRUST-FS). TRUST-FS introduces a new adaptive-weighted CP decomposition that simultaneously performs feature selection, missing-variable imputation, and view weight learning within a unified tensor factorization framework. By utilizing Subjective Logic to acquire trustworthy cross-view similarity information, TRUST-FS facilitates learning a reliable similarity graph, which subsequently guides feature selection and imputation. Comprehensive experimental results demonstrate the effectiveness and superiority of our method over state-of-the-art methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13187v1" target="_blank">Enhancement of torque transmission capability in Magneto-Rheological fluid-based Clutch using novel hybrid corrugated plane transmission surface strategy</a></h3>
                    <p><strong>Authors:</strong> Jithin Vijaykumar, Loyad Joseph Losan, Saddala Reddy Tharun, Murthi Ram Chandra Reddy, Mood Rahul, Jagadeesha T</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph</p>
                    <p><strong>Summary:</strong> In an increased automated world, miniaturization is the key to widespread deployment of advanced technologies. Enhancing the torque transmissibility by abiding to the spatial constraints imposed by radial space availability has consistently remained a hurdle in the implementation of Magneto-Rheological (MR) clutches that use shear mode of MR fluid (MRF). This proves the necessity of a novel design capable of providing required transmission capability with a reduced transmission surface area. The present study analyzes a corrugated transmissible surface design which improves torque transmissibility with the help of increased transmission area and proper alignment of field lines passing through the MRF gap. In this paper, the impact of various dimensional parameters of a hybrid corrugated plane type MR clutch (MRC) design was studied with the aid of magnetic analysis performed on COMSOL Multiphysics software. The results obtained shows that various parameters in the design of MR clutches, such as annular and radial MR gaps, disc width, individual corrugation heights, corrugation width, bobbin thickness and radii of plane surface influences the torque transmission capability of MR clutches. Also, an optimization of the hybrid corrugated plane MR Clutch of the chosen geometry has been conducted with the transmission capability increasing by 39.37% compared with the non-optimized geometrical configuration.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13186v1" target="_blank">Characterizing Phishing Pages by JavaScript Capabilities</a></h3>
                    <p><strong>Authors:</strong> Aleksandr Nahapetyan, Kanv Khare, Kevin Schwarz, Bradley Reaves, Alexandros Kapravelos</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> In 2024, the Anti-Phishing Work Group identified over one million phishing pages. Phishers achieve this scale by using phishing kits -- ready-to-deploy phishing websites -- to rapidly deploy phishing campaigns with specific data exfiltration, evasion, or mimicry techniques. In contrast, researchers and defenders continue to fight phishing on a page-by-page basis and rely on manual analysis to recognize static features for kit identification. This paper aims to aid researchers and analysts by automatically differentiating groups of phishing pages based on the underlying kit, automating a previously manual process, and enabling us to measure how popular different client-side techniques are across these groups. For kit detection, our system has an accuracy of 97% on a ground-truth dataset of 548 kit families deployed across 4,562 phishing URLs. On an unlabeled dataset, we leverage the complexity of 434,050 phishing pages JavaScript logic to group them into 11,377 clusters, annotating the clusters with what phishing techniques they employ. We find that UI interactivity and basic fingerprinting are universal techniques, present in 90% and 80% of the clusters, respectively. On the other hand, mouse detection via the browsers mouse API is among the rarest behaviors, despite being used in a deployment of a 7-year-old open-source phishing kit. Our methods and findings provide new ways for researchers and analysts to tackle the volume of phishing pages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13181v1" target="_blank">Road Obstacle Video Segmentation</a></h3>
                    <p><strong>Authors:</strong> Shyam Nandan Rai, Shyamgopal Karthik, Mariana-Iuliana Georgescu, Barbara Caputo, Carlo Masone, Zeynep Akata</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the growing deployment of autonomous driving agents, the detection and segmentation of road obstacles have become critical to ensure safe autonomous navigation. However, existing road-obstacle segmentation methods are applied on individual frames, overlooking the temporal nature of the problem, leading to inconsistent prediction maps between consecutive frames. In this work, we demonstrate that the road-obstacle segmentation task is inherently temporal, since the segmentation maps for consecutive frames are strongly correlated. To address this, we curate and adapt four evaluation benchmarks for road-obstacle video segmentation and evaluate 11 state-of-the-art image- and video-based segmentation methods on these benchmarks. Moreover, we introduce two strong baseline methods based on vision foundation models. Our approach establishes a new state-of-the-art in road-obstacle video segmentation for long-range video sequences, providing valuable insights and direction for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13179v1" target="_blank">Efficient Cold-Start Recommendation via BPE Token-Level Embedding Initialization with LLM</a></h3>
                    <p><strong>Authors:</strong> Yushang Zhao, Xinyue Han, Qian Leng, Qianyi Sun, Haotian Lyu, Chengrui Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.LG</p>
                    <p><strong>Summary:</strong> The cold-start issue is the challenge when we talk about recommender systems, especially in the case when we do not have the past interaction data of new users or new items. Content-based features or hybrid solutions are common as conventional solutions, but they can only work in a sparse metadata environment with shallow patterns. In this paper, the efficient cold-start recommendation strategy is presented, which is based on the sub word-level representations by applying Byte Pair Encoding (BPE) tokenization and pre-trained Large Language Model (LLM) embedding in the initialization procedure. We obtain fine-grained token-level vectors that are aligned with the BPE vocabulary as opposed to using coarse-grained sentence embeddings. Together, these token embeddings can be used as dense semantic priors on unseen entities, making immediate recommendation performance possible without user-item interaction history. Our mechanism can be compared to collaborative filtering systems and tested over benchmark datasets with stringent cold-start assumptions. Experimental findings show that the given BPE-LLM method achieves higher Recall@k, NDCG@k, and Hit Rate measurements compared to the standard baseline and displays the same capability of sufficient computational performance. Furthermore, we demonstrate that using subword-aware embeddings yields better generalizability and is more interpretable, especially within a multilingual and sparse input setting. The practical application of token-level semantic initialization as a lightweight, but nevertheless effective extension to modern recommender systems in the zero-shot setting is indicated within this work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13175v1" target="_blank">More performant and scalable: Rethinking contrastive vision-language pre-training of radiology in the LLM era</a></h3>
                    <p><strong>Authors:</strong> Yingtai Li, Haoran Lai, Xiaoqian Zhou, Shuai Ming, Wenxin Ma, Wei Wei, Shaohua Kevin Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The emergence of Large Language Models (LLMs) presents unprecedented opportunities to revolutionize medical contrastive vision-language pre-training. In this paper, we show how LLMs can facilitate large-scale supervised pre-training, thereby advancing vision-language alignment. We begin by demonstrate that modern LLMs can automatically extract diagnostic labels from radiology reports with remarkable precision (96\% AUC in our experiments) without complex prompt engineering, enabling the creation of large-scale silver-standard datasets at a minimal cost (~\$3 for 50k CT image-report pairs). Further, we find that vision encoder trained on this silver-standard dataset achieves performance comparable to those trained on labels extracted by specialized BERT-based models, thereby democratizing the access to large-scale supervised pre-training. Building on this foundation, we proceed to reveal that supervised pre-training fundamentally improves contrastive vision-language alignment. Our approach achieves state-of-the-art performance using only a 3D ResNet-18 with vanilla CLIP training, including 83.8\% AUC for zero-shot diagnosis on CT-RATE, 77.3\% AUC on RAD-ChestCT, and substantial improvements in cross-modal retrieval (MAP@50=53.7\% for image-image, Recall@100=52.2\% for report-image). These results demonstrate the potential of utilizing LLMs to facilitate {\bf more performant and scalable} medical AI systems. Our code is avaiable at https://github.com/SadVoxel/More-performant-and-scalable.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13171v1" target="_blank">Hybrid Active-Passive Galactic Cosmic Ray Simulator: in-silico design and optimization</a></h3>
                    <p><strong>Authors:</strong> Luca Lunati, Enrico Pierobon, Uli Weber, Tim Wagner, Tabea Pfuhl, Marco Durante, Christoph Schuy</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> physics.space-ph</p>
                    <p><strong>Summary:</strong> High-energy heavy-ion particle accelerators have long served as a proxy for the harsh space radiation environment, enabling both fundamental life-science research and applied testing of flight components. Typically, monoenergetic high-energy heavy-ion beams are used to mimic the complex mixed radiation field encountered in low Earth orbit and beyond. However, synergistic effects arising from the spatial or temporal proximity of interactions of different radiation qualities in a mixed field cannot be fully assessed with such beams. Therefore, spearheaded by developments at the NASA Space Radiation Laboratory, the GSI Helmholtzzentrum fuer Schwerionenforschung, supported by ESA, has developed advanced space radiation simulation capabilities to support space radiation studies in Europe. Here, we report the design, optimization, and in-silico benchmarking of GSIs hybrid active-passive GCR simulator. Additionally, a computationally optimized phase-space particle source for Geant4 is presented, which will be made available to external users to support their own in-silico studies and experimental planning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13163v1" target="_blank">Euclid preparation. Using mock Low Surface Brightness dwarf galaxies to probe Wide Survey detection capabilities</a></h3>
                    <p><strong>Authors:</strong> Euclid Collaboration, M. Urbano, P. -A. Duc, M. Poulain, A. A. Nucita, A. Venhola, O. Marchal, M. KÃ¼mmel, H. Kong, F. Soldano, E. Romelli, M. Walmsley, T. Saifollahi, K. Voggel, A. LanÃ§on, F. R. Marleau, E. Sola, L. K. Hunt, J. Junais, D. Carollo, P. M. Sanchez-Alarcon, M. Baes, F. Buitrago, Michele Cantiello, J. -C. Cuillandre, H. DomÃ­nguez SÃ¡nchez, A. FerrÃ©-Mateu, A. Franco, J. Gracia-Carpio, R. Habas, M. Hilker, E. Iodice, J. H. Knapen, M. N. Le, D. MartÃ­nez-Delgado, O. MÃ¼ller, F. De Paolis, P. Papaderos, R. Ragusa, J. RomÃ¡n, E. Saremi, V. Testa, B. Altieri, L. Amendola, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, S. Camera, G. CaÃ±as-Herrera, V. Capobianco, C. Carbone, J. Carretero, S. Casas, M. Castellano, G. Castignani, S. Cavuoti, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, G. De Lucia, H. Dole, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Ferriol, F. Finelli, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, A. Grazian, F. Grupp, L. Guzzo, S. V. H. Haugan, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. KeihÃ¤nen, S. Kermiche, A. Kiessling, B. Kubik, M. Kunz, H. Kurki-Suonio, R. Laureijs, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, R. Nakajima, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, M. Roncarelli, R. Saglia, Z. Sakr, D. Sapone, B. Sartoris, P. Schneider, T. Schrabback, A. Secroun, G. Seidel, S. Serrano, P. Simon, C. Sirignano, G. Sirri, L. Stanco, J. -L. Starck, J. Steinwagner, P. Tallada-CrespÃ­, A. N. Taylor, H. I. Teplitz, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, G. Zamorani, I. A. Zinchenko, E. Zucca, M. Ballardini, M. Bolzonella, E. Bozzo, C. Burigana, R. Cabanac, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, M. Huertas-Company, J. MartÃ­n-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. Pezzotta, M. PÃ¶ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, M. Bonici, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, S. Davini, G. Desprez, A. DÃ­az-SÃ¡nchez, J. J. Diaz, S. Di Domizio, J. M. Diego, M. Y. Elkhashab, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, K. Ganga, J. GarcÃ­a-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Guidi, C. M. Gutierrez, A. Hall, H. Hildebrandt, J. Hjorth, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, A. Loureiro, J. Macias-Perez, G. Maggio, M. Magliocchetti, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, K. Naidoo, A. Navarro-Alsina, S. Nesseris, D. Paoletti, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, G. Rodighiero, S. Sacquegna, M. SahlÃ©n, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, J. G. Sorce, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, D. Vergani, G. Verza, P. Vielzeuf, N. A. Walton</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA, astro-ph.IM</p>
                    <p><strong>Summary:</strong> Local Universe dwarf galaxies are both cosmological and mass assembly probes. Deep surveys have enabled the study of these objects down to the low surface brightness (LSB) regime. In this paper, we estimate Euclids dwarf detection capabilities as well as limits of its MERge processing function (MER pipeline), responsible for producing the stacked mosaics and final catalogues. To do this, we inject mock dwarf galaxies in a real Euclid Wide Survey (EWS) field in the VIS band and compare the input catalogue to the final MER catalogue. The mock dwarf galaxies are generated with simple S\ersic models and structural parameters extracted from observed dwarf galaxy property catalogues. To characterize the detected dwarfs, we use the mean surface brightness inside the effective radius SBe (in mag arcsec-2). The final MER catalogues achieve completenesses of 91 % for SBe in [21, 24], and 54 % for SBe in [24, 28]. These numbers do not take into account possible contaminants, including confusion with background galaxies at the location of the dwarfs. After taking into account those effects, they become respectively 86 % and 38 %. The MER pipeline performs a final local background subtraction with small mesh size, leading to a flux loss for galaxies with Re  10. By using the final MER mosaics and reinjecting this local background, we obtain an image in which we recover reliable photometric properties for objects under the arcminute scale. This background-reinjected product is thus suitable for the study of Local Universe dwarf galaxies. Euclids data reduction pipeline serves as a test bed for other deep surveys, particularly regarding background subtraction methods, a key issue in LSB science.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13160v1" target="_blank">FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning</a></h3>
                    <p><strong>Authors:</strong> Liang Hu, Jianpeng Jiao, Jiashuo Liu, Yanle Ren, Zhoufutu Wen, Kaiyuan Zhang, Xuanliang Zhang, Xiang Gao, Tianci He, Fei Hu, Yali Liao, Zaiyuan Wang, Chenghao Yang, Qianyu Yang, Mingren Yin, Zhiyuan Zeng, Ge Zhang, Xinyi Zhang, Xiying Zhao, Zhenwei Zhu, Hongseok Namkoong, Wenhao Huang, Yuwen Tang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Search has emerged as core infrastructure for LLM-based agents and is widely viewed as critical on the path toward more general intelligence. Finance is a particularly demanding proving ground: analysts routinely conduct complex, multi-step searches over time-sensitive, domain-specific data, making it ideal for assessing both search proficiency and knowledge-grounded reasoning. Yet no existing open financial datasets evaluate data searching capability of end-to-end agents, largely because constructing realistic, complicated tasks requires deep financial expertise and time-sensitive data is hard to evaluate. We present FinSearchComp, the first fully open-source agent benchmark for realistic, open-domain financial search and reasoning. FinSearchComp comprises three tasks -- Time-Sensitive Data Fetching, Simple Historical Lookup, and Complex Historical Investigation -- closely reproduce real-world financial analyst workflows. To ensure difficulty and reliability, we engage 70 professional financial experts for annotation and implement a rigorous multi-stage quality-assurance pipeline. The benchmark includes 635 questions spanning global and Greater China markets, and we evaluate 21 models (products) on it. Grok 4 (web) tops the global subset, approaching expert-level accuracy. DouBao (web) leads on the Greater China subset. Experimental analyses show that equipping agents with web search and financial plugins substantially improves results on FinSearchComp, and the country origin of models and tools impact performance significantly.By aligning with realistic analyst tasks and providing end-to-end evaluation, FinSearchComp offers a professional, high-difficulty testbed for complex financial search and reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13159v1" target="_blank">Engineering strong correlations in a perfectly aligned dual moirÃ© system</a></h3>
                    <p><strong>Authors:</strong> Amine Ben Mhenni, Elif Ã‡etiner, Kenji Watanabe, Takashi Taniguchi, Jonathan J. Finley, Nathan P. Wilson</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Exotic collective phenomena emerge when bosons strongly interact within a lattice. However, creating a robust and tunable solid-state platform to explore such phenomena has been elusive. Dual moir\e systems$-$compromising two Coulomb-coupled moir\e lattices$-$offer a promising system for investigating strongly correlated dipolar excitons (composite bosons) with electrical control. Thus far, their implementation has been hindered by the relative misalignment and incommensurability of the two moir\e patterns. Here we report a dual moir\e system with perfect translational and rotational alignment, achieved by utilizing twisted hexagonal boron nitride (hBN) bilayer to both generate an electrostatic moir\e potential and separate MoSe$_{2}$ and WSe$_{2}$ monolayers. We observe strongly correlated electron phases driven by intralayer interactions and identify interlayer Rydberg trions, which become trapped in the presence of the Mott insulating state. Importantly, our platform is electrostatically programmable, allowing the realization of different lattice symmetries with either repulsive or attractive interlayer interactions. In particular, we implement the latter scenario by optically injecting charges, which form a dipolar excitonic phase. Our results establish a versatile platform for the exploration and manipulation of exotic and topological bosonic quantum many-body phases.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13156v1" target="_blank">Designing the Hybrid Cooperative: A Socio-Technical Architecture for Scalable, Global Coordination Using Blockchain</a></h3>
                    <p><strong>Authors:</strong> Henrik Axelsen, Jan Damsgaard</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CY, K.4.3; K.4.4; C.2.4</p>
                    <p><strong>Summary:</strong> Blockchain has been promoted as a remedy for coordination in fragmented, multi-stakeholder ecosystems, yet many projects stall at pilot stage. Using a design-science approach, we develop the Hybrid Cooperative (HC), a digitally native governance architecture that combines smart-contract coordination with a minimal, code-deferent legal interface and jurisdictional modules. This selective decentralization decentralizes rules where programmability lowers agency and verification costs, and centralizes only what is needed for enforceability. A post-case evaluation against two traceability initiatives in supply chains illustrates how the HC improves distributed task management, verifiable information, incentive alignment, institutional interoperability, and scalable, contestable governance. The paper contributes to Information Systems by specifying a socio-technical model for scalable, multi-stakeholder coordination across regulatory and organizational boundaries.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13150v1" target="_blank">Evaluation of Objective Image Quality Metrics for High-Fidelity Image Compression</a></h3>
                    <p><strong>Authors:</strong> Shima Mohammadi, Mohsen Jenadeleh, Jon Sneyers, Dietmar Saupe, JoÃ£o Ascenso</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.MM</p>
                    <p><strong>Summary:</strong> Nowadays, image compression solutions are increasingly designed to operate within high-fidelity quality ranges, where preserving even the most subtle details of the original image is essential. In this context, the ability to detect and quantify subtle compression artifacts becomes critically important, as even slight degradations can impact perceptual quality in professional or quality sensitive applications, such as digital archiving, professional editing and web delivery. However, the performance of current objective image quality assessment metrics in this range has not been thoroughly investigated. In particular, it is not well understood how reliably these metrics estimate distortions at or below the threshold of Just Noticeable Difference (JND). This study directly addresses this issue by proposing evaluation methodologies for assessing the performance of objective quality metrics and performing a comprehensive evaluation using the JPEG AIC-3 dataset which is designed for high-fidelity image compression. Beyond conventional criteria, the study introduces Z-RMSE to incorporate subjective score uncertainty and applies novel statistical tests to assess significant differences between metrics. The analysis spans the full JPEG AIC-3 range and its high- and medium-fidelity subsets, examines the impact of cropping in subjective tests, and a public dataset with benchmarks and evaluation tools is released to support further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13149v1" target="_blank">MSDNet: Efficient 4D Radar Super-Resolution via Multi-Stage Distillation</a></h3>
                    <p><strong>Authors:</strong> Minqing Huang, Shouyi Lu, Boyuan Zheng, Ziyao Li, Xiao Tang, Guirong Zhuo</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 4D radar super-resolution, which aims to reconstruct sparse and noisy point clouds into dense and geometrically consistent representations, is a foundational problem in autonomous perception. However, existing methods often suffer from high training cost or rely on complex diffusion-based sampling, resulting in high inference latency and poor generalization, making it difficult to balance accuracy and efficiency. To address these limitations, we propose MSDNet, a multi-stage distillation framework that efficiently transfers dense LiDAR priors to 4D radar features to achieve both high reconstruction quality and computational efficiency. The first stage performs reconstruction-guided feature distillation, aligning and densifying the students features through feature reconstruction. In the second stage, we propose diffusion-guided feature distillation, which treats the stage-one distilled features as a noisy version of the teachers representations and refines them via a lightweight diffusion network. Furthermore, we introduce a noise adapter that adaptively aligns the noise level of the feature with a predefined diffusion timestep, enabling a more precise denoising. Extensive experiments on the VoD and in-house datasets demonstrate that MSDNet achieves both high-fidelity reconstruction and low-latency inference in the task of 4D radar point cloud super-resolution, and consistently improves performance on downstream tasks. The code will be publicly available upon publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13148v1" target="_blank">Can Large Audio Language Models Understand Audio Well? Speech, Scene and Events Understanding Benchmark for LALMs</a></h3>
                    <p><strong>Authors:</strong> Han Yin, Jung-Woo Choi</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.SD</p>
                    <p><strong>Summary:</strong> Recently, Large Audio Language Models (LALMs) have progressed rapidly, demonstrating their strong efficacy in universal audio understanding through cross-modal integration. To evaluate the LALMs audio understanding performance, researchers have proposed different benchmarks. However, key aspects for real-world interactions are underexplored in existing benchmarks, i.e., audio signals typically contain both speech and non-speech components, and energy levels of these components can vary significantly across different scenarios. Moreover, most benchmarks do not consider the joint understanding of speech, scene, and events within the same audio clip. In this work, we introduce SSEU-Bench, the first versatile audio understanding benchmark that explicitly accounts for energy differences between speech and non-speech audio, with both independent and joint understanding settings for speech, scene, and events. Furthermore, we demonstrate that some LALMs tend to underperform on certain tasks in a joint understanding setting. To address this issue, we introduce Chain-of-Thought, which effectively improves the LALMs joint audio understanding performance by decomposing complex tasks into simpler reasoning steps</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13144v1" target="_blank">Towards the Next Generation of Software: Insights from Grey Literature on AI-Native Applications</a></h3>
                    <p><strong>Authors:</strong> Lingli Cao, Shanshan Li, Ying Fan, Danyang Li, Chenxing Zhong</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Background: The rapid advancement of large language models (LLMs) has given rise to AI-native applications, a new paradigm in software engineering that fundamentally redefines how software is designed, developed, and evolved. Despite their growing prominence, AI-native applications still lack a unified engineering definition and architectural blueprint, leaving practitioners without systematic guidance for system design, quality assurance, and technology selection. Objective: This study seeks to establish a comprehensive understanding of AI-native applications by identifying their defining characteristics, key quality attributes, and typical technology stacks, as well as by clarifying the opportunities and challenges they present. Method: We conducted a grey literature review, integrating conceptual perspectives retrieved from targeted Google and Bing searches with practical insights derived from leading open-source projects on GitHub. A structured protocol encompassing source selection, quality assessment, and thematic analysis was applied to synthesize findings across heterogeneous sources. Results: We finally identified 106 studies based on the selection criteria. The analysis reveals that AI-native applications are distinguished by two core pillars: the central role of AI as the systems intelligence paradigm and their inherently probabilistic, non-deterministic nature. Critical quality attributes include reliability, usability, performance efficiency, and AI-specific observability. In addition, a typical technology stack has begun to emerge, comprising LLM orchestration frameworks, vector databases, and AI-native observability platforms. These systems emphasize response quality, cost-effectiveness, and outcome predictability, setting them apart from conventional software systems. Conclusion: This study is the first to propose a dual-layered engineering blueprint...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13137v1" target="_blank">Agentic AI for Financial Crime Compliance</a></h3>
                    <p><strong>Authors:</strong> Henrik Axelsen, Valdemar Licht, Jan Damsgaard</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, cs.MA, K.4.4; K.6.5; I.2.11</p>
                    <p><strong>Summary:</strong> The cost and complexity of financial crime compliance (FCC) continue to rise, often without measurable improvements in effectiveness. While AI offers potential, most solutions remain opaque and poorly aligned with regulatory expectations. This paper presents the design and deployment of an agentic AI system for FCC in digitally native financial platforms. Developed through an Action Design Research (ADR) process with a fintech firm and regulatory stakeholders, the system automates onboarding, monitoring, investigation, and reporting, emphasizing explainability, traceability, and compliance-by-design. Using artifact-centric modeling, it assigns clearly bounded roles to autonomous agents and enables task-specific model routing and audit logging. The contribution includes a reference architecture, a real-world prototype, and insights into how Agentic AI can reconfigure FCC workflows under regulatory constraints. Our findings extend IS literature on AI-enabled compliance by demonstrating how automation, when embedded within accountable governance structures, can support transparency and institutional trust in high-stakes, regulated environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13135v1" target="_blank">Measurement of neutron total cross-section of Mg and MgF$_{2}$ at MONNET (JRC-Geel) from transmission with fine multi-scattering corrections</a></h3>
                    <p><strong>Authors:</strong> Marco Antonio MartÃ­nez-CaÃ±adas, Pablo Torres-SÃ¡nchez, Miguel MacÃ­as, Javier Praena, Cristiano L. Fontana, CÃ©dric Bonaldi, Wouter Geerts, Stephan Oberstedt, Ignacio Porras</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> nucl-ex</p>
                    <p><strong>Summary:</strong> Neutron-transmission measurements through samples of magnesium fluoride (MgF$_2$) and pure magnesium were performed to obtain the (n, tot) cross section for all isotopes involved, $^{19}$F and $^{24-26}$Mg. Lithium-glass detectors were used in conjunction with the neutron time-of-flight technique. The measurement campaign was performed at the MONNET fast-neutron source of the European Commission Joint Research Centre (JRC-Geel, Belgium). Highly precise corrections for multiple scattering were calculated using a sophisticated iterative method based on Monte Carlo simulations with the MCNP6.3 code, accounting for the effects of the experimental setup. With the SAMMY code, an R-Matrix analysis of the experimental data was performed. The extracted cross-sections, resonance spin and parity as well as the limitations of the method are carefully discussed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13127v1" target="_blank">Empowering LLMs with Parameterized Skills for Adversarial Long-Horizon Planning</a></h3>
                    <p><strong>Authors:</strong> Sijia Cui, Shuai Xu, Aiyao He, Yanna Wang, Bo Xu</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models(LLMs) have led to the development of LLM-based AI agents. A key challenge is the creation of agents that can effectively ground themselves in complex, adversarial long-horizon environments. Existing methods mainly focus on (1) using LLMs as policies to interact with the environment through generating low-level feasible actions, and (2) utilizing LLMs to generate high-level tasks or language guides to stimulate action generation. However, the former struggles to generate reliable actions, while the latter relies heavily on expert experience to translate high-level tasks into specific action sequences. To address these challenges, we introduce the Plan with Language, Act with Parameter (PLAP) planning framework that facilitates the grounding of LLM-based agents in long-horizon environments. The PLAP method comprises three key components: (1) a skill library containing environment-specific parameterized skills, (2) a skill planner powered by LLMs, and (3) a skill executor converting the parameterized skills into executable action sequences. We implement PLAP in MicroRTS, a long-horizon real-time strategy game that provides an unfamiliar and challenging environment for LLMs. The experimental results demonstrate the effectiveness of PLAP. In particular, GPT-4o-driven PLAP in a zero-shot setting outperforms 80% of baseline agents, and Qwen2-72B-driven PLAP, with carefully crafted few-shot examples, surpasses the top-tier scripted agent, CoacAI. Additionally, we design comprehensive evaluation metrics and test 6 closed-source and 2 open-source LLMs within the PLAP framework, ultimately releasing an LLM leaderboard ranking long-horizon skill planning ability. Our code is available at https://github.com/AI-Research-TeamX/PLAP.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13117v1" target="_blank">Vulnerability Patching Across Software Products and Software Components: A Case Study of Red Hats Product Portfolio</a></h3>
                    <p><strong>Authors:</strong> Jukka Ruohonen, Sani Abdullahi, Abhishek Tiwari</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.CR</p>
                    <p><strong>Summary:</strong> Motivated by software maintenance and the more recent concept of security debt, the paper presents a time series analysis of vulnerability patching of Red Hats products and components between 1999 and 2024. According to the results based on segmented regression analysis, the amounts of vulnerable products and components have not been stable; a linear trend describes many of the series well. Nor do the amounts align well with trends characterizing vulnerabilities in general. There are also visible breakpoints indicating that the linear trend is not universally applicable and that the growing security debt may be stabilizing.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/TPAMI.2025.3604036" target="_blank">Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving</a></h3>
                    <p><strong>Authors:</strong> Ruibo Li, Hanyu Shi, Zhe Wang, Guosheng Lin</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Understanding motion in dynamic environments is critical for autonomous driving, thereby motivating research on class-agnostic motion prediction. In this work, we investigate weakly and self-supervised class-agnostic motion prediction from LiDAR point clouds. Outdoor scenes typically consist of mobile foregrounds and static backgrounds, allowing motion understanding to be associated with scene parsing. Based on this observation, we propose a novel weakly supervised paradigm that replaces motion annotations with fully or partially annotated (1%, 0.1%) foreground/background masks for supervision. To this end, we develop a weakly supervised approach utilizing foreground/background cues to guide the self-supervised learning of motion prediction models. Since foreground motion generally occurs in non-ground regions, non-ground/ground masks can serve as an alternative to foreground/background masks, further reducing annotation effort. Leveraging non-ground/ground cues, we propose two additional approaches: a weakly supervised method requiring fewer (0.01%) foreground/background annotations, and a self-supervised method without annotations. Furthermore, we design a Robust Consistency-aware Chamfer Distance loss that incorporates multi-frame information and robust penalty functions to suppress outliers in self-supervised learning. Experiments show that our weakly and self-supervised models outperform existing self-supervised counterparts, and our weakly supervised models even rival some supervised ones. This demonstrates that our approaches effectively balance annotation effort and performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13321v1" target="_blank">Towards detecting the time perturbations from GWs in asynchronous gauges</a></h3>
                    <p><strong>Authors:</strong> Stefano Bondani, Sergio Luigi Cacciatori</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> The experimental possibility of detecting gravitational waves via their induced time perturbations is explored here, expanding from previous work. The oscillations of the time-time component in the metric are made explicit when working in asynchronous gauges: the desynchronization between a perturbed clock and a reference unperturbed clock constitutes the corresponding observable core target of a detector. To this end we explore the experimental techniques currently available for a preliminary assessment towards a feasibility study. We survey the state of the art in the fields of high precision timing and information preservation, necessary for achieving geodesic non-locality. A synthesis for a feasible prototype detector with the desired characteristics is presented. The optimum point between existing technologies is found around the 1 Hz frequency band, opening the window for the observation of classes of speculated sources of gravitational radiation such as intermediate mass black hole binaries.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13318v1" target="_blank">How Theory-Informed Priors Affect DESI Evidence for Evolving Dark Energy</a></h3>
                    <p><strong>Authors:</strong> Michael W. Toomey, Gabriele Montefalcone, Evan McDonough, Katherine Freese</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, hep-ph</p>
                    <p><strong>Summary:</strong> Recent measurements of baryon acoustic oscillations (BAO) from the Dark Energy Spectroscopic Instrument (DESI) have been interpreted to suggest that dark energy may be evolving. In this work, we examine how prior choices affect such conclusions. Specifically, we study the biases introduced by the customary use of uniform priors on the Chevallier-Polarski-Linder (CPL) parameters, $w_0$ and $w_a$, when assessing evidence for evolving dark energy. To do so, we construct theory-informed priors on $(w_0, w_a)$ using a normalizing flow (NF), trained on two representative quintessence models, which learns the distribution of these parameters conditional on the underlying $\Lambda$CDM parameters. In the combined $\textit{Planck}$ CMB + DESI BAO analysis we find that the apparent tension with a cosmological constant in the CPL framework can be reduced from $\sim 3.1\sigma$ to $\sim 1.3\sigma$ once theory-informed priors are applied, rendering the result effectively consistent with $\Lambda$CDM. For completeness, we also analyze combinations that include Type Ia supernova data, showing similar shifts toward the $\Lambda$CDM limit. Taken together, the observed sensitivity to prior choices in these analyses arises because uniform priors - often mischaracterized as uninformative - can actually bias inferences toward unphysical parameter regions. Consequently, our results underscore the importance of adopting physically motivated priors to ensure robust cosmological inferences, especially when evaluating new hypotheses with only marginal statistical support. Lastly, our NF-based framework achieves these results by post-processing existing MCMC chains, requiring $\approx 1$ hour of additional CPU compute time on top of the base analysis - a dramatic speedup over direct model sampling that highlights the scalability of this approach for testing diverse theoretical models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13317v1" target="_blank">3D Aware Region Prompted Vision Language Model</a></h3>
                    <p><strong>Authors:</strong> An-Chieh Cheng, Yang Fu, Yukang Chen, Zhijian Liu, Xiaolong Li, Subhashree Radhakrishnan, Song Han, Yao Lu, Jan Kautz, Pavlo Molchanov, Hongxu Yin, Xiaolong Wang, Sifei Liu</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We present Spatial Region 3D (SR-3D) aware vision-language model that connects single-view 2D images and multi-view 3D data through a shared visual token space. SR-3D supports flexible region prompting, allowing users to annotate regions with bounding boxes, segmentation masks on any frame, or directly in 3D, without the need for exhaustive multi-frame labeling. We achieve this by enriching 2D visual features with 3D positional embeddings, which allows the 3D model to draw upon strong 2D priors for more accurate spatial reasoning across frames, even when objects of interest do not co-occur within the same view. Extensive experiments on both general 2D vision language and specialized 3D spatial benchmarks demonstrate that SR-3D achieves state-of-the-art performance, underscoring its effectiveness for unifying 2D and 3D representation space on scene understanding. Moreover, we observe applicability to in-the-wild videos without sensory 3D inputs or ground-truth 3D annotations, where SR-3D accurately infers spatial relationships and metric measurements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13316v1" target="_blank">Do Natural Language Descriptions of Model Activations Convey Privileged Information?</a></h3>
                    <p><strong>Authors:</strong> Millicent Li, Alberto Mario Ceballos Arroyo, Giordano Rogers, Naomi Saphra, Byron C. Wallace</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Recent interpretability methods have proposed to translate LLM internal representations into natural language descriptions using a second verbalizer LLM. This is intended to illuminate how the target model represents and operates on inputs. But do such activation verbalization approaches actually provide privileged knowledge about the internal workings of the target model, or do they merely convey information about its inputs? We critically evaluate popular verbalization methods across datasets used in prior work and find that they succeed at benchmarks without any access to target model internals, suggesting that these datasets are not ideal for evaluating verbalization methods. We then run controlled experiments which reveal that verbalizations often reflect the parametric knowledge of the verbalizer LLM which generated them, rather than the activations of the target LLM being decoded. Taken together, our results indicate a need for targeted benchmarks and experimental controls to rigorously assess whether verbalization methods provide meaningful insights into the operations of LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13313v1" target="_blank">ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization</a></h3>
                    <p><strong>Authors:</strong> Xixi Wu, Kuan Li, Yida Zhao, Liwen Zhang, Litu Ou, Huifeng Yin, Zhongwang Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Minhao Cheng, Shuai Wang, Hong Cheng, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web agents.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13312v1" target="_blank">WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research</a></h3>
                    <p><strong>Authors:</strong> Zijian Li, Xin Guan, Bo Zhang, Shen Huang, Houquan Zhou, Shaopeng Lai, Ming Yan, Yong Jiang, Pengjun Xie, Fei Huang, Jun Zhang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents must synthesize vast web-scale information into insightful reports. Current approaches are plagued by dual-fold limitations: static research pipelines that decouple planning from evidence acquisition and one-shot generation paradigms that easily suffer from long-context failure issues like loss in the middle and hallucinations. To address these challenges, we introduce WebWeaver, a novel dual-agent framework that emulates the human research process. The planner operates in a dynamic cycle, iteratively interleaving evidence acquisition with outline optimization to produce a comprehensive, source-grounded outline linking to a memory bank of evidence. The writer then executes a hierarchical retrieval and writing process, composing the report section by section. By performing targeted retrieval of only the necessary evidence from the memory bank for each part, it effectively mitigates long-context issues. Our framework establishes a new state-of-the-art across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym. These results validate our human-centric, iterative methodology, demonstrating that adaptive planning and focused synthesis are crucial for producing high-quality, reliable, and well-structured reports.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13311v1" target="_blank">Towards General Agentic Intelligence via Environment Scaling</a></h3>
                    <p><strong>Authors:</strong> Runnan Fang, Shihao Cai, Baixuan Li, Jialong Wu, Guangyu Li, Wenbiao Yin, Xinyu Wang, Xiaobin Wang, Liangcai Su, Zhen Zhang, Shibin Wu, Zhengwei Tao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practical, real-world applications. Diverse real-world APIs demand precise, robust function-calling intelligence, which needs agents to develop these capabilities through interaction in varied environments. The breadth of function-calling competence is closely tied to the diversity of environments in which agents are trained. In this work, we scale up environments as a step towards advancing general agentic intelligence. This gives rise to two central challenges: (i) how to scale environments in a principled manner, and (ii) how to effectively train agentic capabilities from experiences derived through interactions with these environments. To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated, systematically broadening the space of function-calling scenarios. We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts. Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13310v1" target="_blank">Scaling Agents via Continual Pre-training</a></h3>
                    <p><strong>Authors:</strong> Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang, Kuan Li, Jialong Wu, Xuanzhong Chen, Zile Qiao, Zhongwang Zhang, Huifeng Yin, Shihao Cai, Runnan Fang, Zhengwei Tao, Wenbiao Yin, Chenxiong Qian, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13309v1" target="_blank">WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents</a></h3>
                    <p><strong>Authors:</strong> Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, Rui Min, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent advances in deep-research systems have demonstrated the potential for AI agents to autonomously discover and synthesize knowledge from external sources. In this paper, we introduce WebResearcher, a novel framework for building such agents through two key components: (1) WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, where agents periodically consolidate findings into evolving reports while maintaining focused workspaces, overcoming the context suffocation and noise contamination that plague existing mono-contextual approaches; and (2) WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation, enabling systematic creation of research tasks that bridge the gap between passive knowledge recall and active knowledge construction. Notably, we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods. Furthermore, our paradigm naturally scales through parallel thinking, enabling concurrent multi-agent exploration for more comprehensive conclusions. Extensive experiments across 6 challenging benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, even surpassing frontier proprietary systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13307v1" target="_blank">High-Dimensional Bayesian Model Comparison in Cosmology with GPU-accelerated Nested Sampling and Neural Emulators</a></h3>
                    <p><strong>Authors:</strong> Toby Lovick, David Yallup, Davide Piras, Alessio Spurio Mancini, Will Handley</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> We demonstrate a GPU-accelerated nested sampling framework for efficient high-dimensional Bayesian inference in cosmology. Using JAX-based neural emulators and likelihoods for cosmic microwave background and cosmic shear analyses, our approach provides parameter constraints and direct calculation of Bayesian evidence. In the 39 dimensional $\Lambda$CDM vs $w_0w_a$ shear analysis, we produce Bayes Factors and a robust error bar in just 2 days on a single A100 GPU, without loss of accuracy. Where CPU-based nested sampling can now be outpaced by methods relying on MCMC sampling and decoupled evidence estimation, we demonstrate that with GPU acceleration nested sampling offers the necessary speed-up to put it on equal computational footing with these methods, especially where reliable model comparison is paramount. We put forward both nested and gradient-based sampling as useful tools for the modern cosmologist, where cutting-edge inference pipelines can yield orders of magnitude improvements in computation time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13305v1" target="_blank">WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, Xinyu Wang, Zile Qiao, Zhen Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CL</p>
                    <p><strong>Summary:</strong> Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents performance and closing the capability gap.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13302v1" target="_blank">Comparing Minimal and Non-Minimal Quintessence Models to 2025 DESI Data</a></h3>
                    <p><strong>Authors:</strong> Husam Adam, Mark P. Hertzberg, Daniel JimÃ©nez-Aguilar, Iman Khan</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc, hep-ph, hep-th</p>
                    <p><strong>Summary:</strong> In this work we examine the 2025 DESI analysis of dark energy, which suggests that dark energy is evolving in time with an increasing equation of state $w$. We explore a wide range of quintessence models, described by a potential function $V(\varphi)$, including: quadratic potentials, quartic hilltops, double wells, cosine functions, Gaussians, inverse powers. We find that while some provide improvement in fitting to the data, compared to a cosmological constant, the improvement is only modest. We then consider non-minimally coupled scalars which can help fit the data by providing an effective equation of state that temporarily obeys $w-1$. Since the scalar is very light, this leads to a fifth force and to time evolution in the effective gravitational strength, which are both tightly constrained by tests of gravity. For a very narrow range of carefully selected non-minimal couplings we are able to evade these bounds, but not for generic values.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13301v1" target="_blank">StyleSculptor: Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance</a></h3>
                    <p><strong>Authors:</strong> Zefan Qu, Zhenwei Wang, Haoyuan Wang, Ke Xu, Gerhard Hancke, Rynson W. H. Lau</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Creating 3D assets that follow the texture and geometry style of existing ones is often desirable or even inevitable in practical applications like video gaming and virtual reality. While impressive progress has been made in generating 3D objects from text or images, creating style-controllable 3D assets remains a complex and challenging problem. In this work, we propose StyleSculptor, a novel training-free approach for generating style-guided 3D assets from a content image and one or more style images. Unlike previous works, StyleSculptor achieves style-guided 3D generation in a zero-shot manner, enabling fine-grained 3D style control that captures the texture, geometry, or both styles of user-provided style images. At the core of StyleSculptor is a novel Style Disentangled Attention (SD-Attn) module, which establishes a dynamic interaction between the input content image and style image for style-guided 3D asset generation via a cross-3D attention mechanism, enabling stable feature fusion and effective style-guided generation. To alleviate semantic content leakage, we also introduce a style-disentangled feature selection strategy within the SD-Attn module, which leverages the variance of 3D feature patches to disentangle style- and content-significant channels, allowing selective feature injection within the attention framework. With SD-Attn, the network can dynamically compute texture-, geometry-, or both-guided features to steer the 3D generation process. Built upon this, we further propose the Style Guided Control (SGC) mechanism, which enables exclusive geometry- or texture-only stylization, as well as adjustable style intensity control. Extensive experiments demonstrate that StyleSculptor outperforms existing baseline methods in producing high-fidelity 3D assets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13298v1" target="_blank">QDFlow: A Python package for physics simulations of quantum dot devices</a></h3>
                    <p><strong>Authors:</strong> Donovan L. Buterakos, Sandesh S. Kalantre, Joshua Ziegler, Jacob M Taylor, Justyna P. Zwolak</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cs.CV, cs.LG, quant-ph</p>
                    <p><strong>Summary:</strong> Recent advances in machine learning (ML) have accelerated progress in calibrating and operating quantum dot (QD) devices. However, most ML approaches rely on access to large, high-quality labeled datasets for training, benchmarking, and validation, with labels capturing key features in the data. Obtaining such datasets experimentally is challenging due to limited data availability and the labor-intensive nature of labeling. QDFlow is an open-source physics simulator for multi-QD arrays that generates realistic synthetic data with ground-truth labels. QDFlow combines a self-consistent Thomas-Fermi solver, a dynamic capacitance model, and flexible noise modules to produce charge stability diagrams and ray-based data closely resembling experiments. With extensive tunable parameters and customizable noise models, QDFlow supports the creation of large, diverse datasets for ML development, benchmarking, and quantum device research.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3756884.3765984" target="_blank">Investigating Seamless Transitions Between Immersive Computational Notebooks and Embodied Data Interactions</a></h3>
                    <p><strong>Authors:</strong> Sungwon In, Eric Krokos, Kirsten Whitley, Chris North, Yalong Yang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> A growing interest in Immersive Analytics (IA) has led to the extension of computational notebooks (e.g., Jupyter Notebook) into an immersive environment to enhance analytical workflows. However, existing solutions rely on the WIMP (windows, icons, menus, pointer) metaphor, which remains impractical for complex data exploration. Although embodied interaction offers a more intuitive alternative, immersive computational notebooks and embodied data exploration systems are implemented as standalone tools. This separation requires analysts to invest considerable effort to transition from one environment to an entirely different one during analytical workflows. To address this, we introduce ICoN, a prototype that facilitates a seamless transition between computational notebooks and embodied data explorations within a unified, fully immersive environment. Our findings reveal that unification improves transition efficiency and intuitiveness during analytical workflows, highlighting its potential for seamless data analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13294v1" target="_blank">Accelerating Protein Molecular Dynamics Simulation with DeepJump</a></h3>
                    <p><strong>Authors:</strong> Allan dos Santos Costa, Manvitha Ponnapati, Dana Rubin, Tess Smidt, Joseph Jacobson</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> q-bio.BM, cs.LG</p>
                    <p><strong>Summary:</strong> Unraveling the dynamical motions of biomolecules is essential for bridging their structure and function, yet it remains a major computational challenge. Molecular dynamics (MD) simulation provides a detailed depiction of biomolecular motion, but its high-resolution temporal evolution comes at significant computational cost, limiting its applicability to timescales of biological relevance. Deep learning approaches have emerged as promising solutions to overcome these computational limitations by learning to predict long-timescale dynamics. However, generalizable kinetics models for proteins remain largely unexplored, and the fundamental limits of achievable acceleration while preserving dynamical accuracy are poorly understood. In this work, we fill this gap with DeepJump, an Euclidean-Equivariant Flow Matching-based model for predicting protein conformational dynamics across multiple temporal scales. We train DeepJump on trajectories of the diverse proteins of mdCATH, systematically studying our models performance in generalizing to long-term dynamics of fast-folding proteins and characterizing the trade-off between computational acceleration and prediction accuracy. We demonstrate the application of DeepJump to ab initio folding, showcasing prediction of folding pathways and native states. Our results demonstrate that DeepJump achieves significant $\approx$1000$\times$ computational acceleration while effectively recovering long-timescale dynamics, providing a stepping stone for enabling routine simulation of proteins.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13293v1" target="_blank">Inferring Soil Drydown Behaviour with Adaptive Bayesian Online Changepoint Analysis</a></h3>
                    <p><strong>Authors:</strong> Mengyi Gong, Christopher Nemeth, Rebecca Killick, Peter Strauss, John Quinton</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> stat.AP, stat.CO, 62P12</p>
                    <p><strong>Summary:</strong> Continuous soil-moisture measurements provide a direct lens on subsurface hydrological processes, notably the post-rainfall drydown phase. Because these records consist of distinct, segment-specific behaviours whose forms and scales vary over time, realistic inference demands a model that captures piecewise dynamics while accommodating parameters that are unknown a priori. Building on Bayesian Online Changepoint Detection (BOCPD), we introduce two complementary extensions: a particle-filter variant that substitutes exact marginalisation with sequential Monte Carlo to enable real-time inference when critical parameters cannot be integrated out analytically, and an online-gradient variant that embeds stochastic gradient updates within BOCPD to learn application-relevant parameters on the fly without prohibitive computational cost. After validating both algorithms on synthetic data that replicate the temporal structure of field observations-detailing hyperparameter choices, priors, and cost-saving strategies-we apply them to soil-moisture series from experimental sites in Austria and the United States, quantifying site-specific drydown rates and demonstrating the advantages of our adaptive framework over static models.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3756884.3766011" target="_blank">Towards an Embodied Composition Framework for Organizing Immersive Computational Notebooks</a></h3>
                    <p><strong>Authors:</strong> Sungwon In, Eric Krokos, Kirsten Whitley, Chris North, Yalong Yang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> As immersive technologies evolve, immersive computational notebooks offer new opportunities for interacting with code, data, and outputs. However, scaling these environments remains a challenge, particularly when analysts manually arrange large numbers of cells to maintain both execution logic and visual coherence. To address this, we introduce an embodied composition framework, facilitating organizational processes in the context of immersive computational notebooks. To evaluate the effectiveness of the embodied composition framework, we conducted a controlled user study comparing manual and embodied composition frameworks in an organizational process. The results show that embodied composition frameworks significantly reduced user effort and decreased completion time. However, the design of the triggering mechanism requires further refinement. Our findings highlight the potential of embodied composition frameworks to enhance the scalability of the organizational process in immersive computational notebooks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13290v1" target="_blank">Uchimata: a toolkit for visualization of 3D genome structures on the web and in computational notebooks</a></h3>
                    <p><strong>Authors:</strong> David KouÅ™il, Trevor Manz, Tereza Clarence, Nils Gehlenborg</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> q-bio.GN</p>
                    <p><strong>Summary:</strong> Summary: Uchimata is a toolkit for visualization of 3D structures of genomes. It consists of two packages: a Javascript library facilitating the rendering of 3D models of genomes, and a Python widget for visualization in Jupyter Notebooks. Main features include an expressive way to specify visual encodings, and filtering of 3D genome structures based on genomic semantics and spatial aspects. Uchimata is designed to be highly integratable with biological tooling available in Python. Availability and Implementation: Uchimata is released under the MIT License. The Javascript library is available on NPM, while the widget is available as a Python package hosted on PyPI. The source code for both is available publicly on Github (https://github.com/hms-dbmi/uchimata and https://github.com/hms-dbmi/uchimata-py). The documentation with examples is hosted at https://hms-dbmi.github.io/uchimata/ Contact: david_kouril@hms.harvard.edu or nils@hms.harvard.edu.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13289v1" target="_blank">Image Realness Assessment and Localization with Multimodal Features</a></h3>
                    <p><strong>Authors:</strong> Lovish Kaushik, Agnij Biswas, Somdyuti Paul</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> A reliable method of quantifying the perceptual realness of AI-generated images and identifying visually inconsistent regions is crucial for practical use of AI-generated images and for improving photorealism of generative AI via realness feedback during training. This paper introduces a framework that accomplishes both overall objective realness assessment and local inconsistency identification of AI-generated images using textual descriptions of visual inconsistencies generated by vision-language models trained on large datasets that serve as reliable substitutes for human annotations. Our results demonstrate that the proposed multimodal approach improves objective realness prediction performance and produces dense realness maps that effectively distinguish between realistic and unrealistic spatial regions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13288v1" target="_blank">Shapes of Cognition for Computational Cognitive Modeling</a></h3>
                    <p><strong>Authors:</strong> Marjorie McShane, Sergei Nirenburg, Sanjay Oruganti, Jesse English</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.RO</p>
                    <p><strong>Summary:</strong> Shapes of cognition is a new conceptual paradigm for the computational cognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are remembered constellations of sensory, linguistic, conceptual, episodic, and procedural knowledge that allow agents to cut through the complexity of real life the same way as people do: by expecting things to be typical, recognizing patterns, acting by habit, reasoning by analogy, satisficing, and generally minimizing cognitive load to the degree situations permit. Atypical outcomes are treated using shapes-based recovery methods, such as learning on the fly, asking a human partner for help, or seeking an actionable, even if imperfect, situational understanding. Although shapes is an umbrella term, it is not vague: shapes-based modeling involves particular objectives, hypotheses, modeling strategies, knowledge bases, and actual models of wide-ranging phenomena, all implemented within a particular cognitive architecture. Such specificity is needed both to vet our hypotheses and to achieve our practical aims of building useful agent systems that are explainable, extensible, and worthy of our trust, even in critical domains. However, although the LEIA example of shapes-based modeling is specific, the principles can be applied more broadly, giving new life to knowledge-based and hybrid AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13282v1" target="_blank">ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement</a></h3>
                    <p><strong>Authors:</strong> Ali Salamatian, Amirhossein Abaskohi, Wan-Cyuan Fan, Mir Rayat Imtiaz Hossain, Leonid Sigal, Giuseppe Carenini</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Charts are a crucial visual medium for communicating and representing information. While Large Vision-Language Models (LVLMs) have made progress on chart question answering (CQA), the task remains challenging, particularly when models attend to irrelevant regions of the chart. In this work, we present ChartGaze, a new eye-tracking dataset that captures human gaze patterns during chart reasoning tasks. Through a systematic comparison of human and model attention, we find that LVLMs often diverge from human gaze, leading to reduced interpretability and accuracy. To address this, we propose a gaze-guided attention refinement that aligns image-text attention with human fixations. Our approach improves both answer accuracy and attention alignment, yielding gains of up to 2.56 percentage points across multiple models. These results demonstrate the promise of incorporating human gaze to enhance both the reasoning quality and interpretability of chart-focused LVLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13281v1" target="_blank">RepIt: Representing Isolated Targets to Steer Language Models</a></h3>
                    <p><strong>Authors:</strong> Vincent Siu, Nathan W. Henry, Nicholas Crispino, Yang Liu, Dawn Song, Chenguang Wang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> While activation steering in large language models (LLMs) is a growing area of research, methods can often incur broader effects than desired. This motivates isolation of purer concept vectors to enable targeted interventions and understand LLM behavior at a more granular level. We present RepIt, a simple and data-efficient framework for isolating concept-specific representations. Across five frontier LLMs, RepIt enables precise interventions: it selectively suppresses refusal on targeted concepts while preserving refusal elsewhere, producing models that answer WMD-related questions while still scoring as safe on standard benchmarks. We further show that the corrective signal localizes to just 100-200 neurons and that robust target representations can be extracted from as few as a dozen examples on a single A6000. This efficiency raises a dual concern: manipulations can be performed with modest compute and data to extend to underrepresented data-scarce topics while evading existing benchmarks. By disentangling refusal vectors with RepIt, this work demonstrates that targeted interventions can counteract overgeneralization, laying the foundation for more granular control of model behavior.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13280v1" target="_blank">Generalized Quantum Steins Lemma and Reversibility of Quantum Resource Theories for Classical-Quantum Channels</a></h3>
                    <p><strong>Authors:</strong> Bjarne Bergh, Nilanjana Datta, Anirudh Khaitan</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> quant-ph, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We extend the recent proof of the Generalized Quantum Steins Lemma by Hayashi and Yamasaki [arXiv:2408.02722] to classical-quantum (c-q) channels. We analyze the composite hypothesis testing problem of testing a c-q channel $\mathcal{E}^{\otimes n}$ against a sequence of sets of c-q channels $(\mathcal{S}_n)_n$ (satisfying certain natural assumptions), under parallel strategies. We prove that the optimal asymptotic asymmetric error exponent is given by the regularization of Umegaki channel divergence, minimized over $\mathcal{S}_n$. This allows us to prove the reversibility of resource theories of classical-quantum channels in a natural framework, where the distance between channels (and hence also the notion of approximate interconvertibility of channels) is measured in diamond norm, and the set of free operations is the set of all asymptotically resource non-generating superchannels. The results we obtain are similar to the ones in the concurrent and independent work by Hayashi and Yamasaki [arXiv:2509.07271]. However the proof of the direct part of the GQSL uses different arguments and techniques to deal with the challenges that arise from dealing with c-q channels.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13279v1" target="_blank">HARMONIC: A Content-Centric Cognitive Robotic Architecture</a></h3>
                    <p><strong>Authors:</strong> Sanjay Oruganti, Sergei Nirenburg, Marjorie McShane, Jesse English, Michael K. Roberts, Christian Arndt, Carlos Gonzalez, Mingyo Seo, Luis Sentis</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> This paper introduces HARMONIC, a cognitive-robotic architecture designed for robots in human-robotic teams. HARMONIC supports semantic perception interpretation, human-like decision-making, and intentional language communication. It addresses the issues of safety and quality of results; aims to solve problems of data scarcity, explainability, and safety; and promotes transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are demonstrated, each implemented in both a high-fidelity simulation environment and on physical robotic platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13277v1" target="_blank">Odd-parity longitudinal magnetoconductivity in time-reversal symmetry broken materials</a></h3>
                    <p><strong>Authors:</strong> Sunit Das, Akash Adhikary, Divya Sahani, Aveek Bid, Amit Agarwal</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Magnetotransport measurements are a sensitive probe of symmetry and electronic structure in quantum materials. While conventional metals exhibit longitudinal magnetoconductivity that is even in a magnetic field ($B$) for small $B$, we show that magnetic materials which intrinsically break time-reversal symmetry (TRS) show an {\it odd-parity magnetoconductivity} (OMC), with a leading linear-$B$ response. Using semiclassical transport theory, we derive explicit expressions for the longitudinal and transverse conductivities and identify their origin in Berry curvature and orbital magnetic moment. Crystalline symmetry analysis shows that longitudinal OMC follows the same point-group constraints as the anomalous Hall effect, while transverse OMC obeys distinct rules, providing an independent probe of TRS breaking. In the large $B$ quantum oscillation regime, we uncover both odd- and even-$B$ contributions, demonstrating OMC beyond the semiclassical picture. Explicit calculations in valley-polarized gapped graphene show that OMC peaks near the band edges, vanish in the band gap and follow the temperature dependence of the magnetic order parameter. Our results explain the odd-parity magnetoresistance recently observed in magnetized graphene and establish OMC as a robust transport signature of intrinsic TRS breaking in metals.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13275v1" target="_blank">Coherence and Dimensionality Witnesses for Fractional OAM Modes</a></h3>
                    <p><strong>Authors:</strong> A. L. S. Santos Junior, I. Prego, M. Gil de Oliveira, A. C. Barbosa, B. P. da Silva, D. J. Brod, E. F. GalvÃ£o, A. Z. Khoury</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> quant-ph, physics.optics</p>
                    <p><strong>Summary:</strong> We characterize sets of fractional orbital angular momentum (OAM) modes of a light beam using unitary-invariant properties encoded by two-mode overlaps. Using basis-independent coherence and dimension witnesses, we experimentally certify, on a triple of fractional modes, both the presence of coherence and that the states necessarily span a space of dimension 3. We propose and implement a practical, fast experimental method to extract two-mode overlaps requiring only a single intensity image per interference pair. These results lay the groundwork for using fractional OAM states in high-dimensional quantum information protocols.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13271v1" target="_blank">Runaway electron interactions with whistler waves in tokamak plasmas: energy-dependent transport scaling</a></h3>
                    <p><strong>Authors:</strong> Yashika Ghai, D. Del-Castillo-Negrete, D. A. Spong, M. T. Beidler</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> physics.plasm-ph</p>
                    <p><strong>Summary:</strong> Resonant interactions between high energy runaway electrons (REs) and whistler waves are a promising mechanism for RE mitigation in tokamak plasmas. While prior studies have largely relied on quasi-linear diffusion models in simplified geometries, we present a first-principles-informed framework that models RE-whistler interactions in a 3D tokamak equilibrium. This is achieved by coupling AORSA, which computes whistler eigenmodes for a given tokamak plasma equilibrium, and KORC, a kinetic orbit code that tracks full orbit RE trajectories in prescribed wave fields. Our results demonstrate that REs undergo scattering to large pitch angles and exhibit anomalous diffusion in both pitch-angle and kinetic energy space. Crucially, we observe a transition between diffusive, sub-diffusive, and super-diffusive transport regimes as a function of initial RE energy - an effect not captured by existing quasi-linear models. This anomalous transport behavior represents a significant advancement in understanding RE dynamics in the presence of wave - particle interactions. By identifying the conditions under which anomalous diffusion arises, this work lays the theoretical foundation for designing targeted, wave-based mitigation strategies in future tokamak experiments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13270v1" target="_blank">RadGame: An AI-Powered Platform for Radiology Education</a></h3>
                    <p><strong>Authors:</strong> Mohammed Baharoon, Siavash Raissi, John S. Jun, Thibault Heintz, Mahmoud Alabbad, Ali Alburkani, Sung Eun Kim, Kent Kleinschmidt, Abdulrahman O. Alhumaydhi, Mohannad Mohammed G. Alghamdi, Jeremy Francis Palacio, Mohammed Bukhaytan, Noah Michael Prudlo, Rithvik Akula, Brady Chrisler, Benjamin Galligos, Mohammed O. Almutairi, Mazeen Mohammed Alanazi, Nasser M. Alrashdi, Joel Jihwan Hwang, Sri Sai Dinesh Jaliparthi, Luke David Nelson, Nathaniel Nguyen, Sathvik Suryadevara, Steven Kim, Mohammed F. Mohammed, Yevgeniy R. Semenov, Kun-Hsing Yu, Abdulrhman Aljouie, Hassan AlOmaish, Adam Rodman, Pranav Rajpurkar</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> We introduce RadGame, an AI-powered gamified platform for radiology education that targets two core skills: localizing findings and generating reports. Traditional radiology training is based on passive exposure to cases or active practice with real-time input from supervising radiologists, limiting opportunities for immediate and scalable feedback. RadGame addresses this gap by combining gamification with large-scale public datasets and automated, AI-driven feedback that provides clear, structured guidance to human learners. In RadGame Localize, players draw bounding boxes around abnormalities, which are automatically compared to radiologist-drawn annotations from public datasets, and visual explanations are generated by vision-language models for user missed findings. In RadGame Report, players compose findings given a chest X-ray, patient age and indication, and receive structured AI feedback based on radiology report generation metrics, highlighting errors and omissions compared to a radiologists written ground truth report from public datasets, producing a final performance and style score. In a prospective evaluation, participants using RadGame achieved a 68% improvement in localization accuracy compared to 17% with traditional passive methods and a 31% improvement in report-writing accuracy compared to 4% with traditional methods after seeing the same cases. RadGame highlights the potential of AI-driven gamification to deliver scalable, feedback-rich radiology training and reimagines the application of medical AI resources in education.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13269v1" target="_blank">A Robust Modular Quantum Processor</a></h3>
                    <p><strong>Authors:</strong> Ramesh Bhandari</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We explore the concept of redundancy of critical elements in a quantum computing architecture to circumvent disruption of quantum operations due to a failure of such an element, for example, from a catastrophic cosmic ray event. We illustrate this concept with reference to a recently proposed superconducting modular quantum architecture with a star-like configuration, which has a router at the center that enables superconducting qubit interactions across various modules. Regarding this router as a vital element, we propose a double-star configuration, where a loss of one router is backed by the second one. We also examine the usefulness of this double-star configuration under normal conditions, namely, when the quantum hardware has been rendered safe against cosmic rays due to other mitigating actions like shielding or movement to an underground facility. Simultaneous two qubit-pair interactions like two simultaneous CZ gates and multiqubit gates like CCZS are then easily facilitated.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13265v1" target="_blank">Beyond Private or Public: Large Language Models as Quasi-Public Goods in the AI Economy</a></h3>
                    <p><strong>Authors:</strong> Yukun Zhang, TianYang Zhang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This paper conceptualizes Large Language Models (LLMs) as a form of mixed public goods within digital infrastructure, analyzing their economic properties through a comprehensive theoretical framework. We develop mathematical models to quantify the non-rivalry characteristics, partial excludability, and positive externalities of LLMs. Through comparative analysis of open-source and closed-source development paths, we identify systematic differences in resource allocation efficiency, innovation trajectories, and access equity. Our empirical research evaluates the spillover effects and network externalities of LLMs across different domains, including knowledge diffusion, innovation acceleration, and industry transformation. Based on these findings, we propose policy recommendations for balancing innovation incentives with equitable access, including public-private partnership mechanisms, computational resource democratization, and governance structures that optimize social welfare. This interdisciplinary approach contributes to understanding the economic nature of foundation AI models and provides policy guidance for their development as critical digital infrastructure</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13262v1" target="_blank">Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning</a></h3>
                    <p><strong>Authors:</strong> Zhizhong Zhao, Ke Chen</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Uncertainty quantification (UQ) is vital for trustworthy deep learning, yet existing methods are either computationally intensive, such as Bayesian or ensemble methods, or provide only partial, task-specific estimates, such as single-forward-pass techniques. In this paper, we propose a post-hoc single-forward-pass framework that jointly captures aleatoric and epistemic uncertainty without modifying or retraining pretrained models. Our method applies \emph{Split-Point Analysis} (SPA) to decompose predictive residuals into upper and lower subsets, computing \emph{Mean Absolute Residuals} (MARs) on each side. We prove that, under ideal conditions, the total MAR equals the harmonic mean of subset MARs; deviations define a novel \emph{Self-consistency Discrepancy Score} (SDS) for fine-grained epistemic estimation across regression and classification. For regression, side-specific quantile regression yields prediction intervals with improved empirical coverage, which are further calibrated via SDS. For classification, when calibration data are available, we apply SPA-based calibration identities to adjust the softmax outputs and then compute predictive entropy on these calibrated probabilities. Extensive experiments on diverse regression and classification benchmarks demonstrate that our framework matches or exceeds several state-of-the-art UQ methods while incurring minimal overhead. Our source code is available at https://github.com/zzz0527/SPC-UQ.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13259v1" target="_blank">A generalized reduction scheme for the Stochastic Weighted Particle Method</a></h3>
                    <p><strong>Authors:</strong> Matthew Goeckner, Donovan Harcey, Rainier Q Pederson, Axel Niyonzima, John Zweck</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, math-ph, math.MP, 65C05, 65Z05, 76P05, 82C22</p>
                    <p><strong>Summary:</strong> The Stochastic Weighted Particle Method (SWPM) of Rjasanow and Wagner is a generalization of the Direct Simulation Monte Carlo method for computing the probability density function of the velocities of a system of interacting particles for applications that include rarefied gas dynamics and plasma processing systems. Key components of a SWPM simulation are a particle grouping technique and particle reduction scheme. These are periodically applied to reduce the computational cost of simulations due to the gradual increase in the number of stochastic particles. A general framework for designing particle reduction schemes is introduced that enforces the preservation of a prescribed set of moments of the distribution through the construction and explicit solution of a system of linear equations for particle weights in terms of particle velocities and the moments to be preserved. This framework is applied to preserve all moments of the distribution up to order three. Numerical simulations are performed to verify the scheme and quantify the degree to which even higher-order moments and tail functionals are preserved. These results reveal an unexpected trade off between the preservation of these higher-order moments and tail functionals.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.4204/EPTCS.428" target="_blank">Proceedings of the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification</a></h3>
                    <p><strong>Authors:</strong> Giorgio Bacci, Adrian Francalanza</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LO</p>
                    <p><strong>Summary:</strong> This volume contains the proceedings of GandALF 2025, the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification. GandALF 2025 took place on 16-17th September 2025, in Valletta, Malta. The aim of GandALF 2025 is to bring together researchers from academia and industry who are actively working in the fields of Games, Automata, Logics, and Formal Verification. The idea is to cover an ample spectrum of themes, ranging from theory to applications, and stimulate cross-fertilisation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13255v1" target="_blank">ResidualViT for Efficient Temporally Dense Video Encoding</a></h3>
                    <p><strong>Authors:</strong> Mattia Soldan, Fabian Caba Heilbron, Bernard Ghanem, Josef Sivic, Bryan Russell</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.IR, eess.IV</p>
                    <p><strong>Summary:</strong> Several video understanding tasks, such as natural language temporal video grounding, temporal activity localization, and audio description generation, require temporally dense reasoning over frames sampled at high temporal resolution. However, computing frame-level features for these tasks is computationally expensive given the temporal resolution requirements. In this paper, we make three contributions to reduce the cost of computing features for temporally dense tasks. First, we introduce a vision transformer (ViT) architecture, dubbed ResidualViT, that leverages the large temporal redundancy in videos to efficiently compute temporally dense frame-level features. Our architecture incorporates (i) learnable residual connections that ensure temporal consistency across consecutive frames and (ii) a token reduction module that enhances processing speed by selectively discarding temporally redundant information while reusing weights of a pretrained foundation model. Second, we propose a lightweight distillation strategy to approximate the frame-level features of the original foundation model. Finally, we evaluate our approach across four tasks and five datasets, in both zero-shot and fully supervised settings, demonstrating significant reductions in computational cost (up to 60%) and improvements in inference speed (up to 2.5x faster), all while closely approximating the accuracy of the original foundation model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13253v1" target="_blank">Evolution of Programmers Trust in Generative AI Programming Assistants</a></h3>
                    <p><strong>Authors:</strong> Anshul Shah, Thomas Rexin, Elena Tomson, Leo Porter, William G. Griswold, Adalbert Gerald Soosai Raj</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.SE</p>
                    <p><strong>Summary:</strong> Motivation. Trust in generative AI programming assistants is a vital attitude that impacts how programmers use those programming assistants. Programmers that are over-trusting may be too reliant on their tools, leading to incorrect or vulnerable code; programmers that are under-trusting may avoid using tools that can improve their productivity and well-being. Methods. Since trust is a dynamic attitude that may change over time, this study aims to understand programmers evolution of trust after immediate (one hour) and extended (10 days) use of GitHub Copilot. We collected survey data from 71 upper-division computer science students working on a legacy code base, representing a population that is about to enter the workforce. In this study, we quantitatively measure student trust levels and qualitatively uncover why student trust changes. Findings. Student trust, on average, increased over time. After completing a project with Copilot, however, students felt that Copilot requires a competent programmer to complete some tasks manually. Students mentioned that seeing Copilots correctness, understanding how Copilot uses context from the code base, and learning some basics of natural language processing contributed to their elevated trust. Implications. Our study helps instructors and industry managers understand the factors that influence how students calibrate their trust with AI assistants. We make four pedagogical recommendations, which are that CS educators should 1) provide opportunities for students to work with Copilot on challenging software engineering tasks to calibrate their trust, 2) teach traditional skills of comprehending, debugging, and testing so students can verify output, 3) teach students about the basics of natural language processing, and 4) explicitly introduce and demonstrate the range of features available in Copilot.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13251v1" target="_blank">Large Language Model-assisted Meta-optimizer for Automated Design of Constrained Evolutionary Algorithm</a></h3>
                    <p><strong>Authors:</strong> Xu Yang, Rui Wang, Kaiwen Li, Wenhua Li, Weixiong Huang</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.NE</p>
                    <p><strong>Summary:</strong> Meta-black-box optimization has been significantly advanced through the use of large language models (LLMs), yet in fancy on constrained evolutionary optimization. In this work, AwesomeDE is proposed that leverages LLMs as the strategy of meta-optimizer to generate update rules for constrained evolutionary algorithm without human intervention. On the meanwhile, $RTO^2H$ framework is introduced for standardize prompt design of LLMs. The meta-optimizer is trained on a diverse set of constrained optimization problems. Key components, including prompt design and iterative refinement, are systematically analyzed to determine their impact on design quality. Experimental results demonstrate that the proposed approach outperforms existing methods in terms of computational efficiency and solution accuracy. Furthermore, AwesomeDE is shown to generalize well across distinct problem domains, suggesting its potential for broad applicability. This research contributes to the field by providing a scalable and data-driven methodology for automated constrained algorithm design, while also highlighting limitations and directions for future work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13250v1" target="_blank">Intelligent Vacuum Thermoforming Process</a></h3>
                    <p><strong>Authors:</strong> Andi Kuswoyo, Christos Margadji, Sebastian W. Pattinson</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG, I.2.10; I.4.9</p>
                    <p><strong>Summary:</strong> Ensuring consistent quality in vacuum thermoforming presents challenges due to variations in material properties and tooling configurations. This research introduces a vision-based quality control system to predict and optimise process parameters, thereby enhancing part quality with minimal data requirements. A comprehensive dataset was developed using visual data from vacuum-formed samples subjected to various process parameters, supplemented by image augmentation techniques to improve model training. A k-Nearest Neighbour algorithm was subsequently employed to identify adjustments needed in process parameters by mapping low-quality parts to their high-quality counterparts. The model exhibited strong performance in adjusting heating power, heating time, and vacuum time to reduce defects and improve production efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13247v1" target="_blank">Demonstration of a Logical Architecture Uniting Motion and In-Place Entanglement: Shors Algorithm, Constant-Depth CNOT Ladder, and Many-Hypercube Code</a></h3>
                    <p><strong>Authors:</strong> Rich Rines, Benjamin Hall, Mariesa H. Teo, Joshua Viszlai, Daniel C. Cole, David Mason, Cameron Barker, Matt J. Bedalov, Matt Blakely, Tobias Bothwell, Caitlin Carnahan, Frederic T. Chong, Samuel Y. Eubanks, Brian Fields, Matthew Gillette, Palash Goiporia, Pranav Gokhale, Garrett T. Hickman, Marin Iliev, Eric B. Jones, Ryan A. Jones, Kevin W. Kuper, Stephanie Lee, Martin T. Lichtman, Kevin Loeffler, Nate Mackintosh, Farhad Majdeteimouri, Peter T. Mitchell, Thomas W. Noel, Ely Novakoski, Victory Omole, David Owusu-Antwi, Alexander G. Radnaev, Anthony Reiter, Mark Saffman, Bharath Thotakura, Teague Tomesh, Ilya Vinogradov</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Logical qubits are considered an essential component for achieving utility-scale quantum computation. Multiple recent demonstrations of logical qubits on neutral atoms have relied on coherent qubit motion into entangling zones. However, this architecture requires motion prior to every entangling gate, incurring significant cost in wall clock runtime and motion-related error accumulation. We propose and experimentally realize an alternative architecture which unites qubit motion and in-place entanglement via nearest-neighbor gates. Our approach maintains all-to-all connectivity, while minimizing qubit motion overheads. We demonstrate three key results on Infleqtions Sqale QPU, which hosts an array of 114 neutral atom qubits. First, we perform a logical qubit realization of a pre-compiled variant of Shors Algorithm. We find better logical-than-physical performance over a range of settings including with loss correction and leakage detection. Second, we introduce a technique for performing CNOT ladders with depth independent of both the number of logical qubits N and the code distance d. In proof-of-principle experiments with 8 and 12 logical qubits, we find ~4x reduction in error via the logical encodings. Third, we experimentally realize initialization of the [[16, 4, 4]] many-hypercube QEC code. All three results benefit from optimized compilation via Superstaq, as well as our underlying architecture uniting motion and in-place entanglement. This architecture offers a path to reducing the overhead of utility-scale quantum applications relative to architectures based on entangling zones.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13246v1" target="_blank">Effective conduction-band model for zincblende III-V semiconductors in the presence of strain: tuning the properties of bulk crystals and nanostructures</a></h3>
                    <p><strong>Authors:</strong> Samuel D. Escribano, Alfredo Levy Yeyati, Elsa Prada</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Strain provides a powerful knob to tailor the electronic properties of semiconductors. Simple yet accurate approximations that capture strain effects in demanding simulations of mesoscopic nanostructures are therefore highly desirable. However, for III-V compounds, key materials for quantum applications, such approaches remain comparatively underdeveloped. In this work, we derive a compact, effective Hamiltonian that describes the conduction band of zincblende III-V semiconductors incorporating strain effects. Starting from the eight-band k$\cdot$p model with Bir-Pikus corrections, we perform a folding-down procedure to obtain analytical expressions for conduction-band strain-renormalized parameters, including the effective mass, chemical potential, spin-orbit coupling, and $g$-factor. The model reproduces full multiband results under small to moderate strain, while retaining a form suitable for device-scale calculations. We benchmark the model for bulk deformations and apply it to representative nanostructures, such as core.shell nanowires and planar heterostructures. Our results provide a practical and versatile tool for incorporating strain into the design of III-V semiconductor devices, enabling reliable predictions of their properties with direct implications for spintronic, straintronic, optoelectronic, and topological quantum technologies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13245v1" target="_blank">Smallness of neutrino masses and leptogenesis in 331 composite Higgs model</a></h3>
                    <p><strong>Authors:</strong> Roman Nevzorov</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> hep-ph, gr-qc, hep-ex, hep-lat, hep-th</p>
                    <p><strong>Summary:</strong> We consider 331 composite Higgs model (CHM3) in which the Lagrangian of the strongly coupled sector is invariant with respect to global SU(3)_C \times SU(3)\times U(1)_6 symmetry that can originate from SU(6) subgroup of E_6 and contains the gauge group of the standard model (SM) as a subgroup. The breakdown of the approximate SU(3)\times U(1)_6 symmetry down to SU(2)_W\times U(1)_Y subgroup around the scale f\sim 10 TeV results in a set of pseudo--Nambu--Goldstone bosons (pNGBs) that, in particular, involves Higgs doublet. The generation of the masses of the SM fermions in the CHM3 is discussed. We argue that an approximate discrete Z_2 symmetry may give rise to tiny masses of the left-handed neutrinos and several composite fermions with masses 1-2 TeV. The lepton and baryon asymmetries can be generated within the CHM3 via the out--of equilibrium decays of extra Majorana particle into the Higgs doublet and these composite fermions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13244v1" target="_blank">Evaluating LLM Alignment on Personality Inference from Real-World Interview Data</a></h3>
                    <p><strong>Authors:</strong> Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) are increasingly deployed in roles requiring nuanced psychological understanding, such as emotional support agents, counselors, and decision-making assistants. However, their ability to interpret human personality traits, a critical aspect of such applications, remains unexplored, particularly in ecologically valid conversational settings. While prior work has simulated LLM personas using discrete Big Five labels on social media data, the alignment of LLMs with continuous, ground-truth personality assessments derived from natural interactions is largely unexamined. To address this gap, we introduce a novel benchmark comprising semi-structured interview transcripts paired with validated continuous Big Five trait scores. Using this dataset, we systematically evaluate LLM performance across three paradigms: (1) zero-shot and chain-of-thought prompting with GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA architectures, and (3) regression using static embeddings from pretrained BERT and OpenAIs text-embedding-3-small. Our results reveal that all Pearson correlations between model predictions and ground-truth personality traits remain below 0.26, highlighting the limited alignment of current LLMs with validated psychological constructs. Chain-of-thought prompting offers minimal gains over zero-shot, suggesting that personality inference relies more on latent semantic representation than explicit reasoning. These findings underscore the challenges of aligning LLMs with complex human attributes and motivate future work on trait-specific prompting, context-aware modeling, and alignment-oriented fine-tuning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13243v1" target="_blank">Investigating the Performance of EKF, UKF, and PF for Quadrotor Position Estimation in Hurricane Wind Disturbances</a></h3>
                    <p><strong>Authors:</strong> Ahmed A. Elgohary, Benjamin Gwinnell, Josh Augustine</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> math.DS</p>
                    <p><strong>Summary:</strong> Natural disasters, such as hurricanes and typhoons, pose significant challenges to public safety and infrastructure. While government agencies rely on multi million dollar UAV systems for storm data collection and disaster response, smaller drones lack the ability to autonomously adapt to rapidly changing environmental conditions, such as turbulent winds. This project investigates the implementation of advanced state estimation filters, Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF), and Particle Filter (PF), to enhance the control and adaptability of quadrotor drones in uncertain wind profiles modeled by Von Karman turbulence. While the EKF relies on linearization techniques using the Taylor series expansion, which can struggle under high nonlinearity, the UKF leverages sigma points for better performance in nonlinear systems without requiring Jacobian computations. The PF, on the other hand, addresses non-Gaussian noise and severe nonlinearities by employing a large number of particles, albeit at a high computational cost. To enhance accuracy and minimize estimation errors, a genetic algorithm (GA) was employed to optimally tune the process and measurement noise covariances (Q and R matrices) as well as UKF specific parameters alpha, beta, and kappa. This study highlights the tradeoff between accuracy, computational efficiency, and smoothing capabilities across these filters. Despite its robustness, the PF suffered from computational inefficiencies due to the high state dimensionality, while the EKF demonstrated faster computation but lower adaptability in nonlinear conditions. The UKF emerged as a balanced approach, achieving superior performance in capturing dynamic wind disturbances.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13242v1" target="_blank">Band geometric transverse current driven by inhomogeneous AC electric field</a></h3>
                    <p><strong>Authors:</strong> M. Maneesh Kumar, Sanjay Sarkar, Amit Agarwal</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> We develop a semiclassical theory for electron wavepacket dynamics in the presence of an inhomogeneous AC electric field. While static electric-field gradients are known to generate charge transport governed by the quantum metric, we show that AC field gradients induce an additional geometric current that vanishes in the DC limit. This response originates from a novel band-geometric quantity, the higher-order connection (HOC) tensor, constructed from cubic products of interband Berry connections. We derive explicit expressions for the AC current and identify the symmetry conditions under which it arises. Remarkably, inhomogeneous AC fields can generate an anomalous Hall-like response even in nonmagnetic systems. Applying the theory to Bernal-stacked bilayer graphene, we demonstrate that the HOC-induced response produces a measurable Hall current peaking at band edges. These results establish inhomogeneous AC fields as a powerful probe of higher-order band geometric quantities beyond Berry curvature and the quantum metric.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13241v1" target="_blank">Short-Duration Gravitational Wave Burst Detection using Convolutional Neural Network</a></h3>
                    <p><strong>Authors:</strong> Matteo Pracchia, Sacha Peters, Maxime Fays</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> Detecting unmodeled gravitational wave (GW) bursts presents significant challenges due to the lack of accurate waveform templates required for matched-filtering techniques. A primary difficulty lies in distinguishing genuine signals from transient noise. Machine learning approaches, particularly convolutional neural networks (CNNs), offer promising alternatives for this classification problem. This paper presents a CNN-based pipeline for detecting short GW bursts (duration $ 10~\mathrm{s}$), adapted from an existing framework designed for longer-duration events. The CNN has been trained on core-collapse supernova (CCSN) gravitational waveform models injected into simulated Gaussian noise. The network successfully identifies these signals and generalizes to CCSN waveforms not included in the training set, showing the potential of U-Net architectures for detecting short-duration gravitational wave transients across diverse astrophysical scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13238v1" target="_blank">On the Hardness of Order Finding and Equivalence Testing for ROABPs</a></h3>
                    <p><strong>Authors:</strong> C. Ramya, Pratik Shastri</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.CC</p>
                    <p><strong>Summary:</strong> The complexity of representing a polynomial by a Read-Once Oblivious Algebraic Branching Program (ROABP) is highly dependent on the chosen variable ordering. Bhargava et al. prove that finding the optimal ordering is NP-hard, and provide some evidence (based on the Small Set Expansion hypothesis) that it is also hard to approximate the optimal ROABP width. In another work, Baraskar et al. show that it is NP-hard to test whether a polynomial is in the $\mathrm{GL}_n$ orbit of a polynomial of sparsity at most $s$. Building upon these works, we show the following results: first, we prove that approximating the minimum ROABP width up to any constant factor is NP-hard, when the input is presented as a circuit. This removes the reliance on stronger conjectures in the previous work. Second, we show that testing if an input polynomial given in the sparse representation is in the affine $\mathrm{GL}_n$ orbit of a width-$w$ ROABP is NP-hard. Furthermore, we show that over fields of characteristic $0$, the problem is NP-hard even when the input polynomial is homogeneous. This provides the first NP-hardness results for membership testing for a dense subclass of polynomial sized algebraic branching programs (VBP). Finally, we locate the source of hardness for the order finding problem at the lowest possible non-trivial degree, proving that the problem is NP-hard even for quadratic forms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13234v1" target="_blank">Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy</a></h3>
                    <p><strong>Authors:</strong> Nadim Barakat, William Lotter</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV, cs.HC</p>
                    <p><strong>Summary:</strong> Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI systems can expand access to fundus photography screening. Current FDA-cleared systems primarily provide binary referral outputs, where this minimal output may limit clinical trust and utility. Yet, determining the most effective output format to enhance clinician-AI performance is an empirical challenge that is difficult to assess at scale. We evaluated multimodal large language models (MLLMs) for DR detection and their ability to simulate clinical AI assistance across different output types. Two models were tested on IDRiD and Messidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source medical model. Experiments included: (1) baseline evaluation, (2) simulated AI assistance with synthetic predictions, and (3) actual AI-to-AI collaboration where GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at baseline, achieving higher sensitivity and AUROC, while GPT-4o showed near-perfect specificity but low sensitivity. Both models adjusted predictions based on simulated AI inputs, but GPT-4os performance collapsed with incorrect ones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o achieved strong results when guided by MedGemmas descriptive outputs, even without direct image access (AUROC up to 0.96). These findings suggest MLLMs may improve DR screening pipelines and serve as scalable simulators for studying clinical AI assistance across varying output configurations. Open, lightweight models such as MedGemma may be especially valuable in low-resource settings, while descriptive outputs could enhance explainability and clinician trust in clinical workflows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13233v1" target="_blank">Ultrafast non-adiabatic molecular energy conversion into photons induced by quantized electromagnetic fields</a></h3>
                    <p><strong>Authors:</strong> Arley FlÃ³rez LÃ³pez, Johan F. Triana, JosÃ© Luis Sanz-Vicario</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Molecular polaritons within the mid-infrared regime have emerged as a source for modifying and manipulating molecular and photonic properties. However, the development of new methodologies for photon generation is still a challenge in nanophotonics. We propose a molecular model based on the Holstein-quantum-Rabi Hamiltonian, which also incorporates realistic dipole moments and non-adiabatic couplings among electronic excited states, to study the ultrafast photodynamics of diatomic molecules in confined electromagnetic fields within quantized cavities. In addition to vibronic transitions due to intrinsic non-adiabatic couplings, two types of light-induced crossings emerge: one type is located at molecular nuclear geometries where the rotating wave approximation is fulfilled, and another type appears at different geometries where counter-rotating transitions may occur. We make a comprehensive study of polariton photodynamics within a time window of a few tens of femtoseconds, where dissipative mechanisms do not influence the polariton photodynamics. We stress the dramatic change of the polariton energy spectrum as a function of the Huang-Rhys factor when non-adiabatic couplings are included in the model. We conclude that both the molecular non-adiabatic couplings and, more specifically, the counter-rotating couplings in the cavity-molecule interaction play a crucial role in converting vibronic energy into photons through excited dressed states. We also show that the sign of the Huang-Rhys factor has a significant impact on this photon conversion. Our work paves the way for the development of many-photon generation powered by strong light-matter interaction, along with potential applications using alkaline earth monohydride molecules.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13232v1" target="_blank">Single-stream Policy Optimization</a></h3>
                    <p><strong>Authors:</strong> Zhongwen Xu, Zihan Ding</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, stat.ML</p>
                    <p><strong>Summary:</strong> We revisit policy-gradient optimization for Large Language Models (LLMs) from a single-stream perspective. Prevailing group-based methods like GRPO reduce variance with on-the-fly baselines but suffer from critical flaws: frequent degenerate groups erase learning signals, and synchronization barriers hinder scalability. We introduce Single-stream Policy Optimization (SPO), which eliminates these issues by design. SPO replaces per-group baselines with a persistent, KL-adaptive value tracker and normalizes advantages globally across the batch, providing a stable, low-variance learning signal for every sample. Being group-free, SPO enables higher throughput and scales effectively in long-horizon or tool-integrated settings where generation times vary. Furthermore, the persistent value tracker naturally enables an adaptive curriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO converges more smoothly and attains higher accuracy than GRPO, while eliminating computation wasted on degenerate groups. Ablation studies confirm that SPOs gains stem from its principled approach to baseline estimation and advantage normalization, offering a more robust and efficient path for LLM reasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the average maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial absolute point gains on challenging datasets, including +7.3 pp on BRUMO 25, +4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain in pass@$k$ across the evaluated $k$ values. SPOs success challenges the prevailing trend of adding incidental complexity to RL algorithms, highlighting a path where fundamental principles, not architectural workarounds, drive the next wave of progress in LLM reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.13231v1" target="_blank">An algorithm for Aubert-Zelevinsky duality Ã  la MÅ“glin-Waldspurger</a></h3>
                    <p><strong>Authors:</strong> Thomas Lanard, Alberto MÃ­nguez</p>
                    <p><strong>Published:</strong> 9/16/2025</p>
                    <p><strong>Categories:</strong> math.RT, math.NT</p>
                    <p><strong>Summary:</strong> Let $F$ be a locally compact non-Archimedean field of characteristic $0$, and let $G$ be either the split special orthogonal group $\mathrm{SO}_{2n+1}(F)$ or the symplectic group $\mathrm{Sp}_{2n}(F)$. The goal of this paper is to give an explicit description of the Aubert-Zelevinsky duality for $G$ in terms of Langlands parameters. We present a new algorithm, inspired by the Moeglin-Waldspurger algorithm for $\mathrm{GL}_n(F)$, which computes the dual Langlands data in a recursive and combinatorial way. Our method is simple enough to be carried out by hand and provides a practical tool for explicit computations. Interestingly, the algorithm was discovered with the help of machine learning tools, guiding us toward patterns that led to its formulation.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

