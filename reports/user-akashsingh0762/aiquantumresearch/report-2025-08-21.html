
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-21<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The papers related to AI safety research highlight several critical areas of focus, emphasizing the need for robust, efficient, and safe AI systems. One significant trend is the exploration of model efficiency and deployment challenges, particularly in the context of large language models (LLMs) and their quantization, as seen in the study on diffusion LLMs. This research is pivotal for deploying AI models on resource-constrained devices, ensuring they operate safely and efficiently without compromising performance.

Another key area is the robustness and safety of AI systems in various applications. The study on adversarial attacks on LLMs underscores the vulnerability of AI systems to malicious inputs, which can compromise their reliability and safety. The development of frameworks like AFABench for evaluating feature acquisition and the challenges highlighted in the Virtual Community platform for human-robot interaction further illustrate the need for comprehensive testing and validation to ensure AI systems function safely in dynamic and shared environments.

Moreover, the integration of AI in sensitive and critical areas, such as medical research and autonomous systems, further underscores the importance of AI safety. Papers discussing the medical deep research agent and the multiscale video transformers for autonomous driving highlight the necessity of aligning AI systems with safety protocols and ethical considerations to prevent unintended consequences and ensure human-centric, safe AI deployment. These studies collectively emphasize the imperative of ongoing research and development to address the safety challenges posed by advanced AI systems, ensuring they are reliable, transparent, and aligned with human values and societal needs.

*Based on 50 research papers*

---

## ai alignment research

AI alignment research focuses on ensuring that artificial intelligence systems operate in accordance with human values and intentions, particularly as they become more autonomous and integrated into society. Recent advancements demonstrate a growing trend towards creating AI systems that are not only efficient but also aligned with ethical and practical human standards. For instance, the paper on **Virtual Community** explores how robots and humans can coexist in shared environments, offering insights into embodied social intelligence, which is crucial for AI systems designed to interact with humans in real-world settings. This aligns with the broader goal of fostering AI that can understand and adapt to human social dynamics, a key component of alignment.

Moreover, the study on **MedResearcher-R1** highlights the importance of domain-specific knowledge in AI systems, particularly for applications in the medical field. By integrating specialized retrieval tools and medical knowledge graphs, this research addresses the challenge of aligning AIs decision-making processes with expert human knowledge, ensuring accurate and relevant outputs in critical domains. Similarly, the **Prompting Brain** paper investigates the cognitive aspects of interacting with large language models, emphasizing the need for AI systems to be intuitive and compatible with human cognitive processes. These studies underscore the significance of aligning AIs operational frameworks with human expertise and context, promoting systems that are not only functionally capable but also ethically and practically aligned with human expectations and societal norms.

*Based on 50 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.14896v1" target="_blank">Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs</a></h3>
                    <p><strong>Authors:</strong> Haokun Lin, Haobo Xu, Yichen Wu, Ziyu Guo, Renrui Zhang, Zhichao Lu, Ying Wei, Qingfu Zhang, Zhenan Sun</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in diffusion large language models (dLLMs) have introduced a promising alternative to autoregressive (AR) LLMs for natural language generation tasks, leveraging full attention and denoising-based decoding strategies. However, the deployment of these models on edge devices remains challenging due to their massive parameter scale and high resource demands. While post-training quantization (PTQ) has emerged as a widely adopted technique for compressing AR LLMs, its applicability to dLLMs remains largely unexplored. In this work, we present the first systematic study on quantizing diffusion-based language models. We begin by identifying the presence of activation outliers, characterized by abnormally large activation values that dominate the dynamic range. These outliers pose a key challenge to low-bit quantization, as they make it difficult to preserve precision for the majority of values. More importantly, we implement state-of-the-art PTQ methods and conduct a comprehensive evaluation across multiple task types and model variants. Our analysis is structured along four key dimensions: bit-width, quantization method, task category, and model type. Through this multi-perspective evaluation, we offer practical insights into the quantization behavior of dLLMs under different configurations. We hope our findings provide a foundation for future research in efficient dLLM deployment. All codes and experimental setups will be released to support the community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14893v1" target="_blank">Virtual Community: An Open World for Humans, Robots, and Society</a></h3>
                    <p><strong>Authors:</strong> Qinhong Zhou, Hongxin Zhang, Xiangye Lin, Zheyuan Zhang, Yutian Chen, Wenjun Liu, Zunzhe Zhang, Sunli Chen, Lixing Fang, Qiushi Lyu, Xinyu Sun, Jincheng Yang, Zeyuan Wang, Bao Chi Dang, Zhehuan Chen, Daksha Ladia, Jiageng Liu, Chuang Gan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.RO</p>
                    <p><strong>Summary:</strong> The rapid progress in AI and Robotics may lead to a profound societal transformation, as humans and robots begin to coexist within shared communities, introducing both opportunities and challenges. To explore this future, we present Virtual Community-an open-world platform for humans, robots, and society-built on a universal physics engine and grounded in real-world 3D scenes. With Virtual Community, we aim to study embodied social intelligence at scale: 1) How robots can intelligently cooperate or compete; 2) How humans develop social relations and build community; 3) More importantly, how intelligent robots and humans can co-exist in an open world. To support these, Virtual Community features: 1) An open-source multi-agent physics simulator that supports robots, humans, and their interactions within a society; 2) A large-scale, real-world aligned community generation pipeline, including vast outdoor space, diverse indoor scenes, and a community of grounded agents with rich characters and appearances. Leveraging Virtual Community, we propose two novel challenges. The Community Planning Challenge evaluates multi-agent reasoning and planning ability in open-world settings, such as cooperating to help agents with daily activities and efficiently connecting other agents. The Community Robot Challenge requires multiple heterogeneous robots to collaborate in solving complex open-world tasks. We evaluate various baselines on these tasks and demonstrate the challenges in both high-level open-world task planning and low-level cooperation controls. We hope that Virtual Community will unlock further study of human-robot coexistence within open-world environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14885v1" target="_blank">Novel Limits on Dark Photon Mixing from Radiation Safety</a></h3>
                    <p><strong>Authors:</strong> Wen Yin</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-ex, physics.ins-det</p>
                    <p><strong>Summary:</strong> I propose a novel laboratory search for dark photons based on radiation-safety monitoring at synchrotron radiation facilities, including NanoTerasu, SPring-8, KEK-PF, and ESRF. Dark photons can be produced parasitically in undulators or via photon-mirror interactions, and subsequently traverse optical systems and shielding. Taking into account quantum effects and the internal structure of undulators, mirrors, and detectors, I show that even a simple Geiger-M\uller counter, routinely used for radiation-safety monitoring, can detect such dark photons outside the shielding and set competitive limits on the kinetic mixing parameter down to $\chi \lesssim 5\times 10^{-6}$ in the eV mass range, providing some of the strongest bounds among laboratory searches. Because radiation safety is strictly regulated, the resulting limits can be regarded as robust and realistic constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14883v1" target="_blank">The Cost Advantage of Virtual Machine Migrations: Empirical Insights into Amazons EC2 Marketspace</a></h3>
                    <p><strong>Authors:</strong> Benedikt Pittl, Werner Mach, Erich Schikuta</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC, cs.GT, 91-08, J.1; H.1.m</p>
                    <p><strong>Summary:</strong> In recent years, cloud providers have introduced novel approaches for trading virtual machines. For example, Virtustream introduced so-called muVMs to charge cloud computing resources while other providers such as Google, Microsoft, or Amazon re-invented their marketspaces. Today, the market leader Amazon runs six marketspaces for trading virtual machines. Consumers can purchase bundles of virtual machines, which are called cloud-portfolios, from multiple marketspaces and providers. An industry-relevant field of research is to identify best practices and guidelines on how such optimal portfolios are created. In the paper at hand, a cost analysis of cloud portfolios is presented. Therefore, pricing data from Amazon was used as well as a real virtual machine utilization dataset from the Bitbrains datacenter. The results show that a cost optimum can only be reached if heterogeneous portfolios are created where virtual machines are purchased from different marketspaces. Additionally, the cost-benefit of migrating virtual machines to different marketplaces during runtime is presented. Such migrations are especially cost-effective for virtual machines of cloud-portfolios which run between 6 hours and 1 year. The paper further shows that most of the resources of virtual machines are never utilized by consumers, which represents a significant future potential for cost optimization. For the validation of the results, a second dataset of the Bitbrains datacenter was used, which contains utility data of virtual machines from a different domain of application.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14880v1" target="_blank">MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework</a></h3>
                    <p><strong>Authors:</strong> Ailing Yu, Lan Yao, Jingnan Liu, Zhe Chen, Jiajun Yin, Yuan Wang, Xinhao Liao, Zhiling Ye, Ji Li, Yun Yue, Hansong Xiao, Hualei Zhou, Chunxiao Guo, Peng Wei, Jinjie Gu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent developments in Large Language Model (LLM)-based agents have shown impressive capabilities spanning multiple domains, exemplified by deep research systems that demonstrate superior performance on complex information-seeking and synthesis tasks. While general-purpose deep research agents have shown impressive capabilities, they struggle significantly with medical domain challenges, as evidenced by leading proprietary systems achieving limited accuracy on complex medical benchmarks. The key limitations are: (1) the model lacks sufficient dense medical knowledge for clinical reasoning, and (2) the framework is constrained by the absence of specialized retrieval tools tailored for medical contexts.We present a medical deep research agent that addresses these challenges through two core innovations. First, we develop a novel data synthesis framework using medical knowledge graphs, extracting the longest chains from subgraphs around rare medical entities to generate complex multi-hop question-answer pairs. Second, we integrate a custom-built private medical retrieval engine alongside general-purpose tools, enabling accurate medical information synthesis. Our approach generates 2100+ diverse trajectories across 12 medical specialties, each averaging 4.2 tool interactions.Through a two-stage training paradigm combining supervised fine-tuning and online reinforcement learning with composite rewards, our MedResearcher-R1-32B model demonstrates exceptional performance, establishing new state-of-the-art results on medical benchmarks while maintaining competitive performance on general deep research tasks. Our work demonstrates that strategic domain-specific innovations in architecture, tool design, and training data construction can enable smaller open-source models to outperform much larger proprietary systems in specialized domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14878v1" target="_blank">Lifespan Pancreas Morphology for Control vs Type 2 Diabetes using AI on Largescale Clinical Imaging</a></h3>
                    <p><strong>Authors:</strong> Lucas W. Remedios, Chloe Cho, Trent M. Schwartz, Dingjie Su, Gaurav Rudravaram, Chenyu Gao, Aravind R. Krishnan, Adam M. Saunders, Michael E. Kim, Shunxing Bao, Thomas A. Lasko, Alvin C. Powers, Bennett A. Landman, John Virostko</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Purpose: Understanding how the pancreas changes is critical for detecting deviations in type 2 diabetes and other pancreatic disease. We measure pancreas size and shape using morphological measurements from ages 0 to 90. Our goals are to 1) identify reliable clinical imaging modalities for AI-based pancreas measurement, 2) establish normative morphological aging trends, and 3) detect potential deviations in type 2 diabetes. Approach: We analyzed a clinically acquired dataset of 2533 patients imaged with abdominal CT or MRI. We resampled the scans to 3mm isotropic resolution, segmented the pancreas using automated methods, and extracted 13 morphological pancreas features across the lifespan. First, we assessed CT and MRI measurements to determine which modalities provide consistent lifespan trends. Second, we characterized distributions of normative morphological patterns stratified by age group and sex. Third, we used GAMLSS regression to model pancreas morphology trends in 1350 patients matched for age, sex, and type 2 diabetes status to identify any deviations from normative aging associated with type 2 diabetes. Results: When adjusting for confounders, the aging trends for 10 of 13 morphological features were significantly different between patients with type 2 diabetes and non-diabetic controls (p  0.05 after multiple comparisons corrections). Additionally, MRI appeared to yield different pancreas measurements than CT using our AI-based method. Conclusions: We provide lifespan trends demonstrating that the size and shape of the pancreas is altered in type 2 diabetes using 675 control patients and 675 diabetes patients. Moreover, our findings reinforce that the pancreas is smaller in type 2 diabetes. Additionally, we contribute a reference of lifespan pancreas morphology from a large cohort of non-diabetic control patients in a clinical setting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14875v1" target="_blank">The Alma catalogue of OB stars. III. A cross-match with Gaia DR3 and an extension based on new spectral classifications</a></h3>
                    <p><strong>Authors:</strong> M. Pantaleoni GonzÃ¡lez, J. MaÃ­z ApellÃ¡niz, R. H. BarbÃ¡, B. Cameron Reed, S. R. Berlanas, A. Parras Rico, A. Bodaghee</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR, astro-ph.GA</p>
                    <p><strong>Summary:</strong> We present the third installment of the Alma Luminous Star (ALS) catalogue, aimed at creating the most comprehensive and clean sample of Galactic massive stars. This update extends the sample by adding approximately 2000 OB stars, incorporating astrometric and photometric data from the Gaia Data Release 3 (DR3) alongside spectroscopic information from the Galactic O-Star Catalog based on recent ground-based spectroscopic surveys. Rigorous astrometric corrections are applied to Gaia DR3 parallaxes, proper motions, and photometry, ensuring accurate distance estimates through a Bayesian method suited to this stellar populations spatial distribution in the Milky Way. We perform some comparative analyses highlighting the improved distance accuracy over previous versions, underscore the importance of precise spectral classifications with competing catalogues, and identify areas for improvement in Gaia DR3 effective temperature and extinction estimates for massive stars. We also address the challenges of having robust definitions for these objects. In addition, we explore the catalogues ability to trace Galactic features such as spiral arms, spurs and OB associations (with some insights on the nature of Goulds Belt). Finally, we discuss the potential for further expanding the sample with upcoming surveys. This effort marks a significant advancement in the creation of a reliable census of Galactic massive stars, contributing to our understanding of the Milky Ways structure and star formation history. This catalogue should serve as a valuable reference for the massive star community, supporting research on stellar interiors, winds, stellar feedback, and other processes that make OB stars key to the evolution of galaxies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14869v1" target="_blank">The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Hend Al-Khalifa, Raneem Almansour, Layan Abdulrahman Alhuasini, Alanood Alsaleh, Mohamad-Hani Temsah, Mohamad-Hani_Temsah, Ashwag Rafea S Alruwaili</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC, cs.CL</p>
                    <p><strong>Summary:</strong> Prompt engineering has rapidly emerged as a critical skill for effective interaction with large language models (LLMs). However, the cognitive and neural underpinnings of this expertise remain largely unexplored. This paper presents findings from a cross-sectional pilot fMRI study investigating differences in brain functional connectivity and network activity between experts and intermediate prompt engineers. Our results reveal distinct neural signatures associated with higher prompt engineering literacy, including increased functional connectivity in brain regions such as the left middle temporal gyrus and the left frontal pole, as well as altered power-frequency dynamics in key cognitive networks. These findings offer initial insights into the neurobiological basis of prompt engineering proficiency. We discuss the implications of these neurocognitive markers in Natural Language Processing (NLP). Understanding the neural basis of human expertise in interacting with LLMs can inform the design of more intuitive human-AI interfaces, contribute to cognitive models of LLM interaction, and potentially guide the development of AI systems that better align with human cognitive workflows. This interdisciplinary approach aims to bridge the gap between human cognition and machine intelligence, fostering a deeper understanding of how humans learn and adapt to complex AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14853v1" target="_blank">Universal and Transferable Adversarial Attack on Large Language Models Using Exponentiated Gradient Descent</a></h3>
                    <p><strong>Authors:</strong> Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) are increasingly deployed in critical applications, ensuring their robustness and safety alignment remains a major challenge. Despite the overall success of alignment techniques such as reinforcement learning from human feedback (RLHF) on typical prompts, LLMs remain vulnerable to jailbreak attacks enabled by crafted adversarial triggers appended to user prompts. Most existing jailbreak methods either rely on inefficient searches over discrete token spaces or direct optimization of continuous embeddings. While continuous embeddings can be given directly to selected open-source models as input, doing so is not feasible for proprietary models. On the other hand, projecting these embeddings back into valid discrete tokens introduces additional complexity and often reduces attack effectiveness. We propose an intrinsic optimization method which directly optimizes relaxed one-hot encodings of the adversarial suffix tokens using exponentiated gradient descent coupled with Bregman projection, ensuring that the optimized one-hot encoding of each token always remains within the probability simplex. We provide theoretical proof of convergence for our proposed method and implement an efficient algorithm that effectively jailbreaks several widely used LLMs. Our method achieves higher success rates and faster convergence compared to three state-of-the-art baselines, evaluated on five open-source LLMs and four adversarial behavior datasets curated for evaluating jailbreak methods. In addition to individual prompt attacks, we also generate universal adversarial suffixes effective across multiple prompts and demonstrate transferability of optimized suffixes to different LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14848v1" target="_blank">Leveraging Hardware-Aware Computation in Mixed-Precision Matrix Multiply: A Tile-Centric Approach</a></h3>
                    <p><strong>Authors:</strong> Qiao Zhang, Rabab Alomairy, Dali Wang, Zhuowei Gu, Qinglei Cao</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> General Matrix Multiplication (GEMM) is a critical operation underpinning a wide range of applications in high-performance computing (HPC) and artificial intelligence (AI). The emergence of hardware optimized for low-precision arithmetic necessitates a reevaluation of numerical algorithms to leverage mixed-precision computations, achieving improved performance and energy efficiency. This research introduces an adaptive mixed-precision GEMM framework that supports different precision formats at fine-grained tile/block levels. We utilize the PaRSEC runtime system to balance workloads across various architectures. The performance scales well on ARM CPU-based Fugaku supercomputer, Nvidia GPU-based A100 DGX, and AMD GPU-based Frontier supercomputer. This research aims to enhance computational efficiency and accuracy by bridging algorithmic advancements and hardware innovations, driving transformative progress in various applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14828v1" target="_blank">Long Chain-of-Thought Reasoning Across Languages</a></h3>
                    <p><strong>Authors:</strong> Josh Barua, Seun Eisape, Kayo Yin, Alane Suhr</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Scaling inference through long chains-of-thought (CoTs) has unlocked impressive reasoning capabilities in large language models (LLMs), yet the reasoning process remains almost exclusively English-centric. We construct translated versions of two popular English reasoning datasets, fine-tune Qwen 2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT generation across French, Japanese, Latvian, and Swahili. Our experiments reveal three key findings. First, the efficacy of using English as a pivot language varies by language: it provides no benefit for French, improves performance when used as the reasoning language for Japanese and Latvian, and proves insufficient for Swahili where both task comprehension and reasoning remain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but does not eliminate the cross-lingual performance gap. A lightweight fine-tune using only 1k traces still improves performance by over 30\% in Swahili. Third, data quality versus scale trade-offs are language dependent: small, carefully curated datasets suffice for English and French, whereas larger but noisier corpora prove more effective for Swahili and Latvian. Together, these results clarify when and why long CoTs transfer across languages and provide translated datasets to foster equitable multilingual reasoning research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14825v1" target="_blank">From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning</a></h3>
                    <p><strong>Authors:</strong> Lixiang Yan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> The role of Artificial Intelligence (AI) in education is undergoing a rapid transformation, moving beyond its historical function as an instructional tool towards a new potential as an active participant in the learning process. This shift is driven by the emergence of agentic AI, autonomous systems capable of proactive, goal-directed action. However, the field lacks a robust conceptual framework to understand, design, and evaluate this new paradigm of human-AI interaction in learning. This paper addresses this gap by proposing a novel conceptual framework (the APCP framework) that charts the transition from AI as a tool to AI as a collaborative partner. We present a four-level model of escalating AI agency within human-AI collaborative learning: (1) the AI as an Adaptive Instrument, (2) the AI as a Proactive Assistant, (3) the AI as a Co-Learner, and (4) the AI as a Peer Collaborator. Grounded in sociocultural theories of learning and Computer-Supported Collaborative Learning (CSCL), this framework provides a structured vocabulary for analysing the shifting roles and responsibilities between human and AI agents. The paper further engages in a critical discussion of the philosophical underpinnings of collaboration, examining whether an AI, lacking genuine consciousness or shared intentionality, can be considered a true collaborator. We conclude that while AI may not achieve authentic phenomenological partnership, it can be designed as a highly effective functional collaborator. This distinction has significant implications for pedagogy, instructional design, and the future research agenda for AI in education, urging a shift in focus towards creating learning environments that harness the complementary strengths of both human and AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14823v1" target="_blank">Using an LLM to Investigate Students Explanations on Conceptual Physics Questions</a></h3>
                    <p><strong>Authors:</strong> Sean Savage, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Analyzing students written solutions to physics questions is a major area in PER. However, gauging student understanding in college courses is bottlenecked by large class sizes, which limits assessments to a multiple-choice (MC) format for ease of grading. Although sufficient in quantifying scientifically correct conceptions, MC assessments do not uncover students deeper ways of understanding physics. Large language models (LLMs) offer a promising approach for assessing students written responses at scale. Our study used an LLM, validated by human graders, to classify students written explanations to three questions on the Energy and Momentum Conceptual Survey as correct or incorrect, and organized students incorrect explanations into emergent categories. We found that the LLM (GPT-4o) can fairly assess students explanations, comparable to human graders (0-3% discrepancy). Furthermore, the categories of incorrect explanations were different from corresponding MC distractors, allowing for different and deeper conceptions to become accessible to educators.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14819v1" target="_blank">Synchronization driven acoustics: The nonlinear scattering of a self-oscillating meta-atom</a></h3>
                    <p><strong>Authors:</strong> Alexander K. Stoychev, Xinxin Guo, Ulrich Kuhl, Nicolas Noiray</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> In this study we demonstrate a self-oscillating acoustic meta-atom functioning as an amplifying transistor, where a steady external flow serves as a control signal to switch between reflective (off-state) and transmissive (on-state) regimes. In the on-state, an acoustic limit cycle synchronizes with incident sound waves. This process governs the energy transfer across the device, with a transmission bandwidth dictated by the synchronization region in parameter space (Arnold tongue). Our experimental measurements reveal nonlinear dependence on the incident wave amplitude, enabling perturbation filtering therein and stabilizing downstream acoustic power. All experimentally observed phenomena are quantitatively described by a nonlinear Li\enard-type oscillator featuring saturable gain and linear loss, where the essential parameters can be estimated by independent measurements. This work may offer a paradigm shift in acoustic metamaterials research by leveraging self-oscillation and synchronization processes. Bridging those key concepts from nonlinear dynamics and complex systems with active metamaterial design in acoustics and related disciplines, may establish a broadly applicable framework of field-independent mechanisms for wave manipulation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14814v1" target="_blank">TransLight: Image-Guided Customized Lighting Control with Generative Decoupling</a></h3>
                    <p><strong>Authors:</strong> Zongming Li, Lianghui Zhu, Haocheng Shen, Longjin Ran, Wenyu Liu, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Most existing illumination-editing approaches fail to simultaneously provide customized control of light effects and preserve content integrity. This makes them less effective for practical lighting stylization requirements, especially in the challenging task of transferring complex light effects from a reference image to a user-specified target image. To address this problem, we propose TransLight, a novel framework that enables high-fidelity and high-freedom transfer of light effects. Extracting the light effect from the reference image is the most critical and challenging step in our method. The difficulty lies in the complex geometric structure features embedded in light effects that are highly coupled with content in real-world scenarios. To achieve this, we first present Generative Decoupling, where two fine-tuned diffusion models are used to accurately separate image content and light effects, generating a newly curated, million-scale dataset of image-content-light triplets. Then, we employ IC-Light as the generative model and train our model with our triplets, injecting the reference lighting image as an additional conditioning signal. The resulting TransLight model enables customized and natural transfer of diverse light effects. Notably, by thoroughly disentangling light effects from reference images, our generative decoupling strategy endows TransLight with highly flexible illumination control. Experimental results establish TransLight as the first method to successfully transfer light effects across disparate images, delivering more customized illumination control than existing techniques and charting new directions for research in illumination harmonization and editing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14811v1" target="_blank">Tinker: Diffusions Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization</a></h3>
                    <p><strong>Authors:</strong> Canyu Zhao, Xiaoman Li, Tianjian Feng, Zhiyue Zhao, Hao Chen, Chunhua Shen</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Tinker, a versatile framework for high-fidelity 3D editing that operates in both one-shot and few-shot regimes without any per-scene finetuning. Unlike prior techniques that demand extensive per-scene optimization to ensure multi-view consistency or to produce dozens of consistent edited input views, Tinker delivers robust, multi-view consistent edits from as few as one or two images. This capability stems from repurposing pretrained diffusion models, which unlocks their latent 3D awareness. To drive research in this space, we curate the first large-scale multi-view editing dataset and data pipeline, spanning diverse scenes and styles. Building on this dataset, we develop our framework capable of generating multi-view consistent edited views without per-scene training, which consists of two novel components: (1) Referring multi-view editor: Enables precise, reference-driven edits that remain coherent across all viewpoints. (2) Any-view-to-video synthesizer: Leverages spatial-temporal priors from video diffusion to perform high-quality scene completion and novel-view generation even from sparse inputs. Through extensive experiments, Tinker significantly reduces the barrier to generalizable 3D content creation, achieving state-of-the-art performance on editing, novel-view synthesis, and rendering enhancement tasks. We believe that Tinker represents a key step towards truly scalable, zero-shot 3D editing. Project webpage: https://aim-uofa.github.io/Tinker</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14802v1" target="_blank">Privileged Self-Access Matters for Introspection in AI</a></h3>
                    <p><strong>Authors:</strong> Siyuan Song, Harvey Lederman, Jennifer Hu, Kyle Mahowald</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Whether AI models can introspect is an increasingly important practical question. But there is no consensus on how introspection is to be defined. Beginning from a recently proposed lightweight definition, we argue instead for a thicker one. According to our proposal, introspection in AI is any process which yields information about internal states through a process more reliable than one with equal or lower computational cost available to a third party. Using experiments where LLMs reason about their internal temperature parameters, we show they can appear to have lightweight introspection while failing to meaningfully introspect per our proposed definition.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14801v1" target="_blank">A Guide for Manual Annotation of Scientific Imagery: How to Prepare for Large Projects</a></h3>
                    <p><strong>Authors:</strong> Azim Ahmadzadeh, Rohan Adhyapak, Armin Iraji, Kartik Chaurasiya, V Aparna, Petrus C. Martens</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite the high demand for manually annotated image data, managing complex and costly annotation projects remains under-discussed. This is partly due to the fact that leading such projects requires dealing with a set of diverse and interconnected challenges which often fall outside the expertise of specific domain experts, leaving practical guidelines scarce. These challenges range widely from data collection to resource allocation and recruitment, from mitigation of biases to effective training of the annotators. This paper provides a domain-agnostic preparation guide for annotation projects, with a focus on scientific imagery. Drawing from the authors extensive experience in managing a large manual annotation project, it addresses fundamental concepts including success measures, annotation subjects, project goals, data availability, and essential team roles. Additionally, it discusses various human biases and recommends tools and technologies to improve annotation quality and efficiency. The goal is to encourage further research and frameworks for creating a comprehensive knowledge base to reduce the costs of manual annotation projects across various fields.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14796v1" target="_blank">A Guide to Stakeholder Analysis for Cybersecurity Researchers</a></h3>
                    <p><strong>Authors:</strong> James C Davis, Sophie Chen, Huiyun Peng, Paschal C Amusuo, Kelechi G Kalu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.SE</p>
                    <p><strong>Summary:</strong> Stakeholder-based ethics analysis is now a formal requirement for submissions to top cybersecurity research venues. This requirement reflects a growing consensus that cybersecurity researchers must go beyond providing capabilities to anticipating and mitigating the potential harms thereof. However, many cybersecurity researchers may be uncertain about how to proceed in an ethics analysis. In this guide, we provide practical support for that requirement by enumerating stakeholder types and mapping them to common empirical research methods. We also offer worked examples to demonstrate how researchers can identify likely stakeholder exposures in real-world projects. Our goal is to help research teams meet new ethics mandates with confidence and clarity, not confusion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14790v1" target="_blank">Exploring the Interplay Between Quantum Entanglement and Decoherence</a></h3>
                    <p><strong>Authors:</strong> Samuel Marquez Gonzalez</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum entanglement manifests as a distinctive correlation between particles that transcends classical boundaries when their quantum states cannot be described independently. On the other hand, as quantum systems interact with their surroundings, decoherence emerges, leading to the gradual decay of quantum coherence and entanglement. In the case of entanglement, this is known as entanglement sudden death (ESD). Decoherence mechanisms are examined, focusing on how various environmental factors, such as thermal, electromagnetic, and collisional decoherence, influence the integrity of entangled states. The role of quantum noise, such as amplitude damping, phase damping, and depolarizing, is also analyzed. By integrating theoretical insights with experimental findings, this study highlights the delicate balance between maintaining entanglement and mitigating decoherence. The findings have significant implications for the development of quantum technologies, including quantum computing and quantum communication, where preserving entanglement is crucial for achieving robust and reliable performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14789v1" target="_blank">Quantifying How Much Has Been Learned from a Research Study</a></h3>
                    <p><strong>Authors:</strong> Jonas M. Mikhaeil, Donald P. Green</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.AP</p>
                    <p><strong>Summary:</strong> How much does a research study contribute to a scientific literature? We propose a learning metric to quantify how much a research community learns from a given study. To do so, we adopt a Bayesian perspective and assess changes in the communitys beliefs once updated with a new studys evidence. We recommend the Wasserstein-2 distance as a way to describe how the research communitys prior beliefs change to incorporate a studys findings. We illustrate this approach through stylized examples and empirical applications, showing how it differs from more traditional evaluative standards, such as statistical significance. We then extend the framework to the prospective setting, offering a way for decision-makers to evaluate the expected amount of learning from a proposed study. While assessments about what has or could be learned from a research program are often expressed informally, our learning metric provides a principled tool for judging scientific contributions. By formalizing these judgments, our measure has the potential to allow for more transparent assessments of past and prospective research contributions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14787v1" target="_blank">Challenges and Opportunities for Participatory Design of Conversational Agents for Young Peoples Wellbeing</a></h3>
                    <p><strong>Authors:</strong> Natalia Kucirkova, Alexis Hiniker, Megumi Ishikawa, Sho Tsuji, Aayushi Dangol, Robert Wolfe</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY</p>
                    <p><strong>Summary:</strong> This paper outlines the challenges and opportunities of research on conversational agents with children and young people across four countries, exploring the ways AI technologies can support childrens well-being across social and cultural contexts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14778v1" target="_blank">Analyzing Undergraduate Problem-Solving in Physics Through Interaction With an AI Chatbot</a></h3>
                    <p><strong>Authors:</strong> Syed Furqan Abbas Hashmi, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Providing individualized scaffolding for physics problem solving at scale remains an instructional challenge. We investigate (1) students perceptions of a Socratic Artificial Intelligence (AI) chatbots impact on problem-solving skills and confidence and (2) how the specificity of students questions during tutoring relates to performance. We deployed a custom Socratic AI chatbot in a large-enrollment introductory mechanics course at a Midwestern public university, logging full dialogue transcripts from 150 first-year STEM majors. Post-interaction surveys revealed median ratings of 4.0/5 for knowledge-based skills and 3.4/5 for overall effectiveness. Transcript analysis showed question specificity rose from approximately 10-15% in the first turn to 100% by the final turn, and specificity correlated positively with self reported expected course grade (Pearson r = 0.43). These findings demonstrate that AI-driven Socratic dialogue not only fosters expert-like reasoning but also generates fine-grained analytics for physics education research, establishing a scalable dual-purpose tool for instruction and learning analytics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14770v1" target="_blank">Non-Existent Outcomes in Research on Inequality: A Causal Approach</a></h3>
                    <p><strong>Authors:</strong> Ian Lundberg, Soonhong Cho</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.AP, 62D20, J.4; G.3</p>
                    <p><strong>Summary:</strong> Scholars of social stratification often study exposures that shape life outcomes. But some outcomes (such as wage) only exist for some people (such as those who are employed). We show how a common practice -- dropping cases with non-existent outcomes -- can obscure causal effects when a treatment affects both outcome existence and outcome values. The effects of both beneficial and harmful treatments can be underestimated. Drawing on existing approaches for principal stratification, we show how to study (1) the average effect on whether an outcome exists and (2) the average effect on the outcome among the latent subgroup whose outcome would exist in either treatment condition. To extend our approach to the selection-on-observables settings common in applied research, we develop a framework involving regression and simulation to enable principal stratification estimates that adjust for measured confounders. We illustrate through an empirical example about the effects of parenthood on labor market outcomes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14767v1" target="_blank">Fusing Monocular RGB Images with AIS Data to Create a 6D Pose Estimation Dataset for Marine Vessels</a></h3>
                    <p><strong>Authors:</strong> Fabian Holst, Emre GÃ¼lsoylu, Simone Frintrop</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> The paper presents a novel technique for creating a 6D pose estimation dataset for marine vessels by fusing monocular RGB images with Automatic Identification System (AIS) data. The proposed technique addresses the limitations of relying purely on AIS for location information, caused by issues like equipment reliability, data manipulation, and transmission delays. By combining vessel detections from monocular RGB images, obtained using an object detection network (YOLOX-X), with AIS messages, the technique generates 3D bounding boxes that represent the vessels 6D poses, i.e. spatial and rotational dimensions. The paper evaluates different object detection models to locate vessels in image space. We also compare two transformation methods (homography and Perspective-n-Point) for aligning AIS data with image coordinates. The results of our work demonstrate that the Perspective-n-Point (PnP) method achieves a significantly lower projection error compared to homography-based approaches used before, and the YOLOX-X model achieves a mean Average Precision (mAP) of 0.80 at an Intersection over Union (IoU) threshold of 0.5 for relevant vessel classes. We show indication that our approach allows the creation of a 6D pose estimation dataset without needing manual annotation. Additionally, we introduce the Boats on Nordelbe Kehrwieder (BONK-pose), a publicly available dataset comprising 3753 images with 3D bounding box annotations for pose estimation, created by our data fusion approach. This dataset can be used for training and evaluating 6D pose estimation networks. In addition we introduce a set of 1000 images with 2D bounding box annotations for ship detection from the same scene.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14764v1" target="_blank">Investigation of the Inter-Rater Reliability between Large Language Models and Human Raters in Qualitative Analysis</a></h3>
                    <p><strong>Authors:</strong> Nikhil Sanjay Borse, Ravishankar Chatta Subramaniam, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Qualitative analysis is typically limited to small datasets because it is time-intensive. Moreover, a second human rater is required to ensure reliable findings. Artificial intelligence tools may replace human raters if we demonstrate high reliability compared to human ratings. We investigated the inter-rater reliability of state-of-the-art Large Language Models (LLMs), ChatGPT-4o and ChatGPT-4.5-preview, in rating audio transcripts coded manually. We explored prompts and hyperparameters to optimize model performance. The participants were 14 undergraduate student groups from a university in the midwestern United States who discussed problem-solving strategies for a project. We prompted an LLM to replicate manual coding, and calculated Cohens Kappa for inter-rater reliability. After optimizing model hyperparameters and prompts, the results showed substantial agreement (${\kappa}0.6$) for three themes and moderate agreement on one. Our findings demonstrate the potential of GPT-4o and GPT-4.5 for efficient, scalable qualitative analysis in physics education and identify their limitations in rating domain-general constructs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14763v1" target="_blank">Safe and Transparent Robots for Human-in-the-Loop Meat Processing</a></h3>
                    <p><strong>Authors:</strong> Sagar Parekh, Casey Grothoff, Ryan Wright, Robin White, Dylan P. Losey</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Labor shortages have severely affected the meat processing sector. Automated technology has the potential to support the meat industry, assist workers, and enhance job quality. However, existing automation in meat processing is highly specialized, inflexible, and cost intensive. Instead of forcing manufacturers to buy a separate device for each step of the process, our objective is to develop general-purpose robotic systems that work alongside humans to perform multiple meat processing tasks. Through a recently conducted survey of industry experts, we identified two main challenges associated with integrating these collaborative robots alongside human workers. First, there must be measures to ensure the safety of human coworkers; second, the coworkers need to understand what the robot is doing. This paper addresses both challenges by introducing a safety and transparency framework for general-purpose meat processing robots. For safety, we implement a hand-detection system that continuously monitors nearby humans. This system can halt the robot in situations where the human comes into close proximity of the operating robot. We also develop an instrumented knife equipped with a force sensor that can differentiate contact between objects such as meat, bone, or fixtures. For transparency, we introduce a method that detects the robots uncertainty about its performance and uses an LED interface to communicate that uncertainty to the human. Additionally, we design a graphical interface that displays the robots plans and allows the human to provide feedback on the planned cut. Overall, our framework can ensure safe operation while keeping human workers in-the-loop about the robots actions which we validate through a user study.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14760v1" target="_blank">Dual-Role Dynamics in Prompting: Elementary Pre-service Teachers AI Prompting Strategies for Representational Choices</a></h3>
                    <p><strong>Authors:</strong> Razan Hamed, Amogh Sirnoorkar, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Pre-service teachers play a unique dual role as they straddle between the roles of students and future teachers. This dual role requires them to adopt both the learners and the instructors perspectives while engaging with pedagogical and content knowledge. The current study investigates how pre-service elementary teachers taking a physical science course prompt AI to generate representations that effectively communicate conceptual ideas to two distinct audiences. The context involves participants interacting with AI to generate appropriate representations that explain the concepts of wave velocity to their elementary students (while casting themselves as teachers) and the Ideal Gas Law to their English teachers (while casting themselves as students). Emergent coding of the AI prompts highlight that, when acting as teachers, participants were more explicit in specifying the target audience, predetermining the type of representation, and producing a broader variety of representations compared to when they acted as students. Implications of the observed exploratory and prescriptive prompting trends across the two roles on pre-service teachers education and their professional development are discussed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14759v1" target="_blank">Students Perceptions to a Large Language Models Generated Feedback and Scores of Argumentation Essays</a></h3>
                    <p><strong>Authors:</strong> Winter Allen, Anand Shanker, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Students in introductory physics courses often rely on ineffective strategies, focusing on final answers rather than understanding underlying principles. Integrating scientific argumentation into problem-solving fosters critical thinking and links conceptual knowledge with practical application. By facilitating learners to articulate their scientific arguments for solving problems, and by providing real-time feedback on students strategies, we aim to enable students to develop superior problem-solving skills. Providing timely, individualized feedback to students in large-enrollment physics courses remains a challenge. Recent advances in Artificial Intelligence (AI) offer promising solutions. This study investigates the potential of AI-generated feedback on students written scientific arguments in an introductory physics class. Using Open AIs GPT-4o, we provided delayed feedback on student written scientific arguments and surveyed them about the perceived usefulness and accuracy of this feedback. Our findings offer insights into the viability of implementing real-time AI feedback to enhance students problem-solving and metacognitive skills in large-enrollment classrooms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14754v1" target="_blank">Near-resonant nuclear spin detection with megahertz mechanical resonators</a></h3>
                    <p><strong>Authors:</strong> Diego A. Visani, Letizia Catalini, Christian L. Degen, Alexander Eichler, Javier del Pino</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Mechanical resonators operating in the megahertz range have become a versatile platform for fundamental and applied quantum research. Their exceptional properties, such as low mass and high quality factor, make them also appealing for force sensing experiments. In this work, we propose a method for detecting, and ultimately controlling, nuclear spins by coupling them to megahertz resonators via a magnetic field gradient. Dynamical backaction between the sensor and an ensemble of $N$ nuclear spins produces a shift in the sensors resonance frequency. The mean frequency shift due to the Boltzmann polarization is challenging to measure in nanoscale sample volumes. Here, we show that the fluctuating polarization of the spin ensemble results in a measurable increase of the resonators frequency variance. On the basis of analytical as well as numerical results, we predict that the variance measurement will allow single nuclear spin detection with existing resonator devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14751v1" target="_blank">HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents</a></h3>
                    <p><strong>Authors:</strong> Thomas Carta, ClÃ©ment Romac, Loris Gaven, Pierre-Yves Oudeyer, Olivier Sigaud, Sylvain Lamprier</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Open-ended AI agents need to be able to learn efficiently goals of increasing complexity, abstraction and heterogeneity over their lifetime. Beyond sampling efficiently their own goals, autotelic agents specifically need to be able to keep the growing complexity of goals under control, limiting the associated growth in sample and computational complexity. To adress this challenge, recent approaches have leveraged hierarchical reinforcement learning (HRL) and language, capitalizing on its compositional and combinatorial generalization capabilities to acquire temporally extended reusable behaviours. Existing approaches use expert defined spaces of subgoals over which they instantiate a hierarchy, and often assume pre-trained associated low-level policies. Such designs are inadequate in open-ended scenarios, where goal spaces naturally diversify across a broad spectrum of difficulties. We introduce HERAKLES, a framework that enables a two-level hierarchical autotelic agent to continuously compile mastered goals into the low-level policy, executed by a small, fast neural network, dynamically expanding the set of subgoals available to the high-level policy. We train a Large Language Model (LLM) to serve as the high-level controller, exploiting its strengths in goal decomposition and generalization to operate effectively over this evolving subgoal space. We evaluate HERAKLES in the open-ended Crafter environment and show that it scales effectively with goal complexity, improves sample efficiency through skill compilation, and enables the agent to adapt robustly to novel challenges over time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14747v1" target="_blank">Challenges of Virtual Validation and Verification for Automotive Functions</a></h3>
                    <p><strong>Authors:</strong> Beatriz Cabrero-Daniel, Mazen Mohamad</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Verification and validation of vehicles is a complex yet critical process, particularly for ensuring safety and coverage through simulations. However, achieving realistic and useful simulations comes with significant challenges. To explore these challenges, we conducted a workshop with experts in the field, allowing them to brainstorm key obstacles. Following this, we distributed a survey to consolidate findings and gain further insights into potential solutions. The experts identified 17 key challenges, along with proposed solutions, an assessment of whether they represent next steps for research, and the roadblocks to their implementation. While a lack of resources was not initially highlighted as a major challenge, utilizing more resources emerged as a critical necessity when experts discussed solutions. Interestingly, we expected some of these challenges to have already been addressed or to have systematic solutions readily available, given the collective expertise in the field. Many of the identified problems already have known solutions, allowing us to shift focus towards unresolved challenges and share the next steps with the broader community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14741v1" target="_blank">CaTE Data Curation for Trustworthy AI</a></h3>
                    <p><strong>Authors:</strong> Mary Versa Clemens-Sewall, Christopher Cervantes, Emma Rafkin, J. Neil Otte, Tom Magelinski, Libby Lewis, Michelle Liu, Dana Udwin, Monique Kirkman-Bey</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> This report provides practical guidance to teams designing or developing AI-enabled systems for how to promote trustworthiness during the data curation phase of development. In this report, the authors first define data, the data curation phase, and trustworthiness. We then describe a series of steps that the development team, especially data scientists, can take to build a trustworthy AI-enabled system. We enumerate the sequence of core steps and trace parallel paths where alternatives exist. The descriptions of these steps include strengths, weaknesses, preconditions, outcomes, and relevant open-source software tool implementations. In total, this report is a synthesis of data curation tools and approaches from relevant academic literature, and our goal is to equip readers with a diverse yet coherent set of practices for improving AI trustworthiness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14734v1" target="_blank">AFABench: A Generic Framework for Benchmarking Active Feature Acquisition</a></h3>
                    <p><strong>Authors:</strong> Valter SchÃ¼tz, Han Wu, Reza Rezvan, Linus Aronsson, Morteza Haghir Chehreghani</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> In many real-world scenarios, acquiring all features of a data instance can be expensive or impractical due to monetary cost, latency, or privacy concerns. Active Feature Acquisition (AFA) addresses this challenge by dynamically selecting a subset of informative features for each data instance, trading predictive performance against acquisition cost. While numerous methods have been proposed for AFA, ranging from greedy information-theoretic strategies to non-myopic reinforcement learning approaches, fair and systematic evaluation of these methods has been hindered by the lack of standardized benchmarks. In this paper, we introduce AFABench, the first benchmark framework for AFA. Our benchmark includes a diverse set of synthetic and real-world datasets, supports a wide range of acquisition policies, and provides a modular design that enables easy integration of new methods and tasks. We implement and evaluate representative algorithms from all major categories, including static, greedy, and reinforcement learning-based approaches. To test the lookahead capabilities of AFA policies, we introduce a novel synthetic dataset, AFAContext, designed to expose the limitations of greedy selection. Our results highlight key trade-offs between different AFA strategies and provide actionable insights for future research. The benchmark code is available at: https://github.com/Linusaronsson/AFA-Benchmark.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14729v1" target="_blank">Multiscale Video Transformers for Class Agnostic Segmentation in Autonomous Driving</a></h3>
                    <p><strong>Authors:</strong> Leila Cheshmi, Mennatullah Siam</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Ensuring safety in autonomous driving is a complex challenge requiring handling unknown objects and unforeseen driving scenarios. We develop multiscale video transformers capable of detecting unknown objects using only motion cues. Video semantic and panoptic segmentation often relies on known classes seen during training, overlooking novel categories. Recent visual grounding with large language models is computationally expensive, especially for pixel-level output. We propose an efficient video transformer trained end-to-end for class-agnostic segmentation without optical flow. Our method uses multi-stage multiscale query-memory decoding and a scale-specific random drop-token to ensure efficiency and accuracy, maintaining detailed spatiotemporal features with a shared, learnable memory module. Unlike conventional decoders that compress features, our memory-centric design preserves high-resolution information at multiple scales. We evaluate on DAVIS16, KITTI, and Cityscapes. Our method consistently outperforms multiscale baselines while being efficient in GPU memory and run-time, demonstrating a promising direction for real-time, robust dense prediction in safety-critical robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14727v1" target="_blank">Assessing the Quality and Security of AI-Generated Code: A Quantitative Analysis</a></h3>
                    <p><strong>Authors:</strong> Abbas Sabra, Olivier Schmitt, Joseph Tyler</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.LG</p>
                    <p><strong>Summary:</strong> This study presents a quantitative evaluation of the code quality and security of five prominent Large Language Models (LLMs): Claude Sonnet 4, Claude 3.7 Sonnet, GPT-4o, Llama 3.2 90B, and OpenCoder 8B. While prior research has assessed the functional performance of LLM-generated code, this research tested LLM output from 4,442 Java coding assignments through comprehensive static analysis using SonarQube. The findings suggest that although LLMs can generate functional code, they also introduce a range of software defects, including bugs, security vulnerabilities, and code smells. These defects do not appear to be isolated; rather, they may represent shared weaknesses stemming from systemic limitations within current LLM code generation methods. In particular, critically severe issues, such as hard-coded passwords and path traversal vulnerabilities, were observed across multiple models. These results indicate that LLM-generated code requires verification in order to be considered production-ready. This study found no direct correlation between a models functional performance (measured by Pass@1 rate of unit tests) and the overall quality and security of its generated code, measured by the number of SonarQube issues in benchmark solutions that passed the functional tests. This suggests that functional benchmark performance score is not a good indicator of overall code quality and security. The goal of this study is not to rank LLM performance but to highlight that all evaluated models appear to share certain weaknesses. Consequently, these findings support the view that static analysis can be a valuable instrument for detecting latent defects and an important safeguard for organizations that deploy AI in software development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14725v1" target="_blank">Emerson-Lei and Manna-Pnueli Games for LTLf+ and PPLTL+ Synthesis</a></h3>
                    <p><strong>Authors:</strong> Daniel Hausmann, Shufang Zhu, Gianmarco Parretti, Christoph Weinhuber, Giuseppe De Giacomo, Nir Piterman</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI, cs.FL</p>
                    <p><strong>Summary:</strong> Recently, the Manna-Pnueli Hierarchy has been used to define the temporal logics LTLfp and PPLTLp, which allow to use finite-trace LTLf/PPLTL techniques in infinite-trace settings while achieving the expressiveness of full LTL. In this paper, we present the first actual solvers for reactive synthesis in these logics. These are based on games on graphs that leverage DFA-based techniques from LTLf/PPLTL to construct the game arena. We start with a symbolic solver based on Emerson-Lei games, which reduces lower-class properties (guarantee, safety) to higher ones (recurrence, persistence) before solving the game. We then introduce Manna-Pnueli games, which natively embed Manna-Pnueli objectives into the arena. These games are solved by composing solutions to a DAG of simpler Emerson-Lei games, resulting in a provably more efficient approach. We implemented the solvers and practically evaluated their performance on a range of representative formulas. The results show that Manna-Pnueli games often offer significant advantages, though not universally, indicating that combining both approaches could further enhance practical performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14718v1" target="_blank">The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language Models for Recipe Generation</a></h3>
                    <p><strong>Authors:</strong> Shubham Pundhir, Ganesh Bagler</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We established a rigorous benchmark for text-based recipe generation, a fundamental task in natural language generation. We present a comprehensive comparative study contrasting a fine-tuned GPT-2 large (774M) model against the GPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine corpus from RecipeDB. Our key contribution is a targeted tokenization strategy that augments the vocabulary with 23 common fraction tokens and custom structural markers. This approach addresses a critical limitation of generic tokenizers by preserving essential recipe structures and precise numerical quantities, thereby enhancing domain specificity. Performance is evaluated using a comprehensive suite of seven automatic metrics spanning fluency (BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and diversity. Our experiments show that the large transformer-based approach yields a 20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the best recurrent baseline, while reducing perplexity by 69.8%. We conclude with a discussion of remaining challenges, particularly regarding factual accuracy, and outline how this foundational study paves the way for integrating real-world constraints and multi-modal inputs in advanced recipe generation research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14710v1" target="_blank">Data-Driven Probabilistic Evaluation of Logic Properties with PAC-Confidence on Mealy Machines</a></h3>
                    <p><strong>Authors:</strong> Swantje Plambeck, Ali Salamati, Eyke Huellermeier, Goerschwin Fey</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Cyber-Physical Systems (CPS) are complex systems that require powerful models for tasks like verification, diagnosis, or debugging. Often, suitable models are not available and manual extraction is difficult. Data-driven approaches then provide a solution to, e.g., diagnosis tasks and verification problems based on data collected from the system. In this paper, we consider CPS with a discrete abstraction in the form of a Mealy machine. We propose a data-driven approach to determine the safety probability of the system on a finite horizon of n time steps. The approach is based on the Probably Approximately Correct (PAC) learning paradigm. Thus, we elaborate a connection between discrete logic and probabilistic reachability analysis of systems, especially providing an additional confidence on the determined probability. The learning process follows an active learning paradigm, where new learning data is sampled in a guided way after an initial learning set is collected. We validate the approach with a case study on an automated lane-keeping system.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14704v1" target="_blank">MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers</a></h3>
                    <p><strong>Authors:</strong> Ziyang Luo, Zhiqi Shen, Wenzhuo Yang, Zirui Zhao, Prathyusha Jwalapuram, Amrita Saha, Doyen Sahoo, Silvio Savarese, Caiming Xiong, Junnan Li</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms. However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching. To ensure rigorous evaluation, we implement execution-based evaluators, including format evaluators for agent format compliance, static evaluators for time-invariant content matching, and dynamic evaluators that automatically retrieve real-time ground truth for temporally sensitive tasks. Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. In addition, our benchmark poses a significant long-context challenge for LLM agents, as the number of input tokens increases rapidly with the number of interaction steps. Moreover, it introduces an unknown-tools challenge, as LLM agents often lack familiarity with the precise usage of the MCP servers. Notably, enterprise-level agents like Cursor cannot achieve better performance than standard ReAct frameworks. Beyond evaluation, we open-source our extensible evaluation framework with UI support, enabling researchers and practitioners to seamlessly integrate new agents and MCP servers while fostering innovation in the rapidly evolving MCP ecosystem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14692v1" target="_blank">Sociotechnical Imaginaries of ChatGPT in Higher Education: The Evolving Media Discourse</a></h3>
                    <p><strong>Authors:</strong> Yinan Sun, Ali Unlu, Aditya Johri</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This study investigates how U.S. news media framed the use of ChatGPT in higher education from November 2022 to October 2024. Employing Framing Theory and combining temporal and sentiment analysis of 198 news articles, we trace the evolving narratives surrounding generative AI. We found that the media discourse largely centered on institutional responses; policy changes and teaching practices showed the most consistent presence and positive sentiment over time. Conversely, coverage of topics such as human-centered learning, the job market, and skill development appeared more sporadically, with initially uncertain portrayals gradually shifting toward cautious optimism. Importantly, media sentiment toward ChatGPTs role in college admissions remained predominantly negative. Our findings suggest that media narratives prioritize institutional responses to generative AI over long-term, broader ethical, social, and labor-related implications, shaping an emerging sociotechnical imaginary that frames generative AI in education primarily through the lens of adaptation and innovation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14684v1" target="_blank">Addressing Graph Anomaly Detection via Causal Edge Separation and Spectrum</a></h3>
                    <p><strong>Authors:</strong> Zengyi Wo, Wenjun Wang, Minglai Shao, Chang Liu, Yumeng Wang, Yueheng Sun</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In the real world, anomalous entities often add more legitimate connections while hiding direct links with other anomalous entities, leading to heterophilic structures in anomalous networks that most GNN-based techniques fail to address. Several works have been proposed to tackle this issue in the spatial domain. However, these methods overlook the complex relationships between node structure encoding, node features, and their contextual environment and rely on principled guidance, research on solving spectral domain heterophilic problems remains limited. This study analyzes the spectral distribution of nodes with different heterophilic degrees and discovers that the heterophily of anomalous nodes causes the spectral energy to shift from low to high frequencies. To address the above challenges, we propose a spectral neural network CES2-GAD based on causal edge separation for anomaly detection on heterophilic graphs. Firstly, CES2-GAD will separate the original graph into homophilic and heterophilic edges using causal interventions. Subsequently, various hybrid-spectrum filters are used to capture signals from the segmented graphs. Finally, representations from multiple signals are concatenated and input into a classifier to predict anomalies. Extensive experiments with real-world datasets have proven the effectiveness of the method we proposed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14654v1" target="_blank">Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration</a></h3>
                    <p><strong>Authors:</strong> Peilin Ji, Xiao Xue, Simeng Wang, Wenhao Yan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> In recent years, the increasing frequency of extreme urban rainfall events has posed significant challenges to emergency scheduling systems. Urban flooding often leads to severe traffic congestion and service disruptions, threatening public safety and mobility. However, effective decision making remains hindered by three key challenges: (1) managing trade-offs among competing goals (e.g., traffic flow, task completion, and risk mitigation) requires dynamic, context-aware strategies; (2) rapidly evolving environmental conditions render static rules inadequate; and (3) LLM-generated strategies frequently suffer from semantic instability and execution inconsistency. Existing methods fail to align perception, global optimization, and multi-agent coordination within a unified framework. To tackle these challenges, we introduce H-J, a hierarchical multi-agent framework that integrates knowledge-guided prompting, entropy-constrained generation, and feedback-driven optimization. The framework establishes a closed-loop pipeline spanning from multi-source perception to strategic execution and continuous refinement. We evaluate H-J on real-world urban topology and rainfall data under three representative conditions: extreme rainfall, intermittent bursts, and daily light rain. Experiments show that H-J outperforms rule-based and reinforcement-learning baselines in traffic smoothness, task success rate, and system robustness. These findings highlight the promise of uncertainty-aware, knowledge-constrained LLM-based approaches for enhancing resilience in urban flood response.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14644v1" target="_blank">LeanGeo: Formalizing Competitional Geometry problems in Lean</a></h3>
                    <p><strong>Authors:</strong> Chendong Song, Zihan Wang, Frederick Pu, Haiming Wang, Xiaohan Lin, Junqi Liu, Jia Li, Zhengying Liu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Geometry problems are a crucial testbed for AI reasoning capabilities. Most existing geometry solving systems cannot express problems within a unified framework, thus are difficult to integrate with other mathematical fields. Besides, since most geometric proofs rely on intuitive diagrams, verifying geometry problems is particularly challenging. To address these gaps, we introduce LeanGeo, a unified formal system for formalizing and solving competition-level geometry problems within the Lean 4 theorem prover. LeanGeo features a comprehensive library of high-level geometric theorems with Leans foundational logic, enabling rigorous proof verification and seamless integration with Mathlib. We also present LeanGeo-Bench, a formal geometry benchmark in LeanGeo, comprising problems from the International Mathematical Olympiad (IMO) and other advanced sources. Our evaluation demonstrates the capabilities and limitations of state-of-the-art Large Language Models on this benchmark, highlighting the need for further advancements in automated geometric reasoning. We open source the theorem library and the benchmark of LeanGeo at https://github.com/project-numina/LeanGeo/tree/master.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14631v1" target="_blank">Towards a DSL to Formalize Multimodal Requirements</a></h3>
                    <p><strong>Authors:</strong> Marcos Gomez-Vazquez, Jordi Cabot</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Multimodal systems, which process multiple input types such as text, audio, and images, are becoming increasingly prevalent in software systems, enabled by the huge advancements in Machine Learning. This triggers the need to easily define the requirements linked to these new types of user interactions, potentially involving more than one modality at the same time. This remains an open challenge due to the lack of languages and methods adapted to the diverse nature of multimodal interactions, with the risk of implementing AI-enhanced systems that do not properly satisfy the user needs. In this sense, this paper presents MERLAN, a Domain-Specific Language (DSL) to specify the requirements for these new types of multimodal interfaces. We present the metamodel for such language together with a textual syntax implemented as an ANTLR grammar. A prototype tool enabling requirements engineers to write such requirements and automatically generate a possible implementation of a system compliant with them on top of an agentic framework is also provided.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14618v1" target="_blank">A Fuzzy-Enhanced Explainable AI Framework for Flight Continuous Descent Operations Classification</a></h3>
                    <p><strong>Authors:</strong> Amin Noroozi, Sandaruwan K. Sethunge, Elham Norouzi, Phat T. Phan, Kavinda U. Waduge, Md. Arafatur Rahman</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Continuous Descent Operations (CDO) involve smooth, idle-thrust descents that avoid level-offs, reducing fuel burn, emissions, and noise while improving efficiency and passenger comfort. Despite its operational and environmental benefits, limited research has systematically examined the factors influencing CDO performance. Moreover, many existing methods in related areas, such as trajectory optimization, lack the transparency required in aviation, where explainability is critical for safety and stakeholder trust. This study addresses these gaps by proposing a Fuzzy-Enhanced Explainable AI (FEXAI) framework that integrates fuzzy logic with machine learning and SHapley Additive exPlanations (SHAP) analysis. For this purpose, a comprehensive dataset of 29 features, including 11 operational and 18 weather-related features, was collected from 1,094 flights using Automatic Dependent Surveillance-Broadcast (ADS-B) data. Machine learning models and SHAP were then applied to classify flights CDO adherence levels and rank features by importance. The three most influential features, as identified by SHAP scores, were then used to construct a fuzzy rule-based classifier, enabling the extraction of interpretable fuzzy rules. All models achieved classification accuracies above 90%, with FEXAI providing meaningful, human-readable rules for operational users. Results indicated that the average descent rate within the arrival route, the number of descent segments, and the average change in directional heading during descent were the strongest predictors of CDO performance. The FEXAI method proposed in this study presents a novel pathway for operational decision support and could be integrated into aviation tools to enable real-time advisories that maintain CDO adherence under varying operational conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14603v1" target="_blank">Similarities of subspace lattices in Banach spaces</a></h3>
                    <p><strong>Authors:</strong> Janko BraÄiÄ, Marko KandiÄ‡</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> math.FA, 47A15</p>
                    <p><strong>Summary:</strong> A collineation of a subspace lattice $\fL$ in a complex Banach space $\eX$ is an invertible operator $S$ on $\eX$ with the property that the image $S\eM$ of a subspace $\eM$ belongs to $\fL$ if and and only if $\eM$ belongs to it. Hence, $S$ is a collineation of $\fL$ if and only if it implements an order automorphism of $\fL$. We study the group $\Col(\fL)$ of all collineations of $\fL$ and its subgroup $\Grp(\Alg(\fL))$ of all invertible operators that fix every subspace in $\fL$. We show that $\Grp(\Alg(\fL))$ is a normal subgroup of $\Col(\fL)$; moreover, if $\fL$ is a reflexive subspace lattice, then $\Col(\fL)$ is the normalizer of $\Grp(\Alg(\fL))$ in the group of all invertible operators on $\eX$. One of the main questions that we consider is whether $\Grp(\Alg(\fL))$ is a complemented subgroup in $\Col(\fL)$. For certain subspace lattices $\fL$, such as some realizations of the diamond or the double triangle, some nests in the space of continuous functions on $[0,1]$, and the classical Volterra nest in $L^1[0,1]$, we characterize the complement of $\Grp(\Alg(\fL))$ in $\Col(\fL)$. On the other hand, for the Volterra nests in $L^p[0,1]$, where $1p\infty$, a further study is needed, and we prove only some partial results.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14597v1" target="_blank">Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling</a></h3>
                    <p><strong>Authors:</strong> Nitish Kumar Mahala, Muzammil Khan, Pushpendra Kumar</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Fire outbreaks pose critical threats to human life and infrastructure, necessitating high-fidelity early-warning systems that detect combustion precursors such as smoke. However, smoke plumes exhibit complex spatiotemporal dynamics influenced by illumination variability, flow kinematics, and environmental noise, undermining the reliability of traditional detectors. To address these challenges without the logistical complexity of multi-sensor arrays, we propose an information-fusion framework by integrating smoke feature representations extracted from monocular imagery. Specifically, a Two-Phase Uncertainty-Aware Shifted Windows Transformer for robust and reliable smoke detection, leveraging a novel smoke segmentation dataset, constructed via optical flow-based motion encoding, is proposed. The optical flow estimation is performed with a four-color-theorem-inspired dual-phase level-set fractional-order variational model, which preserves motion discontinuities. The resulting color-encoded optical flow maps are fused with appearance cues via a Gaussian Mixture Model to generate binary segmentation masks of the smoke regions. These fused representations are fed into the novel Shifted-Windows Transformer, which is augmented with a multi-scale uncertainty estimation head and trained under a two-phase learning regimen. First learning phase optimizes smoke detection accuracy, while during the second phase, the model learns to estimate plausibility confidence in its predictions by jointly modeling aleatoric and epistemic uncertainties. Extensive experiments using multiple evaluation metrics and comparative analysis with state-of-the-art approaches demonstrate superior generalization and robustness, offering a reliable solution for early fire detection in surveillance, industrial safety, and autonomous monitoring applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14582v1" target="_blank">An Open-Source HW-SW Co-Development Framework Enabling Efficient Multi-Accelerator Systems</a></h3>
                    <p><strong>Authors:</strong> Ryan Albert Antonio, Joren Dumoulin, Xiaoling Yi, Josse Van Delm, Yunhao Deng, Guilherme Paim, Marian Verhelst</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AR, cs.AI</p>
                    <p><strong>Summary:</strong> Heterogeneous accelerator-centric compute clusters are emerging as efficient solutions for diverse AI workloads. However, current integration strategies often compromise data movement efficiency and encounter compatibility issues in hardware and software. This prevents a unified approach that balances performance and ease of use. To this end, we present SNAX, an open-source integrated HW-SW framework enabling efficient multi-accelerator platforms through a novel hybrid-coupling scheme, consisting of loosely coupled asynchronous control and tightly coupled data access. SNAX brings reusable hardware modules designed to enhance compute accelerator utilization, and its customizable MLIR-based compiler to automate key system management tasks, jointly enabling rapid development and deployment of customized multi-accelerator compute clusters. Through extensive experimentation, we demonstrate SNAXs efficiency and flexibility in a low-power heterogeneous SoC. Accelerators can easily be integrated and programmed to achieve  10x improvement in neural network performance compared to other accelerator systems while maintaining accelerator utilization of  90% in full system operation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14580v1" target="_blank">Towards AI-based Sustainable and XR-based human-centric manufacturing: Implementation of ISO 23247 for digital twins of production systems</a></h3>
                    <p><strong>Authors:</strong> Huizhong Cao, Henrik SÃ¶derlund, Qi Fang, Siyuan Chen, Lejla Erdal, Ammar Gubartalla, Paulo Victor Lopes, Guodong Shao, Per Lonnehed, Henri Putto, Abbe Ahmed, Sven Ekered, BjÃ¶rn Johansson</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Since the introduction of Industry 4.0, digital twin technology has significantly evolved, laying the groundwork for a transition toward Industry 5.0 principles centered on human-centricity, sustainability, and resilience. Through digital twins, real-time connected production systems are anticipated to be more efficient, resilient, and sustainable, facilitating communication and connectivity between digital and physical systems. However, environmental performance and integration with virtual reality (VR) and artificial intelligence (AI) of such systems remain challenging. Further exploration of digital twin technologies is needed to validate the real-world impact and benefits. This paper investigates these challenges by implementing a real-time digital twin based on the ISO 23247 standard, connecting the physical factory and simulation software with VR capabilities. This digital twin system provides cognitive assistance and a user-friendly interface for operators, thereby improving cognitive ergonomics. The connection of the Internet of Things (IoT) platform allows the digital twin to have real-time bidirectional communication, collaboration, monitoring, and assistance. A lab-scale drone factory was used as the digital twin application to test and evaluate the ISO 23247 standard and its potential benefits. Additionally, AI integration and environmental performance Key Performance Indicators (KPIs) have been considered as the next stages in improving VR-integrated digital twins. With a solid theoretical foundation and a demonstration of the VR-integrated digital twins, this paper addresses integration issues between various technologies and advances the framework of digital twins based on ISO 23247.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14896v1" target="_blank">Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs</a></h3>
                    <p><strong>Authors:</strong> Haokun Lin, Haobo Xu, Yichen Wu, Ziyu Guo, Renrui Zhang, Zhichao Lu, Ying Wei, Qingfu Zhang, Zhenan Sun</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in diffusion large language models (dLLMs) have introduced a promising alternative to autoregressive (AR) LLMs for natural language generation tasks, leveraging full attention and denoising-based decoding strategies. However, the deployment of these models on edge devices remains challenging due to their massive parameter scale and high resource demands. While post-training quantization (PTQ) has emerged as a widely adopted technique for compressing AR LLMs, its applicability to dLLMs remains largely unexplored. In this work, we present the first systematic study on quantizing diffusion-based language models. We begin by identifying the presence of activation outliers, characterized by abnormally large activation values that dominate the dynamic range. These outliers pose a key challenge to low-bit quantization, as they make it difficult to preserve precision for the majority of values. More importantly, we implement state-of-the-art PTQ methods and conduct a comprehensive evaluation across multiple task types and model variants. Our analysis is structured along four key dimensions: bit-width, quantization method, task category, and model type. Through this multi-perspective evaluation, we offer practical insights into the quantization behavior of dLLMs under different configurations. We hope our findings provide a foundation for future research in efficient dLLM deployment. All codes and experimental setups will be released to support the community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14893v1" target="_blank">Virtual Community: An Open World for Humans, Robots, and Society</a></h3>
                    <p><strong>Authors:</strong> Qinhong Zhou, Hongxin Zhang, Xiangye Lin, Zheyuan Zhang, Yutian Chen, Wenjun Liu, Zunzhe Zhang, Sunli Chen, Lixing Fang, Qiushi Lyu, Xinyu Sun, Jincheng Yang, Zeyuan Wang, Bao Chi Dang, Zhehuan Chen, Daksha Ladia, Jiageng Liu, Chuang Gan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.RO</p>
                    <p><strong>Summary:</strong> The rapid progress in AI and Robotics may lead to a profound societal transformation, as humans and robots begin to coexist within shared communities, introducing both opportunities and challenges. To explore this future, we present Virtual Community-an open-world platform for humans, robots, and society-built on a universal physics engine and grounded in real-world 3D scenes. With Virtual Community, we aim to study embodied social intelligence at scale: 1) How robots can intelligently cooperate or compete; 2) How humans develop social relations and build community; 3) More importantly, how intelligent robots and humans can co-exist in an open world. To support these, Virtual Community features: 1) An open-source multi-agent physics simulator that supports robots, humans, and their interactions within a society; 2) A large-scale, real-world aligned community generation pipeline, including vast outdoor space, diverse indoor scenes, and a community of grounded agents with rich characters and appearances. Leveraging Virtual Community, we propose two novel challenges. The Community Planning Challenge evaluates multi-agent reasoning and planning ability in open-world settings, such as cooperating to help agents with daily activities and efficiently connecting other agents. The Community Robot Challenge requires multiple heterogeneous robots to collaborate in solving complex open-world tasks. We evaluate various baselines on these tasks and demonstrate the challenges in both high-level open-world task planning and low-level cooperation controls. We hope that Virtual Community will unlock further study of human-robot coexistence within open-world environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14891v1" target="_blank">GaussianArt: Unified Modeling of Geometry and Motion for Articulated Objects</a></h3>
                    <p><strong>Authors:</strong> Licheng Shen, Saining Zhang, Honghan Li, Peilin Yang, Zihao Huang, Zongzheng Zhang, Hao Zhao</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Reconstructing articulated objects is essential for building digital twins of interactive environments. However, prior methods typically decouple geometry and motion by first reconstructing object shape in distinct states and then estimating articulation through post-hoc alignment. This separation complicates the reconstruction pipeline and restricts scalability, especially for objects with complex, multi-part articulation. We introduce a unified representation that jointly models geometry and motion using articulated 3D Gaussians. This formulation improves robustness in motion decomposition and supports articulated objects with up to 20 parts, significantly outperforming prior approaches that often struggle beyond 2--3 parts due to brittle initialization. To systematically assess scalability and generalization, we propose MPArt-90, a new benchmark consisting of 90 articulated objects across 20 categories, each with diverse part counts and motion configurations. Extensive experiments show that our method consistently achieves superior accuracy in part-level geometry reconstruction and motion estimation across a broad range of object types. We further demonstrate applicability to downstream tasks such as robotic simulation and human-scene interaction modeling, highlighting the potential of unified articulated representations in scalable physical modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14890v1" target="_blank">Estimating Initial Mass of Gaia-Enceladus Dwarf Galaxy with Chemical Evolution Model</a></h3>
                    <p><strong>Authors:</strong> Olcay Plevne, Furkan Akbaba</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> This work investigates the initial mass and chemical evolution history of the Gaia-Enceladus dwarf galaxy. We combine spectroscopic data from APOGEE with astrometric data from Gaia DR3 to identify Gaia-Enceladus candidate stars via a machine-learning pipeline using t-SNE and HDBSCAN. By focusing on kinematic and chemical parameters, especially $\mathrm{[Fe/H]}$, $\mathrm{[Mg/Fe]}$, $\mathrm{[Al/Fe]}$, and $\mathrm{[Mn/Fe]}$, we uncover a population of metal-poor, high-eccentricity stars that align with literature criteria for Gaia-Enceladus debris. We then apply the \textit{OMEGA+} chemical evolution model, incorporating MCMC fitting of the observed abundance trends in the $\mathrm{[Mg/Fe]\times[Fe/H]}$ plane. Our best-fitting model indicates a gas mass of $4.93_{-0.72}^{+0.32}\times10^9\,{M_{\odot}}$ for Gaia-Enceladus, placing it at the higher end of previously suggested mass ranges. The model scenario suggests a short star formation timescale, substantial outflows, and a rapid build-up of metals mainly driven by core-collapse supernovae, with a lesser contribution from Type~Ia supernovae. Comparison with observational data in other chemical planes (e.g., $\mathrm{[Mg/Mn]\times[Al/Fe]}$) supports this scenario, emphasizing a distinct evolution path relative to the Milky Way. Additionally, our results provide indirect evidence that star formation in Gaia-Enceladus likely ceased within the first 4 Gyr, consistent with earlier inferences of an early merger event. These findings highlight the power of chemical evolution modeling in reconstructing the origin and mass of ancient accreted systems. Overall, we show that Gaia-Enceladus, through a rapid star formation and strong outflows, contributed a significant fraction of the metal-poor stellar halo of the Milky Way.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14889v1" target="_blank">MS-CLR: Multi-Skeleton Contrastive Learning for Human Action Recognition</a></h3>
                    <p><strong>Authors:</strong> Mert Kiray, Alvaro Ritter, Nassir Navab, Benjamin Busam</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Contrastive learning has gained significant attention in skeleton-based action recognition for its ability to learn robust representations from unlabeled data. However, existing methods rely on a single skeleton convention, which limits their ability to generalize across datasets with diverse joint structures and anatomical coverage. We propose Multi-Skeleton Contrastive Learning (MS-CLR), a general self-supervised framework that aligns pose representations across multiple skeleton conventions extracted from the same sequence. This encourages the model to learn structural invariances and capture diverse anatomical cues, resulting in more expressive and generalizable features. To support this, we adapt the ST-GCN architecture to handle skeletons with varying joint layouts and scales through a unified representation scheme. Experiments on the NTU RGB+D 60 and 120 datasets demonstrate that MS-CLR consistently improves performance over strong single-skeleton contrastive learning baselines. A multi-skeleton ensemble further boosts performance, setting new state-of-the-art results on both datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14883v1" target="_blank">The Cost Advantage of Virtual Machine Migrations: Empirical Insights into Amazons EC2 Marketspace</a></h3>
                    <p><strong>Authors:</strong> Benedikt Pittl, Werner Mach, Erich Schikuta</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC, cs.GT, 91-08, J.1; H.1.m</p>
                    <p><strong>Summary:</strong> In recent years, cloud providers have introduced novel approaches for trading virtual machines. For example, Virtustream introduced so-called muVMs to charge cloud computing resources while other providers such as Google, Microsoft, or Amazon re-invented their marketspaces. Today, the market leader Amazon runs six marketspaces for trading virtual machines. Consumers can purchase bundles of virtual machines, which are called cloud-portfolios, from multiple marketspaces and providers. An industry-relevant field of research is to identify best practices and guidelines on how such optimal portfolios are created. In the paper at hand, a cost analysis of cloud portfolios is presented. Therefore, pricing data from Amazon was used as well as a real virtual machine utilization dataset from the Bitbrains datacenter. The results show that a cost optimum can only be reached if heterogeneous portfolios are created where virtual machines are purchased from different marketspaces. Additionally, the cost-benefit of migrating virtual machines to different marketplaces during runtime is presented. Such migrations are especially cost-effective for virtual machines of cloud-portfolios which run between 6 hours and 1 year. The paper further shows that most of the resources of virtual machines are never utilized by consumers, which represents a significant future potential for cost optimization. For the validation of the results, a second dataset of the Bitbrains datacenter was used, which contains utility data of virtual machines from a different domain of application.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14880v1" target="_blank">MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework</a></h3>
                    <p><strong>Authors:</strong> Ailing Yu, Lan Yao, Jingnan Liu, Zhe Chen, Jiajun Yin, Yuan Wang, Xinhao Liao, Zhiling Ye, Ji Li, Yun Yue, Hansong Xiao, Hualei Zhou, Chunxiao Guo, Peng Wei, Jinjie Gu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent developments in Large Language Model (LLM)-based agents have shown impressive capabilities spanning multiple domains, exemplified by deep research systems that demonstrate superior performance on complex information-seeking and synthesis tasks. While general-purpose deep research agents have shown impressive capabilities, they struggle significantly with medical domain challenges, as evidenced by leading proprietary systems achieving limited accuracy on complex medical benchmarks. The key limitations are: (1) the model lacks sufficient dense medical knowledge for clinical reasoning, and (2) the framework is constrained by the absence of specialized retrieval tools tailored for medical contexts.We present a medical deep research agent that addresses these challenges through two core innovations. First, we develop a novel data synthesis framework using medical knowledge graphs, extracting the longest chains from subgraphs around rare medical entities to generate complex multi-hop question-answer pairs. Second, we integrate a custom-built private medical retrieval engine alongside general-purpose tools, enabling accurate medical information synthesis. Our approach generates 2100+ diverse trajectories across 12 medical specialties, each averaging 4.2 tool interactions.Through a two-stage training paradigm combining supervised fine-tuning and online reinforcement learning with composite rewards, our MedResearcher-R1-32B model demonstrates exceptional performance, establishing new state-of-the-art results on medical benchmarks while maintaining competitive performance on general deep research tasks. Our work demonstrates that strategic domain-specific innovations in architecture, tool design, and training data construction can enable smaller open-source models to outperform much larger proprietary systems in specialized domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14878v1" target="_blank">Lifespan Pancreas Morphology for Control vs Type 2 Diabetes using AI on Largescale Clinical Imaging</a></h3>
                    <p><strong>Authors:</strong> Lucas W. Remedios, Chloe Cho, Trent M. Schwartz, Dingjie Su, Gaurav Rudravaram, Chenyu Gao, Aravind R. Krishnan, Adam M. Saunders, Michael E. Kim, Shunxing Bao, Thomas A. Lasko, Alvin C. Powers, Bennett A. Landman, John Virostko</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Purpose: Understanding how the pancreas changes is critical for detecting deviations in type 2 diabetes and other pancreatic disease. We measure pancreas size and shape using morphological measurements from ages 0 to 90. Our goals are to 1) identify reliable clinical imaging modalities for AI-based pancreas measurement, 2) establish normative morphological aging trends, and 3) detect potential deviations in type 2 diabetes. Approach: We analyzed a clinically acquired dataset of 2533 patients imaged with abdominal CT or MRI. We resampled the scans to 3mm isotropic resolution, segmented the pancreas using automated methods, and extracted 13 morphological pancreas features across the lifespan. First, we assessed CT and MRI measurements to determine which modalities provide consistent lifespan trends. Second, we characterized distributions of normative morphological patterns stratified by age group and sex. Third, we used GAMLSS regression to model pancreas morphology trends in 1350 patients matched for age, sex, and type 2 diabetes status to identify any deviations from normative aging associated with type 2 diabetes. Results: When adjusting for confounders, the aging trends for 10 of 13 morphological features were significantly different between patients with type 2 diabetes and non-diabetic controls (p  0.05 after multiple comparisons corrections). Additionally, MRI appeared to yield different pancreas measurements than CT using our AI-based method. Conclusions: We provide lifespan trends demonstrating that the size and shape of the pancreas is altered in type 2 diabetes using 675 control patients and 675 diabetes patients. Moreover, our findings reinforce that the pancreas is smaller in type 2 diabetes. Additionally, we contribute a reference of lifespan pancreas morphology from a large cohort of non-diabetic control patients in a clinical setting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14875v1" target="_blank">The Alma catalogue of OB stars. III. A cross-match with Gaia DR3 and an extension based on new spectral classifications</a></h3>
                    <p><strong>Authors:</strong> M. Pantaleoni GonzÃ¡lez, J. MaÃ­z ApellÃ¡niz, R. H. BarbÃ¡, B. Cameron Reed, S. R. Berlanas, A. Parras Rico, A. Bodaghee</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR, astro-ph.GA</p>
                    <p><strong>Summary:</strong> We present the third installment of the Alma Luminous Star (ALS) catalogue, aimed at creating the most comprehensive and clean sample of Galactic massive stars. This update extends the sample by adding approximately 2000 OB stars, incorporating astrometric and photometric data from the Gaia Data Release 3 (DR3) alongside spectroscopic information from the Galactic O-Star Catalog based on recent ground-based spectroscopic surveys. Rigorous astrometric corrections are applied to Gaia DR3 parallaxes, proper motions, and photometry, ensuring accurate distance estimates through a Bayesian method suited to this stellar populations spatial distribution in the Milky Way. We perform some comparative analyses highlighting the improved distance accuracy over previous versions, underscore the importance of precise spectral classifications with competing catalogues, and identify areas for improvement in Gaia DR3 effective temperature and extinction estimates for massive stars. We also address the challenges of having robust definitions for these objects. In addition, we explore the catalogues ability to trace Galactic features such as spiral arms, spurs and OB associations (with some insights on the nature of Goulds Belt). Finally, we discuss the potential for further expanding the sample with upcoming surveys. This effort marks a significant advancement in the creation of a reliable census of Galactic massive stars, contributing to our understanding of the Milky Ways structure and star formation history. This catalogue should serve as a valuable reference for the massive star community, supporting research on stellar interiors, winds, stellar feedback, and other processes that make OB stars key to the evolution of galaxies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14869v1" target="_blank">The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Hend Al-Khalifa, Raneem Almansour, Layan Abdulrahman Alhuasini, Alanood Alsaleh, Mohamad-Hani Temsah, Mohamad-Hani_Temsah, Ashwag Rafea S Alruwaili</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC, cs.CL</p>
                    <p><strong>Summary:</strong> Prompt engineering has rapidly emerged as a critical skill for effective interaction with large language models (LLMs). However, the cognitive and neural underpinnings of this expertise remain largely unexplored. This paper presents findings from a cross-sectional pilot fMRI study investigating differences in brain functional connectivity and network activity between experts and intermediate prompt engineers. Our results reveal distinct neural signatures associated with higher prompt engineering literacy, including increased functional connectivity in brain regions such as the left middle temporal gyrus and the left frontal pole, as well as altered power-frequency dynamics in key cognitive networks. These findings offer initial insights into the neurobiological basis of prompt engineering proficiency. We discuss the implications of these neurocognitive markers in Natural Language Processing (NLP). Understanding the neural basis of human expertise in interacting with LLMs can inform the design of more intuitive human-AI interfaces, contribute to cognitive models of LLM interaction, and potentially guide the development of AI systems that better align with human cognitive workflows. This interdisciplinary approach aims to bridge the gap between human cognition and machine intelligence, fostering a deeper understanding of how humans learn and adapt to complex AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14853v1" target="_blank">Universal and Transferable Adversarial Attack on Large Language Models Using Exponentiated Gradient Descent</a></h3>
                    <p><strong>Authors:</strong> Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) are increasingly deployed in critical applications, ensuring their robustness and safety alignment remains a major challenge. Despite the overall success of alignment techniques such as reinforcement learning from human feedback (RLHF) on typical prompts, LLMs remain vulnerable to jailbreak attacks enabled by crafted adversarial triggers appended to user prompts. Most existing jailbreak methods either rely on inefficient searches over discrete token spaces or direct optimization of continuous embeddings. While continuous embeddings can be given directly to selected open-source models as input, doing so is not feasible for proprietary models. On the other hand, projecting these embeddings back into valid discrete tokens introduces additional complexity and often reduces attack effectiveness. We propose an intrinsic optimization method which directly optimizes relaxed one-hot encodings of the adversarial suffix tokens using exponentiated gradient descent coupled with Bregman projection, ensuring that the optimized one-hot encoding of each token always remains within the probability simplex. We provide theoretical proof of convergence for our proposed method and implement an efficient algorithm that effectively jailbreaks several widely used LLMs. Our method achieves higher success rates and faster convergence compared to three state-of-the-art baselines, evaluated on five open-source LLMs and four adversarial behavior datasets curated for evaluating jailbreak methods. In addition to individual prompt attacks, we also generate universal adversarial suffixes effective across multiple prompts and demonstrate transferability of optimized suffixes to different LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14848v1" target="_blank">Leveraging Hardware-Aware Computation in Mixed-Precision Matrix Multiply: A Tile-Centric Approach</a></h3>
                    <p><strong>Authors:</strong> Qiao Zhang, Rabab Alomairy, Dali Wang, Zhuowei Gu, Qinglei Cao</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> General Matrix Multiplication (GEMM) is a critical operation underpinning a wide range of applications in high-performance computing (HPC) and artificial intelligence (AI). The emergence of hardware optimized for low-precision arithmetic necessitates a reevaluation of numerical algorithms to leverage mixed-precision computations, achieving improved performance and energy efficiency. This research introduces an adaptive mixed-precision GEMM framework that supports different precision formats at fine-grained tile/block levels. We utilize the PaRSEC runtime system to balance workloads across various architectures. The performance scales well on ARM CPU-based Fugaku supercomputer, Nvidia GPU-based A100 DGX, and AMD GPU-based Frontier supercomputer. This research aims to enhance computational efficiency and accuracy by bridging algorithmic advancements and hardware innovations, driving transformative progress in various applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14828v1" target="_blank">Long Chain-of-Thought Reasoning Across Languages</a></h3>
                    <p><strong>Authors:</strong> Josh Barua, Seun Eisape, Kayo Yin, Alane Suhr</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Scaling inference through long chains-of-thought (CoTs) has unlocked impressive reasoning capabilities in large language models (LLMs), yet the reasoning process remains almost exclusively English-centric. We construct translated versions of two popular English reasoning datasets, fine-tune Qwen 2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT generation across French, Japanese, Latvian, and Swahili. Our experiments reveal three key findings. First, the efficacy of using English as a pivot language varies by language: it provides no benefit for French, improves performance when used as the reasoning language for Japanese and Latvian, and proves insufficient for Swahili where both task comprehension and reasoning remain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but does not eliminate the cross-lingual performance gap. A lightweight fine-tune using only 1k traces still improves performance by over 30\% in Swahili. Third, data quality versus scale trade-offs are language dependent: small, carefully curated datasets suffice for English and French, whereas larger but noisier corpora prove more effective for Swahili and Latvian. Together, these results clarify when and why long CoTs transfer across languages and provide translated datasets to foster equitable multilingual reasoning research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14826v1" target="_blank">Delayed transitions, promoted states and multistability in a pressure-driven nematic under an electric field</a></h3>
                    <p><strong>Authors:</strong> G. McKay, N. J. Mottram</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft</p>
                    <p><strong>Summary:</strong> We consider the effects of an applied pressure gradient on the classical Freedericksz transition, finding a delayed transition, the promotion of particular director configurations and even pressure-induced multistability. Using the theoretical framework developed by Ericksen and Leslie, we find that the applied pressure gradient adapts the normal pitchfork bifurcation at critical applied voltage, leading to both a delayed bifurcation to higher voltages and a transformation from a supercritical to a subcritical bifurcation so that within a range of voltages there are at least two possible steady states. This range of voltages grows with increasing pressure gradient and eventually includes the zero voltage state so that, for sufficiently strong flow, there are at least two steady states at zero applied voltage. For sufficiently high pressure gradients, we also find that flow-alignment can create a completely new attracting steady state, one that is unstable without flow. We provide a flow-strength-electric field parameter plane that summarises the parameter ranges for which there are multiple steady states and suggest realistic mechanisms to move between these states, as well as an analytical model for the delayed Freedericksz transition effect. The novel steady states found in this work give the possibility of director and flow hysteresis in microfluidic devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14825v1" target="_blank">From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning</a></h3>
                    <p><strong>Authors:</strong> Lixiang Yan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> The role of Artificial Intelligence (AI) in education is undergoing a rapid transformation, moving beyond its historical function as an instructional tool towards a new potential as an active participant in the learning process. This shift is driven by the emergence of agentic AI, autonomous systems capable of proactive, goal-directed action. However, the field lacks a robust conceptual framework to understand, design, and evaluate this new paradigm of human-AI interaction in learning. This paper addresses this gap by proposing a novel conceptual framework (the APCP framework) that charts the transition from AI as a tool to AI as a collaborative partner. We present a four-level model of escalating AI agency within human-AI collaborative learning: (1) the AI as an Adaptive Instrument, (2) the AI as a Proactive Assistant, (3) the AI as a Co-Learner, and (4) the AI as a Peer Collaborator. Grounded in sociocultural theories of learning and Computer-Supported Collaborative Learning (CSCL), this framework provides a structured vocabulary for analysing the shifting roles and responsibilities between human and AI agents. The paper further engages in a critical discussion of the philosophical underpinnings of collaboration, examining whether an AI, lacking genuine consciousness or shared intentionality, can be considered a true collaborator. We conclude that while AI may not achieve authentic phenomenological partnership, it can be designed as a highly effective functional collaborator. This distinction has significant implications for pedagogy, instructional design, and the future research agenda for AI in education, urging a shift in focus towards creating learning environments that harness the complementary strengths of both human and AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14823v1" target="_blank">Using an LLM to Investigate Students Explanations on Conceptual Physics Questions</a></h3>
                    <p><strong>Authors:</strong> Sean Savage, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Analyzing students written solutions to physics questions is a major area in PER. However, gauging student understanding in college courses is bottlenecked by large class sizes, which limits assessments to a multiple-choice (MC) format for ease of grading. Although sufficient in quantifying scientifically correct conceptions, MC assessments do not uncover students deeper ways of understanding physics. Large language models (LLMs) offer a promising approach for assessing students written responses at scale. Our study used an LLM, validated by human graders, to classify students written explanations to three questions on the Energy and Momentum Conceptual Survey as correct or incorrect, and organized students incorrect explanations into emergent categories. We found that the LLM (GPT-4o) can fairly assess students explanations, comparable to human graders (0-3% discrepancy). Furthermore, the categories of incorrect explanations were different from corresponding MC distractors, allowing for different and deeper conceptions to become accessible to educators.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14819v1" target="_blank">Synchronization driven acoustics: The nonlinear scattering of a self-oscillating meta-atom</a></h3>
                    <p><strong>Authors:</strong> Alexander K. Stoychev, Xinxin Guo, Ulrich Kuhl, Nicolas Noiray</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> In this study we demonstrate a self-oscillating acoustic meta-atom functioning as an amplifying transistor, where a steady external flow serves as a control signal to switch between reflective (off-state) and transmissive (on-state) regimes. In the on-state, an acoustic limit cycle synchronizes with incident sound waves. This process governs the energy transfer across the device, with a transmission bandwidth dictated by the synchronization region in parameter space (Arnold tongue). Our experimental measurements reveal nonlinear dependence on the incident wave amplitude, enabling perturbation filtering therein and stabilizing downstream acoustic power. All experimentally observed phenomena are quantitatively described by a nonlinear Li\enard-type oscillator featuring saturable gain and linear loss, where the essential parameters can be estimated by independent measurements. This work may offer a paradigm shift in acoustic metamaterials research by leveraging self-oscillation and synchronization processes. Bridging those key concepts from nonlinear dynamics and complex systems with active metamaterial design in acoustics and related disciplines, may establish a broadly applicable framework of field-independent mechanisms for wave manipulation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14814v1" target="_blank">TransLight: Image-Guided Customized Lighting Control with Generative Decoupling</a></h3>
                    <p><strong>Authors:</strong> Zongming Li, Lianghui Zhu, Haocheng Shen, Longjin Ran, Wenyu Liu, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Most existing illumination-editing approaches fail to simultaneously provide customized control of light effects and preserve content integrity. This makes them less effective for practical lighting stylization requirements, especially in the challenging task of transferring complex light effects from a reference image to a user-specified target image. To address this problem, we propose TransLight, a novel framework that enables high-fidelity and high-freedom transfer of light effects. Extracting the light effect from the reference image is the most critical and challenging step in our method. The difficulty lies in the complex geometric structure features embedded in light effects that are highly coupled with content in real-world scenarios. To achieve this, we first present Generative Decoupling, where two fine-tuned diffusion models are used to accurately separate image content and light effects, generating a newly curated, million-scale dataset of image-content-light triplets. Then, we employ IC-Light as the generative model and train our model with our triplets, injecting the reference lighting image as an additional conditioning signal. The resulting TransLight model enables customized and natural transfer of diverse light effects. Notably, by thoroughly disentangling light effects from reference images, our generative decoupling strategy endows TransLight with highly flexible illumination control. Experimental results establish TransLight as the first method to successfully transfer light effects across disparate images, delivering more customized illumination control than existing techniques and charting new directions for research in illumination harmonization and editing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14812v1" target="_blank">Repeating Words for Video-Language Retrieval with Coarse-to-Fine Objectives</a></h3>
                    <p><strong>Authors:</strong> Haoyu Zhao, Jiaxi Gu, Shicong Wang, Xing Zhang, Hang Xu, Zuxuan Wu, Yu-Gang Jiang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The explosive growth of video streaming presents challenges in achieving high accuracy and low training costs for video-language retrieval. However, existing methods rely on large-scale pre-training to improve video retrieval performance, resulting in significant computational demands. Additionally, the fine-grained information in videos and texts remains underexplored. To alleviate these problems, we propose a novel framework to learn fine-grained features for better alignment and introduce an inference pipeline to improve performance without additional training. Specifically, we employ coarse-to-fine objectives to understand the semantic information of video-text pairs, including contrastive and matching learning. The fine-grained data used for training is obtained through the Granularity-Aware Representation module, which is designed based on similarity analysis between video frames and words in captions. Furthermore, we observe that the repetition of keywords in the original captions, referred to as Repetition, can enhance retrieval performance and improve alignment between video and text. Based on this insight, we propose a novel and effective inference pipeline that incorporates a voting mechanism and a new Matching Entropy metric to achieve better retrieval performance without requiring additional pre-training. Experimental results on four benchmarks demonstrate that the proposed method outperforms previous approaches. Additionally, our inference pipeline achieves significant performance improvements, with a 2.1% increase in Recall@1 on the MSR-VTT dataset and a 1.6% increase on the DiDeMo dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14811v1" target="_blank">Tinker: Diffusions Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization</a></h3>
                    <p><strong>Authors:</strong> Canyu Zhao, Xiaoman Li, Tianjian Feng, Zhiyue Zhao, Hao Chen, Chunhua Shen</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Tinker, a versatile framework for high-fidelity 3D editing that operates in both one-shot and few-shot regimes without any per-scene finetuning. Unlike prior techniques that demand extensive per-scene optimization to ensure multi-view consistency or to produce dozens of consistent edited input views, Tinker delivers robust, multi-view consistent edits from as few as one or two images. This capability stems from repurposing pretrained diffusion models, which unlocks their latent 3D awareness. To drive research in this space, we curate the first large-scale multi-view editing dataset and data pipeline, spanning diverse scenes and styles. Building on this dataset, we develop our framework capable of generating multi-view consistent edited views without per-scene training, which consists of two novel components: (1) Referring multi-view editor: Enables precise, reference-driven edits that remain coherent across all viewpoints. (2) Any-view-to-video synthesizer: Leverages spatial-temporal priors from video diffusion to perform high-quality scene completion and novel-view generation even from sparse inputs. Through extensive experiments, Tinker significantly reduces the barrier to generalizable 3D content creation, achieving state-of-the-art performance on editing, novel-view synthesis, and rendering enhancement tasks. We believe that Tinker represents a key step towards truly scalable, zero-shot 3D editing. Project webpage: https://aim-uofa.github.io/Tinker</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14809v1" target="_blank">DINOv3 with Test-Time Training for Medical Image Registration</a></h3>
                    <p><strong>Authors:</strong> Shansong Wang, Mojtaba Safari, Mingzhe Hu, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Xiaofeng Yang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Prior medical image registration approaches, particularly learning-based methods, often require large amounts of training data, which constrains clinical adoption. To overcome this limitation, we propose a training-free pipeline that relies on a frozen DINOv3 encoder and test-time optimization of the deformation field in feature space. Across two representative benchmarks, the method is accurate and yields regular deformations. On Abdomen MR-CT, it attained the best mean Dice score (DSC) of 0.790 together with the lowest 95th percentile Hausdorff Distance (HD95) of 4.9+-5.0 and the lowest standard deviation of Log-Jacobian (SDLogJ) of 0.08+-0.02. On ACDC cardiac MRI, it improves mean DSC to 0.769 and reduces SDLogJ to 0.11 and HD95 to 4.8, a marked gain over the initial alignment. The results indicate that operating in a compact foundation feature space at test time offers a practical and general solution for clinical registration without additional training.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14802v1" target="_blank">Privileged Self-Access Matters for Introspection in AI</a></h3>
                    <p><strong>Authors:</strong> Siyuan Song, Harvey Lederman, Jennifer Hu, Kyle Mahowald</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Whether AI models can introspect is an increasingly important practical question. But there is no consensus on how introspection is to be defined. Beginning from a recently proposed lightweight definition, we argue instead for a thicker one. According to our proposal, introspection in AI is any process which yields information about internal states through a process more reliable than one with equal or lower computational cost available to a third party. Using experiments where LLMs reason about their internal temperature parameters, we show they can appear to have lightweight introspection while failing to meaningfully introspect per our proposed definition.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14801v1" target="_blank">A Guide for Manual Annotation of Scientific Imagery: How to Prepare for Large Projects</a></h3>
                    <p><strong>Authors:</strong> Azim Ahmadzadeh, Rohan Adhyapak, Armin Iraji, Kartik Chaurasiya, V Aparna, Petrus C. Martens</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite the high demand for manually annotated image data, managing complex and costly annotation projects remains under-discussed. This is partly due to the fact that leading such projects requires dealing with a set of diverse and interconnected challenges which often fall outside the expertise of specific domain experts, leaving practical guidelines scarce. These challenges range widely from data collection to resource allocation and recruitment, from mitigation of biases to effective training of the annotators. This paper provides a domain-agnostic preparation guide for annotation projects, with a focus on scientific imagery. Drawing from the authors extensive experience in managing a large manual annotation project, it addresses fundamental concepts including success measures, annotation subjects, project goals, data availability, and essential team roles. Additionally, it discusses various human biases and recommends tools and technologies to improve annotation quality and efficiency. The goal is to encourage further research and frameworks for creating a comprehensive knowledge base to reduce the costs of manual annotation projects across various fields.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14796v1" target="_blank">A Guide to Stakeholder Analysis for Cybersecurity Researchers</a></h3>
                    <p><strong>Authors:</strong> James C Davis, Sophie Chen, Huiyun Peng, Paschal C Amusuo, Kelechi G Kalu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.SE</p>
                    <p><strong>Summary:</strong> Stakeholder-based ethics analysis is now a formal requirement for submissions to top cybersecurity research venues. This requirement reflects a growing consensus that cybersecurity researchers must go beyond providing capabilities to anticipating and mitigating the potential harms thereof. However, many cybersecurity researchers may be uncertain about how to proceed in an ethics analysis. In this guide, we provide practical support for that requirement by enumerating stakeholder types and mapping them to common empirical research methods. We also offer worked examples to demonstrate how researchers can identify likely stakeholder exposures in real-world projects. Our goal is to help research teams meet new ethics mandates with confidence and clarity, not confusion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14790v1" target="_blank">Exploring the Interplay Between Quantum Entanglement and Decoherence</a></h3>
                    <p><strong>Authors:</strong> Samuel Marquez Gonzalez</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum entanglement manifests as a distinctive correlation between particles that transcends classical boundaries when their quantum states cannot be described independently. On the other hand, as quantum systems interact with their surroundings, decoherence emerges, leading to the gradual decay of quantum coherence and entanglement. In the case of entanglement, this is known as entanglement sudden death (ESD). Decoherence mechanisms are examined, focusing on how various environmental factors, such as thermal, electromagnetic, and collisional decoherence, influence the integrity of entangled states. The role of quantum noise, such as amplitude damping, phase damping, and depolarizing, is also analyzed. By integrating theoretical insights with experimental findings, this study highlights the delicate balance between maintaining entanglement and mitigating decoherence. The findings have significant implications for the development of quantum technologies, including quantum computing and quantum communication, where preserving entanglement is crucial for achieving robust and reliable performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14789v1" target="_blank">Quantifying How Much Has Been Learned from a Research Study</a></h3>
                    <p><strong>Authors:</strong> Jonas M. Mikhaeil, Donald P. Green</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.AP</p>
                    <p><strong>Summary:</strong> How much does a research study contribute to a scientific literature? We propose a learning metric to quantify how much a research community learns from a given study. To do so, we adopt a Bayesian perspective and assess changes in the communitys beliefs once updated with a new studys evidence. We recommend the Wasserstein-2 distance as a way to describe how the research communitys prior beliefs change to incorporate a studys findings. We illustrate this approach through stylized examples and empirical applications, showing how it differs from more traditional evaluative standards, such as statistical significance. We then extend the framework to the prospective setting, offering a way for decision-makers to evaluate the expected amount of learning from a proposed study. While assessments about what has or could be learned from a research program are often expressed informally, our learning metric provides a principled tool for judging scientific contributions. By formalizing these judgments, our measure has the potential to allow for more transparent assessments of past and prospective research contributions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14787v1" target="_blank">Challenges and Opportunities for Participatory Design of Conversational Agents for Young Peoples Wellbeing</a></h3>
                    <p><strong>Authors:</strong> Natalia Kucirkova, Alexis Hiniker, Megumi Ishikawa, Sho Tsuji, Aayushi Dangol, Robert Wolfe</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY</p>
                    <p><strong>Summary:</strong> This paper outlines the challenges and opportunities of research on conversational agents with children and young people across four countries, exploring the ways AI technologies can support childrens well-being across social and cultural contexts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14780v1" target="_blank">Context Steering: A New Paradigm for Compression-based Embeddings by Synthesizing Relevant Information Features</a></h3>
                    <p><strong>Authors:</strong> Guillermo Sarasa DurÃ¡n, Ana Granados Fontecha, Francisco de Borja RodrÃ­guez OrtÃ­z</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> Compression-based distances (CD) offer a flexible and domain-agnostic means of measuring similarity by identifying implicit information through redundancies between data objects. However, as similarity features are derived from the data, rather than defined as an input, it often proves difficult to align with the task at hand, particularly in complex clustering or classification settings. To address this issue, we introduce context steering, a novel methodology that actively guides the feature-shaping process. Instead of passively accepting the emergent data structure (typically a hierarchy derived from clustering CDs), our approach steers the process by systematically analyzing how each object influences the relational context within a clustering framework. This process generates a custom-tailored embedding that isolates and amplifies class-distinctive information. We validate the capabilities of this strategy using Normalized Compression Distance (NCD) and Relative Compression Distance (NRC) with common hierarchical clustering, providing an effective alternative to common transductive methods. Experimental results across heterogeneous datasets-from text to real-world audio-validate the robustness and generality of context steering, marking a fundamental shift in their application: from merely discovering inherent data structures to actively shaping a feature space tailored to a specific objective.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14778v1" target="_blank">Analyzing Undergraduate Problem-Solving in Physics Through Interaction With an AI Chatbot</a></h3>
                    <p><strong>Authors:</strong> Syed Furqan Abbas Hashmi, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Providing individualized scaffolding for physics problem solving at scale remains an instructional challenge. We investigate (1) students perceptions of a Socratic Artificial Intelligence (AI) chatbots impact on problem-solving skills and confidence and (2) how the specificity of students questions during tutoring relates to performance. We deployed a custom Socratic AI chatbot in a large-enrollment introductory mechanics course at a Midwestern public university, logging full dialogue transcripts from 150 first-year STEM majors. Post-interaction surveys revealed median ratings of 4.0/5 for knowledge-based skills and 3.4/5 for overall effectiveness. Transcript analysis showed question specificity rose from approximately 10-15% in the first turn to 100% by the final turn, and specificity correlated positively with self reported expected course grade (Pearson r = 0.43). These findings demonstrate that AI-driven Socratic dialogue not only fosters expert-like reasoning but also generates fine-grained analytics for physics education research, establishing a scalable dual-purpose tool for instruction and learning analytics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14770v1" target="_blank">Non-Existent Outcomes in Research on Inequality: A Causal Approach</a></h3>
                    <p><strong>Authors:</strong> Ian Lundberg, Soonhong Cho</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.AP, 62D20, J.4; G.3</p>
                    <p><strong>Summary:</strong> Scholars of social stratification often study exposures that shape life outcomes. But some outcomes (such as wage) only exist for some people (such as those who are employed). We show how a common practice -- dropping cases with non-existent outcomes -- can obscure causal effects when a treatment affects both outcome existence and outcome values. The effects of both beneficial and harmful treatments can be underestimated. Drawing on existing approaches for principal stratification, we show how to study (1) the average effect on whether an outcome exists and (2) the average effect on the outcome among the latent subgroup whose outcome would exist in either treatment condition. To extend our approach to the selection-on-observables settings common in applied research, we develop a framework involving regression and simulation to enable principal stratification estimates that adjust for measured confounders. We illustrate through an empirical example about the effects of parenthood on labor market outcomes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14767v1" target="_blank">Fusing Monocular RGB Images with AIS Data to Create a 6D Pose Estimation Dataset for Marine Vessels</a></h3>
                    <p><strong>Authors:</strong> Fabian Holst, Emre GÃ¼lsoylu, Simone Frintrop</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> The paper presents a novel technique for creating a 6D pose estimation dataset for marine vessels by fusing monocular RGB images with Automatic Identification System (AIS) data. The proposed technique addresses the limitations of relying purely on AIS for location information, caused by issues like equipment reliability, data manipulation, and transmission delays. By combining vessel detections from monocular RGB images, obtained using an object detection network (YOLOX-X), with AIS messages, the technique generates 3D bounding boxes that represent the vessels 6D poses, i.e. spatial and rotational dimensions. The paper evaluates different object detection models to locate vessels in image space. We also compare two transformation methods (homography and Perspective-n-Point) for aligning AIS data with image coordinates. The results of our work demonstrate that the Perspective-n-Point (PnP) method achieves a significantly lower projection error compared to homography-based approaches used before, and the YOLOX-X model achieves a mean Average Precision (mAP) of 0.80 at an Intersection over Union (IoU) threshold of 0.5 for relevant vessel classes. We show indication that our approach allows the creation of a 6D pose estimation dataset without needing manual annotation. Additionally, we introduce the Boats on Nordelbe Kehrwieder (BONK-pose), a publicly available dataset comprising 3753 images with 3D bounding box annotations for pose estimation, created by our data fusion approach. This dataset can be used for training and evaluating 6D pose estimation networks. In addition we introduce a set of 1000 images with 2D bounding box annotations for ship detection from the same scene.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14764v1" target="_blank">Investigation of the Inter-Rater Reliability between Large Language Models and Human Raters in Qualitative Analysis</a></h3>
                    <p><strong>Authors:</strong> Nikhil Sanjay Borse, Ravishankar Chatta Subramaniam, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Qualitative analysis is typically limited to small datasets because it is time-intensive. Moreover, a second human rater is required to ensure reliable findings. Artificial intelligence tools may replace human raters if we demonstrate high reliability compared to human ratings. We investigated the inter-rater reliability of state-of-the-art Large Language Models (LLMs), ChatGPT-4o and ChatGPT-4.5-preview, in rating audio transcripts coded manually. We explored prompts and hyperparameters to optimize model performance. The participants were 14 undergraduate student groups from a university in the midwestern United States who discussed problem-solving strategies for a project. We prompted an LLM to replicate manual coding, and calculated Cohens Kappa for inter-rater reliability. After optimizing model hyperparameters and prompts, the results showed substantial agreement (${\kappa}0.6$) for three themes and moderate agreement on one. Our findings demonstrate the potential of GPT-4o and GPT-4.5 for efficient, scalable qualitative analysis in physics education and identify their limitations in rating domain-general constructs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14760v1" target="_blank">Dual-Role Dynamics in Prompting: Elementary Pre-service Teachers AI Prompting Strategies for Representational Choices</a></h3>
                    <p><strong>Authors:</strong> Razan Hamed, Amogh Sirnoorkar, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Pre-service teachers play a unique dual role as they straddle between the roles of students and future teachers. This dual role requires them to adopt both the learners and the instructors perspectives while engaging with pedagogical and content knowledge. The current study investigates how pre-service elementary teachers taking a physical science course prompt AI to generate representations that effectively communicate conceptual ideas to two distinct audiences. The context involves participants interacting with AI to generate appropriate representations that explain the concepts of wave velocity to their elementary students (while casting themselves as teachers) and the Ideal Gas Law to their English teachers (while casting themselves as students). Emergent coding of the AI prompts highlight that, when acting as teachers, participants were more explicit in specifying the target audience, predetermining the type of representation, and producing a broader variety of representations compared to when they acted as students. Implications of the observed exploratory and prescriptive prompting trends across the two roles on pre-service teachers education and their professional development are discussed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14759v1" target="_blank">Students Perceptions to a Large Language Models Generated Feedback and Scores of Argumentation Essays</a></h3>
                    <p><strong>Authors:</strong> Winter Allen, Anand Shanker, N. Sanjay Rebello</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Students in introductory physics courses often rely on ineffective strategies, focusing on final answers rather than understanding underlying principles. Integrating scientific argumentation into problem-solving fosters critical thinking and links conceptual knowledge with practical application. By facilitating learners to articulate their scientific arguments for solving problems, and by providing real-time feedback on students strategies, we aim to enable students to develop superior problem-solving skills. Providing timely, individualized feedback to students in large-enrollment physics courses remains a challenge. Recent advances in Artificial Intelligence (AI) offer promising solutions. This study investigates the potential of AI-generated feedback on students written scientific arguments in an introductory physics class. Using Open AIs GPT-4o, we provided delayed feedback on student written scientific arguments and surveyed them about the perceived usefulness and accuracy of this feedback. Our findings offer insights into the viability of implementing real-time AI feedback to enhance students problem-solving and metacognitive skills in large-enrollment classrooms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14754v1" target="_blank">Near-resonant nuclear spin detection with megahertz mechanical resonators</a></h3>
                    <p><strong>Authors:</strong> Diego A. Visani, Letizia Catalini, Christian L. Degen, Alexander Eichler, Javier del Pino</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Mechanical resonators operating in the megahertz range have become a versatile platform for fundamental and applied quantum research. Their exceptional properties, such as low mass and high quality factor, make them also appealing for force sensing experiments. In this work, we propose a method for detecting, and ultimately controlling, nuclear spins by coupling them to megahertz resonators via a magnetic field gradient. Dynamical backaction between the sensor and an ensemble of $N$ nuclear spins produces a shift in the sensors resonance frequency. The mean frequency shift due to the Boltzmann polarization is challenging to measure in nanoscale sample volumes. Here, we show that the fluctuating polarization of the spin ensemble results in a measurable increase of the resonators frequency variance. On the basis of analytical as well as numerical results, we predict that the variance measurement will allow single nuclear spin detection with existing resonator devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14751v1" target="_blank">HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents</a></h3>
                    <p><strong>Authors:</strong> Thomas Carta, ClÃ©ment Romac, Loris Gaven, Pierre-Yves Oudeyer, Olivier Sigaud, Sylvain Lamprier</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Open-ended AI agents need to be able to learn efficiently goals of increasing complexity, abstraction and heterogeneity over their lifetime. Beyond sampling efficiently their own goals, autotelic agents specifically need to be able to keep the growing complexity of goals under control, limiting the associated growth in sample and computational complexity. To adress this challenge, recent approaches have leveraged hierarchical reinforcement learning (HRL) and language, capitalizing on its compositional and combinatorial generalization capabilities to acquire temporally extended reusable behaviours. Existing approaches use expert defined spaces of subgoals over which they instantiate a hierarchy, and often assume pre-trained associated low-level policies. Such designs are inadequate in open-ended scenarios, where goal spaces naturally diversify across a broad spectrum of difficulties. We introduce HERAKLES, a framework that enables a two-level hierarchical autotelic agent to continuously compile mastered goals into the low-level policy, executed by a small, fast neural network, dynamically expanding the set of subgoals available to the high-level policy. We train a Large Language Model (LLM) to serve as the high-level controller, exploiting its strengths in goal decomposition and generalization to operate effectively over this evolving subgoal space. We evaluate HERAKLES in the open-ended Crafter environment and show that it scales effectively with goal complexity, improves sample efficiency through skill compilation, and enables the agent to adapt robustly to novel challenges over time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14747v1" target="_blank">Challenges of Virtual Validation and Verification for Automotive Functions</a></h3>
                    <p><strong>Authors:</strong> Beatriz Cabrero-Daniel, Mazen Mohamad</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Verification and validation of vehicles is a complex yet critical process, particularly for ensuring safety and coverage through simulations. However, achieving realistic and useful simulations comes with significant challenges. To explore these challenges, we conducted a workshop with experts in the field, allowing them to brainstorm key obstacles. Following this, we distributed a survey to consolidate findings and gain further insights into potential solutions. The experts identified 17 key challenges, along with proposed solutions, an assessment of whether they represent next steps for research, and the roadblocks to their implementation. While a lack of resources was not initially highlighted as a major challenge, utilizing more resources emerged as a critical necessity when experts discussed solutions. Interestingly, we expected some of these challenges to have already been addressed or to have systematic solutions readily available, given the collective expertise in the field. Many of the identified problems already have known solutions, allowing us to shift focus towards unresolved challenges and share the next steps with the broader community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14741v1" target="_blank">CaTE Data Curation for Trustworthy AI</a></h3>
                    <p><strong>Authors:</strong> Mary Versa Clemens-Sewall, Christopher Cervantes, Emma Rafkin, J. Neil Otte, Tom Magelinski, Libby Lewis, Michelle Liu, Dana Udwin, Monique Kirkman-Bey</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> This report provides practical guidance to teams designing or developing AI-enabled systems for how to promote trustworthiness during the data curation phase of development. In this report, the authors first define data, the data curation phase, and trustworthiness. We then describe a series of steps that the development team, especially data scientists, can take to build a trustworthy AI-enabled system. We enumerate the sequence of core steps and trace parallel paths where alternatives exist. The descriptions of these steps include strengths, weaknesses, preconditions, outcomes, and relevant open-source software tool implementations. In total, this report is a synthesis of data curation tools and approaches from relevant academic literature, and our goal is to equip readers with a diverse yet coherent set of practices for improving AI trustworthiness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14735v1" target="_blank">Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference</a></h3>
                    <p><strong>Authors:</strong> Samir Abdaljalil, Erchin Serpedin, Khalid Qaraqe, Hasan Kurban</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are increasingly applied in multilingual contexts, yet their capacity for consistent, logically grounded alignment across languages remains underexplored. We present a controlled evaluation framework for multilingual natural language inference (NLI) that generates synthetic, logic-based premise-hypothesis pairs and translates them into a typologically diverse set of languages. This design enables precise control over semantic relations and allows testing in both monolingual and mixed-language (code-switched) conditions. Surprisingly, code-switching does not degrade, and can even improve, performance, suggesting that translation-induced lexical variation may serve as a regularization signal. We validate semantic preservation through embedding-based similarity analyses and cross-lingual alignment visualizations, confirming the fidelity of translated pairs. Our findings expose both the potential and the brittleness of current LLM cross-lingual reasoning, and identify code-switching as a promising lever for improving multilingual robustness. Code available at: https://github.com/KurbanIntelligenceLab/nli-stress-testing</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14734v1" target="_blank">AFABench: A Generic Framework for Benchmarking Active Feature Acquisition</a></h3>
                    <p><strong>Authors:</strong> Valter SchÃ¼tz, Han Wu, Reza Rezvan, Linus Aronsson, Morteza Haghir Chehreghani</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> In many real-world scenarios, acquiring all features of a data instance can be expensive or impractical due to monetary cost, latency, or privacy concerns. Active Feature Acquisition (AFA) addresses this challenge by dynamically selecting a subset of informative features for each data instance, trading predictive performance against acquisition cost. While numerous methods have been proposed for AFA, ranging from greedy information-theoretic strategies to non-myopic reinforcement learning approaches, fair and systematic evaluation of these methods has been hindered by the lack of standardized benchmarks. In this paper, we introduce AFABench, the first benchmark framework for AFA. Our benchmark includes a diverse set of synthetic and real-world datasets, supports a wide range of acquisition policies, and provides a modular design that enables easy integration of new methods and tasks. We implement and evaluate representative algorithms from all major categories, including static, greedy, and reinforcement learning-based approaches. To test the lookahead capabilities of AFA policies, we introduce a novel synthetic dataset, AFAContext, designed to expose the limitations of greedy selection. Our results highlight key trade-offs between different AFA strategies and provide actionable insights for future research. The benchmark code is available at: https://github.com/Linusaronsson/AFA-Benchmark.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14727v1" target="_blank">Assessing the Quality and Security of AI-Generated Code: A Quantitative Analysis</a></h3>
                    <p><strong>Authors:</strong> Abbas Sabra, Olivier Schmitt, Joseph Tyler</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.LG</p>
                    <p><strong>Summary:</strong> This study presents a quantitative evaluation of the code quality and security of five prominent Large Language Models (LLMs): Claude Sonnet 4, Claude 3.7 Sonnet, GPT-4o, Llama 3.2 90B, and OpenCoder 8B. While prior research has assessed the functional performance of LLM-generated code, this research tested LLM output from 4,442 Java coding assignments through comprehensive static analysis using SonarQube. The findings suggest that although LLMs can generate functional code, they also introduce a range of software defects, including bugs, security vulnerabilities, and code smells. These defects do not appear to be isolated; rather, they may represent shared weaknesses stemming from systemic limitations within current LLM code generation methods. In particular, critically severe issues, such as hard-coded passwords and path traversal vulnerabilities, were observed across multiple models. These results indicate that LLM-generated code requires verification in order to be considered production-ready. This study found no direct correlation between a models functional performance (measured by Pass@1 rate of unit tests) and the overall quality and security of its generated code, measured by the number of SonarQube issues in benchmark solutions that passed the functional tests. This suggests that functional benchmark performance score is not a good indicator of overall code quality and security. The goal of this study is not to rank LLM performance but to highlight that all evaluated models appear to share certain weaknesses. Consequently, these findings support the view that static analysis can be a valuable instrument for detecting latent defects and an important safeguard for organizations that deploy AI in software development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14718v1" target="_blank">The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language Models for Recipe Generation</a></h3>
                    <p><strong>Authors:</strong> Shubham Pundhir, Ganesh Bagler</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We established a rigorous benchmark for text-based recipe generation, a fundamental task in natural language generation. We present a comprehensive comparative study contrasting a fine-tuned GPT-2 large (774M) model against the GPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine corpus from RecipeDB. Our key contribution is a targeted tokenization strategy that augments the vocabulary with 23 common fraction tokens and custom structural markers. This approach addresses a critical limitation of generic tokenizers by preserving essential recipe structures and precise numerical quantities, thereby enhancing domain specificity. Performance is evaluated using a comprehensive suite of seven automatic metrics spanning fluency (BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and diversity. Our experiments show that the large transformer-based approach yields a 20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the best recurrent baseline, while reducing perplexity by 69.8%. We conclude with a discussion of remaining challenges, particularly regarding factual accuracy, and outline how this foundational study paves the way for integrating real-world constraints and multi-modal inputs in advanced recipe generation research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14708v1" target="_blank">Rule-based Key-Point Extraction for MR-Guided Biomechanical Digital Twins of the Spine</a></h3>
                    <p><strong>Authors:</strong> Robert Graf, Tanja Lerchl, Kati Nispel, Hendrik MÃ¶ller, Matan Atad, Julian McGinnis, Julius Maria Watrinet, Johannes Paetzold, Daniel Rueckert, Jan S. Kirschke</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Digital twins offer a powerful framework for subject-specific simulation and clinical decision support, yet their development often hinges on accurate, individualized anatomical modeling. In this work, we present a rule-based approach for subpixel-accurate key-point extraction from MRI, adapted from prior CT-based methods. Our approach incorporates robust image alignment and vertebra-specific orientation estimation to generate anatomically meaningful landmarks that serve as boundary conditions and force application points, like muscle and ligament insertions in biomechanical models. These models enable the simulation of spinal mechanics considering the subjects individual anatomy, and thus support the development of tailored approaches in clinical diagnostics and treatment planning. By leveraging MR imaging, our method is radiation-free and well-suited for large-scale studies and use in underrepresented populations. This work contributes to the digital twin ecosystem by bridging the gap between precise medical image analysis with biomechanical simulation, and aligns with key themes in personalized modeling for healthcare.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14704v1" target="_blank">MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers</a></h3>
                    <p><strong>Authors:</strong> Ziyang Luo, Zhiqi Shen, Wenzhuo Yang, Zirui Zhao, Prathyusha Jwalapuram, Amrita Saha, Doyen Sahoo, Silvio Savarese, Caiming Xiong, Junnan Li</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms. However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching. To ensure rigorous evaluation, we implement execution-based evaluators, including format evaluators for agent format compliance, static evaluators for time-invariant content matching, and dynamic evaluators that automatically retrieve real-time ground truth for temporally sensitive tasks. Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. In addition, our benchmark poses a significant long-context challenge for LLM agents, as the number of input tokens increases rapidly with the number of interaction steps. Moreover, it introduces an unknown-tools challenge, as LLM agents often lack familiarity with the precise usage of the MCP servers. Notably, enterprise-level agents like Cursor cannot achieve better performance than standard ReAct frameworks. Beyond evaluation, we open-source our extensible evaluation framework with UI support, enabling researchers and practitioners to seamlessly integrate new agents and MCP servers while fostering innovation in the rapidly evolving MCP ecosystem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14692v1" target="_blank">Sociotechnical Imaginaries of ChatGPT in Higher Education: The Evolving Media Discourse</a></h3>
                    <p><strong>Authors:</strong> Yinan Sun, Ali Unlu, Aditya Johri</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This study investigates how U.S. news media framed the use of ChatGPT in higher education from November 2022 to October 2024. Employing Framing Theory and combining temporal and sentiment analysis of 198 news articles, we trace the evolving narratives surrounding generative AI. We found that the media discourse largely centered on institutional responses; policy changes and teaching practices showed the most consistent presence and positive sentiment over time. Conversely, coverage of topics such as human-centered learning, the job market, and skill development appeared more sporadically, with initially uncertain portrayals gradually shifting toward cautious optimism. Importantly, media sentiment toward ChatGPTs role in college admissions remained predominantly negative. Our findings suggest that media narratives prioritize institutional responses to generative AI over long-term, broader ethical, social, and labor-related implications, shaping an emerging sociotechnical imaginary that frames generative AI in education primarily through the lens of adaptation and innovation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14690v1" target="_blank">An Integrated Target Study and Target Trial Framework to Evaluate Intervention Effects on Disparities</a></h3>
                    <p><strong>Authors:</strong> Xinyi Sun, Theodore J. Iwashyna, Emmanuel F. Drabo, Deidra C. Crews, Kadija Ferryman, John W. Jackson</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> We present a novel framework -- the integrated Target Study + Target Trial (TS+TT) -- to evaluate the effects of interventions on disparities. This framework combines the ethical clarity of the Target Study, which balances allowable covariates across social groups to define meaningful disparity measures, with the causal rigor of the Target Trial, which emulates randomized trials to estimate intervention effects. TS+TT achieves two forms of balance: (1) stratified sampling ensures that allowable covariates are balanced across social groups to enable an ethically interpretable disparity contrast; (2) intervention-randomization within social groups balances both allowable and non-allowable covariates across intervention arms within each group to support unconfounded estimation of intervention effects on disparity. We describe the key components of protocol specification and its emulation and demonstrate the approach using electronic medical record data to evaluate how hypothetical interventions on pulse oximeter racial bias affect disparities in treatment receipt in clinical care. We also extend semiparametric G-computation for time-to-event outcomes in continuous time to accommodate continuous, stochastic interventions, allowing counterfactual estimation of disparities in time-to-treatment. More broadly, the framework accommodates a wide range of intervention and outcome types. The TS+TT framework offers a versatile and policy-relevant tool for generating ethically aligned causal evidence to help eliminate disparities and avoid unintentionally exacerbating disparities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14684v1" target="_blank">Addressing Graph Anomaly Detection via Causal Edge Separation and Spectrum</a></h3>
                    <p><strong>Authors:</strong> Zengyi Wo, Wenjun Wang, Minglai Shao, Chang Liu, Yumeng Wang, Yueheng Sun</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In the real world, anomalous entities often add more legitimate connections while hiding direct links with other anomalous entities, leading to heterophilic structures in anomalous networks that most GNN-based techniques fail to address. Several works have been proposed to tackle this issue in the spatial domain. However, these methods overlook the complex relationships between node structure encoding, node features, and their contextual environment and rely on principled guidance, research on solving spectral domain heterophilic problems remains limited. This study analyzes the spectral distribution of nodes with different heterophilic degrees and discovers that the heterophily of anomalous nodes causes the spectral energy to shift from low to high frequencies. To address the above challenges, we propose a spectral neural network CES2-GAD based on causal edge separation for anomaly detection on heterophilic graphs. Firstly, CES2-GAD will separate the original graph into homophilic and heterophilic edges using causal interventions. Subsequently, various hybrid-spectrum filters are used to capture signals from the segmented graphs. Finally, representations from multiple signals are concatenated and input into a classifier to predict anomalies. Extensive experiments with real-world datasets have proven the effectiveness of the method we proposed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14654v1" target="_blank">Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration</a></h3>
                    <p><strong>Authors:</strong> Peilin Ji, Xiao Xue, Simeng Wang, Wenhao Yan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> In recent years, the increasing frequency of extreme urban rainfall events has posed significant challenges to emergency scheduling systems. Urban flooding often leads to severe traffic congestion and service disruptions, threatening public safety and mobility. However, effective decision making remains hindered by three key challenges: (1) managing trade-offs among competing goals (e.g., traffic flow, task completion, and risk mitigation) requires dynamic, context-aware strategies; (2) rapidly evolving environmental conditions render static rules inadequate; and (3) LLM-generated strategies frequently suffer from semantic instability and execution inconsistency. Existing methods fail to align perception, global optimization, and multi-agent coordination within a unified framework. To tackle these challenges, we introduce H-J, a hierarchical multi-agent framework that integrates knowledge-guided prompting, entropy-constrained generation, and feedback-driven optimization. The framework establishes a closed-loop pipeline spanning from multi-source perception to strategic execution and continuous refinement. We evaluate H-J on real-world urban topology and rainfall data under three representative conditions: extreme rainfall, intermittent bursts, and daily light rain. Experiments show that H-J outperforms rule-based and reinforcement-learning baselines in traffic smoothness, task success rate, and system robustness. These findings highlight the promise of uncertainty-aware, knowledge-constrained LLM-based approaches for enhancing resilience in urban flood response.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14644v1" target="_blank">LeanGeo: Formalizing Competitional Geometry problems in Lean</a></h3>
                    <p><strong>Authors:</strong> Chendong Song, Zihan Wang, Frederick Pu, Haiming Wang, Xiaohan Lin, Junqi Liu, Jia Li, Zhengying Liu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Geometry problems are a crucial testbed for AI reasoning capabilities. Most existing geometry solving systems cannot express problems within a unified framework, thus are difficult to integrate with other mathematical fields. Besides, since most geometric proofs rely on intuitive diagrams, verifying geometry problems is particularly challenging. To address these gaps, we introduce LeanGeo, a unified formal system for formalizing and solving competition-level geometry problems within the Lean 4 theorem prover. LeanGeo features a comprehensive library of high-level geometric theorems with Leans foundational logic, enabling rigorous proof verification and seamless integration with Mathlib. We also present LeanGeo-Bench, a formal geometry benchmark in LeanGeo, comprising problems from the International Mathematical Olympiad (IMO) and other advanced sources. Our evaluation demonstrates the capabilities and limitations of state-of-the-art Large Language Models on this benchmark, highlighting the need for further advancements in automated geometric reasoning. We open source the theorem library and the benchmark of LeanGeo at https://github.com/project-numina/LeanGeo/tree/master.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14631v1" target="_blank">Towards a DSL to Formalize Multimodal Requirements</a></h3>
                    <p><strong>Authors:</strong> Marcos Gomez-Vazquez, Jordi Cabot</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Multimodal systems, which process multiple input types such as text, audio, and images, are becoming increasingly prevalent in software systems, enabled by the huge advancements in Machine Learning. This triggers the need to easily define the requirements linked to these new types of user interactions, potentially involving more than one modality at the same time. This remains an open challenge due to the lack of languages and methods adapted to the diverse nature of multimodal interactions, with the risk of implementing AI-enhanced systems that do not properly satisfy the user needs. In this sense, this paper presents MERLAN, a Domain-Specific Language (DSL) to specify the requirements for these new types of multimodal interfaces. We present the metamodel for such language together with a textual syntax implemented as an ANTLR grammar. A prototype tool enabling requirements engineers to write such requirements and automatically generate a possible implementation of a system compliant with them on top of an agentic framework is also provided.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14898v1" target="_blank">Lorentz-Equivariance without Limitations</a></h3>
                    <p><strong>Authors:</strong> Luigi Favaro, Gerrit Gerhartz, Fred A. Hamprecht, Peter Lippmann, Sebastian Pitz, Tilman Plehn, Huilin Qu, Jonas Spinner</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-ex</p>
                    <p><strong>Summary:</strong> Lorentz Local Canonicalization (LLoCa) ensures exact Lorentz-equivariance for arbitrary neural networks with minimal computational overhead. For the LHC, it equivariantly predicts local reference frames for each particle and propagates any-order tensorial information between them. We apply it to graph networks and transformers. We showcase its cutting-edge performance on amplitude regression, end-to-end event generation, and jet tagging. For jet tagging, we introduce a large top tagging dataset, to benchmark LLoCa versions of a range of established benchmark architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14896v1" target="_blank">Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs</a></h3>
                    <p><strong>Authors:</strong> Haokun Lin, Haobo Xu, Yichen Wu, Ziyu Guo, Renrui Zhang, Zhichao Lu, Ying Wei, Qingfu Zhang, Zhenan Sun</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in diffusion large language models (dLLMs) have introduced a promising alternative to autoregressive (AR) LLMs for natural language generation tasks, leveraging full attention and denoising-based decoding strategies. However, the deployment of these models on edge devices remains challenging due to their massive parameter scale and high resource demands. While post-training quantization (PTQ) has emerged as a widely adopted technique for compressing AR LLMs, its applicability to dLLMs remains largely unexplored. In this work, we present the first systematic study on quantizing diffusion-based language models. We begin by identifying the presence of activation outliers, characterized by abnormally large activation values that dominate the dynamic range. These outliers pose a key challenge to low-bit quantization, as they make it difficult to preserve precision for the majority of values. More importantly, we implement state-of-the-art PTQ methods and conduct a comprehensive evaluation across multiple task types and model variants. Our analysis is structured along four key dimensions: bit-width, quantization method, task category, and model type. Through this multi-perspective evaluation, we offer practical insights into the quantization behavior of dLLMs under different configurations. We hope our findings provide a foundation for future research in efficient dLLM deployment. All codes and experimental setups will be released to support the community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14894v1" target="_blank">Anyon superfluidity of excitons in quantum Hall bilayers</a></h3>
                    <p><strong>Authors:</strong> Zhaoyu Han, Taige Wang, Zhihuan Dong, Michael P. Zaletel, Ashvin Vishwanath</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el</p>
                    <p><strong>Summary:</strong> The charged anyons of a fractional quantum Hall fluid are necessarily dispersionless due to the continuous magnetic translation symmetry. Neutral anyons, however, can disperse, resulting in a much richer space of possible ``daughter states when doped to finite density. We discuss a natural realization of such physics in quantum Hall bilayers, where a finite density of excitons with fractional statistics is argued to give rise to `anyonic exciton superfluidity, the charge-neutral analog of anyon superconductivity. In a balanced bilayer of two Laughlin $\nu = 1/3$ states, the minimal interlayer exciton carries anyonic exchange statistics. A finite density of these excitons is argued to yield an exciton superfluid stitched to a specific bulk topological order and edge spectrum. Such superfluidity should be most robust near the direct transition into the Halperin $(112)$ state, and near analogous transitions in the bilayer Jain sequence at total filling $\nu_\text{T} = 2\times \frac{n}{2n+1}$. These topological transitions can be described by Chern-Simons QED$_3$, from which we derive several novel and general properties of anyon superfluidity near such transitions, including an anomalously large superfluid stiffness of $\kappa_\text{s} \propto |\delta\nu|^{1/2}$ at layer imbalance fraction $\delta\nu$. A notable feature of the phase diagrams we construct is the prevalence of spatial symmetry breaking, driven by an underlying composite Fermi surface. Our results can be directly tested with currently available experimental techniques. We compare our theory with existing data and make concrete predictions for future measurements, including higher-pseudospin exciton superfluids when doping higher Jain fractions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14893v1" target="_blank">Virtual Community: An Open World for Humans, Robots, and Society</a></h3>
                    <p><strong>Authors:</strong> Qinhong Zhou, Hongxin Zhang, Xiangye Lin, Zheyuan Zhang, Yutian Chen, Wenjun Liu, Zunzhe Zhang, Sunli Chen, Lixing Fang, Qiushi Lyu, Xinyu Sun, Jincheng Yang, Zeyuan Wang, Bao Chi Dang, Zhehuan Chen, Daksha Ladia, Jiageng Liu, Chuang Gan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.RO</p>
                    <p><strong>Summary:</strong> The rapid progress in AI and Robotics may lead to a profound societal transformation, as humans and robots begin to coexist within shared communities, introducing both opportunities and challenges. To explore this future, we present Virtual Community-an open-world platform for humans, robots, and society-built on a universal physics engine and grounded in real-world 3D scenes. With Virtual Community, we aim to study embodied social intelligence at scale: 1) How robots can intelligently cooperate or compete; 2) How humans develop social relations and build community; 3) More importantly, how intelligent robots and humans can co-exist in an open world. To support these, Virtual Community features: 1) An open-source multi-agent physics simulator that supports robots, humans, and their interactions within a society; 2) A large-scale, real-world aligned community generation pipeline, including vast outdoor space, diverse indoor scenes, and a community of grounded agents with rich characters and appearances. Leveraging Virtual Community, we propose two novel challenges. The Community Planning Challenge evaluates multi-agent reasoning and planning ability in open-world settings, such as cooperating to help agents with daily activities and efficiently connecting other agents. The Community Robot Challenge requires multiple heterogeneous robots to collaborate in solving complex open-world tasks. We evaluate various baselines on these tasks and demonstrate the challenges in both high-level open-world task planning and low-level cooperation controls. We hope that Virtual Community will unlock further study of human-robot coexistence within open-world environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14892v1" target="_blank">Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds</a></h3>
                    <p><strong>Authors:</strong> Jia Lu, Taoran Yi, Jiemin Fang, Chen Yang, Chuiyun Wu, Wei Shen, Wenyu Liu, Qi Tian, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV</p>
                    <p><strong>Summary:</strong> Reconstructing 3D human bodies from sparse views has been an appealing topic, which is crucial to broader the related applications. In this paper, we propose a quite challenging but valuable task to reconstruct the human body from only two images, i.e., the front and back view, which can largely lower the barrier for users to create their own 3D digital humans. The main challenges lie in the difficulty of building 3D consistency and recovering missing information from the highly sparse input. We redesign a geometry reconstruction model based on foundation reconstruction models to predict consistent point clouds even input images have scarce overlaps with extensive human data training. Furthermore, an enhancement algorithm is applied to supplement the missing color information, and then the complete human point clouds with colors can be obtained, which are directly transformed into 3D Gaussians for better rendering quality. Experiments show that our method can reconstruct the entire human in 190 ms on a single NVIDIA RTX 4090, with two images at a resolution of 1024x1024, demonstrating state-of-the-art performance on the THuman2.0 and cross-domain datasets. Additionally, our method can complete human reconstruction even with images captured by low-cost mobile devices, reducing the requirements for data collection. Demos and code are available at https://hustvl.github.io/Snap-Snap/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14891v1" target="_blank">GaussianArt: Unified Modeling of Geometry and Motion for Articulated Objects</a></h3>
                    <p><strong>Authors:</strong> Licheng Shen, Saining Zhang, Honghan Li, Peilin Yang, Zihao Huang, Zongzheng Zhang, Hao Zhao</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Reconstructing articulated objects is essential for building digital twins of interactive environments. However, prior methods typically decouple geometry and motion by first reconstructing object shape in distinct states and then estimating articulation through post-hoc alignment. This separation complicates the reconstruction pipeline and restricts scalability, especially for objects with complex, multi-part articulation. We introduce a unified representation that jointly models geometry and motion using articulated 3D Gaussians. This formulation improves robustness in motion decomposition and supports articulated objects with up to 20 parts, significantly outperforming prior approaches that often struggle beyond 2--3 parts due to brittle initialization. To systematically assess scalability and generalization, we propose MPArt-90, a new benchmark consisting of 90 articulated objects across 20 categories, each with diverse part counts and motion configurations. Extensive experiments show that our method consistently achieves superior accuracy in part-level geometry reconstruction and motion estimation across a broad range of object types. We further demonstrate applicability to downstream tasks such as robotic simulation and human-scene interaction modeling, highlighting the potential of unified articulated representations in scalable physical modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14889v1" target="_blank">MS-CLR: Multi-Skeleton Contrastive Learning for Human Action Recognition</a></h3>
                    <p><strong>Authors:</strong> Mert Kiray, Alvaro Ritter, Nassir Navab, Benjamin Busam</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Contrastive learning has gained significant attention in skeleton-based action recognition for its ability to learn robust representations from unlabeled data. However, existing methods rely on a single skeleton convention, which limits their ability to generalize across datasets with diverse joint structures and anatomical coverage. We propose Multi-Skeleton Contrastive Learning (MS-CLR), a general self-supervised framework that aligns pose representations across multiple skeleton conventions extracted from the same sequence. This encourages the model to learn structural invariances and capture diverse anatomical cues, resulting in more expressive and generalizable features. To support this, we adapt the ST-GCN architecture to handle skeletons with varying joint layouts and scales through a unified representation scheme. Experiments on the NTU RGB+D 60 and 120 datasets demonstrate that MS-CLR consistently improves performance over strong single-skeleton contrastive learning baselines. A multi-skeleton ensemble further boosts performance, setting new state-of-the-art results on both datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14885v1" target="_blank">Novel Limits on Dark Photon Mixing from Radiation Safety</a></h3>
                    <p><strong>Authors:</strong> Wen Yin</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-ex, physics.ins-det</p>
                    <p><strong>Summary:</strong> I propose a novel laboratory search for dark photons based on radiation-safety monitoring at synchrotron radiation facilities, including NanoTerasu, SPring-8, KEK-PF, and ESRF. Dark photons can be produced parasitically in undulators or via photon-mirror interactions, and subsequently traverse optical systems and shielding. Taking into account quantum effects and the internal structure of undulators, mirrors, and detectors, I show that even a simple Geiger-M\uller counter, routinely used for radiation-safety monitoring, can detect such dark photons outside the shielding and set competitive limits on the kinetic mixing parameter down to $\chi \lesssim 5\times 10^{-6}$ in the eV mass range, providing some of the strongest bounds among laboratory searches. Because radiation safety is strictly regulated, the resulting limits can be regarded as robust and realistic constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14883v1" target="_blank">The Cost Advantage of Virtual Machine Migrations: Empirical Insights into Amazons EC2 Marketspace</a></h3>
                    <p><strong>Authors:</strong> Benedikt Pittl, Werner Mach, Erich Schikuta</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC, cs.GT, 91-08, J.1; H.1.m</p>
                    <p><strong>Summary:</strong> In recent years, cloud providers have introduced novel approaches for trading virtual machines. For example, Virtustream introduced so-called muVMs to charge cloud computing resources while other providers such as Google, Microsoft, or Amazon re-invented their marketspaces. Today, the market leader Amazon runs six marketspaces for trading virtual machines. Consumers can purchase bundles of virtual machines, which are called cloud-portfolios, from multiple marketspaces and providers. An industry-relevant field of research is to identify best practices and guidelines on how such optimal portfolios are created. In the paper at hand, a cost analysis of cloud portfolios is presented. Therefore, pricing data from Amazon was used as well as a real virtual machine utilization dataset from the Bitbrains datacenter. The results show that a cost optimum can only be reached if heterogeneous portfolios are created where virtual machines are purchased from different marketspaces. Additionally, the cost-benefit of migrating virtual machines to different marketplaces during runtime is presented. Such migrations are especially cost-effective for virtual machines of cloud-portfolios which run between 6 hours and 1 year. The paper further shows that most of the resources of virtual machines are never utilized by consumers, which represents a significant future potential for cost optimization. For the validation of the results, a second dataset of the Bitbrains datacenter was used, which contains utility data of virtual machines from a different domain of application.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14881v1" target="_blank">Compute-Optimal Scaling for Value-Based Deep RL</a></h3>
                    <p><strong>Authors:</strong> Preston Fu, Oleh Rybkin, Zhiyuan Zhou, Michal Nauman, Pieter Abbeel, Sergey Levine, Aviral Kumar</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> As models grow larger and training them becomes expensive, it becomes increasingly important to scale training recipes not just to larger models and more data, but to do so in a compute-optimal manner that extracts maximal performance per unit of compute. While such scaling has been well studied for language modeling, reinforcement learning (RL) has received less attention in this regard. In this paper, we investigate compute scaling for online, value-based deep RL. These methods present two primary axes for compute allocation: model capacity and the update-to-data (UTD) ratio. Given a fixed compute budget, we ask: how should resources be partitioned across these axes to maximize sample efficiency? Our analysis reveals a nuanced interplay between model size, batch size, and UTD. In particular, we identify a phenomenon we call TD-overfitting: increasing the batch quickly harms Q-function accuracy for small models, but this effect is absent in large models, enabling effective use of large batch size at scale. We provide a mental model for understanding this phenomenon and build guidelines for choosing batch size and UTD to optimize compute usage. Our findings provide a grounded starting point for compute-optimal scaling in deep RL, mirroring studies in supervised learning but adapted to TD learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14880v1" target="_blank">MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework</a></h3>
                    <p><strong>Authors:</strong> Ailing Yu, Lan Yao, Jingnan Liu, Zhe Chen, Jiajun Yin, Yuan Wang, Xinhao Liao, Zhiling Ye, Ji Li, Yun Yue, Hansong Xiao, Hualei Zhou, Chunxiao Guo, Peng Wei, Jinjie Gu</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent developments in Large Language Model (LLM)-based agents have shown impressive capabilities spanning multiple domains, exemplified by deep research systems that demonstrate superior performance on complex information-seeking and synthesis tasks. While general-purpose deep research agents have shown impressive capabilities, they struggle significantly with medical domain challenges, as evidenced by leading proprietary systems achieving limited accuracy on complex medical benchmarks. The key limitations are: (1) the model lacks sufficient dense medical knowledge for clinical reasoning, and (2) the framework is constrained by the absence of specialized retrieval tools tailored for medical contexts.We present a medical deep research agent that addresses these challenges through two core innovations. First, we develop a novel data synthesis framework using medical knowledge graphs, extracting the longest chains from subgraphs around rare medical entities to generate complex multi-hop question-answer pairs. Second, we integrate a custom-built private medical retrieval engine alongside general-purpose tools, enabling accurate medical information synthesis. Our approach generates 2100+ diverse trajectories across 12 medical specialties, each averaging 4.2 tool interactions.Through a two-stage training paradigm combining supervised fine-tuning and online reinforcement learning with composite rewards, our MedResearcher-R1-32B model demonstrates exceptional performance, establishing new state-of-the-art results on medical benchmarks while maintaining competitive performance on general deep research tasks. Our work demonstrates that strategic domain-specific innovations in architecture, tool design, and training data construction can enable smaller open-source models to outperform much larger proprietary systems in specialized domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14879v1" target="_blank">MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds</a></h3>
                    <p><strong>Authors:</strong> Bingquan Dai, Li Ray Luo, Qihong Tang, Jie Wang, Xinyu Lian, Hao Xu, Minghan Qin, Xudong Xu, Bo Dai, Haoqian Wang, Zhaoyang Lyu, Jiangmiao Pang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV</p>
                    <p><strong>Summary:</strong> Reconstructing 3D objects into editable programs is pivotal for applications like reverse engineering and shape editing. However, existing methods often rely on limited domain-specific languages (DSLs) and small-scale datasets, restricting their ability to model complex geometries and structures. To address these challenges, we introduce MeshCoder, a novel framework that reconstructs complex 3D objects from point clouds into editable Blender Python scripts. We develop a comprehensive set of expressive Blender Python APIs capable of synthesizing intricate geometries. Leveraging these APIs, we construct a large-scale paired object-code dataset, where the code for each object is decomposed into distinct semantic parts. Subsequently, we train a multimodal large language model (LLM) that translates 3D point cloud into executable Blender Python scripts. Our approach not only achieves superior performance in shape-to-code reconstruction tasks but also facilitates intuitive geometric and topological editing through convenient code modifications. Furthermore, our code-based representation enhances the reasoning capabilities of LLMs in 3D shape understanding tasks. Together, these contributions establish MeshCoder as a powerful and flexible solution for programmatic 3D shape reconstruction and understanding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14878v1" target="_blank">Lifespan Pancreas Morphology for Control vs Type 2 Diabetes using AI on Largescale Clinical Imaging</a></h3>
                    <p><strong>Authors:</strong> Lucas W. Remedios, Chloe Cho, Trent M. Schwartz, Dingjie Su, Gaurav Rudravaram, Chenyu Gao, Aravind R. Krishnan, Adam M. Saunders, Michael E. Kim, Shunxing Bao, Thomas A. Lasko, Alvin C. Powers, Bennett A. Landman, John Virostko</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Purpose: Understanding how the pancreas changes is critical for detecting deviations in type 2 diabetes and other pancreatic disease. We measure pancreas size and shape using morphological measurements from ages 0 to 90. Our goals are to 1) identify reliable clinical imaging modalities for AI-based pancreas measurement, 2) establish normative morphological aging trends, and 3) detect potential deviations in type 2 diabetes. Approach: We analyzed a clinically acquired dataset of 2533 patients imaged with abdominal CT or MRI. We resampled the scans to 3mm isotropic resolution, segmented the pancreas using automated methods, and extracted 13 morphological pancreas features across the lifespan. First, we assessed CT and MRI measurements to determine which modalities provide consistent lifespan trends. Second, we characterized distributions of normative morphological patterns stratified by age group and sex. Third, we used GAMLSS regression to model pancreas morphology trends in 1350 patients matched for age, sex, and type 2 diabetes status to identify any deviations from normative aging associated with type 2 diabetes. Results: When adjusting for confounders, the aging trends for 10 of 13 morphological features were significantly different between patients with type 2 diabetes and non-diabetic controls (p  0.05 after multiple comparisons corrections). Additionally, MRI appeared to yield different pancreas measurements than CT using our AI-based method. Conclusions: We provide lifespan trends demonstrating that the size and shape of the pancreas is altered in type 2 diabetes using 675 control patients and 675 diabetes patients. Moreover, our findings reinforce that the pancreas is smaller in type 2 diabetes. Additionally, we contribute a reference of lifespan pancreas morphology from a large cohort of non-diabetic control patients in a clinical setting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14877v1" target="_blank">Proof of a Generalized Ryu-Takayanagi Conjecture</a></h3>
                    <p><strong>Authors:</strong> Artem Averin</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc, hep-ph</p>
                    <p><strong>Summary:</strong> We derive a generalized version of the Ryu-Takayanagi formula for the entanglement entropy in arbitrary diffeomorphism invariant field theories. We use a recent framework which expresses the measurable quantities of a quantum theory as a weighted sum over paths in the theorys phase space. If this framework is applied to a field theory on a spacetime foliated by a hypersurface $\Sigma,$ the choice of a codimension-2 surface $B$ without boundary contained in $\Sigma$ specifies a submanifold in the phase space. For diffeomorphism invariant field theories, a functional integral expression for their density matrices was recently given and then used to derive bounds on phase space volumes in the considered submanifold associated to $B.$ These bounds formalize the gravitational entropy bound. Here, we present an implication of this derivation in that we show the obtained functional integral expression for density matrices to be naturally suited for the replica trick. Correspondingly, we prove a functional integral expression for the associated entanglement entropies and derive a practical prescription for their evaluation to leading order and beyond. An important novelty of our approach is the contact to phase space. This allows us both to obtain a prescription for entanglement entropies in arbitrary diffeomorphism invariant field theories not necessarily possessing a holographic dual as well as to use entanglement entropies to study their phase space structure. In the case of the bulk-boundary correspondence, our prescription consistently reproduces and hence provides a natural and independent proof of the Ryu-Takayanagi formula as well as its various generalizations. These include the covariant holographic entanglement entropy proposal, Dongs proposal for higher-derivative gravity as well as the quantum extremal surface prescription.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14873v1" target="_blank">Holographic Extended Thermodynamics of deformed AdS-Schwarzschild black hole</a></h3>
                    <p><strong>Authors:</strong> Kamal L. Panigrahi, Balbeer Singh</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> We investigate the thermodynamics and phase structure of a deformed AdS-Schwarzschild black hole, generated via the gravitational decoupling (GD) method as a minimal geometric deformation. In the bulk canonical ensemble, our results exhibit a van der Waals-type first-order phase transition in addition to the Hawking-Page transition, in the suitable parameter regime. Further, we compute the critical exponents characterising the bulk transition, confirming their consistency with mean-field theory predictions. Exploiting the exact holographic dictionary between extended black hole thermodynamics and the dual conformal field theory (CFT), we extend this analysis to the boundary and uncover a rich array of phase transitions and critical phenomena across three distinct thermodynamic ensembles. In particular, for an ensemble of fixed volume and central charge, the dual CFT displays a van der Waals-like phase structure. Throughout, we emphasise the pivotal influence of the GD deformation parameter on the thermodynamic behaviour, and we elucidate its role in the confinement-deconfinement transitions characteristic of the deformed AdS-Schwarzschild geometry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14871v1" target="_blank">Squeezed Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Jyotirmai Singh, Samar Khanna, James Burgess</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> Diffusion models typically inject isotropic Gaussian noise, disregarding structure in the data. Motivated by the way quantum squeezed states redistribute uncertainty according to the Heisenberg uncertainty principle, we introduce Squeezed Diffusion Models (SDM), which scale noise anisotropically along the principal component of the training distribution. As squeezing enhances the signal-to-noise ratio in physics, we hypothesize that scaling noise in a data-dependent manner can better assist diffusion models in learning important data features. We study two configurations: (i) a Heisenberg diffusion model that compensates the scaling on the principal axis with inverse scaling on orthogonal directions and (ii) a standard SDM variant that scales only the principal axis. Counterintuitively, on CIFAR-10/100 and CelebA-64, mild antisqueezing - i.e. increasing variance on the principal axis - consistently improves FID by up to 15% and shifts the precision-recall frontier toward higher recall. Our results demonstrate that simple, data-aware noise shaping can deliver robust generative gains without architectural changes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14869v1" target="_blank">The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Hend Al-Khalifa, Raneem Almansour, Layan Abdulrahman Alhuasini, Alanood Alsaleh, Mohamad-Hani Temsah, Mohamad-Hani_Temsah, Ashwag Rafea S Alruwaili</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC, cs.CL</p>
                    <p><strong>Summary:</strong> Prompt engineering has rapidly emerged as a critical skill for effective interaction with large language models (LLMs). However, the cognitive and neural underpinnings of this expertise remain largely unexplored. This paper presents findings from a cross-sectional pilot fMRI study investigating differences in brain functional connectivity and network activity between experts and intermediate prompt engineers. Our results reveal distinct neural signatures associated with higher prompt engineering literacy, including increased functional connectivity in brain regions such as the left middle temporal gyrus and the left frontal pole, as well as altered power-frequency dynamics in key cognitive networks. These findings offer initial insights into the neurobiological basis of prompt engineering proficiency. We discuss the implications of these neurocognitive markers in Natural Language Processing (NLP). Understanding the neural basis of human expertise in interacting with LLMs can inform the design of more intuitive human-AI interfaces, contribute to cognitive models of LLM interaction, and potentially guide the development of AI systems that better align with human cognitive workflows. This interdisciplinary approach aims to bridge the gap between human cognition and machine intelligence, fostering a deeper understanding of how humans learn and adapt to complex AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14863v1" target="_blank">Rotating Kinetic Gas Disk Morphology Surrounding a Schwarzschild Black Hole</a></h3>
                    <p><strong>Authors:</strong> Carlos Gabarrete, Roger Raudales</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> In this work, the behavior of a rotating relativistic kinetic gas surrounding a Schwarzschild black hole is studied. We are interested in the description and the analysis of the morphology of the resulting configurations for a kinetic gas cloud with and without total angular momentum, and we also compare the macroscopic observables with configurations of finite total mass. A collisionless gas in the Schwarzschild spacetime background is analyzed, considering models of the one-particle distribution function depending on the polytropic ansatz and the inclination angle of the orbits of the particles in the kinetic gas. Profiles of the macroscopic observables of the gas configurations are presented, which are derived from the density current vector field and energy-momentum-stress tensor.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14861v1" target="_blank">Fermionic greybody factors and strong gravitational lensing by Lorentz-violating global monopole</a></h3>
                    <p><strong>Authors:</strong> F. M. Belchior, R. V. Maluf, A. R. M. Oliveira, A. Yu. Petrov, P. J. PorfÃ­rio</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> In this work, we study the greybody factors (GFs) of spin 1/2 and spin 3/2 fermions for a black hole with global monopole in self-interacting Kalb-Ramond gravity with Lorentz symmetry violation. For our purpose, we consider the Dirac and Rarita-Schwinger equations in curved spacetime by proceeding with separating these equations into sets of radial and angular equations. Using the analytical solution of the angular equation, the Schr\{o}dinger-like wave equations with potentials are derived by decoupling the radial wave equations using the tortoise coordinate. Moreover, we calculate the angular deflection of light in the strong field limit. With the expression for angular deflection in the strong field limit, we compute the positions as well as magnification of the respective relativistic images. We compute the shadows cast by the Lorentz-violating (LV) black hole with a global monopole and analyze how the LV parameter and the monopole charge affect the shadows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14857v1" target="_blank">Single-click protocols for remote state preparation using weak coherent pulses</a></h3>
                    <p><strong>Authors:</strong> Janice van Dam, Emil R. Hellebek, Tzula B. Propp, Junior R. Gonzales-Ureta, Anders S. SÃ¸rensen, Stephanie D. C. Wehner</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Remote state preparation (RSP) allows one party to remotely prepare a known quantum state on another partys qubit using entanglement. This can be used in quantum networks to perform applications such as blind quantum computing or long-distance quantum key distribution (QKD) with quantum repeaters. Devices to perform RSP, referred to as a client, ideally have low hardware requirements, such as only sending photonic qubits. A weak coherent pulse source offers a practical alternative to true single-photon sources and is already widely used in QKD. Here, we introduce two new protocols to the previously known protocol for RSP with a weak-coherent-pulse-based device. The known technique uses a double-click (DC) protocol, where a photon from both the server and the client needs to reach an intermediate Bell state measurement. Here, we add to that a single-click (SC) RSP protocol, which requires only one photon to reach the Bell state measurement, allowing for better performance in certain regimes. In addition, we introduce a double-single-click (DSC) protocol, where the SC protocol is repeated twice, and a CNOT gate is applied between the resulting qubits. DSC mitigates the need for phase stabilization in certain regimes, lowering technical complexity while still improving performance compared to DC in some regimes. We compare these protocols in terms of fidelity and rate, finding that SC consistently achieves higher rates than DC and, interestingly, does not suffer from an inherently lower fidelity than the DC, as is the case for entanglement generation. Although SC provides stronger performance, DSC can still show performance improvements over DC, and it may have reduced technical complexity compared to SC. Lastly, we show how these protocols can be used in long-distance QKD using quantum repeaters.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14856v1" target="_blank">EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention</a></h3>
                    <p><strong>Authors:</strong> Lakshmi Annamalai, Chetan Singh Thakur</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Road segmentation is pivotal for autonomous vehicles, yet achieving low latency and low compute solutions using frame based cameras remains a challenge. Event cameras offer a promising alternative. To leverage their low power sensing, we introduce EventSSEG, a method for road segmentation that uses event only computing and a probabilistic attention mechanism. Event only computing poses a challenge in transferring pretrained weights from the conventional camera domain, requiring abundant labeled data, which is scarce. To overcome this, EventSSEG employs event-based self supervised learning, eliminating the need for extensive labeled data. Experiments on DSEC-Semantic and DDD17 show that EventSSEG achieves state of the art performance with minimal labeled events. This approach maximizes event cameras capabilities and addresses the lack of labeled events.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14852v1" target="_blank">Carrier mobilities and electron-phonon interactions beyond DFT</a></h3>
                    <p><strong>Authors:</strong> Aleksandr Poliukhin, Nicola Colonna, Francesco Libbi, Samuel PoncÃ©, Nicola Marzari</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Electron-phonon coupling is a key interaction that governs diverse physical processes such as carrier transport, superconductivity, and optical absorption. Calculating such interactions from first-principles with methods beyond density-functional theory remains a challenge. We introduce here a finite-difference framework for computing electron-phonon couplings for any electronic structure method that provides eigenvalues and eigenvectors, and showcase applications for hybrid and Koopmans functionals, and $GW$ many-body perturbation theory. Our approach introduces a novel projectability scheme based on eigenvalue differences and bypasses many of the limitations of the direct finite difference methods. It also leverages symmetries to reduce the number of independent atomic displacements, thereby keeping computational costs manageable. This approach enables seamless integration with established first-principles codes for generating displaced supercells, performing Wannier interpolations, and evaluating transport properties. Applications to silicon and gallium arsenide show that advanced electronic-structure functionals predict different electron-phonon couplings and modify band curvatures, resulting in much more accurate estimates of intrinsic carrier drift mobilities and effective masses. In general, our method provides a robust and accessible framework for exploring electron-phonon interactions in complex materials with state-of-the-art electronic structure methods.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3763069" target="_blank">Correct Black-Box Monitors for Distributed Deadlock Detection: Formalisation and Implementation (Technical Report)</a></h3>
                    <p><strong>Authors:</strong> RadosÅ‚aw Jan Rowicki, Adrian Francalanza, Alceste Scalas</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.PL</p>
                    <p><strong>Summary:</strong> Many software applications rely on concurrent and distributed (micro)services that interact via message-passing and various forms of remote procedure calls (RPC). As these systems organically evolve and grow in scale and complexity, the risk of introducing deadlocks increases and their impact may worsen: even if only a few services deadlock, many other services may block while awaiting responses from the deadlocked ones. As a result, the core of the deadlock can be obfuscated by its consequences on the rest of the system, and diagnosing and fixing the problem can be challenging. In this work we tackle the challenge by proposing distributed black-box monitors that are deployed alongside each service and detect deadlocks by only observing the incoming and outgoing messages, and exchanging probes with other monitors. We present a formal model that captures popular RPC-based application styles (e.g., gen_servers in Erlang/OTP), and a distributed black-box monitoring algorithm that we prove sound and complete (i.e., identifies deadlocked services with neither false positives nor false negatives). We implement our results in a tool called DDMon for the monitoring of Erlang/OTP applications, and we evaluate its performance. This is the first work that formalises, proves the correctness, and implements distributed black-box monitors for deadlock detection. Our results are mechanised in Coq. DDMon is the companion artifact of this paper.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14850v1" target="_blank">EECT: an Eccentricity Evolution Consistency Test to distinguish eccentric gravitational-wave signals from eccentricity mimickers</a></h3>
                    <p><strong>Authors:</strong> Sajad A. Bhat, Avinash Tiwari, Md Arif Shaikh, Shasvath J. Kapadia</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.HE, astro-ph.IM</p>
                    <p><strong>Summary:</strong> Eccentric compact binary coalescences (CBCs) are expected to be observed in current and future gravitational-wave (GW) detector networks. However, it has been recently pointed out that a number of other physical and beyond-GR effects, could imitate, or be mimicked by, eccentric CBCs. In this work, we propose a conceptually simple but powerful method to directly confirm or reject the eccentric hypothesis, without needing to compare the hypothesis with the plethora of other possible hypotheses. The key idea is that while spurious non-zero values of eccentricity, at some reference frequency, could be acquired when a non-eccentric CBC with additional physical/beyond-GR effects is recovered with an eccentric CBC waveform model, the {\it evolution} of eccentricity with frequency will in general not be mimicked. We accordingly formulate an eccentricity evolution consistency test (EECT). The method compares the eccentricity recovered at some low frequency value (e.g, $10$ Hz), evolved to higher frequencies assuming GR, with eccentricities recovered at those same higher frequencies. Discrepancy between the two eccentricities at any reference frequency would violate EECT and indicate the presence of a mimicker. As a proof of concept, assuming a few eccentric CBC systems, quasi-circular CBCs with additional physics mimicking eccentricity, and an O4-like three-detector-network configuration, we demonstrate that our proposed method is indeed able to reject mimickers at $\geq 68\%$ confidence, while ensuring that truly eccentric CBCs satisfy EECT.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14849v1" target="_blank">Physics-Informed ML Exploration of Structure-Transport Relationships in Hard Carbon</a></h3>
                    <p><strong>Authors:</strong> Nikhil Rampal, Stephen E. Weitzner, Fredrick Omenya, Marissa Wood, David M. Reed, Xiaolin Li, Jonathan R. I. Lee, Liwen F. Wan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Sodium-ion batteries are a cost-effective and sustainable alternative to lithium-ion systems for large-scale energy storage. Hard carbon (HC) anodes, composed of disordered graphitic and amorphous domains, offer high capacity but exhibit complex, poorly understood ion transport behavior. In particular, the relationship between local microstructure and sodium mobility remains unresolved, hindering rational performance optimization. Here, we introduce a data-driven framework that combines machine-learned interatomic potentials with molecular dynamics simulations to systematically investigate sodium diffusion across a broad range of carbon densities and sodium loadings. By computing per-ion structural descriptors, we identify the microscopic factors that govern ion transport. Unsupervised learning uncovers distinct diffusion modes, including hopping, clustering, and void trapping, while supervised analysis highlights tortuosity and NaNa coordination as primary determinants of mobility. Correlation mapping further connects these transport regimes to processing variables such as bulk density and sodium content. This physics-informed approach establishes quantitative structure-transport relationships that capture the heterogeneity of disordered carbon. Our findings deliver mechanistic insights into sodium-ion dynamics and provide actionable design principles for engineering high-performance HC anodes in next-generation battery systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14848v1" target="_blank">Leveraging Hardware-Aware Computation in Mixed-Precision Matrix Multiply: A Tile-Centric Approach</a></h3>
                    <p><strong>Authors:</strong> Qiao Zhang, Rabab Alomairy, Dali Wang, Zhuowei Gu, Qinglei Cao</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> General Matrix Multiplication (GEMM) is a critical operation underpinning a wide range of applications in high-performance computing (HPC) and artificial intelligence (AI). The emergence of hardware optimized for low-precision arithmetic necessitates a reevaluation of numerical algorithms to leverage mixed-precision computations, achieving improved performance and energy efficiency. This research introduces an adaptive mixed-precision GEMM framework that supports different precision formats at fine-grained tile/block levels. We utilize the PaRSEC runtime system to balance workloads across various architectures. The performance scales well on ARM CPU-based Fugaku supercomputer, Nvidia GPU-based A100 DGX, and AMD GPU-based Frontier supercomputer. This research aims to enhance computational efficiency and accuracy by bridging algorithmic advancements and hardware innovations, driving transformative progress in various applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14847v1" target="_blank">Power-Law Interactions Stabilize Time Crystals Realizing Quantum Energy Storage and Sensing</a></h3>
                    <p><strong>Authors:</strong> Ayan Sahoo, Debraj Rakshit</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.other</p>
                    <p><strong>Summary:</strong> We study discrete time-crystalline (DTC) phases in one-dimensional spin-1/2 chains with power-law interactions under periodic Floquet driving. By generalizing Stark localization to power-law interaction profiles, we identify robust period-doubled dynamics across a wide range of interaction exponents, stabilized by the interplay between coherent driving and spatially varying coupling. Within the DTC phase, the energy stored in the system, interpreted as a quantum battery, increases superlinearly with system size, although no scaling advantage persists in normalized power. Beyond energy storage, we demonstrate that the DTC phase supports enhanced quantum sensing. The quantum Fisher information associated with estimating timing deviations in the drive scales superextensively with system size, surpassing the Heisenberg limit. The degree of quantum advantage can be tuned by varying the interaction exponent, though DTC behavior remains robust throughout. Our results position power-law interacting Floquet systems as robust platforms for storing quantum energy and achieving metrological enhancement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14845v1" target="_blank">Quantum Interference of Distinguishable Photons Based on Spatially-Resolved Measurements</a></h3>
                    <p><strong>Authors:</strong> Miguel Angel Gonzalez, Alejandra AlarcÃ³n, Andres Camilo Quintero, Daniel Sabogal, Luca Maggio, Vincenzo Tamma, Daniel F. Urrego, Alejandra Valencia</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We present experimental results demonstrating the quantum interference of two photons distinguishable in their transverse momenta, each entering the input ports of a balanced beam splitter. This counterintuitive interference effect is made possible through spatially resolved measurements in the near field, i.e., by resolving the conjugate variable in which the photons are distinguishable. Our experimental findings agree with theoretical predictions. We contrast our results with a non-spatially resolved measurement where averaging over the photons positions washes out the quantum interference observed in spatially resolved measurements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14844v1" target="_blank">Multimodal Quantum Vision Transformer for Enzyme Commission Classification from Biochemical Representations</a></h3>
                    <p><strong>Authors:</strong> Murat Isik, Mandeep Kaur Saggi, Humaira Gowher, Sabre Kais</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Accurately predicting enzyme functionality remains one of the major challenges in computational biology, particularly for enzymes with limited structural annotations or sequence homology. We present a novel multimodal Quantum Machine Learning (QML) framework that enhances Enzyme Commission (EC) classification by integrating four complementary biochemical modalities: protein sequence embeddings, quantum-derived electronic descriptors, molecular graph structures, and 2D molecular image representations. Quantum Vision Transformer (QVT) backbone equipped with modality-specific encoders and a unified cross-attention fusion module. By integrating graph features and spatial patterns, our method captures key stereoelectronic interactions behind enzyme function. Experimental results demonstrate that our multimodal QVT model achieves a top-1 accuracy of 85.1%, outperforming sequence-only baselines by a substantial margin and achieving better performance results compared to other QML models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14840v1" target="_blank">A State-Space Representation of Coupled Linear Multivariate PDEs and Stability Analysis using SDP</a></h3>
                    <p><strong>Authors:</strong> Declan S. Jagt, Matthew M. Peet</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> math.AP, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> Physical processes evolving in both time and space are often modeled using Partial Differential Equations (PDEs). Recently, it has been shown how stability analysis and control of coupled PDEs in a single spatial variable can be more conveniently performed using an equivalent Partial Integral Equation (PIE) representation. The construction of this PIE representation is based on an analytic expression for the inverse of the spatial differential operator, $\partial_s^{d}$, on the domain defined by boundary conditions. In this paper, we show how this univariate representation may be extended inductively to multiple spatial variables by representing the domain as the intersection of lifted univariate domains. Specifically, we show that if each univariate domain is well-posed, then there exists a readily verified consistency condition which is necessary and sufficient for existence of an inverse to the multivariate spatial differential operator, $D^\alpha=\partial_{s_1}^{\alpha_1}\cdots\partial_{s_N}^{\alpha_N}$, on the PDE domain. Furthermore, we show that this inverse is an element of a $*$-algebra of Partial Integral (PI) operators defined by polynomial semi-separable kernels. Based on this operator algebra, we show that the evolution of any suitably well-posed linear multivariate PDE may be described by a PIE, parameterized by elements of the PI algebra. A convex computational test for PDE stability is then proposed using a positive matrix parameterization of positive PI operators, and software (PIETOOLS) is provided which automates the process of representation and stability analysis of such PDEs. This software is used to analyze stability of 2D heat, wave, and plate equations, obtaining accurate bounds on the rate of decay.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14838v1" target="_blank">Constraint satisfaction problems, compactness and non-measurable sets</a></h3>
                    <p><strong>Authors:</strong> Claude Tardif</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.LO, 03E65, 68Q19, G.0</p>
                    <p><strong>Summary:</strong> A finite relational structure A is called compact if for any infinite relational structure B of the same type, the existence of a homomorphism from B to A is equivalent to the existence of homomorphisms from all finite substructures of B to A. We show that if A has width one, then the compactness of A can be proved in the axiom system of Zermelo and Fraenkel, but otherwise, the compactness of A implies the existence of non-measurable sets in 3-space.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14837v1" target="_blank">The Renormalized Yukawa Hamiltonian: Spectrum, Parton Distribution Functons, and Resource Estimates for Quantum Simulation</a></h3>
                    <p><strong>Authors:</strong> Carter M. Gustin, Kamil Serafin, William A. Simon, Alexis Ralli, Gary R. Goldstein, Peter J. Love</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> hep-th, nucl-th, quant-ph</p>
                    <p><strong>Summary:</strong> We apply the Renormalization Group Procedure for Effective Particles (RGPEP) to the front form Yukawa Hamiltonian, yielding a renormalized (effective) Hamiltonian, accurate up to second order in the coupling strength. Subsequently, we examine the spectrum and parton distribution functions produced by the renormalized Hamiltonian, and show that the addition of counterterms leads to finite results. Resource estimates for quantum simulation are calculated for a single `Ladder Operator Block Encoding (LOBE), and show that the cost to block encode the renormalized Hamiltonian is comparable to block encoding the bare Hamiltonian.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14836v1" target="_blank">Quantum mechanics, non-locality, and the space discreteness hypothesis</a></h3>
                    <p><strong>Authors:</strong> W. A. ZÃºÃ±iga-Galindo</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> The space discreteness hypothesis asserts that the nature of space at short distances is radically different from that at large distances. Based on the Bronstein inequality, here, we use a totally disconnected topological space $\mathcal{X}$ as a model for the space. However, we consider the time as a real variable. In this framework, the formalism of Dirac-von Neumann can be used. This discreteness hypothesis implies that given two different points in space, there is no continuous curve (a world line) joining them. Consequently, this hypothesis is not compatible with the theory of relativity. We propose $\mathbb{R}\times(\mathbb{R}\times\mathcal{X})^{3}$ as a model of a space-time. For simplicity, we work out our models using $\mathbb{R}\times(\mathbb{R}\times\mathcal{X})$ as the configuration space. Quantum mechanics (QM), in the sense of Dirac-von Neumann, on the Hilbert space $L^{2}(\mathbb{R}\times\mathcal{X})$ is a non-local theory: the Hamiltonians are non-local operators, and thus, spooky action at a distance is allowed. The paradigm asserting that the universe is non-locally real implies that the proposed version of QM admits realism. This version of QM can be specialized to standard QM by using Hamiltonians acting on wavefunctions supported on the region $\mathbb{R}\times\mathbb{R}$. We apply the developed formalism to the measurement problem. We propose a new mechanism for the collapse of the wavefunction. The mechanism resembles the one proposed by Ghirardi, Ramini, and Weber, but there are significant differences. The most important feature is that the Schr\{o}dinger equation describes the dynamics at all times, even at the moment of measurement. We also discuss a model for the two-slit experiment, where bright and dark states of light (proposed recently) naturally occur.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14833v1" target="_blank">An Investigation Into Secondary School Students Debugging Behaviour in Python</a></h3>
                    <p><strong>Authors:</strong> Laurie Gale, Sue Sentance</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Background and context: Debugging is a common and often frustrating challenge for beginner programmers. Understanding students debugging processes can help us identify the difficulties and misunderstandings they possess. However, we currently have limited knowledge of how secondary students debug in a text-based language, a medium through which millions of students will learn to program in the future. Objectives: In this paper, we investigate the debugging behaviour of K-12 students learning a text-based programming language, as part of an effort to shape how to effectively teach debugging to these students. Method: We collected log data from 73 students attempting a set of debugging exercises using an online code editor. We inductively analysed these logs using qualitative content analysis, generating a categorisation of the debugging behaviours observed. Findings: A range of behaviours were exhibited by students, skewed towards being ineffective. Most students were able to partially locate errors but often struggled to resolve them, sometimes introducing additional errors in the process. We argue that students struggling to debug possess fragile knowledge, a lens through which we view the results. Implications: This paper highlights some of the difficulties K-12 learners have when debugging in a text-based programming language. We argue, like much related work, that effective debugging strategies should be explicitly taught, while ineffective strategies should be discouraged.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14831v1" target="_blank">TIME$[t] \subseteq {\rm SPACE}[O(\sqrt{t})]$ via Tree Height Compression</a></h3>
                    <p><strong>Authors:</strong> Logan Nye</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CC, cs.AI, cs.DS</p>
                    <p><strong>Summary:</strong> We prove a square-root space simulation for deterministic multitape Turing machines, showing ${\rm TIME}[[t] \subseteq {\rm SPACE}[O(\sqrt{t})]$. The key step is a Height Compression Theorem that uniformly (and in logspace) reshapes the canonical left-deep succinct computation tree for a block-respecting run into a binary tree whose evaluation-stack depth along any DFS path is $O(\log T)$ for $T = \lceil t/b \rceil$, while preserving $O(b)$ work at leaves, $O(1)$ at internal nodes, and edges that are logspace-checkable; semantic correctness across merges is witnessed by an exact $O(b)$ window replay at the unique interface. The proof uses midpoint (balanced) recursion, a per-path potential that bounds simultaneously active interfaces by $O(\log T)$, and an indegree-capping replacement of multiway merges by balanced binary combiners. Algorithmically, an Algebraic Replay Engine with constant-degree maps over a constant-size field, together with pointerless DFS and index-free streaming, ensures constant-size per-level tokens and eliminates wide counters, yielding the additive tradeoff $S(b)=O(b + \log(t/b))$ for block sizes $b \ge b_0$ with $b_0 = \Theta(\log t)$, which at the canonical choice $b = \Theta(\sqrt{t})$ gives $O(\sqrt{t})$ space; the $b_0$ threshold rules out degenerate blocks where addressing scratch would dominate the window footprint. The construction is uniform, relativizes, and is robust to standard model choices. Consequences include branching-program upper bounds $2^{O(\sqrt{s})}$ for size-$s$ bounded-fan-in circuits, tightened quadratic-time lower bounds for SPACE$[n]$-complete problems via the standard hierarchy argument, and $O(\sqrt{t})$-space certifying interpreters; under explicit locality assumptions, the framework extends to geometric $d$-dimensional models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14830v1" target="_blank">MOHAF: A Multi-Objective Hierarchical Auction Framework for Scalable and Fair Resource Allocation in IoT Ecosystems</a></h3>
                    <p><strong>Authors:</strong> Kushagra Agrawal, Polat Goktas, Anjan Bandopadhyay, Debolina Ghosh, Junali Jasmine Jena, Mahendra Kumar Gourisaria</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.DC, cs.GT, cs.NE, cs.NI</p>
                    <p><strong>Summary:</strong> The rapid growth of Internet of Things (IoT) ecosystems has intensified the challenge of efficiently allocating heterogeneous resources in highly dynamic, distributed environments. Conventional centralized mechanisms and single-objective auction models, focusing solely on metrics such as cost minimization or revenue maximization, struggle to deliver balanced system performance. This paper proposes the Multi-Objective Hierarchical Auction Framework (MOHAF), a distributed resource allocation mechanism that jointly optimizes cost, Quality of Service (QoS), energy efficiency, and fairness. MOHAF integrates hierarchical clustering to reduce computational complexity with a greedy, submodular optimization strategy that guarantees a (1-1/e) approximation ratio. A dynamic pricing mechanism adapts in real time to resource utilization, enhancing market stability and allocation quality. Extensive experiments on the Google Cluster Data trace, comprising 3,553 requests and 888 resources, demonstrate MOHAFs superior allocation efficiency (0.263) compared to Greedy (0.185), First-Price (0.138), and Random (0.101) auctions, while achieving perfect fairness (Jains index = 1.000). Ablation studies reveal the critical influence of cost and QoS components in sustaining balanced multi-objective outcomes. With near-linear scalability, theoretical guarantees, and robust empirical performance, MOHAF offers a practical and adaptable solution for large-scale IoT deployments, effectively reconciling efficiency, equity, and sustainability in distributed resource coordination.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14829v1" target="_blank">Core position-dependent gyrotropic and damping contributions to the Thiele equation approach for accurate spin-torque vortex oscillator dynamics</a></h3>
                    <p><strong>Authors:</strong> Colin Ducarme, Simon De Wergifosse, Flavio Abreu Araujo</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Understanding the nonlinear dynamics of magnetic vortices in spin-torque vortex oscillators (STVOs) is essential for their application in neuromorphic computing. Existing models either rely on the standard Thiele equation approach (TEA), which offer only qualitative predictions, or on micromagnetic simulations (MMS), which are computationally demanding. We present a refined Thiele approach that incorporates the deformation of the vortex profile for the evaluation of the gyrotropic and damping terms. In this manuscript, a more realistic ansatz of the vortex magnetization profile is introduced to extract these effective parameters semi-analytically. A method to extract the gyrotropic and damping terms directly from MMS is also presented. The resulting expressions are benchmarked against state-of-the-art analytical derivations, and reveal a damping anisotropy of the vortex core. This framework captures the essential nonlinearities of STVO dynamics with high fidelity at low computational cost, paving the way for predictive modeling of large-scale neuromorphic circuits based on STVOs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14828v1" target="_blank">Long Chain-of-Thought Reasoning Across Languages</a></h3>
                    <p><strong>Authors:</strong> Josh Barua, Seun Eisape, Kayo Yin, Alane Suhr</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Scaling inference through long chains-of-thought (CoTs) has unlocked impressive reasoning capabilities in large language models (LLMs), yet the reasoning process remains almost exclusively English-centric. We construct translated versions of two popular English reasoning datasets, fine-tune Qwen 2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT generation across French, Japanese, Latvian, and Swahili. Our experiments reveal three key findings. First, the efficacy of using English as a pivot language varies by language: it provides no benefit for French, improves performance when used as the reasoning language for Japanese and Latvian, and proves insufficient for Swahili where both task comprehension and reasoning remain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but does not eliminate the cross-lingual performance gap. A lightweight fine-tune using only 1k traces still improves performance by over 30\% in Swahili. Third, data quality versus scale trade-offs are language dependent: small, carefully curated datasets suffice for English and French, whereas larger but noisier corpora prove more effective for Swahili and Latvian. Together, these results clarify when and why long CoTs transfer across languages and provide translated datasets to foster equitable multilingual reasoning research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14825v1" target="_blank">From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning</a></h3>
                    <p><strong>Authors:</strong> Lixiang Yan</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> The role of Artificial Intelligence (AI) in education is undergoing a rapid transformation, moving beyond its historical function as an instructional tool towards a new potential as an active participant in the learning process. This shift is driven by the emergence of agentic AI, autonomous systems capable of proactive, goal-directed action. However, the field lacks a robust conceptual framework to understand, design, and evaluate this new paradigm of human-AI interaction in learning. This paper addresses this gap by proposing a novel conceptual framework (the APCP framework) that charts the transition from AI as a tool to AI as a collaborative partner. We present a four-level model of escalating AI agency within human-AI collaborative learning: (1) the AI as an Adaptive Instrument, (2) the AI as a Proactive Assistant, (3) the AI as a Co-Learner, and (4) the AI as a Peer Collaborator. Grounded in sociocultural theories of learning and Computer-Supported Collaborative Learning (CSCL), this framework provides a structured vocabulary for analysing the shifting roles and responsibilities between human and AI agents. The paper further engages in a critical discussion of the philosophical underpinnings of collaboration, examining whether an AI, lacking genuine consciousness or shared intentionality, can be considered a true collaborator. We conclude that while AI may not achieve authentic phenomenological partnership, it can be designed as a highly effective functional collaborator. This distinction has significant implications for pedagogy, instructional design, and the future research agenda for AI in education, urging a shift in focus towards creating learning environments that harness the complementary strengths of both human and AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14822v1" target="_blank">Operational reconstruction of Feynman rules for quantum amplitudes via composition algebras</a></h3>
                    <p><strong>Authors:</strong> Jens KÃ¶plinger, Michael Habeck, Philip Goyal</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> This paper revisits an operational model presented in Origin of complex quantum amplitudes and Feynmans rules, Phys. Rev. A 81 (2010), 022109 (P. Goyal, K. H. Knuth, J. Skilling) as part of the Quantum Reconstruction Program, describing transition amplitudes between measurements. Our methodology establishes clarity by separating axioms from mathematics, choices from physics, and deductions therefrom. We carefully evaluate the original model in a coordinate-independent way without requiring a two-dimensional space a priori. All scalar field and vector space axioms are traced from model axioms and observer choices, including additive and multiplicative units and inverses. Known theorems in math classify allowable amplitude algebras as the real associative composition algebras, namely, the two-dimensional (split-)complex numbers and the four-dimensional (split-)quaternions. Observed probabilities are quadratic in amplitudes, akin to the Born rule in physics. We point out select ramifications of postulated model axioms and ways to rephrase observer questions; and advertise broad utility of our work towards follow-on discovery, whether as a consequence, generalization, or alternative. One seemingly minute generalization is sketched in the outlook, with algebraic consequences at the heart of current open questions in mathematics and physics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14820v1" target="_blank">The Rectilinear Marco Polo Problem</a></h3>
                    <p><strong>Authors:</strong> Ofek Gila, Michael T. Goodrich, Zahra Hadizadeh, Daniel S. Hirschberg, Shayan Taherijam</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CG, I.3.5; F.2.2; I.2.8</p>
                    <p><strong>Summary:</strong> We study the rectilinear Marco Polo problem, which generalizes the Euclidean version of the Marco Polo problem for performing geometric localization to rectilinear search environments, such as in geometries motivated from urban settings, and to higher dimensions. In the rectilinear Marco Polo problem, there is at least one point of interest (POI) within distance $n$, in either the $L_1$ or $L_\infty$ metric, from the origin. Motivated from a search-and-rescue application, our goal is to move a search point, $\Delta$, from the origin to a location within distance $1$ of a POI. We periodically issue probes from $\Delta$ out a given distance (in either the $L_1$ or $L_\infty$ metric) and if a POI is within the specified distance of $\Delta$, then we learn this (but no other location information). Optimization goals are to minimize the number of probes and the distance traveled by $\Delta$. We describe a number of efficient search strategies for rectilinear Marco Polo problems and we analyze each one in terms of the size, $n$, of the search domain, as defined by the maximum distance to a POI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14817v1" target="_blank">Evaluating Retrieval-Augmented Generation vs. Long-Context Input for Clinical Reasoning over EHRs</a></h3>
                    <p><strong>Authors:</strong> Skatje Myers, Dmitriy Dligach, Timothy A. Miller, Samantha Barr, Yanjun Gao, Matthew Churpek, Anoop Mayampurath, Majid Afshar</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Electronic health records (EHRs) are long, noisy, and often redundant, posing a major challenge for the clinicians who must navigate them. Large language models (LLMs) offer a promising solution for extracting and reasoning over this unstructured text, but the length of clinical notes often exceeds even state-of-the-art models extended context windows. Retrieval-augmented generation (RAG) offers an alternative by retrieving task-relevant passages from across the entire EHR, potentially reducing the amount of required input tokens. In this work, we propose three clinical tasks designed to be replicable across health systems with minimal effort: 1) extracting imaging procedures, 2) generating timelines of antibiotic use, and 3) identifying key diagnoses. Using EHRs from actual hospitalized patients, we test three state-of-the-art LLMs with varying amounts of provided context, using either targeted text retrieval or the most recent clinical notes. We find that RAG closely matches or exceeds the performance of using recent notes, and approaches the performance of using the models full context while requiring drastically fewer input tokens. Our results suggest that RAG remains a competitive and efficient approach even as newer models become capable of handling increasingly longer amounts of text.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14815v1" target="_blank">A Lightweight Privacy-Preserving Smart Metering Billing Protocol with Dynamic Tariff Policy Adjustment</a></h3>
                    <p><strong>Authors:</strong> Farid Zaredar, Morteza Amini</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> The integration of information and communication technology (ICT) with traditional power grids has led to the emergence of smart grids. Advanced metering infrastructure (AMI) plays a crucial role in smart grids by facilitating two-way communication between smart meters and the utility provider. This bidirectional communication allows intelligent meters to report fine-grained consumption data at predefined intervals, enabling accurate billing, efficient grid monitoring and management, and rapid outage detection. However, the collection of detailed consumption data can inadvertently disclose consumers daily activities, raising privacy concerns and potentially leading to privacy violations. To address these issues and preserve individuals privacy, we propose a lightweight privacy-preserving smart metering protocol specifically designed to support real-time tariff billing service with dynamic policy adjustment. Our scheme employs an efficient data perturbation technique to obscure precise energy usage data from internal adversaries, including the intermediary gateways and the utility provider. Subsequently, we validate the efficiency and security of our protocol through comprehensive performance and privacy evaluations. We examined the computational, memory, and communication overhead of the proposed scheme. The execution time of our secure and privacy-aware billing system is approximately 3.94540 seconds for a complete year. Furthermore, we employed the Jensen-Shannon divergence as a privacy metric to demonstrate that our protocol can effectively safeguard users privacy by increasing the noise scale.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14814v1" target="_blank">TransLight: Image-Guided Customized Lighting Control with Generative Decoupling</a></h3>
                    <p><strong>Authors:</strong> Zongming Li, Lianghui Zhu, Haocheng Shen, Longjin Ran, Wenyu Liu, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Most existing illumination-editing approaches fail to simultaneously provide customized control of light effects and preserve content integrity. This makes them less effective for practical lighting stylization requirements, especially in the challenging task of transferring complex light effects from a reference image to a user-specified target image. To address this problem, we propose TransLight, a novel framework that enables high-fidelity and high-freedom transfer of light effects. Extracting the light effect from the reference image is the most critical and challenging step in our method. The difficulty lies in the complex geometric structure features embedded in light effects that are highly coupled with content in real-world scenarios. To achieve this, we first present Generative Decoupling, where two fine-tuned diffusion models are used to accurately separate image content and light effects, generating a newly curated, million-scale dataset of image-content-light triplets. Then, we employ IC-Light as the generative model and train our model with our triplets, injecting the reference lighting image as an additional conditioning signal. The resulting TransLight model enables customized and natural transfer of diverse light effects. Notably, by thoroughly disentangling light effects from reference images, our generative decoupling strategy endows TransLight with highly flexible illumination control. Experimental results establish TransLight as the first method to successfully transfer light effects across disparate images, delivering more customized illumination control than existing techniques and charting new directions for research in illumination harmonization and editing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14813v1" target="_blank">Pricing Options on Forwards in Function-Valued Affine Stochastic Volatility Models</a></h3>
                    <p><strong>Authors:</strong> Jian He, Sven Karbach, Asma Khedher</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> q-fin.MF, math.PR, q-fin.CP</p>
                    <p><strong>Summary:</strong> We study the pricing of European-style options written on forward contracts within function-valued infinite-dimensional affine stochastic volatility models. The dynamics of the underlying forward price curves are modeled within the Heath-Jarrow-Morton-Musiela framework as solution to a stochastic partial differential equation modulated by a stochastic volatility process. We analyze two classes of affine stochastic volatility models: (i) a Gaussian model governed by a finite-rank Wishart process, and (ii) a pure-jump affine model extending the Barndorff--Nielsen--Shephard framework with state-dependent jumps in the covariance component. For both models, we derive conditions for the existence of exponential moments and develop semi-closed Fourier-based pricing formulas for vanilla call and put options written on forward price curves. Our approach allows for tractable pricing in models with infinitely many risk factors, thereby capturing maturity-specific and term structure risk essential in forward markets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14812v1" target="_blank">Repeating Words for Video-Language Retrieval with Coarse-to-Fine Objectives</a></h3>
                    <p><strong>Authors:</strong> Haoyu Zhao, Jiaxi Gu, Shicong Wang, Xing Zhang, Hang Xu, Zuxuan Wu, Yu-Gang Jiang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The explosive growth of video streaming presents challenges in achieving high accuracy and low training costs for video-language retrieval. However, existing methods rely on large-scale pre-training to improve video retrieval performance, resulting in significant computational demands. Additionally, the fine-grained information in videos and texts remains underexplored. To alleviate these problems, we propose a novel framework to learn fine-grained features for better alignment and introduce an inference pipeline to improve performance without additional training. Specifically, we employ coarse-to-fine objectives to understand the semantic information of video-text pairs, including contrastive and matching learning. The fine-grained data used for training is obtained through the Granularity-Aware Representation module, which is designed based on similarity analysis between video frames and words in captions. Furthermore, we observe that the repetition of keywords in the original captions, referred to as Repetition, can enhance retrieval performance and improve alignment between video and text. Based on this insight, we propose a novel and effective inference pipeline that incorporates a voting mechanism and a new Matching Entropy metric to achieve better retrieval performance without requiring additional pre-training. Experimental results on four benchmarks demonstrate that the proposed method outperforms previous approaches. Additionally, our inference pipeline achieves significant performance improvements, with a 2.1% increase in Recall@1 on the MSR-VTT dataset and a 1.6% increase on the DiDeMo dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14811v1" target="_blank">Tinker: Diffusions Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization</a></h3>
                    <p><strong>Authors:</strong> Canyu Zhao, Xiaoman Li, Tianjian Feng, Zhiyue Zhao, Hao Chen, Chunhua Shen</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Tinker, a versatile framework for high-fidelity 3D editing that operates in both one-shot and few-shot regimes without any per-scene finetuning. Unlike prior techniques that demand extensive per-scene optimization to ensure multi-view consistency or to produce dozens of consistent edited input views, Tinker delivers robust, multi-view consistent edits from as few as one or two images. This capability stems from repurposing pretrained diffusion models, which unlocks their latent 3D awareness. To drive research in this space, we curate the first large-scale multi-view editing dataset and data pipeline, spanning diverse scenes and styles. Building on this dataset, we develop our framework capable of generating multi-view consistent edited views without per-scene training, which consists of two novel components: (1) Referring multi-view editor: Enables precise, reference-driven edits that remain coherent across all viewpoints. (2) Any-view-to-video synthesizer: Leverages spatial-temporal priors from video diffusion to perform high-quality scene completion and novel-view generation even from sparse inputs. Through extensive experiments, Tinker significantly reduces the barrier to generalizable 3D content creation, achieving state-of-the-art performance on editing, novel-view synthesis, and rendering enhancement tasks. We believe that Tinker represents a key step towards truly scalable, zero-shot 3D editing. Project webpage: https://aim-uofa.github.io/Tinker</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14809v1" target="_blank">DINOv3 with Test-Time Training for Medical Image Registration</a></h3>
                    <p><strong>Authors:</strong> Shansong Wang, Mojtaba Safari, Mingzhe Hu, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Xiaofeng Yang</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Prior medical image registration approaches, particularly learning-based methods, often require large amounts of training data, which constrains clinical adoption. To overcome this limitation, we propose a training-free pipeline that relies on a frozen DINOv3 encoder and test-time optimization of the deformation field in feature space. Across two representative benchmarks, the method is accurate and yields regular deformations. On Abdomen MR-CT, it attained the best mean Dice score (DSC) of 0.790 together with the lowest 95th percentile Hausdorff Distance (HD95) of 4.9+-5.0 and the lowest standard deviation of Log-Jacobian (SDLogJ) of 0.08+-0.02. On ACDC cardiac MRI, it improves mean DSC to 0.769 and reduces SDLogJ to 0.11 and HD95 to 4.8, a marked gain over the initial alignment. The results indicate that operating in a compact foundation feature space at test time offers a practical and general solution for clinical registration without additional training.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14803v1" target="_blank">Exact $\ell^\infty$-separation radius of Sobol sequences in dimension 2</a></h3>
                    <p><strong>Authors:</strong> Kosuke Suzuki</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, 05B40, 11K36, 52C15</p>
                    <p><strong>Summary:</strong> Quasi-uniformity is a fundamental geometric property of point sets, crucial for applications such as kernel interpolation, Gaussian process regression, and space-filling experimental designs. While quasi-Monte Carlo methods are widely recognized for their low-discrepancy characteristics, understanding their quasi-uniformity remains important for practical applications. For the two-dimensional Sobol sequence, Sobol and Shukhman (2007) conjectured that the separation radius of the first $N$ points achieves the optimal rate $N^{-1/2}$, which would imply quasi-uniformity. This conjecture was disproved by Goda (2024), who computed exact values of the $\ell^2$-separation radius for a sparse subsequence $N = 2^{2^v-1}$. However, the general behavior of the Sobol sequence for arbitrary $N$ remained unclear. In this paper, we derive exact expressions for the $\ell^\infty$-separation radius of the first $N = 2^m$ points of the two-dimensional Sobol sequence for all $m \in \mathbb{N}$. As an immediate consequence, we show that the separation radius of Sobol points is $O(N^{-3/4})$, which is strictly worse than the optimal rate $N^{-1/2}$, revealing that the two-dimensional Sobol sequence has a suboptimal mesh ratio that grows at least as $N^{1/4}$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14802v1" target="_blank">Privileged Self-Access Matters for Introspection in AI</a></h3>
                    <p><strong>Authors:</strong> Siyuan Song, Harvey Lederman, Jennifer Hu, Kyle Mahowald</p>
                    <p><strong>Published:</strong> 8/20/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Whether AI models can introspect is an increasingly important practical question. But there is no consensus on how introspection is to be defined. Beginning from a recently proposed lightweight definition, we argue instead for a thicker one. According to our proposal, introspection in AI is any process which yields information about internal states through a process more reliable than one with equal or lower computational cost available to a third party. Using experiments where LLMs reason about their internal temperature parameters, we show they can appear to have lightweight introspection while failing to meaningfully introspect per our proposed definition.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

