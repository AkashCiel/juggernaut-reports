
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-07-25<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 103
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The recent papers in AI safety research showcase significant advancements and challenges across multiple domains, highlighting trends in responsible AI development and safety alignment. Notably, the paper Layer-Aware Representation Filtering introduces a method to maintain safety alignment during the fine-tuning of large language models (LLMs), addressing the risk of safety degradation due to hidden unsafe features in datasets. This highlights an ongoing trend towards developing techniques for preserving and enhancing model safety during adaptation to new tasks.

Another significant contribution is SafeWork-R1, where a multimodal reasoning model is developed with intrinsic safety reasoning capabilities, demonstrating the coevolution of AI capabilities and safety. This work emphasizes the potential for models to evolve safety-oriented reasoning abilities, suggesting a shift towards AI systems that can autonomously manage safety concerns.

Additionally, the paper Checklists Are Better Than Reward Models For Aligning Language Models proposes a novel reinforcement learning approach that uses checklists for better alignment of language models with user instructions, moving towards more effective and flexible model training methods that can adapt to diverse user needs while ensuring safety.

Together, these papers underscore a critical focus on enhancing AI safety through improved data handling, intrinsic safety reasoning in models, and innovative alignment methodologies. These advancements are vital for mitigating risks associated with AI deployment across various applications, ensuring robust and trustworthy AI systems.

*Based on 50 research papers*

---

## ai alignment research

AI alignment research focuses on ensuring that AI systems act in ways that align with human values and intentions. The papers summarized here contribute to this field by addressing challenges related to the alignment of AI models with their intended purposes.

The first paper, Identifying Prompted Artist Names from Generated Images, tackles the challenge of moderating text-to-image models, which can generate images in the style of named artists. The authors introduce a benchmark for recognizing which artist names were used in prompts based solely on the generated images. This work highlights the complexity of AI alignment in creative domains, as it reveals the difficulty in distinguishing styles and moderating content generation. Their benchmark serves as a tool to improve the responsible use of these models, which is crucial for maintaining ethical standards in AI-generated art.

The second paper, SIDA: Synthetic Image Driven Zero-shot Domain Adaptation, addresses domain adaptation without target domain data, which aligns with the goal of making AI systems robust across various environments. The authors propose a method that uses synthetic images to simulate target domain styles, thereby reducing the adaptation time and enhancing performance in challenging domains. This approach exemplifies an important trend in AI alignmentâ€”improving model robustness and generalization without explicit target dataâ€”thereby reducing potential biases and improving reliability.

Lastly, the paper Layer-Aware Representation Filtering focuses on maintaining safety in fine-tuning large language models (LLMs). The authors identify that fine-tuning data often includes samples that can degrade model safety, even if they appear benign. They propose a method to filter out such data, preserving the models safety alignment. This has significant implications for AI alignment, as it addresses the challenge of ensuring that models remain secure and aligned with user intentions during the adaptation process. Together, these papers underscore the ongoing efforts to align AI systems with human values and ethical standards, highlighting innovative strategies to tackle alignment challenges in different domains.

*Based on 3 research papers*

---

## quantum computing

The provided list of research papers does not directly focus on quantum computing, which makes it challenging to extract relevant trends, breakthroughs, or implications specific to quantum computing from the documents. However, among the diverse topics covered, one paper stands out with a potential quantum computing connection:

The paper titled **Hybrid quantum-classical algorithm for near-optimal planning in POMDPs** by Gilberto Cunha et al. explores the intersection of quantum computing and reinforcement learning. It introduces Quantum Bayesian Reinforcement Learning (QBRL), a hybrid quantum-classical algorithm that enhances decision-making in partially observable environments, modeled as Markov decision processes. The key innovation lies in using quantum rejection sampling and amplitude amplification to accelerate inference in sparse Bayesian networks, achieving computational speedups in estimating acceptance probabilities. This paper highlights a significant trend in quantum computing, where quantum algorithms are being developed to tackle complex decision-making processes, showcasing their potential to enhance classical reinforcement learning frameworks. The implications of this research suggest that quantum computing can provide tangible benefits in terms of speed and efficiency in domains traditionally dominated by classical computing, thus opening new avenues for further exploration and application.

*Based on 50 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2507.18633v1" target="_blank">Identifying Prompted Artist Names from Generated Images</a></h3>
                    <p><strong>Authors:</strong> Grace Su, Sheng-Yu Wang, Aaron Hertzmann, Eli Shechtman, Jun-Yan Zhu, Richard Zhang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> A common and controversial use of text-to-image models is to generate pictures by explicitly naming artists, such as in the style of Greg Rutkowski. We introduce a benchmark for prompted-artist recognition: predicting which artist names were invoked in the prompt from the image alone. The dataset contains 1.95M images covering 110 artists and spans four generalization settings: held-out artists, increasing prompt complexity, multiple-artist prompts, and different text-to-image models. We evaluate feature similarity baselines, contrastive style descriptors, data attribution methods, supervised classifiers, and few-shot prototypical networks. Generalization patterns vary: supervised and few-shot models excel on seen artists and complex prompts, whereas style descriptors transfer better when the artists style is pronounced; multi-artist prompts remain the most challenging. Our benchmark reveals substantial headroom and provides a public testbed to advance the responsible moderation of text-to-image models. We release the dataset and benchmark to foster further research: https://graceduansu.github.io/IdentifyingPromptedArtists/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18631v1" target="_blank">Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment</a></h3>
                    <p><strong>Authors:</strong> Hao Li, Lijun Li, Zhenghao Lu, Xianyi Wei, Rui Li, Jing Shao, Lei Sha</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> With rapid advancement and increasing accessibility of LLMs, fine-tuning aligned models has become a critical step for adapting them to real-world applications, which makes the safety of this fine-tuning process more important than ever. However, recent studies have highlighted a critical challenge: even when fine-tuning with seemingly benign downstream datasets, the safety of aligned LLMs can be compromised, making them more susceptible to malicious instructions. In this paper, we show that fine-tuning datasets often contain samples with safety-degrading features that are not easily identifiable on the surface. These samples can significantly degrade the safety alignment of LLMs during fine-tuning. To address this issue, we propose LARF, a \textbf{L}ayer-\textbf{A}ware \textbf{R}epresentation \textbf{F}iltering method. This method identifies safety-sensitive layers within the LLM and leverages their representations to detect which data samples in the post-training dataset contain safety-degrading features. Experimental results demonstrate that LARF can effectively identify benign data with safety-degrading features. After removing such data, the safety alignment degradation caused by fine-tuning is mitigated. Please see our code at \href{https://github.com/LLLeoLi/LARF}{https://github.com/LLLeoLi/LARF}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18630v1" target="_blank">Design and optimization of a novel leaf-shape antenna for RF energy transfer</a></h3>
                    <p><strong>Authors:</strong> Junbin Zhong, Mingtong Chen, Zhengbao Yang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> In this research, the design and optimization of a novel leaf-shaped antenna inspired by natural leaf structures for radio frequency energy transfer is presented. The objectives of this study are to develop a bio-inspired antenna, optimize its performance through impedance matching for the 915 MHz frequency band, and evaluate its efficiency in capturing RF energy. The design process involves selecting an appropriate leaf shape, modeling the antenna using AutoCAD and HFSS software, and fabricating a printed circuit board (PCB) prototype. Simulations and physical tests are conducted to optimize the antennas performance, achieving an S11 parameter of nearly -20 dB at 915 MHz, indicating effective energy capture. Experimental results demonstrate the antennas ability to power a device at distances up to 200 cm, with charging times reflecting its efficiency. The study concludes that the bio-inspired design of the proposed antenna improves RF energy transfer. Future work should focus on testing the antennas penetration through concrete and developing a feedback system for autonomous alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18627v1" target="_blank">Gait Recognition Based on Tiny ML and IMU Sensors</a></h3>
                    <p><strong>Authors:</strong> Jiahang Zhang, Mingtong Chen, Zhengbao Yang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> This project presents the development of a gait recognition system using Tiny Machine Learning (Tiny ML) and Inertial Measurement Unit (IMU) sensors. The system leverages the XIAO-nRF52840 Sense microcontroller and the LSM6DS3 IMU sensor to capture motion data, including acceleration and angular velocity, from four distinct activities: walking, stationary, going upstairs, and going downstairs. The data collected is processed through Edge Impulse, an edge AI platform, which enables the training of machine learning models that can be deployed directly onto the microcontroller for real-time activity classification.The data preprocessing step involves extracting relevant features from the raw sensor data using techniques such as sliding windows and data normalization, followed by training a Deep Neural Network (DNN) classifier for activity recognition. The model achieves over 80% accuracy on a test dataset, demonstrating its ability to classify the four activities effectively. Additionally, the platform enables anomaly detection, further enhancing the robustness of the system. The integration of Tiny ML ensures low-power operation, making it suitable for battery-powered or energy-harvesting devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18624v1" target="_blank">Checklists Are Better Than Reward Models For Aligning Language Models</a></h3>
                    <p><strong>Authors:</strong> Vijay Viswanathan, Yanchao Sun, Shuang Ma, Xiang Kong, Meng Cao, Graham Neubig, Tongshuang Wu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Language models must be adapted to understand and follow user instructions. Reinforcement learning is widely used to facilitate this -- typically using fixed criteria such as helpfulness and harmfulness. In our work, we instead propose using flexible, instruction-specific criteria as a means of broadening the impact that reinforcement learning can have in eliciting instruction following. We propose Reinforcement Learning from Checklist Feedback (RLCF). From instructions, we extract checklists and evaluate how well responses satisfy each item - using both AI judges and specialized verifier programs - then combine these scores to compute rewards for RL. We compare RLCF with other alignment methods applied to a strong instruction following model (Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only method to improve performance on every benchmark, including a 4-point boost in hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a 3-point rise in win rate on Arena-Hard. These results establish checklist feedback as a key tool for improving language models support of queries that express a multitude of needs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18623v1" target="_blank">Moving Out: Physically-grounded Human-AI Collaboration</a></h3>
                    <p><strong>Authors:</strong> Xuhui Kang, Sung-Wook Lee, Haolin Liu, Yuyan Wang, Yen-Ling Kuo</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.MA</p>
                    <p><strong>Summary:</strong> The ability to adapt to physical actions and constraints in an environment is crucial for embodied agents (e.g., robots) to effectively collaborate with humans. Such physically grounded human-AI collaboration must account for the increased complexity of the continuous state-action space and constrained dynamics caused by physical constraints. In this paper, we introduce \textit{Moving Out}, a new human-AI collaboration benchmark that resembles a wide range of collaboration modes affected by physical attributes and constraints, such as moving heavy items together and maintaining consistent actions to move a big item around a corner. Using Moving Out, we designed two tasks and collected human-human interaction data to evaluate models abilities to adapt to diverse human behaviors and unseen physical attributes. To address the challenges in physical environments, we propose a novel method, BASS (Behavior Augmentation, Simulation, and Selection), to enhance the diversity of agents and their understanding of the outcome of actions. Our experiments show that BASS outperforms state-of-the-art models in AI-AI and human-AI collaboration. The project page is available at \href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\_ai/}.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3743049.3748566" target="_blank">Evaluation of a Provenance Management Tool for Immersive Virtual Fieldwork</a></h3>
                    <p><strong>Authors:</strong> Armin Bernstetter, Tom Kwasnitschka, Isabella Peters</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Ensuring reproducibility of research is an integral part of good scientific practice. One way to support this is through provenance: information about research workflows from data gathering to researchers sensemaking processes leading to published results. This is highly important in disciplines such as geosciences, where researchers use software for interactive and immersive visualizations of geospatial data, doing virtual measurements in simulated fieldwork on 3D models. We evaluated a provenance management tool, which allows recording of interactions with a virtual fieldwork tool and annotating different states of the visualization. The user study investigated how researchers used this Digital Lab Book (DLB) and whether perceived ease of use and perceived usefulness differed between groups in immersive or non-immersive settings. Participants perceived the DLB as both useful and easy to use. While there were indications of differences in perceived ease of use (higher for immersive setting), usage patterns showed no significant group differences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18618v1" target="_blank">TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards</a></h3>
                    <p><strong>Authors:</strong> Andreea Nica, Ivan Zakazov, Nicolas Mario Baldwin, Saibo Geng, Robert West</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Prompt optimization improves the reasoning abilities of large language models (LLMs) without requiring parameter updates to the target model. Following heuristic-based Think step by step approaches, the field has evolved in two main directions: while one group of methods uses textual feedback to elicit improved prompts from general-purpose LLMs in a training-free way, a concurrent line of research relies on numerical rewards to train a special prompt model, tailored for providing optimal prompts to the target model. In this paper, we introduce the Textual Reward Prompt framework (TRPrompt), which unifies these approaches by directly incorporating textual feedback into training of the prompt model. Our framework does not require prior dataset collection and is being iteratively improved with the feedback on the generated prompts. When coupled with the capacity of an LLM to internalize the notion of what a good prompt is, the high-resolution signal provided by the textual rewards allows us to train a prompt model yielding state-of-the-art query-specific prompts for the problems from the challenging math datasets GSMHard and MATH.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18607v1" target="_blank">Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents</a></h3>
                    <p><strong>Authors:</strong> Xinyuan Yan, Rita Sevastjanova, Sinie van der Ben, Mennatallah El-Assady, Bei Wang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CG, cs.LG</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) produce high-dimensional embeddings that capture rich semantic and syntactic relationships between words, sentences, and concepts. Investigating the topological structures of LLM embedding spaces via mapper graphs enables us to understand their underlying structures. Specifically, a mapper graph summarizes the topological structure of the embedding space, where each node represents a topological neighborhood (containing a cluster of embeddings), and an edge connects two nodes if their corresponding neighborhoods overlap. However, manually exploring these embedding spaces to uncover encoded linguistic properties requires considerable human effort. To address this challenge, we introduce a framework for semi-automatic annotation of these embedding properties. To organize the exploration process, we first define a taxonomy of explorable elements within a mapper graph such as nodes, edges, paths, components, and trajectories. The annotation of these elements is executed through two types of customizable LLM-based agents that employ perturbation techniques for scalable and automated analysis. These agents help to explore and explain the characteristics of mapper elements and verify the robustness of the generated explanations. We instantiate the framework within a visual analytics workspace and demonstrate its effectiveness through case studies. In particular, we replicate findings from prior research on BERTs embedding properties across various layers of its architecture and provide further observations into the linguistic properties of topological neighborhoods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18603v1" target="_blank">Demystify Protein Generation with Hierarchical Conditional Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Zinan Ling, Yi Shi, Da Yan, Yang Zhou, Bo Hui</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Generating novel and functional protein sequences is critical to a wide range of applications in biology. Recent advancements in conditional diffusion models have shown impressive empirical performance in protein generation tasks. However, reliable generations of protein remain an open research question in de novo protein design, especially when it comes to conditional diffusion models. Considering the biological function of a protein is determined by multi-level structures, we propose a novel multi-level conditional diffusion model that integrates both sequence-based and structure-based information for efficient end-to-end protein design guided by specified functions. By generating representations at different levels simultaneously, our framework can effectively model the inherent hierarchical relations between different levels, resulting in an informative and discriminative representation of the generated protein. We also propose a Protein-MMD, a new reliable evaluation metric, to evaluate the quality of generated protein with conditional diffusion models. Our new metric is able to capture both distributional and functional similarities between real and generated protein sequences while ensuring conditional consistency. We experiment with the benchmark datasets, and the results on conditional protein generation tasks demonstrate the efficacy of the proposed generation framework and evaluation metric.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18602v1" target="_blank">Open problems in ageing science: A roadmap for biogerontology</a></h3>
                    <p><strong>Authors:</strong> Angelo Talay, Aleksey V. Belikov, Paul Ka Po To, Hamid H. Alfatemi, Uri Alon, Joris Deelen, Collin Y. Ewald, David Gems, Vera Gorbunova, Jan Gruber, Sara HÃ¤gg, John Hemming, Steve Horvath, Alaattin Kaya, Caitlin J. Lewis, Andrea Maier, Maria B Marinova, Graham Pawelec, Shahaf Peleg, Suresh Rattan, Morten Scheibye-Knudsen, Tomas Schmauck-Medina, Vardan Saroyan, Andrei Seluanov, Alexandra Stolzing, Emma Teeling, Robert W. Williams, Todd White, Maximilian Unfried, JoÃ£o Pedro de MagalhÃ£es</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> q-bio.OT</p>
                    <p><strong>Summary:</strong> The field of ageing science has gone through remarkable progress in recent decades, yet many fundamental questions remain unanswered or unexplored. Here we present a curated list of 100 open problems in ageing and longevity science. These questions were collected through community engagement and further analysed using Natural Language Processing to assess their prevalence in the literature and to identify both well-established and emerging research gaps. The final list is categorized into different topics, including molecular and cellular mechanisms of ageing, comparative biology and the use of model organisms, biomarkers, and the development of therapeutic interventions. Both long-standing questions and more recent and specific questions are featured. Our comprehensive compilation is available to the biogerontology community on our website (www.longevityknowledge.app). Overall, this work highlights current key research questions in ageing biology and offers a roadmap for fostering future progress in biogerontology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18599v1" target="_blank">Laser micromachining of arbitrarily complex and overhang-free SiN nanomechanical resonators</a></h3>
                    <p><strong>Authors:</strong> Yahya Saleh, Zachary Louis-Seize, Timothy Hodges, David Girard, Mohammed Shakir, Mathis Turgeon-Roy, Francis Doyon-DAmour, Chang Zhang, Arnaud Weck, Raphael St-Gelais</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> physics.optics, physics.app-ph</p>
                    <p><strong>Summary:</strong> Research on silicon nitride (SiN) nanomechanical resonators produces an exceptionally rich variety of resonator geometries, for which there is currently no available rapid prototyping solution. Experimental advances in nanobeam, trampoline, phononic bandgap, and soft-clamping structures all rely on conventional nanofabrication involving e-beam or photolithography, followed by various etching steps. These techniques are typically time-consuming, relatively inflexible, and often result in spurious residual SiN overhang that can degrade mechanical quality factors. In contrast, recent work has shown that simple resonant structures, such as nanobeams, can be prototyped by direct laser ablation of free-standing SiN membranes using a spatially distributed sequence of microholes that limits stress concentration. However, these early demonstrations were restricted to basic shapes, created by manually combining ablation routines for circles and straight lines. Here, we demonstrate the fabrication of arbitrarily complex geometries using an open-source software toolset--released with this publication--that automatically generates laser-ablated hole sequences directly from standard semiconductor layout files (i.e., GDSII). The software includes a layout alignment tool that compensates for the membrane orientation and dimensional variations, limiting material overhang to ~2 um. Using this toolset, we fabricate several resonator geometries, each in under 1 hour, two of which are exhaustively characterized as candidate structures for high-performance radiation sensing. The measured quality factors of these structures closely match finite element simulations and reach values up to 3.7 x 10^6. From these measurements, we extract material quality factors above 3700, which is on par with low-stress SiN unablated plain membranes and with comparable structures produced using conventional fabrication methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18576v1" target="_blank">SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law</a></h3>
                    <p><strong>Authors:</strong> Shanghai AI Lab, :, Yicheng Bao, Guanxu Chen, Mingkang Chen, Yunhao Chen, Chiyu Chen, Lingjie Chen, Sirui Chen, Xinquan Chen, Jie Cheng, Yu Cheng, Dengke Deng, Yizhuo Ding, Dan Ding, Xiaoshan Ding, Yi Ding, Zhichen Dong, Lingxiao Du, Yuyu Fan, Xinshun Feng, Yanwei Fu, Yuxuan Gao, Ruijun Ge, Tianle Gu, Lujun Gui, Jiaxuan Guo, Qianxi He, Yuenan Hou, Xuhao Hu, Hong Huang, Kaichen Huang, Shiyang Huang, Yuxian Jiang, Shanzhe Lei, Jie Li, Lijun Li, Hao Li, Juncheng Li, Xiangtian Li, Yafu Li, Lingyu Li, Xueyan Li, Haotian Liang, Dongrui Liu, Qihua Liu, Zhixuan Liu, Bangwei Liu, Huacan Liu, Yuexiao Liu, Zongkai Liu, Chaochao Lu, Yudong Lu, Xiaoya Lu, Zhenghao Lu, Qitan Lv, Caoyuan Ma, Jiachen Ma, Xiaoya Ma, Zhongtian Ma, Lingyu Meng, Ziqi Miao, Yazhe Niu, Yuezhang Peng, Yuan Pu, Han Qi, Chen Qian, Xingge Qiao, Jingjing Qu, Jiashu Qu, Wanying Qu, Wenwen Qu, Xiaoye Qu, Qihan Ren, Qingnan Ren, Qingyu Ren, Jing Shao, Wenqi Shao, Shuai Shao, Dongxing Shi, Xin Song, Xinhao Song, Yan Teng, Xuan Tong, Yingchun Wang, Xuhong Wang, Shujie Wang, Xin Wang, Yige Wang, Yixu Wang, Yuanfu Wang, Futing Wang, Ruofan Wang, Wenjie Wang, Yajie Wang, Muhao Wei, Xiaoyu Wen, Fenghua Weng, Yuqi Wu, Yingtong Xiong, Xingcheng Xu, Chao Yang, Yue Yang, Yang Yao, Yulei Ye, Zhenyun Yin, Yi Yu, Bo Zhang, Qiaosheng Zhang, Jinxuan Zhang, Yexin Zhang, Yinqiang Zheng, Hefeng Zhou, Zhanhui Zhou, Pengyu Zhu, Qingzi Zhu, Yubo Zhu, Bowen Zhou</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CV</p>
                    <p><strong>Summary:</strong> We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746059.3747769" target="_blank">PosterMate: Audience-driven Collaborative Persona Agents for Poster Design</a></h3>
                    <p><strong>Authors:</strong> Donghoon Shin, Daniel Lee, Gary Hsieh, Gromit Yeuk-Yin Chan</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CL, H.5.2; I.2.7</p>
                    <p><strong>Summary:</strong> Poster designing can benefit from synchronous feedback from target audiences. However, gathering audiences with diverse perspectives and reconciling them on design edits can be challenging. Recent generative AI models present opportunities to simulate human-like interactions, but it is unclear how they may be used for feedback processes in design. We introduce PosterMate, a poster design assistant that facilitates collaboration by creating audience-driven persona agents constructed from marketing documents. PosterMate gathers feedback from each persona agent regarding poster components, and stimulates discussion with the help of a moderator to reach a conclusion. These agreed-upon edits can then be directly integrated into the poster design. Through our user study (N=12), we identified the potential of PosterMate to capture overlooked viewpoints, while serving as an effective prototyping tool. Additionally, our controlled online evaluation (N=100) revealed that the feedback from an individual persona agent is appropriate given its persona identity, and the discussion effectively synthesizes the different persona agents perspectives.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18570v1" target="_blank">Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods</a></h3>
                    <p><strong>Authors:</strong> Ganesh Sapkota, Md Hasibur Rahman</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper presents a novel hybrid tokenization strategy that enhances the performance of DNA Language Models (DLMs) by combining 6-mer tokenization with Byte Pair Encoding (BPE-600). Traditional k-mer tokenization is effective at capturing local DNA sequence structures but often faces challenges, including uneven token distribution and a limited understanding of global sequence context. To address these limitations, we propose merging unique 6mer tokens with optimally selected BPE tokens generated through 600 BPE cycles. This hybrid approach ensures a balanced and context-aware vocabulary, enabling the model to capture both short and long patterns within DNA sequences simultaneously. A foundational DLM trained on this hybrid vocabulary was evaluated using next-k-mer prediction as a fine-tuning task, demonstrating significantly improved performance. The model achieved prediction accuracies of 10.78% for 3-mers, 10.1% for 4-mers, and 4.12% for 5-mers, outperforming state-of-the-art models such as NT, DNABERT2, and GROVER. These results highlight the ability of the hybrid tokenization strategy to preserve both the local sequence structure and global contextual information in DNA modeling. This work underscores the importance of advanced tokenization methods in genomic language modeling and lays a robust foundation for future applications in downstream DNA sequence analysis and biological research.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.4204/EPTCS.423" target="_blank">Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications</a></h3>
                    <p><strong>Authors:</strong> Ruben Gamboa, Panagiotis Manolios</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI</p>
                    <p><strong>Summary:</strong> The ACL2 Workshop series is the major technical forum for users of the ACL2 theorem proving system to present research related to the ACL2 theorem prover and its applications. ACL2 is an industrial-strength automated reasoning system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM Software System Award was awarded to Boyer, Kaufmann, and Moore for their work on ACL2 and the other theorem provers in the Boyer-Moore family.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18565v1" target="_blank">Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement</a></h3>
                    <p><strong>Authors:</strong> Muhammad Imran Zaman, Nisar Ahmed</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper presents a novel deep learning-based approach for simultaneous age and gender classification from facial images, designed to enhance the effectiveness of targeted advertising campaigns. We propose a custom Convolutional Neural Network (CNN) architecture, optimized for both tasks, which leverages the inherent correlation between age and gender information present in facial features. Unlike existing methods that often treat these tasks independently, our model learns shared representations, leading to improved performance. The network is trained on a large, diverse dataset of facial images, carefully pre-processed to ensure robustness against variations in lighting, pose, and image quality. Our experimental results demonstrate a significant improvement in gender classification accuracy, achieving 95%, and a competitive mean absolute error of 5.77 years for age estimation. Critically, we analyze the performance across different age groups, identifying specific challenges in accurately estimating the age of younger individuals. This analysis reveals the need for targeted data augmentation and model refinement to address these biases. Furthermore, we explore the impact of different CNN architectures and hyperparameter settings on the overall performance, providing valuable insights for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18561v1" target="_blank">Beyond Internal Data: Constructing Complete Datasets for Fairness Testing</a></h3>
                    <p><strong>Authors:</strong> Varsha Ramineni, Hossein A. Rahmani, Emine Yilmaz, David Barber</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, stat.ML</p>
                    <p><strong>Summary:</strong> As AI becomes prevalent in high-risk domains and decision-making, it is essential to test for potential harms and biases. This urgency is reflected by the global emergence of AI regulations that emphasise fairness and adequate testing, with some mandating independent bias audits. However, procuring the necessary data for fairness testing remains a significant challenge. Particularly in industry settings, legal and privacy concerns restrict the collection of demographic data required to assess group disparities, and auditors face practical and cultural challenges in gaining access to data. Further, internal historical datasets are often insufficiently representative to identify real-world biases. This work focuses on evaluating classifier fairness when complete datasets including demographics are inaccessible. We propose leveraging separate overlapping datasets to construct complete synthetic data that includes demographic information and accurately reflects the underlying relationships between protected attributes and model features. We validate the fidelity of the synthetic data by comparing it to real data, and empirically demonstrate that fairness metrics derived from testing on such synthetic data are consistent with those obtained from real data. This work, therefore, offers a path to overcome real-world data scarcity for fairness testing, enabling independent, model-agnostic evaluation of fairness, and serving as a viable substitute where real data is limited.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18558v1" target="_blank">Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation</a></h3>
                    <p><strong>Authors:</strong> Yihong Feng, Chaitanya Pallerla, Xiaomin Lin, Pouya Sohrabipour Sr, Philip Crandall, Wan Shou, Yu She, Dongyi Wang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> The poultry industry has been driven by broiler chicken production and has grown into the worlds largest animal protein sector. Automated detection of chicken carcasses on processing lines is vital for quality control, food safety, and operational efficiency in slaughterhouses and poultry processing plants. However, developing robust deep learning models for tasks like instance segmentation in these fast-paced industrial environments is often hampered by the need for laborious acquisition and annotation of large-scale real-world image datasets. We present the first pipeline generating photo-realistic, automatically labeled synthetic images of chicken carcasses. We also introduce a new benchmark dataset containing 300 annotated real-world images, curated specifically for poultry segmentation research. Using these datasets, this study investigates the efficacy of synthetic data and automatic data annotation to enhance the instance segmentation of chicken carcasses, particularly when real annotated data from the processing line is scarce. A small real dataset with varying proportions of synthetic images was evaluated in prominent instance segmentation models. Results show that synthetic data significantly boosts segmentation performance for chicken carcasses across all models. This research underscores the value of synthetic data augmentation as a viable and effective strategy to mitigate data scarcity, reduce manual annotation efforts, and advance the development of robust AI-driven automated detection systems for chicken carcasses in the poultry processing industry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18557v1" target="_blank">Deep Learning for Blood-Brain Barrier Permeability Prediction</a></h3>
                    <p><strong>Authors:</strong> Zihan Yang, Haipeng Gong</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> q-bio.QM</p>
                    <p><strong>Summary:</strong> Predicting whether a molecule can cross the blood-brain barrier (BBB) is a key step in early-stage neuropharmaceutical development, directly influencing both research efficiency and success rates in drug discovery. Traditional empirical methods based on physicochemical properties are prone to systematic misjudgements due to their reliance on static rules. Early machine learning models, although data-driven, often suffer from limited capacity, poor generalization, and insufficient interpretability. In recent years, artificial intelligence (AI) methods have become essential tools for predicting BBB permeability and guiding related drug design, owing to their ability to model molecular structures and capture complex biological mechanisms. This article systematically reviews the evolution of this field-from deep neural networks to graph-based structural modeling-highlighting the advantages of multi-task and multimodal learning strategies in identifying mechanism-relevant variables. We further explore the emerging potential of generative models and causal inference methods for integrating permeability prediction with mechanism-aware drug design. BBB modeling is in the transition from static classification toward mechanistic perception and structure-function modeling. This paradigm shift provides a methodological foundation and future roadmap for the integration of AI into neuropharmacological development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18550v1" target="_blank">On the Performance of Concept Probing: The Influence of the Data (Extended Version)</a></h3>
                    <p><strong>Authors:</strong> Manuel de Sousa Ribeiro, Afonso Leote, JoÃ£o Leite</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV, cs.LG, cs.NE</p>
                    <p><strong>Summary:</strong> Concept probing has recently garnered increasing interest as a way to help interpret artificial neural networks, dealing both with their typically large size and their subsymbolic nature, which ultimately renders them unfeasible for direct human interpretation. Concept probing works by training additional classifiers to map the internal representations of a model into human-defined concepts of interest, thus allowing humans to peek inside artificial neural networks. Research on concept probing has mainly focused on the model being probed or the probing model itself, paying limited attention to the data required to train such probing models. In this paper, we address this gap. Focusing on concept probing in the context of image classification tasks, we investigate the effect of the data used to train probing models on their performance. We also make available concept labels for two widely used datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18545v1" target="_blank">The unreasonable likelihood of being: origin of life, terraforming, and AI</a></h3>
                    <p><strong>Authors:</strong> Robert G. Endres</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> q-bio.PE, q-bio.BM</p>
                    <p><strong>Summary:</strong> The origin of life on Earth via the spontaneous emergence of a protocell prior to Darwinian evolution remains a fundamental open question in physics and chemistry. Here, we develop a conceptual framework based on information theory and algorithmic complexity. Using estimates grounded in modern computational models, we evaluate the difficulty of assembling structured biological information under plausible prebiotic conditions. Our results highlight the formidable entropic and informational barriers to forming a viable protocell within the available window of Earths early history. While the idea of Earth being terraformed by advanced extraterrestrials might violate Occams razor from within mainstream science, directed panspermia -- originally proposed by Francis Crick and Leslie Orgel -- remains a speculative but logically open alternative. Ultimately, uncovering physical principles for lifes spontaneous emergence remains a grand challenge for biological physics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18538v1" target="_blank">AI/ML Life Cycle Management for Interoperable AI Native RAN</a></h3>
                    <p><strong>Authors:</strong> Chu-Hsiang Huang, Chao-Kai Wen, Geoffrey Ye Li</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.LG, math.IT</p>
                    <p><strong>Summary:</strong> Artificial intelligence (AI) and machine learning (ML) models are rapidly permeating the 5G Radio Access Network (RAN), powering beam management, channel state information (CSI) feedback, positioning, and mobility prediction. However, without a standardized life-cycle management (LCM) framework, challenges, such as model drift, vendor lock-in, and limited transparency, hinder large-scale adoption. 3GPP Releases 16-20 progressively evolve AI/ML from experimental features to managed, interoperable network functions. Beginning with the Network Data Analytics Function (NWDAF) in Rel-16, subsequent releases introduced standardized interfaces for model transfer, execution, performance monitoring, and closed-loop control, culminating in Rel-20s two-sided CSI-compression Work Item and vendor-agnostic LCM profile. This article reviews the resulting five-block LCM architecture, KPI-driven monitoring mechanisms, and inter-vendor collaboration schemes, while identifying open challenges in resource-efficient monitoring, environment drift detection, intelligent decision-making, and flexible model training. These developments lay the foundation for AI-native transceivers as a key enabler for 6G.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18525v1" target="_blank">Performance Study of the IceCube Upgrade Camera System</a></h3>
                    <p><strong>Authors:</strong> Carsten Rott, Minje Park, Matti Jansson, Garrett Iverson, Seowon Choi</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM, astro-ph.HE</p>
                    <p><strong>Summary:</strong> The IceCube Upgrade Camera System is a novel calibration system designed to calibrate the IceCube detector by measuring the optical properties of the Antarctic ice. The system comprises nearly 2,000 cameras and illumination LEDs, which are present on every D-Egg and mDOM, the newly designed optical modules for the IceCube Upgrade. These units, deployed across the IceCube Upgrade volume, will capture transmission and reflection images that can be used to characterize the optical properties of both the refrozen ice within drill holes and the bulk ice between strings. Additionally, the images can aid in determining the positions of the optical modules the camera systems are mounted on. To maximize the systems performance, various image analysis methodologies have been explored, ranging from classical maximum likelihood estimation to AI-based approaches using neural networks. In this study, we present preliminary results on the performance of these methods based on images generated by a simulation tool developed specifically for this system.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.13140/RG.2.2.26221.70880" target="_blank">The Moral Gap of Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Maciej Skorski, Alina Landowska</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CY, cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Moral foundation detection is crucial for analyzing social discourse and developing ethically-aligned AI systems. While large language models excel across diverse tasks, their performance on specialized moral reasoning remains unclear. This study provides the first comprehensive comparison between state-of-the-art LLMs and fine-tuned transformers across Twitter and Reddit datasets using ROC, PR, and DET curve analysis. Results reveal substantial performance gaps, with LLMs exhibiting high false negative rates and systematic under-detection of moral content despite prompt engineering efforts. These findings demonstrate that task-specific fine-tuning remains superior to prompting for moral reasoning applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18518v1" target="_blank">Transform Before You Query: A Privacy-Preserving Approach for Vector Retrieval with Embedding Space Alignment</a></h3>
                    <p><strong>Authors:</strong> Ruiqi He, Zekun Fei, Jiaqi Li, Xinyuan Zhu, Biao Yi, Siyi Lv, Weijie Liu, Zheli Liu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Vector Database (VDB) can efficiently index and search high-dimensional vector embeddings from unstructured data, crucially enabling fast semantic similarity search essential for modern AI applications like generative AI and recommendation systems. Since current VDB service providers predominantly use proprietary black-box models, users are forced to expose raw query text to them via API in exchange for the vector retrieval services. Consequently, if query text involves confidential records from finance or healthcare domains, this mechanism inevitably leads to critical leakage of users sensitive information. To address this issue, we introduce STEER (\textbf{S}ecure \textbf{T}ransformed \textbf{E}mbedding v\textbf{E}ctor\textbf{ R}etrieval), a private vector retrieval framework that leverages the alignment relationship between the semantic spaces of different embedding models to derive approximate embeddings for the query text. STEER performs the retrieval using the approximate embeddings within the original VDB and requires no modifications to the server side. Our theoretical and experimental analyses demonstrate that STEER effectively safeguards query text privacy while maintaining the retrieval accuracy. Even though approximate embeddings are approximations of the embeddings from proprietary models, they still prevent the providers from recovering the query text through Embedding Inversion Attacks (EIAs). Extensive experimental results show that Recall@100 of STEER can basically achieve a decrease of less than 5\%. Furthermore, even when searching within a text corpus of millions of entries, STEER achieves a Recall@20 accuracy 20\% higher than current baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18503v1" target="_blank">Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention</a></h3>
                    <p><strong>Authors:</strong> JoÃ£o Luzio, Alexandre Bernardino, Plinio Moreno</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In goal-directed visual tasks, human perception is guided by both top-down and bottom-up cues. At the same time, foveal vision plays a crucial role in directing attention efficiently. Modern research on bio-inspired computational attention models has taken advantage of advancements in deep learning by utilizing human scanpath data to achieve new state-of-the-art performance. In this work, we assess the performance of SemBA-FAST, i.e. Semantic-based Bayesian Attention for Foveal Active visual Search Tasks, a top-down framework designed for predicting human visual attention in target-present visual search. SemBA-FAST integrates deep object detection with a probabilistic semantic fusion mechanism to generate attention maps dynamically, leveraging pre-trained detectors and artificial foveation to update top-down knowledge and improve fixation prediction sequentially. We evaluate SemBA-FAST on the COCO-Search18 benchmark dataset, comparing its performance against other scanpath prediction models. Our methodology achieves fixation sequences that closely match human ground-truth scanpaths. Notably, it surpasses baseline and other top-down approaches and competes, in some cases, with scanpath-informed models. These findings provide valuable insights into the capabilities of semantic-foveal probabilistic frameworks for human-like attention modelling, with implications for real-time cognitive computing and robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18487v1" target="_blank">Low-power switching of memristors exhibiting fractional-order dynamics</a></h3>
                    <p><strong>Authors:</strong> Nathan Astin, Yuriy V. Pershin</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.ET, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> In this conference contribution, we present some initial results on switching memristive devices exhibiting fractional-order behavior using current pulses. In our model, it is assumed that the evolution of a state variable follows a fractional-order differential equation involving a Caputo-type derivative. A study of Joule losses demonstrates that the best switching strategy minimizing these losses depends on the fractional derivatives order and the power exponent in the equation of motion. It is found that when the order of the fractional derivative exceeds half of the power exponent, the best approach is to employ a wide pulse. Conversely, when this condition is not met, Joule losses are minimized by applying a zero current followed by a narrow current pulse of the highest allowable amplitude. These findings are explored further in the context of multi-pulse control. Our research lays the foundation for the advancement of the next generation of energy-efficient neuromorphic computing architectures that more closely mimic their biological counterparts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18484v1" target="_blank">Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments</a></h3>
                    <p><strong>Authors:</strong> Xiao Yang, Lingxuan Wu, Lizhong Wang, Chengyang Ying, Hang Su, Jun Zhu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Adversarial attacks in 3D environments have emerged as a critical threat to the reliability of visual perception systems, particularly in safety-sensitive applications such as identity verification and autonomous driving. These attacks employ adversarial patches and 3D objects to manipulate deep neural network (DNN) predictions by exploiting vulnerabilities within complex scenes. Existing defense mechanisms, such as adversarial training and purification, primarily employ passive strategies to enhance robustness. However, these approaches often rely on pre-defined assumptions about adversarial tactics, limiting their adaptability in dynamic 3D settings. To address these challenges, we introduce Reinforced Embodied Active Defense (Rein-EAD), a proactive defense framework that leverages adaptive exploration and interaction with the environment to improve perception robustness in 3D adversarial contexts. By implementing a multi-step objective that balances immediate prediction accuracy with predictive entropy minimization, Rein-EAD optimizes defense strategies over a multi-step horizon. Additionally, Rein-EAD involves an uncertainty-oriented reward-shaping mechanism that facilitates efficient policy updates, thereby reducing computational overhead and supporting real-world applicability without the need for differentiable environments. Comprehensive experiments validate the effectiveness of Rein-EAD, demonstrating a substantial reduction in attack success rates while preserving standard accuracy across diverse tasks. Notably, Rein-EAD exhibits robust generalization to unseen and adaptive attacks, making it suitable for real-world complex tasks, including 3D object classification, face recognition and autonomous driving.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.trip.2025.101507." target="_blank">Contested logistics: Resilience of strategic highways and railways</a></h3>
                    <p><strong>Authors:</strong> Sukhwan Chung, Daniel Sardak, Maksim Kitsak, Andrew Jin, Igor Linkov</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> physics.soc-ph</p>
                    <p><strong>Summary:</strong> Military logistics rely heavily on public infrastructure, such as highways and railways, to transport troops, equipment, and supplies, linking critical installations through the Department of Defenses Strategic Highway Network and Strategic Rail Corridor Network. However, these networks are vulnerable to disruptions that can jeopardize operational readiness, particularly in contested environments where adversaries employ non-traditional threats to disrupt logistics, even within the homeland. This paper presents a contested logistics model that utilizes network science and Geographic Information System (GIS) to evaluate the robustness and resilience of strategic transportation networks under various disruption scenarios. By integrating GIS data to model logistics networks, simulating disruptions, and quantifying their impacts, we identified vulnerabilities in US power projection routes and assessed the resilience and robustness of highways and railways. Our findings reveal that highways are more resilient than railways, with greater capacity to absorb targeted disruptions. These findings underscore the importance of prioritizing investments in highway infrastructure and reinforcing vulnerable road and rail segments, particularly in high-risk regions, to enhance the resilience of military logistics and maintain operational effectiveness in contested conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18457v1" target="_blank">Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols</a></h3>
                    <p><strong>Authors:</strong> Luo Cheng, Hanwei Zhang, Lijun Zhang, Holger Hermanns</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Adversarial robustness in LiDAR-based 3D object detection is a critical research area due to its widespread application in real-world scenarios. While many digital attacks manipulate point clouds or meshes, they often lack physical realizability, limiting their practical impact. Physical adversarial object attacks remain underexplored and suffer from poor reproducibility due to inconsistent setups and hardware differences. To address this, we propose a device-agnostic, standardized framework that abstracts key elements of physical adversarial object attacks, supports diverse methods, and provides open-source code with benchmarking protocols in simulation and real-world settings. Our framework enables fair comparison, accelerates research, and is validated by successfully transferring simulated attacks to a physical LiDAR system. Beyond the framework, we offer insights into factors influencing attack success and advance understanding of adversarial robustness in real-world LiDAR perception.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18455v1" target="_blank">LLM-based Embedders for Prior Case Retrieval</a></h3>
                    <p><strong>Authors:</strong> Damith Premasiri, Tharindu Ranasinghe, Ruslan Mitkov</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL</p>
                    <p><strong>Summary:</strong> In common law systems, legal professionals such as lawyers and judges rely on precedents to build their arguments. As the volume of cases has grown massively over time, effectively retrieving prior cases has become essential. Prior case retrieval (PCR) is an information retrieval (IR) task that aims to automatically identify the most relevant court cases for a specific query from a large pool of potential candidates. While IR methods have seen several paradigm shifts over the last few years, the vast majority of PCR methods continue to rely on traditional IR methods, such as BM25. The state-of-the-art deep learning IR methods have not been successful in PCR due to two key challenges: i. Lengthy legal text limitation; when using the powerful BERT-based transformer models, there is a limit of input text lengths, which inevitably requires to shorten the input via truncation or division with a loss of legal context information. ii. Lack of legal training data; due to data privacy concerns, available PCR datasets are often limited in size, making it difficult to train deep learning-based models effectively. In this research, we address these challenges by leveraging LLM-based text embedders in PCR. LLM-based embedders support longer input lengths, and since we use them in an unsupervised manner, they do not require training data, addressing both challenges simultaneously. In this paper, we evaluate state-of-the-art LLM-based text embedders in four PCR benchmark datasets and show that they outperform BM25 and supervised transformer-based models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18452v1" target="_blank">DIFFA: Large Language Diffusion Models Can Listen and Understand</a></h3>
                    <p><strong>Authors:</strong> Jiaming Zhou, Hongjie Chen, Shiwan Zhao, Jian Kang, Jie Li, Enzhi Wang, Yujie Guo, Haoqin Sun, Hui Wang, Aobo Kong, Yong Qin, Xuelong Li</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> Recent advances in Large language models (LLMs) have shown remarkable capabilities across textual and multimodal domains. In parallel, diffusion-based language models have emerged as a promising alternative to the autoregressive paradigm, offering improved controllability, bidirectional context modeling, and robust generation. However, their application to the audio modality remains underexplored. In this work, we introduce \textbf{DIFFA}, the first diffusion-based Large Audio-Language Model designed to perform spoken language understanding. DIFFA integrates a frozen diffusion language model with a lightweight dual-adapter architecture that bridges speech understanding and natural language reasoning. We employ a two-stage training pipeline: first, aligning semantic representations via an ASR objective; then, learning instruction-following abilities through synthetic audio-caption pairs automatically generated by prompting LLMs. Despite being trained on only 960 hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates competitive performance on major benchmarks, including MMSU, MMAU, and VoiceBench, outperforming several autoregressive open-source baselines. Our results reveal the potential of diffusion-based language models for efficient and scalable audio understanding, opening a new direction for speech-driven AI. Our code will be available at https://github.com/NKU-HLT/DIFFA.git.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18451v1" target="_blank">Generation of Synthetic Clinical Text: A Systematic Review</a></h3>
                    <p><strong>Authors:</strong> Basel Alshaikhdeeb, Ahmed Abdelmonem Hemedan, Soumyabrata Ghosh, Irina Balaur, Venkata Satagopam</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Generating clinical synthetic text represents an effective solution for common clinical NLP issues like sparsity and privacy. This paper aims to conduct a systematic review on generating synthetic medical free-text by formulating quantitative analysis to three research questions concerning (i) the purpose of generation, (ii) the techniques, and (iii) the evaluation methods. We searched PubMed, ScienceDirect, Web of Science, Scopus, IEEE, Google Scholar, and arXiv databases for publications associated with generating synthetic medical unstructured free-text. We have identified 94 relevant articles out of 1,398 collected ones. A great deal of attention has been given to the generation of synthetic medical text from 2018 onwards, where the main purpose of such a generation is towards text augmentation, assistive writing, corpus building, privacy-preserving, annotation, and usefulness. Transformer architectures were the main predominant technique used to generate the text, especially the GPTs. On the other hand, there were four main aspects of evaluation, including similarity, privacy, structure, and utility, where utility was the most frequent method used to assess the generated synthetic medical text. Although the generated synthetic medical text demonstrated a moderate possibility to act as real medical documents in different downstream NLP tasks, it has proven to be a great asset as augmented, complementary to the real documents, towards improving the accuracy and overcoming sparsity/undersampling issues. Yet, privacy is still a major issue behind generating synthetic medical text, where more human assessments are needed to check for the existence of any sensitive information. Despite that, advances in generating synthetic medical text will considerably accelerate the adoption of workflows and pipeline development, discarding the time-consuming legalities of data transfer.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18448v1" target="_blank">Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language</a></h3>
                    <p><strong>Authors:</strong> Md Obyedullahil Mamun, Md Adyelullahil Mamun, Arif Ahmad, Md. Imran Hossain Emu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG, I.2; I.7</p>
                    <p><strong>Summary:</strong> Punctuation restoration enhances the readability of text and is critical for post-processing tasks in Automatic Speech Recognition (ASR), especially for low-resource languages like Bangla. In this study, we explore the application of transformer-based models, specifically XLM-RoBERTa-large, to automatically restore punctuation in unpunctuated Bangla text. We focus on predicting four punctuation marks: period, comma, question mark, and exclamation mark across diverse text domains. To address the scarcity of annotated resources, we constructed a large, varied training corpus and applied data augmentation techniques. Our best-performing model, trained with an augmentation factor of alpha = 0.20%, achieves an accuracy of 97.1% on the News test set, 91.2% on the Reference set, and 90.2% on the ASR set. Results show strong generalization to reference and ASR transcripts, demonstrating the models effectiveness in real-world, noisy scenarios. This work establishes a strong baseline for Bangla punctuation restoration and contributes publicly available datasets and code to support future research in low-resource NLP.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18447v1" target="_blank">PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior</a></h3>
                    <p><strong>Authors:</strong> Junda Wu, Jessica Echterhoff, Kyungtae Han, Amr Abdelraouf, Rohit Gupta, Julian McAuley</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Understanding a drivers behavior and intentions is important for potential risk assessment and early accident prevention. Safety and driver assistance systems can be tailored to individual drivers behavior, significantly enhancing their effectiveness. However, existing datasets are limited in describing and explaining general vehicle movements based on external visual evidence. This paper introduces a benchmark, PDB-Eval, for a detailed understanding of Personalized Driver Behavior, and aligning Large Multimodal Models (MLLMs) with driving comprehension and reasoning. Our benchmark consists of two main components, PDB-X and PDB-QA. PDB-X can evaluate MLLMs understanding of temporal driving scenes. Our dataset is designed to find valid visual evidence from the external view to explain the drivers behavior from the internal view. To align MLLMs reasoning abilities with driving tasks, we propose PDB-QA as a visual explanation question-answering task for MLLM instruction fine-tuning. As a generic learning task for generative models like MLLMs, PDB-QA can bridge the domain gap without harming MLLMs generalizability. Our evaluation indicates that fine-tuning MLLMs on fine-grained descriptions and explanations can effectively bridge the gap between MLLMs and the driving domain, which improves zero-shot performance on question-answering tasks by up to 73.2%. We further evaluate the MLLMs fine-tuned on PDB-X in Brain4Cars intention prediction and AIDEs recognition tasks. We observe up to 12.5% performance improvements on the turn intention prediction task in Brain4Cars, and consistent performance improvements up to 11.0% on all tasks in AIDE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18442v1" target="_blank">AraTable: Benchmarking LLMs Reasoning and Understanding of Arabic Tabular Data</a></h3>
                    <p><strong>Authors:</strong> Rana Alshaikh, Israa Alghanmi, Shelan Jeawak</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The cognitive and reasoning abilities of large language models (LLMs) have enabled remarkable progress in natural language processing. However, their performance in interpreting structured data, especially in tabular formats, remains limited. Although benchmarks for English tabular data are widely available, Arabic is still underrepresented because of the limited availability of public resources and its unique language features. To address this gap, we present AraTable, a novel and comprehensive benchmark designed to evaluate the reasoning and understanding capabilities of LLMs when applied to Arabic tabular data. AraTable consists of various evaluation tasks, such as direct question answering, fact verification, and complex reasoning, involving a wide range of Arabic tabular sources. Our methodology follows a hybrid pipeline, where initial content is generated by LLMs and subsequently filtered and verified by human experts to ensure high dataset quality. Initial analyses using AraTable show that, while LLMs perform adequately on simpler tabular tasks such as direct question answering, they continue to face significant cognitive challenges when tasks require deeper reasoning and fact verification. This indicates that there are substantial opportunities for future work to improve performance on complex tabular reasoning tasks. We also propose a fully automated evaluation framework that uses a self-deliberation mechanism and achieves performance nearly identical to that of human judges. This research provides a valuable, publicly available resource and evaluation framework that can help accelerate the development of foundational models for processing and analysing Arabic structured data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18434v1" target="_blank">Guessing sequences of eigenvectors for LMPs defining spectrahedral relaxations of Eulerian rigidly convex sets</a></h3>
                    <p><strong>Authors:</strong> Alejandro GonzÃ¡lez Nevado</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> math.CO, cs.NA, math.NA, math.OC, 05A05, 05A15, 05A20 (Primary), 06A07, 65H04, 41A10, 41A45, 41A60,
  90C23 (Secondary), G.2.1; G.1.2; G.1.3; G.1.5; G.1.6</p>
                    <p><strong>Summary:</strong> Stable multivariate Eulerian polynomials were introduced by Br\and\en. Particularizing some variables, it is possible to extract real zero multivariate Eulerian polynomials from them. These real zero multivariate Eulerian polynomials can be fed into constructions of spectrahedral relaxations providing therefore approximations to the (Eulerian) rigidly convex sets defined by these polynomials. The accuracy of these approximations is measured through the behaviour in the diagonal, where the usual univariate Eulerian polynomials sit. In particular, in this sense, the accuracy of the global spectrahedral approximation produced by the spectrahedral relaxation can be measured in terms of bounds for the extreme roots of univariate Eulerian polynomials. The bounds thus obtained beat the previous bounds found in the literature. However, the bound explicitly studied and obtained before beat the previously known bounds by a quantity going to $0$ when $n$ goes to infinity. Here we use numerical experiments to construct a sequence of vectors providing a (linearized) bound whose difference with the previous known bounds is a growing exponential function (going therefore fast to infinity when $n$ grows). This allows us to establish a better (diagonal) measure of accuracy for the spectrahedral relaxation of the Eulerian rigidly convex sets. In particular, we will achieve this by linearizing through the sequence of vectors $\{(y,(-2^{m-i})_{i=3}^{m},(0,\frac{1}{2}),(1)_{i=1}^{m})\in\mathbb{R}^{n+1}\}_{n=1}^{\infty}$ for even $n=2m$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18428v1" target="_blank">Towards Understanding Decision Problems As a Goal of Visualization Design</a></h3>
                    <p><strong>Authors:</strong> Lena Cibulski, Stefan Bruckner</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Decision-making is a central yet under-defined goal in visualization research. While existing task models address decision processes, they often neglect the conditions framing a decision. To better support decision-making tasks, we propose a characterization scheme that describes decision problems through key properties of the data, users, and task context. This scheme helps visualization researchers specify decision-support claims more precisely and informs the design of appropriate visual encodings and interactions. We demonstrate the utility of our approach by applying it to characterize decision tasks targeted by existing design studies, highlighting opportunities for future research in decision-centric visualization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18417v1" target="_blank">FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs</a></h3>
                    <p><strong>Authors:</strong> Giorgos Iacovides, Wuyang Zhou, Danilo Mandic</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG, q-fin.ST, q-fin.TR</p>
                    <p><strong>Summary:</strong> Opinions expressed in online finance-related textual data are having an increasingly profound impact on trading decisions and market movements. This trend highlights the vital role of sentiment analysis as a tool for quantifying the nature and strength of such opinions. With the rapid development of Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs) have become the de facto standard for financial sentiment analysis. However, the SFT paradigm can lead to memorization of the training data and often fails to generalize to unseen samples. This is a critical limitation in financial domains, where models must adapt to previously unobserved events and the nuanced, domain-specific language of finance. To this end, we introduce FinDPO, the first finance-specific LLM framework based on post-training human preference alignment via Direct Preference Optimization (DPO). The proposed FinDPO achieves state-of-the-art performance on standard sentiment classification benchmarks, outperforming existing supervised fine-tuned models by 11% on the average. Uniquely, the FinDPO framework enables the integration of a fine-tuned causal LLM into realistic portfolio strategies through a novel logit-to-score conversion, which transforms discrete sentiment predictions into continuous, rankable sentiment scores (probabilities). In this way, simulations demonstrate that FinDPO is the first sentiment-based approach to maintain substantial positive returns of 67% annually and strong risk-adjusted performance, as indicated by a Sharpe ratio of 2.0, even under realistic transaction costs of 5 basis points (bps).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18408v1" target="_blank">Quasicrystalline Altermagnetism</a></h3>
                    <p><strong>Authors:</strong> Rui Chen, Bin Zhou, Dong-Hui Xu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Altermagnets are a recently discovered class of magnetic materials that combine a collinear, zero-magnetization spin structure, characteristic of antiferromagnets, with spin-split electronic bands, a hallmark of ferromagnets. This unique behavior arises from the breaking of combined time-reversal and spatial symmetries (such as inversion or lattice translation), which are preserved in conventional antiferromagnets. To date, research has focused on altermagnetic phases in periodic crystals, where the order is linked to specific crystallographic rotation symmetries. In this work, we demonstrate that quasicrystals, which possess rotational symmetries forbidden in periodic lattices, can host exotic altermagnetic orders. Using symmetry analysis and self-consistent mean-field theory, we predict stable $g$-wave and $i$-wave altermagnetism in octagonal and dodecagonal quasicrystals, respectively. These novel phases are characterized by global $C_8T$ and $C_{12}T$ symmetries and manifest as unique anisotropic spin-splittings in their spectral functions and spin conductance, featuring characteristic eight- and twelve-fold nodal structures that serve as unambiguous experimental fingerprints. Our findings establish quasicrystals as a versatile platform for realizing unconventional altermagnetic orders beyond the constraints of crystallographic symmetry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18406v1" target="_blank">Factual Inconsistencies in Multilingual Wikipedia Tables</a></h3>
                    <p><strong>Authors:</strong> Silvia Cappa, Lingxiao Kong, Pille-Riin Peet, Fanfu Wei, Yuchen Zhou, Jan-Christoph Kalo</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.DB, cs.DL, cs.IR</p>
                    <p><strong>Summary:</strong> Wikipedia serves as a globally accessible knowledge source with content in over 300 languages. Despite covering the same topics, the different versions of Wikipedia are written and updated independently. This leads to factual inconsistencies that can impact the neutrality and reliability of the encyclopedia and AI systems, which often rely on Wikipedia as a main training source. This study investigates cross-lingual inconsistencies in Wikipedias structured content, with a focus on tabular data. We developed a methodology to collect, align, and analyze tables from Wikipedia multilingual articles, defining categories of inconsistency. We apply various quantitative and qualitative metrics to assess multilingual alignment using a sample dataset. These insights have implications for factual verification, multilingual knowledge interaction, and design for reliable AI systems leveraging Wikipedia content.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18405v1" target="_blank">Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows</a></h3>
                    <p><strong>Authors:</strong> Simin Huo, Ning Li</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> We introduce Iwin Transformer, a novel position-embedding-free hierarchical vision transformer, which can be fine-tuned directly from low to high resolution, through the collaboration of innovative interleaved window attention and depthwise separable convolution. This approach uses attention to connect distant tokens and applies convolution to link neighboring tokens, enabling global information exchange within a single module, overcoming Swin Transformers limitation of requiring two consecutive blocks to approximate global attention. Extensive experiments on visual benchmarks demonstrate that Iwin Transformer exhibits strong competitiveness in tasks such as image classification (87.4 top-1 accuracy on ImageNet-1K), semantic segmentation and video action recognition. We also validate the effectiveness of the core component in Iwin as a standalone module that can seamlessly replace the self-attention module in class-conditional image generation. The concepts and methods introduced by the Iwin Transformer have the potential to inspire future research, like Iwin 3D Attention in video generation. The code and models are available at https://github.com/cominder/Iwin-Transformer.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18401v1" target="_blank">Multisensory Integration and Sensory Substitution Across Vision, Audition, and Haptics: Answering the What, Which, and When in Study Protocols</a></h3>
                    <p><strong>Authors:</strong> Andrew Jeyathasan, Swati Banerjee</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC, q-bio.NC</p>
                    <p><strong>Summary:</strong> We experience the world through multiple senses that work together to create a cohesive perception, whether in daily life or immersive technologies. Understanding this multisensory integration (MSI) requires examining the interactions between sensory modalities, each with unique temporal dynamics and characteristics. While most research focuses on unimodal or bimodal cues, the integration of three or more modalities remains underexplored. MSI studies must account for factors like cross-modal correspondence, congruence, cognitive load, and stimulus timing, which become increasingly complex as modalities multiply. This article examines these key factors and how they can be applied to 8 design effective MSI study protocols.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18396v1" target="_blank">Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input</a></h3>
                    <p><strong>Authors:</strong> Yonghao Fu, Cheng Hu, Haokun Xiong, Zhangpeng Bao, Wenyuan Du, Edoardo Ghignone, Michele Magno, Lei Xie, Hongye Su</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> In vehicle trajectory tracking tasks, the simplest approach is the Pure Pursuit (PP) Control. However, this single-point preview tracking strategy fails to consider vehicle model constraints, compromising driving safety. Model Predictive Control (MPC) as a widely adopted control method, optimizes control actions by incorporating mechanistic models and physical constraints. While its control performance critically depends on the accuracy of vehicle modeling. Traditional vehicle modeling approaches face inherent trade-offs between capturing nonlinear dynamics and maintaining computational efficiency, often resulting in reduced control performance. To address these challenges, this paper proposes Residual Koopman Model Predictive Control (RKMPC) framework. This method uses two linear MPC architecture to calculate control inputs: a Linear Model Predictive Control (LMPC) computes the baseline control input based on the vehicle kinematic model, and a neural network-based RKMPC calculates the compensation input. The final control command is obtained by adding these two components. This design preserves the reliability and interpretability of traditional mechanistic model while achieving performance optimization through residual modeling. This method has been validated on the Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH racing car. Experimental results show that RKMPC requires only 20% of the training data needed by traditional Koopman Model Predictive Control (KMPC) while delivering superior tracking performance. Compared to traditional LMPC, RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by 8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The implementation code is available at: https://github.com/ZJU-DDRX/Residual Koopman.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18393v1" target="_blank">PALM: PAnoramic Learning Map Integrating Learning Analytics and Curriculum Map for Scalable Insights Across Courses</a></h3>
                    <p><strong>Authors:</strong> Mahiro Ozaki, Li Chen, Shotaro Naganuma, Valdemar Å vÃ¡benskÃ½, Fumiya Okubo, Atsushi Shimada</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY</p>
                    <p><strong>Summary:</strong> This study proposes and evaluates the PAnoramic Learning Map (PALM), a learning analytics (LA) dashboard designed to address the scalability challenges of LA by integrating curriculum-level information. Traditional LA research has predominantly focused on individual courses or learners and often lacks a framework that considers the relationships between courses and the long-term trajectory of learning. To bridge this gap, PALM was developed to integrate multilayered educational data into a curriculum map, enabling learners to intuitively understand their learning records and academic progression. We conducted a system evaluation to assess PALMs effectiveness in two key areas: (1) its impact on students awareness of their learning behaviors, and (2) its comparative performance against existing systems. The results indicate that PALM enhances learners awareness of study planning and reflection, particularly by improving perceived behavioral control through the visual presentation of individual learning histories and statistical trends, which clarify the links between learning actions and outcomes. Although PALM requires ongoing refinement as a system, it received significantly higher evaluations than existing systems in terms of visual appeal and usability. By serving as an information resource with previously inaccessible insights, PALM enhances self-regulated learning and engagement, representing a significant step beyond conventional LA toward a comprehensive and scalable approach.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18376v1" target="_blank">A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges</a></h3>
                    <p><strong>Authors:</strong> Xing Hua, Haodong Chen, Qianqian Duan, Danfeng Hong, Ruijiao Li, Huiliang Shang, Linghua Jiang, Haima Yang, Dawei Zhang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> With the global population growing and arable land resources becoming increasingly scarce,smart agriculture and precision agriculture have emerged as key directions for the future ofagricultural development.Artificial intelligence (AI) technologies, particularly deep learning models, have found widespread applications in areas such as crop monitoring and pest detection. As an emerging generative model, diffusion models have shown significant promise in tasks like agricultural image processing, data augmentation, and remote sensing. Compared to traditional generative adversarial networks (GANs), diffusion models offer superior training stability and generation quality, effectively addressing challenges such as limited agricultural data and imbalanced image samples. This paper reviews the latest advancements in the application of diffusion models in agriculture, focusing on their potential in crop pest and disease detection, remote sensing image enhancement, crop growth prediction, and agricultural resource management. Experimental results demonstrate that diffusion models significantly improve model accuracy and robustness in data augmentation, image generation, and denoising, especially in complex environments. Despite challenges related to computational efficiency and generalization capabilities, diffusion models are expected to play an increasingly important role in smart and precision agriculture as technology advances, providing substantial support for the sustainable development of global agriculture.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18375v1" target="_blank">Fagins Theorem for Semiring Turing Machines</a></h3>
                    <p><strong>Authors:</strong> Guillermo Badia, Manfred Droste, Thomas Eiter, Rafael Kiesel, Carles Noguera, Erik Paul</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CC, cs.LO</p>
                    <p><strong>Summary:</strong> In recent years, quantitative complexity over semirings has been intensively investigated. An important problem in this context is to connect computational complexity with logical expressiveness. In this paper we improve on the model of \emph{Semiring Turing Machines} (distinct from so called weighted Turing machines) introduced by Eiter \ Kiesel (Semiring Reasoning Frameworks in AI and Their Computational Complexity, \emph{J. Artif. Intell. Res.}, 2023). Our central result is a Fagin-style theorem for a new quantitative complexity class using a suitable weighted logical formalism. We show that the quantitative complexity class that we call \NPnewinf{$\mathcal{R}$}, where $\mathcal{R}$ is a commutative semiring, can be captured using a version of weighted existential second-order logic that allows for predicates interpreted as semiring-annotated relations. This result provides a precise logical characterization of the power series that form the class \NPnewinf{$\mathcal{R}$}. We also give the exact relation between Eiter \ Kiesels version of NP, called \NPoldinf{$\mathcal{R}$}, and the class \NPnewinf{$\mathcal{R}$}. Incidentally, we are able to recapture all the complexity results by Eiter \ Kiesel (2023) in our new model, connecting a quantitative version of NP to various counting complexity classes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18374v1" target="_blank">Towards Effective Human-in-the-Loop Assistive AI Agents</a></h3>
                    <p><strong>Authors:</strong> Filippos Bellos, Yayuan Li, Cary Shu, Ruey Day, Jeffrey M. Siskind, Jason J. Corso</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Effective human-AI collaboration for physical task completion has significant potential in both everyday activities and professional domains. AI agents equipped with informative guidance can enhance human performance, but evaluating such collaboration remains challenging due to the complexity of human-in-the-loop interactions. In this work, we introduce an evaluation framework and a multimodal dataset of human-AI interactions designed to assess how AI guidance affects procedural task performance, error reduction and learning outcomes. Besides, we develop an augmented reality (AR)-equipped AI agent that provides interactive guidance in real-world tasks, from cooking to battlefield medicine. Through human studies, we share empirical insights into AI-assisted human performance and demonstrate that AI-assisted collaboration improves task completion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18368v1" target="_blank">Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios</a></h3>
                    <p><strong>Authors:</strong> Zhuang Qiang Bok, Watson Wei Khong Chua</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.AI, I.2.0; I.2.6; J.4</p>
                    <p><strong>Summary:</strong> Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step logic. In finance, however, professionals must not only converge on optimal decisions but also generate creative, plausible futures under uncertainty. We introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent thinking in LLMs for financial tasks. ConDiFi features 607 macro-financial prompts for divergent reasoning and 990 multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we evaluated 14 leading models and uncovered striking differences. Despite high fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models like DeepSeek-R1 and Cohere Command R+ rank among the top for generating actionable, insights suitable for investment decisions. ConDiFi provides a new perspective to assess reasoning capabilities essential to safe and strategic deployment of LLMs in finance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18633v1" target="_blank">Identifying Prompted Artist Names from Generated Images</a></h3>
                    <p><strong>Authors:</strong> Grace Su, Sheng-Yu Wang, Aaron Hertzmann, Eli Shechtman, Jun-Yan Zhu, Richard Zhang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> A common and controversial use of text-to-image models is to generate pictures by explicitly naming artists, such as in the style of Greg Rutkowski. We introduce a benchmark for prompted-artist recognition: predicting which artist names were invoked in the prompt from the image alone. The dataset contains 1.95M images covering 110 artists and spans four generalization settings: held-out artists, increasing prompt complexity, multiple-artist prompts, and different text-to-image models. We evaluate feature similarity baselines, contrastive style descriptors, data attribution methods, supervised classifiers, and few-shot prototypical networks. Generalization patterns vary: supervised and few-shot models excel on seen artists and complex prompts, whereas style descriptors transfer better when the artists style is pronounced; multi-artist prompts remain the most challenging. Our benchmark reveals substantial headroom and provides a public testbed to advance the responsible moderation of text-to-image models. We release the dataset and benchmark to foster further research: https://graceduansu.github.io/IdentifyingPromptedArtists/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18632v1" target="_blank">SIDA: Synthetic Image Driven Zero-shot Domain Adaptation</a></h3>
                    <p><strong>Authors:</strong> Ye-Chan Kim, SeungJu Cha, Si-Woo Kim, Taewhan Kim, Dong-Jin Kim</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG, cs.MM</p>
                    <p><strong>Summary:</strong> Zero-shot domain adaptation is a method for adapting a model to a target domain without utilizing target domain image data. To enable adaptation without target images, existing studies utilize CLIPs embedding space and text description to simulate target-like style features. Despite the previous achievements in zero-shot domain adaptation, we observe that these text-driven methods struggle to capture complex real-world variations and significantly increase adaptation time due to their alignment process. Instead of relying on text descriptions, we explore solutions leveraging image data, which provides diverse and more fine-grained style cues. In this work, we propose SIDA, a novel and efficient zero-shot domain adaptation method leveraging synthetic images. To generate synthetic images, we first create detailed, source-like images and apply image translation to reflect the style of the target domain. We then utilize the style features of these synthetic images as a proxy for the target domain. Based on these features, we introduce Domain Mix and Patch Style Transfer modules, which enable effective modeling of real-world variations. In particular, Domain Mix blends multiple styles to expand the intra-domain representations, and Patch Style Transfer assigns different styles to individual patches. We demonstrate the effectiveness of our method by showing state-of-the-art performance in diverse zero-shot adaptation scenarios, particularly in challenging domains. Moreover, our approach achieves high efficiency by significantly reducing the overall adaptation time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18631v1" target="_blank">Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment</a></h3>
                    <p><strong>Authors:</strong> Hao Li, Lijun Li, Zhenghao Lu, Xianyi Wei, Rui Li, Jing Shao, Lei Sha</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> With rapid advancement and increasing accessibility of LLMs, fine-tuning aligned models has become a critical step for adapting them to real-world applications, which makes the safety of this fine-tuning process more important than ever. However, recent studies have highlighted a critical challenge: even when fine-tuning with seemingly benign downstream datasets, the safety of aligned LLMs can be compromised, making them more susceptible to malicious instructions. In this paper, we show that fine-tuning datasets often contain samples with safety-degrading features that are not easily identifiable on the surface. These samples can significantly degrade the safety alignment of LLMs during fine-tuning. To address this issue, we propose LARF, a \textbf{L}ayer-\textbf{A}ware \textbf{R}epresentation \textbf{F}iltering method. This method identifies safety-sensitive layers within the LLM and leverages their representations to detect which data samples in the post-training dataset contain safety-degrading features. Experimental results demonstrate that LARF can effectively identify benign data with safety-degrading features. After removing such data, the safety alignment degradation caused by fine-tuning is mitigated. Please see our code at \href{https://github.com/LLLeoLi/LARF}{https://github.com/LLLeoLi/LARF}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18634v1" target="_blank">Captain Cinema: Towards Short Movie Generation</a></h3>
                    <p><strong>Authors:</strong> Junfei Xiao, Ceyuan Yang, Lvmin Zhang, Shengqu Cai, Yang Zhao, Yuwei Guo, Gordon Wetzstein, Maneesh Agrawala, Alan Yuille, Lu Jiang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We present Captain Cinema, a generation framework for short movie generation. Given a detailed textual description of a movie storyline, our approach firstly generates a sequence of keyframes that outline the entire narrative, which ensures long-range coherence in both the storyline and visual appearance (e.g., scenes and characters). We refer to this step as top-down keyframe planning. These keyframes then serve as conditioning signals for a video synthesis model, which supports long context learning, to produce the spatio-temporal dynamics between them. This step is referred to as bottom-up video synthesis. To support stable and efficient generation of multi-scene long narrative cinematic works, we introduce an interleaved training strategy for Multimodal Diffusion Transformers (MM-DiT), specifically adapted for long-context video data. Our model is trained on a specially curated cinematic dataset consisting of interleaved data pairs. Our experiments demonstrate that Captain Cinema performs favorably in the automated creation of visually coherent and narrative consistent short movies in high quality and efficiency. Project page: https://thecinema.ai</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18633v1" target="_blank">Identifying Prompted Artist Names from Generated Images</a></h3>
                    <p><strong>Authors:</strong> Grace Su, Sheng-Yu Wang, Aaron Hertzmann, Eli Shechtman, Jun-Yan Zhu, Richard Zhang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> A common and controversial use of text-to-image models is to generate pictures by explicitly naming artists, such as in the style of Greg Rutkowski. We introduce a benchmark for prompted-artist recognition: predicting which artist names were invoked in the prompt from the image alone. The dataset contains 1.95M images covering 110 artists and spans four generalization settings: held-out artists, increasing prompt complexity, multiple-artist prompts, and different text-to-image models. We evaluate feature similarity baselines, contrastive style descriptors, data attribution methods, supervised classifiers, and few-shot prototypical networks. Generalization patterns vary: supervised and few-shot models excel on seen artists and complex prompts, whereas style descriptors transfer better when the artists style is pronounced; multi-artist prompts remain the most challenging. Our benchmark reveals substantial headroom and provides a public testbed to advance the responsible moderation of text-to-image models. We release the dataset and benchmark to foster further research: https://graceduansu.github.io/IdentifyingPromptedArtists/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18632v1" target="_blank">SIDA: Synthetic Image Driven Zero-shot Domain Adaptation</a></h3>
                    <p><strong>Authors:</strong> Ye-Chan Kim, SeungJu Cha, Si-Woo Kim, Taewhan Kim, Dong-Jin Kim</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG, cs.MM</p>
                    <p><strong>Summary:</strong> Zero-shot domain adaptation is a method for adapting a model to a target domain without utilizing target domain image data. To enable adaptation without target images, existing studies utilize CLIPs embedding space and text description to simulate target-like style features. Despite the previous achievements in zero-shot domain adaptation, we observe that these text-driven methods struggle to capture complex real-world variations and significantly increase adaptation time due to their alignment process. Instead of relying on text descriptions, we explore solutions leveraging image data, which provides diverse and more fine-grained style cues. In this work, we propose SIDA, a novel and efficient zero-shot domain adaptation method leveraging synthetic images. To generate synthetic images, we first create detailed, source-like images and apply image translation to reflect the style of the target domain. We then utilize the style features of these synthetic images as a proxy for the target domain. Based on these features, we introduce Domain Mix and Patch Style Transfer modules, which enable effective modeling of real-world variations. In particular, Domain Mix blends multiple styles to expand the intra-domain representations, and Patch Style Transfer assigns different styles to individual patches. We demonstrate the effectiveness of our method by showing state-of-the-art performance in diverse zero-shot adaptation scenarios, particularly in challenging domains. Moreover, our approach achieves high efficiency by significantly reducing the overall adaptation time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18628v1" target="_blank">Design and fabrication of ultrasound linear array transducer used in ultrasound endoscope</a></h3>
                    <p><strong>Authors:</strong> Yuan Zhang, Mingtong Chen, Zhengbao Yang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> physics.med-ph, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> This report details the successful construction of an ultrasound imaging platform and the design and fabrication of a novel ultrasound endoscope probe. The projects primary objective was to establish a functional system for acquiring and processing ultrasound signals, specifically targeting minimally invasive endoscopic applications. The ultrasound imaging platform was primarily designed and developed based on Texas Instruments (TI) Evaluation Modules (EVMs). It enables the transmission of 32-channel high-voltage signals and the reception of echo signals, with on-chip signal amplification and acquisition capabilities. Furthermore, the platform integrates a complete Time Gain Control (TGC) imaging path and a ContinuousWave Doppler (CWD) path. In conjunction with host computer software, it supports imaging with linear array, convex array, and phased array probes. Concurrently, a 64-element, 5MHz center frequency, phased array linear ultrasound endoscopic probe was designed, aiming for miniaturization and optimal imaging performance. The fabrication and assembly of its matching layer, backing layer, 2-2 piezoelectric composite material, and electrodes were completed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18626v1" target="_blank">Integrable spin chains in twisted maximally supersymmetric Yang-Mills theory</a></h3>
                    <p><strong>Authors:</strong> Tim Meier, Stijn J. van Tongeren</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> We study an angular dipole deformation of maximally supersymmetric Yang-Mills theory (SYM) that preserves its classical scale invariance. We show that two-point functions of suitable single trace operators, restricted to an invariant plane, are determined by scaling dimensions computable from an integrable spin chain. This spin chain is a diagonally twisted version of the famous integrable spin chain of SYM. It matches expectations from the dual string theory perfectly, presenting a precision test of holography in this new setting, and an important step to understanding general twisted integrable AdS/CFT.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18625v1" target="_blank">3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation</a></h3>
                    <p><strong>Authors:</strong> Shuqing Li, Anson Y. Lam, Yun Peng, Wenxuan Wang, Michael R. Lyu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.MM, cs.SE</p>
                    <p><strong>Summary:</strong> Graphical user interface (UI) software has undergone a fundamental transformation from traditional two-dimensional (2D) desktop/web/mobile interfaces to spatial three-dimensional (3D) environments. While existing work has made remarkable success in automated 2D software generation, such as HTML/CSS and mobile app interface code synthesis, the generation of 3D software still remains under-explored. Current methods for 3D software generation usually generate the 3D environments as a whole and cannot modify or control specific elements in the software. Furthermore, these methods struggle to handle the complex spatial and semantic constraints inherent in the real world. To address the challenges, we present Scenethesis, a novel requirement-sensitive 3D software synthesis approach that maintains formal traceability between user specifications and generated 3D software. Scenethesis is built upon ScenethesisLang, a domain-specific language that serves as a granular constraint-aware intermediate representation (IR) to bridge natural language requirements and executable 3D software. It serves both as a comprehensive scene description language enabling fine-grained modification of 3D software elements and as a formal constraint-expressive specification language capable of expressing complex spatial constraints. By decomposing 3D software synthesis into stages operating on ScenethesisLang, Scenethesis enables independent verification, targeted modification, and systematic constraint satisfaction. Our evaluation demonstrates that Scenethesis accurately captures over 80% of user requirements and satisfies more than 90% of hard constraints while handling over 100 constraints simultaneously. Furthermore, Scenethesis achieves a 42.8% improvement in BLIP-2 visual evaluation scores compared to the state-of-the-art method.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18624v1" target="_blank">Checklists Are Better Than Reward Models For Aligning Language Models</a></h3>
                    <p><strong>Authors:</strong> Vijay Viswanathan, Yanchao Sun, Shuang Ma, Xiang Kong, Meng Cao, Graham Neubig, Tongshuang Wu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Language models must be adapted to understand and follow user instructions. Reinforcement learning is widely used to facilitate this -- typically using fixed criteria such as helpfulness and harmfulness. In our work, we instead propose using flexible, instruction-specific criteria as a means of broadening the impact that reinforcement learning can have in eliciting instruction following. We propose Reinforcement Learning from Checklist Feedback (RLCF). From instructions, we extract checklists and evaluate how well responses satisfy each item - using both AI judges and specialized verifier programs - then combine these scores to compute rewards for RL. We compare RLCF with other alignment methods applied to a strong instruction following model (Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only method to improve performance on every benchmark, including a 4-point boost in hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a 3-point rise in win rate on Arena-Hard. These results establish checklist feedback as a key tool for improving language models support of queries that express a multitude of needs.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3743049.3748566" target="_blank">Evaluation of a Provenance Management Tool for Immersive Virtual Fieldwork</a></h3>
                    <p><strong>Authors:</strong> Armin Bernstetter, Tom Kwasnitschka, Isabella Peters</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Ensuring reproducibility of research is an integral part of good scientific practice. One way to support this is through provenance: information about research workflows from data gathering to researchers sensemaking processes leading to published results. This is highly important in disciplines such as geosciences, where researchers use software for interactive and immersive visualizations of geospatial data, doing virtual measurements in simulated fieldwork on 3D models. We evaluated a provenance management tool, which allows recording of interactions with a virtual fieldwork tool and annotating different states of the visualization. The user study investigated how researchers used this Digital Lab Book (DLB) and whether perceived ease of use and perceived usefulness differed between groups in immersive or non-immersive settings. Participants perceived the DLB as both useful and easy to use. While there were indications of differences in perceived ease of use (higher for immersive setting), usage patterns showed no significant group differences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18618v1" target="_blank">TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards</a></h3>
                    <p><strong>Authors:</strong> Andreea Nica, Ivan Zakazov, Nicolas Mario Baldwin, Saibo Geng, Robert West</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Prompt optimization improves the reasoning abilities of large language models (LLMs) without requiring parameter updates to the target model. Following heuristic-based Think step by step approaches, the field has evolved in two main directions: while one group of methods uses textual feedback to elicit improved prompts from general-purpose LLMs in a training-free way, a concurrent line of research relies on numerical rewards to train a special prompt model, tailored for providing optimal prompts to the target model. In this paper, we introduce the Textual Reward Prompt framework (TRPrompt), which unifies these approaches by directly incorporating textual feedback into training of the prompt model. Our framework does not require prior dataset collection and is being iteratively improved with the feedback on the generated prompts. When coupled with the capacity of an LLM to internalize the notion of what a good prompt is, the high-resolution signal provided by the textual rewards allows us to train a prompt model yielding state-of-the-art query-specific prompts for the problems from the challenging math datasets GSMHard and MATH.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18617v1" target="_blank">Diffusion as a Signature of Chaos</a></h3>
                    <p><strong>Authors:</strong> Nachiket Karve, Nathan Rose, David Campbell</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> nlin.CD, cond-mat.stat-mech, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> While classical chaos is defined via a systems sensitive dependence on its initial conditions (SDIC), this notion does not directly extend to quantum systems. Instead, recent works have established defining both quantum and classical chaos via the sensitivity to adiabatic deformations and measuring this sensitivity using the adiabatic gauge potential (AGP). Building on this formalism, we introduce the ``observable drift as a probe of chaos in generic, non-Hamiltonian, classical systems. We show that this probe correctly characterizes classical systems that exhibit SDIC as chaotic. Moreover, this characterization is consistent with the measure-theoretic definition of chaos via weak mixing. Thus, we show that these two notions of sensitivity (to changes in initial conditions and to adiabatic deformations) can be probed using the same quantity, and therefore, are equivalent definitions of chaos. Numerical examples are provided via the tent map, the logistic map, and the Chirikov standard map.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18616v1" target="_blank">SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning</a></h3>
                    <p><strong>Authors:</strong> Si-Woo Kim, MinJu Jeon, Ye-Chan Kim, Soeun Lee, Taewhan Kim, Dong-Jin Kim</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Zero-shot Image Captioning (ZIC) increasingly utilizes synthetic datasets generated by text-to-image (T2I) models to mitigate the need for costly manual annotation. However, these T2I models often produce images that exhibit semantic misalignments with their corresponding input captions (e.g., missing objects, incorrect attributes), resulting in noisy synthetic image-caption pairs that can hinder model training. Existing dataset pruning techniques are largely designed for removing noisy text in web-crawled data. However, these methods are ill-suited for the distinct challenges of synthetic data, where captions are typically well-formed, but images may be inaccurate representations. To address this gap, we introduce SynC, a novel framework specifically designed to refine synthetic image-caption datasets for ZIC. Instead of conventional filtering or regeneration, SynC focuses on reassigning captions to the most semantically aligned images already present within the synthetic image pool. Our approach employs a one-to-many mapping strategy by initially retrieving multiple relevant candidate images for each caption. We then apply a cycle-consistency-inspired alignment scorer that selects the best image by verifying its ability to retrieve the original caption via image-to-text retrieval. Extensive evaluations demonstrate that SynC consistently and significantly improves performance across various ZIC models on standard benchmarks (MS-COCO, Flickr30k, NoCaps), achieving state-of-the-art results in several scenarios. SynC offers an effective strategy for curating refined synthetic data to enhance ZIC.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18612v1" target="_blank">Approximate SMT Counting Beyond Discrete Domains</a></h3>
                    <p><strong>Authors:</strong> Arijit Shaw, Kuldeep S. Meel</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI</p>
                    <p><strong>Summary:</strong> Satisfiability Modulo Theory (SMT) solvers have advanced automated reasoning, solving complex formulas across discrete and continuous domains. Recent progress in propositional model counting motivates extending SMT capabilities toward model counting, especially for hybrid SMT formulas. Existing approaches, like bit-blasting, are limited to discrete variables, highlighting the challenge of counting solutions projected onto the discrete domain in hybrid formulas. We introduce pact, an SMT model counter for hybrid formulas that uses hashing-based approximate model counting to estimate solutions with theoretical guarantees. pact makes a logarithmic number of SMT solver calls relative to the projection variables, leveraging optimized hash functions. pact achieves significant performance improvements over baselines on a large suite of benchmarks. In particular, out of 14,202 instances, pact successfully finished on 603 instances, while Baseline could only finish on 13 instances.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18611v1" target="_blank">Topological constraint on crystalline current</a></h3>
                    <p><strong>Authors:</strong> Tomohiro Soejima, Junkai Dong, Ophelia Evelyn Sommer, Daniel E. Parker, Ashvin Vishwanath</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> How much current does a sliding electron crystal carry? The answer to this simple question has important implications for the dynamic properties of the crystal, such as the frequency of its cyclotron motion, and its phonon spectrum. In this work we introduce a precise definition of a sliding crystal and compute the corresponding current $\mathbf{j}_c$ for topological electron crystals in the presence of magnetic field. Our result is fully non-perturbative, does not rely on Galilean invariance, and applies equally to Wigner crystals and (anomalous) Hall crystals. In terms of the electron density $\rho$ and magnetic flux density $\phi$, we find that $\mathbf{j}_c = e(\rho-C\phi)\mathbf{v}$. Surprisingly, the current receives a contribution from the many-body Chern number $C$ of the crystal. When $\rho = C\phi$, sliding crystals therefore carry zero current. The crystalline current fixes the Lorentz force felt by the sliding crystal and the dispersion of low-energy phonons of such crystals. This gives us a simple counting rule for the number of gapless phonons: if a sliding crystal carries nonzero current in a magnetic field, there is a single gapless mode, while otherwise there are two gapless modes. This result can also be understood from anomaly-matching of emanant discrete translation symmetries -- an idea that is also applicable to the dispersion of skyrmion crystals. Our results lead to novel experimental implications and invite further conceptual developments for electron crystals.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18607v1" target="_blank">Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents</a></h3>
                    <p><strong>Authors:</strong> Xinyuan Yan, Rita Sevastjanova, Sinie van der Ben, Mennatallah El-Assady, Bei Wang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CG, cs.LG</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) produce high-dimensional embeddings that capture rich semantic and syntactic relationships between words, sentences, and concepts. Investigating the topological structures of LLM embedding spaces via mapper graphs enables us to understand their underlying structures. Specifically, a mapper graph summarizes the topological structure of the embedding space, where each node represents a topological neighborhood (containing a cluster of embeddings), and an edge connects two nodes if their corresponding neighborhoods overlap. However, manually exploring these embedding spaces to uncover encoded linguistic properties requires considerable human effort. To address this challenge, we introduce a framework for semi-automatic annotation of these embedding properties. To organize the exploration process, we first define a taxonomy of explorable elements within a mapper graph such as nodes, edges, paths, components, and trajectories. The annotation of these elements is executed through two types of customizable LLM-based agents that employ perturbation techniques for scalable and automated analysis. These agents help to explore and explain the characteristics of mapper elements and verify the robustness of the generated explanations. We instantiate the framework within a visual analytics workspace and demonstrate its effectiveness through case studies. In particular, we replicate findings from prior research on BERTs embedding properties across various layers of its architecture and provide further observations into the linguistic properties of topological neighborhoods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18606v1" target="_blank">Hybrid quantum-classical algorithm for near-optimal planning in POMDPs</a></h3>
                    <p><strong>Authors:</strong> Gilberto Cunha, Alexandra RamÃ´a, AndrÃ© Sequeira, Michael de Oliveira, LuÃ­s Barbosa</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.LG</p>
                    <p><strong>Summary:</strong> Reinforcement learning (RL) provides a principled framework for decision-making in partially observable environments, which can be modeled as Markov decision processes and compactly represented through dynamic decision Bayesian networks. Recent advances demonstrate that inference on sparse Bayesian networks can be accelerated using quantum rejection sampling combined with amplitude amplification, leading to a computational speedup in estimating acceptance probabilities.\\ Building on this result, we introduce Quantum Bayesian Reinforcement Learning (QBRL), a hybrid quantum-classical look-ahead algorithm for model-based RL in partially observable environments. We present a rigorous, oracle-free time complexity analysis under fault-tolerant assumptions for the quantum device. Unlike standard treatments that assume a black-box oracle, we explicitly specify the inference process, allowing our bounds to more accurately reflect the true computational cost. We show that, for environments whose dynamics form a sparse Bayesian network, horizon-based near-optimal planning can be achieved sub-quadratically faster through quantum-enhanced belief updates. Furthermore, we present numerical experiments benchmarking QBRL against its classical counterpart on simple yet illustrative decision-making tasks. Our results offer a detailed analysis of how the quantum computational advantage translates into decision-making performance, highlighting that the magnitude of the advantage can vary significantly across different deployment settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18605v1" target="_blank">Graviton scattering on self-dual black holes</a></h3>
                    <p><strong>Authors:</strong> Tim Adamo, Giuseppe Bogna, Lionel Mason, Atul Sharma</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> The computation of gravitational wave scattering on black hole spacetimes is an extremely hard problem, typically requiring approximation schemes which either treat the black hole perturbatively or are only amenable to numerical techniques. In this paper, we consider linearised gravitational waves (or gravitons) scattering on the self-dual analogue of a black hole: namely, the self-dual Taub-NUT metric. Using the hidden integrability of the self-dual sector, we can solve the linearised Einstein equations on these self-dual black hole backgrounds exactly in terms of simple, explicit quasi-momentum eigenstates. Using a description of the self-dual Taub-NUT metric and its gravitons in terms of twistor theory, we obtain an explicit formula, exact in the background, for the tree-level maximal helicity violating graviton scattering amplitude at arbitrary multiplicity, with and without spin. This is obtained from the description of the MHV amplitudes in terms of the perturbation theory of a chiral sigma model whose target is the twistor space of the background. The incorporation of spin effects on these backgrounds is a straightforward application of the Newman-Janis shift. We also demonstrate that the holomorphic collinear splitting functions in the self-dual background are equal to those in flat space so that the celestial symmetry algebra is undeformed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18597v1" target="_blank">Linear Memory SE(2) Invariant Attention</a></h3>
                    <p><strong>Authors:</strong> Ethan Pronovost, Neha Boloor, Peter Schleede, Noureldin Hendy, Andres Morales, Nicholas Roy</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Processing spatial data is a key component in many learning tasks for autonomous driving such as motion forecasting, multi-agent simulation, and planning. Prior works have demonstrated the value in using SE(2) invariant network architectures that consider only the relative poses between objects (e.g. other agents, scene features such as traffic lanes). However, these methods compute the relative poses for all pairs of objects explicitly, requiring quadratic memory. In this work, we propose a mechanism for SE(2) invariant scaled dot-product attention that requires linear memory relative to the number of objects in the scene. Our SE(2) invariant transformer architecture enjoys the same scaling properties that have benefited large language models in recent years. We demonstrate experimentally that our approach is practical to implement and improves performance compared to comparable non-invariant architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18596v1" target="_blank">Preselection-Free Fiber-Optic Weak Measurement Sensing Framework with High-sensitivity</a></h3>
                    <p><strong>Authors:</strong> Zifu Su, Weiqian Zhao, Wanshou Sun, Hexiang Li, Yafei Yu, Jindong Wang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> physics.optics, quant-ph</p>
                    <p><strong>Summary:</strong> A preselection-free fiber-optic weak measurement sensing framework is proposed and experimentally verified in this paper. In view of the limitation that fiber-optic weak measurement require specific preselection, this scheme innovates theoretically and achieves high sensitivity sensing by optimizing the post-selection when single-mode optical fiber is used to generate random polarization state. The experimental results show that the sensing performance is two to three orders of magnitude higher than that of traditional optical fiber sensing technology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18595v1" target="_blank">Investigating Mobility in Spatial Biodiversity Models through Recurrence Quantification Analysis</a></h3>
                    <p><strong>Authors:</strong> Matheus Palmero, Matheus Bongestab</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> q-bio.PE, physics.app-ph</p>
                    <p><strong>Summary:</strong> Recurrence plots and their associated quantifiers provide a robust framework for detecting and characterising complex patterns in non-linear time-series. In this paper, we employ recurrence quantification analysis to investigate the dynamics of the cyclic, non-hierarchical May-Leonard model, also referred to as rock--paper--scissors systems, that describes competitive interactions among three species. A crucial control parameter in these systems is the species mobility $m$, which governs the spatial displacement of individuals and profoundly influences the resulting dynamics. By systematically varying $m$ and constructing suitable recurrence plots from numerical simulations, we explore how recurrence quantifiers reflect distinct dynamical features associated with different ecological states. We then introduce an ensemble-based approach that leverages statistical distributions of recurrence quantifiers, computed from numerous independent realisations, allowing us to identify dynamical outliers as significant deviations from typical system behaviour. Through detailed numerical analyses, we demonstrate that these outliers correspond to divergent ecological regimes associated with specific mobility values, providing also a robust manner to infer the mobility parameter from observed numerical data. Our results highlight the potential of recurrence-based methods as diagnostic tools for analysing spatial ecological systems and extracting ecologically relevant information from their non-linear dynamical patterns.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18594v1" target="_blank">DRWKV: Focusing on Object Edges for Low-Light Image Enhancement</a></h3>
                    <p><strong>Authors:</strong> Xuecheng Bai, Yuxiang Wang, Boyu Hu, Qinyuan Jie, Chuanzhi Xu, Hongru Xiao, Kechen Li, Vera Chung</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Low-light image enhancement remains a challenging task, particularly in preserving object edge continuity and fine structural details under extreme illumination degradation. In this paper, we propose a novel model, DRWKV (Detailed Receptance Weighted Key Value), which integrates our proposed Global Edge Retinex (GER) theory, enabling effective decoupling of illumination and edge structures for enhanced edge fidelity. Secondly, we introduce Evolving WKV Attention, a spiral-scanning mechanism that captures spatial edge continuity and models irregular structures more effectively. Thirdly, we design the Bilateral Spectrum Aligner (Bi-SAB) and a tailored MS2-Loss to jointly align luminance and chrominance features, improving visual naturalness and mitigating artifacts. Extensive experiments on five LLIE benchmarks demonstrate that DRWKV achieves leading performance in PSNR, SSIM, and NIQE while maintaining low computational complexity. Furthermore, DRWKV enhances downstream performance in low-light multi-object tracking tasks, validating its generalization capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18593v1" target="_blank">Searching for Gravitational Waves with Gaia and its Cross-Correlation with PTA: Absolute vs Relative Astrometry</a></h3>
                    <p><strong>Authors:</strong> Massimo Vaglio, Mikel Falxa, Giorgio Mentasti, Arianna I. Renzini, Adrien Kuntz, Enrico Barausse, Carlo Contaldi, Alberto Sesana</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.IM</p>
                    <p><strong>Summary:</strong> Astrometric missions like Gaia provide exceptionally precise measurements of stellar positions and proper motions. Gravitational waves traveling between the observer and distant stars can induce small, correlated shifts in these apparent positions, a phenomenon known as astrometric deflection. The precision and scale of astrometric datasets make them well-suited for searching for a stochastic gravitational wave background, whose signature appears in the two-point correlation function of the deflection field across the sky. Although Gaia achieves high accuracy in measuring angular separations in its focal plane, systematic uncertainties in the satellites absolute orientation limit the precision of absolute position measurements. These orientation errors can be mitigated by focusing on relative angles between star pairs, which effectively cancel out common-mode orientation noise. In this work, we compute the astrometric response and the overlap reduction functions for this relative astrometry approach, correcting previous expressions presented in the literature. We use a Fisher matrix analysis to compare the sensitivity of relative astrometry to that of conventional absolute astrometry. Our analysis shows that while the relative method is theoretically sound, its sensitivity is limited for closely spaced star pairs within a single Gaia field of view. Pairs with large angular separations could provide competitive sensitivity, but are practically inaccessible due to Gaias scanning law. Finally, we demonstrate that combining astrometric data with observations from pulsar timing arrays leads to slight improvements in sensitivity at frequencies greater than approximately 10^-7 Hz.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18590v1" target="_blank">Vortex dynamics for the Gross-Pitaevskii equation</a></h3>
                    <p><strong>Authors:</strong> Manuel del Pino, Rowan Juneman, Monica Musso</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> math.AP</p>
                    <p><strong>Summary:</strong> We rigorously establish the formal asymptotics of Neu for Gross-Pitaevskii vortex dynamics in the plane. Given any integer $n\geq2$, we construct a family of $n$-vortex solutions with vortices of degree $\pm1$, and describe precisely the solution profile and associated vortex dynamics on an arbitrarily large, finite time interval. We compute an asymptotic expansion of the vortex positions in terms of the vortex core size $\epsilon0$, and show that the dynamics is governed at leading order as $\epsilon\to0$ by the classical Helmholtz-Kirchhoff system. Moreover, we show that the first correction to the leading order dynamics is determined by the solution of a linear wave equation, justifying a formal expansion found by Ovchinnikov and Sigal.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18588v1" target="_blank">gsaot: an R package for Optimal Transport-based sensitivity analysis</a></h3>
                    <p><strong>Authors:</strong> Leonardo Chiani, Emanuele Borgonovo, Elmar Plischke, Massimo Tavoni</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> stat.CO</p>
                    <p><strong>Summary:</strong> gsaot is an R package for Optimal Transport-based global sensitivity analysis. It provides a simple interface for indices estimation using a variety of state-of-the-art Optimal Transport solvers such as the network simplex and Sinkhorn-Knopp. The package is model-agnostic, allowing analysts to perform the sensitivity analysis as a post-processing step. Moreover, gsaot provides functions for indices and statistics visualization. In this work, we provide an overview of the theoretical grounds, of the implemented algorithms, and show how to use the package in different examples.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18587v1" target="_blank">A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff</a></h3>
                    <p><strong>Authors:</strong> JÃ©rÃ´me Emery, Ali Hasanzadeh Karkan, Jean-FranÃ§ois Frigon, FranÃ§ois Leduc-Primeau</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> eess.SP, cs.AI</p>
                    <p><strong>Summary:</strong> Deep learning (DL) has emerged as a solution for precoding in massive multiple-input multiple-output (mMIMO) systems due to its capacity to learn the characteristics of the propagation environment. However, training such a model requires high-quality, local datasets at the deployment site, which are often difficult to collect. We propose a transformer-based foundation model for mMIMO precoding that seeks to minimize the energy consumption of the transmitter while dynamically adapting to per-user rate requirements. At equal energy consumption, zero-shot deployment of the proposed foundation model significantly outperforms zero forcing, and approaches weighted minimum mean squared error performance with 8x less complexity. To address model adaptation in data-scarce settings, we introduce a data augmentation method that finds training samples similar to the target distribution by computing the cosine similarity between the outputs of the pre-trained feature extractor. Our work enables the implementation of DL-based solutions in practice by addressing challenges of data availability and training complexity. Moreover, the ability to dynamically configure per-user rate requirements can be leveraged by higher level resource allocation and scheduling algorithms for greater control over energy efficiency, spectral efficiency and fairness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18586v1" target="_blank">Implementation of the inverse scattering transform method for the nonlinear SchrÃ¶dinger equation</a></h3>
                    <p><strong>Authors:</strong> Vladislav V. Kravchenko</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> math.AP, math-ph, math.CA, math.MP, nlin.SI</p>
                    <p><strong>Summary:</strong> We study the initial-value problem for the nonlinear Schr\odinger equation. Application of the inverse scattering transform method involves solving direct and inverse scattering problems for the Zakharov-Shabat system with complex potentials. We solve these problems by using new series representations for the Jost solutions of the Zakharov-Shabat system. The representations have the form of power series with respect to a transformed spectral parameter. In terms of the representations, solution of the direct scattering problem reduces to computing the series coefficients following a simple recurrent integration procedure, computation of the scattering coefficients by multiplying corresponding pairs of polynomials (partial sums of the series representations) and locating zeros of a polynomial inside the unit disk. Solution of the inverse scattering problem reduces to the solution of a system of linear algebraic equations for the power series coefficients, while the potential is recovered from the first coefficients. The system is obtained directly from the scattering relations. Thus, unlike other existing techniques, the method does not involve solving the Gelfand-Levitan-Marchenko equation or the matrix Riemann-Hilbert problem. The overall approach leads to a simple and efficient algorithm for the numerical solution of the initial-value problem for the nonlinear Schr\odinger equation, which is illustrated by numerical examples.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18585v1" target="_blank">Stability of Big Bang singularity for the Einstein-Maxwell-scalar field-Vlasov system in the full strong sub-critical regime</a></h3>
                    <p><strong>Authors:</strong> Xinliang An, Taoran He, Dawei Shen</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> gr-qc, math-ph, math.AP, math.DG, math.MP</p>
                    <p><strong>Summary:</strong> In $3+1$ dimensions, we study the stability of Kasner solutions for the Einstein-Maxwell-scalar field-Vlasov system. This system incorporates gravity, electromagnetic, weak and strong interactions for the initial stage of our universe. Due to the presence of the Vlasov field, various new challenges arise. By observing detailed mathematical structures and designing new delicate arguments, we identify a new strong sub-critical regime and prove the nonlinear stability with Kasner exponents lying in this full regime. This extends the result of Fournodavlos-Rodnianski-Speck [8] from the Einstein-scalar field system to the physically more complex system with the Vlasov field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18584v1" target="_blank">AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs</a></h3>
                    <p><strong>Authors:</strong> Xiaopeng Ke, Hexuan Deng, Xuebo Liu, Jun Rao, Zhenxi Song, Jun Yu, Min Zhang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Despite the impressive performance of large language models (LLMs) in general domains, they often underperform in specialized domains. Existing approaches typically rely on data synthesis methods and yield promising results by using unlabeled data to capture domain-specific features. However, these methods either incur high computational costs or suffer from performance limitations, while also demonstrating insufficient generalization across different tasks. To address these challenges, we propose AQuilt, a framework for constructing instruction-tuning data for any specialized domains from corresponding unlabeled data, including Answer, Question, Unlabeled data, Inspection, Logic, and Task type. By incorporating logic and inspection, we encourage reasoning processes and self-inspection to enhance model performance. Moreover, customizable task instructions enable high-quality data generation for any task. As a result, we construct a dataset of 703k examples to train a powerful data synthesis model. Experiments show that AQuilt is comparable to DeepSeek-V3 while utilizing just 17% of the production cost. Further analysis demonstrates that our generated data exhibits higher relevance to downstream tasks. Source code, models, and scripts are available at https://github.com/Krueske/AQuilt.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18583v1" target="_blank">DR.EHR: Dense Retrieval for Electronic Health Record with Knowledge Injection and Synthetic Data</a></h3>
                    <p><strong>Authors:</strong> Zhengyun Zhao, Huaiyuan Ying, Yue Zhong, Sheng Yu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Electronic Health Records (EHRs) are pivotal in clinical practices, yet their retrieval remains a challenge mainly due to semantic gap issues. Recent advancements in dense retrieval offer promising solutions but existing models, both general-domain and biomedical-domain, fall short due to insufficient medical knowledge or mismatched training corpora. This paper introduces \texttt{DR.EHR}, a series of dense retrieval models specifically tailored for EHR retrieval. We propose a two-stage training pipeline utilizing MIMIC-IV discharge summaries to address the need for extensive medical knowledge and large-scale training data. The first stage involves medical entity extraction and knowledge injection from a biomedical knowledge graph, while the second stage employs large language models to generate diverse training data. We train two variants of \texttt{DR.EHR}, with 110M and 7B parameters, respectively. Evaluated on the CliniQ benchmark, our models significantly outperforms all existing dense retrievers, achieving state-of-the-art results. Detailed analyses confirm our models superiority across various match and query types, particularly in challenging semantic matches like implication and abbreviation. Ablation studies validate the effectiveness of each pipeline component, and supplementary experiments on EHR QA datasets demonstrate the models generalizability on natural language questions, including complex ones with multiple entities. This work significantly advances EHR retrieval, offering a robust solution for clinical applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18580v1" target="_blank">System Report for CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition</a></h3>
                    <p><strong>Authors:</strong> Jiahao Wang, Ramen Liu, Longhui Zhang, Jing Li</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper presents our system for CCL25-Eval Task 10, addressing Fine-Grained Chinese Hate Speech Recognition (FGCHSR). We propose a novel SRAG-MAV framework that synergistically integrates task reformulation(TR), Self-Retrieval-Augmented Generation (SRAG), and Multi-Round Accumulative Voting (MAV). Our method reformulates the quadruplet extraction task into triplet extraction, uses dynamic retrieval from the training set to create contextual prompts, and applies multi-round inference with voting to improve output stability and performance. Our system, based on the Qwen2.5-7B model, achieves a Hard Score of 26.66, a Soft Score of 48.35, and an Average Score of 37.505 on the STATE ToxiCN dataset, significantly outperforming baselines such as GPT-4o (Average Score 15.63) and fine-tuned Qwen2.5-7B (Average Score 35.365). The code is available at https://github.com/king-wang123/CCL25-SRAG-MAV.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18579v1" target="_blank">Invariants of the finite orthogonal groups in odd dimension and even characteristic</a></h3>
                    <p><strong>Authors:</strong> H. E. A. Campbell, R. J. Shank, D. L. Wehlau</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> math.AC, 13A50 (Primary) 20F55 (Secondary)</p>
                    <p><strong>Summary:</strong> We describe the ring of invariants for the finite orthogonal groups in odd dimension and even characteristic acting on the defining representation. We construct a minimal algebra generating set and describe the relations among the generators. This ring of invariants is shown to be a complete intersection and thus is Cohen-Macaulay. This extends the previous computation of Kropholler, Mohseni Rajaei, and Segal valid over the field of order 2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18578v1" target="_blank">Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs</a></h3>
                    <p><strong>Authors:</strong> Feng Hong, Geng Yu, Yushi Ye, Haicheng Huang, Huangjie Zheng, Ya Zhang, Yanfeng Wang, Jiangchao Yao</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Diffusion Large Language Models (DLLMs) have emerged as a compelling alternative to Autoregressive models, designed for fast parallel generation. However, existing DLLMs are plagued by a severe quality-speed trade-off, where faster parallel decoding leads to significant performance degradation. We attribute this to the irreversibility of standard decoding in DLLMs, which is easily polarized into the wrong decoding direction along with early error context accumulation. To resolve this, we introduce Wide-In, Narrow-Out (WINO), a training-free decoding algorithm that enables revokable decoding in DLLMs. WINO employs a parallel draft-and-verify mechanism, aggressively drafting multiple tokens while simultaneously using the models bidirectional context to verify and re-mask suspicious ones for refinement. Verified in open-source DLLMs like LLaDA and MMaDA, WINO is shown to decisively improve the quality-speed trade-off. For instance, on the GSM8K math benchmark, it accelerates inference by 6$\times$ while improving accuracy by 2.58%; on Flickr30K captioning, it achieves a 10$\times$ speedup with higher performance. More comprehensive experiments are conducted to demonstrate the superiority and provide an in-depth understanding of WINO.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18576v1" target="_blank">SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law</a></h3>
                    <p><strong>Authors:</strong> Shanghai AI Lab, :, Yicheng Bao, Guanxu Chen, Mingkang Chen, Yunhao Chen, Chiyu Chen, Lingjie Chen, Sirui Chen, Xinquan Chen, Jie Cheng, Yu Cheng, Dengke Deng, Yizhuo Ding, Dan Ding, Xiaoshan Ding, Yi Ding, Zhichen Dong, Lingxiao Du, Yuyu Fan, Xinshun Feng, Yanwei Fu, Yuxuan Gao, Ruijun Ge, Tianle Gu, Lujun Gui, Jiaxuan Guo, Qianxi He, Yuenan Hou, Xuhao Hu, Hong Huang, Kaichen Huang, Shiyang Huang, Yuxian Jiang, Shanzhe Lei, Jie Li, Lijun Li, Hao Li, Juncheng Li, Xiangtian Li, Yafu Li, Lingyu Li, Xueyan Li, Haotian Liang, Dongrui Liu, Qihua Liu, Zhixuan Liu, Bangwei Liu, Huacan Liu, Yuexiao Liu, Zongkai Liu, Chaochao Lu, Yudong Lu, Xiaoya Lu, Zhenghao Lu, Qitan Lv, Caoyuan Ma, Jiachen Ma, Xiaoya Ma, Zhongtian Ma, Lingyu Meng, Ziqi Miao, Yazhe Niu, Yuezhang Peng, Yuan Pu, Han Qi, Chen Qian, Xingge Qiao, Jingjing Qu, Jiashu Qu, Wanying Qu, Wenwen Qu, Xiaoye Qu, Qihan Ren, Qingnan Ren, Qingyu Ren, Jing Shao, Wenqi Shao, Shuai Shao, Dongxing Shi, Xin Song, Xinhao Song, Yan Teng, Xuan Tong, Yingchun Wang, Xuhong Wang, Shujie Wang, Xin Wang, Yige Wang, Yixu Wang, Yuanfu Wang, Futing Wang, Ruofan Wang, Wenjie Wang, Yajie Wang, Muhao Wei, Xiaoyu Wen, Fenghua Weng, Yuqi Wu, Yingtong Xiong, Xingcheng Xu, Chao Yang, Yue Yang, Yang Yao, Yulei Ye, Zhenyun Yin, Yi Yu, Bo Zhang, Qiaosheng Zhang, Jinxuan Zhang, Yexin Zhang, Yinqiang Zheng, Hefeng Zhou, Zhanhui Zhou, Pengyu Zhu, Qingzi Zhu, Yubo Zhu, Bowen Zhou</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CV</p>
                    <p><strong>Summary:</strong> We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18575v1" target="_blank">HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation</a></h3>
                    <p><strong>Authors:</strong> Xinyu Wang, Jinghua Hou, Zhe Liu, Yingying Zhu</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Transformer-based methods have demonstrated remarkable capabilities in 3D semantic segmentation through their powerful attention mechanisms, but the quadratic complexity limits their modeling of long-range dependencies in large-scale point clouds. While recent Mamba-based approaches offer efficient processing with linear complexity, they struggle with feature representation when extracting 3D features. However, effectively combining these complementary strengths remains an open challenge in this field. In this paper, we propose HybridTM, the first hybrid architecture that integrates Transformer and Mamba for 3D semantic segmentation. In addition, we propose the Inner Layer Hybrid Strategy, which combines attention and Mamba at a finer granularity, enabling simultaneous capture of long-range dependencies and fine-grained local features. Extensive experiments demonstrate the effectiveness and generalization of our HybridTM on diverse indoor and outdoor datasets. Furthermore, our HybridTM achieves state-of-the-art performance on ScanNet, ScanNet200, and nuScenes benchmarks. The code will be made available at https://github.com/deepinact/HybridTM.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746059.3747769" target="_blank">PosterMate: Audience-driven Collaborative Persona Agents for Poster Design</a></h3>
                    <p><strong>Authors:</strong> Donghoon Shin, Daniel Lee, Gary Hsieh, Gromit Yeuk-Yin Chan</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CL, H.5.2; I.2.7</p>
                    <p><strong>Summary:</strong> Poster designing can benefit from synchronous feedback from target audiences. However, gathering audiences with diverse perspectives and reconciling them on design edits can be challenging. Recent generative AI models present opportunities to simulate human-like interactions, but it is unclear how they may be used for feedback processes in design. We introduce PosterMate, a poster design assistant that facilitates collaboration by creating audience-driven persona agents constructed from marketing documents. PosterMate gathers feedback from each persona agent regarding poster components, and stimulates discussion with the help of a moderator to reach a conclusion. These agreed-upon edits can then be directly integrated into the poster design. Through our user study (N=12), we identified the potential of PosterMate to capture overlooked viewpoints, while serving as an effective prototyping tool. Additionally, our controlled online evaluation (N=100) revealed that the feedback from an individual persona agent is appropriate given its persona identity, and the discussion effectively synthesizes the different persona agents perspectives.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18571v1" target="_blank">Tunable Non-Gaussian Mechanical States in a Strongly Coupled Hybrid Quantum System</a></h3>
                    <p><strong>Authors:</strong> Jugal Talukdar, Scott E. Smart, Prineha Narang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum states of motion are critical components in the second quantum revolution. We investigate the generation and control of non-Gaussian motional states in a tripartite hybrid quantum system consisting of a collection of qubits coupled to a mechanical resonator, which in turn interacts with an externally driven photonic cavity. This hybrid architecture provides a versatile platform for quantum control by integrating nonlinear interactions and multiple control parameters. Operating in the strong coupling regime, we study the transient dynamics resulting from a time-dependent external drive that has a boxcar profile. Starting from coherent states in both the mechanical and cavity subsystems, we show that this drive protocol, combined with time-independent interaction and frequency configurations, leads to the emergence of highly non-Gaussian quantum states in the intermediary mechanical degree of freedom. These states are characterized by a pronounced negative volume in the Wigner quasi-probability distribution and enhanced quantum Fisher information, indicative of their quantum utility. We systematically analyze the impact of the qubit phase, interaction strengths, and drive parameters on the degree of non-Gaussianity. Our findings underscore the tunability and richness of this hybrid platform, paving the way for advanced quantum state engineering and applications in quantum sensing, metrology, and information processing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18570v1" target="_blank">Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods</a></h3>
                    <p><strong>Authors:</strong> Ganesh Sapkota, Md Hasibur Rahman</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper presents a novel hybrid tokenization strategy that enhances the performance of DNA Language Models (DLMs) by combining 6-mer tokenization with Byte Pair Encoding (BPE-600). Traditional k-mer tokenization is effective at capturing local DNA sequence structures but often faces challenges, including uneven token distribution and a limited understanding of global sequence context. To address these limitations, we propose merging unique 6mer tokens with optimally selected BPE tokens generated through 600 BPE cycles. This hybrid approach ensures a balanced and context-aware vocabulary, enabling the model to capture both short and long patterns within DNA sequences simultaneously. A foundational DLM trained on this hybrid vocabulary was evaluated using next-k-mer prediction as a fine-tuning task, demonstrating significantly improved performance. The model achieved prediction accuracies of 10.78% for 3-mers, 10.1% for 4-mers, and 4.12% for 5-mers, outperforming state-of-the-art models such as NT, DNABERT2, and GROVER. These results highlight the ability of the hybrid tokenization strategy to preserve both the local sequence structure and global contextual information in DNA modeling. This work underscores the importance of advanced tokenization methods in genomic language modeling and lays a robust foundation for future applications in downstream DNA sequence analysis and biological research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18569v1" target="_blank">Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis</a></h3>
                    <p><strong>Authors:</strong> Yanzuo Lu, Yuxi Ren, Xin Xia, Shanchuan Lin, Xing Wang, Xuefeng Xiao, Andy J. Ma, Xiaohua Xie, Jian-Huang Lai</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Distribution Matching Distillation (DMD) is a promising score distillation technique that compresses pre-trained teacher diffusion models into efficient one-step or multi-step student generators. Nevertheless, its reliance on the reverse Kullback-Leibler (KL) divergence minimization potentially induces mode collapse (or mode-seeking) in certain applications. To circumvent this inherent drawback, we propose Adversarial Distribution Matching (ADM), a novel framework that leverages diffusion-based discriminators to align the latent predictions between real and fake score estimators for score distillation in an adversarial manner. In the context of extremely challenging one-step distillation, we further improve the pre-trained generator by adversarial distillation with hybrid discriminators in both latent and pixel spaces. Different from the mean squared error used in DMD2 pre-training, our method incorporates the distributional loss on ODE pairs collected from the teacher model, and thus providing a better initialization for score distillation fine-tuning in the next stage. By combining the adversarial distillation pre-training with ADM fine-tuning into a unified pipeline termed DMDX, our proposed method achieves superior one-step performance on SDXL compared to DMD2 while consuming less GPU time. Additional experiments that apply multi-step ADM distillation on SD3-Medium, SD3.5-Large, and CogVideoX set a new benchmark towards efficient image and video synthesis.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.4204/EPTCS.423" target="_blank">Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications</a></h3>
                    <p><strong>Authors:</strong> Ruben Gamboa, Panagiotis Manolios</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI</p>
                    <p><strong>Summary:</strong> The ACL2 Workshop series is the major technical forum for users of the ACL2 theorem proving system to present research related to the ACL2 theorem prover and its applications. ACL2 is an industrial-strength automated reasoning system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM Software System Award was awarded to Boyer, Kaufmann, and Moore for their work on ACL2 and the other theorem provers in the Boyer-Moore family.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18566v1" target="_blank">Facial Demorphing from a Single Morph Using a Latent Conditional GAN</a></h3>
                    <p><strong>Authors:</strong> Nitish Shukla, Arun Ross</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> A morph is created by combining two (or more) face images from two (or more) identities to create a composite image that is highly similar to both constituent identities, allowing the forged morph to be biometrically associated with more than one individual. Morph Attack Detection (MAD) can be used to detect a morph, but does not reveal the constituent images. Demorphing - the process of deducing the constituent images - is thus vital to provide additional evidence about a morph. Existing demorphing methods suffer from the morph replication problem, where the outputs tend to look very similar to the morph itself, or assume that train and test morphs are generated using the same morph technique. The proposed method overcomes these issues. The method decomposes a morph in latent space allowing it to demorph images created from unseen morph techniques and face styles. We train our method on morphs created from synthetic faces and test on morphs created from real faces using arbitrary morph techniques. Our method outperforms existing methods by a considerable margin and produces high fidelity demorphed face images.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18565v1" target="_blank">Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement</a></h3>
                    <p><strong>Authors:</strong> Muhammad Imran Zaman, Nisar Ahmed</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper presents a novel deep learning-based approach for simultaneous age and gender classification from facial images, designed to enhance the effectiveness of targeted advertising campaigns. We propose a custom Convolutional Neural Network (CNN) architecture, optimized for both tasks, which leverages the inherent correlation between age and gender information present in facial features. Unlike existing methods that often treat these tasks independently, our model learns shared representations, leading to improved performance. The network is trained on a large, diverse dataset of facial images, carefully pre-processed to ensure robustness against variations in lighting, pose, and image quality. Our experimental results demonstrate a significant improvement in gender classification accuracy, achieving 95%, and a competitive mean absolute error of 5.77 years for age estimation. Critically, we analyze the performance across different age groups, identifying specific challenges in accurately estimating the age of younger individuals. This analysis reveals the need for targeted data augmentation and model refinement to address these biases. Furthermore, we explore the impact of different CNN architectures and hyperparameter settings on the overall performance, providing valuable insights for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18564v1" target="_blank">Computability of Separation Axioms in Countable Second Countable Spaces</a></h3>
                    <p><strong>Authors:</strong> Andrew DeLapo, David Gonzalez</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> math.LO, math.GN, 03D55, 54D10 (Primary) 03D45, 06A05, 54G20 (Secondary)</p>
                    <p><strong>Summary:</strong> We analyze the effective content of countable, second countable topological spaces by directly calculating the complexity of several topologically defined index sets. We focus on the separation principles, calibrating an arithmetic completeness result for each of the Tychonoff separation axioms. Beyond this, we prove completeness results for various other topological properties, such as being Polish and having a particular Cantor-Bendixson rank, using tools from computable structure theory. This work contrasts with previous work analyzing countable, second countable spaces which used the framework of reverse mathematics, as reverse mathematics generally lacks the precision to pin down exact arithmetic complexity levels for properties of interest.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18563v1" target="_blank">Ultrafast coherent magnon spin currents in antiferromagnets</a></h3>
                    <p><strong>Authors:</strong> Torstein Hegstad, Johan H. Mentink</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, quant-ph</p>
                    <p><strong>Summary:</strong> Generating coherent magnon spin currents with the highest frequencies and shortest wavelengths is a key challenge in ultrafast spintronics and magnonics. A promising route is to excite counter-propagating magnon pairs. In antiferromagnets, such pairs can be accessed in the ultrafast regime, where coherent dynamics are dominated by magnons at the edge of the Brillouin zone. However, it has seemed impossible to generate a net spin current from coherent magnon pairs. Here we show that a coherent superposition of multiple magnon-pair modes can produce such a current in parity-time symmetric antiferromagnets. The ultrafast coherent spin currents are excited with linearly polarized light, with the light polarization steering the current direction. Finally, by superposing two orthogonal spin currents, circular spin currents can be generated, which have not been discussed for steady-state currents.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18562v1" target="_blank">GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation</a></h3>
                    <p><strong>Authors:</strong> Jiafeng Xiong, Yuting Zhao</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Multimodal Machine Translation (MMT) has demonstrated the significant help of visual information in machine translation. However, existing MMT methods face challenges in leveraging the modality gap by enforcing rigid visual-linguistic alignment whilst being confined to inference within their trained multimodal domains. In this work, we construct novel multimodal scene graphs to preserve and integrate modality-specific information and introduce GIIFT, a two-stage Graph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph Attention Network adapter to learn multimodal knowledge in a unified fused space and inductively generalize it to broader image-free translation domains. Experimental results on the Multi30K dataset of English-to-French and English-to-German tasks demonstrate that our GIIFT surpasses existing approaches and achieves the state-of-the-art, even without images during inference. Results on the WMT benchmark show significant improvements over the image-free translation baselines, demonstrating the strength of GIIFT towards inductive image-free inference.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18558v1" target="_blank">Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation</a></h3>
                    <p><strong>Authors:</strong> Yihong Feng, Chaitanya Pallerla, Xiaomin Lin, Pouya Sohrabipour Sr, Philip Crandall, Wan Shou, Yu She, Dongyi Wang</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> The poultry industry has been driven by broiler chicken production and has grown into the worlds largest animal protein sector. Automated detection of chicken carcasses on processing lines is vital for quality control, food safety, and operational efficiency in slaughterhouses and poultry processing plants. However, developing robust deep learning models for tasks like instance segmentation in these fast-paced industrial environments is often hampered by the need for laborious acquisition and annotation of large-scale real-world image datasets. We present the first pipeline generating photo-realistic, automatically labeled synthetic images of chicken carcasses. We also introduce a new benchmark dataset containing 300 annotated real-world images, curated specifically for poultry segmentation research. Using these datasets, this study investigates the efficacy of synthetic data and automatic data annotation to enhance the instance segmentation of chicken carcasses, particularly when real annotated data from the processing line is scarce. A small real dataset with varying proportions of synthetic images was evaluated in prominent instance segmentation models. Results show that synthetic data significantly boosts segmentation performance for chicken carcasses across all models. This research underscores the value of synthetic data augmentation as a viable and effective strategy to mitigate data scarcity, reduce manual annotation efforts, and advance the development of robust AI-driven automated detection systems for chicken carcasses in the poultry processing industry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18552v1" target="_blank">VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding</a></h3>
                    <p><strong>Authors:</strong> Baoyao Yang, Wanyun Li, Dixin Chen, Junxiang Chen, Wenbin Yao, Haifeng Lin</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, 68T45, 68T50, 68U35,, I.4.8; I.2.7; I.2.10; H.5.1</p>
                    <p><strong>Summary:</strong> This paper introduces VideoMind, a video-centric omni-modal dataset designed for deep video content cognition and enhanced multi-modal feature representation. The dataset comprises 103K video samples (3K reserved for testing), each paired with audio and systematically detailed textual descriptions. Specifically, every video and its audio is described across three hierarchical layers (factual, abstract, and intent), progressing from surface to depth. It contains over 22 million words, averaging ~225 words per sample. VideoMinds key distinction from existing datasets is its provision of intent expressions, which require contextual integration across the entire video and are not directly observable. These deep-cognitive expressions are generated using a Chain-of-Thought (COT) approach, prompting the mLLM through step-by-step reasoning. Each description includes annotations for subject, place, time, event, action, and intent, supporting downstream recognition tasks. Crucially, we establish a gold-standard benchmark with 3,000 manually validated samples for evaluating deep-cognitive video understanding. We design hybrid-cognitive retrieval experiments, scored by multi-level retrieval metrics, to appropriately assess deep video comprehension. Evaluation results for models (e.g., InternVideo, VAST, UMT-L) are released. VideoMind serves as a powerful benchmark for fine-grained cross-modal alignment and advances fields requiring in-depth video understanding, such as emotion and intent recognition. The data is publicly available on GitHub, HuggingFace, and OpenDataLab, https://github.com/cdx-cindy/VideoMind.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18551v1" target="_blank">A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration</a></h3>
                    <p><strong>Authors:</strong> Daniil Morozov, Reuben Dorent, Nazim Haouchine</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Intraoperative registration of real-time ultrasound (iUS) to preoperative Magnetic Resonance Imaging (MRI) remains an unsolved problem due to severe modality-specific differences in appearance, resolution, and field-of-view. To address this, we propose a novel 3D cross-modal keypoint descriptor for MRI-iUS matching and registration. Our approach employs a patient-specific matching-by-synthesis approach, generating synthetic iUS volumes from preoperative MRI. This enables supervised contrastive training to learn a shared descriptor space. A probabilistic keypoint detection strategy is then employed to identify anatomically salient and modality-consistent locations. During training, a curriculum-based triplet loss with dynamic hard negative mining is used to learn descriptors that are i) robust to iUS artifacts such as speckle noise and limited coverage, and ii) rotation-invariant . At inference, the method detects keypoints in MR and real iUS images and identifies sparse matches, which are then used to perform rigid registration. Our approach is evaluated using 3D MRI-iUS pairs from the ReMIND dataset. Experiments show that our approach outperforms state-of-the-art keypoint matching methods across 11 patients, with an average precision of $69.8\%$. For image registration, our method achieves a competitive mean Target Registration Error of 2.39 mm on the ReMIND2Reg benchmark. Compared to existing iUS-MR registration approach, our framework is interpretable, requires no manual initialization, and shows robustness to iUS field-of-view variation. Code is available at https://github.com/morozovdd/CrossKEY.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18550v1" target="_blank">On the Performance of Concept Probing: The Influence of the Data (Extended Version)</a></h3>
                    <p><strong>Authors:</strong> Manuel de Sousa Ribeiro, Afonso Leote, JoÃ£o Leite</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV, cs.LG, cs.NE</p>
                    <p><strong>Summary:</strong> Concept probing has recently garnered increasing interest as a way to help interpret artificial neural networks, dealing both with their typically large size and their subsymbolic nature, which ultimately renders them unfeasible for direct human interpretation. Concept probing works by training additional classifiers to map the internal representations of a model into human-defined concepts of interest, thus allowing humans to peek inside artificial neural networks. Research on concept probing has mainly focused on the model being probed or the probing model itself, paying limited attention to the data required to train such probing models. In this paper, we address this gap. Focusing on concept probing in the context of image classification tasks, we investigate the effect of the data used to train probing models on their performance. We also make available concept labels for two widely used datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18548v1" target="_blank">Supersymmetry and integrability of the elliptic $\mathrm{AdS}_3 \times \mathrm{S}^3 \times \mathrm{T}^4$ superstring</a></h3>
                    <p><strong>Authors:</strong> Ben Hoare, Fiona K. Seibold</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> We construct a 1-parameter family of Ramond-Ramond fluxes supporting the elliptic $\mathrm{AdS}_3 \times \mathrm{S}^3 \times \mathrm{T}^4$ metric with constant dilaton and preserving 8 of the 16 supercharges of the undeformed background. On the supersymmetric locus, we compute the tree-level worldsheet S-matrix in uniform light-cone gauge up to quadratic order in fermions and find that it non-trivially satisfies the classical Yang-Baxter equation. Moreover, imposing classical integrability and symmetries, we conjecture compatible processes quartic in fermions. We also investigate different limits of interest, including trigonometric deformations and the limit to the $\mathrm{AdS}_2 \times \mathrm{S}^2 \times \mathrm{T}^6$ superstring. Our results provide strong evidence for a supersymmetric and integrable elliptic deformation of the $\mathrm{AdS}_3 \times \mathrm{S}^3 \times \mathrm{T}^4$ superstring supported by Ramond-Ramond flux and a constant dilaton.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18546v1" target="_blank">GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface</a></h3>
                    <p><strong>Authors:</strong> Urchade Zaratiana, Gil Pasternak, Oliver Boyd, George Hurn-Maloney, Ash Lewis</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Information extraction (IE) is fundamental to numerous NLP applications, yet existing solutions often require specialized models for different tasks or rely on computationally expensive large language models. We present GLiNER2, a unified framework that enhances the original GLiNER architecture to support named entity recognition, text classification, and hierarchical structured data extraction within a single efficient model. Built pretrained transformer encoder architecture, GLiNER2 maintains CPU efficiency and compact size while introducing multi-task composition through an intuitive schema-based interface. Our experiments demonstrate competitive performance across extraction and classification tasks with substantial improvements in deployment accessibility compared to LLM-based alternatives. We release GLiNER2 as an open-source pip-installable library with pre-trained models and documentation at https://github.com/fastino-ai/GLiNER2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.18545v1" target="_blank">The unreasonable likelihood of being: origin of life, terraforming, and AI</a></h3>
                    <p><strong>Authors:</strong> Robert G. Endres</p>
                    <p><strong>Published:</strong> 7/24/2025</p>
                    <p><strong>Categories:</strong> q-bio.PE, q-bio.BM</p>
                    <p><strong>Summary:</strong> The origin of life on Earth via the spontaneous emergence of a protocell prior to Darwinian evolution remains a fundamental open question in physics and chemistry. Here, we develop a conceptual framework based on information theory and algorithmic complexity. Using estimates grounded in modern computational models, we evaluate the difficulty of assembling structured biological information under plausible prebiotic conditions. Our results highlight the formidable entropic and informational barriers to forming a viable protocell within the available window of Earths early history. While the idea of Earth being terraformed by advanced extraterrestrials might violate Occams razor from within mainstream science, directed panspermia -- originally proposed by Francis Crick and Leslie Orgel -- remains a speculative but logically open alternative. Ultimately, uncovering physical principles for lifes spontaneous emergence remains a grand challenge for biological physics.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

