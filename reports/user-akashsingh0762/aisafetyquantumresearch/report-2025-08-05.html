
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-05<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 115
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

In the realm of AI safety research, several recent papers highlight emerging trends and breakthroughs that address the challenges and implications of deploying artificial intelligence across various domains. A prominent theme is the emphasis on developing robust, interpretable, and context-aware AI systems that ensure safety and trustworthiness. For instance, the paper on **MedVLThinker** introduces a methodology for reasoning-centric medical language models, showcasing the value of reinforcement learning for enhancing model performance, which could enhance AI reliability in critical medical decision-making scenarios. Similarly, **HealthFlow** presents a self-evolving AI agent for healthcare research, emphasizing the need for dynamic, adaptable AI strategies that can autonomously refine their problem-solving capabilities, an essential feature in ensuring AI safety in complex environments.

Moreover, the growing concern over AIs unintended consequences is addressed through frameworks like **PoseGuard**, which focuses on mitigating risks in pose-guided generation to prevent unsafe content creation. This aligns with broader efforts to incorporate ethical and safety considerations into AI development processes. The study on **Federated Graph Unlearning** highlights the importance of data privacy and the right to be forgotten, emphasizing the need for AI systems to be designed with mechanisms that allow for comprehensive data removal, thus safeguarding user privacy and trust.

Overall, these papers reflect an increasing awareness of the challenges posed by AI systems and the necessity of integrating safety measures at both the technical and ethical levels. This involves not only improving the robustness and interpretability of AI models but also ensuring that they are designed with considerations for privacy, ethical use, and adaptability to changing environments. As a result, AI safety research is evolving towards creating more resilient and responsible AI systems capable of operating safely in diverse and dynamic real-world contexts.

*Based on 50 research papers*

---

## ai alignment research

The listed research papers span a variety of topics, but the direct connection to AI alignment research is not immediately apparent in most of them. AI alignment research focuses on ensuring that AI systems act in ways that are aligned with human values and intentions, particularly as these systems become more autonomous and capable. 

Among the papers, the work on MedVLThinker addresses AI alignment in a medical context by developing a framework for medical reasoning that emphasizes robustness and correctness in AI decision-making. The use of Reinforcement Learning with Verifiable Rewards (RLVR) highlights a trend towards ensuring that AI systems not only produce correct answers but do so in a way that is verifiable and transparent, aligning with the broader goals of AI alignment.

Another relevant paper is What Is Your AI Agent Buying? which investigates the behavior of AI agents in e-commerce. This research explores how AI agents make purchasing decisions, reflecting on the biases and preferences they exhibit. Understanding and potentially guiding the decision-making processes of these agents is a crucial aspect of AI alignment, particularly in ensuring that their actions are consistent with human economic goals and ethical standards.

Furthermore, Noosemia provides insights into how humans attribute agency and intentionality to AI systems, which is central to AI alignment. By understanding the cognitive and phenomenological mechanisms through which users perceive AI systems as intentional agents, researchers can better design AI systems that communicate their intentions clearly and align with user expectations.

Overall, the significance of these studies in AI alignment lies in their focus on making AI systems understandable, predictable, and controllable, ensuring that they operate in ways that are congruent with human values and societal norms. These themes are critical in addressing the challenge of aligning increasingly sophisticated AI systems with human interests.

*Based on 50 research papers*

---

## quantum computing

While the provided list of research papers covers a broad range of topics, only a few have direct implications for quantum computing, particularly in hardware and algorithmic advancements.

The paper titled **atommovr: An open-source simulation framework for rearrangement in atomic arrays** by Nikhil K Harle et al. is significant in the context of quantum computing. It focuses on atom rearrangement, which is vital for developing neutral atom-based quantum processors. The authors introduce an open-source framework that allows for the benchmarking and development of more efficient atom rearrangement algorithms. This framework is pivotal as it can enhance the scalability and efficiency of quantum processors by improving atomic arrangement techniques, which are crucial for constructing larger and more complex quantum systems.

Another relevant paper is **Anticipating Decoherence: a Predictive Framework for Enhancing Coherence in Quantum Emitters** by Pranshu Maan et al. This research addresses the challenge of maintaining optical coherence in quantum systems, a key requirement for scalable quantum communication and computation. By leveraging statistical theories and machine learning, the authors propose a framework to predict and manage decoherence in quantum emitters, potentially enhancing spectral stability. This advancement could significantly impact the development of robust quantum networks by improving the coherence and synchronization of quantum devices.

These studies indicate key trends in quantum computing towards optimizing quantum hardware and mitigating decoherence, both essential for advancing quantum technologies. The implications of these breakthroughs are profound, potentially leading to more stable and scalable quantum systems capable of tackling complex computational tasks.

*Based on 15 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.02669v1" target="_blank">MedVLThinker: Simple Baselines for Multimodal Medical Reasoning</a></h3>
                    <p><strong>Authors:</strong> Xiaoke Huang, Juncheng Wu, Hui Liu, Xianfeng Tang, Yuyin Zhou</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to ``think before responding via chain-of-thought reasoning. However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and comparison. In this paper, we present MedVLThinker, a suite of simple yet strong baselines. Our fully open recipe consists of: (1) systematic data curation for both text-only and image-text medical data, filtered according to varying levels of reasoning difficulty, and (2) two training paradigms: Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement Learning with Verifiable Rewards (RLVR) based on final answer correctness. Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six medical QA benchmarks, we find that RLVR consistently and significantly outperforms SFT. Additionally, under the RLVR framework, a key, counter-intuitive finding is that training on our curated text-only reasoning data provides a more substantial performance boost than training on multimodal image-text data. Our best open 7B model, trained using the RLVR recipe on text-only data, establishes a new state-of-the-art on existing public VQA benchmarks, surpassing all previous open-source medical LMMs. Furthermore, scaling our model to 32B achieves performance on par with the proprietary GPT-4o. We release all curated data, models, and code to provide the community with a strong, open foundation for future research in multimodal medical reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02650v1" target="_blank">Design and demonstration of a direct air capture system with moisture-driven CO2 delivery into aqueous medium</a></h3>
                    <p><strong>Authors:</strong> Justin Flory, Samantha Taylor, Shuqin Li, Sunil Tiwari, Garrett Cole, Amory Lowe, Lindsey Hamblin, Samuel Piorkowski, Matthew Ryan, Thiago Stangherlin Barbosa, Jason Kmon, Nick Lowery, Joel Eliston, Jason C. Quinn, John McGowen, Matthew D. Green, Klaus Lackner, Wim Vermaas</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft, cond-mat.mtrl-sci, cond-mat.other</p>
                    <p><strong>Summary:</strong> A moisture-driven air capture (DAC) system was designed and demonstrated. A laboratory-scale system delivering ~1 g CO2 per day was demonstrated in a laminar flow hood and a small pilot-scale system that could deliver ~100 g CO2 daily was operated outdoors in a 4.2 m2 (areal surface area) raceway pond. Elongated mesh tube packets were designed to contain AER beads with high surface area for contacting the air and were found to reduce drying and CO2 loading time ~4-fold over larger mesh bags. Whereas this system was designed for CO2 delivery for cultivating photosynthetic microbes, its potential uses are much broader and include CO2 use in the food and beverage industry, conversion to fuels and chemicals, and sequestration. Techno-economic assessments for a practical scenario based on current results are \$670/tonne to capture CO2 into an alkaline solution and an additional \$280/tonne to extract CO2 from solution, purify and compress to 15 MPa for sequestration. An aspirational scenario modelling reasonable improvements to develop AER sorbents with a capacity of 4 mmol CO2 per gram of sorbent and water uptake of 50 wt.%, which leads to sorbent drying and loading within 1 h, shows a potential to reach \$51/tonne to capture CO2 into an alkaline solution and an additional \$109/tonne to get to 15 MPa for sequestration. Life cycle analysis shows the aspirational moisture-driven process uses up to 87% less energy than thermal and/or vacuum swing DAC by using energy from water evaporation; however, ~330 wt.% water uptake by the sorbent contained in a hydrophilic mesh packets leads to ~33-fold higher water use than the thermodynamic limits, which emphasizes future research is needed to increase sorbent hydrophobicity while maintaining and further increasing ion exchange capacity needed to bind CO2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02643v1" target="_blank">CAK: Emergent Audio Effects from Minimal Deep Learning</a></h3>
                    <p><strong>Authors:</strong> Austin Rockman</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> We demonstrate that a single 3x3 convolutional kernel can produce emergent audio effects when trained on 200 samples from a personalized corpus. We achieve this through two key techniques: (1) Conditioning Aware Kernels (CAK), where output = input + (learned_pattern x control), with a soft-gate mechanism supporting identity preservation at zero control; and (2) AuGAN (Audit GAN), which reframes adversarial training from is this real? to did you apply the requested value? Rather than learning to generate or detect forgeries, our networks cooperate to verify control application, discovering unique transformations. The learned kernel exhibits a diagonal structure creating frequency-dependent temporal shifts that are capable of producing musical effects based on input characteristics. Our results show the potential of adversarial training to discover audio transformations from minimal data, enabling new approaches to effect design.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02639v1" target="_blank">Reframing Pattern: A Comprehensive Approach to a Composite Visual Variable</a></h3>
                    <p><strong>Authors:</strong> Tingying He, Jason Dykes, Petra Isenberg, Tobias Isenberg</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> We present a new comprehensive theory for explaining, exploring, and using pattern as a visual variable in visualization. Although patterns have long been used for data encoding and continue to be valuable today, their conceptual foundations are precarious: the concepts and terminology used across the research literature and in practice are inconsistent, making it challenging to use patterns effectively and to conduct research to inform their use. To address this problem, we conduct a comprehensive cross-disciplinary literature review that clarifies ambiguities around the use of pattern and texture. As a result, we offer a new consistent treatment of pattern as a composite visual variable composed of structured groups of graphic primitives that can serve as marks for encoding data individually and collectively. This new and widely applicable formulation opens a sizable design space for the visual variable pattern, which we formalize as a new system comprising three sets of variables: the spatial arrangement of primitives, the appearance relationships among primitives, and the retinal visual variables that characterize individual primitives. We show how our pattern system relates to existing visualization theory and highlight opportunities for visualization design. We further explore patterns based on complex spatial arrangements, demonstrating explanatory power and connecting our conceptualization to broader theory on maps and cartography. An author version and additional materials are available on OSF: osf.io/z7ae2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02636v1" target="_blank">Dam Management in the Era of Climate Change</a></h3>
                    <p><strong>Authors:</strong> Cristina Di Girolami, Mhamed Mrad, GaÃ¯gi, Vathana Ly Vath, Simone Scotti</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> math.OC, 49L25, 49J40, 60G55, 60G57, 91G99</p>
                    <p><strong>Summary:</strong> Climate change has a dramatic impact, particularly by concentrating rainfall into a few short periods, interspersed by long dry spells. In this context, the role of dams is crucial. We consider the optimal control of a dam, where the water level must not exceed a designated safety threshold, nor fall below a minimum level to ensure functionality and sustainability for for the outgoing river. To model dry spells and intense rainfall events, commonly referred to as water bombs, we introduce a Hawkes process, a well-known example of a self-exciting process characterised by time-correlated intensity, which endogenously reproduces the concentration of events. The problem is formulated as an optimal switching problem with constraints. We establish existence results and propose numerical methods for approximating the solution. Finally, we illustrate the main achievements of this approach through numerical examples. The main and counterintuitive result of our numerical analysis is that the optimal water level inside the dam increases with the self-exciting parameter. This result shows that, when facing the dilemma of managing the opposing risks of dam overtopping and dry spells, the former ultimately dominates the latter. In conclusion, dams will increasingly lose their role as water reserves and take on a greater role in flood protection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02631v1" target="_blank">Pointer: Linear-Complexity Long-Range Modeling without Pre-training</a></h3>
                    <p><strong>Authors:</strong> Zixi Li</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We introduce Pointer, a novel architecture that achieves linear $O(NK)$ complexity for long-range sequence modeling while maintaining superior performance without requiring pre-training. Unlike standard attention mechanisms that compute $O(N^2)$ pairwise interactions, our approach uses layer-wise pointer chaining where each layers pointer selection depends on previous layers pointer positions, creating explicit long-distance connections through pointer chains. We demonstrate that this architecture achieves $2$--$10\times$ speedup on long sequences compared to standard transformers, maintains $95\%$ accuracy on copy tasks at distances up to 2048 tokens, and learns interpretable pointer patterns that reveal structured dependency modeling. Our experiments on efficiency benchmarks, long-range dependency tasks, and interpretability analysis show that Pointer offers a compelling alternative to attention mechanisms for scenarios requiring efficient long-range modeling without pre-training dependencies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02630v1" target="_blank">What Is Your AI Agent Buying? Evaluation, Implications and Emerging Questions for Agentic E-Commerce</a></h3>
                    <p><strong>Authors:</strong> Amine Allouah, Omar Besbes, JosuÃ© D Figueroa, Yash Kanoria, Akshit Kumar</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY, cs.HC, cs.MA, econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Online marketplaces will be transformed by autonomous AI agents acting on behalf of consumers. Rather than humans browsing and clicking, vision-language-model (VLM) agents can parse webpages, evaluate products, and transact. This raises a fundamental question: what do AI agents buy, and why? We develop ACES, a sandbox environment that pairs a platform-agnostic VLM agent with a fully programmable mock marketplace to study this question. We first conduct basic rationality checks in the context of simple tasks, and then, by randomizing product positions, prices, ratings, reviews, sponsored tags, and platform endorsements, we obtain causal estimates of how frontier VLMs actually shop. Models show strong but heterogeneous position effects: all favor the top row, yet different models prefer different columns, undermining the assumption of a universal top rank. They penalize sponsored tags and reward endorsements. Sensitivities to price, ratings, and reviews are directionally human-like but vary sharply in magnitude across models. Motivated by scenarios where sellers use AI agents to optimize product listings, we show that a seller-side agent that makes minor tweaks to product descriptions, targeting AI buyer preferences, can deliver substantial market-share gains if AI-mediated shopping dominates. We also find that modal product choices can differ across models and, in some cases, demand may concentrate on a few select products, raising competition questions. Together, our results illuminate how AI agents may behave in e-commerce settings and surface concrete seller strategy, platform design, and regulatory questions in an AI-mediated ecosystem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02622v1" target="_blank">Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction</a></h3>
                    <p><strong>Authors:</strong> Enrico De Santis, Antonello Rizzi</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> This paper introduces and formalizes Noosemia, a novel cognitive-phenomenological phenomenon emerging from human interaction with generative AI systems, particularly those enabling dialogic or multimodal exchanges. We propose a multidisciplinary framework to explain how, under certain conditions, users attribute intentionality, agency, and even interiority to these systems - a process grounded not in physical resemblance, but in linguistic performance, epistemic opacity, and emergent technological complexity. By linking an LLM declination of meaning holism to our technical notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct meaning relationally and how coherence and a simulacrum of agency arise at the human-AI interface. The analysis situates noosemia alongside pareidolia, animism, the intentional stance and the uncanny valley, distinguishing its unique characteristics. We also introduce a-noosemia to describe the phenomenological withdrawal of such projections. The paper concludes with reflections on the broader philosophical, epistemological, and social implications of noosemic dynamics and directions for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02621v1" target="_blank">HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research</a></h3>
                    <p><strong>Authors:</strong> Yinghao Zhu, Yifan Qi, Zixiang Wang, Lei Gu, Dehao Sui, Haoran Hu, Xichen Zhang, Ziyi He, Liantao Ma, Lequan Yu</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG, cs.MA</p>
                    <p><strong>Summary:</strong> The efficacy of AI agents in healthcare research is hindered by their reliance on static, predefined strategies. This creates a critical limitation: agents can become better tool-users but cannot learn to become better strategic planners, a crucial skill for complex domains like healthcare. We introduce HealthFlow, a self-evolving AI agent that overcomes this limitation through a novel meta-level evolution mechanism. HealthFlow autonomously refines its own high-level problem-solving policies by distilling procedural successes and failures into a durable, strategic knowledge base. To anchor our research and facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark featuring complex, realistic health data analysis tasks derived from peer-reviewed clinical research. Our comprehensive experiments demonstrate that HealthFlows self-evolving approach significantly outperforms state-of-the-art agent frameworks. This work marks a necessary shift from building better tool-users to designing smarter, self-evolving task-managers, paving the way for more autonomous and effective AI for scientific discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02617v1" target="_blank">Vision-based Navigation of Unmanned Aerial Vehicles in Orchards: An Imitation Learning Approach</a></h3>
                    <p><strong>Authors:</strong> Peng Wei, Prabhash Ragbir, Stavros G. Vougioukas, Zhaodan Kong</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Autonomous unmanned aerial vehicle (UAV) navigation in orchards presents significant challenges due to obstacles and GPS-deprived environments. In this work, we introduce a learning-based approach to achieve vision-based navigation of UAVs within orchard rows. Our method employs a variational autoencoder (VAE)-based controller, trained with an intervention-based learning framework that allows the UAV to learn a visuomotor policy from human experience. We validate our approach in real orchard environments with a custom-built quadrotor platform. Field experiments demonstrate that after only a few iterations of training, the proposed VAE-based controller can autonomously navigate the UAV based on a front-mounted camera stream. The controller exhibits strong obstacle avoidance performance, achieves longer flying distances with less human assistance, and outperforms existing algorithms. Furthermore, we show that the policy generalizes effectively to novel environments and maintains competitive performance across varying conditions and speeds. This research not only advances UAV autonomy but also holds significant potential for precision agriculture, improving efficiency in orchard monitoring and management.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02611v1" target="_blank">Meta-RAG on Large Codebases Using Code Summarization</a></h3>
                    <p><strong>Authors:</strong> Vali Tawosia, Salwa Alamir, Xiaomo Liu, Manuela Veloso</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM) systems have been at the forefront of applied Artificial Intelligence (AI) research in a multitude of domains. One such domain is software development, where researchers have pushed the automation of a number of code tasks through LLM agents. Software development is a complex ecosystem, that stretches far beyond code implementation and well into the realm of code maintenance. In this paper, we propose a multi-agent system to localize bugs in large pre-existing codebases using information retrieval and LLMs. Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. We then use an LLM agent to determine which parts of the codebase are critical for bug resolution, i.e. bug localization. We demonstrate the usefulness of Meta-RAG through evaluation with the SWE-bench Lite dataset. Meta-RAG scores 84.67 % and 53.0 % for file-level and function-level correct localization rates, respectively, achieving state-of-the-art performance.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3663547.3746365" target="_blank">PunchPulse: A Physically Demanding Virtual Reality Boxing Game Designed with, for and by Blind and Low-Vision Players</a></h3>
                    <p><strong>Authors:</strong> Sanchita S. Kamath, Omar Khan, Anurag Choudhary, Jan Meyerhoff-Liang, Soyoung Choi, JooYoung Seo</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Blind and low-vision (BLV) individuals experience lower levels of physical activity (PA) compared to sighted peers due to a lack of accessible, engaging exercise options. Existing solutions often rely on auditory cues but do not fully integrate rich sensory feedback or support spatial navigation, limiting their effectiveness. This study introduces PunchPulse, a virtual reality (VR) boxing exergame designed to motivate BLV users to reach and sustain moderate to vigorous physical activity (MVPA) levels. Over a seven-month, multi-phased study, PunchPulse was iteratively refined with three BLV co-designers, informed by two early pilot testers, and evaluated by six additional BLV user-study participants. Data collection included both qualitative (researcher observations, SOPI) and quantitative (MVPA zones, aid usage, completion times) measures of physical exertion and gameplay performance. The user study revealed that all participants reached moderate MVPA thresholds, with high levels of immersion and engagement observed. This work demonstrates the potential of VR as an inclusive medium for promoting meaningful PA in the BLV community and addresses a critical gap in accessible, intensity-driven exercise interventions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02602v1" target="_blank">Trustworthy scientific inference for inverse problems with generative models</a></h3>
                    <p><strong>Authors:</strong> James Carzon, Luca Masserano, Joshua D. Ingram, Alex Shen, Antonio Carlos Herling Ribeiro Junior, Tommaso Dorigo, Michele Doro, Joshua S. Speagle, Rafael Izbicki, Ann B. Lee</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> stat.ML, astro-ph.IM, cs.LG, stat.AP, stat.ME</p>
                    <p><strong>Summary:</strong> Generative artificial intelligence (AI) excels at producing complex data structures (text, images, videos) by learning patterns from training examples. Across scientific disciplines, researchers are now applying generative models to ``inverse problems to infer hidden parameters from observed data. While these methods can handle intractable models and large-scale studies, they can also produce biased or overconfident conclusions. We present a solution with Frequentist-Bayes (FreB), a mathematically rigorous protocol that reshapes AI-generated probability distributions into confidence regions that consistently include true parameters with the expected probability, while achieving minimum size when training and target data align. We demonstrate FreBs effectiveness by tackling diverse case studies in the physical sciences: identifying unknown sources under dataset shift, reconciling competing theoretical models, and mitigating selection bias and systematics in observational studies. By providing validity guarantees with interpretable diagnostics, FreB enables trustworthy scientific inference across fields where direct likelihood evaluation remains impossible or prohibitively expensive.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1063/5.0272970" target="_blank">Molecular Processes as Quantum Information Resources</a></h3>
                    <p><strong>Authors:</strong> Saikat Sur, Pritam Chattopadhyay, Gershon Kurizki</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> In this contribution to Abraham Nitzans Festschrift, we present a perspective of theoretical research over the years that has pointed to the potential of molecular processes to act as quantum information resources. Under appropriate control, homonuclear dimer (diatom) dissociation (half-collision) and the inverse process of atom-pair collisions are shown to reveal translational (EPR-like) entanglement that enables molecular wavepacket teleportation. When such processes involve electronic-state excitation of the diatom, the fluorescence following dissociation can serve as an entanglement witness that unravels the molecular-state characteristics and evolution. Such entangling processes can also exhibit anomalous quantum thermodynamic features, particularly temperature enhancement of a cavity field that interacts with dissociated entangled diatoms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02593v1" target="_blank">Explainable AI for Automated User-specific Feedback in Surgical Skill Acquisition</a></h3>
                    <p><strong>Authors:</strong> Catalina Gomez, Lalithkumar Seenivasan, Xinrui Zou, Jeewoo Yoon, Sirui Chu, Ariel Leong, Patrick Kramer, Yu-Chun Ku, Jose L. Porras, Alejandro Martin-Gomez, Masaru Ishii, Mathias Unberath</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> Traditional surgical skill acquisition relies heavily on expert feedback, yet direct access is limited by faculty availability and variability in subjective assessments. While trainees can practice independently, the lack of personalized, objective, and quantitative feedback reduces the effectiveness of self-directed learning. Recent advances in computer vision and machine learning have enabled automated surgical skill assessment, demonstrating the feasibility of automatic competency evaluation. However, it is unclear whether such Artificial Intelligence (AI)-driven feedback can contribute to skill acquisition. Here, we examine the effectiveness of explainable AI (XAI)-generated feedback in surgical training through a human-AI study. We create a simulation-based training framework that utilizes XAI to analyze videos and extract surgical skill proxies related to primitive actions. Our intervention provides automated, user-specific feedback by comparing trainee performance to expert benchmarks and highlighting deviations from optimal execution through understandable proxies for actionable guidance. In a prospective user study with medical students, we compare the impact of XAI-guided feedback against traditional video-based coaching on task outcomes, cognitive load, and trainees perceptions of AI-assisted learning. Results showed improved cognitive load and confidence post-intervention. While no differences emerged between the two feedback types in reducing performance gaps or practice adjustments, trends in the XAI group revealed desirable effects where participants more closely mimicked expert practice. This work encourages the study of explainable AI in surgical education and the development of data-driven, adaptive feedback mechanisms that could transform learning experiences and competency assessment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02572v1" target="_blank">Facility Location and $k$-Median with Fair Outliers</a></h3>
                    <p><strong>Authors:</strong> Rajni Dabas, Samir Khuller, Emilie Rivkin</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.DS</p>
                    <p><strong>Summary:</strong> Classical clustering problems such as \emph{Facility Location} and \emph{$k$-Median} aim to efficiently serve a set of clients from a subset of facilities -- minimizing the total cost of facility openings and client assignments in Facility Location, and minimizing assignment (service) cost under a facility count constraint in $k$-Median. These problems are highly sensitive to outliers, and therefore researchers have studied variants that allow excluding a small number of clients as outliers to reduce cost. However, in many real-world settings, clients belong to different demographic or functional groups, and unconstrained outlier removal can disproportionately exclude certain groups, raising fairness concerns. We study \emph{Facility Location with Fair Outliers}, where each group is allowed a specified number of outliers, and the objective is to minimize total cost while respecting group-wise fairness constraints. We present a bicriteria approximation with a $O(1/\epsilon)$ approximation factor and $(1+ 2\epsilon)$ factor violation in outliers per group. For \emph{$k$-Median with Fair Outliers}, we design a bicriteria approximation with a $4(1+\omega/\epsilon)$ approximation factor and $(\omega + \epsilon)$ violation in outliers per group improving on prior work by avoiding dependence on $k$ in outlier violations. We also prove that the problems are W[1]-hard parameterized by $\omega$, assuming the Exponential Time Hypothesis. We complement our algorithmic contributions with a detailed empirical analysis, demonstrating that fairness can be achieved with negligible increase in cost and that the integrality gap of the standard LP is small in practice.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02571v1" target="_blank">ASINT: Learning AS-to-Organization Mapping from Internet Metadata</a></h3>
                    <p><strong>Authors:</strong> Yongzhe Xu, Weitong Li, Eeshan Umrani, Taejoong Chung</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> Accurately mapping Autonomous Systems (ASNs) to their owning or operating organizations underpins Internet measurement research and security applications. Yet existing approaches commonly rely solely on WHOIS or PeeringDB, missing important relationships (e.g., cross-regional aliases, parent-child ownership) and failing to unify organizations scattered across different RIR identifiers. We introduce ASINT, an end-to-end pipeline that fuses bulk registry data with unstructured Web sources, then employs retrieval-augmented generation (RAG) to guide large language model (LLM) inference. Through a multi-stage procedure, ASINT merges ASNs into organization families, capturing nuanced ties beyond the scope of simpler heuristics. ASINT maps 111,470 ASNs to 81,233 organization families; compared to both AS2ORG+ and AS-Sibling, ASINT identifies more cross-regional groupings (e.g., operator aliases, rebrands) that other datasets overlook. Moreover, our refined mappings enhance multiple security and measurement tasks: ASINT exposes 27.5% more intra-organizational RPKI misconfigurations, cuts false-positive hijack alarms by 9.4%, and lowers erroneous IP leasing inferences by 5.9%. Finally, ASINT supports periodic updates and cost-sensitive LLM selection, demonstrating that broader Web evidence can provide a more accurate, evolving view of the Internets organizational structure.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02570v1" target="_blank">Neural Scaling Laws Surpass Chemical Accuracy for the Many-Electron SchrÃ¶dinger Equation</a></h3>
                    <p><strong>Authors:</strong> Du Jiang, Xuelan Wen, Yixiao Chen, Ruichen Li, Weizhong Fu, Hung Q. Pham, Ji Chen, Di He, William A. Goddard III, Liwei Wang, Weiluo Ren</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph, physics.comp-ph</p>
                    <p><strong>Summary:</strong> We demonstrate, for the first time, that neural scaling laws can deliver near-exact solutions to the many-electron Schr\odinger equation across a broad range of realistic molecules. This progress is enabled by the Lookahead Variational Algorithm (LAVA), an effective optimization scheme that systematically translates increased model size and computational resources into greatly improved energy accuracy for neural network wavefunctions. Across all tested cases, including benzene, the absolute energy error exhibits a systematic power-law decay with respect to model capacity and computation resources. The resulting energies not only surpass the 1 kcal/mol chemical-accuracy threshold but also achieve 1 kJ/mol subchemical accuracy. Beyond energies, the scaled-up neural network also yields better wavefunctions with improved physical symmetries, alongside accurate electron densities, dipole moments, and other important properties. Our approach offers a promising way forward to addressing many long-standing challenges in quantum chemistry. For instance, we improve energetic properties for systems such as the potential energy curve of nitrogen dimer as dissociation is approached and the cyclobutadiene automerization reaction barrier, producing definitive benchmarks, particularly in regimes where experimental data are sparse or highly uncertain. We also shed light on the decades-old puzzle of the cyclic ozone stability with highly accurate calculations for the cyclic-to-open ozone barrier. These results provide near-exact reference calculations with unprecedented accuracy, universal reliability and practical applicability, establishing a foundation for AI-driven quantum chemistry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02565v1" target="_blank">The analytically tractable zoo of similarity-induced exceptional structures</a></h3>
                    <p><strong>Authors:</strong> Anton Montag, Jordan Isaacs, Marcus StÃ¥lhammar, Flore K. Kunst</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> physics.optics, cond-mat.mes-hall, quant-ph</p>
                    <p><strong>Summary:</strong> Exceptional points (EPs) are non-Hermitian spectral degeneracies marking a simultaneous coalescence of eigenvalues and eigenvectors. Despite the fact that multiband $n$-fold EPs (EP$n$s) generically emerge as special points on manifolds of EP$m$s, where $mn$, EP$n$s as well as their topological properties have hitherto been studied as isolated objects. In this work we address this issue and carefully map out the emerging properties of multifold exceptional structures in three and four dimensions under the influence of one or multiple generalized similarities, revealing diverse combinations of EP$m$s in direct connection to EP$n$s. We find that simply counting the number of constraints defining the EP$n$s is not sufficient in the presence of similarities; the constraints can also be satisfied by the EP$m$-manifolds obeying certain spectral symmetries in the complex eigenvalue plane, reducing their dimension beyond what is expected from counting the number of constraints. Furthermore, the induced spectral symmetries not always allow for any EP$m$-manifold to emerge in $n$-band systems, making the plethora of exceptional structures deviate further from naive expectations. We illustrate our findings in simple periodic toy models. By relying on similarity relations instead of the less general symmetries, we simultaneously cover several physically relevant scenarios, ranging from optics and topolectrical circuits, to open quantum systems. This makes our predictions highly relevant and broadly applicable in modern research, as well as experimentally viable within various branches of physics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02560v1" target="_blank">Explainable AI Methods for Neuroimaging: Systematic Failures of Common Tools, the Need for Domain-Specific Validation, and a Proposal for Safe Application</a></h3>
                    <p><strong>Authors:</strong> Nys Tjade Siegel, James H. Cole, Mohamad Habes, Stefan Haufe, Kerstin Ritter, Marc-AndrÃ© Schulz</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV, eess.IV, q-bio.NC</p>
                    <p><strong>Summary:</strong> Trustworthy interpretation of deep learning models is critical for neuroimaging applications, yet commonly used Explainable AI (XAI) methods lack rigorous validation, risking misinterpretation. We performed the first large-scale, systematic comparison of XAI methods on ~45,000 structural brain MRIs using a novel XAI validation framework. This framework establishes verifiable ground truth by constructing prediction tasks with known signal sources - from localized anatomical features to subject-specific clinical lesions - without artificially altering input images. Our analysis reveals systematic failures in two of the most widely used methods: GradCAM consistently failed to localize predictive features, while Layer-wise Relevance Propagation generated extensive, artifactual explanations that suggest incompatibility with neuroimaging data characteristics. Our results indicate that these failures stem from a domain mismatch, where methods with design principles tailored to natural images require substantial adaptation for neuroimaging data. In contrast, the simpler, gradient-based method SmoothGrad, which makes fewer assumptions about data structure, proved consistently accurate, suggesting its conceptual simplicity makes it more robust to this domain shift. These findings highlight the need for domain-specific adaptation and validation of XAI methods, suggest that interpretations from prior neuroimaging studies using standard XAI methodology warrant re-evaluation, and provide urgent guidance for practical application of XAI in neuroimaging.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02541v1" target="_blank">Automatic Identification of Machine Learning-Specific Code Smells</a></h3>
                    <p><strong>Authors:</strong> Peter Hamfelt, Ricardo Britto, Lincoln Rocha, Camilo Almendra</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Machine learning (ML) has rapidly grown in popularity, becoming vital to many industries. Currently, the research on code smells in ML applications lacks tools and studies that address the identification and validity of ML-specific code smells. This work investigates suitable methods and tools to design and develop a static code analysis tool (MLpylint) based on code smell criteria. This research employed the Design Science Methodology. In the problem identification phase, a literature review was conducted to identify ML-specific code smells. In solution design, a secondary literature review and consultations with experts were performed to select methods and tools for implementing the tool. We evaluated the tool on data from 160 open-source ML applications sourced from GitHub. We also conducted a static validation through an expert survey involving 15 ML professionals. The results indicate the effectiveness and usefulness of the MLpylint. We aim to extend our current approach by investigating ways to introduce MLpylint seamlessly into development workflows, fostering a more productive and innovative developer environment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02536v1" target="_blank">ReGate: Enabling Power Gating in Neural Processing Units</a></h3>
                    <p><strong>Authors:</strong> Yuqi Xue, Jian Huang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> The energy efficiency of neural processing units (NPU) is playing a critical role in developing sustainable data centers. Our study with different generations of NPU chips reveals that 30%-72% of their energy consumption is contributed by static power dissipation, due to the lack of power management support in modern NPU chips. In this paper, we present ReGate, which enables fine-grained power-gating of each hardware component in NPU chips with hardware/software co-design. Unlike conventional power-gating techniques for generic processors, enabling power-gating in NPUs faces unique challenges due to the fundamental difference in hardware architecture and program execution model. To address these challenges, we carefully investigate the power-gating opportunities in each component of NPU chips and decide the best-fit power management scheme (i.e., hardware- vs. software-managed power gating). Specifically, for systolic arrays (SAs) that have deterministic execution patterns, ReGate enables cycle-level power gating at the granularity of processing elements (PEs) following the inherent dataflow execution in SAs. For inter-chip interconnect (ICI) and HBM controllers that have long idle intervals, ReGate employs a lightweight hardware-based idle-detection mechanism. For vector units and SRAM whose idle periods vary significantly depending on workload patterns, ReGate extends the NPU ISA and allows software like compilers to manage the power gating. With implementation on a production-level NPU simulator, we show that ReGate can reduce the energy consumption of NPU chips by up to 32.8% (15.5% on average), with negligible impact on AI workload performance. The hardware implementation of power-gating logic introduces less than 3.3% overhead in NPU chips.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02533v1" target="_blank">Precision-Aware Video Compression for Reducing Bandwidth Requirements in Video Communication for Vehicle Detection-Based Applications</a></h3>
                    <p><strong>Authors:</strong> Abyad Enan, Jon C Calhoun, Mashrur Chowdhury</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Computer vision has become a popular tool in intelligent transportation systems (ITS), enabling various applications through roadside traffic cameras that capture video and transmit it in real time to computing devices within the same network. The efficiency of this video transmission largely depends on the available bandwidth of the communication system. However, limited bandwidth can lead to communication bottlenecks, hindering the real-time performance of ITS applications. To mitigate this issue, lossy video compression techniques can be used to reduce bandwidth requirements, at the cost of degrading video quality. This degradation can negatively impact the accuracy of applications that rely on real-time vehicle detection. Additionally, vehicle detection accuracy is influenced by environmental factors such as weather and lighting conditions, suggesting that compression levels should be dynamically adjusted in response to these variations. In this work, we utilize a framework called Precision-Aware Video Compression (PAVC), where a roadside video camera captures footage of vehicles on roadways, compresses videos, and then transmits them to a processing unit, running a vehicle detection algorithm for safety-critical applications, such as real-time collision risk assessment. The system dynamically adjusts the video compression level based on current weather and lighting conditions to maintain vehicle detection accuracy while minimizing bandwidth usage. Our results demonstrate that PAVC improves vehicle detection accuracy by up to 13% and reduces communication bandwidth requirements by up to 8.23x in areas with moderate bandwidth availability. Moreover, in locations with severely limited bandwidth, PAVC reduces bandwidth requirements by up to 72x while preserving vehicle detection performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02530v1" target="_blank">Understanding the Risks of Asphalt Art on the Reliability of Surveillance Perception Systems</a></h3>
                    <p><strong>Authors:</strong> Jin Ma, Abyad Enan, Long Cheng, Mashrur Chowdhury</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Artistic crosswalks featuring asphalt art, introduced by different organizations in recent years, aim to enhance the visibility and safety of pedestrians. However, their visual complexity may interfere with surveillance systems that rely on vision-based object detection models. In this study, we investigate the impact of asphalt art on pedestrian detection performance of a pretrained vision-based object detection model. We construct realistic crosswalk scenarios by compositing various street art patterns into a fixed surveillance scene and evaluate the models performance in detecting pedestrians on asphalt-arted crosswalks under both benign and adversarial conditions. A benign case refers to pedestrian crosswalks painted with existing normal asphalt art, whereas an adversarial case involves digitally crafted or altered asphalt art perpetrated by an attacker. Our results show that while simple, color-based designs have minimal effect, complex artistic patterns, particularly those with high visual salience, can significantly degrade pedestrian detection performance. Furthermore, we demonstrate that adversarially crafted asphalt art can be exploited to deliberately obscure real pedestrians or generate non-existent pedestrian detections. These findings highlight a potential vulnerability in urban vision-based pedestrian surveillance systems and underscore the importance of accounting for environmental visual variations when designing robust pedestrian perception models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02525v1" target="_blank">Accurate and Interpretable Postmenstrual Age Prediction via Multimodal Large Language Model</a></h3>
                    <p><strong>Authors:</strong> Qifan Chen, Jin Cui, Cindy Duan, Yushuo Han, Yifei Shi</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Accurate estimation of postmenstrual age (PMA) at scan is crucial for assessing neonatal development and health. While deep learning models have achieved high accuracy in predicting PMA from brain MRI, they often function as black boxes, offering limited transparency and interpretability in clinical decision support. In this work, we address the dual challenge of accuracy and interpretability by adapting a multimodal large language model (MLLM) to perform both precise PMA prediction and clinically relevant explanation generation. We introduce a parameter-efficient fine-tuning (PEFT) strategy using instruction tuning and Low-Rank Adaptation (LoRA) applied to the Qwen2.5-VL-7B model. The model is trained on four 2D cortical surface projection maps derived from neonatal MRI scans. By employing distinct prompts for training and inference, our approach enables the MLLM to handle a regression task during training and generate clinically relevant explanations during inference. The fine-tuned model achieves a low prediction error with a 95 percent confidence interval of 0.78 to 1.52 weeks, while producing interpretable outputs grounded in developmental features, marking a significant step toward transparent and trustworthy AI systems in perinatal neuroscience.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02523v1" target="_blank">Transportation Cyber Incident Awareness through Generative AI-Based Incident Analysis and Retrieval-Augmented Question-Answering Systems</a></h3>
                    <p><strong>Authors:</strong> Ostonya Thomas, Muhaimin Bin Munir, Jean-Michel Tine, Mizanur Rahman, Yuchen Cai, Khandakar Ashrafi Akbar, Md Nahiyan Uddin, Latifur Khan, Trayce Hockstad, Mashrur Chowdhury</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Technological advancements have revolutionized numerous industries, including transportation. While digitalization, automation, and connectivity have enhanced safety and efficiency, they have also introduced new vulnerabilities. With 95% of data breaches attributed to human error, promoting cybersecurity awareness in transportation is increasingly critical. Despite numerous cyberattacks on transportation systems worldwide, comprehensive and centralized records of these incidents remain scarce. To address this gap and enhance cyber awareness, this paper presents a large language model (LLM) based approach to extract and organize transportation related cyber incidents from publicly available datasets. A key contribution of this work is the use of generative AI to transform unstructured, heterogeneous cyber incident data into structured formats. Incidents were sourced from the Center for Strategic  International Studies (CSIS) List of Significant Cyber Incidents, the University of Maryland Cyber Events Database (UMCED), the European Repository of Cyber Incidents (EuRepoC), the Maritime Cyber Attack Database (MCAD), and the U.S. DOT Transportation Cybersecurity and Resiliency (TraCR) Examples of Cyber Attacks in Transportation (2018 to 2022). These were classified by a fine tuned LLM into five transportation modes: aviation, maritime, rail, road, and multimodal, forming a transportation specific cyber incident database. Another key contribution of this work is the development of a Retrieval Augmented Generation question answering system, designed to enhance accessibility and practical use by enabling users to query the curated database for specific details on transportation related cyber incidents. By leveraging LLMs for both data extraction and user interaction, this study contributes a novel, accessible tool for improving cybersecurity awareness in the transportation sector.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02520v1" target="_blank">xDeepServe: Model-as-a-Service on Huawei CloudMatrix384</a></h3>
                    <p><strong>Authors:</strong> Ao Xiao, Bangzheng He, Baoquan Zhang, Baoxing Huai, Bingji Wang, Bo Wang, Bo Xu, Boyi Hou, Chan Yang, Changhong Liu, Cheng Cui, Chenyu Zhu, Cong Feng, Daohui Wang, Dayun Lin, Duo Zhao, Fengshao Zou, Fu Wang, Gangqiang Zhang, Gengyuan Dan, Guanjie Chen, Guodong Guan, Guodong Yang, Haifeng Li, Haipei Zhu, Hao Feng, Hao Huang, Hao Xu, Hengrui Ma, Hengtao Fan, Hui Liu, Jia Li, Jiang Liu, Jiang Xu, Jie Meng, Jinhan Xin, Junhao Hu, Juwei Chen, Lan Yu, Lanxin Miao, Liang Liu, Linan Jing, Lu Zhou, Meina Han, Mingkun Deng, Mingyu Deng, Naitian Deng, Nizhong Lin, Peihan Zhao, Peng Pan, Pengfei Shen, Ping Li, Qi Zhang, Qin Zhang, Qingrong Xia, Qingyi Zhang, Qunchao Fu, Ren Guo, Ruimin Gao, Shaochun Li, Sheng Long, Shentian Li, Shining Wan, Shuai Shen, Shuangfu Zeng, Shuming Jing, Siqi Yang, Song Zhang, Tao Xu, Tianlin Du, Ting Chen, Wanxu Wu, Wei Jiang, Weinan Tong, Weiwei Chen, Wen Peng, Wenli Zhou, Wenquan Yang, Wenxin Liang, Xiang Liu, Xiaoli Zhou, Xin Jin, Xinyu Duan, Xu Li, Xu Zhang, Xusheng Chen, Yalong Shan, Yang Gan, Yao Lu, Yi Deng, Yi Zheng, Yingfei Zheng, Yiyun Zheng, Yizhou Shan, Yong Gao, Yongqiang Yang, Yuanjin Gong, Yue Yu, Yuetao Chen, Yukun Zhu, Yulong He, Yusu Zhao, Yuyan Wu, Zenan Zhang, Zhaojin Zhuo, Zhaoyang Ji, Zhefeng Wang, Zheng Wang, Zhenhua Yang, Zhenli Sheng, Zhibin Yu, Zhigang Ji, Zhihao Ren, Zhipeng Bian, Zhixia Liu, Zhiyu Dong, Zhonghua Li, Zhou Yu, Zhuoming Shen, Zhuwei Peng, Zi Ye, Zihao Xiang, Zimin Fu, Zixuan Zhang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> The rise of scaled-out LLMs and scaled-up SuperPods signals a new era in large-scale AI infrastructure. LLMs continue to scale out via MoE, as seen in recent models like DeepSeek, Kimi, and Qwen. In parallel, AI hardware is scaling up, with Huaweis CloudMatrix384 SuperPod offering hundreds of GB/s high-speed interconnects. Running large MoE models on SuperPod-scale hardware brings new challenges. It requires new execution models, scalable scheduling, efficient expert load balancing, and elimination of single points of failure. This paper presents xDeepServe, Huawei Clouds LLM serving system designed for SuperPod-scale infrastructure. At its core is Transformerless, a disaggregated architecture that decomposes transformer models into modular units--attention, feedforward, and MoE--executed independently on NPUs connected via high-speed fabric. We implement this design in two forms: disaggregated prefill-decode and disaggregated MoE-attention. This fully disaggregated setup enables independent scaling of compute and memory without sacrificing performance. To support this architecture, we propose XCCL, a communication library that leverages CloudMatrix384s global shared memory to implement efficient point-to-point and all-to-all primitives. We also extend our serving engine FlowServe with system-level techniques, enabling scalable inference across hundreds of NPUs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02510v1" target="_blank">On Distributional Dependent Performance of Classical and Neural Routing Solvers</a></h3>
                    <p><strong>Authors:</strong> Daniela Thyssens, Tim Dernedde, Wilson Sentanoe, Lars Schmidt-Thieme</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Neural Combinatorial Optimization aims to learn to solve a class of combinatorial problems through data-driven methods and notably through employing neural networks by learning the underlying distribution of problem instances. While, so far neural methods struggle to outperform highly engineered problem specific meta-heuristics, this work explores a novel approach to formulate the distribution of problem instances to learn from and, more importantly, plant a structure in the sampled problem instances. In application to routing problems, we generate large problem instances that represent custom base problem instance distributions from which training instances are sampled. The test instances to evaluate the methods on the routing task consist of unseen problems sampled from the underlying large problem instance. We evaluate representative NCO methods and specialized Operation Research meta heuristics on this novel task and demonstrate that the performance gap between neural routing solvers and highly specialized meta-heuristics decreases when learning from sub-samples drawn from a fixed base node distribution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02505v1" target="_blank">Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Humanoid-Robot Interaction</a></h3>
                    <p><strong>Authors:</strong> Maria Lombardi, Carmela Calabrese, Davide Ghiglino, Caterina Foglino, Davide De Tommaso, Giulia Da Lisca, Lorenzo Natale, Agnieszka Wykowska</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> A key challenge in human-robot interaction research lies in developing robotic systems that can effectively perceive and interpret social cues, facilitating natural and adaptive interactions. In this work, we present a novel framework for enhancing the attention of the iCub humanoid robot by integrating advanced perceptual abilities to recognise social cues, understand surroundings through generative models, such as ChatGPT, and respond with contextually appropriate social behaviour. Specifically, we propose an interaction task implementing a narrative protocol (storytelling task) in which the human and the robot create a short imaginary story together, exchanging in turn cubes with creative images placed on them. To validate the protocol and the framework, experiments were performed to quantify the degree of usability and the quality of experience perceived by participants interacting with the system. Such a system can be beneficial in promoting effective human robot collaborations, especially in assistance, education and rehabilitation scenarios where the social awareness and the robot responsiveness play a pivotal role.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02499v1" target="_blank">Pre-discovery TESS Observations of Interstellar Object 3I/ATLAS</a></h3>
                    <p><strong>Authors:</strong> Jorge Martinez-Palomera, Amy Tuson, Christina Hedges, Jessie Dotson, Thomas Barclay, Brian Powell</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.EP, astro-ph.GA</p>
                    <p><strong>Summary:</strong> 3I/ATLAS, also known as C/2025 N1 (ATLAS), is the third known interstellar object to pass through our Solar System. We report serendipitous Transiting Exoplanet Survey Satellite (TESS) observations of 3I/ATLAS taken between 2025-05-07 and 2025-06-02,, 55 days prior to the discovery date (2025-07-01) and 14 days prior to the current earliest observation (2025-05-21). We retrieve the TESS pixel data, perform a robust background correction and use a data-driven approach to refine the objects ephemeris. We find a statistically significant offset between the targets observed and predicted positions and we show that this is dominated by uncertainty in the TESS World Coordinate System (WCS) rather than the ephemeris. 3I/ATLAS is too faint to be detected in the individual 200\,second TESS integrations, so we perform image stacking to improve detectability. After co-adding the TESS image data, we performed aperture and Pixel Response Function (PRF) photometry to create two light curves for 3I/ATLAS. Each light curve consists of 15 measurements with $\text{SNR}3$, collected across two different TESS cameras during the 26\,days that the object was observed, but the PRF light curve is more robust against image noise. The PRF light curve in the TESS bandpass shows a gradual increase in brightness from $T_{\text{mag}} = 20.9 \pm 0.29$ to $T_{\text{mag}} = 19.57 \pm 0.15$. This is expected as 3I/ATLAS approaches the inner Solar System. This paper highlights the power of using TESS for Solar System science; by increasing the photometric observing baseline, future studies will be able to investigate the long-term behavior of 3I/ATLAS</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02498v1" target="_blank">Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity</a></h3>
                    <p><strong>Authors:</strong> Md Tasin Abir, Arpita Chowdhury, Ashfia Rahman</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This study investigates how Facebook shaped collective identity during the July 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising. During government repression, protesters turned to Facebook as a central space for resistance, where multimodal expressions, images, memes, videos, hashtags, and satirical posts played an important role in unifying participants. Using a qualitative approach, this research analyzes visual rhetoric, verbal discourse, and digital irony to reveal how shared symbols, protest art, and slogans built a sense of solidarity. Key elements included the symbolic use of red, the ironic metaphorical use of the term Razakar, and the widespread sharing of visuals representing courage, injustice, and resistance. The findings show that the combination of visual and verbal strategies on Facebook not only mobilized public sentiment, but also built a strong collective identity that challenged authoritarian narratives. This study tries to demonstrate how online platforms can serve as powerful tools for identity construction and political mobilization in the digital age.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02485v1" target="_blank">Federated Graph Unlearning</a></h3>
                    <p><strong>Authors:</strong> Yuming Ai, Xunkai Li, Jiaqi Chao, Bowen Fan, Zhengyu Wu, Yinlin Zhu, Rong-Hua Li, Guoren Wang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> The demand for data privacy has led to the development of frameworks like Federated Graph Learning (FGL), which facilitate decentralized model training. However, a significant operational challenge in such systems is adhering to the right to be forgotten. This principle necessitates robust mechanisms for two distinct types of data removal: the selective erasure of specific entities and their associated knowledge from local subgraphs and the wholesale removal of a users entire dataset and influence. Existing methods often struggle to fully address both unlearning requirements, frequently resulting in incomplete data removal or the persistence of residual knowledge within the system. This work introduces a unified framework, conceived to provide a comprehensive solution to these challenges. The proposed framework employs a bifurcated strategy tailored to the specific unlearning request. For fine-grained Meta Unlearning, it uses prototype gradients to direct the initial local forgetting process, which is then refined by generating adversarial graphs to eliminate any remaining data traces among affected clients. In the case of complete client unlearning, the framework utilizes adversarial graph generation exclusively to purge the departed clients contributions from the remaining network. Extensive experiments on multiple benchmark datasets validate the proposed approach. The framework achieves substantial improvements in model prediction accuracy across both client and meta-unlearning scenarios when compared to existing methods. Furthermore, additional studies confirm its utility as a plug-in module, where it materially enhances the predictive capabilities and unlearning effectiveness of other established methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02476v1" target="_blank">PoseGuard: Pose-Guided Generation with Safety Guardrails</a></h3>
                    <p><strong>Authors:</strong> Kongxin Wang, Jie Zhang, Peigui Qi, Kunsheng Tang, Tianwei Zhang, Wenbo Zhou</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Pose-guided video generation has become a powerful tool in creative industries, exemplified by frameworks like Animate Anyone. However, conditioning generation on specific poses introduces serious risks, such as impersonation, privacy violations, and NSFW content creation. To address these challenges, we propose $\textbf{PoseGuard}$, a safety alignment framework for pose-guided generation. PoseGuard is designed to suppress unsafe generations by degrading output quality when encountering malicious poses, while maintaining high-fidelity outputs for benign inputs. We categorize unsafe poses into three representative types: discriminatory gestures such as kneeling or offensive salutes, sexually suggestive poses that lead to NSFW content, and poses imitating copyrighted celebrity movements. PoseGuard employs a dual-objective training strategy combining generation fidelity with safety alignment, and uses LoRA-based fine-tuning for efficient, parameter-light updates. To ensure adaptability to evolving threats, PoseGuard supports pose-specific LoRA fusion, enabling flexible and modular updates when new unsafe poses are identified. We further demonstrate the generalizability of PoseGuard to facial landmark-guided generation. Extensive experiments validate that PoseGuard effectively blocks unsafe generations, maintains generation quality for benign inputs, and remains robust against slight pose variations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02473v1" target="_blank">An Efficient and Adaptive Next Edit Suggestion Framework with Zero Human Instructions in IDEs</a></h3>
                    <p><strong>Authors:</strong> Xinfang Chen, Siyang Xiao, Xianying Zhu, Junhong Xie, Ming Liang, Dajun Chen, Wei Jiang, Yong Li, Peng Di</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.LG, 68N30, D.2.3; D.1.2; I.2.2</p>
                    <p><strong>Summary:</strong> Code editing, including modifying, refactoring, and maintaining existing code, is the most frequent task in software development and has garnered significant attention from AI-powered tools. However, existing solutions that translate explicit natural language instructions into code edits face critical limitations, such as heavy reliance on human instruction input and high latency, which hinder their effective integration into a developers workflow. We observe that developers habitual behaviors and coding objectives are often reflected in their historical editing patterns, making this data key to addressing existing limitations. To leverage these insights, we propose NES (Next Edit Suggestion), an LLM-driven code editing framework that delivers an instruction-free and low-latency experience. Built on a dual-model architecture and trained with our high-quality SFT and DAPO datasets, NES enhances productivity by understanding developer intent while optimizing inference to minimize latency. NES is a scalable, industry-ready solution with a continuous Tab key interaction workflow, seamlessly adopted by a FinTech company with over 20,000 developers. Evaluations on real-world datasets show NES achieves 75.6% and 81.6% accuracy in two tasks of predicting next edit locations, alongside 91.36% ES and 27.7% EMR for intent-aligned edits, outperforming SOTA models. Our open-sourced SFT and DAPO datasets have been demonstrated to enhance the performance of open-source CodeLLMs. The demonstration of NES is available at https://youtu.be/yGoyYOe6fbY.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02470v1" target="_blank">AIAP: A No-Code Workflow Builder for Non-Experts with Natural Language and Multi-Agent Collaboration</a></h3>
                    <p><strong>Authors:</strong> Hyunjn An, Yongwon Kim, Wonduk Seo, Joonil Park, Daye Kang, Changhoon Oh, Dokyun Kim, Seunghyun Lee</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CL, cs.MA, cs.SE</p>
                    <p><strong>Summary:</strong> While many tools are available for designing AI, non-experts still face challenges in clearly expressing their intent and managing system complexity. We introduce AIAP, a no-code platform that integrates natural language input with visual workflows. AIAP leverages a coordinated multi-agent system to decompose ambiguous user instructions into modular, actionable steps, hidden from users behind a unified interface. A user study involving 32 participants showed that AIAPs AI-generated suggestions, modular workflows, and automatic identification of data, actions, and context significantly improved participants ability to develop services intuitively. These findings highlight that natural language-based visual programming significantly reduces barriers and enhances user experience in AI service design.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02454v1" target="_blank">Thwart Me If You Can: An Empirical Analysis of Android Platform Armoring Against Stalkerware</a></h3>
                    <p><strong>Authors:</strong> Malvika Jadhav, Wenxuan Bao, Vincent Bindschaedler</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Stalkerware is a serious threat to individuals privacy that is receiving increased attention from the security and privacy research communities. Existing works have largely focused on studying leading stalkerware apps, dual-purpose apps, monetization of stalkerware, or the experience of survivors. However, there remains a need to understand potential defenses beyond the detection-and-removal approach, which may not necessarily be effective in the context of stalkerware. In this paper, we perform a systematic analysis of a large corpus of recent Android stalkerware apps. We combine multiple analysis techniques to quantify stalkerware behaviors and capabilities and how these evolved over time. Our primary goal is understanding: how (and whether) recent Android platform changes -- largely designed to improve user privacy -- have thwarted stalkerware functionality; how stalkerware may have adapted as a result; and what we may conclude about potential defenses. Our investigation reveals new insights into tactics used by stalkerware and may inspire alternative defense strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02448v1" target="_blank">Charting 15 years of progress in deep learning for speech emotion recognition: A replication study</a></h3>
                    <p><strong>Authors:</strong> Andreas Triantafyllopoulos, Anton Batliner, BjÃ¶rn W. Schuller</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> Speech emotion recognition (SER) has long benefited from the adoption of deep learning methodologies. Deeper models -- with more layers and more trainable parameters -- are generally perceived as being `better by the SER community. This raises the question -- \emph{how much better} are modern-era deep neural networks compared to their earlier iterations? Beyond that, the more important question of how to move forward remains as poignant as ever. SER is far from a solved problem; therefore, identifying the most prominent avenues of future research is of paramount importance. In the present contribution, we attempt a quantification of progress in the 15 years of research beginning with the introduction of the landmark 2009 INTERSPEECH Emotion Challenge. We conduct a large scale investigation of model architectures, spanning both audio-based models that rely on speech inputs and text-baed models that rely solely on transcriptions. Our results point towards diminishing returns and a plateau after the recent introduction of transformer architectures. Moreover, we demonstrate how perceptions of progress are conditioned on the particular selection of models that are compared. Our findings have important repercussions about the state-of-the-art in SER research and the paths forward</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02439v1" target="_blank">Glioblastoma Overall Survival Prediction With Vision Transformers</a></h3>
                    <p><strong>Authors:</strong> Yin Lin, iccardo Barbieri, Domenico Aquino, Giuseppe Lauria, Marina Grisoli, Elena De Momi, Alberto Redaelli, Simona Ferrante</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Glioblastoma is one of the most aggressive and common brain tumors, with a median survival of 10-15 months. Predicting Overall Survival (OS) is critical for personalizing treatment strategies and aligning clinical decisions with patient outcomes. In this study, we propose a novel Artificial Intelligence (AI) approach for OS prediction using Magnetic Resonance Imaging (MRI) images, exploiting Vision Transformers (ViTs) to extract hidden features directly from MRI images, eliminating the need of tumor segmentation. Unlike traditional approaches, our method simplifies the workflow and reduces computational resource requirements. The proposed model was evaluated on the BRATS dataset, reaching an accuracy of 62.5% on the test set, comparable to the top-performing methods. Additionally, it demonstrated balanced performance across precision, recall, and F1 score, overcoming the best model in these metrics. The dataset size limits the generalization of the ViT which typically requires larger datasets compared to convolutional neural networks. This limitation in generalization is observed across all the cited studies. This work highlights the applicability of ViTs for downsampled medical imaging tasks and establishes a foundation for OS prediction models that are computationally efficient and do not rely on segmentation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02431v1" target="_blank">Identifying actionable driver mutations in lung cancer using an efficient Asymmetric Transformer Decoder</a></h3>
                    <p><strong>Authors:</strong> Biagio Brattoli, Jack Shi, Jongchan Park, Taebum Lee, Donggeun Yoo, Sergio Pereira</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Identifying actionable driver mutations in non-small cell lung cancer (NSCLC) can impact treatment decisions and significantly improve patient outcomes. Despite guideline recommendations, broader adoption of genetic testing remains challenging due to limited availability and lengthy turnaround times. Machine Learning (ML) methods for Computational Pathology (CPath) offer a potential solution; however, research often focuses on only one or two common mutations, limiting the clinical value of these tools and the pool of patients who can benefit from them. This study evaluates various Multiple Instance Learning (MIL) techniques to detect six key actionable NSCLC driver mutations: ALK, BRAF, EGFR, ERBB2, KRAS, and MET ex14. Additionally, we introduce an Asymmetric Transformer Decoder model that employs queries and key-values of varying dimensions to maintain a low query dimensionality. This approach efficiently extracts information from patch embeddings and minimizes overfitting risks, proving highly adaptable to the MIL setting. Moreover, we present a method to directly utilize tissue type in the model, addressing a typical MIL limitation where either all regions or only some specific regions are analyzed, neglecting biological relevance. Our method outperforms top MIL models by an average of 3%, and over 4% when predicting rare mutations such as ERBB2 and BRAF, moving ML-based tests closer to being practical alternatives to standard genetic testing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02430v1" target="_blank">AI-Based Measurement of Innovation: Mapping Expert Insight into Large Language Model Applications</a></h3>
                    <p><strong>Authors:</strong> Robin Nowak, Patrick Figge, Carolin Haeussler</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Measuring innovation often relies on context-specific proxies and on expert evaluation. Hence, empirical innovation research is often limited to settings where such data is available. We investigate how large language models (LLMs) can be leveraged to overcome the constraints of manual expert evaluations and assist researchers in measuring innovation. We design an LLM framework that reliably approximates domain experts assessment of innovation from unstructured text data. We demonstrate the performance and broad applicability of this framework through two studies in different contexts: (1) the innovativeness of software application updates and (2) the originality of user-generated feedback and improvement ideas in product reviews. We compared the performance (F1-score) and reliability (consistency rate) of our LLM framework against alternative measures used in prior innovation studies, and to state-of-the-art machine learning- and deep learning-based models. The LLM framework achieved higher F1-scores than the other approaches, and its results are highly consistent (i.e., results do not change across runs). This article equips RD personnel in firms, as well as researchers, reviewers, and editors, with the knowledge and tools to effectively use LLMs for measuring innovation and evaluating the performance of LLM-based innovation measures. In doing so, we discuss, the impact of important design decisions-including model selection, prompt engineering, training data size, training data distribution, and parameter settings-on performance and reliability. Given the challenges inherent in using human expert evaluation and existing text-based measures, our framework has important implications for harnessing LLMs as reliable, increasingly accessible, and broadly applicable research tools for measuring innovation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02429v1" target="_blank">Multimodal Large Language Models for End-to-End Affective Computing: Benchmarking and Boosting with Generative Knowledge Prompting</a></h3>
                    <p><strong>Authors:</strong> Miaosen Luo, Jiesen Long, Zequn Li, Yunying Yang, Yuncheng Jiang, Sijie Mai</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Multimodal Affective Computing (MAC) aims to recognize and interpret human emotions by integrating information from diverse modalities such as text, video, and audio. Recent advancements in Multimodal Large Language Models (MLLMs) have significantly reshaped the landscape of MAC by offering a unified framework for processing and aligning cross-modal information. However, practical challenges remain, including performance variability across complex MAC tasks and insufficient understanding of how architectural designs and data characteristics impact affective analysis. To address these gaps, we conduct a systematic benchmark evaluation of state-of-the-art open-source MLLMs capable of concurrently processing audio, visual, and textual modalities across multiple established MAC datasets. Our evaluation not only compares the performance of these MLLMs but also provides actionable insights into model optimization by analyzing the influence of model architectures and dataset properties. Furthermore, we propose a novel hybrid strategy that combines generative knowledge prompting with supervised fine-tuning to enhance MLLMs affective computing capabilities. Experimental results demonstrate that this integrated approach significantly improves performance across various MAC tasks, offering a promising avenue for future research and development in this field. Our code is released on https://github.com/LuoMSen/MLLM-MAC.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02427v1" target="_blank">CABENCH: Benchmarking Composable AI for Solving Complex Tasks through Composing Ready-to-Use Models</a></h3>
                    <p><strong>Authors:</strong> Tung-Thuy Pham, Duy-Quan Luong, Minh-Quan Duong, Trung-Hieu Nguyen, Thu-Trang Nguyen, Son Nguyen, Hieu Dinh Vo</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.SE</p>
                    <p><strong>Summary:</strong> Composable AI offers a scalable and effective paradigm for tackling complex AI tasks by decomposing them into sub-tasks and solving each sub-task using ready-to-use well-trained models. However, systematically evaluating methods under this setting remains largely unexplored. In this paper, we introduce CABENCH, the first public benchmark comprising 70 realistic composable AI tasks, along with a curated pool of 700 models across multiple modalities and domains. We also propose an evaluation framework to enable end-to-end assessment of composable AI solutions. To establish initial baselines, we provide human-designed reference solutions and compare their performance with two LLM-based approaches. Our results illustrate the promise of composable AI in addressing complex real-world problems while highlighting the need for methods that can fully unlock its potential by automatically generating effective execution pipelines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02426v1" target="_blank">Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding</a></h3>
                    <p><strong>Authors:</strong> Linyu Li, Zhi Jin, Yuanpeng He, Dongming Jin, Yichi Zhang, Haoran Duan, Nyima Tash</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Since knowledge graphs (KG) will continue to evolve in real scenarios, traditional KGE models are only suitable for static knowledge graphs. Therefore, continual knowledge graph embedding (CKGE) has attracted the attention of researchers. Currently, a key challenge facing CKGE is that the model is prone to catastrophic forgetting, resulting in the loss of previously learned knowledge. In order to effectively alleviate this problem, we propose a new CKGE model BAKE. First, we note that the Bayesian posterior update principle provides a natural continual learning strategy that is insensitive to data order and can theoretically effectively resist the forgetting of previous knowledge during data evolution. Different from the existing CKGE method, BAKE regards each batch of new data as a Bayesian update of the model prior. Under this framework, as long as the posterior distribution of the model is maintained, the model can better preserve the knowledge of early snapshots even after evolving through multiple time snapshots. Secondly, we propose a continual clustering method for CKGE, which further directly combats knowledge forgetting by constraining the evolution difference (or change amplitude) between new and old knowledge between different snapshots. We conduct extensive experiments on BAKE on multiple datasets, and the results show that BAKE significantly outperforms existing baseline models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02425v1" target="_blank">Multi-Class Human/Object Detection on Robot Manipulators using Proprioceptive Sensing</a></h3>
                    <p><strong>Authors:</strong> Justin Hehli, Marco Heiniger, Maryam Rezayati, Hans Wernher van de Venn</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI</p>
                    <p><strong>Summary:</strong> In physical human-robot collaboration (pHRC) settings, humans and robots collaborate directly in shared environments. Robots must analyze interactions with objects to ensure safety and facilitate meaningful workflows. One critical aspect is human/object detection, where the contacted object is identified. Past research introduced binary machine learning classifiers to distinguish between soft and hard objects. This study improves upon those results by evaluating three-class human/object detection models, offering more detailed contact analysis. A dataset was collected using the Franka Emika Panda robot manipulator, exploring preprocessing strategies for time-series analysis. Models including LSTM, GRU, and Transformers were trained on these datasets. The best-performing model achieved 91.11\% accuracy during real-time testing, demonstrating the feasibility of multi-class detection models. Additionally, a comparison of preprocessing strategies suggests a sliding window approach is optimal for this task.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02423v1" target="_blank">Evolutionary Paradigms in Histopathology Serial Sections technology</a></h3>
                    <p><strong>Authors:</strong> Zhenfeng Zhuang, Min Cen, Lei Jiang, Qiong Peng, Yihuang Hu, Hong-Yu Zhou, Liansheng Wang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> q-bio.TO</p>
                    <p><strong>Summary:</strong> Histopathological analysis has been transformed by serial section-based methods, advancing beyond traditional 2D histology to enable volumetric and microstructural insights in oncology and inflammatory disease diagnostics. This review outlines key developments in specimen preparation and high-throughput imaging that support these innovations. Computational workflows are categorized into multimodal image co-registration, 3D histoarchitecture reconstruction, multiplexed immunohistochemical correlation, and cross-scale data fusion. These approaches exploit serial section-derived spatial concordance to enhance resolution in microenvironmental and molecular profiling. Despite progress, challenges remain in harmonizing heterogeneous datasets, optimizing large-scale registration, and ensuring interpretability. Future directions include spatial transcriptomics, and applications in developmental biology and neuroscience in AI integration, establishing serial section analytics as central to precision histopathology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02411v1" target="_blank">HGTS-Former: Hierarchical HyperGraph Transformer for Multivariate Time Series Analysis</a></h3>
                    <p><strong>Authors:</strong> Xiao Wang, Hao Si, Fan Zhang, Xiaoya Zhou, Dengdi Sun, Wanli Lyu, Qingquan Yang, Jin Tang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Multivariate time series analysis has long been one of the key research topics in the field of artificial intelligence. However, analyzing complex time series data remains a challenging and unresolved problem due to its high dimensionality, dynamic nature, and complex interactions among variables. Inspired by the strong structural modeling capability of hypergraphs, this paper proposes a novel hypergraph-based time series transformer backbone network, termed HGTS-Former, to address the multivariate coupling in time series data. Specifically, given the multivariate time series signal, we first normalize and embed each patch into tokens. Then, we adopt the multi-head self-attention to enhance the temporal representation of each patch. The hierarchical hypergraphs are constructed to aggregate the temporal patterns within each channel and fine-grained relations between different variables. After that, we convert the hyperedge into node features through the EdgeToNode module and adopt the feed-forward network to further enhance the output features. Extensive experiments conducted on two multivariate time series tasks and eight datasets fully validated the effectiveness of our proposed HGTS-Former. The source code will be released on https://github.com/Event-AHU/Time_Series_Analysis.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3636534.3690662" target="_blank">Hydra: Accurate Multi-Modal Leaf Wetness Sensing with mm-Wave and Camera Fusion</a></h3>
                    <p><strong>Authors:</strong> Yimeng Liu, Maolin Gan, Huaili Zeng, Li Liu, Younsuk Dong, Zhichao Cao</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Leaf Wetness Duration (LWD), the time that water remains on leaf surfaces, is crucial in the development of plant diseases. Existing LWD detection lacks standardized measurement techniques, and variations across different plant characteristics limit its effectiveness. Prior research proposes diverse approaches, but they fail to measure real natural leaves directly and lack resilience in various environmental conditions. This reduces the precision and robustness, revealing a notable practical application and effectiveness gap in real-world agricultural settings. This paper presents Hydra, an innovative approach that integrates millimeter-wave (mm-Wave) radar with camera technology to detect leaf wetness by determining if there is water on the leaf. We can measure the time to determine the LWD based on this detection. Firstly, we design a Convolutional Neural Network (CNN) to selectively fuse multiple mm-Wave depth images with an RGB image to generate multiple feature images. Then, we develop a transformer-based encoder to capture the inherent connection among the multiple feature images to generate a feature map, which is further fed to a classifier for detection. Moreover, we augment the dataset during training to generalize our model. Implemented using a frequency-modulated continuous-wave (FMCW) radar within the 76 to 81 GHz band, Hydras performance is meticulously evaluated on plants, demonstrating the potential to classify leaf wetness with up to 96% accuracy across varying scenarios. Deploying Hydra in the farm, including rainy, dawn, or poorly light nights, it still achieves an accuracy rate of around 90%.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02403v1" target="_blank">SoK: Stablecoins for Digital Transformation -- Design, Metrics, and Application with Real World Asset Tokenization as a Case Study</a></h3>
                    <p><strong>Authors:</strong> Luyao Zhang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Stablecoins have become a foundational component of the digital asset ecosystem, with their market capitalization exceeding 230 billion USD as of May 2025. As fiat-referenced and programmable assets, stablecoins provide low-latency, globally interoperable infrastructure for payments, decentralized finance, DeFi, and tokenized commerce. Their accelerated adoption has prompted extensive regulatory engagement, exemplified by the European Unions Markets in Crypto-assets Regulation, MiCA, the US Guiding and Establishing National Innovation for US Stablecoins Act, GENIUS Act, and Hong Kongs Stablecoins Bill. Despite this momentum, academic research remains fragmented across economics, law, and computer science, lacking a unified framework for design, evaluation, and application. This study addresses that gap through a multi-method research design. First, it synthesizes cross-disciplinary literature to construct a taxonomy of stablecoin systems based on custodial structure, stabilization mechanism, and governance. Second, it develops a performance evaluation framework tailored to diverse stakeholder needs, supported by an open-source benchmarking pipeline to ensure transparency and reproducibility. Third, a case study on Real World Asset tokenization illustrates how stablecoins operate as programmable monetary infrastructure in cross-border digital systems. By integrating conceptual theory with empirical tools, the paper contributes: a unified taxonomy for stablecoin design; a stakeholder-oriented performance evaluation framework; an empirical case linking stablecoins to sectoral transformation; and reproducible methods and datasets to inform future research. These contributions support the development of trusted, inclusive, and transparent digital monetary infrastructure.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02400v1" target="_blank">Combining machine learning with data assimilation to improve the quality of phytoplankton forecasting in a shelf sea environment</a></h3>
                    <p><strong>Authors:</strong> Deep S Banerjee, Jozef Skakala, David Ford</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> q-bio.QM</p>
                    <p><strong>Summary:</strong> We demonstrate that combining machine learning with data assimilation leads to a major improvement in phytoplankton short-range (1-5 day) forecasts for the North-West European Shelf (NWES) seas. We show that excess nitrate concentrations are a major reason behind known biases in phytoplankton forecasts during late Spring and Summer, which can grow fast with lead time. Assimilating observations of nitrate would potentially help address this, but NWES nitrate data are typically not available in sufficient abundance to be effectively assimilated. We have therefore used a recently developed and validated neural network (NN) model predicting surface nitrate concentrations from a range of observable variables and implemented its assimilation within a research and development version of the Met Offices NWES operational forecasting system. As a result of nitrate assimilation the phytoplankton forecast skill improves by up to 30%. We show that although much of this improvement can be achieved by using a weekly nitrate climatology predicted by the NN model, there is a clear advantage in using flow-dependent nitrate data. We discuss the impacts of this improvement on a range of additional eutrophication indicators, such as dissolved inorganic phosphorus and sea bottom oxygen. We argue that it should be feasible to implement this hybrid machine learning - data assimilation approach within the near-real time NWES operational forecasting system.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1103/xbvn-5b59" target="_blank">Oscillating chemical reactions enable communication between responsive hydrogels</a></h3>
                    <p><strong>Authors:</strong> Joseph J. Webber, Thomas D. Montenegro-Johnson</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft</p>
                    <p><strong>Summary:</strong> Responsive hydrogels can sense environmental stimuli and respond as actuators by expelling water and changing shape. In this article, we develop theory to demonstrate that groups of responsive hydrogels can also communicate with each other, by utilising the effect of elastic deformation on chemical reaction dynamics. Specifically, we consider a system of two spatially-separated chemically responsive hydrogels suspended in a solution in which a Belousov-Zhabotinsky (BZ)-type reaction occurs. Solving for the gel dynamics with the transport of solvent through the poroelastic network and the chemical kinetics, we show how the periodic swelling-deswelling oscillations of each gel can become coupled, and how this coupling can be exploited to send signals from one gel to the other via mechanical manipulation of the sender that affect the local (and thus global) frequency of oscillation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02672v1" target="_blank">Super-Penrose $\And$ Witten Transforms for SCFT$_3$</a></h3>
                    <p><strong>Authors:</strong> Deep Mazumdar</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> The study of three dimensional CFT correlators in twistor space has recently garnered a significant interest. Conformal symmetry acts linearly in the twistor space, which streamlines the analysis. Moreover, twistors provide a connection to the position and momentum space through the Penrose and Witten transforms, respectively. In this work, we develop the supersymmetric versions of Penrose and Witten transforms for three dimensional superconformal field theories for $\mathcal{N}=1\;\textrm{to}\;4$. We derive two and three point functions in the position and momentum superspace for the $\mathcal{N}=1$ scenario using these transforms. Extending this setup to higher supersymmetries turns out to be a simple extension of the $\mathcal{N}=1$ case, which aligns with the inherent simplicity of supertwistors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02669v1" target="_blank">MedVLThinker: Simple Baselines for Multimodal Medical Reasoning</a></h3>
                    <p><strong>Authors:</strong> Xiaoke Huang, Juncheng Wu, Hui Liu, Xianfeng Tang, Yuyin Zhou</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to ``think before responding via chain-of-thought reasoning. However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and comparison. In this paper, we present MedVLThinker, a suite of simple yet strong baselines. Our fully open recipe consists of: (1) systematic data curation for both text-only and image-text medical data, filtered according to varying levels of reasoning difficulty, and (2) two training paradigms: Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement Learning with Verifiable Rewards (RLVR) based on final answer correctness. Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six medical QA benchmarks, we find that RLVR consistently and significantly outperforms SFT. Additionally, under the RLVR framework, a key, counter-intuitive finding is that training on our curated text-only reasoning data provides a more substantial performance boost than training on multimodal image-text data. Our best open 7B model, trained using the RLVR recipe on text-only data, establishes a new state-of-the-art on existing public VQA benchmarks, surpassing all previous open-source medical LMMs. Furthermore, scaling our model to 32B achieves performance on par with the proprietary GPT-4o. We release all curated data, models, and code to provide the community with a strong, open foundation for future research in multimodal medical reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02650v1" target="_blank">Design and demonstration of a direct air capture system with moisture-driven CO2 delivery into aqueous medium</a></h3>
                    <p><strong>Authors:</strong> Justin Flory, Samantha Taylor, Shuqin Li, Sunil Tiwari, Garrett Cole, Amory Lowe, Lindsey Hamblin, Samuel Piorkowski, Matthew Ryan, Thiago Stangherlin Barbosa, Jason Kmon, Nick Lowery, Joel Eliston, Jason C. Quinn, John McGowen, Matthew D. Green, Klaus Lackner, Wim Vermaas</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft, cond-mat.mtrl-sci, cond-mat.other</p>
                    <p><strong>Summary:</strong> A moisture-driven air capture (DAC) system was designed and demonstrated. A laboratory-scale system delivering ~1 g CO2 per day was demonstrated in a laminar flow hood and a small pilot-scale system that could deliver ~100 g CO2 daily was operated outdoors in a 4.2 m2 (areal surface area) raceway pond. Elongated mesh tube packets were designed to contain AER beads with high surface area for contacting the air and were found to reduce drying and CO2 loading time ~4-fold over larger mesh bags. Whereas this system was designed for CO2 delivery for cultivating photosynthetic microbes, its potential uses are much broader and include CO2 use in the food and beverage industry, conversion to fuels and chemicals, and sequestration. Techno-economic assessments for a practical scenario based on current results are \$670/tonne to capture CO2 into an alkaline solution and an additional \$280/tonne to extract CO2 from solution, purify and compress to 15 MPa for sequestration. An aspirational scenario modelling reasonable improvements to develop AER sorbents with a capacity of 4 mmol CO2 per gram of sorbent and water uptake of 50 wt.%, which leads to sorbent drying and loading within 1 h, shows a potential to reach \$51/tonne to capture CO2 into an alkaline solution and an additional \$109/tonne to get to 15 MPa for sequestration. Life cycle analysis shows the aspirational moisture-driven process uses up to 87% less energy than thermal and/or vacuum swing DAC by using energy from water evaporation; however, ~330 wt.% water uptake by the sorbent contained in a hydrophilic mesh packets leads to ~33-fold higher water use than the thermodynamic limits, which emphasizes future research is needed to increase sorbent hydrophobicity while maintaining and further increasing ion exchange capacity needed to bind CO2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02643v1" target="_blank">CAK: Emergent Audio Effects from Minimal Deep Learning</a></h3>
                    <p><strong>Authors:</strong> Austin Rockman</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> We demonstrate that a single 3x3 convolutional kernel can produce emergent audio effects when trained on 200 samples from a personalized corpus. We achieve this through two key techniques: (1) Conditioning Aware Kernels (CAK), where output = input + (learned_pattern x control), with a soft-gate mechanism supporting identity preservation at zero control; and (2) AuGAN (Audit GAN), which reframes adversarial training from is this real? to did you apply the requested value? Rather than learning to generate or detect forgeries, our networks cooperate to verify control application, discovering unique transformations. The learned kernel exhibits a diagonal structure creating frequency-dependent temporal shifts that are capable of producing musical effects based on input characteristics. Our results show the potential of adversarial training to discover audio transformations from minimal data, enabling new approaches to effect design.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02639v1" target="_blank">Reframing Pattern: A Comprehensive Approach to a Composite Visual Variable</a></h3>
                    <p><strong>Authors:</strong> Tingying He, Jason Dykes, Petra Isenberg, Tobias Isenberg</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> We present a new comprehensive theory for explaining, exploring, and using pattern as a visual variable in visualization. Although patterns have long been used for data encoding and continue to be valuable today, their conceptual foundations are precarious: the concepts and terminology used across the research literature and in practice are inconsistent, making it challenging to use patterns effectively and to conduct research to inform their use. To address this problem, we conduct a comprehensive cross-disciplinary literature review that clarifies ambiguities around the use of pattern and texture. As a result, we offer a new consistent treatment of pattern as a composite visual variable composed of structured groups of graphic primitives that can serve as marks for encoding data individually and collectively. This new and widely applicable formulation opens a sizable design space for the visual variable pattern, which we formalize as a new system comprising three sets of variables: the spatial arrangement of primitives, the appearance relationships among primitives, and the retinal visual variables that characterize individual primitives. We show how our pattern system relates to existing visualization theory and highlight opportunities for visualization design. We further explore patterns based on complex spatial arrangements, demonstrating explanatory power and connecting our conceptualization to broader theory on maps and cartography. An author version and additional materials are available on OSF: osf.io/z7ae2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02631v1" target="_blank">Pointer: Linear-Complexity Long-Range Modeling without Pre-training</a></h3>
                    <p><strong>Authors:</strong> Zixi Li</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We introduce Pointer, a novel architecture that achieves linear $O(NK)$ complexity for long-range sequence modeling while maintaining superior performance without requiring pre-training. Unlike standard attention mechanisms that compute $O(N^2)$ pairwise interactions, our approach uses layer-wise pointer chaining where each layers pointer selection depends on previous layers pointer positions, creating explicit long-distance connections through pointer chains. We demonstrate that this architecture achieves $2$--$10\times$ speedup on long sequences compared to standard transformers, maintains $95\%$ accuracy on copy tasks at distances up to 2048 tokens, and learns interpretable pointer patterns that reveal structured dependency modeling. Our experiments on efficiency benchmarks, long-range dependency tasks, and interpretability analysis show that Pointer offers a compelling alternative to attention mechanisms for scenarios requiring efficient long-range modeling without pre-training dependencies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02630v1" target="_blank">What Is Your AI Agent Buying? Evaluation, Implications and Emerging Questions for Agentic E-Commerce</a></h3>
                    <p><strong>Authors:</strong> Amine Allouah, Omar Besbes, JosuÃ© D Figueroa, Yash Kanoria, Akshit Kumar</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY, cs.HC, cs.MA, econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Online marketplaces will be transformed by autonomous AI agents acting on behalf of consumers. Rather than humans browsing and clicking, vision-language-model (VLM) agents can parse webpages, evaluate products, and transact. This raises a fundamental question: what do AI agents buy, and why? We develop ACES, a sandbox environment that pairs a platform-agnostic VLM agent with a fully programmable mock marketplace to study this question. We first conduct basic rationality checks in the context of simple tasks, and then, by randomizing product positions, prices, ratings, reviews, sponsored tags, and platform endorsements, we obtain causal estimates of how frontier VLMs actually shop. Models show strong but heterogeneous position effects: all favor the top row, yet different models prefer different columns, undermining the assumption of a universal top rank. They penalize sponsored tags and reward endorsements. Sensitivities to price, ratings, and reviews are directionally human-like but vary sharply in magnitude across models. Motivated by scenarios where sellers use AI agents to optimize product listings, we show that a seller-side agent that makes minor tweaks to product descriptions, targeting AI buyer preferences, can deliver substantial market-share gains if AI-mediated shopping dominates. We also find that modal product choices can differ across models and, in some cases, demand may concentrate on a few select products, raising competition questions. Together, our results illuminate how AI agents may behave in e-commerce settings and surface concrete seller strategy, platform design, and regulatory questions in an AI-mediated ecosystem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02622v1" target="_blank">Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction</a></h3>
                    <p><strong>Authors:</strong> Enrico De Santis, Antonello Rizzi</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> This paper introduces and formalizes Noosemia, a novel cognitive-phenomenological phenomenon emerging from human interaction with generative AI systems, particularly those enabling dialogic or multimodal exchanges. We propose a multidisciplinary framework to explain how, under certain conditions, users attribute intentionality, agency, and even interiority to these systems - a process grounded not in physical resemblance, but in linguistic performance, epistemic opacity, and emergent technological complexity. By linking an LLM declination of meaning holism to our technical notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct meaning relationally and how coherence and a simulacrum of agency arise at the human-AI interface. The analysis situates noosemia alongside pareidolia, animism, the intentional stance and the uncanny valley, distinguishing its unique characteristics. We also introduce a-noosemia to describe the phenomenological withdrawal of such projections. The paper concludes with reflections on the broader philosophical, epistemological, and social implications of noosemic dynamics and directions for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02621v1" target="_blank">HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research</a></h3>
                    <p><strong>Authors:</strong> Yinghao Zhu, Yifan Qi, Zixiang Wang, Lei Gu, Dehao Sui, Haoran Hu, Xichen Zhang, Ziyi He, Liantao Ma, Lequan Yu</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG, cs.MA</p>
                    <p><strong>Summary:</strong> The efficacy of AI agents in healthcare research is hindered by their reliance on static, predefined strategies. This creates a critical limitation: agents can become better tool-users but cannot learn to become better strategic planners, a crucial skill for complex domains like healthcare. We introduce HealthFlow, a self-evolving AI agent that overcomes this limitation through a novel meta-level evolution mechanism. HealthFlow autonomously refines its own high-level problem-solving policies by distilling procedural successes and failures into a durable, strategic knowledge base. To anchor our research and facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark featuring complex, realistic health data analysis tasks derived from peer-reviewed clinical research. Our comprehensive experiments demonstrate that HealthFlows self-evolving approach significantly outperforms state-of-the-art agent frameworks. This work marks a necessary shift from building better tool-users to designing smarter, self-evolving task-managers, paving the way for more autonomous and effective AI for scientific discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02618v1" target="_blank">Mitigating Attention Hacking in Preference-Based Reward Modeling via Interaction Distillation</a></h3>
                    <p><strong>Authors:</strong> Jianxiang Zang, Meiling Ning, Shihan Dou, Jiazheng Zhang, Tao Gui, Qi Zhang, Xuanjing Huang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The reward model (RM), as the core component of reinforcement learning from human feedback (RLHF) for large language models (LLMs), responsible for providing reward signals to generated responses. However, mainstream preference modeling in RM is inadequate in terms of token-level interaction, making its judgment signals vulnerable to being hacked by misallocated attention to context. This stems from two fundamental limitations: (1) Current preference modeling employs decoder-only architectures, where the unidirectional causal attention mechanism leads to forward-decaying intra-sequence attention within the prompt-response sequence. (2) The independent Siamese-encoding paradigm induces the absence of token-level inter-sequence attention between chosen and rejected sequences. To address this attention hacking, we propose Interaction Distillation, a novel training framework for more adequate preference modeling through attention-level optimization. The method introduces an interaction-based natural language understanding model as the teacher to provide sophisticated token interaction patterns via comprehensive attention, and guides the preference modeling to simulate teacher models interaction pattern through an attentional alignment objective. Through extensive experiments, interaction distillation has demonstrated its ability to provide more stable and generalizable reward signals compared to state-of-the-art RM optimization methods that target data noise, highlighting the attention hacking constitute a more fundamental limitation in RM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02617v1" target="_blank">Vision-based Navigation of Unmanned Aerial Vehicles in Orchards: An Imitation Learning Approach</a></h3>
                    <p><strong>Authors:</strong> Peng Wei, Prabhash Ragbir, Stavros G. Vougioukas, Zhaodan Kong</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Autonomous unmanned aerial vehicle (UAV) navigation in orchards presents significant challenges due to obstacles and GPS-deprived environments. In this work, we introduce a learning-based approach to achieve vision-based navigation of UAVs within orchard rows. Our method employs a variational autoencoder (VAE)-based controller, trained with an intervention-based learning framework that allows the UAV to learn a visuomotor policy from human experience. We validate our approach in real orchard environments with a custom-built quadrotor platform. Field experiments demonstrate that after only a few iterations of training, the proposed VAE-based controller can autonomously navigate the UAV based on a front-mounted camera stream. The controller exhibits strong obstacle avoidance performance, achieves longer flying distances with less human assistance, and outperforms existing algorithms. Furthermore, we show that the policy generalizes effectively to novel environments and maintains competitive performance across varying conditions and speeds. This research not only advances UAV autonomy but also holds significant potential for precision agriculture, improving efficiency in orchard monitoring and management.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02614v1" target="_blank">Work extraction from long-lived quantum coherence of a three-level system</a></h3>
                    <p><strong>Authors:</strong> Wenjing Chen, Si-Wei Han, Xiaoshan Feng, Jun Feng</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We analyze work extraction protocols using the long-lived quantum coherence of a three-level quantum system, which is coupled to a thermal bath through dipole-monopole interactions. We identify situations where persistent quantum coherence arises, i.e., for systems with degenerate excited states with aligned transition dipoles or nearly degenerate systems with small energy splittings. By designing two innovative thermodynamic protocols involving energy-preserving unitary operations, we show that quantum coherence can be transformed into population asymmetry, serving as a quantum resource for work extraction. As the system approaches final thermal equilibrium, the initial quantum coherence effectively acts as fuel, being progressively consumed. Specifically, we propose an optimized protocol capable of extracting the maximal extractable work (MEW), measured by the free energy difference (FED), from quantum coherence in a single-shot thermodynamic cycle. Our results highlight the thermodynamic advantages of long-lived coherence in a three-level quantum system and could influence future designs of coherence-driven quantum thermal machines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02611v1" target="_blank">Meta-RAG on Large Codebases Using Code Summarization</a></h3>
                    <p><strong>Authors:</strong> Vali Tawosia, Salwa Alamir, Xiaomo Liu, Manuela Veloso</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM) systems have been at the forefront of applied Artificial Intelligence (AI) research in a multitude of domains. One such domain is software development, where researchers have pushed the automation of a number of code tasks through LLM agents. Software development is a complex ecosystem, that stretches far beyond code implementation and well into the realm of code maintenance. In this paper, we propose a multi-agent system to localize bugs in large pre-existing codebases using information retrieval and LLMs. Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. We then use an LLM agent to determine which parts of the codebase are critical for bug resolution, i.e. bug localization. We demonstrate the usefulness of Meta-RAG through evaluation with the SWE-bench Lite dataset. Meta-RAG scores 84.67 % and 53.0 % for file-level and function-level correct localization rates, respectively, achieving state-of-the-art performance.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3663547.3746365" target="_blank">PunchPulse: A Physically Demanding Virtual Reality Boxing Game Designed with, for and by Blind and Low-Vision Players</a></h3>
                    <p><strong>Authors:</strong> Sanchita S. Kamath, Omar Khan, Anurag Choudhary, Jan Meyerhoff-Liang, Soyoung Choi, JooYoung Seo</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Blind and low-vision (BLV) individuals experience lower levels of physical activity (PA) compared to sighted peers due to a lack of accessible, engaging exercise options. Existing solutions often rely on auditory cues but do not fully integrate rich sensory feedback or support spatial navigation, limiting their effectiveness. This study introduces PunchPulse, a virtual reality (VR) boxing exergame designed to motivate BLV users to reach and sustain moderate to vigorous physical activity (MVPA) levels. Over a seven-month, multi-phased study, PunchPulse was iteratively refined with three BLV co-designers, informed by two early pilot testers, and evaluated by six additional BLV user-study participants. Data collection included both qualitative (researcher observations, SOPI) and quantitative (MVPA zones, aid usage, completion times) measures of physical exertion and gameplay performance. The user study revealed that all participants reached moderate MVPA thresholds, with high levels of immersion and engagement observed. This work demonstrates the potential of VR as an inclusive medium for promoting meaningful PA in the BLV community and addresses a critical gap in accessible, intensity-driven exercise interventions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02606v1" target="_blank">Interface Structure and Electronic Properties in Cubic Boron Nitride - Diamond Heterostructures</a></h3>
                    <p><strong>Authors:</strong> Cody L. Milne, Hector Gomez, Adway Gupta, A. Glen Birdwell, Sergey Rudin, Elias J. Garratt, Bradford B. Pate, Tony G. Ivanov, Arunima K. Singh, Mahesh R. Neupane</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Heterointerfaces of cubic boron nitride (cBN) with diamond have garnered significant interest due to their ultra-wide bandgaps and small lattice mismatch ($\sim1.5$\%), offering promising advancements in high-power and high-frequency electronic devices. However, the realization of this heterointerface has been limited by challenging growth conditions and insufficient understanding of interfacial properties. In this work, we employ density-functional theory to investigate the structural and electronic properties of diamond/cBN heterostructures as a function of interfacial stoichiometry, cBN thickness, and surface termination and passivation. Formation energies and interfacial bond lengths reveal that boron-terminated heterojunctions are the most stable while abrupt nitrogen-terminated heterojunctions are least stable, but can be stabilized by carbon-mixing. Bandstructures are computed for the heterostructures using hybrid functionals, where we find the abrupt boron-terminated and nitrogen-terminated heterojunctions exhibit $p$-type and $n$-type conductivity, respectively, while carbon-mixed heterojunctions retain wide insulating bandgaps ($4.2-4.4$ eV). The effective masses of the abrupt interfaces are found to vary strongly with stoichiometry. Intriguingly, charge analysis reveals two-dimensional electron or hole gas regions with ultra-high densities on the order of $10^{14}$ cm$^{-2}$, with distinct spatial localization on either side of the interface. Band alignments show type-I and type-II band offsets tunable by interfacial composition. Further analysis of the band alignments reveals that the diamond valence bands consistently lie above the cBN valence bands by $0.25-2.1$ eV. Interestingly, the interface termination type switches the relative conduction band position of diamond relative to the cBN conduction band, exhibiting a type-I to type-II band alignment transition.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02605v1" target="_blank">ReMoMask: Retrieval-Augmented Masked Motion Generation</a></h3>
                    <p><strong>Authors:</strong> Zhengdao Li, Siheng Wang, Zeyu Zhang, Hao Tang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-Motion (T2M) generation aims to synthesize realistic and semantically aligned human motion sequences from natural language descriptions. However, current approaches face dual challenges: Generative models (e.g., diffusion models) suffer from limited diversity, error accumulation, and physical implausibility, while Retrieval-Augmented Generation (RAG) methods exhibit diffusion inertia, partial-mode collapse, and asynchronous artifacts. To address these limitations, we propose ReMoMask, a unified framework integrating three key innovations: 1) A Bidirectional Momentum Text-Motion Model decouples negative sample scale from batch size via momentum queues, substantially improving cross-modal retrieval precision; 2) A Semantic Spatio-temporal Attention mechanism enforces biomechanical constraints during part-level fusion to eliminate asynchronous artifacts; 3) RAG-Classier-Free Guidance incorporates minor unconditional generation to enhance generalization. Built upon MoMasks RVQ-VAE, ReMoMask efficiently generates temporally coherent motions in minimal steps. Extensive experiments on standard benchmarks demonstrate the state-of-the-art performance of ReMoMask, achieving a 3.88% and 10.97% improvement in FID scores on HumanML3D and KIT-ML, respectively, compared to the previous SOTA method RAG-T2M. Code: https://github.com/AIGeeksGroup/ReMoMask. Website: https://aigeeksgroup.github.io/ReMoMask.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02602v1" target="_blank">Trustworthy scientific inference for inverse problems with generative models</a></h3>
                    <p><strong>Authors:</strong> James Carzon, Luca Masserano, Joshua D. Ingram, Alex Shen, Antonio Carlos Herling Ribeiro Junior, Tommaso Dorigo, Michele Doro, Joshua S. Speagle, Rafael Izbicki, Ann B. Lee</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> stat.ML, astro-ph.IM, cs.LG, stat.AP, stat.ME</p>
                    <p><strong>Summary:</strong> Generative artificial intelligence (AI) excels at producing complex data structures (text, images, videos) by learning patterns from training examples. Across scientific disciplines, researchers are now applying generative models to ``inverse problems to infer hidden parameters from observed data. While these methods can handle intractable models and large-scale studies, they can also produce biased or overconfident conclusions. We present a solution with Frequentist-Bayes (FreB), a mathematically rigorous protocol that reshapes AI-generated probability distributions into confidence regions that consistently include true parameters with the expected probability, while achieving minimum size when training and target data align. We demonstrate FreBs effectiveness by tackling diverse case studies in the physical sciences: identifying unknown sources under dataset shift, reconciling competing theoretical models, and mitigating selection bias and systematics in observational studies. By providing validity guarantees with interpretable diagnostics, FreB enables trustworthy scientific inference across fields where direct likelihood evaluation remains impossible or prohibitively expensive.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1063/5.0272970" target="_blank">Molecular Processes as Quantum Information Resources</a></h3>
                    <p><strong>Authors:</strong> Saikat Sur, Pritam Chattopadhyay, Gershon Kurizki</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> In this contribution to Abraham Nitzans Festschrift, we present a perspective of theoretical research over the years that has pointed to the potential of molecular processes to act as quantum information resources. Under appropriate control, homonuclear dimer (diatom) dissociation (half-collision) and the inverse process of atom-pair collisions are shown to reveal translational (EPR-like) entanglement that enables molecular wavepacket teleportation. When such processes involve electronic-state excitation of the diatom, the fluorescence following dissociation can serve as an entanglement witness that unravels the molecular-state characteristics and evolution. Such entangling processes can also exhibit anomalous quantum thermodynamic features, particularly temperature enhancement of a cavity field that interacts with dissociated entangled diatoms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02593v1" target="_blank">Explainable AI for Automated User-specific Feedback in Surgical Skill Acquisition</a></h3>
                    <p><strong>Authors:</strong> Catalina Gomez, Lalithkumar Seenivasan, Xinrui Zou, Jeewoo Yoon, Sirui Chu, Ariel Leong, Patrick Kramer, Yu-Chun Ku, Jose L. Porras, Alejandro Martin-Gomez, Masaru Ishii, Mathias Unberath</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> Traditional surgical skill acquisition relies heavily on expert feedback, yet direct access is limited by faculty availability and variability in subjective assessments. While trainees can practice independently, the lack of personalized, objective, and quantitative feedback reduces the effectiveness of self-directed learning. Recent advances in computer vision and machine learning have enabled automated surgical skill assessment, demonstrating the feasibility of automatic competency evaluation. However, it is unclear whether such Artificial Intelligence (AI)-driven feedback can contribute to skill acquisition. Here, we examine the effectiveness of explainable AI (XAI)-generated feedback in surgical training through a human-AI study. We create a simulation-based training framework that utilizes XAI to analyze videos and extract surgical skill proxies related to primitive actions. Our intervention provides automated, user-specific feedback by comparing trainee performance to expert benchmarks and highlighting deviations from optimal execution through understandable proxies for actionable guidance. In a prospective user study with medical students, we compare the impact of XAI-guided feedback against traditional video-based coaching on task outcomes, cognitive load, and trainees perceptions of AI-assisted learning. Results showed improved cognitive load and confidence post-intervention. While no differences emerged between the two feedback types in reducing performance gaps or practice adjustments, trends in the XAI group revealed desirable effects where participants more closely mimicked expert practice. This work encourages the study of explainable AI in surgical education and the development of data-driven, adaptive feedback mechanisms that could transform learning experiences and competency assessment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02587v1" target="_blank">Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands Mixture of Adaptation Modules</a></h3>
                    <p><strong>Authors:</strong> Yilun Liu, Yunpu Ma, Yuetian Lu, Shuo Chen, Zifeng Ding, Volker Tresp</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among their specialized experts, which existing Parameter- Efficient Fine-Tuning (PEFT) strategies fail to leverage. This motivates us to investigate whether adaptation modules themselves should incorporate routing mechanisms to align with MoEs multi-expert architecture. We analyze dynamics of core components when applying PEFT to MoE language models and examine how different routing strategies affect adaptation effectiveness. Extensive experiments adapting OLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks validate the performance and efficiency of our routed approach. We identify the optimal configurations for different scenarios and provide empirical analyses with practical insights to facilitate better PEFT and MoE applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02583v1" target="_blank">CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge</a></h3>
                    <p><strong>Authors:</strong> Lei Zan, Keli Zhang, Ruichu Cai, Lujia Pan</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have demonstrated strong performance across a wide range of tasks, yet they still struggle with complex mathematical reasoning, a challenge fundamentally rooted in deep structural dependencies. To address this challenge, we propose \textbf{CA}usal \textbf{MA}thematician (\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit, reusable mathematical structure. In the learning stage, CAMA first constructs the \textbf{M}athematical \textbf{C}ausal \textbf{G}raph (\textbf{MCG}), a high-level representation of solution strategies, by combining LLM priors with causal discovery algorithms applied to a corpus of question-solution pairs. The resulting MCG encodes essential knowledge points and their causal dependencies. To better align the graph with downstream reasoning tasks, CAMA further refines the MCG through iterative feedback derived from a selected subset of the question-solution pairs. In the reasoning stage, given a new question, CAMA dynamically extracts a task-relevant subgraph from the MCG, conditioned on both the question content and the LLMs intermediate reasoning trace. This subgraph, which encodes the most pertinent knowledge points and their causal dependencies, is then injected back into the LLM to guide its reasoning process. Empirical results on real-world datasets show that CAMA significantly improves LLM performance on challenging mathematical problems. Furthermore, our experiments demonstrate that structured guidance consistently outperforms unstructured alternatives, and that incorporating asymmetric causal relationships yields greater improvements than using symmetric associations alone.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02579v1" target="_blank">A notion of partial order in the Choose the Leader model</a></h3>
                    <p><strong>Authors:</strong> Amit Einav, Yue Jiang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> math-ph, math.AP, math.MP, math.PR, 82C22, 60F99, 35Q82, 35B40</p>
                    <p><strong>Summary:</strong> In this work we continue the study of non-chaotic asymptotic correlations in many element systems and discuss the emergence of a new notion of asymptotic correlation -- partial order -- in the Choose the Leader (CL) system. Similarly to the newly defined notion of order, partial order refers to alignment of the elements in the system -- though it allows for deviation from total adherence. Our presented work revolves around the definition of partial order and shows its emergence in the CL model in its original critical scaling. Furthermore, we discuss the propagation of partial order in the CL model and give a quantitative estimate to the convergence to this state. This new notion (as well as that of order) opens the door to exploring old and new (probabilistic) models of biological and societal nature in a more realistic way.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02574v1" target="_blank">EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based Sentiment Analysis in Healthcare</a></h3>
                    <p><strong>Authors:</strong> Eman Alamoudi, Ellis Solaiman</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG, cs.SI</p>
                    <p><strong>Summary:</strong> Arabic-language patient feedback remains under-analysed because dialect diversity and scarce aspect-level sentiment labels hinder automated assessment. To address this gap, we introduce EHSAN, a data-centric hybrid pipeline that merges ChatGPT pseudo-labelling with targeted human review to build the first explainable Arabic aspect-based sentiment dataset for healthcare. Each sentence is annotated with an aspect and sentiment label (positive, negative, or neutral), forming a pioneering Arabic dataset aligned with healthcare themes, with ChatGPT-generated rationales provided for each label to enhance transparency. To evaluate the impact of annotation quality on model performance, we created three versions of the training data: a fully supervised set with all labels reviewed by humans, a semi-supervised set with 50% human review, and an unsupervised set with only machine-generated labels. We fine-tuned two transformer models on these datasets for both aspect and sentiment classification. Experimental results show that our Arabic-specific model achieved high accuracy even with minimal human supervision, reflecting only a minor performance drop when using ChatGPT-only labels. Reducing the number of aspect classes notably improved classification metrics across the board. These findings demonstrate an effective, scalable approach to Arabic aspect-based sentiment analysis (SA) in healthcare, combining large language model annotation with human expertise to produce a robust and explainable dataset. Future directions include generalisation across hospitals, prompt refinement, and interpretable data-driven modelling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02573v1" target="_blank">Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs</a></h3>
                    <p><strong>Authors:</strong> JÃ©rÃ©mie Dentan, Davide Buscaldi, Sonia Vanier</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Verbatim memorization in Large Language Models (LLMs) is a multifaceted phenomenon involving distinct underlying mechanisms. We introduce a novel method to analyze the different forms of memorization described by the existing taxonomy. Specifically, we train Convolutional Neural Networks (CNNs) on the attention weights of the LLM and evaluate the alignment between this taxonomy and the attention weights involved in decoding. We find that the existing taxonomy performs poorly and fails to reflect distinct mechanisms within the attention blocks. We propose a new taxonomy that maximizes alignment with the attention weights, consisting of three categories: memorized samples that are guessed using language modeling abilities, memorized samples that are recalled due to high duplication in the training set, and non-memorized samples. Our results reveal that few-shot verbatim memorization does not correspond to a distinct attention mechanism. We also show that a significant proportion of extractable samples are in fact guessed by the model and should therefore be studied separately. Finally, we develop a custom visual interpretability technique to localize the regions of the attention weights involved in each form of memorization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02572v1" target="_blank">Facility Location and $k$-Median with Fair Outliers</a></h3>
                    <p><strong>Authors:</strong> Rajni Dabas, Samir Khuller, Emilie Rivkin</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.DS</p>
                    <p><strong>Summary:</strong> Classical clustering problems such as \emph{Facility Location} and \emph{$k$-Median} aim to efficiently serve a set of clients from a subset of facilities -- minimizing the total cost of facility openings and client assignments in Facility Location, and minimizing assignment (service) cost under a facility count constraint in $k$-Median. These problems are highly sensitive to outliers, and therefore researchers have studied variants that allow excluding a small number of clients as outliers to reduce cost. However, in many real-world settings, clients belong to different demographic or functional groups, and unconstrained outlier removal can disproportionately exclude certain groups, raising fairness concerns. We study \emph{Facility Location with Fair Outliers}, where each group is allowed a specified number of outliers, and the objective is to minimize total cost while respecting group-wise fairness constraints. We present a bicriteria approximation with a $O(1/\epsilon)$ approximation factor and $(1+ 2\epsilon)$ factor violation in outliers per group. For \emph{$k$-Median with Fair Outliers}, we design a bicriteria approximation with a $4(1+\omega/\epsilon)$ approximation factor and $(\omega + \epsilon)$ violation in outliers per group improving on prior work by avoiding dependence on $k$ in outlier violations. We also prove that the problems are W[1]-hard parameterized by $\omega$, assuming the Exponential Time Hypothesis. We complement our algorithmic contributions with a detailed empirical analysis, demonstrating that fairness can be achieved with negligible increase in cost and that the integrality gap of the standard LP is small in practice.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02571v1" target="_blank">ASINT: Learning AS-to-Organization Mapping from Internet Metadata</a></h3>
                    <p><strong>Authors:</strong> Yongzhe Xu, Weitong Li, Eeshan Umrani, Taejoong Chung</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> Accurately mapping Autonomous Systems (ASNs) to their owning or operating organizations underpins Internet measurement research and security applications. Yet existing approaches commonly rely solely on WHOIS or PeeringDB, missing important relationships (e.g., cross-regional aliases, parent-child ownership) and failing to unify organizations scattered across different RIR identifiers. We introduce ASINT, an end-to-end pipeline that fuses bulk registry data with unstructured Web sources, then employs retrieval-augmented generation (RAG) to guide large language model (LLM) inference. Through a multi-stage procedure, ASINT merges ASNs into organization families, capturing nuanced ties beyond the scope of simpler heuristics. ASINT maps 111,470 ASNs to 81,233 organization families; compared to both AS2ORG+ and AS-Sibling, ASINT identifies more cross-regional groupings (e.g., operator aliases, rebrands) that other datasets overlook. Moreover, our refined mappings enhance multiple security and measurement tasks: ASINT exposes 27.5% more intra-organizational RPKI misconfigurations, cuts false-positive hijack alarms by 9.4%, and lowers erroneous IP leasing inferences by 5.9%. Finally, ASINT supports periodic updates and cost-sensitive LLM selection, demonstrating that broader Web evidence can provide a more accurate, evolving view of the Internets organizational structure.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02570v1" target="_blank">Neural Scaling Laws Surpass Chemical Accuracy for the Many-Electron SchrÃ¶dinger Equation</a></h3>
                    <p><strong>Authors:</strong> Du Jiang, Xuelan Wen, Yixiao Chen, Ruichen Li, Weizhong Fu, Hung Q. Pham, Ji Chen, Di He, William A. Goddard III, Liwei Wang, Weiluo Ren</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph, physics.comp-ph</p>
                    <p><strong>Summary:</strong> We demonstrate, for the first time, that neural scaling laws can deliver near-exact solutions to the many-electron Schr\odinger equation across a broad range of realistic molecules. This progress is enabled by the Lookahead Variational Algorithm (LAVA), an effective optimization scheme that systematically translates increased model size and computational resources into greatly improved energy accuracy for neural network wavefunctions. Across all tested cases, including benzene, the absolute energy error exhibits a systematic power-law decay with respect to model capacity and computation resources. The resulting energies not only surpass the 1 kcal/mol chemical-accuracy threshold but also achieve 1 kJ/mol subchemical accuracy. Beyond energies, the scaled-up neural network also yields better wavefunctions with improved physical symmetries, alongside accurate electron densities, dipole moments, and other important properties. Our approach offers a promising way forward to addressing many long-standing challenges in quantum chemistry. For instance, we improve energetic properties for systems such as the potential energy curve of nitrogen dimer as dissociation is approached and the cyclobutadiene automerization reaction barrier, producing definitive benchmarks, particularly in regimes where experimental data are sparse or highly uncertain. We also shed light on the decades-old puzzle of the cyclic ozone stability with highly accurate calculations for the cyclic-to-open ozone barrier. These results provide near-exact reference calculations with unprecedented accuracy, universal reliability and practical applicability, establishing a foundation for AI-driven quantum chemistry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02565v1" target="_blank">The analytically tractable zoo of similarity-induced exceptional structures</a></h3>
                    <p><strong>Authors:</strong> Anton Montag, Jordan Isaacs, Marcus StÃ¥lhammar, Flore K. Kunst</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> physics.optics, cond-mat.mes-hall, quant-ph</p>
                    <p><strong>Summary:</strong> Exceptional points (EPs) are non-Hermitian spectral degeneracies marking a simultaneous coalescence of eigenvalues and eigenvectors. Despite the fact that multiband $n$-fold EPs (EP$n$s) generically emerge as special points on manifolds of EP$m$s, where $mn$, EP$n$s as well as their topological properties have hitherto been studied as isolated objects. In this work we address this issue and carefully map out the emerging properties of multifold exceptional structures in three and four dimensions under the influence of one or multiple generalized similarities, revealing diverse combinations of EP$m$s in direct connection to EP$n$s. We find that simply counting the number of constraints defining the EP$n$s is not sufficient in the presence of similarities; the constraints can also be satisfied by the EP$m$-manifolds obeying certain spectral symmetries in the complex eigenvalue plane, reducing their dimension beyond what is expected from counting the number of constraints. Furthermore, the induced spectral symmetries not always allow for any EP$m$-manifold to emerge in $n$-band systems, making the plethora of exceptional structures deviate further from naive expectations. We illustrate our findings in simple periodic toy models. By relying on similarity relations instead of the less general symmetries, we simultaneously cover several physically relevant scenarios, ranging from optics and topolectrical circuits, to open quantum systems. This makes our predictions highly relevant and broadly applicable in modern research, as well as experimentally viable within various branches of physics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02560v1" target="_blank">Explainable AI Methods for Neuroimaging: Systematic Failures of Common Tools, the Need for Domain-Specific Validation, and a Proposal for Safe Application</a></h3>
                    <p><strong>Authors:</strong> Nys Tjade Siegel, James H. Cole, Mohamad Habes, Stefan Haufe, Kerstin Ritter, Marc-AndrÃ© Schulz</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV, eess.IV, q-bio.NC</p>
                    <p><strong>Summary:</strong> Trustworthy interpretation of deep learning models is critical for neuroimaging applications, yet commonly used Explainable AI (XAI) methods lack rigorous validation, risking misinterpretation. We performed the first large-scale, systematic comparison of XAI methods on ~45,000 structural brain MRIs using a novel XAI validation framework. This framework establishes verifiable ground truth by constructing prediction tasks with known signal sources - from localized anatomical features to subject-specific clinical lesions - without artificially altering input images. Our analysis reveals systematic failures in two of the most widely used methods: GradCAM consistently failed to localize predictive features, while Layer-wise Relevance Propagation generated extensive, artifactual explanations that suggest incompatibility with neuroimaging data characteristics. Our results indicate that these failures stem from a domain mismatch, where methods with design principles tailored to natural images require substantial adaptation for neuroimaging data. In contrast, the simpler, gradient-based method SmoothGrad, which makes fewer assumptions about data structure, proved consistently accurate, suggesting its conceptual simplicity makes it more robust to this domain shift. These findings highlight the need for domain-specific adaptation and validation of XAI methods, suggest that interpretations from prior neuroimaging studies using standard XAI methodology warrant re-evaluation, and provide urgent guidance for practical application of XAI in neuroimaging.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02557v1" target="_blank">RL-U$^2$Net: A Dual-Branch UNet with Reinforcement Learning-Assisted Multimodal Feature Fusion for Accurate 3D Whole-Heart Segmentation</a></h3>
                    <p><strong>Authors:</strong> Jierui Qu, Jianchun Zhao</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Accurate whole-heart segmentation is a critical component in the precise diagnosis and interventional planning of cardiovascular diseases. Integrating complementary information from modalities such as computed tomography (CT) and magnetic resonance imaging (MRI) can significantly enhance segmentation accuracy and robustness. However, existing multi-modal segmentation methods face several limitations: severe spatial inconsistency between modalities hinders effective feature fusion; fusion strategies are often static and lack adaptability; and the processes of feature alignment and segmentation are decoupled and inefficient. To address these challenges, we propose a dual-branch U-Net architecture enhanced by reinforcement learning for feature alignment, termed RL-U$^2$Net, designed for precise and efficient multi-modal 3D whole-heart segmentation. The model employs a dual-branch U-shaped network to process CT and MRI patches in parallel, and introduces a novel RL-XAlign module between the encoders. The module employs a cross-modal attention mechanism to capture semantic correspondences between modalities and a reinforcement-learning agent learns an optimal rotation strategy that consistently aligns anatomical pose and texture features. The aligned features are then reconstructed through their respective decoders. Finally, an ensemble-learning-based decision module integrates the predictions from individual patches to produce the final segmentation result. Experimental results on the publicly available MM-WHS 2017 dataset demonstrate that the proposed RL-U$^2$Net outperforms existing state-of-the-art methods, achieving Dice coefficients of 93.1% on CT and 87.0% on MRI, thereby validating the effectiveness and superiority of the proposed approach.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02555v1" target="_blank">Building and Aligning Comparable Corpora</a></h3>
                    <p><strong>Authors:</strong> Motaz Saad, David Langlois, Kamel Smaili</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, I.2.7</p>
                    <p><strong>Summary:</strong> Comparable corpus is a set of topic aligned documents in multiple languages, which are not necessarily translations of each other. These documents are useful for multilingual natural language processing when there is no parallel text available in some domains or languages. In addition, comparable documents are informative because they can tell what is being said about a topic in different languages. In this paper, we present a method to build comparable corpora from Wikipedia encyclopedia and EURONEWS website in English, French and Arabic languages. We further experiment a method to automatically align comparable documents using cross-lingual similarity measures. We investigate two cross-lingual similarity measures to align comparable documents. The first measure is based on bilingual dictionary, and the second measure is based on Latent Semantic Indexing (LSI). Experiments on several corpora show that the Cross-Lingual LSI (CL-LSI) measure outperforms the dictionary based measure. Finally, we collect English and Arabic news documents from the British Broadcast Corporation (BBC) and from ALJAZEERA (JSC) news website respectively. Then we use the CL-LSI similarity measure to automatically align comparable documents of BBC and JSC. The evaluation of the alignment shows that CL-LSI is not only able to align cross-lingual documents at the topic level, but also it is able to do this at the event level.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02549v1" target="_blank">MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming</a></h3>
                    <p><strong>Authors:</strong> Shuo Wang, Yongcai Wang, Wanting Li, Yucheng Wang, Maiyue Chen, Kaihui Wang, Zhizhong Su, Xudong Cai, Yeying Jin, Deying Li, Zhaoxin Fan</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Vision-Language Navigation (VLN) tasks often leverage panoramic RGB and depth inputs to provide rich spatial cues for action planning, but these sensors can be costly or less accessible in real-world deployments. Recent approaches based on Vision-Language Action (VLA) models achieve strong results with monocular input, yet they still lag behind methods using panoramic RGB-D information. We present MonoDream, a lightweight VLA framework that enables monocular agents to learn a Unified Navigation Representation (UNR). This shared feature representation jointly aligns navigation-relevant visual semantics (e.g., global layout, depth, and future cues) and language-grounded action intent, enabling more reliable action prediction. MonoDream further introduces Latent Panoramic Dreaming (LPD) tasks to supervise the UNR, which train the model to predict latent features of panoramic RGB and depth observations at both current and future steps based on only monocular input. Experiments on multiple VLN benchmarks show that MonoDream consistently improves monocular navigation performance and significantly narrows the gap with panoramic-based agents.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02541v1" target="_blank">Automatic Identification of Machine Learning-Specific Code Smells</a></h3>
                    <p><strong>Authors:</strong> Peter Hamfelt, Ricardo Britto, Lincoln Rocha, Camilo Almendra</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Machine learning (ML) has rapidly grown in popularity, becoming vital to many industries. Currently, the research on code smells in ML applications lacks tools and studies that address the identification and validity of ML-specific code smells. This work investigates suitable methods and tools to design and develop a static code analysis tool (MLpylint) based on code smell criteria. This research employed the Design Science Methodology. In the problem identification phase, a literature review was conducted to identify ML-specific code smells. In solution design, a secondary literature review and consultations with experts were performed to select methods and tools for implementing the tool. We evaluated the tool on data from 160 open-source ML applications sourced from GitHub. We also conducted a static validation through an expert survey involving 15 ML professionals. The results indicate the effectiveness and usefulness of the MLpylint. We aim to extend our current approach by investigating ways to introduce MLpylint seamlessly into development workflows, fostering a more productive and innovative developer environment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02536v1" target="_blank">ReGate: Enabling Power Gating in Neural Processing Units</a></h3>
                    <p><strong>Authors:</strong> Yuqi Xue, Jian Huang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> The energy efficiency of neural processing units (NPU) is playing a critical role in developing sustainable data centers. Our study with different generations of NPU chips reveals that 30%-72% of their energy consumption is contributed by static power dissipation, due to the lack of power management support in modern NPU chips. In this paper, we present ReGate, which enables fine-grained power-gating of each hardware component in NPU chips with hardware/software co-design. Unlike conventional power-gating techniques for generic processors, enabling power-gating in NPUs faces unique challenges due to the fundamental difference in hardware architecture and program execution model. To address these challenges, we carefully investigate the power-gating opportunities in each component of NPU chips and decide the best-fit power management scheme (i.e., hardware- vs. software-managed power gating). Specifically, for systolic arrays (SAs) that have deterministic execution patterns, ReGate enables cycle-level power gating at the granularity of processing elements (PEs) following the inherent dataflow execution in SAs. For inter-chip interconnect (ICI) and HBM controllers that have long idle intervals, ReGate employs a lightweight hardware-based idle-detection mechanism. For vector units and SRAM whose idle periods vary significantly depending on workload patterns, ReGate extends the NPU ISA and allows software like compilers to manage the power gating. With implementation on a production-level NPU simulator, we show that ReGate can reduce the energy consumption of NPU chips by up to 32.8% (15.5% on average), with negligible impact on AI workload performance. The hardware implementation of power-gating logic introduces less than 3.3% overhead in NPU chips.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02533v1" target="_blank">Precision-Aware Video Compression for Reducing Bandwidth Requirements in Video Communication for Vehicle Detection-Based Applications</a></h3>
                    <p><strong>Authors:</strong> Abyad Enan, Jon C Calhoun, Mashrur Chowdhury</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Computer vision has become a popular tool in intelligent transportation systems (ITS), enabling various applications through roadside traffic cameras that capture video and transmit it in real time to computing devices within the same network. The efficiency of this video transmission largely depends on the available bandwidth of the communication system. However, limited bandwidth can lead to communication bottlenecks, hindering the real-time performance of ITS applications. To mitigate this issue, lossy video compression techniques can be used to reduce bandwidth requirements, at the cost of degrading video quality. This degradation can negatively impact the accuracy of applications that rely on real-time vehicle detection. Additionally, vehicle detection accuracy is influenced by environmental factors such as weather and lighting conditions, suggesting that compression levels should be dynamically adjusted in response to these variations. In this work, we utilize a framework called Precision-Aware Video Compression (PAVC), where a roadside video camera captures footage of vehicles on roadways, compresses videos, and then transmits them to a processing unit, running a vehicle detection algorithm for safety-critical applications, such as real-time collision risk assessment. The system dynamically adjusts the video compression level based on current weather and lighting conditions to maintain vehicle detection accuracy while minimizing bandwidth usage. Our results demonstrate that PAVC improves vehicle detection accuracy by up to 13% and reduces communication bandwidth requirements by up to 8.23x in areas with moderate bandwidth availability. Moreover, in locations with severely limited bandwidth, PAVC reduces bandwidth requirements by up to 72x while preserving vehicle detection performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02530v1" target="_blank">Understanding the Risks of Asphalt Art on the Reliability of Surveillance Perception Systems</a></h3>
                    <p><strong>Authors:</strong> Jin Ma, Abyad Enan, Long Cheng, Mashrur Chowdhury</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Artistic crosswalks featuring asphalt art, introduced by different organizations in recent years, aim to enhance the visibility and safety of pedestrians. However, their visual complexity may interfere with surveillance systems that rely on vision-based object detection models. In this study, we investigate the impact of asphalt art on pedestrian detection performance of a pretrained vision-based object detection model. We construct realistic crosswalk scenarios by compositing various street art patterns into a fixed surveillance scene and evaluate the models performance in detecting pedestrians on asphalt-arted crosswalks under both benign and adversarial conditions. A benign case refers to pedestrian crosswalks painted with existing normal asphalt art, whereas an adversarial case involves digitally crafted or altered asphalt art perpetrated by an attacker. Our results show that while simple, color-based designs have minimal effect, complex artistic patterns, particularly those with high visual salience, can significantly degrade pedestrian detection performance. Furthermore, we demonstrate that adversarially crafted asphalt art can be exploited to deliberately obscure real pedestrians or generate non-existent pedestrian detections. These findings highlight a potential vulnerability in urban vision-based pedestrian surveillance systems and underscore the importance of accounting for environmental visual variations when designing robust pedestrian perception models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02528v1" target="_blank">From Pixels to Pathology: Restoration Diffusion for Diagnostic-Consistent Virtual IHC</a></h3>
                    <p><strong>Authors:</strong> Jingsong Liu, Xiaofeng Deng, Han Li, Azar Kazemi, Christian Grashei, Gesa Wilkens, Xin You, Tanja Groll, Nassir Navab, Carolin Mogler, Peter J. SchÃ¼ffler</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Hematoxylin and eosin (HE) staining is the clinical standard for assessing tissue morphology, but it lacks molecular-level diagnostic information. In contrast, immunohistochemistry (IHC) provides crucial insights into biomarker expression, such as HER2 status for breast cancer grading, but remains costly and time-consuming, limiting its use in time-sensitive clinical workflows. To address this gap, virtual staining from HE to IHC has emerged as a promising alternative, yet faces two core challenges: (1) Lack of fair evaluation of synthetic images against misaligned IHC ground truths, and (2) preserving structural integrity and biological variability during translation. To this end, we present an end-to-end framework encompassing both generation and evaluation in this work. We introduce Star-Diff, a structure-aware staining restoration diffusion model that reformulates virtual staining as an image restoration task. By combining residual and noise-based generation pathways, Star-Diff maintains tissue structure while modeling realistic biomarker variability. To evaluate the diagnostic consistency of the generated IHC patches, we propose the Semantic Fidelity Score (SFS), a clinical-grading-task-driven metric that quantifies class-wise semantic degradation based on biomarker classification accuracy. Unlike pixel-level metrics such as SSIM and PSNR, SFS remains robust under spatial misalignment and classifier uncertainty. Experiments on the BCI dataset demonstrate that Star-Diff achieves state-of-the-art (SOTA) performance in both visual fidelity and diagnostic relevance. With rapid inference and strong clinical alignment,it presents a practical solution for applications such as intraoperative virtual IHC synthesis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02525v1" target="_blank">Accurate and Interpretable Postmenstrual Age Prediction via Multimodal Large Language Model</a></h3>
                    <p><strong>Authors:</strong> Qifan Chen, Jin Cui, Cindy Duan, Yushuo Han, Yifei Shi</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Accurate estimation of postmenstrual age (PMA) at scan is crucial for assessing neonatal development and health. While deep learning models have achieved high accuracy in predicting PMA from brain MRI, they often function as black boxes, offering limited transparency and interpretability in clinical decision support. In this work, we address the dual challenge of accuracy and interpretability by adapting a multimodal large language model (MLLM) to perform both precise PMA prediction and clinically relevant explanation generation. We introduce a parameter-efficient fine-tuning (PEFT) strategy using instruction tuning and Low-Rank Adaptation (LoRA) applied to the Qwen2.5-VL-7B model. The model is trained on four 2D cortical surface projection maps derived from neonatal MRI scans. By employing distinct prompts for training and inference, our approach enables the MLLM to handle a regression task during training and generate clinically relevant explanations during inference. The fine-tuned model achieves a low prediction error with a 95 percent confidence interval of 0.78 to 1.52 weeks, while producing interpretable outputs grounded in developmental features, marking a significant step toward transparent and trustworthy AI systems in perinatal neuroscience.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02523v1" target="_blank">Transportation Cyber Incident Awareness through Generative AI-Based Incident Analysis and Retrieval-Augmented Question-Answering Systems</a></h3>
                    <p><strong>Authors:</strong> Ostonya Thomas, Muhaimin Bin Munir, Jean-Michel Tine, Mizanur Rahman, Yuchen Cai, Khandakar Ashrafi Akbar, Md Nahiyan Uddin, Latifur Khan, Trayce Hockstad, Mashrur Chowdhury</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Technological advancements have revolutionized numerous industries, including transportation. While digitalization, automation, and connectivity have enhanced safety and efficiency, they have also introduced new vulnerabilities. With 95% of data breaches attributed to human error, promoting cybersecurity awareness in transportation is increasingly critical. Despite numerous cyberattacks on transportation systems worldwide, comprehensive and centralized records of these incidents remain scarce. To address this gap and enhance cyber awareness, this paper presents a large language model (LLM) based approach to extract and organize transportation related cyber incidents from publicly available datasets. A key contribution of this work is the use of generative AI to transform unstructured, heterogeneous cyber incident data into structured formats. Incidents were sourced from the Center for Strategic  International Studies (CSIS) List of Significant Cyber Incidents, the University of Maryland Cyber Events Database (UMCED), the European Repository of Cyber Incidents (EuRepoC), the Maritime Cyber Attack Database (MCAD), and the U.S. DOT Transportation Cybersecurity and Resiliency (TraCR) Examples of Cyber Attacks in Transportation (2018 to 2022). These were classified by a fine tuned LLM into five transportation modes: aviation, maritime, rail, road, and multimodal, forming a transportation specific cyber incident database. Another key contribution of this work is the development of a Retrieval Augmented Generation question answering system, designed to enhance accessibility and practical use by enabling users to query the curated database for specific details on transportation related cyber incidents. By leveraging LLMs for both data extraction and user interaction, this study contributes a novel, accessible tool for improving cybersecurity awareness in the transportation sector.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02520v1" target="_blank">xDeepServe: Model-as-a-Service on Huawei CloudMatrix384</a></h3>
                    <p><strong>Authors:</strong> Ao Xiao, Bangzheng He, Baoquan Zhang, Baoxing Huai, Bingji Wang, Bo Wang, Bo Xu, Boyi Hou, Chan Yang, Changhong Liu, Cheng Cui, Chenyu Zhu, Cong Feng, Daohui Wang, Dayun Lin, Duo Zhao, Fengshao Zou, Fu Wang, Gangqiang Zhang, Gengyuan Dan, Guanjie Chen, Guodong Guan, Guodong Yang, Haifeng Li, Haipei Zhu, Hao Feng, Hao Huang, Hao Xu, Hengrui Ma, Hengtao Fan, Hui Liu, Jia Li, Jiang Liu, Jiang Xu, Jie Meng, Jinhan Xin, Junhao Hu, Juwei Chen, Lan Yu, Lanxin Miao, Liang Liu, Linan Jing, Lu Zhou, Meina Han, Mingkun Deng, Mingyu Deng, Naitian Deng, Nizhong Lin, Peihan Zhao, Peng Pan, Pengfei Shen, Ping Li, Qi Zhang, Qin Zhang, Qingrong Xia, Qingyi Zhang, Qunchao Fu, Ren Guo, Ruimin Gao, Shaochun Li, Sheng Long, Shentian Li, Shining Wan, Shuai Shen, Shuangfu Zeng, Shuming Jing, Siqi Yang, Song Zhang, Tao Xu, Tianlin Du, Ting Chen, Wanxu Wu, Wei Jiang, Weinan Tong, Weiwei Chen, Wen Peng, Wenli Zhou, Wenquan Yang, Wenxin Liang, Xiang Liu, Xiaoli Zhou, Xin Jin, Xinyu Duan, Xu Li, Xu Zhang, Xusheng Chen, Yalong Shan, Yang Gan, Yao Lu, Yi Deng, Yi Zheng, Yingfei Zheng, Yiyun Zheng, Yizhou Shan, Yong Gao, Yongqiang Yang, Yuanjin Gong, Yue Yu, Yuetao Chen, Yukun Zhu, Yulong He, Yusu Zhao, Yuyan Wu, Zenan Zhang, Zhaojin Zhuo, Zhaoyang Ji, Zhefeng Wang, Zheng Wang, Zhenhua Yang, Zhenli Sheng, Zhibin Yu, Zhigang Ji, Zhihao Ren, Zhipeng Bian, Zhixia Liu, Zhiyu Dong, Zhonghua Li, Zhou Yu, Zhuoming Shen, Zhuwei Peng, Zi Ye, Zihao Xiang, Zimin Fu, Zixuan Zhang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> The rise of scaled-out LLMs and scaled-up SuperPods signals a new era in large-scale AI infrastructure. LLMs continue to scale out via MoE, as seen in recent models like DeepSeek, Kimi, and Qwen. In parallel, AI hardware is scaling up, with Huaweis CloudMatrix384 SuperPod offering hundreds of GB/s high-speed interconnects. Running large MoE models on SuperPod-scale hardware brings new challenges. It requires new execution models, scalable scheduling, efficient expert load balancing, and elimination of single points of failure. This paper presents xDeepServe, Huawei Clouds LLM serving system designed for SuperPod-scale infrastructure. At its core is Transformerless, a disaggregated architecture that decomposes transformer models into modular units--attention, feedforward, and MoE--executed independently on NPUs connected via high-speed fabric. We implement this design in two forms: disaggregated prefill-decode and disaggregated MoE-attention. This fully disaggregated setup enables independent scaling of compute and memory without sacrificing performance. To support this architecture, we propose XCCL, a communication library that leverages CloudMatrix384s global shared memory to implement efficient point-to-point and all-to-all primitives. We also extend our serving engine FlowServe with system-level techniques, enabling scalable inference across hundreds of NPUs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02510v1" target="_blank">On Distributional Dependent Performance of Classical and Neural Routing Solvers</a></h3>
                    <p><strong>Authors:</strong> Daniela Thyssens, Tim Dernedde, Wilson Sentanoe, Lars Schmidt-Thieme</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Neural Combinatorial Optimization aims to learn to solve a class of combinatorial problems through data-driven methods and notably through employing neural networks by learning the underlying distribution of problem instances. While, so far neural methods struggle to outperform highly engineered problem specific meta-heuristics, this work explores a novel approach to formulate the distribution of problem instances to learn from and, more importantly, plant a structure in the sampled problem instances. In application to routing problems, we generate large problem instances that represent custom base problem instance distributions from which training instances are sampled. The test instances to evaluate the methods on the routing task consist of unseen problems sampled from the underlying large problem instance. We evaluate representative NCO methods and specialized Operation Research meta heuristics on this novel task and demonstrate that the performance gap between neural routing solvers and highly specialized meta-heuristics decreases when learning from sub-samples drawn from a fixed base node distribution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02505v1" target="_blank">Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Humanoid-Robot Interaction</a></h3>
                    <p><strong>Authors:</strong> Maria Lombardi, Carmela Calabrese, Davide Ghiglino, Caterina Foglino, Davide De Tommaso, Giulia Da Lisca, Lorenzo Natale, Agnieszka Wykowska</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> A key challenge in human-robot interaction research lies in developing robotic systems that can effectively perceive and interpret social cues, facilitating natural and adaptive interactions. In this work, we present a novel framework for enhancing the attention of the iCub humanoid robot by integrating advanced perceptual abilities to recognise social cues, understand surroundings through generative models, such as ChatGPT, and respond with contextually appropriate social behaviour. Specifically, we propose an interaction task implementing a narrative protocol (storytelling task) in which the human and the robot create a short imaginary story together, exchanging in turn cubes with creative images placed on them. To validate the protocol and the framework, experiments were performed to quantify the degree of usability and the quality of experience perceived by participants interacting with the system. Such a system can be beneficial in promoting effective human robot collaborations, especially in assistance, education and rehabilitation scenarios where the social awareness and the robot responsiveness play a pivotal role.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02499v1" target="_blank">Pre-discovery TESS Observations of Interstellar Object 3I/ATLAS</a></h3>
                    <p><strong>Authors:</strong> Jorge Martinez-Palomera, Amy Tuson, Christina Hedges, Jessie Dotson, Thomas Barclay, Brian Powell</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.EP, astro-ph.GA</p>
                    <p><strong>Summary:</strong> 3I/ATLAS, also known as C/2025 N1 (ATLAS), is the third known interstellar object to pass through our Solar System. We report serendipitous Transiting Exoplanet Survey Satellite (TESS) observations of 3I/ATLAS taken between 2025-05-07 and 2025-06-02,, 55 days prior to the discovery date (2025-07-01) and 14 days prior to the current earliest observation (2025-05-21). We retrieve the TESS pixel data, perform a robust background correction and use a data-driven approach to refine the objects ephemeris. We find a statistically significant offset between the targets observed and predicted positions and we show that this is dominated by uncertainty in the TESS World Coordinate System (WCS) rather than the ephemeris. 3I/ATLAS is too faint to be detected in the individual 200\,second TESS integrations, so we perform image stacking to improve detectability. After co-adding the TESS image data, we performed aperture and Pixel Response Function (PRF) photometry to create two light curves for 3I/ATLAS. Each light curve consists of 15 measurements with $\text{SNR}3$, collected across two different TESS cameras during the 26\,days that the object was observed, but the PRF light curve is more robust against image noise. The PRF light curve in the TESS bandpass shows a gradual increase in brightness from $T_{\text{mag}} = 20.9 \pm 0.29$ to $T_{\text{mag}} = 19.57 \pm 0.15$. This is expected as 3I/ATLAS approaches the inner Solar System. This paper highlights the power of using TESS for Solar System science; by increasing the photometric observing baseline, future studies will be able to investigate the long-term behavior of 3I/ATLAS</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02498v1" target="_blank">Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity</a></h3>
                    <p><strong>Authors:</strong> Md Tasin Abir, Arpita Chowdhury, Ashfia Rahman</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This study investigates how Facebook shaped collective identity during the July 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising. During government repression, protesters turned to Facebook as a central space for resistance, where multimodal expressions, images, memes, videos, hashtags, and satirical posts played an important role in unifying participants. Using a qualitative approach, this research analyzes visual rhetoric, verbal discourse, and digital irony to reveal how shared symbols, protest art, and slogans built a sense of solidarity. Key elements included the symbolic use of red, the ironic metaphorical use of the term Razakar, and the widespread sharing of visuals representing courage, injustice, and resistance. The findings show that the combination of visual and verbal strategies on Facebook not only mobilized public sentiment, but also built a strong collective identity that challenged authoritarian narratives. This study tries to demonstrate how online platforms can serve as powerful tools for identity construction and political mobilization in the digital age.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02490v1" target="_blank">PHM-Bench: A Domain-Specific Benchmarking Framework for Systematic Evaluation of Large Models in Prognostics and Health Management</a></h3>
                    <p><strong>Authors:</strong> Puyu Yang, Laifa Tao, Zijian Huang, Haifei Liu, Wenyan Cao, Hao Ji, Jianan Qiu, Qixuan Huang, Xuanyuan Su, Yuhang Xie, Jun Zhang, Shangyu Li, Chen Lu, Zhixuan Lian</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> With the rapid advancement of generative artificial intelligence, large language models (LLMs) are increasingly adopted in industrial domains, offering new opportunities for Prognostics and Health Management (PHM). These models help address challenges such as high development costs, long deployment cycles, and limited generalizability. However, despite the growing synergy between PHM and LLMs, existing evaluation methodologies often fall short in structural completeness, dimensional comprehensiveness, and evaluation granularity. This hampers the in-depth integration of LLMs into the PHM domain. To address these limitations, this study proposes PHM-Bench, a novel three-dimensional evaluation framework for PHM-oriented large models. Grounded in the triadic structure of fundamental capability, core task, and entire lifecycle, PHM-Bench is tailored to the unique demands of PHM system engineering. It defines multi-level evaluation metrics spanning knowledge comprehension, algorithmic generation, and task optimization. These metrics align with typical PHM tasks, including condition monitoring, fault diagnosis, RUL prediction, and maintenance decision-making. Utilizing both curated case sets and publicly available industrial datasets, our study enables multi-dimensional evaluation of general-purpose and domain-specific models across diverse PHM tasks. PHM-Bench establishes a methodological foundation for large-scale assessment of LLMs in PHM and offers a critical benchmark to guide the transition from general-purpose to PHM-specialized models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02485v1" target="_blank">Federated Graph Unlearning</a></h3>
                    <p><strong>Authors:</strong> Yuming Ai, Xunkai Li, Jiaqi Chao, Bowen Fan, Zhengyu Wu, Yinlin Zhu, Rong-Hua Li, Guoren Wang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> The demand for data privacy has led to the development of frameworks like Federated Graph Learning (FGL), which facilitate decentralized model training. However, a significant operational challenge in such systems is adhering to the right to be forgotten. This principle necessitates robust mechanisms for two distinct types of data removal: the selective erasure of specific entities and their associated knowledge from local subgraphs and the wholesale removal of a users entire dataset and influence. Existing methods often struggle to fully address both unlearning requirements, frequently resulting in incomplete data removal or the persistence of residual knowledge within the system. This work introduces a unified framework, conceived to provide a comprehensive solution to these challenges. The proposed framework employs a bifurcated strategy tailored to the specific unlearning request. For fine-grained Meta Unlearning, it uses prototype gradients to direct the initial local forgetting process, which is then refined by generating adversarial graphs to eliminate any remaining data traces among affected clients. In the case of complete client unlearning, the framework utilizes adversarial graph generation exclusively to purge the departed clients contributions from the remaining network. Extensive experiments on multiple benchmark datasets validate the proposed approach. The framework achieves substantial improvements in model prediction accuracy across both client and meta-unlearning scenarios when compared to existing methods. Furthermore, additional studies confirm its utility as a plug-in module, where it materially enhances the predictive capabilities and unlearning effectiveness of other established methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02482v1" target="_blank">Toward Using Machine Learning as a Shape Quality Metric for Liver Point Cloud Generation</a></h3>
                    <p><strong>Authors:</strong> Khoa Tuan Nguyen, Gaeun Oh, Ho-min Park, Francesca Tozzi, Wouter Willaert, Joris Vankerschaver, Niki Rashidian, Wesley De Neve</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> While 3D medical shape generative models such as diffusion models have shown promise in synthesizing diverse and anatomically plausible structures, the absence of ground truth makes quality evaluation challenging. Existing evaluation metrics commonly measure distributional distances between training and generated sets, while the medical field requires assessing quality at the individual level for each generated shape, which demands labor-intensive expert review. In this paper, we investigate the use of classical machine learning (ML) methods and PointNet as an alternative, interpretable approach for assessing the quality of generated liver shapes. We sample point clouds from the surfaces of the generated liver shapes, extract handcrafted geometric features, and train a group of supervised ML and PointNet models to classify liver shapes as good or bad. These trained models are then used as proxy discriminators to assess the quality of synthetic liver shapes produced by generative models. Our results show that ML-based shape classifiers provide not only interpretable feedback but also complementary insights compared to expert evaluation. This suggests that ML classifiers can serve as lightweight, task-relevant quality metrics in 3D organ shape generation, supporting more transparent and clinically aligned evaluation protocols in medical shape modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02479v1" target="_blank">Fine-grained Multiple Supervisory Network for Multi-modal Manipulation Detecting and Grounding</a></h3>
                    <p><strong>Authors:</strong> Xinquan Yu, Wei Lu, Xiangyang Luo</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The task of Detecting and Grounding Multi-Modal Media Manipulation (DGM$^4$) is a branch of misinformation detection. Unlike traditional binary classification, it includes complex subtasks such as forgery content localization and forgery method classification. Consider that existing methods are often limited in performance due to neglecting the erroneous interference caused by unreliable unimodal data and failing to establish comprehensive forgery supervision for mining fine-grained tampering traces. In this paper, we present a Fine-grained Multiple Supervisory (FMS) network, which incorporates modality reliability supervision, unimodal internal supervision and cross-modal supervision to provide comprehensive guidance for DGM$^4$ detection. For modality reliability supervision, we propose the Multimodal Decision Supervised Correction (MDSC) module. It leverages unimodal weak supervision to correct the multi-modal decision-making process. For unimodal internal supervision, we propose the Unimodal Forgery Mining Reinforcement (UFMR) module. It amplifies the disparity between real and fake information within unimodal modality from both feature-level and sample-level perspectives. For cross-modal supervision, we propose the Multimodal Forgery Alignment Reasoning (MFAR) module. It utilizes soft-attention interactions to achieve cross-modal feature perception from both consistency and inconsistency perspectives, where we also design the interaction constraints to ensure the interaction quality. Extensive experiments demonstrate the superior performance of our FMS compared to state-of-the-art methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02476v1" target="_blank">PoseGuard: Pose-Guided Generation with Safety Guardrails</a></h3>
                    <p><strong>Authors:</strong> Kongxin Wang, Jie Zhang, Peigui Qi, Kunsheng Tang, Tianwei Zhang, Wenbo Zhou</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Pose-guided video generation has become a powerful tool in creative industries, exemplified by frameworks like Animate Anyone. However, conditioning generation on specific poses introduces serious risks, such as impersonation, privacy violations, and NSFW content creation. To address these challenges, we propose $\textbf{PoseGuard}$, a safety alignment framework for pose-guided generation. PoseGuard is designed to suppress unsafe generations by degrading output quality when encountering malicious poses, while maintaining high-fidelity outputs for benign inputs. We categorize unsafe poses into three representative types: discriminatory gestures such as kneeling or offensive salutes, sexually suggestive poses that lead to NSFW content, and poses imitating copyrighted celebrity movements. PoseGuard employs a dual-objective training strategy combining generation fidelity with safety alignment, and uses LoRA-based fine-tuning for efficient, parameter-light updates. To ensure adaptability to evolving threats, PoseGuard supports pose-specific LoRA fusion, enabling flexible and modular updates when new unsafe poses are identified. We further demonstrate the generalizability of PoseGuard to facial landmark-guided generation. Extensive experiments validate that PoseGuard effectively blocks unsafe generations, maintains generation quality for benign inputs, and remains robust against slight pose variations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02473v1" target="_blank">An Efficient and Adaptive Next Edit Suggestion Framework with Zero Human Instructions in IDEs</a></h3>
                    <p><strong>Authors:</strong> Xinfang Chen, Siyang Xiao, Xianying Zhu, Junhong Xie, Ming Liang, Dajun Chen, Wei Jiang, Yong Li, Peng Di</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.LG, 68N30, D.2.3; D.1.2; I.2.2</p>
                    <p><strong>Summary:</strong> Code editing, including modifying, refactoring, and maintaining existing code, is the most frequent task in software development and has garnered significant attention from AI-powered tools. However, existing solutions that translate explicit natural language instructions into code edits face critical limitations, such as heavy reliance on human instruction input and high latency, which hinder their effective integration into a developers workflow. We observe that developers habitual behaviors and coding objectives are often reflected in their historical editing patterns, making this data key to addressing existing limitations. To leverage these insights, we propose NES (Next Edit Suggestion), an LLM-driven code editing framework that delivers an instruction-free and low-latency experience. Built on a dual-model architecture and trained with our high-quality SFT and DAPO datasets, NES enhances productivity by understanding developer intent while optimizing inference to minimize latency. NES is a scalable, industry-ready solution with a continuous Tab key interaction workflow, seamlessly adopted by a FinTech company with over 20,000 developers. Evaluations on real-world datasets show NES achieves 75.6% and 81.6% accuracy in two tasks of predicting next edit locations, alongside 91.36% ES and 27.7% EMR for intent-aligned edits, outperforming SOTA models. Our open-sourced SFT and DAPO datasets have been demonstrated to enhance the performance of open-source CodeLLMs. The demonstration of NES is available at https://youtu.be/yGoyYOe6fbY.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02671v1" target="_blank">Raw Data Matters: Enhancing Prompt Tuning by Internal Augmentation on Vision-Language Models</a></h3>
                    <p><strong>Authors:</strong> Haoyang Li, Liang Wang, Chao Wang, Siyu Zhou, Jing Jiang, Yan Peng, Guodong Long</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> For CLIP-based prompt tuning, introducing more data as additional knowledge for enhancing fine-tuning process is proved to be an effective approach. Existing data amplification strategies for prompt tuning typically rely on external knowledge (e.g., large language models or pre-structured knowledge bases), resulting in higher costs for data collection and processing, while generally ignoring further utilization of features in image modality. To address this, we propose Augmentation-driven Prompt Tuning (AugPT), a self-contained distillation-based prompt tuning approach using only internal augmentation on raw dataset to better exploit known features. Specifically, AugPT employs self-supervised augmentation on unlabeled images in the training set, and introduces a novel gating mechanism based on consensus test, reusing the pre-trained prompt tuning backbone model to spontaneously filter noisy samples, further enhancing the quality of augmented views. Extensive experiments validate that AugPT simultaneously enhances model performance and generalization capability without using appended external knowledge. The code of AugPT is available at: https://github.com/JREion/AugPT .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02670v1" target="_blank">atommovr: An open-source simulation framework for rearrangement in atomic arrays</a></h3>
                    <p><strong>Authors:</strong> Nikhil K Harle, Bo-Yu Chen, Bob Bao, Hannes Bernien</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph, physics.atom-ph</p>
                    <p><strong>Summary:</strong> The task of atom rearrangement has emerged in the last decade as a fundamental building block for the development of neutral atom-based quantum processors. However, despite many recent efforts to develop algorithms with favorable asymptotic scaling, no time-optimal algorithm has been developed for any rearrangement task. Moreover, no open-source code exists to reproduce or benchmark existing algorithms, and to assist the development of new rearrangement protocols. To address this deficiency, we develop an open-source simulation framework for developing, comparing, and benchmarking algorithms under realistic and customizable noise models. Using this framework, we \textbf{a)} numerically extract lower bounds for the scaling of a time-optimal rearrangement algorithm and compare it to existing heuristic algorithms \textbf{b)} develop a naive dual-species algorithm able to prepare arbitrary targets with near-unity success rate. With this framework, we hope to develop a common tool for the community to study rearrangement, lower the barrier to entry for new experimental groups, and stimulate progress in developing algorithms which approach time-optimal scaling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02669v1" target="_blank">MedVLThinker: Simple Baselines for Multimodal Medical Reasoning</a></h3>
                    <p><strong>Authors:</strong> Xiaoke Huang, Juncheng Wu, Hui Liu, Xianfeng Tang, Yuyin Zhou</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to ``think before responding via chain-of-thought reasoning. However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and comparison. In this paper, we present MedVLThinker, a suite of simple yet strong baselines. Our fully open recipe consists of: (1) systematic data curation for both text-only and image-text medical data, filtered according to varying levels of reasoning difficulty, and (2) two training paradigms: Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement Learning with Verifiable Rewards (RLVR) based on final answer correctness. Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six medical QA benchmarks, we find that RLVR consistently and significantly outperforms SFT. Additionally, under the RLVR framework, a key, counter-intuitive finding is that training on our curated text-only reasoning data provides a more substantial performance boost than training on multimodal image-text data. Our best open 7B model, trained using the RLVR recipe on text-only data, establishes a new state-of-the-art on existing public VQA benchmarks, surpassing all previous open-source medical LMMs. Furthermore, scaling our model to 32B achieves performance on par with the proprietary GPT-4o. We release all curated data, models, and code to provide the community with a strong, open foundation for future research in multimodal medical reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02668v1" target="_blank">LOST: Low-rank and Sparse Pre-training for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Jiaxi Li, Lu Yin, Li Shen, Jinjin Xu, Liwu Xu, Tianjin Huang, Wenwu Wang, Shiwei Liu, Xilu Wang</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> While large language models (LLMs) have achieved remarkable performance across a wide range of tasks, their massive scale incurs prohibitive computational and memory costs for pre-training from scratch. Recent studies have investigated the use of low-rank parameterization as a means of reducing model size and training cost. In this context, sparsity is often employed as a complementary technique to recover important information lost in low-rank compression by capturing salient features in the residual space. However, existing approaches typically combine low-rank and sparse components in a simplistic or ad hoc manner, often resulting in undesirable performance degradation compared to full-rank training. In this paper, we propose \textbf{LO}w-rank and \textbf{S}parse pre-\textbf{T}raining (\textbf{LOST}) for LLMs, a novel method that ingeniously integrates low-rank and sparse structures to enable effective training of LLMs from scratch under strict efficiency constraints. LOST applies singular value decomposition to weight matrices, preserving the dominant low-rank components, while allocating the remaining singular values to construct channel-wise sparse components to complement the expressiveness of low-rank training. We evaluate LOST on LLM pretraining ranging from 60M to 7B parameters. Our experiments show that LOST achieves competitive or superior performance compared to full-rank models, while significantly reducing both memory and compute overhead. Moreover, Code is available at \href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST Repo}</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02665v1" target="_blank">Branch  Solve for Hub Location</a></h3>
                    <p><strong>Authors:</strong> Elena FernÃ¡ndez, NicolÃ¡s Zerega</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> math.OC</p>
                    <p><strong>Summary:</strong> This paper introduces a new formulation and solution framework for hub location problems. The formulation is based on 2-index aggregated flow variables and incorporates a set of aggregated demand constraints, which are novel in hub location. With minor adaptations, the approach applies to a large class of single- and multiple-allocation models, possibly incorporating flow bounds on activated arcs. General-purpose feasibility and optimality inequalities are also developed. Because of the small number of continuous variables, there is no need to project them out, differentiating the method from solution algorithms that rely heavily on feasibility and optimality cuts. The proposed Branch  Solve solution framework leverages the nested structure of the problems, by solving auxiliary subproblems at selected nodes of the enumeration tree. Extensive computational experiments on benchmark instances from the literature confirm the good performance of the proposal: the basic version of the algorithm is able to solve to proven optimality instances with up to 200 nodes for several hub location families.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02663v1" target="_blank">Bosonization, BTZ Black Hole Microstates, and Logarithmic Correction to Entropy</a></h3>
                    <p><strong>Authors:</strong> Suvankar Dutta, Shruti Menon, Aayush Srivastav</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> We study three-dimensional gravity with negative cosmological constant under non-standard boundary conditions where chemical potentials are determined dynamically. Using a boundary Hamiltonian inspired by collective field theory (ColFT), the boundary dynamics reduce to those of a one-dimensional fluid on a circle, with configurations corresponding to bulk geometries such as BTZ black holes. Quantizing the system via bosonization of relativistic fermions, we obtain a microscopic description of black hole states in terms of Young diagrams, whose degeneracies match the Bekenstein-Hawking entropy. We compute the Euclidean canonical partition function and free energy for both the ColFT Hamiltonian and a relativistic free-fermion Hamiltonian. In the ColFT case, the partition function resembles that of chiral U(N) Yang-Mills theory on a torus, with N~1/(\beta G). This offers a novel way to compute quantum corrections to the partition function. The leading entropy term receives contributions from all genera, while the subleading logarithmic correction is one-loop exact, arising solely from the genus-one sector with coefficient -1/2 . This coefficient remains unchanged in the relativistic fermion case, suggesting the universality of the one-loop correction across different boundary Hamiltonians.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02661v1" target="_blank">Classification of Average Crystalline Topological Superconductors through a Generalized Real-Space Construction</a></h3>
                    <p><strong>Authors:</strong> Sarvesh Srinivasan, Jian-Hao Zhang, Yang Qi, Zhen Bi</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, quant-ph</p>
                    <p><strong>Summary:</strong> We investigate a novel class of topological superconducting phases protected by exact fermion-parity symmetry and average crystalline symmetries. These phases belong to the broader class of average crystalline symmetry-protected topological (ACSPT) states and include numerous examples of intrinsic ACSPTs -- topological phases that arise only in the presence of disorder or decoherence. Unlike conventional symmetry-protected topological (SPT) phases, which require exact symmetry protection, average SPT (ASPT) phases remain robust as long as the symmetry is restored on average across disorder realizations or mixed-state ensembles. To classify these phases, we extend the real-space block state construction framework to account for average crystalline symmetries. In this generalized setting, lower-dimensional cells are decorated with ASPT phases, and the obstruction-free conditions are reformulated to incorporate the constraints imposed by average symmetry at block intersections. This provides a physically transparent and systematic method for classifying ASPTs with spatial symmetries that are only preserved statistically. We further validate our classification using a generalized spectral sequence analysis, which serves as an independent consistency check. Our results demonstrate that many crystalline topological superconductors remain well defined under realistic imperfections, and they uncover a rich landscape of intrinsically average-symmetry-protected phases that have no analog in clean systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02660v1" target="_blank">PMGS: Reconstruction of Projectile Motion across Large Spatiotemporal Spans via 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Yijun Xu, Jingrui Zhang, Yuhan Chen, Dingwen Wang, Lei Yu, Chu He</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Modeling complex rigid motion across large spatiotemporal spans remains an unresolved challenge in dynamic reconstruction. Existing paradigms are mainly confined to short-term, small-scale deformation and offer limited consideration for physical consistency. This study proposes PMGS, focusing on reconstructing Projectile Motion via 3D Gaussian Splatting. The workflow comprises two stages: 1) Target Modeling: achieving object-centralized reconstruction through dynamic scene decomposition and an improved point density control; 2) Motion Recovery: restoring full motion sequences by learning per-frame SE(3) poses. We introduce an acceleration consistency constraint to bridge Newtonian mechanics and pose estimation, and design a dynamic simulated annealing strategy that adaptively schedules learning rates based on motion states. Futhermore, we devise a Kalman fusion scheme to optimize error accumulation from multi-source observations to mitigate disturbances. Experiments show PMGSs superior performance in reconstructing high-speed nonlinear rigid motion compared to mainstream dynamic methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02659v1" target="_blank">Enhancing the ergodicity of Worldvolume HMC via embedding Generalized-thimble HMC</a></h3>
                    <p><strong>Authors:</strong> Masafumi Fukuma, Yusuke Namekawa</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, hep-lat, hep-th</p>
                    <p><strong>Summary:</strong> The Worldvolume Hybrid Monte Carlo (WV-HMC) method [arXiv:2012.08468] is an efficient and versatile algorithm that simultaneously mitigates both the sign problem and the ergodicity problem -- the latter being intrinsic to algorithms based on Lefschetz thimbles. We consider a situation in which the maximum flow time can be set to a small value, as occurs when WV-HMC is applied to the doped Hubbard model using a nonphysical redundant parameter. An optimal choice of this parameter significantly reduces the sign problem on the original integration surface and allows the maximum flow time to remain small, a feature that facilitates increasing the system size while keeping the computation time modest. However, as the worldvolume becomes a thin layer, it becomes increasingly difficult to explore it efficiently, leading to potential ergodicity issues. To overcome this limitation, we propose embedding the Generalized-thimble HMC (GT-HMC) into the WV-HMC framework. GT-HMC performs HMC updates on a deformed surface at a fixed flow time. Although it suffers from ergodicity issues due to infinitely high potential barriers at the zeros of the Boltzmann weight, it enables more efficient exploration within the allowed region. Furthermore, its molecular dynamics step size can typically be taken to be larger than in WV-HMC. GT-HMC is thus better suited for sampling regions where ergodicity issues are not serious. We provide a proof that GT-HMC can be embedded within the WV-HMC algorithm, and verify that the two methods -- the pure WV-HMC and the combined version -- yield consistent results within statistical errors for the two-dimensional doped Hubbard model on a $6 \times 6$ spatial lattice at $T/\kappa = 1/6.4\simeq 0.156$ and $U/\kappa = 8.0$ with Trotter number $N_t = 20$ ($\kappa$: hopping parameter).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02657v1" target="_blank">RC-Gossip: Information Freshness in Clustered Networks with Rate-Changing Gossip</a></h3>
                    <p><strong>Authors:</strong> Irtiza Hasan, Ahmed Arafa</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.NI, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> A clustered gossip network is considered in which a source updates its information over time, and end-nodes, organized in clusters through clusterheads, are keeping track of it. The goal for the nodes is to remain as fresh as possible, i.e., have the same information as the source, which we assess by the long-term average binary freshness metric. We introduce a smart mechanism of information dissemination which we coin rate-changing gossip (RC-Gossip). Its main idea is that gossiping is directed towards nodes that need it the most, and hence the rate of gossiping changes based on the number of fresh nodes in the network at a given time. While Stochastic Hybrid System (SHS) analysis has been the norm in studying freshness of gossip networks, we present an equivalent way to analyze freshness using a renewal-reward-based approach. Using that, we show that RC-gossip significantly increases freshness of nodes in different clustered networks, with optimal cluster sizes, compared to traditional gossiping techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02645v1" target="_blank">Evaluating Variance in Visual Question Answering Benchmarks</a></h3>
                    <p><strong>Authors:</strong> Nikitha SR</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Multimodal large language models (MLLMs) have emerged as powerful tools for visual question answering (VQA), enabling reasoning and contextual understanding across visual and textual modalities. Despite their advancements, the evaluation of MLLMs on VQA benchmarks often relies on point estimates, overlooking the significant variance in performance caused by factors such as stochastic model outputs, training seed sensitivity, and hyperparameter configurations. This paper critically examines these issues by analyzing variance across 14 widely used VQA benchmarks, covering diverse tasks such as visual reasoning, text understanding, and commonsense reasoning. We systematically study the impact of training seed, framework non-determinism, model scale, and extended instruction finetuning on performance variability. Additionally, we explore Cloze-style evaluation as an alternate assessment strategy, studying its effectiveness in reducing stochasticity and improving reliability across benchmarks. Our findings highlight the limitations of current evaluation practices and advocate for variance-aware methodologies to foster more robust and reliable development of MLLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02641v1" target="_blank">FastCSP: Accelerated Molecular Crystal Structure Prediction with Universal Model for Atoms</a></h3>
                    <p><strong>Authors:</strong> Vahe Gharakhanyan, Yi Yang, Luis Barroso-Luque, Muhammed Shuaibi, Daniel S. Levine, Kyle Michel, Viachaslau Bernat, Misko Dzamba, Xiang Fu, Meng Gao, Xingyu Liu, Keian Noori, Lafe J. Purvis, Tingling Rao, Brandon M. Wood, Ammar Rizvi, Matt Uyttendaele, Andrew J. Ouderkirk, Chiara Daraio, C. Lawrence Zitnick, Arman Boromand, Noa Marom, Zachary W. Ulissi, Anuroop Sriram</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph, cs.LG</p>
                    <p><strong>Summary:</strong> Crystal Structure Prediction (CSP) of molecular crystals plays a central role in applications, such as pharmaceuticals and organic electronics. CSP is challenging and computationally expensive due to the need to explore a large search space with sufficient accuracy to capture energy differences of a few kJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT) provides the required accuracy but its computational cost is impractical for a large number of putative structures. We introduce FastCSP, an open-source, high-throughput CSP workflow based on machine learning interatomic potentials (MLIPs). FastCSP combines random structure generation using Genarris 3.0 with geometry relaxation and free energy calculations powered entirely by the Universal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of 28 mostly rigid molecules, demonstrating that our workflow consistently generates known experimental structures and ranks them within 5 kJ/mol per molecule of the global minimum. Our results demonstrate that universal MLIPs can be used across diverse compounds without requiring system-specific tuning. Moreover, the speed and accuracy afforded by UMA eliminate the need for classical force fields in the early stages of CSP and for final re-ranking with DFT. The open-source release of the entire FastCSP workflow significantly lowers the barrier to accessing CSP. CSP results for a single system can be obtained within hours on tens of modern GPUs, making high-throughput crystal structure prediction feasible for a broad range of scientific applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02640v1" target="_blank">An Efficient Continuous-Time MILP for Integrated Aircraft Hangar Scheduling and Layout</a></h3>
                    <p><strong>Authors:</strong> Shayan Farhang Pazhooh, Hossein Shams Shemirani</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> math.OC, cs.AI, cs.CE, 90C11 (Primary), 90B35, 90C27 (Secondary)</p>
                    <p><strong>Summary:</strong> Efficient management of aircraft maintenance hangars is a critical operational challenge, involving complex, interdependent decisions regarding aircraft scheduling and spatial allocation. This paper introduces a novel continuous-time mixed-integer linear programming (MILP) model to solve this integrated spatio-temporal problem. By treating time as a continuous variable, our formulation overcomes the scalability limitations of traditional discrete-time approaches. The performance of the exact model is benchmarked against a constructive heuristic, and its practical applicability is demonstrated through a custom-built visualization dashboard. Computational results are compelling: the model solves instances with up to 25 aircraft to proven optimality, often in mere seconds, and for large-scale cases of up to 40 aircraft, delivers high-quality solutions within known optimality gaps. In all tested scenarios, the resulting solutions consistently and significantly outperform the heuristic, which highlights the frameworks substantial economic benefits and provides valuable managerial insights into the trade-off between solution time and optimality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02638v1" target="_blank">Anticipating Decoherence: a Predictive Framework for Enhancing Coherence in Quantum Emitters</a></h3>
                    <p><strong>Authors:</strong> Pranshu Maan, Yuheng Chen, Sean Borneman, Benjamin Lawrie, Alexander Puretzky, Hadiseh Alaeian, Alexandra Boltasseva, Vladimir M. Shalaev, Alexander V. Kildishev</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Large-scale quantum systems require optical coherence between distant quantum devices, necessitating spectral indistinguishability. Scalable solid-state platforms offer promising routes to this goal. However, environmental disorders, including dephasing, spectral diffusion, and spin-bath interactions, influence the emitters spectra and deteriorate the coherence. Using statistical theory, we identify correlations in spectral diffusion from slowly varying environmental coupling, revealing predictable dynamics extendable to other disorders. Importantly, this could enable the development of an anticipatory framework for forecasting and decoherence engineering in remote quantum emitters. To validate this framework, we demonstrate that a machine learning model trained on limited data can accurately forecast unseen spectral behavior. Realization of such a model on distinct quantum emitters could reduce the spectral shift by factors $\approx$ 2.1 to 15.8, depending on emitter stability, compared to no prediction. This work presents, for the first time, the application of anticipatory systems and replica theory to quantum technology, along with the first experimental demonstration of internal prediction that generalizes across multiple quantum emitters. These results pave the way for real-time decoherence engineering in scalable quantum systems. Such capability could lead to enhanced optical coherence and multi-emitter synchronization, with broad implications for quantum communication, computation, imaging, and sensing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.02635v1" target="_blank">Test Set Quality in Multilingual LLM Evaluation</a></h3>
                    <p><strong>Authors:</strong> Kranti Chalamalasetti, Gabriel Bernier-Colborne, Yvan Gauthier, Sowmya Vajjala</p>
                    <p><strong>Published:</strong> 8/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Several multilingual benchmark datasets have been developed in a semi-automatic manner in the recent past to measure progress and understand the state-of-the-art in the multilingual capabilities of Large Language Models. However, there is not a lot of attention paid to the quality of the datasets themselves, despite the existence of previous work in identifying errors in even fully human-annotated test sets. In this paper, we manually analyze recent multilingual evaluation sets in two languages - French and Telugu, identifying several errors in the process. We compare the performance difference across several LLMs with the original and revised versions of the datasets and identify large differences (almost 10% in some cases) in both languages). Based on these results, we argue that test sets should not be considered immutable and should be revisited, checked for correctness, and potentially versioned. We end with some recommendations for both the dataset creators as well as consumers on addressing the dataset quality issues.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

