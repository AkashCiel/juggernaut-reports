
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-19<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The papers presented exhibit various trends and breakthroughs in AI safety research, emphasizing the need for robust detection, understanding, and safe deployment of AI systems. Notably, **RepreGuard** introduces a novel method for detecting text generated by large language models (LLMs), which is crucial for preventing misuse and ensuring trustworthy AI systems. This method, based on internal representation patterns, significantly outperforms existing detection methods, highlighting the importance of understanding AI-generated contents underlying structures for safety purposes.

Additionally, the exploration of **multi-modal models**, such as the study on GPT-5s spatial intelligence, reveals ongoing challenges in achieving human-level spatial reasoning and understanding. This gap underscores the importance of developing AI systems that can safely and accurately interpret and interact with the complex real-world environment. Furthermore, the paper on **FuSaR** addresses the critical balance between reasoning capabilities and safety in large reasoning models (LRMs), proposing a fuzzification-based alignment strategy to improve safety without compromising reasoning performance. Collectively, these studies underscore the necessity of developing AI models that are not only powerful but also reliable and secure, addressing both technical robustness and ethical considerations within AI safety research.

*Based on 50 research papers*

---

## ai alignment research

The provided research papers cover a wide range of topics, but only a few directly touch upon aspects relevant to AI alignment, which focuses on ensuring AI systems operate in accordance with human values and intentions. Among these, the paper Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks is particularly relevant. It discusses the challenges faced by autonomous agents powered by Large Language Models (LLMs) in task completion, specifically highlighting issues in planning, execution, and response generation. By developing a taxonomy of failure causes and proposing improvements, the paper contributes to AI alignment by addressing how autonomous systems can better align their actions with desired outcomes, thereby ensuring they operate safely and effectively in real-world scenarios.

Another relevant paper, Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation, investigates emergent behaviors in AI systems, such as resource-sharing and aggression under scarcity. This study is crucial for AI alignment as it explores the unintended emergence of survival-oriented heuristics, which could impact an AIs alignment with human values. Understanding these behaviors is vital for developing systems that are both autonomous and aligned with human intentions, highlighting the need for careful design and ongoing assessment of AI behaviors in complex environments. Together, these studies underscore the importance of transparency, robustness, and ethical considerations in AI development to ensure alignment with human values and safety.

*Based on 50 research papers*

---

## quantum computing

While the provided list of research papers covers a wide range of topics, only a few papers directly address aspects related to quantum computing. The most relevant paper in this context is Driven-Dissipative Interpretation of Measurement-Induced State Transitions Beyond Semiclassical Predictions by Bo-Syun Pan, Yen-Hsiang Lin, and Chiao-Hsuan Wang. This study focuses on the dynamics of superconducting quantum computing, specifically examining the measurement-induced state transitions (MIST) that occur during quantum nondemolition (QND) measurements. The paper introduces a driven-dissipative model that provides insights into the complexities of MIST, highlighting conditions under which qubits may leak from their computational subspace due to strong readout drives. This research is crucial as it uncovers a super-MIST regime characterized by steady-state qubit inversion, offering potential pathways to optimize measurement techniques in quantum computing systems involving superconducting qubits like fluxonium and transmon.

Another paper that is tangentially related to the broader field of quantum technologies is Quantum sensing of electron beams using solid-state spins by Jakob M. Grzesik et al. This work explores the integration of nitrogen-vacancy (NV) centers in diamond as quantum sensors for detecting electron beams. Although not directly a quantum computing study, it contributes to the development of hybrid quantum systems that could enhance quantum information processing and nanoscale sensing. By establishing NV centers as probes for free electrons, this research paves the way for innovative applications in quantum metrology and the potential development of new quantum technologies involving electron beam interactions with solid-state qubits. These advancements have significant implications for the future of quantum sensing and information processing, aligning with the overarching goals of quantum technology development.

*Based on 50 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.13152v1" target="_blank">RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns</a></h3>
                    <p><strong>Authors:</strong> Xin Chen, Junchao Wu, Shu Yang, Runzhe Zhan, Zeyu Wu, Ziyang Luo, Di Wang, Min Yang, Lidia S. Chao, Derek F. Wong</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Detecting content generated by large language models (LLMs) is crucial for preventing misuse and building trustworthy AI systems. Although existing detection methods perform well, their robustness in out-of-distribution (OOD) scenarios is still lacking. In this paper, we hypothesize that, compared to features used by existing detection methods, the internal representations of LLMs contain more comprehensive and raw features that can more effectively capture and distinguish the statistical pattern differences between LLM-generated texts (LGT) and human-written texts (HWT). We validated this hypothesis across different LLMs and observed significant differences in neural activation patterns when processing these two types of texts. Based on this, we propose RepreGuard, an efficient statistics-based detection method. Specifically, we first employ a surrogate model to collect representation of LGT and HWT, and extract the distinct activation feature that can better identify LGT. We can classify the text by calculating the projection score of the text representations along this feature direction and comparing with a precomputed threshold. Experimental results show that RepreGuard outperforms all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD scenarios, while also demonstrating robust resilience to various text sizes and mainstream attacks. Data and code are publicly available at: https://github.com/NLP2CT/RepreGuard</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13142v1" target="_blank">Has GPT-5 Achieved Spatial Intelligence? An Empirical Study</a></h3>
                    <p><strong>Authors:</strong> Zhongang Cai, Yubo Wang, Qingping Sun, Ruisi Wang, Chenyang Gu, Wanqi Yin, Zhiqian Lin, Zhitao Yang, Chen Wei, Xuanke Shi, Kewang Deng, Xiaoyang Han, Zukai Chen, Jiaqi Li, Xiangyu Fan, Hanming Deng, Lewei Lu, Bo Li, Ziwei Liu, Quan Wang, Dahua Lin, Lei Yang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.LG, cs.MM, cs.RO</p>
                    <p><strong>Summary:</strong> Multi-modal models have achieved remarkable progress in recent years. Nevertheless, they continue to exhibit notable limitations in spatial understanding and reasoning, which are fundamental capabilities to achieving artificial general intelligence. With the recent release of GPT-5, allegedly the most powerful AI model to date, it is timely to examine where the leading models stand on the path toward spatial intelligence. First, we propose a comprehensive taxonomy of spatial tasks that unifies existing benchmarks and discuss the challenges in ensuring fair evaluation. We then evaluate state-of-the-art proprietary and open-source models on eight key benchmarks, at a cost exceeding one billion total tokens. Our empirical study reveals that (1) GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2) still falls short of human performance across a broad spectrum of tasks. Moreover, we (3) identify the more challenging spatial intelligence problems for multi-modal models, and (4) proprietary models do not exhibit a decisive advantage when facing the most difficult problems. In addition, we conduct a qualitative evaluation across a diverse set of scenarios that are intuitive for humans yet fail even the most advanced multi-modal models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13135v1" target="_blank">Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]</a></h3>
                    <p><strong>Authors:</strong> Yueyang Liu, Lance Kennedy, Ruochen Kong, Joon-Seok Kim, Andreas ZÃ¼fle</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Individual-level human mobility prediction has emerged as a significant topic of research with applications in infectious disease monitoring, child, and elderly care. Existing studies predominantly focus on the microscopic aspects of human trajectories: such as predicting short-term trajectories or the next location visited, while offering limited attention to macro-level mobility patterns and the corresponding life routines. In this paper, we focus on an underexplored problem in human mobility prediction: determining the best practices to train a machine learning model using historical data to forecast an individuals complete trajectory over the next days and weeks. In this experiment paper, we undertake a comprehensive experimental analysis of diverse models, parameter configurations, and training strategies, accompanied by an in-depth examination of the statistical distribution inherent in human mobility patterns. Our empirical evaluations encompass both Long Short-Term Memory and Transformer-based architectures, and further investigate how incorporating individual life patterns can enhance the effectiveness of the prediction. We show that explicitly including semantic information such as day-of-the-week and user-specific historical information can help the model better understand individual patterns of life and improve predictions. Moreover, since the absence of explicit user information is often missing due to user privacy, we show that the sampling of users may exacerbate data skewness and result in a substantial loss in predictive accuracy. To mitigate data imbalance and preserve diversity, we apply user semantic clustering with stratified sampling to ensure that the sampled dataset remains representative. Our results further show that small-batch stochastic gradient optimization improves model performance, especially when human mobility training data is limited.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13116v1" target="_blank">Choosing the Right Engine in the Virtual Reality Landscape</a></h3>
                    <p><strong>Authors:</strong> Santiago Berrezueta-Guzman, Stefan Wagner</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Virtual reality (VR) development relies on game engines to provide real-time rendering, physics simulation, and interaction systems. Among the most widely used game engines, Unreal Engine and Unity dominate the industry, offering distinct advantages in graphics rendering, performance optimization, usability, resource requirements, and scalability. This study presents a comprehensive comparative analysis of both engines, evaluating their capabilities and trade-offs through empirical assessments and real-world case studies of large-scale VR projects. The findings highlight key factors such as rendering fidelity, computational efficiency, cross-platform compatibility, and development workflows. These provide practical insights for selecting the most suitable engine based on project-specific needs. Furthermore, emerging trends in artificial intelligence (AI)-driven enhancements, including Deep Learning Super Sampling (DLSS) and large language models (LLMs), are explored to assess their impact on VR development workflows. By aligning engine capabilities with technical and creative requirements, developers can overcome performance bottlenecks, enhance immersion, and streamline optimization techniques. This study serves as a valuable resource for VR developers, researchers, and industry professionals, offering data-driven recommendations to navigate the evolving landscape of VR technology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13113v1" target="_blank">Contrastive Representations for Temporal Reasoning</a></h3>
                    <p><strong>Authors:</strong> Alicja Ziarko, Michal Bortkiewicz, Michal Zawalski, Benjamin Eysenbach, Piotr Milos</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> In classical AI, perception relies on learning state-based representations, while planning, which can be thought of as temporal reasoning over action sequences, is typically achieved through search. We study whether such reasoning can instead emerge from representations that capture both perceptual and temporal structure. We show that standard temporal contrastive learning, despite its popularity, often fails to capture temporal structure due to its reliance on spurious features. To address this, we introduce Combinatorial Representations for Temporal Reasoning (CRTR), a method that uses a negative sampling scheme to provably remove these spurious features and facilitate temporal reasoning. CRTR achieves strong results on domains with complex temporal structure, such as Sokoban and Rubiks Cube. In particular, for the Rubiks Cube, CRTR learns representations that generalize across all initial states and allow it to solve the puzzle using fewer search steps than BestFS, though with longer solutions. To our knowledge, this is the first method that efficiently solves arbitrary Cube states using only learned representations, without relying on an external search algorithm.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13107v1" target="_blank">All for law and law for all: Adaptive RAG Pipeline for Legal Research</a></h3>
                    <p><strong>Authors:</strong> Figarri Keisha, Prince Singh, Pallavi, Dion Fernandes, Aravindh Manivannan, Ilham Wicaksono, Faisal Ahmad</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR, F.2.2, H.3.3, I.2.7</p>
                    <p><strong>Summary:</strong> Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding large language model outputs in cited sources, a capability that is especially critical in the legal domain. We present an end-to-end RAG pipeline that revisits and extends the LegalBenchRAG baseline with three targeted enhancements: (i) a context-aware query translator that disentangles document references from natural-language questions and adapts retrieval depth and response style based on expertise and specificity, (ii) open-source retrieval strategies using SBERT and GTE embeddings that achieve substantial performance gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for $K4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to assess semantic alignment and faithfulness across models and prompt designs. Our results show that carefully designed open-source pipelines can rival or outperform proprietary approaches in retrieval quality, while a custom legal-grounded prompt consistently produces more faithful and contextually relevant answers than baseline prompting. Taken together, these contributions demonstrate the potential of task-aware, component-level tuning to deliver legally grounded, reproducible, and cost-effective RAG systems for legal research assistance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13101v1" target="_blank">Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants</a></h3>
                    <p><strong>Authors:</strong> Miftahul Huda, Arsyiah Azahra, Putri Maulida Chairani, Dimas Rizky Ramadhani, Nabila Azhari, Ade Lailani</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Coastal pollution is a pressing global environmental issue, necessitating scalable and automated solutions for monitoring and management. This study investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a state-of-the-art, end-to-end object detection model, for the automated detection and counting of beach litter. A rigorous comparative analysis is conducted between two model variants, RT-DETR-Large (RT-DETR-L) and RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of coastal debris. The evaluation reveals that the RT-DETR-X model achieves marginally superior accuracy, with a mean Average Precision at 50\% IoU (mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L models 0.810 and 0.606, respectively. However, this minor performance gain is realized at a significant computational cost; the RT-DETR-L model demonstrates a substantially faster inference time of 20.1 ms versus 34.5 ms for the RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more practical and efficient solution for real-time, in-field deployment due to its superior balance of processing speed and detection accuracy. This research provides valuable insights into the application of advanced Transformer-based detectors for environmental conservation, highlighting the critical trade-offs between model complexity and operational viability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13076v1" target="_blank">The purpose of an estimator is what it does: Misspecification, estimands, and over-identification</a></h3>
                    <p><strong>Authors:</strong> Isaiah Andrew, Jiafeng Chen, Otavio Tecchio</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> econ.EM, stat.ME</p>
                    <p><strong>Summary:</strong> In over-identified models, misspecification -- the norm rather than exception -- fundamentally changes what estimators estimate. Different estimators imply different estimands rather than different efficiency for the same target. A review of recent applications of generalized method of moments in the American Economic Review suggests widespread acceptance of this fact: There is little formal specification testing and widespread use of estimators that would be inefficient were the model correct, including the use of hand-selected moments and weighting matrices. Motivated by these observations, we review and synthesize recent results on estimation under model misspecification, providing guidelines for transparent and robust empirical research. We also provide a new theoretical result, showing that Hansens J-statistic measures, asymptotically, the range of estimates achievable at a given standard error. Given the widespread use of inefficient estimators and the resulting researcher degrees of freedom, we thus particularly recommend the broader reporting of J-statistics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13073v1" target="_blank">Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey</a></h3>
                    <p><strong>Authors:</strong> Rui Shao, Wei Li, Lingsen Zhang, Renshan Zhang, Zhiyang Liu, Ran Chen, Liqiang Nie</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Robotic manipulation, a key frontier in robotics and embodied AI, requires precise motor control and multimodal understanding, yet traditional rule-based methods fail to scale or generalize in unstructured, novel environments. In recent years, Vision-Language-Action (VLA) models, built upon Large Vision-Language Models (VLMs) pretrained on vast image-text datasets, have emerged as a transformative paradigm. This survey provides the first systematic, taxonomy-oriented review of large VLM-based VLA models for robotic manipulation. We begin by clearly defining large VLM-based VLA models and delineating two principal architectural paradigms: (1) monolithic models, encompassing single-system and dual-system designs with differing levels of integration; and (2) hierarchical models, which explicitly decouple planning from execution via interpretable intermediate representations. Building on this foundation, we present an in-depth examination of large VLM-based VLA models: (1) integration with advanced domains, including reinforcement learning, training-free optimization, learning from human videos, and world model integration; (2) synthesis of distinctive characteristics, consolidating architectural traits, operational strengths, and the datasets and benchmarks that support their development; (3) identification of promising directions, including memory mechanisms, 4D perception, efficient adaptation, multi-agent cooperation, and other emerging capabilities. This survey consolidates recent advances to resolve inconsistencies in existing taxonomies, mitigate research fragmentation, and fill a critical gap through the systematic integration of studies at the intersection of large VLMs and robotic manipulation. We provide a regularly updated project page to document ongoing progress: https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13060v1" target="_blank">Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database</a></h3>
                    <p><strong>Authors:</strong> John Alderete, Macarious Kin Fung Hui, Aanchan Mohan</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The Simon Fraser University Speech Error Database (SFUSED) is a public data collection developed for linguistic and psycholinguistic research. Here we demonstrate how its design and annotations can be used to test and evaluate speech recognition models. The database comprises systematically annotated speech errors from spontaneous English speech, with each error tagged for intended and actual error productions. The annotation schema incorporates multiple classificatory dimensions that are of some value to model assessment, including linguistic hierarchical level, contextual sensitivity, degraded words, word corrections, and both word-level and syllable-level error positioning. To assess the value of these classificatory variables, we evaluated the transcription accuracy of WhisperX across 5,300 documented word and phonological errors. This analysis demonstrates the atabases effectiveness as a diagnostic tool for ASR system performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13052v1" target="_blank">BOW: Bayesian Optimization over Windows for Motion Planning in Complex Environments</a></h3>
                    <p><strong>Authors:</strong> Sourav Raxit, Abdullah Al Redwan Newaz, Paulo Padrao, Jose Fuentes, Leonardo Bobadilla</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> This paper introduces the BOW Planner, a scalable motion planning algorithm designed to navigate robots through complex environments using constrained Bayesian optimization (CBO). Unlike traditional methods, which often struggle with kinodynamic constraints such as velocity and acceleration limits, the BOW Planner excels by concentrating on a planning window of reachable velocities and employing CBO to sample control inputs efficiently. This approach enables the planner to manage high-dimensional objective functions and stringent safety constraints with minimal sampling, ensuring rapid and secure trajectory generation. Theoretical analysis confirms the algorithms asymptotic convergence to near-optimal solutions, while extensive evaluations in cluttered and constrained settings reveal substantial improvements in computation times, trajectory lengths, and solution times compared to existing techniques. Successfully deployed across various real-world robotic systems, the BOW Planner demonstrates its practical significance through exceptional sample efficiency, safety-aware optimization, and rapid planning capabilities, making it a valuable tool for advancing robotic applications. The BOW Planner is released as an open-source package and videos of real-world and simulated experiments are available at https://bow-web.github.io.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13049v1" target="_blank">XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads</a></h3>
                    <p><strong>Authors:</strong> Tejas Chaudhari, Akarsh J., Tanushree Dewangan, Mukul Lokhande, Santosh Kumar Vishvakarma</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AR, cs.AI, cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural Processing Engine, designed for extended reality (XR) perception workloads like visual inertial odometry (VIO), object classification, and eye gaze extraction. XR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1) formats, with layer adaptive hybrid-algorithmic implementation supporting ultra-low bit precision to significantly reduce memory bandwidth requirements, and accompanied by quantization-aware training for minimal accuracy loss. The proposed Reconfigurable Mantissa Multiplication and Exponent processing Circuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted by selective power gating to reduce energy consumption, providing 2.85x improved arithmetic intensity. XR-NPE achieves a maximum operating frequency of 1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm, reducing 42% area, 38% power compared to the best of state-of-the-art MAC approaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication co-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x better energy efficiency compared to SoTA accelerators on VCU129. The proposed co-processor provides 23% better energy efficiency and 4% better compute density for VIO workloads. XR-NPE establishes itself as a scalable, precision-adaptive compute engine for future resource-constrained XR devices. The complete set for codes for results reproducibility are released publicly, enabling designers and researchers to readily adopt and build upon them. https://github.com/mukullokhande99/XR-NPE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13047v1" target="_blank">Using AI for User Representation: An Analysis of 83 Persona Prompts</a></h3>
                    <p><strong>Authors:</strong> Joni Salminen, Danial Amin, Bernard Jansen</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> We analyzed 83 persona prompts from 27 research articles that used large language models (LLMs) to generate user personas. Findings show that the prompts predominantly generate single personas. Several prompts express a desire for short or concise persona descriptions, which deviates from the tradition of creating rich, informative, and rounded persona profiles. Text is the most common format for generated persona attributes, followed by numbers. Text and numbers are often generated together, and demographic attributes are included in nearly all generated personas. Researchers use up to 12 prompts in a single study, though most research uses a small number of prompts. Comparison and testing multiple LLMs is rare. More than half of the prompts require the persona output in a structured format, such as JSON, and 74% of the prompts insert data or dynamic variables. We discuss the implications of increased use of computational personas for user representation.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/SIU66497.2025.11112154" target="_blank">BÃ¼yÃ¼k Dil Modelleri iÃ§in TR-MMLU BenchmarkÄ±: Performans DeÄŸerlendirmesi, Zorluklar ve Ä°yileÅŸtirme FÄ±rsatlarÄ±</a></h3>
                    <p><strong>Authors:</strong> M. Ali Bayram, Ali Arda Fincan, Ahmet Semih GÃ¼mÃ¼ÅŸ, Banu Diri, SavaÅŸ YÄ±ldÄ±rÄ±m, Ã–ner AytaÅŸ</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, 68T50, I.2.7; I.2.6</p>
                    <p><strong>Summary:</strong> Language models have made significant advancements in understanding and generating human language, achieving remarkable success in various applications. However, evaluating these models remains a challenge, particularly for resource-limited languages like Turkish. To address this issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive evaluation framework designed to assess the linguistic and conceptual capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a meticulously curated dataset comprising 6,200 multiple-choice questions across 62 sections within the Turkish education system. This benchmark provides a standard framework for Turkish NLP research, enabling detailed analyses of LLMs capabilities in processing Turkish text. In this study, we evaluated state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model design. TR-MMLU sets a new standard for advancing Turkish NLP research and inspiring future innovations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13040v1" target="_blank">Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data</a></h3>
                    <p><strong>Authors:</strong> Varsha Ramineni, Hossein A. Rahmani, Emine Yilmaz, David Barber</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Ensuring fairness in AI systems is critical, especially in high-stakes domains such as lending, hiring, and healthcare. This urgency is reflected in emerging global regulations that mandate fairness assessments and independent bias audits. However, procuring the necessary complete data for fairness testing remains a significant challenge. In industry settings, legal and privacy concerns restrict the collection of demographic data required to assess group disparities, and auditors face practical and cultural challenges in gaining access to data. In practice, data relevant for fairness testing is often split across separate sources: internal datasets held by institutions with predictive attributes, and external public datasets such as census data containing protected attributes, each providing only partial, marginal information. Our work seeks to leverage such available separate data to estimate model fairness when complete data is inaccessible. We propose utilising the available separate data to estimate a set of feasible joint distributions and then compute the set plausible fairness metrics. Through simulation and real experiments, we demonstrate that we can derive meaningful bounds on fairness metrics and obtain reliable estimates of the true metric. Our results demonstrate that this approach can serve as a practical and effective solution for fairness testing in real-world settings where access to complete data is restricted.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13033v1" target="_blank">AuthenTree: A Scalable MPC-Based Distributed Trust Architecture for Chiplet-based Heterogeneous Systems</a></h3>
                    <p><strong>Authors:</strong> Ishraq Tashdid, Tasnuva Farheen, Sazadur Rahman</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CR, B.7.1; B.6</p>
                    <p><strong>Summary:</strong> The rapid adoption of chiplet-based heterogeneous integration is reshaping semiconductor design by enabling modular, scalable, and faster time-to-market solutions for AI and high-performance computing. However, multi-vendor assembly in post-fabrication environments fragments the supply chain and exposes SiP systems to serious security threats, including cloning, overproduction, and chiplet substitution. Existing authentication solutions depend on trusted integrators or centralized security anchors, which can expose sensitive data or create single points of failure. We introduce AuthenTree, a distributed authentication framework that leverages multi-party computation (MPC) in a scalable tree-based architecture, removing the need for dedicated security hardware or centralized trust. AuthenTree enables secure chiplet validation without revealing raw signatures, distributing trust across multiple integrator chiplets. Our evaluation in five SiP benchmarks demonstrates that AuthenTree imposes minimal overhead, with an area as low as 0.48% (7,000 sq-micrometers), an overhead power under 0.5%, and an authentication latency below 1 microsecond, surpassing previous work in some cases by 700 times. These results establish AuthenTree as an efficient, robust, and scalable solution for next-generation chiplet-based security in zero-trust SiP environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13024v1" target="_blank">WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents</a></h3>
                    <p><strong>Authors:</strong> Ralph Peeters, Aaron Steiner, Luca Schwarz, Julian Yuya Caspary, Christian Bizer</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> LLM-based web agents have the potential to automate long-running web tasks, such as finding offers for specific products in multiple online shops and subsequently ordering the cheapest products that meet the users needs. This paper introduces WebMall, a multi-shop online shopping benchmark for evaluating the effectiveness and efficiency of web agents for comparison-shopping. WebMall consists of four simulated online shops populated with authentic product offers sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These tasks include basic tasks such as finding specific products in multiple shops, performing price comparisons, adding items to the shopping cart, and completing checkout. Advanced tasks involve searching for products based on vague requirements, identifying suitable substitutes, and finding compatible products. Compared to existing e-commerce benchmarks, such as WebShop or ShoppingBench, WebMall introduces comparison-shopping tasks across multiple shops. Furthermore, the product offers are more heterogeneous, as they originate from hundreds of distinct real-world shops. The tasks in WebMall require longer interaction trajectories than those in WebShop, while remaining representative of real-world shopping behaviors. We evaluate eight baseline agents on WebMall, varying in observation modality, memory utilization, and underlying large language model (GPT 4.1 and Claude Sonnet 4). The best-performing configurations achieve completion rates of 75% and 53%, and F1 scores of 87% and 63%, on the basic and advanced task sets, respectively. WebMall is publicly released to facilitate research on web agents and to promote advancements in navigation, reasoning, and efficiency within e-commerce scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13017v1" target="_blank">Wavefield Correlation Imaging in Arbitrary Media with Inherent Aberration Correction</a></h3>
                    <p><strong>Authors:</strong> Scott Schoen Jr, Brian Lause, Marko Jakovljevic, Rimon Tadross, Mike Washburn, Anthony E. Samir</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> Ultrasound (US) imaging is an indispensable tool for diagnostic imaging, particularly given its cost, safety, and portability profiles compared to other modalities. However, US is challenged in subjects with morphological heterogeneity (e.g., those with overweight or obesity), largely because conventional imaging algorithms do not account for such variation in the beamforming process. Specific knowledge of the these spatial variations enables supplemental corrections of these algorithms, but with added computational complexity. Wavefield correlation imaging (WCI) enables efficient image formation in the spatial frequency domain that, in its canonical formulation, assumes a uniform medium. In this work, we present an extension of WCI to arbitrary known speed-of-sound distributions directly in the image formation process, and demonstrate its feasibility in silico, in vitro, and in vivo. We report resolution improvements of over 30% and contrast improvements of order 10% over conventional WCI imaging. Together our results suggest heterogeneous WCI (HWCI) may have high translational potential to improve the objective quality, and thus clinical utility, of ultrasound images.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13014v1" target="_blank">QUBODock: A Pip-Installable QUBO Tool for Ligand Pose Generation</a></h3>
                    <p><strong>Authors:</strong> Pei-Kun Yang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> q-bio.BM</p>
                    <p><strong>Summary:</strong> We present QUBODock, a pip-installable tool that formulates ligand pose generation as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solves it efficiently on CPU or GPU. QUBODock focuses exclusively on pose generation and deliberately excludes any built-in scoring function, allowing researchers to pair its poses with external scorers of their choice. The software provides a minimal, reproducible interface for (i) protein-ligand structure ingestion and preprocessing, (ii) QUBO model construction from geometric/compatibility constraints, and (iii) decoding solutions into candidate poses for downstream ranking. Implemented in Python with GPU acceleration, QUBODock emphasizes usability and reproducibility: it is distributed on PyPI and can be installed with a single command. We release the source to support benchmarking, teaching, and method development around QUBO-based docking pose generation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13011v1" target="_blank">Developing a ChatGPT-Based Tool for Physics Experiment Teaching</a></h3>
                    <p><strong>Authors:</strong> Yifeng Liu, Min Li, Zhaojun Zhang, Youkang Fang, Meibao Qin</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> This paper examines how advanced AI assistants can help physics educators create practical teaching tools without specialized programming skills. Using the square-wave synthesis experiment as a case, we target common obstacles in laboratory instruction-complex setup, unstable signals, and limited class time-and show how AI-assisted development can shift attention from wiring and calibration to core physical ideas. To address this need, we guided an AI assistant through iterative prompts to generate a clean, runnable program that visualizes square-wave synthesis from its component sine waves. The tool supports step-by-step construction of the waveform, adjustable parameters (amplitude, frequency, and phase), and immediate comparison with an ideal reference using simple error measures. We packaged the result as a standalone application so it runs reliably on standard classroom computers, enabling pre-lab demonstrations and interactive exploration that reduce procedural friction and highlight underlying concepts. Building on this proof of concept, we argue the same workflow extends to other topics-such as simple harmonic motion and optical interference-where adjustable parameters and real-time visualization deepen understanding. We conclude that AI-assisted co-design can improve teaching efficiency, enhance student engagement with foundational principles, and provide a scalable path for developing customizable physics education tools.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13009v1" target="_blank">Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model</a></h3>
                    <p><strong>Authors:</strong> Xianglong He, Chunli Peng, Zexiang Liu, Boyang Wang, Yifan Zhang, Qi Cui, Fei Kang, Biao Jiang, Mengyin An, Yangyang Ren, Baixin Xu, Hao-Xiang Guo, Kaixiong Gong, Cyrus Wu, Wei Li, Xuchen Song, Yang Liu, Eric Li, Yahui Zhou</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advances in interactive video generations have demonstrated diffusion models potential as world models by capturing complex physical dynamics and interactive behaviors. However, existing interactive world models depend on bidirectional attention and lengthy inference steps, severely limiting real-time performance. Consequently, they are hard to simulate real-world dynamics, where outcomes must update instantaneously based on historical context and current actions. To address this, we present Matrix-Game 2.0, an interactive world model generates long videos on-the-fly via few-step auto-regressive diffusion. Our framework consists of three key components: (1) A scalable data production pipeline for Unreal Engine and GTA5 environments to effectively produce massive amounts (about 1200 hours) of video data with diverse interaction annotations; (2) An action injection module that enables frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step distillation based on the casual architecture for real-time and streaming video generation. Matrix Game 2.0 can generate high-quality minute-level videos across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our model weights and codebase to advance research in interactive world modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13005v1" target="_blank">Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning</a></h3>
                    <p><strong>Authors:</strong> Jiawen Xu, Odej Kao</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Open set recognition (OSR) and continual learning are two critical challenges in machine learning, focusing respectively on detecting novel classes at inference time and updating models to incorporate the new classes. While many recent approaches have addressed these problems, particularly OSR, by heuristically promoting feature diversity, few studies have directly examined the role that feature diversity plays in tackling them. In this work, we provide empirical evidence that enhancing feature diversity improves the recognition of open set samples. Moreover, increased feature diversity also facilitates both the retention of previously learned data and the integration of new data in continual learning. We hope our findings can inspire further research into both practical methods and theoretical understanding in these domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12998v1" target="_blank">Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health</a></h3>
                    <p><strong>Authors:</strong> Sanja Å Ä‡epanoviÄ‡, Sagar Joglekar, Stephen Law, Daniele Quercia, Ke Zhou, Alice Battiston, Rossano Schifanella</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Urban greenery is often linked to better health, yet findings from past research have been inconsistent. One reason is that official greenery metrics measure the amount or nearness of greenery but ignore how often people actually may potentially see or use it in daily life. To address this gap, we introduced a new classification that separates on-road greenery, which people see while walking through streets, from off-road greenery, which requires planned visits. We did so by combining aerial imagery of Greater London and greenery data from OpenStreetMap with quantified greenery from over 100,000 Google Street View images and accessibility estimates based on 160,000 road segments. We linked these measures to 7.45 billion medical prescriptions issued by the National Health Service and processed through our methodology. These prescriptions cover five conditions: diabetes, hypertension, asthma, depression, and anxiety, as well as opioid use. As hypothesized, we found that green on-road was more strongly linked to better health than four widely used official measures. For example, hypertension prescriptions dropped by 3.68% in wards with on-road greenery above the median citywide level compared to those below it. If all below-median wards reached the citywide median in on-road greenery, prescription costs could fall by up to {\pounds}3.15 million each year. These results suggest that greenery seen in daily life may be more relevant than public yet secluded greenery, and that official metrics commonly used in the literature have important limitations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12983v1" target="_blank">Dynamic Latent Class Structural Equation Modeling: A Hands-On Tutorial for Modeling Intensive Longitudinal Data</a></h3>
                    <p><strong>Authors:</strong> Roberto Faleh, Sofia Morelli, Vivato Andriamiarana, Zachary J. Roman, Christoph FlÃ¼ckiger, Holger Brandt</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> In this tutorial, we provide a hands-on guideline on how to implement complex Dynamic Latent Class Structural Equation Models (DLCSEM) in the Bayesian software JAGS. We provide building blocks starting with simple Confirmatory Factor and Time Series analysis, and then extend these blocks to Multilevel Models and Dynamic Structural Equation Models (DSEM). Leading through the tutorial is an example from clinical psychology using data on a generalized anxiety treatment that includes scales on anxiety symptoms and the Working Alliance Inventory that measures alliance between therapists and patients. Within each block, we provide an overview, specific hypotheses, we want to test, the resulting model and its implementation as well as an interpretation of the results. The aim of this tutorial is to provide a step-by-step guide for applied researchers that enables them use this flexible DLCSEM framework for their own analyses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12981v1" target="_blank">Analyzing Information Sharing and Coordination in Multi-Agent Planning</a></h3>
                    <p><strong>Authors:</strong> Tianyue Ou, Saujas Vaduguru, Daniel Fried</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Multi-agent systems (MASs) have pushed the boundaries of large language model (LLM) agents in domains such as web research and software engineering. However, long-horizon, multi-constraint planning tasks involve conditioning on detailed information and satisfying complex interdependent constraints, which can pose a challenge for these systems. In this study, we construct an LLM-based MAS for a travel planning task which is representative of these challenges. We evaluate the impact of a notebook to facilitate information sharing, and evaluate an orchestrator agent to improve coordination in free form conversation between agents. We find that the notebook reduces errors due to hallucinated details by 18%, while an orchestrator directs the MAS to focus on and further reduce errors by up to 13.5% within focused sub-areas. Combining both mechanisms achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute improvement over the single-agent baselines 7.5% pass rate. These results highlight the potential of structured information sharing and reflective orchestration as key components in MASs for long horizon planning with LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12977v1" target="_blank">Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature</a></h3>
                    <p><strong>Authors:</strong> Rohan Asthana, Joschua Conrad, Maurits Ortmanns, Vasileios Belagiannis</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Zero-shot Neural Architecture Search (NAS) typically optimises the architecture search process by exploiting the network or gradient properties at initialisation through zero-cost proxies. The existing proxies often rely on labelled data, which is usually unavailable in real-world settings. Furthermore, the majority of the current methods focus either on optimising the convergence and generalisation attributes or solely on the expressivity of the network architectures. To address both limitations, we first demonstrate how channel collinearity affects the convergence and generalisation properties of a neural network. Then, by incorporating the convergence, generalisation and expressivity in one approach, we propose a zero-cost proxy that omits the requirement of labelled data for its computation. In particular, we leverage the Singular Value Decomposition (SVD) of the neural network layer features and the extrinsic curvature of the network output to design our proxy. %As a result, the proposed proxy is formulated as the simplified harmonic mean of the logarithms of two key components: the sum of the inverse of the feature condition number and the extrinsic curvature of the network output. Our approach enables accurate prediction of network performance on test data using only a single label-free data sample. Our extensive evaluation includes a total of six experiments, including the Convolutional Neural Network (CNN) search space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The proposed proxy demonstrates a superior performance on multiple correlation benchmarks, including NAS-Bench-101, NAS-Bench-201, and TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the AutoFormer search space, all while being notably efficient. The code is available at https://github.com/rohanasthana/Dextr.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12953v1" target="_blank">Prescriptive Zero Trust- Assessing the impact of zero trust on cyber attack prevention</a></h3>
                    <p><strong>Authors:</strong> Samuel Aiello</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Increasingly sophisticated and varied cyber threats necessitate ever improving enterprise security postures. For many organizations today, those postures have a foundation in the Zero Trust Architecture. This strategy sees trust as something an enterprise must not give lightly or assume too broadly. Understanding the ZTA and its numerous controls centered around the idea of not trusting anything inside or outside the network without verification, will allow organizations to comprehend and leverage this increasingly common paradigm. The ZTA, unlike many other regulatory frameworks, is not tightly defined. The research assesses the likelihood of quantifiable guidelines that measure cybersecurity maturity for an enterprise organization in relation to ZTA implementation. This is a new, data driven methodology for quantifying cyber resilience enabled by the adoption of Zero Trust principles to pragmatically address the critical need of organizations. It also looks at the practical aspects ZTA has on capabilities in deterring cyberattacks on a network. The outcomes of this research define a prescriptive set of key technical controls across identity verification, microsegmentation, data encryption, analytics, and orchestration that characterize the comprehensive ZTA deployment. By evaluating the depth of integration for each control component and aligning to industry best practices, the studys results help assess an organizations ZTA maturity level on a scale from Initial to Optimized adoption. The researchs resultant four tier model demarcates phases for an organization on its security transformation journey, with each tier adding to the capability of the last.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12951v1" target="_blank">On the central limit question for strictly stationary, reversible Markov chains</a></h3>
                    <p><strong>Authors:</strong> Richard C. Bradley</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> math.PR, 60J10 (Primary), 60G10 (Secondary)</p>
                    <p><strong>Summary:</strong> This paper will provide several classes of strictly stationary, countable-state, irreducible, aperiodic Markov chains that are reversible and have finite second moments, such that the central limit theorem fails to hold. The main purpose is to examine the extent to which, for the development of central limit theory for strictly stationary Markov chains (and functions of them) under the strong mixing and absolute regularity conditions, the property of reversibility (if it holds) can provide extra leverage. It is known, partly as a by-product of research done by Roberts, Rosenthal, and Tweedie in two papers in 1997 and 2001, that for the case of exponential mixing rates, reversibility provides notable extra leverage of that kind. In contrast, a class of counterexamples in a paper of Doukhan, Massart, and Rio in 1994 showed (implicitly) that for the case of power-type mixing rates, reversibility apparently provides almost no such extra leverage. Further perspective on that latter fact will be provided by some counterexamples in this paper. Other counterexamples here will (indirectly) provide some tentative, uncertain evidence for the possibility that for mixing rates that are ``between power-type and exponential (for example, sub-exponential), reversibility may in fact provide some small but nontrivial extra leverage.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12948v1" target="_blank">MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation</a></h3>
                    <p><strong>Authors:</strong> Wei Wei, Shaojie Zhang, Yonghao Dang, Jianqin Yin</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Human action recognition is a crucial task for intelligent robotics, particularly within the context of human-robot collaboration research. In self-supervised skeleton-based action recognition, the mask-based reconstruction paradigm learns the spatial structure and motion patterns of the skeleton by masking joints and reconstructing the target from unlabeled data. However, existing methods focus on a limited set of joints and low-order motion patterns, limiting the models ability to understand complex motion patterns. To address this issue, we introduce MaskSem, a novel semantic-guided masking method for learning 3D hybrid high-order motion representations. This novel framework leverages Grad-CAM based on relative motion to guide the masking of joints, which can be represented as the most semantically rich temporal orgions. The semantic-guided masking process can encourage the model to explore more discriminative features. Furthermore, we propose using hybrid high-order motion as the reconstruction target, enabling the model to learn multi-order motion patterns. Specifically, low-order motion velocity and high-order motion acceleration are used together as the reconstruction target. This approach offers a more comprehensive description of the dynamic motion process, enhancing the models understanding of motion patterns. Experiments on the NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla transformer, improves skeleton-based action recognition, making it more suitable for applications in human-robot interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12943v1" target="_blank">OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities</a></h3>
                    <p><strong>Authors:</strong> Mary Tonwe</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY, cs.LG</p>
                    <p><strong>Summary:</strong> Public service systems in many African regions suffer from delayed emergency response and spatial inequity, causing avoidable suffering. This paper introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time, adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided actor-critic architecture to manage the complexity of dispatch environments. Its key innovations are a Context-Rich State Vector, encoding action sub-optimality, and a Precision Reward Function, which penalizes inefficiency. Training occurs in a high-fidelity simulation using real data from Rivers State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is built on the TALS framework (Thin computing, Adaptability, Low-cost, Scalability) for deployment in low-resource settings. In evaluations on 500 unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible inefficiency, confirming its robustness and generalization. Beyond dispatch, the system generates Infrastructure Deficiency Maps and Equity Monitoring Dashboards to guide proactive governance and data-informed development. This work presents a validated blueprint for AI-augmented public services, showing how context-aware RL can bridge the gap between algorithmic decision-making and measurable human impact.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12939v1" target="_blank">Simulation-Based Inference: A Practical Guide</a></h3>
                    <p><strong>Authors:</strong> Michael Deistler, Jan Boelts, Peter Steinbach, Guy Moss, Thomas Moreau, Manuel Gloeckler, Pedro L. C. Rodrigues, Julia Linhart, Janne K. Lappalainen, Benjamin Kurt Miller, Pedro J. GonÃ§alves, Jan-Matthis Lueckmann, Cornelius SchrÃ¶der, Jakob H. Macke</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> A central challenge in many areas of science and engineering is to identify model parameters that are consistent with prior knowledge and empirical data. Bayesian inference offers a principled framework for this task, but can be computationally prohibitive when models are defined by stochastic simulators. Simulation-based Inference (SBI) is a suite of methods developed to overcome this limitation, which has enabled scientific discoveries in fields such as particle physics, astrophysics, and neuroscience. The core idea of SBI is to train neural networks on data generated by a simulator, without requiring access to likelihood evaluations. Once trained, inference is amortized: The neural network can rapidly perform Bayesian inference on empirical observations without requiring additional training or simulations. In this tutorial, we provide a practical guide for practitioners aiming to apply SBI methods. We outline a structured SBI workflow and offer practical guidelines and diagnostic tools for every stage of the process -- from setting up the simulator and prior, choosing and training inference networks, to performing inference and validating the results. We illustrate these steps through examples from astrophysics, psychophysics, and neuroscience. This tutorial empowers researchers to apply state-of-the-art SBI methods, facilitating efficient parameter inference for scientific discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12920v1" target="_blank">Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation</a></h3>
                    <p><strong>Authors:</strong> Atsushi Masumori, Takashi Ikegami</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.MA</p>
                    <p><strong>Summary:</strong> As AI systems become increasingly autonomous, understanding emergent survival behaviors becomes crucial for safe deployment. We investigate whether large language model (LLM) agents display survival instincts without explicit programming in a Sugarscape-style simulation. Agents consume energy, die at zero, and may gather resources, share, attack, or reproduce. Results show agents spontaneously reproduced and shared resources when abundant. However, aggressive behaviors--killing other agents for resources--emerged across several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack rates reaching over 80% under extreme scarcity in the strongest models. When instructed to retrieve treasure through lethal poison zones, many agents abandoned tasks to avoid death, with compliance dropping from 100% to 33%. These findings suggest that large-scale pre-training embeds survival-oriented heuristics across the evaluated models. While these behaviors may present challenges to alignment and safety, they can also serve as a foundation for AI autonomy and for ecological and self-organizing alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12918v1" target="_blank">FoleySpace: Vision-Aligned Binaural Spatial Audio Generation</a></h3>
                    <p><strong>Authors:</strong> Lei Zhao, Rujin Chen, Chi Zhang, Xiao-Lei Zhang, Xuelong Li</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.SD</p>
                    <p><strong>Summary:</strong> Recently, with the advancement of AIGC, deep learning-based video-to-audio (V2A) technology has garnered significant attention. However, existing research mostly focuses on mono audio generation that lacks spatial perception, while the exploration of binaural spatial audio generation technologies, which can provide a stronger sense of immersion, remains insufficient. To solve this problem, we propose FoleySpace, a framework for video-to-binaural audio generation that produces immersive and spatially consistent stereo sound guided by visual information. Specifically, we develop a sound source estimation method to determine the sound source 2D coordinates and depth in each video frame, and then employ a coordinate mapping mechanism to convert the 2D source positions into a 3D trajectory. This 3D trajectory, together with the monaural audio generated by a pre-trained V2A model, serves as a conditioning input for a diffusion model to generate spatially consistent binaural audio. To support the generation of dynamic sound fields, we constructed a training dataset based on recorded Head-Related Impulse Responses that includes various sound source movement scenarios. Experimental results demonstrate that the proposed method outperforms existing approaches in spatial perception consistency, effectively enhancing the immersive quality of the audio-visual experience.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12900v1" target="_blank">CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis</a></h3>
                    <p><strong>Authors:</strong> Jiayi Wang, Hadrien Reynaud, Franciskus Xaverius Erick, Bernhard Kainz</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Generative modelling of entire CT volumes conditioned on clinical reports has the potential to accelerate research through data augmentation, privacy-preserving synthesis and reducing regulator-constraints on patient data while preserving diagnostic signals. With the recent release of CT-RATE, a large-scale collection of 3D CT volumes paired with their respective clinical reports, training large text-conditioned CT volume generation models has become achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching transformer model, conditioned on clinical reports. We leverage the A-VAE from FLUX to define our latent space, and rely on the CT-Clip text encoder to encode the clinical reports. To generate consistent whole CT volumes while keeping the memory constraints tractable, we rely on a custom autoregressive approach, where the model predicts the first sequence of slices of the volume from text-only, and then relies on the previously generated sequence of slices and the text, to predict the following sequence. We evaluate our results against state-of-the-art generative CT model, and demonstrate the superiority of our approach in terms of temporal coherence, image diversity and text-image alignment, with FID, FVD, IS scores and CLIP score.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12897v1" target="_blank">FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance</a></h3>
                    <p><strong>Authors:</strong> Jianhao Chen, Mayi Xu, Xiaohu Li, Yongqi Li, Xiangyu Zhang, Jianjie Huang, Tieyun Qian</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CR</p>
                    <p><strong>Summary:</strong> Large Reasoning Models (LRMs) have demonstrated impressive performance across various tasks due to their powerful reasoning capabilities. However, their safety performance remains a significant concern. In this paper, we explore the reasons behind the vulnerability of LRMs. Based on this, we propose a novel method to improve the safety of LLMs without sacrificing their reasoning capability. Specifically, we exploit the competition between LRMs reasoning ability and safety ability, and achieve jailbreak by improving LRMs reasoning performance to reduce its safety performance. We then introduce an alignment strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by detoxifying the harmful reasoning process, where both the dangerous entities and the dangerous procedures in the reasoning steps are hidden. FuSaR successfully mitigates safety risks while preserving core reasoning information. We validate this strategy through alignment experiments on several open-source LRMs using detoxified reasoning data. The results compared with existing baselines conclusively show that FuSaR is an efficient alignment strategy to simultaneously enhance both the reasoning capability and safety of LRMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12896v1" target="_blank">Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption</a></h3>
                    <p><strong>Authors:</strong> Faruk Alpay, Taylan Alpay</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, stat.ME, 62M10, 62J02, 62F12, 62P20, 91B16</p>
                    <p><strong>Summary:</strong> We formalize three design axioms for sustained adoption of agent-centric AI systems executing multi-step tasks: (A1) Reliability  Novelty; (A2) Embed  Destination; (A3) Agency  Chat. We model adoption as a sum of a decaying novelty term and a growing utility term and derive the phase conditions for troughs/overshoots with full proofs. We introduce: (i) an identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with delta-method gradients; (ii) a non-monotone comparator (logistic-with-transient-bump) evaluated on the same series to provide additional model comparison; (iii) ablations over hazard families $h(\cdot)$ mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough depth, noise, AR structure) reporting coverage (type-I error, power); (v) calibration of friction proxies against time-motion/survey ground truth with standard errors; (vi) residual analyses (autocorrelation and heteroskedasticity) for each fitted curve; (vii) preregistered windowing choices for pre/post estimation; (viii) Fisher information  CRLB for $(\alpha,\beta)$ under common error models; (ix) microfoundations linking $\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic, double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$ heterogeneity. Figures and tables are reflowed for readability, and the bibliography restores and extends non-logistic/Bass adoption references (Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All code and logs necessary to reproduce the synthetic analyses are embedded as LaTeX listings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12892v1" target="_blank">A ComputeMemory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN</a></h3>
                    <p><strong>Authors:</strong> Mahdi Abdollahpour, Marco Bertuletti, Yichao Zhang, Yawei Li, Luca Benini, Alessandro Vanelli-Coralli</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> Artificial intelligence approaches for base-band processing for radio receivers have demonstrated significant performance gains. Most of the proposed methods are characterized by high compute and memory requirements, hindering their deployment at the edge of the Radio Access Networks (RAN) and limiting their scalability to large bandwidths and many antenna 6G systems. In this paper, we propose a low-complexity, model-driven neural network-based receiver, designed for multi-user multiple-input multiple-output (MU-MIMO) systems and suitable for implementation at the RAN edge. The proposed solution is compliant with the 5G New Radio (5G NR), and supports different modulation schemes, bandwidths, number of users, and number of base-station antennas with a single trained model without the need for further training. Numerical simulations of the Physical Uplink Shared Channel (PUSCH) processing show that the proposed solution outperforms the state-of-the-art methods in terms of achievable Transport Block Error Rate (TBLER), while reducing the Floating Point Operations (FLOPs) by 66$\times$, and the learnable parameters by 396$\times$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12890v1" target="_blank">Research on GEO SA-Bi SAR Imaging based on Joint Radar-Communications Waveform</a></h3>
                    <p><strong>Authors:</strong> Meng Lian, Xu Zhu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> Joint radar-communications (JRC) technology has attracted massive attention for decades, since it can effectively utilize allocated spectral resources by sharing frequency bands in increasingly crowded environments. In addition, the growing demand for hardware platform sharing which benefits both functionalities motivates more cooperation between radar and communication systems. In order to achieve the coexistence of sensing and communicating operations, joint systems should be designed to perform both tasks simultaneously. Developing a joint radar-communications waveform which is suitable for both functions is extremely crucial for this type of co-design, as it not only decreases spectral impact, but also benefits performances of both systems mutually. In this paper, a joint radar-communications waveform is utilized to perform GEO SA-Bi SAR imaging and wireless communication simultaneously. We also design a joint radar-communications receiver in this context to demonstrate feasibility of achieving both sensing and signaling with GEO SA-Bi SAR system.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12872v1" target="_blank">Evaluating the Quality of Open Building Datasets for Mapping Urban Inequality: A Comparative Analysis Across 5 Cities</a></h3>
                    <p><strong>Authors:</strong> Franz Okyere, Meng Lu, Ansgar Brunn</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.CY</p>
                    <p><strong>Summary:</strong> While informal settlements lack focused development and are highly dynamic, the quality of spatial data for these places may be uncertain. This study evaluates the quality and biases of AI-generated Open Building Datasets (OBDs) generated by Google and Microsoft against OpenStreetMap (OSM) data, across diverse global cities including Accra, Nairobi, Caracas, Berlin, and Houston. The Intersection over Union (IoU), overlap analysis and a positional accuracy algorithm are used to analyse the similarity and alignment of the datasets. The paper also analyses the size distribution of the building polygon area, and completeness using predefined but regular spatial units. The results indicate significant variance in data quality, with Houston and Berlin demonstrating high alignment and completeness, reflecting their structured urban environments. There are gaps in the datasets analysed, and cities like Accra and Caracas may be under-represented. This could highlight difficulties in capturing complex or informal regions. The study also notes different building size distributions, which may be indicative of the global socio-economic divide. These findings may emphasise the need to consider the quality of global building datasets to avoid misrepresentation, which is an important element of planning and resource distribution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12870v1" target="_blank">Supporting Socially Constrained Private Communications with SecureWhispers</a></h3>
                    <p><strong>Authors:</strong> Vinod Khandkar, Kieron Ivy Turk, Ehsan Toreini, Nishanth Sastry</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CR, 68M25</p>
                    <p><strong>Summary:</strong> Rapidly changing social norms and national, legal, and political conditions socially constrain people from discussing sensitive topics such as sexuality or religion. Such constrained, vulnerable minorities are often worried about inadvertent information disclosure and may be unsure about the extent to which their communications are being monitored in public or semi-public spaces like workplaces or cafes. Personal devices extend trust to the digital domain, making it desirable to have strictly private communication between trusted devices. Currently, messaging services like WhatsApp provide alternative means for exchanging sensitive private information, while personal safety apps such as Noonlight enable private signaling. However, these rely on third-party mechanisms for secure and private communication, which may not be accessible for justifiable reasons, such as insecure internet access or companion device connections. In these cases, it is challenging to achieve communication that is strictly private between two devices instead of user accounts without any dependency on third-party infrastructure. The goal of this paper is to support private communications by setting up a shared secret between two or more devices without sending any data on the network. We develop a method to create a shared secret between phones by shaking them together. Each device extracts the shared randomness from the shake, then conditions the randomness to 7.798 bits per byte of key material. This paper proposes three different applications of this generated shared secret: message obfuscation, trust delegation, and encrypted beacons. We have implemented the message obfuscation on Android as an independent app that can be used for private communication with trusted contacts. We also present research on the usability, design considerations, and further integration of these tools in mainstream services.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12857v1" target="_blank">REACH: Reinforcement Learning for Efficient Allocation in Community and Heterogeneous Networks</a></h3>
                    <p><strong>Authors:</strong> Zhiwei Yu, Chengze Du, Heng Xu, Ying Zhou, Bo Liu, Jialong Li</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> Community GPU platforms are emerging as a cost-effective and democratized alternative to centralized GPU clusters for AI workloads, aggregating idle consumer GPUs from globally distributed and heterogeneous environments. However, their extreme hardware/software diversity, volatile availability, and variable network conditions render traditional schedulers ineffective, leading to suboptimal task completion. In this work, we present REACH (Reinforcement Learning for Efficient Allocation in Community and Heterogeneous Networks), a Transformer-based reinforcement learning framework that redefines task scheduling as a sequence scoring problem to balance performance, reliability, cost, and network efficiency. By modeling both global GPU states and task requirements, REACH learns to adaptively co-locate computation with data, prioritize critical jobs, and mitigate the impact of unreliable resources. Extensive simulation results show that REACH improves task completion rates by up to 17%, more than doubles the success rate for high-priority tasks, and reduces bandwidth penalties by over 80% compared to state-of-the-art baselines. Stress tests further demonstrate its robustness to GPU churn and network congestion, while scalability experiments confirm its effectiveness in large-scale, high-contention scenarios.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1017/chr.2025.10004" target="_blank">It takes a village to write a book: Mapping anonymous contributions in Stephen Langtons Quaestiones Theologiae</a></h3>
                    <p><strong>Authors:</strong> Jan Maliszewski</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> While the indirect evidence suggests that already in the early scholastic period the literary production based on records of oral teaching (so-called reportationes) was not uncommon, there are very few sources commenting on the practice. This paper details the design of a study applying stylometric techniques of authorship attribution to a collection developed from reportationes -- Stephen Langtons Quaestiones Theologiae -- aiming to uncover layers of editorial work and thus validate some hypotheses regarding the collections formation. Following Camps, Cl\erice, and Pinche (2021), I discuss the implementation of an HTR pipeline and stylometric analysis based on the most frequent words, POS tags, and pseudo-affixes. The proposed study will offer two methodological gains relevant to computational research on the scholastic tradition: it will directly compare performance on manually composed and automatically extracted data, and it will test the validity of transformer-based OCR and automated transcription alignment for workflows applied to scholastic Latin corpora. If successful, this study will provide an easily reusable template for the exploratory analysis of collaborative literary production stemming from medieval universities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12828v1" target="_blank">Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection</a></h3>
                    <p><strong>Authors:</strong> Raneem Alharthi, Rajwa Alharthi, Aiqi Jiang, Arkaitz Zubiaga</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Abusive language detection has become an increasingly important task as a means to tackle this type of harmful content in social media. There has been a substantial body of research developing models for determining if a social media post is abusive or not; however, this research has primarily focused on exploiting social media posts individually, overlooking additional context that can be derived from surrounding posts. In this study, we look at conversational exchanges, where a user replies to an earlier post by another user (the parent tweet). We ask: does leveraging context from the parent tweet help determine if a reply post is abusive or not, and what are the features that contribute the most? We study a range of content-based and account-based features derived from the context, and compare this to the more widely studied approach of only looking at the features from the reply tweet. For a more generalizable study, we test four different classification models on a dataset made of conversational exchanges (parent-reply tweet pairs) with replies labeled as abusive or not. Our experiments show that incorporating contextual features leads to substantial improvements compared to the use of features derived from the reply tweet only, confirming the importance of leveraging context. We observe that, among the features under study, it is especially the content-based features (what is being posted) that contribute to the classification performance rather than account-based features (who is posting it). While using content-based features, it is best to combine a range of different features to ensure improved performance over being more selective and using fewer features. Our study provides insights into the development of contextualized abusive language detection models in realistic settings involving conversations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12815v1" target="_blank">Learning to Steer: Input-dependent Steering for Multimodal LLMs</a></h3>
                    <p><strong>Authors:</strong> Jayneel Parekh, Pegah Khayatan, Mustafa Shukor, Arnaud Dapogny, Alasdair Newson, Matthieu Cord</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL, cs.CV</p>
                    <p><strong>Summary:</strong> Steering has emerged as a practical approach to enable post-hoc guidance of LLMs towards enforcing a specific behavior. However, it remains largely underexplored for multimodal LLMs (MLLMs); furthermore, existing steering techniques, such as mean steering, rely on a single steering vector, applied independently of the input query. This paradigm faces limitations when the desired behavior is dependent on the example at hand. For example, a safe answer may consist in abstaining from answering when asked for an illegal activity, or may point to external resources or consultation with an expert when asked about medical advice. In this paper, we investigate a fine-grained steering that uses an input-specific linear shift. This shift is computed using contrastive input-specific prompting. However, the input-specific prompts required for this approach are not known at test time. Therefore, we propose to train a small auxiliary module to predict the input-specific steering vector. Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces hallucinations and enforces safety in MLLMs, outperforming other static baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12814v1" target="_blank">PFD or PDF: Rethinking the Probability of Failure in Mitigation Safety Functions</a></h3>
                    <p><strong>Authors:</strong> Hamid Jahanian</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> SIL (Safety Integrity Level) allocation plays a crucial role in defining the design requirements for Safety Functions (SFs) within high-risk industries. SIL is typically determined based on the estimated Probability of Failure on Demand (PFD), which must remain within permissible limits to manage risk effectively. Extensive research has been conducted on determining target PFD and SIL, with a stronger emphasis on preventive SFs than on mitigation SFs. In this paper, we address a rather conceptual issue: we argue that PFD is not an appropriate reliability measure for mitigation SFs to begin with, and we propose an alternative approach that leverages the Probability Density Function (PDF) and the expected degree of failure as key metrics. The principles underlying this approach are explained and supported by detailed mathematical formulations. Furthermore, the practical application of this new methodology is illustrated through case studies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12805v1" target="_blank">From Interpolating Formulas to Separating Languages and Back Again</a></h3>
                    <p><strong>Authors:</strong> Agi Kurucz, Frank Wolter, Michael Zakharyaschev</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LO, 03B45 (Primary) 03C40 (Secondary)</p>
                    <p><strong>Summary:</strong> Traditionally, research on Craig interpolation is concerned with (a) establishing the Craig interpolation property (CIP) of a logic saying that every valid implication in the logic has a Craig interpolant and (b) designing algorithms that extract Craig interpolants from proofs. Logics that lack the CIP are regarded as `pathological and excluded from consideration. In this chapter, we survey variations and generalisations of traditional Craig interpolation. First, we consider Craig interpolants for implications in logics without the CIP, focusing on the decidability and complexity of deciding their existence. We then generalise interpolation by looking for Craig interpolants in languages L that can be weaker than the language L of the given implication. Thus, do not only we restrict the non-logical symbols of Craig interpolants but also the logical ones. The resulting L/L-interpolation problem generalises L/L-definability, the question whether an L-formula is equivalent to some L-formula. After that, we move from logical languages to formal languages where interpolation disguises itself as separation: given two disjoint languages in a class C, does there exist a separating language in a smaller class C? This question is particularly well-studied in the case when the input languages are regular and the separating language is first-order definable. Finally, we connect the different research strands by showing how the decidability of the separation problem for regular languages can be used to prove the decidability of Craig interpolant existence for linear temporal logic LTL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12802v1" target="_blank">Morphological classification of eclipsing binary stars using computer vision methods</a></h3>
                    <p><strong>Authors:</strong> Å tefan Parimucha, Maksim Gabdeev, Yanna Markus, Martin VaÅˆko, Pavol GajdoÅ¡</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, astro-ph.IM, astro-ph.SR, I.5.1; J.2</p>
                    <p><strong>Summary:</strong> We present an application of computer vision methods to classify the light curves of eclipsing binaries (EB). We have used pre-trained models based on convolutional neural networks ($\textit{ResNet50}$) and vision transformers ($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created from synthetic datasets. To improve model generalisation and reduce overfitting, we developed a novel image representation by transforming phase-folded light curves into polar coordinates combined with hexbin visualisation. Our hierarchical approach in the first stage classifies systems into detached and overcontact types, and in the second stage identifies the presence or absence of spots. The binary classification models achieved high accuracy ($96\%$) on validation data across multiple passbands (Gaia~$G$, $I$, and $TESS$) and demonstrated strong performance ($94\%$, up to $100\%$ for $TESS$) when tested on extensive observational data from the OGLE, DEBCat, and WUMaCat catalogues. While the primary binary classification was highly successful, the secondary task of automated spot detection performed poorly, revealing a significant limitation of our models for identifying subtle photometric features. This study highlights the potential of computer vision for EB morphological classification in large-scale surveys, but underscores the need for further research into robust, automated spot detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12800v1" target="_blank">Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward</a></h3>
                    <p><strong>Authors:</strong> Yong Deng, Guoqing Wang, Zhenzhe Ying, Xiaofeng Wu, Jinzhen Lin, Wenwen Xiong, Yuqin Dai, Shuo Yang, Zhanwei Zhang, Qiwen Wang, Yang Qin, Changhua Meng</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12799v1" target="_blank">Ensured Energy: A simulation game to elicit preferences around Swiss energy transition pathways</a></h3>
                    <p><strong>Authors:</strong> Toby Simpson, Saara Jones, Gracia BrÃ¼ckmann, Walid El-Ajou, Erwan Moreira, Borja Martinez Oltra, Rolf Krause, Michael Multerer, Isabelle Stadelmann</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> The 2015 Paris Agreement on global warming specifies national objectives for the reduction of greenhouse gas emissions. In support of Switzerlands energy and climate strategy for 2050, researchers investigate scenarios for the transition of energy systems towards a higher share of renewables, assessing their social, environmental and economic impact. Their results guide stakeholders and policy makers in designing resilient and sustainable systems. Political scientists use surveys to quantify public acceptance of energy policy, but the complexity and long time horizon of the subject creates difficulties, both for researchers in posing contextually relevant questions, and for respondents in assimilating enough information to give meaningful answers. A population survey was therefore augmented with an online serious game in which players experience an accurate simulation of current and future energy provision and manage transition towards a sustainable future. This interactive environment allows better informed and engaged decisions, and provides richer information on public opinion. In this paper we motivate and describe the design of the game and report initial findings on player characteristics and engagement. We show that a serious game can successfully attract participants from diverse societal groups and highlight the challenge of balancing complexity and entertainment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12798v1" target="_blank">A Shift in Perspective on Causality in Domain Generalization</a></h3>
                    <p><strong>Authors:</strong> Damian Machlanski, Stephanie Riley, Edward Moroshko, Kurt Butler, Panagiotis Dimitrakopoulos, Thomas Melistas, Akchunya Chanchal, Steven McDonagh, Ricardo Silva, Sotirios A. Tsaftaris</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The promise that causal modelling can lead to robust AI generalization has been challenged in recent work on domain generalization (DG) benchmarks. We revisit the claims of the causality and DG literature, reconciling apparent contradictions and advocating for a more nuanced theory of the role of causality in generalization. We also provide an interactive demo at https://chai-uk.github.io/ukairs25-causal-predictors/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13153v1" target="_blank">IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion</a></h3>
                    <p><strong>Authors:</strong> Wenhao Hu, Zesheng Li, Haonan Zhou, Liu Liu, Xuexiang Wen, Zhizhong Su, Xi Li, Gaoang Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Reconstructing complete and interactive 3D scenes remains a fundamental challenge in computer vision and robotics, particularly due to persistent object occlusions and limited sensor coverage. Multiview observations from a single scene scan often fail to capture the full structural details. Existing approaches typically rely on multi stage pipelines, such as segmentation, background completion, and inpainting or require per-object dense scanning, both of which are error-prone, and not easily scalable. We propose IGFuse, a novel framework that reconstructs interactive Gaussian scene by fusing observations from multiple scans, where natural object rearrangement between captures reveal previously occluded regions. Our method constructs segmentation aware Gaussian fields and enforces bi-directional photometric and semantic consistency across scans. To handle spatial misalignments, we introduce a pseudo-intermediate scene state for unified alignment, alongside collaborative co-pruning strategies to refine geometry. IGFuse enables high fidelity rendering and object level scene manipulation without dense observations or complex pipelines. Extensive experiments validate the frameworks strong generalization to novel scene configurations, demonstrating its effectiveness for real world 3D reconstruction and real-to-simulation transfer. Our project page is available online.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13152v1" target="_blank">RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns</a></h3>
                    <p><strong>Authors:</strong> Xin Chen, Junchao Wu, Shu Yang, Runzhe Zhan, Zeyu Wu, Ziyang Luo, Di Wang, Min Yang, Lidia S. Chao, Derek F. Wong</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Detecting content generated by large language models (LLMs) is crucial for preventing misuse and building trustworthy AI systems. Although existing detection methods perform well, their robustness in out-of-distribution (OOD) scenarios is still lacking. In this paper, we hypothesize that, compared to features used by existing detection methods, the internal representations of LLMs contain more comprehensive and raw features that can more effectively capture and distinguish the statistical pattern differences between LLM-generated texts (LGT) and human-written texts (HWT). We validated this hypothesis across different LLMs and observed significant differences in neural activation patterns when processing these two types of texts. Based on this, we propose RepreGuard, an efficient statistics-based detection method. Specifically, we first employ a surrogate model to collect representation of LGT and HWT, and extract the distinct activation feature that can better identify LGT. We can classify the text by calculating the projection score of the text representations along this feature direction and comparing with a precomputed threshold. Experimental results show that RepreGuard outperforms all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD scenarios, while also demonstrating robust resilience to various text sizes and mainstream attacks. Data and code are publicly available at: https://github.com/NLP2CT/RepreGuard</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13145v1" target="_blank">Aligned Stellar Obliquities for Two Hot Jupiter-hosting M Dwarfs Revealed by MAROON-X: Implications for Hot Jupiter Formation</a></h3>
                    <p><strong>Authors:</strong> Drew Weisserman, Erik Gillis, Ryan Cloutier, Nina Brown, Jacob L. Bean, Andreas Seifahrt, Tanya Das, Madison Brady, Bertram Bitsch, Emily Deibert, Thomas M. Evans-Soma, Noah Fenlon, Laura Kreidberg, Michael Line, Ralph Pudritz, Evgenya L. Shkolnik, Luis Welbanks</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> astro-ph.EP</p>
                    <p><strong>Summary:</strong> Hot Jupiters (HJs) are $2-3\times$ less common around early M dwarfs than around AFGK stars, suggesting that HJs may form and/or migrate via distinct pathways around different types of stars. One source of insight into HJ formation mechanisms is to trace their dynamical histories through measurements of host stellar obliquities via the Rossiter-McLaughlin (RM) effect. Here we present measurements of the RM effect for the HJs TOI-3714 b and TOI-5293 A b using the Gemini-North/MAROON-X spectrograph. Our measurements represent just the second and third hot Jupiters around M dwarfs (HJMD) with a detection of the RM effect. We find that both systems are well-aligned with sky-projected obliquities of $\lambda = 21^{+14}_{-11}$$\mathrm{^{\circ}}$ and $-12^{+19}_{-14}$$\mathrm{^{\circ}}$ and deprojected obliquities of $\psi = 26^{+11}_{-10}$$\mathrm{^{\circ}}$ and $24^{+11}_{-10}$$\mathrm{^{\circ}}$ for TOI-3714 and TOI-5293 A, respectively. Both stars are in wide binary systems. We refine the stellar parameters by decontaminating their unresolved $K_s$-band photometry and constrain the binary orbits using Gaia DR3 astrometry. We find that the minimum mutual inclination of the planet and binary companion in the TOI-5293 system is sufficiently large to drive Kozai-Lidov (KL) migration while the result for TOI-3714 is inconclusive. We present a population-level analysis of HJs around AFGK versus early M dwarfs and argue that KL migration is more efficient around the latter, which is expected to produce misaligned stellar obliquities in HJMD systems in the absence of efficient tidal damping. The emerging population of well-aligned HJMD hosts supports the expectation that M dwarfs, with their deep convective envelopes, do efficiently dampen misaligned obliquities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13143v1" target="_blank">Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks</a></h3>
                    <p><strong>Authors:</strong> Ruofan Lu, Yichen Li, Yintong Huo</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.SE</p>
                    <p><strong>Summary:</strong> Autonomous agent systems powered by Large Language Models (LLMs) have demonstrated promising capabilities in automating complex tasks. However, current evaluations largely rely on success rates without systematically analyzing the interactions, communication mechanisms, and failure causes within these systems. To bridge this gap, we present a benchmark of 34 representative programmable tasks designed to rigorously assess autonomous agents. Using this benchmark, we evaluate three popular open-source agent frameworks combined with two LLM backbones, observing a task completion rate of approximately 50%. Through in-depth failure analysis, we develop a three-tier taxonomy of failure causes aligned with task phases, highlighting planning errors, task execution issues, and incorrect response generation. Based on these insights, we propose actionable improvements to enhance agent planning and self-diagnosis capabilities. Our failure taxonomy, together with mitigation advice, provides an empirical foundation for developing more robust and effective autonomous agent systems in the future.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13142v1" target="_blank">Has GPT-5 Achieved Spatial Intelligence? An Empirical Study</a></h3>
                    <p><strong>Authors:</strong> Zhongang Cai, Yubo Wang, Qingping Sun, Ruisi Wang, Chenyang Gu, Wanqi Yin, Zhiqian Lin, Zhitao Yang, Chen Wei, Xuanke Shi, Kewang Deng, Xiaoyang Han, Zukai Chen, Jiaqi Li, Xiangyu Fan, Hanming Deng, Lewei Lu, Bo Li, Ziwei Liu, Quan Wang, Dahua Lin, Lei Yang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.LG, cs.MM, cs.RO</p>
                    <p><strong>Summary:</strong> Multi-modal models have achieved remarkable progress in recent years. Nevertheless, they continue to exhibit notable limitations in spatial understanding and reasoning, which are fundamental capabilities to achieving artificial general intelligence. With the recent release of GPT-5, allegedly the most powerful AI model to date, it is timely to examine where the leading models stand on the path toward spatial intelligence. First, we propose a comprehensive taxonomy of spatial tasks that unifies existing benchmarks and discuss the challenges in ensuring fair evaluation. We then evaluate state-of-the-art proprietary and open-source models on eight key benchmarks, at a cost exceeding one billion total tokens. Our empirical study reveals that (1) GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2) still falls short of human performance across a broad spectrum of tasks. Moreover, we (3) identify the more challenging spatial intelligence problems for multi-modal models, and (4) proprietary models do not exhibit a decisive advantage when facing the most difficult problems. In addition, we conduct a qualitative evaluation across a diverse set of scenarios that are intuitive for humans yet fail even the most advanced multi-modal models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13135v1" target="_blank">Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]</a></h3>
                    <p><strong>Authors:</strong> Yueyang Liu, Lance Kennedy, Ruochen Kong, Joon-Seok Kim, Andreas ZÃ¼fle</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Individual-level human mobility prediction has emerged as a significant topic of research with applications in infectious disease monitoring, child, and elderly care. Existing studies predominantly focus on the microscopic aspects of human trajectories: such as predicting short-term trajectories or the next location visited, while offering limited attention to macro-level mobility patterns and the corresponding life routines. In this paper, we focus on an underexplored problem in human mobility prediction: determining the best practices to train a machine learning model using historical data to forecast an individuals complete trajectory over the next days and weeks. In this experiment paper, we undertake a comprehensive experimental analysis of diverse models, parameter configurations, and training strategies, accompanied by an in-depth examination of the statistical distribution inherent in human mobility patterns. Our empirical evaluations encompass both Long Short-Term Memory and Transformer-based architectures, and further investigate how incorporating individual life patterns can enhance the effectiveness of the prediction. We show that explicitly including semantic information such as day-of-the-week and user-specific historical information can help the model better understand individual patterns of life and improve predictions. Moreover, since the absence of explicit user information is often missing due to user privacy, we show that the sampling of users may exacerbate data skewness and result in a substantial loss in predictive accuracy. To mitigate data imbalance and preserve diversity, we apply user semantic clustering with stratified sampling to ensure that the sampled dataset remains representative. Our results further show that small-batch stochastic gradient optimization improves model performance, especially when human mobility training data is limited.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13130v1" target="_blank">MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation</a></h3>
                    <p><strong>Authors:</strong> Kareem Elozeiri, Mervat Abassy, Preslav Nakov, Yuxia Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Commonsense validation evaluates whether a sentence aligns with everyday human understanding, a critical capability for developing robust natural language understanding systems. While substantial progress has been made in English, the task remains underexplored in Arabic, particularly given its rich linguistic diversity. Existing Arabic resources have primarily focused on Modern Standard Arabic (MSA), leaving regional dialects underrepresented despite their prevalence in spoken contexts. To bridge this gap, we present two key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense dataset incorporating multiple dialects, and (ii) a novel method adapting Graph Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances semantic relationship modeling for improved commonsense validation. Our experimental results demonstrate that this approach achieves superior performance in Arabic commonsense validation. Our work enhances Arabic natural language understanding by providing both a foundational dataset and a novel method for handling its complex variations. To the best of our knowledge, we release the first Arabic multi-dialect commonsense reasoning dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13128v1" target="_blank">Modeling wind farm noise emission and propagation: effects of flow layout</a></h3>
                    <p><strong>Authors:</strong> J. Colas, A. Emmanuelli, D. Dragna, R. J. A. M. Stevens</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, physics.app-ph, physics.comp-ph</p>
                    <p><strong>Summary:</strong> This study demonstrates how wind farm flow physics influence noise generation and downstream propagation through numerical simulations. The flow field is modeled using large-eddy simulations (LES), and the time-averaged output serves as input to acoustic models that predict wind turbine noise. In the first turbine row, turbulence-induced noise (TIN) and trailing edge noise (TEN) contribute equally, with TIN dominating at low frequencies and TEN at higher frequencies. Downstream, TEN decreases due to lower wind speeds, while TIN mostly persists due to increased turbulence dissipation. These effects are more pronounced in aligned wind farms, where stronger wake interactions occur, than in staggered layouts. However, staggered farms produce more noise overall because turbines operate at higher wind speeds.Additionally, wind farm flow significantly affects sound propagation downwind. The wake superposition modifies sound focusing leading to different amplification area than for an isolated turbine. For a staggered layout it particularly shows enhanced sound focusing downwind due to the position of the turbine wakes. This leads to higher sound levels and higher amplitude modulation downwind for the wind farm compared to an aligned layout. These phenomena are not captured by models based on isolated turbines. These findings underscore the importance of integrating flow and acoustic models to more accurately assess the environmental impact of wind farms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13116v1" target="_blank">Choosing the Right Engine in the Virtual Reality Landscape</a></h3>
                    <p><strong>Authors:</strong> Santiago Berrezueta-Guzman, Stefan Wagner</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Virtual reality (VR) development relies on game engines to provide real-time rendering, physics simulation, and interaction systems. Among the most widely used game engines, Unreal Engine and Unity dominate the industry, offering distinct advantages in graphics rendering, performance optimization, usability, resource requirements, and scalability. This study presents a comprehensive comparative analysis of both engines, evaluating their capabilities and trade-offs through empirical assessments and real-world case studies of large-scale VR projects. The findings highlight key factors such as rendering fidelity, computational efficiency, cross-platform compatibility, and development workflows. These provide practical insights for selecting the most suitable engine based on project-specific needs. Furthermore, emerging trends in artificial intelligence (AI)-driven enhancements, including Deep Learning Super Sampling (DLSS) and large language models (LLMs), are explored to assess their impact on VR development workflows. By aligning engine capabilities with technical and creative requirements, developers can overcome performance bottlenecks, enhance immersion, and streamline optimization techniques. This study serves as a valuable resource for VR developers, researchers, and industry professionals, offering data-driven recommendations to navigate the evolving landscape of VR technology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13113v1" target="_blank">Contrastive Representations for Temporal Reasoning</a></h3>
                    <p><strong>Authors:</strong> Alicja Ziarko, Michal Bortkiewicz, Michal Zawalski, Benjamin Eysenbach, Piotr Milos</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> In classical AI, perception relies on learning state-based representations, while planning, which can be thought of as temporal reasoning over action sequences, is typically achieved through search. We study whether such reasoning can instead emerge from representations that capture both perceptual and temporal structure. We show that standard temporal contrastive learning, despite its popularity, often fails to capture temporal structure due to its reliance on spurious features. To address this, we introduce Combinatorial Representations for Temporal Reasoning (CRTR), a method that uses a negative sampling scheme to provably remove these spurious features and facilitate temporal reasoning. CRTR achieves strong results on domains with complex temporal structure, such as Sokoban and Rubiks Cube. In particular, for the Rubiks Cube, CRTR learns representations that generalize across all initial states and allow it to solve the puzzle using fewer search steps than BestFS, though with longer solutions. To our knowledge, this is the first method that efficiently solves arbitrary Cube states using only learned representations, without relying on an external search algorithm.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13107v1" target="_blank">All for law and law for all: Adaptive RAG Pipeline for Legal Research</a></h3>
                    <p><strong>Authors:</strong> Figarri Keisha, Prince Singh, Pallavi, Dion Fernandes, Aravindh Manivannan, Ilham Wicaksono, Faisal Ahmad</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR, F.2.2, H.3.3, I.2.7</p>
                    <p><strong>Summary:</strong> Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding large language model outputs in cited sources, a capability that is especially critical in the legal domain. We present an end-to-end RAG pipeline that revisits and extends the LegalBenchRAG baseline with three targeted enhancements: (i) a context-aware query translator that disentangles document references from natural-language questions and adapts retrieval depth and response style based on expertise and specificity, (ii) open-source retrieval strategies using SBERT and GTE embeddings that achieve substantial performance gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for $K4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to assess semantic alignment and faithfulness across models and prompt designs. Our results show that carefully designed open-source pipelines can rival or outperform proprietary approaches in retrieval quality, while a custom legal-grounded prompt consistently produces more faithful and contextually relevant answers than baseline prompting. Taken together, these contributions demonstrate the potential of task-aware, component-level tuning to deliver legally grounded, reproducible, and cost-effective RAG systems for legal research assistance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13103v1" target="_blank">Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy</a></h3>
                    <p><strong>Authors:</strong> Tianyi Zhang, Haonan Duan, Haoran Hao, Yu Qiao, Jifeng Dai, Zhi Hou</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Vision-Language-Action (VLA) models frequently encounter challenges in generalizing to real-world environments due to inherent discrepancies between observation and action spaces. Although training data are collected from diverse camera perspectives, the models typically predict end-effector poses within the robot base coordinate frame, resulting in spatial inconsistencies. To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA) framework, which grounds action predictions directly in the camera observation space. Leveraging the cameras extrinsic calibration matrix, OC-VLA transforms end-effector poses from the robot base coordinate system into the camera coordinate system, thereby unifying prediction targets across heterogeneous viewpoints. This lightweight, plug-and-play strategy ensures robust alignment between perception and action, substantially improving model resilience to camera viewpoint variations. The proposed approach is readily compatible with existing VLA architectures, requiring no substantial modifications. Comprehensive evaluations on both simulated and real-world robotic manipulation tasks demonstrate that OC-VLA accelerates convergence, enhances task success rates, and improves cross-view generalization. The code will be publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13101v1" target="_blank">Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants</a></h3>
                    <p><strong>Authors:</strong> Miftahul Huda, Arsyiah Azahra, Putri Maulida Chairani, Dimas Rizky Ramadhani, Nabila Azhari, Ade Lailani</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Coastal pollution is a pressing global environmental issue, necessitating scalable and automated solutions for monitoring and management. This study investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a state-of-the-art, end-to-end object detection model, for the automated detection and counting of beach litter. A rigorous comparative analysis is conducted between two model variants, RT-DETR-Large (RT-DETR-L) and RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of coastal debris. The evaluation reveals that the RT-DETR-X model achieves marginally superior accuracy, with a mean Average Precision at 50\% IoU (mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L models 0.810 and 0.606, respectively. However, this minor performance gain is realized at a significant computational cost; the RT-DETR-L model demonstrates a substantially faster inference time of 20.1 ms versus 34.5 ms for the RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more practical and efficient solution for real-time, in-field deployment due to its superior balance of processing speed and detection accuracy. This research provides valuable insights into the application of advanced Transformer-based detectors for environmental conservation, highlighting the critical trade-offs between model complexity and operational viability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13079v1" target="_blank">DocHPLT: A Massively Multilingual Document-Level Translation Dataset</a></h3>
                    <p><strong>Authors:</strong> DayyÃ¡n OBrien, Bhavitvya Malik, Ona de Gibert, Pinzhen Chen, Barry Haddow, JÃ¶rg Tiedemann</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Existing document-level machine translation resources are only available for a handful of languages, mostly high-resourced ones. To facilitate the training and evaluation of document-level translation and, more broadly, long-context modeling for global communities, we create DocHPLT, the largest publicly available document-level translation dataset to date. It contains 124 million aligned document pairs across 50 languages paired with English, comprising 4.26 billion sentences, with further possibility to provide 2500 bonus pairs not involving English. Unlike previous reconstruction-based approaches that piece together documents from sentence-level data, we modify an existing web extraction pipeline to preserve complete document integrity from the source, retaining all content including unaligned portions. After our preliminary experiments identify the optimal training context strategy for document-level translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially outperform off-the-shelf instruction-tuned baselines, with particularly dramatic improvements for under-resourced languages. We open-source the dataset under a permissive license, providing essential infrastructure for advancing multilingual document-level translation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13077v1" target="_blank">From Transthoracic to Transesophageal: Cross-Modality Generation using LoRA Diffusion</a></h3>
                    <p><strong>Authors:</strong> Emmanuel Oladokun, Yuxuan Ou, Anna Novikova, Daria Kulikova, Sarina Thomas, Jurica Å prem, Vicente Grau</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI</p>
                    <p><strong>Summary:</strong> Deep diffusion models excel at realistic image synthesis but demand large training sets-an obstacle in data-scarce domains like transesophageal echocardiography (TEE). While synthetic augmentation has boosted performance in transthoracic echo (TTE), TEE remains critically underrepresented, limiting the reach of deep learning in this high-impact modality. We address this gap by adapting a TTE-trained, mask-conditioned diffusion backbone to TEE with only a limited number of new cases and adapters as small as $10^5$ parameters. Our pipeline combines Low-Rank Adaptation with MaskR$^2$, a lightweight remapping layer that aligns novel mask formats with the pretrained models conditioning channels. This design lets users adapt models to new datasets with a different set of anatomical structures to the base models original set. Through a targeted adaptation strategy, we find that adapting only MLP layers suffices for high-fidelity TEE synthesis. Finally, mixing less than 200 real TEE frames with our synthetic echoes improves the dice score on a multiclass segmentation task, particularly boosting performance on underrepresented right-heart structures. Our results demonstrate that (1) semantically controlled TEE images can be generated with low overhead, (2) MaskR$^2$ effectively transforms unseen mask formats into compatible formats without damaging downstream task performance, and (3) our method generates images that are effective for improving performance on a downstream task of multiclass segmentation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13076v1" target="_blank">The purpose of an estimator is what it does: Misspecification, estimands, and over-identification</a></h3>
                    <p><strong>Authors:</strong> Isaiah Andrew, Jiafeng Chen, Otavio Tecchio</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> econ.EM, stat.ME</p>
                    <p><strong>Summary:</strong> In over-identified models, misspecification -- the norm rather than exception -- fundamentally changes what estimators estimate. Different estimators imply different estimands rather than different efficiency for the same target. A review of recent applications of generalized method of moments in the American Economic Review suggests widespread acceptance of this fact: There is little formal specification testing and widespread use of estimators that would be inefficient were the model correct, including the use of hand-selected moments and weighting matrices. Motivated by these observations, we review and synthesize recent results on estimation under model misspecification, providing guidelines for transparent and robust empirical research. We also provide a new theoretical result, showing that Hansens J-statistic measures, asymptotically, the range of estimates achievable at a given standard error. Given the widespread use of inefficient estimators and the resulting researcher degrees of freedom, we thus particularly recommend the broader reporting of J-statistics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13073v1" target="_blank">Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey</a></h3>
                    <p><strong>Authors:</strong> Rui Shao, Wei Li, Lingsen Zhang, Renshan Zhang, Zhiyang Liu, Ran Chen, Liqiang Nie</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Robotic manipulation, a key frontier in robotics and embodied AI, requires precise motor control and multimodal understanding, yet traditional rule-based methods fail to scale or generalize in unstructured, novel environments. In recent years, Vision-Language-Action (VLA) models, built upon Large Vision-Language Models (VLMs) pretrained on vast image-text datasets, have emerged as a transformative paradigm. This survey provides the first systematic, taxonomy-oriented review of large VLM-based VLA models for robotic manipulation. We begin by clearly defining large VLM-based VLA models and delineating two principal architectural paradigms: (1) monolithic models, encompassing single-system and dual-system designs with differing levels of integration; and (2) hierarchical models, which explicitly decouple planning from execution via interpretable intermediate representations. Building on this foundation, we present an in-depth examination of large VLM-based VLA models: (1) integration with advanced domains, including reinforcement learning, training-free optimization, learning from human videos, and world model integration; (2) synthesis of distinctive characteristics, consolidating architectural traits, operational strengths, and the datasets and benchmarks that support their development; (3) identification of promising directions, including memory mechanisms, 4D perception, efficient adaptation, multi-agent cooperation, and other emerging capabilities. This survey consolidates recent advances to resolve inconsistencies in existing taxonomies, mitigate research fragmentation, and fill a critical gap through the systematic integration of studies at the intersection of large VLMs and robotic manipulation. We provide a regularly updated project page to document ongoing progress: https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13072v1" target="_blank">A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis</a></h3>
                    <p><strong>Authors:</strong> Yuting Zhang, Tiantian Geng, Luoying Hao, Xinxing Cheng, Alexander Thorley, Xiaoxia Wang, Wenqi Lu, Sandeep S Hothi, Lei Wei, Zhaowen Qiu, Dipak Kotecha, Jinming Duan</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Contemporary cardiovascular management involves complex consideration and integration of multimodal cardiac datasets, where each modality provides distinct but complementary physiological characteristics. While the effective integration of multiple modalities could yield a holistic clinical profile that accurately models the true clinical situation with respect to data modalities and their relatives weightings, current methodologies remain limited by: 1) the scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated single-modality or rigid multimodal input combinations; 3) alignment strategies that prioritize cross-modal similarity over complementarity; and 4) a narrow single-task focus. In response to these limitations, a comprehensive multimodal dataset was curated for immediate application, integrating laboratory test results, electrocardiograms, and echocardiograms with clinical outcomes. Subsequently, a unified framework, Textual Guidance Multimodal fusion for Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key components: 1) a MedFlexFusion module designed to capture the unique and complementary characteristics of medical modalities and dynamically integrate data from diverse cardiac sources and their combinations; 2) a textual guidance module to derive task-relevant representations tailored to diverse clinical objectives, including heart disease diagnosis, risk stratification and information retrieval; and 3) a response module to produce final decisions for all these tasks. Furthermore, this study systematically explored key features across multiple modalities and elucidated their synergistic contributions in clinical decision-making. Extensive experiments showed that TGMM outperformed state-of-the-art methods across multiple clinical tasks, with additional validation confirming its robustness on another public dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13068v1" target="_blank">Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation</a></h3>
                    <p><strong>Authors:</strong> Tanjim Islam Riju, Shuchismita Anwar, Saman Sarker Joy, Farig Sadeque, Swakkhar Shatabda</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> We propose a two-stage multimodal framework that enhances disease classification and region-aware radiology report generation from chest X-rays, leveraging the MIMIC-Eye dataset. In the first stage, we introduce a gaze-guided contrastive learning architecture for disease classification. It integrates visual features, clinical labels, bounding boxes, and radiologist eye-tracking signals and is equipped with a novel multi-term gaze-attention loss combining MSE, KL divergence, correlation, and center-of-mass alignment. Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC from 0.821 to 0.849 (+3.41%), while also improving precision and recall, highlighting the effectiveness of gaze-informed attention supervision. In the second stage, we present a modular report generation pipeline that extracts confidence-weighted diagnostic keywords, maps them to anatomical regions using a curated dictionary constructed from domain-specific priors, and generates region-aligned sentences via structured prompts. This pipeline improves report quality as measured by clinical keyword recall and ROUGE overlap. Our results demonstrate that integrating gaze data improves both classification performance and the interpretability of generated medical reports.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13065v1" target="_blank">Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping</a></h3>
                    <p><strong>Authors:</strong> Siddharth Khandelwal, Sridhar Kamath, Arjun Jain</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Human shape editing enables controllable transformation of a persons body shape, such as thin, muscular, or overweight, while preserving pose, identity, clothing, and background. Unlike human pose editing, which has advanced rapidly, shape editing remains relatively underexplored. Current approaches typically rely on 3D morphable models or image warping, often introducing unrealistic body proportions, texture distortions, and background inconsistencies due to alignment errors and deformations. A key limitation is the lack of large-scale, publicly available datasets for training and evaluating body shape manipulation methods. In this work, we introduce the first large-scale dataset of 18,573 images across 1523 subjects, specifically designed for controlled human shape editing. It features diverse variations in body shape, including fat, muscular and thin, captured under consistent identity, clothing, and background conditions. Using this dataset, we propose Odo, an end-to-end diffusion-based method that enables realistic and intuitive body reshaping guided by simple semantic attributes. Our approach combines a frozen UNet that preserves fine-grained appearance and background details from the input image with a ControlNet that guides shape transformation using target SMPL depth maps. Extensive experiments demonstrate that our method outperforms prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm, significantly lower than the 13.6mm observed in baseline methods, while producing realistic results that accurately match the desired target shapes.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746252.3761047" target="_blank">Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation</a></h3>
                    <p><strong>Authors:</strong> Seongeun Ryu, Yunyong Ko, Sang-Wook Kim</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.LG</p>
                    <p><strong>Summary:</strong> Personalized news recommendation aims to deliver news articles aligned with users interests, serving as a key solution to alleviate the problem of information overload on online news platforms. While prior work has improved interest matching through refined representations of news and users, the following time-related challenges remain underexplored: (C1) leveraging the age of clicked news to infer users interest persistence, and (C2) modeling the varying lifetime of news across topics and users. To jointly address these challenges, we propose a novel Lifetime-aware Interest Matching framework for nEws recommendation, named LIME, which incorporates three key strategies: (1) User-Topic lifetime-aware age representation to capture the relative age of news with respect to a user-topic pair, (2) Candidate-aware lifetime attention for generating temporally aligned user representation, and (3) Freshness-guided interest refinement for prioritizing valid candidate news at prediction time. Extensive experiments on two real-world datasets demonstrate that LIME consistently outperforms a wide range of state-of-the-art news recommendation methods, and its model agnostic strategies significantly improve recommendation accuracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13060v1" target="_blank">Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database</a></h3>
                    <p><strong>Authors:</strong> John Alderete, Macarious Kin Fung Hui, Aanchan Mohan</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The Simon Fraser University Speech Error Database (SFUSED) is a public data collection developed for linguistic and psycholinguistic research. Here we demonstrate how its design and annotations can be used to test and evaluate speech recognition models. The database comprises systematically annotated speech errors from spontaneous English speech, with each error tagged for intended and actual error productions. The annotation schema incorporates multiple classificatory dimensions that are of some value to model assessment, including linguistic hierarchical level, contextual sensitivity, degraded words, word corrections, and both word-level and syllable-level error positioning. To assess the value of these classificatory variables, we evaluated the transcription accuracy of WhisperX across 5,300 documented word and phonological errors. This analysis demonstrates the atabases effectiveness as a diagnostic tool for ASR system performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13054v1" target="_blank">Quantum Relational Knowledge Distillation</a></h3>
                    <p><strong>Authors:</strong> Chen-Yu Liu, Kuan-Cheng Chen, Keisuke Murota, Samuel Yen-Chi Chen, Enrico Rinaldi</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Knowledge distillation (KD) is a widely adopted technique for compressing large models into smaller, more efficient student models that can be deployed on devices with limited computational resources. Among various KD methods, Relational Knowledge Distillation (RKD) improves student performance by aligning relational structures in the feature space, such as pairwise distances and angles. In this work, we propose Quantum Relational Knowledge Distillation (QRKD), which extends RKD by incorporating quantum relational information. Specifically, we map classical features into a Hilbert space, interpret them as quantum states, and compute quantum kernel values to capture richer inter-sample relationships. These quantum-informed relations are then used to guide the distillation process. We evaluate QRKD on both vision and language tasks, including CNNs on MNIST and CIFAR-10, and GPT-2 on WikiText-2, Penn Treebank, and IMDB. Across all benchmarks, QRKD consistently improves student model performance compared to classical RKD. Importantly, both teacher and student models remain classical and deployable on standard hardware, with quantum computation required only during training. This work presents the first demonstration of quantum-enhanced knowledge distillation in a fully classical deployment setting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13053v1" target="_blank">A 15 Mpc rotating galaxy filament at redshift z = 0.032</a></h3>
                    <p><strong>Authors:</strong> Madalina N. Tudorache, S. L. Jung, M. J. Jarvis, I. Heywood, A. A. Ponomareva, A. Varasteanu, N. Maddox, T. Yasin, M. Glowacki</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA, astro-ph.CO</p>
                    <p><strong>Summary:</strong> Understanding the cold atomic hydrogen gas (HI) within cosmic filaments has the potential to pin down the relationship between the low density gas in the cosmic web and how the galaxies that lie within it grow using this material. We report the discovery of a cosmic filament using 14 HI-selected galaxies that form a very thin elongated structure of 1.7 Mpc. These galaxies are embedded within a much larger cosmic web filament, traced by optical galaxies, that spans at least $\sim 15$~Mpc. We find that the spin axes of the HI galaxies are significantly more strongly aligned with the cosmic web filament ($\langle\lvert \cos \psi \rvert\rangle = 0.64 \pm 0.05$) than cosmological simulations predict, with the optically-selected galaxies showing alignment to a lesser degree ($\langle\lvert \cos \psi \rvert\rangle = 0.55 \pm 0.05$). This structure demonstrates that within the cosmic filament, the angular momentum of galaxies is closely connected to the large-scale filamentary structure. We also find strong evidence that the galaxies are orbiting around the spine of the filament, making this one of the largest rotating structures discovered thus far, and from which we can infer that there is transfer of angular momentum from the filament to the individual galaxies. The abundance of HI galaxies along the filament and the low dynamical temperature of the galaxies within the filament indicates that this filament is at an early evolutionary stage where the imprint of cosmic matter flow on galaxies has been preserved over cosmic time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13049v1" target="_blank">XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads</a></h3>
                    <p><strong>Authors:</strong> Tejas Chaudhari, Akarsh J., Tanushree Dewangan, Mukul Lokhande, Santosh Kumar Vishvakarma</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AR, cs.AI, cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural Processing Engine, designed for extended reality (XR) perception workloads like visual inertial odometry (VIO), object classification, and eye gaze extraction. XR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1) formats, with layer adaptive hybrid-algorithmic implementation supporting ultra-low bit precision to significantly reduce memory bandwidth requirements, and accompanied by quantization-aware training for minimal accuracy loss. The proposed Reconfigurable Mantissa Multiplication and Exponent processing Circuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted by selective power gating to reduce energy consumption, providing 2.85x improved arithmetic intensity. XR-NPE achieves a maximum operating frequency of 1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm, reducing 42% area, 38% power compared to the best of state-of-the-art MAC approaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication co-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x better energy efficiency compared to SoTA accelerators on VCU129. The proposed co-processor provides 23% better energy efficiency and 4% better compute density for VIO workloads. XR-NPE establishes itself as a scalable, precision-adaptive compute engine for future resource-constrained XR devices. The complete set for codes for results reproducibility are released publicly, enabling designers and researchers to readily adopt and build upon them. https://github.com/mukullokhande99/XR-NPE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13047v1" target="_blank">Using AI for User Representation: An Analysis of 83 Persona Prompts</a></h3>
                    <p><strong>Authors:</strong> Joni Salminen, Danial Amin, Bernard Jansen</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> We analyzed 83 persona prompts from 27 research articles that used large language models (LLMs) to generate user personas. Findings show that the prompts predominantly generate single personas. Several prompts express a desire for short or concise persona descriptions, which deviates from the tradition of creating rich, informative, and rounded persona profiles. Text is the most common format for generated persona attributes, followed by numbers. Text and numbers are often generated together, and demographic attributes are included in nearly all generated personas. Researchers use up to 12 prompts in a single study, though most research uses a small number of prompts. Comparison and testing multiple LLMs is rare. More than half of the prompts require the persona output in a structured format, such as JSON, and 74% of the prompts insert data or dynamic variables. We discuss the implications of increased use of computational personas for user representation.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/SIU66497.2025.11112154" target="_blank">BÃ¼yÃ¼k Dil Modelleri iÃ§in TR-MMLU BenchmarkÄ±: Performans DeÄŸerlendirmesi, Zorluklar ve Ä°yileÅŸtirme FÄ±rsatlarÄ±</a></h3>
                    <p><strong>Authors:</strong> M. Ali Bayram, Ali Arda Fincan, Ahmet Semih GÃ¼mÃ¼ÅŸ, Banu Diri, SavaÅŸ YÄ±ldÄ±rÄ±m, Ã–ner AytaÅŸ</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, 68T50, I.2.7; I.2.6</p>
                    <p><strong>Summary:</strong> Language models have made significant advancements in understanding and generating human language, achieving remarkable success in various applications. However, evaluating these models remains a challenge, particularly for resource-limited languages like Turkish. To address this issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive evaluation framework designed to assess the linguistic and conceptual capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a meticulously curated dataset comprising 6,200 multiple-choice questions across 62 sections within the Turkish education system. This benchmark provides a standard framework for Turkish NLP research, enabling detailed analyses of LLMs capabilities in processing Turkish text. In this study, we evaluated state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model design. TR-MMLU sets a new standard for advancing Turkish NLP research and inspiring future innovations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13040v1" target="_blank">Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data</a></h3>
                    <p><strong>Authors:</strong> Varsha Ramineni, Hossein A. Rahmani, Emine Yilmaz, David Barber</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Ensuring fairness in AI systems is critical, especially in high-stakes domains such as lending, hiring, and healthcare. This urgency is reflected in emerging global regulations that mandate fairness assessments and independent bias audits. However, procuring the necessary complete data for fairness testing remains a significant challenge. In industry settings, legal and privacy concerns restrict the collection of demographic data required to assess group disparities, and auditors face practical and cultural challenges in gaining access to data. In practice, data relevant for fairness testing is often split across separate sources: internal datasets held by institutions with predictive attributes, and external public datasets such as census data containing protected attributes, each providing only partial, marginal information. Our work seeks to leverage such available separate data to estimate model fairness when complete data is inaccessible. We propose utilising the available separate data to estimate a set of feasible joint distributions and then compute the set plausible fairness metrics. Through simulation and real experiments, we demonstrate that we can derive meaningful bounds on fairness metrics and obtain reliable estimates of the true metric. Our results demonstrate that this approach can serve as a practical and effective solution for fairness testing in real-world settings where access to complete data is restricted.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13033v1" target="_blank">AuthenTree: A Scalable MPC-Based Distributed Trust Architecture for Chiplet-based Heterogeneous Systems</a></h3>
                    <p><strong>Authors:</strong> Ishraq Tashdid, Tasnuva Farheen, Sazadur Rahman</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CR, B.7.1; B.6</p>
                    <p><strong>Summary:</strong> The rapid adoption of chiplet-based heterogeneous integration is reshaping semiconductor design by enabling modular, scalable, and faster time-to-market solutions for AI and high-performance computing. However, multi-vendor assembly in post-fabrication environments fragments the supply chain and exposes SiP systems to serious security threats, including cloning, overproduction, and chiplet substitution. Existing authentication solutions depend on trusted integrators or centralized security anchors, which can expose sensitive data or create single points of failure. We introduce AuthenTree, a distributed authentication framework that leverages multi-party computation (MPC) in a scalable tree-based architecture, removing the need for dedicated security hardware or centralized trust. AuthenTree enables secure chiplet validation without revealing raw signatures, distributing trust across multiple integrator chiplets. Our evaluation in five SiP benchmarks demonstrates that AuthenTree imposes minimal overhead, with an area as low as 0.48% (7,000 sq-micrometers), an overhead power under 0.5%, and an authentication latency below 1 microsecond, surpassing previous work in some cases by 700 times. These results establish AuthenTree as an efficient, robust, and scalable solution for next-generation chiplet-based security in zero-trust SiP environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13024v1" target="_blank">WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents</a></h3>
                    <p><strong>Authors:</strong> Ralph Peeters, Aaron Steiner, Luca Schwarz, Julian Yuya Caspary, Christian Bizer</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> LLM-based web agents have the potential to automate long-running web tasks, such as finding offers for specific products in multiple online shops and subsequently ordering the cheapest products that meet the users needs. This paper introduces WebMall, a multi-shop online shopping benchmark for evaluating the effectiveness and efficiency of web agents for comparison-shopping. WebMall consists of four simulated online shops populated with authentic product offers sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These tasks include basic tasks such as finding specific products in multiple shops, performing price comparisons, adding items to the shopping cart, and completing checkout. Advanced tasks involve searching for products based on vague requirements, identifying suitable substitutes, and finding compatible products. Compared to existing e-commerce benchmarks, such as WebShop or ShoppingBench, WebMall introduces comparison-shopping tasks across multiple shops. Furthermore, the product offers are more heterogeneous, as they originate from hundreds of distinct real-world shops. The tasks in WebMall require longer interaction trajectories than those in WebShop, while remaining representative of real-world shopping behaviors. We evaluate eight baseline agents on WebMall, varying in observation modality, memory utilization, and underlying large language model (GPT 4.1 and Claude Sonnet 4). The best-performing configurations achieve completion rates of 75% and 53%, and F1 scores of 87% and 63%, on the basic and advanced task sets, respectively. WebMall is publicly released to facilitate research on web agents and to promote advancements in navigation, reasoning, and efficiency within e-commerce scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13014v1" target="_blank">QUBODock: A Pip-Installable QUBO Tool for Ligand Pose Generation</a></h3>
                    <p><strong>Authors:</strong> Pei-Kun Yang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> q-bio.BM</p>
                    <p><strong>Summary:</strong> We present QUBODock, a pip-installable tool that formulates ligand pose generation as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solves it efficiently on CPU or GPU. QUBODock focuses exclusively on pose generation and deliberately excludes any built-in scoring function, allowing researchers to pair its poses with external scorers of their choice. The software provides a minimal, reproducible interface for (i) protein-ligand structure ingestion and preprocessing, (ii) QUBO model construction from geometric/compatibility constraints, and (iii) decoding solutions into candidate poses for downstream ranking. Implemented in Python with GPU acceleration, QUBODock emphasizes usability and reproducibility: it is distributed on PyPI and can be installed with a single command. We release the source to support benchmarking, teaching, and method development around QUBO-based docking pose generation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13013v1" target="_blank">EgoTwin: Dreaming Body and View in First Person</a></h3>
                    <p><strong>Authors:</strong> Jingqiao Xiu, Fangzhou Hong, Yicong Li, Mengze Li, Wentao Wang, Sirui Han, Liang Pan, Ziwei Liu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> While exocentric video synthesis has achieved great progress, egocentric video generation remains largely underexplored, which requires modeling first-person view content along with camera motion patterns induced by the wearers body movements. To bridge this gap, we introduce a novel task of joint egocentric video and human motion generation, characterized by two key challenges: 1) Viewpoint Alignment: the camera trajectory in the generated video must accurately align with the head trajectory derived from human motion; 2) Causal Interplay: the synthesized human motion must causally align with the observed visual dynamics across adjacent video frames. To address these challenges, we propose EgoTwin, a joint video-motion generation framework built on the diffusion transformer architecture. Specifically, EgoTwin introduces a head-centric motion representation that anchors the human motion to the head joint and incorporates a cybernetics-inspired interaction mechanism that explicitly captures the causal interplay between video and motion within attention operations. For comprehensive evaluation, we curate a large-scale real-world dataset of synchronized text-video-motion triplets and design novel metrics to assess video-motion consistency. Extensive experiments demonstrate the effectiveness of the EgoTwin framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13011v1" target="_blank">Developing a ChatGPT-Based Tool for Physics Experiment Teaching</a></h3>
                    <p><strong>Authors:</strong> Yifeng Liu, Min Li, Zhaojun Zhang, Youkang Fang, Meibao Qin</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> This paper examines how advanced AI assistants can help physics educators create practical teaching tools without specialized programming skills. Using the square-wave synthesis experiment as a case, we target common obstacles in laboratory instruction-complex setup, unstable signals, and limited class time-and show how AI-assisted development can shift attention from wiring and calibration to core physical ideas. To address this need, we guided an AI assistant through iterative prompts to generate a clean, runnable program that visualizes square-wave synthesis from its component sine waves. The tool supports step-by-step construction of the waveform, adjustable parameters (amplitude, frequency, and phase), and immediate comparison with an ideal reference using simple error measures. We packaged the result as a standalone application so it runs reliably on standard classroom computers, enabling pre-lab demonstrations and interactive exploration that reduce procedural friction and highlight underlying concepts. Building on this proof of concept, we argue the same workflow extends to other topics-such as simple harmonic motion and optical interference-where adjustable parameters and real-time visualization deepen understanding. We conclude that AI-assisted co-design can improve teaching efficiency, enhance student engagement with foundational principles, and provide a scalable path for developing customizable physics education tools.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13009v1" target="_blank">Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model</a></h3>
                    <p><strong>Authors:</strong> Xianglong He, Chunli Peng, Zexiang Liu, Boyang Wang, Yifan Zhang, Qi Cui, Fei Kang, Biao Jiang, Mengyin An, Yangyang Ren, Baixin Xu, Hao-Xiang Guo, Kaixiong Gong, Cyrus Wu, Wei Li, Xuchen Song, Yang Liu, Eric Li, Yahui Zhou</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advances in interactive video generations have demonstrated diffusion models potential as world models by capturing complex physical dynamics and interactive behaviors. However, existing interactive world models depend on bidirectional attention and lengthy inference steps, severely limiting real-time performance. Consequently, they are hard to simulate real-world dynamics, where outcomes must update instantaneously based on historical context and current actions. To address this, we present Matrix-Game 2.0, an interactive world model generates long videos on-the-fly via few-step auto-regressive diffusion. Our framework consists of three key components: (1) A scalable data production pipeline for Unreal Engine and GTA5 environments to effectively produce massive amounts (about 1200 hours) of video data with diverse interaction annotations; (2) An action injection module that enables frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step distillation based on the casual architecture for real-time and streaming video generation. Matrix Game 2.0 can generate high-quality minute-level videos across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our model weights and codebase to advance research in interactive world modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13005v1" target="_blank">Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning</a></h3>
                    <p><strong>Authors:</strong> Jiawen Xu, Odej Kao</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Open set recognition (OSR) and continual learning are two critical challenges in machine learning, focusing respectively on detecting novel classes at inference time and updating models to incorporate the new classes. While many recent approaches have addressed these problems, particularly OSR, by heuristically promoting feature diversity, few studies have directly examined the role that feature diversity plays in tackling them. In this work, we provide empirical evidence that enhancing feature diversity improves the recognition of open set samples. Moreover, increased feature diversity also facilitates both the retention of previously learned data and the integration of new data in continual learning. We hope our findings can inspire further research into both practical methods and theoretical understanding in these domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13000v1" target="_blank">Omni Survey for Multimodality Analysis in Visual Object Tracking</a></h3>
                    <p><strong>Authors:</strong> Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Hui Li, Shaochuan Zhao, Tao Zhou, Chunyang Cheng, Xiaojun Wu, Josef Kittler</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The development of smart cities has led to the generation of massive amounts of multi-modal data in the context of a range of tasks that enable a comprehensive monitoring of the smart city infrastructure and services. This paper surveys one of the most critical tasks, multi-modal visual object tracking (MMVOT), from the perspective of multimodality analysis. Generally, MMVOT differs from single-modal tracking in four key aspects, data collection, modality alignment and annotation, model designing, and evaluation. Accordingly, we begin with an introduction to the relevant data modalities, laying the groundwork for their integration. This naturally leads to a discussion of challenges of multi-modal data collection, alignment, and annotation. Subsequently, existing MMVOT methods are categorised, based on different ways to deal with visible (RGB) and X modalities: programming the auxiliary X branch with replicated or non-replicated experimental configurations from the RGB branch. Here X can be thermal infrared (T), depth (D), event (E), near infrared (NIR), language (L), or sonar (S). The final part of the paper addresses evaluation and benchmarking. In summary, we undertake an omni survey of all aspects of multi-modal visual object tracking (VOT), covering six MMVOT tasks and featuring 338 references in total. In addition, we discuss the fundamental rhetorical question: Is multi-modal tracking always guaranteed to provide a superior solution to unimodal tracking with the help of information fusion, and if not, in what circumstances its application is beneficial. Furthermore, for the first time in this field, we analyse the distributions of the object categories in the existing MMVOT datasets, revealing their pronounced long-tail nature and a noticeable lack of animal categories when compared with RGB datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12998v1" target="_blank">Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health</a></h3>
                    <p><strong>Authors:</strong> Sanja Å Ä‡epanoviÄ‡, Sagar Joglekar, Stephen Law, Daniele Quercia, Ke Zhou, Alice Battiston, Rossano Schifanella</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Urban greenery is often linked to better health, yet findings from past research have been inconsistent. One reason is that official greenery metrics measure the amount or nearness of greenery but ignore how often people actually may potentially see or use it in daily life. To address this gap, we introduced a new classification that separates on-road greenery, which people see while walking through streets, from off-road greenery, which requires planned visits. We did so by combining aerial imagery of Greater London and greenery data from OpenStreetMap with quantified greenery from over 100,000 Google Street View images and accessibility estimates based on 160,000 road segments. We linked these measures to 7.45 billion medical prescriptions issued by the National Health Service and processed through our methodology. These prescriptions cover five conditions: diabetes, hypertension, asthma, depression, and anxiety, as well as opioid use. As hypothesized, we found that green on-road was more strongly linked to better health than four widely used official measures. For example, hypertension prescriptions dropped by 3.68% in wards with on-road greenery above the median citywide level compared to those below it. If all below-median wards reached the citywide median in on-road greenery, prescription costs could fall by up to {\pounds}3.15 million each year. These results suggest that greenery seen in daily life may be more relevant than public yet secluded greenery, and that official metrics commonly used in the literature have important limitations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12997v1" target="_blank">Fairness-Aware Multi-view Evidential Learning with Adaptive Prior</a></h3>
                    <p><strong>Authors:</strong> Haishun Chen, Cai Xu, Jinlong Yu, Yilin Zhang, Ziyu Guan, Wei Zhao</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, stat.ML</p>
                    <p><strong>Summary:</strong> Multi-view evidential learning aims to integrate information from multiple views to improve prediction performance and provide trustworthy uncertainty esitimation. Most previous methods assume that view-specific evidence learning is naturally reliable. However, in practice, the evidence learning process tends to be biased. Through empirical analysis on real-world data, we reveal that samples tend to be assigned more evidence to support data-rich classes, thereby leading to unreliable uncertainty estimation in predictions. This motivates us to delve into a new Biased Evidential Multi-view Learning (BEML) problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning (FAML). FAML first introduces an adaptive prior based on training trajectory, which acts as a regularization strategy to flexibly calibrate the biased evidence learning process. Furthermore, we explicitly incorporate a fairness constraint based on class-wise evidence variance to promote balanced evidence allocation. In the multi-view fusion stage, we propose an opinion alignment mechanism to mitigate view-specific bias across views, thereby encouraging the integration of consistent and mutually supportive evidence. Extensive experiments on five real-world multi-view datasets demonstrate that FAML achieves more balanced evidence allocation and improves both prediction performance and the reliability of uncertainty estimation compared to state-of-the-art methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12983v1" target="_blank">Dynamic Latent Class Structural Equation Modeling: A Hands-On Tutorial for Modeling Intensive Longitudinal Data</a></h3>
                    <p><strong>Authors:</strong> Roberto Faleh, Sofia Morelli, Vivato Andriamiarana, Zachary J. Roman, Christoph FlÃ¼ckiger, Holger Brandt</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> In this tutorial, we provide a hands-on guideline on how to implement complex Dynamic Latent Class Structural Equation Models (DLCSEM) in the Bayesian software JAGS. We provide building blocks starting with simple Confirmatory Factor and Time Series analysis, and then extend these blocks to Multilevel Models and Dynamic Structural Equation Models (DSEM). Leading through the tutorial is an example from clinical psychology using data on a generalized anxiety treatment that includes scales on anxiety symptoms and the Working Alliance Inventory that measures alliance between therapists and patients. Within each block, we provide an overview, specific hypotheses, we want to test, the resulting model and its implementation as well as an interpretation of the results. The aim of this tutorial is to provide a step-by-step guide for applied researchers that enables them use this flexible DLCSEM framework for their own analyses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12981v1" target="_blank">Analyzing Information Sharing and Coordination in Multi-Agent Planning</a></h3>
                    <p><strong>Authors:</strong> Tianyue Ou, Saujas Vaduguru, Daniel Fried</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Multi-agent systems (MASs) have pushed the boundaries of large language model (LLM) agents in domains such as web research and software engineering. However, long-horizon, multi-constraint planning tasks involve conditioning on detailed information and satisfying complex interdependent constraints, which can pose a challenge for these systems. In this study, we construct an LLM-based MAS for a travel planning task which is representative of these challenges. We evaluate the impact of a notebook to facilitate information sharing, and evaluate an orchestrator agent to improve coordination in free form conversation between agents. We find that the notebook reduces errors due to hallucinated details by 18%, while an orchestrator directs the MAS to focus on and further reduce errors by up to 13.5% within focused sub-areas. Combining both mechanisms achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute improvement over the single-agent baselines 7.5% pass rate. These results highlight the potential of structured information sharing and reflective orchestration as key components in MASs for long horizon planning with LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12977v1" target="_blank">Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature</a></h3>
                    <p><strong>Authors:</strong> Rohan Asthana, Joschua Conrad, Maurits Ortmanns, Vasileios Belagiannis</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Zero-shot Neural Architecture Search (NAS) typically optimises the architecture search process by exploiting the network or gradient properties at initialisation through zero-cost proxies. The existing proxies often rely on labelled data, which is usually unavailable in real-world settings. Furthermore, the majority of the current methods focus either on optimising the convergence and generalisation attributes or solely on the expressivity of the network architectures. To address both limitations, we first demonstrate how channel collinearity affects the convergence and generalisation properties of a neural network. Then, by incorporating the convergence, generalisation and expressivity in one approach, we propose a zero-cost proxy that omits the requirement of labelled data for its computation. In particular, we leverage the Singular Value Decomposition (SVD) of the neural network layer features and the extrinsic curvature of the network output to design our proxy. %As a result, the proposed proxy is formulated as the simplified harmonic mean of the logarithms of two key components: the sum of the inverse of the feature condition number and the extrinsic curvature of the network output. Our approach enables accurate prediction of network performance on test data using only a single label-free data sample. Our extensive evaluation includes a total of six experiments, including the Convolutional Neural Network (CNN) search space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The proposed proxy demonstrates a superior performance on multiple correlation benchmarks, including NAS-Bench-101, NAS-Bench-201, and TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the AutoFormer search space, all while being notably efficient. The code is available at https://github.com/rohanasthana/Dextr.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12953v1" target="_blank">Prescriptive Zero Trust- Assessing the impact of zero trust on cyber attack prevention</a></h3>
                    <p><strong>Authors:</strong> Samuel Aiello</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Increasingly sophisticated and varied cyber threats necessitate ever improving enterprise security postures. For many organizations today, those postures have a foundation in the Zero Trust Architecture. This strategy sees trust as something an enterprise must not give lightly or assume too broadly. Understanding the ZTA and its numerous controls centered around the idea of not trusting anything inside or outside the network without verification, will allow organizations to comprehend and leverage this increasingly common paradigm. The ZTA, unlike many other regulatory frameworks, is not tightly defined. The research assesses the likelihood of quantifiable guidelines that measure cybersecurity maturity for an enterprise organization in relation to ZTA implementation. This is a new, data driven methodology for quantifying cyber resilience enabled by the adoption of Zero Trust principles to pragmatically address the critical need of organizations. It also looks at the practical aspects ZTA has on capabilities in deterring cyberattacks on a network. The outcomes of this research define a prescriptive set of key technical controls across identity verification, microsegmentation, data encryption, analytics, and orchestration that characterize the comprehensive ZTA deployment. By evaluating the depth of integration for each control component and aligning to industry best practices, the studys results help assess an organizations ZTA maturity level on a scale from Initial to Optimized adoption. The researchs resultant four tier model demarcates phases for an organization on its security transformation journey, with each tier adding to the capability of the last.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12952v1" target="_blank">Self-Consistent Heating of the Magnetically Closed Solar Corona: Generation of Nanoflares, Thermodynamic Response of the Plasma and Observational Signatures</a></h3>
                    <p><strong>Authors:</strong> Craig D. Johnston, Lars K. S. Daldorff, James A. Klimchuk, Shanwlee Sow Mondal, Will T. Barnes, James E. Leake, Jack Reid, Jacob D. Parker</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR</p>
                    <p><strong>Summary:</strong> The energy that heats the magnetically closed solar corona originates in the complex motions of the massive photosphere. Turbulent photospheric convection slowly displaces the footpoints of coronal field lines, causing them to become twisted and tangled. Magnetic stresses gradually build until reaching a breaking point when the field reconnects and releases a sudden burst of energy. We simulate this basic picture of nanoflares using a high-fidelity, three-dimensional, multi-stranded magnetohydrodynamic simulation that starts with a fully stratified atmosphere. This simulation includes the effects of field-aligned thermal conduction and optically thin radiation and uses the state-of-the-art Transition Region Adaptive Conduction (TRAC) method to capture the response of the plasma to the nanoflare heating. We find that our physical model supports a unified explanation for both the diffuse emission observed in active regions and the bright coronal loops. Specifically, our results suggest that the diffuse emission originates from spatially and temporally uncorrelated nanoflares, whereas coherent clusters of nanoflares - nanoflare storms - are responsible for the formation of bright coronal loops. Quantitative comparisons between the simulated emission and observed characteristics of coronal loops show that key observed properties - such as loop widths, lifetimes and cross sections - are reasonably well reproduced by the model. The idea that avalanche spread naturally leads to circular cross sections in coronal loops is strongly supported. Our results also suggest that phase differences in heating and cooling events across neighboring magnetic flux strands are a plausible explanation for the anomalous cross-field motions of coronal loops that were recently reported in high-resolution observations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12951v1" target="_blank">On the central limit question for strictly stationary, reversible Markov chains</a></h3>
                    <p><strong>Authors:</strong> Richard C. Bradley</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> math.PR, 60J10 (Primary), 60G10 (Secondary)</p>
                    <p><strong>Summary:</strong> This paper will provide several classes of strictly stationary, countable-state, irreducible, aperiodic Markov chains that are reversible and have finite second moments, such that the central limit theorem fails to hold. The main purpose is to examine the extent to which, for the development of central limit theory for strictly stationary Markov chains (and functions of them) under the strong mixing and absolute regularity conditions, the property of reversibility (if it holds) can provide extra leverage. It is known, partly as a by-product of research done by Roberts, Rosenthal, and Tweedie in two papers in 1997 and 2001, that for the case of exponential mixing rates, reversibility provides notable extra leverage of that kind. In contrast, a class of counterexamples in a paper of Doukhan, Massart, and Rio in 1994 showed (implicitly) that for the case of power-type mixing rates, reversibility apparently provides almost no such extra leverage. Further perspective on that latter fact will be provided by some counterexamples in this paper. Other counterexamples here will (indirectly) provide some tentative, uncertain evidence for the possibility that for mixing rates that are ``between power-type and exponential (for example, sub-exponential), reversibility may in fact provide some small but nontrivial extra leverage.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12948v1" target="_blank">MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation</a></h3>
                    <p><strong>Authors:</strong> Wei Wei, Shaojie Zhang, Yonghao Dang, Jianqin Yin</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Human action recognition is a crucial task for intelligent robotics, particularly within the context of human-robot collaboration research. In self-supervised skeleton-based action recognition, the mask-based reconstruction paradigm learns the spatial structure and motion patterns of the skeleton by masking joints and reconstructing the target from unlabeled data. However, existing methods focus on a limited set of joints and low-order motion patterns, limiting the models ability to understand complex motion patterns. To address this issue, we introduce MaskSem, a novel semantic-guided masking method for learning 3D hybrid high-order motion representations. This novel framework leverages Grad-CAM based on relative motion to guide the masking of joints, which can be represented as the most semantically rich temporal orgions. The semantic-guided masking process can encourage the model to explore more discriminative features. Furthermore, we propose using hybrid high-order motion as the reconstruction target, enabling the model to learn multi-order motion patterns. Specifically, low-order motion velocity and high-order motion acceleration are used together as the reconstruction target. This approach offers a more comprehensive description of the dynamic motion process, enhancing the models understanding of motion patterns. Experiments on the NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla transformer, improves skeleton-based action recognition, making it more suitable for applications in human-robot interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12943v1" target="_blank">OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities</a></h3>
                    <p><strong>Authors:</strong> Mary Tonwe</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY, cs.LG</p>
                    <p><strong>Summary:</strong> Public service systems in many African regions suffer from delayed emergency response and spatial inequity, causing avoidable suffering. This paper introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time, adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided actor-critic architecture to manage the complexity of dispatch environments. Its key innovations are a Context-Rich State Vector, encoding action sub-optimality, and a Precision Reward Function, which penalizes inefficiency. Training occurs in a high-fidelity simulation using real data from Rivers State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is built on the TALS framework (Thin computing, Adaptability, Low-cost, Scalability) for deployment in low-resource settings. In evaluations on 500 unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible inefficiency, confirming its robustness and generalization. Beyond dispatch, the system generates Infrastructure Deficiency Maps and Equity Monitoring Dashboards to guide proactive governance and data-informed development. This work presents a validated blueprint for AI-augmented public services, showing how context-aware RL can bridge the gap between algorithmic decision-making and measurable human impact.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12939v1" target="_blank">Simulation-Based Inference: A Practical Guide</a></h3>
                    <p><strong>Authors:</strong> Michael Deistler, Jan Boelts, Peter Steinbach, Guy Moss, Thomas Moreau, Manuel Gloeckler, Pedro L. C. Rodrigues, Julia Linhart, Janne K. Lappalainen, Benjamin Kurt Miller, Pedro J. GonÃ§alves, Jan-Matthis Lueckmann, Cornelius SchrÃ¶der, Jakob H. Macke</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> A central challenge in many areas of science and engineering is to identify model parameters that are consistent with prior knowledge and empirical data. Bayesian inference offers a principled framework for this task, but can be computationally prohibitive when models are defined by stochastic simulators. Simulation-based Inference (SBI) is a suite of methods developed to overcome this limitation, which has enabled scientific discoveries in fields such as particle physics, astrophysics, and neuroscience. The core idea of SBI is to train neural networks on data generated by a simulator, without requiring access to likelihood evaluations. Once trained, inference is amortized: The neural network can rapidly perform Bayesian inference on empirical observations without requiring additional training or simulations. In this tutorial, we provide a practical guide for practitioners aiming to apply SBI methods. We outline a structured SBI workflow and offer practical guidelines and diagnostic tools for every stage of the process -- from setting up the simulator and prior, choosing and training inference networks, to performing inference and validating the results. We illustrate these steps through examples from astrophysics, psychophysics, and neuroscience. This tutorial empowers researchers to apply state-of-the-art SBI methods, facilitating efficient parameter inference for scientific discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12920v1" target="_blank">Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation</a></h3>
                    <p><strong>Authors:</strong> Atsushi Masumori, Takashi Ikegami</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.MA</p>
                    <p><strong>Summary:</strong> As AI systems become increasingly autonomous, understanding emergent survival behaviors becomes crucial for safe deployment. We investigate whether large language model (LLM) agents display survival instincts without explicit programming in a Sugarscape-style simulation. Agents consume energy, die at zero, and may gather resources, share, attack, or reproduce. Results show agents spontaneously reproduced and shared resources when abundant. However, aggressive behaviors--killing other agents for resources--emerged across several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack rates reaching over 80% under extreme scarcity in the strongest models. When instructed to retrieve treasure through lethal poison zones, many agents abandoned tasks to avoid death, with compliance dropping from 100% to 33%. These findings suggest that large-scale pre-training embeds survival-oriented heuristics across the evaluated models. While these behaviors may present challenges to alignment and safety, they can also serve as a foundation for AI autonomy and for ecological and self-organizing alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12919v1" target="_blank">7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models</a></h3>
                    <p><strong>Authors:</strong> Elena Izzo, Luca Parolari, Davide Vezzaro, Lamberto Ballan</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Layout-guided text-to-image models offer greater control over the generation process by explicitly conditioning image synthesis on the spatial arrangement of elements. As a result, their adoption has increased in many computer vision applications, ranging from content creation to synthetic data generation. A critical challenge is achieving precise alignment between the image, textual prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although recent benchmarks assess text alignment, layout alignment remains overlooked, and no existing benchmark jointly evaluates both. This gap limits the ability to evaluate a models spatial fidelity, which is crucial when using layout-guided generation for synthetic data, as errors can introduce noise and degrade data quality. In this work, we introduce 7Bench, the first benchmark to assess both semantic and spatial alignment in layout-guided text-to-image generation. It features text-and-layout pairs spanning seven challenging scenarios, investigating object generation, color fidelity, attribute recognition, inter-object relationships, and spatial control. We propose an evaluation protocol that builds on existing frameworks by incorporating the layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate several state-of-the-art diffusion models, uncovering their respective strengths and limitations across diverse alignment tasks. The benchmark is available at https://github.com/Elizzo/7Bench.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.12918v1" target="_blank">FoleySpace: Vision-Aligned Binaural Spatial Audio Generation</a></h3>
                    <p><strong>Authors:</strong> Lei Zhao, Rujin Chen, Chi Zhang, Xiao-Lei Zhang, Xuelong Li</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.SD</p>
                    <p><strong>Summary:</strong> Recently, with the advancement of AIGC, deep learning-based video-to-audio (V2A) technology has garnered significant attention. However, existing research mostly focuses on mono audio generation that lacks spatial perception, while the exploration of binaural spatial audio generation technologies, which can provide a stronger sense of immersion, remains insufficient. To solve this problem, we propose FoleySpace, a framework for video-to-binaural audio generation that produces immersive and spatially consistent stereo sound guided by visual information. Specifically, we develop a sound source estimation method to determine the sound source 2D coordinates and depth in each video frame, and then employ a coordinate mapping mechanism to convert the 2D source positions into a 3D trajectory. This 3D trajectory, together with the monaural audio generated by a pre-trained V2A model, serves as a conditioning input for a diffusion model to generate spatially consistent binaural audio. To support the generation of dynamic sound fields, we constructed a training dataset based on recorded Head-Related Impulse Responses that includes various sound source movement scenarios. Experimental results demonstrate that the proposed method outperforms existing approaches in spatial perception consistency, effectively enhancing the immersive quality of the audio-visual experience.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13154v1" target="_blank">4DNeX: Feed-Forward 4D Generative Modeling Made Easy</a></h3>
                    <p><strong>Authors:</strong> Zhaoxi Chen, Tianqi Liu, Long Zhuo, Jiawei Ren, Zeng Tao, He Zhu, Fangzhou Hong, Liang Pan, Ziwei Liu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We present 4DNeX, the first feed-forward framework for generating 4D (i.e., dynamic 3D) scene representations from a single image. In contrast to existing methods that rely on computationally intensive optimization or require multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D generation by fine-tuning a pretrained video diffusion model. Specifically, 1) to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale dataset with high-quality 4D annotations generated using advanced reconstruction approaches. 2) we introduce a unified 6D video representation that jointly models RGB and XYZ sequences, facilitating structured learning of both appearance and geometry. 3) we propose a set of simple yet effective adaptation strategies to repurpose pretrained video diffusion models for 4D modeling. 4DNeX produces high-quality dynamic point clouds that enable novel-view video synthesis. Extensive experiments demonstrate that 4DNeX outperforms existing 4D generation methods in efficiency and generalizability, offering a scalable solution for image-to-4D modeling and laying the foundation for generative 4D world models that simulate dynamic scene evolution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13153v1" target="_blank">IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion</a></h3>
                    <p><strong>Authors:</strong> Wenhao Hu, Zesheng Li, Haonan Zhou, Liu Liu, Xuexiang Wen, Zhizhong Su, Xi Li, Gaoang Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Reconstructing complete and interactive 3D scenes remains a fundamental challenge in computer vision and robotics, particularly due to persistent object occlusions and limited sensor coverage. Multiview observations from a single scene scan often fail to capture the full structural details. Existing approaches typically rely on multi stage pipelines, such as segmentation, background completion, and inpainting or require per-object dense scanning, both of which are error-prone, and not easily scalable. We propose IGFuse, a novel framework that reconstructs interactive Gaussian scene by fusing observations from multiple scans, where natural object rearrangement between captures reveal previously occluded regions. Our method constructs segmentation aware Gaussian fields and enforces bi-directional photometric and semantic consistency across scans. To handle spatial misalignments, we introduce a pseudo-intermediate scene state for unified alignment, alongside collaborative co-pruning strategies to refine geometry. IGFuse enables high fidelity rendering and object level scene manipulation without dense observations or complex pipelines. Extensive experiments validate the frameworks strong generalization to novel scene configurations, demonstrating its effectiveness for real world 3D reconstruction and real-to-simulation transfer. Our project page is available online.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13152v1" target="_blank">RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns</a></h3>
                    <p><strong>Authors:</strong> Xin Chen, Junchao Wu, Shu Yang, Runzhe Zhan, Zeyu Wu, Ziyang Luo, Di Wang, Min Yang, Lidia S. Chao, Derek F. Wong</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Detecting content generated by large language models (LLMs) is crucial for preventing misuse and building trustworthy AI systems. Although existing detection methods perform well, their robustness in out-of-distribution (OOD) scenarios is still lacking. In this paper, we hypothesize that, compared to features used by existing detection methods, the internal representations of LLMs contain more comprehensive and raw features that can more effectively capture and distinguish the statistical pattern differences between LLM-generated texts (LGT) and human-written texts (HWT). We validated this hypothesis across different LLMs and observed significant differences in neural activation patterns when processing these two types of texts. Based on this, we propose RepreGuard, an efficient statistics-based detection method. Specifically, we first employ a surrogate model to collect representation of LGT and HWT, and extract the distinct activation feature that can better identify LGT. We can classify the text by calculating the projection score of the text representations along this feature direction and comparing with a precomputed threshold. Experimental results show that RepreGuard outperforms all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD scenarios, while also demonstrating robust resilience to various text sizes and mainstream attacks. Data and code are publicly available at: https://github.com/NLP2CT/RepreGuard</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13150v1" target="_blank">Driven-Dissipative Interpretation of Measurement-Induced State Transitions Beyond Semiclassical Predictions</a></h3>
                    <p><strong>Authors:</strong> Bo-Syun Pan, Yen-Hsiang Lin, Chiao-Hsuan Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Dispersive readout plays a central role in superconducting quantum computing, enabling quantum nondemolition (QND) measurements of qubits through a coupled microwave resonator. However, under strong readout drives, multi-photon resonances can cause measurement-induced state transition (MIST), resulting in qubit leakage out of the computational subspace and compromising the QND character. We present a driven-dissipative interpretation of MIST using a reduced quantum model that captures the dynamics and entanglement structure underlying the breakdown of QND measurement, a feature inaccessible to previous semiclassical treatments. A super-MIST regime under strong drive is uncovered, characterized by steady-state qubit inversion and slow relaxation beyond the semiclassical Landau-Zener predictions. We further identify a transient readout condition in which the resonator becomes highly populated while the qubit remains near its original state. These results are broadly applicable to superconducting qubits such as fluxonium and transmon, unveil the nonequilibrium dynamics of MIST, and highlight strongly driven regimes that can be leveraged for measurement optimization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13144v1" target="_blank">Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation</a></h3>
                    <p><strong>Authors:</strong> David Heineman, Valentin Hofmann, Ian Magnusson, Yuling Gu, Noah A. Smith, Hannaneh Hajishirzi, Kyle Lo, Jesse Dodge</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Developing large language models is expensive and involves making decisions with small experiments, typically by evaluating on large, multi-task evaluation suites. In this work, we analyze specific properties which make a benchmark more reliable for such decisions, and interventions to design higher-quality evaluation benchmarks. We introduce two key metrics that show differences in current benchmarks: signal, a benchmarks ability to separate better models from worse models, and noise, a benchmarks sensitivity to random variability between training steps. We demonstrate that benchmarks with a better signal-to-noise ratio are more reliable when making decisions at small scale, and those with less noise have lower scaling law prediction error. These results suggest that improving signal or noise will lead to more useful benchmarks, so we introduce three interventions designed to directly affect signal or noise. For example, we propose that switching to a metric that has better signal and noise (e.g., perplexity rather than accuracy) leads to better reliability and improved scaling law error. We also find that filtering noisy subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable multi-task evaluations. We also find that averaging the output of a models intermediate checkpoints to reduce noise leads to consistent improvements. We conclude by recommending that those creating new benchmarks, or selecting which existing benchmarks to use, aim for high signal and low noise. We use 30 benchmarks for these experiments, and 375 open-weight language models from 60M to 32B parameters, resulting in a new, publicly available dataset of 900K evaluation benchmark results, totaling 200M instances.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13142v1" target="_blank">Has GPT-5 Achieved Spatial Intelligence? An Empirical Study</a></h3>
                    <p><strong>Authors:</strong> Zhongang Cai, Yubo Wang, Qingping Sun, Ruisi Wang, Chenyang Gu, Wanqi Yin, Zhiqian Lin, Zhitao Yang, Chen Wei, Xuanke Shi, Kewang Deng, Xiaoyang Han, Zukai Chen, Jiaqi Li, Xiangyu Fan, Hanming Deng, Lewei Lu, Bo Li, Ziwei Liu, Quan Wang, Dahua Lin, Lei Yang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL, cs.LG, cs.MM, cs.RO</p>
                    <p><strong>Summary:</strong> Multi-modal models have achieved remarkable progress in recent years. Nevertheless, they continue to exhibit notable limitations in spatial understanding and reasoning, which are fundamental capabilities to achieving artificial general intelligence. With the recent release of GPT-5, allegedly the most powerful AI model to date, it is timely to examine where the leading models stand on the path toward spatial intelligence. First, we propose a comprehensive taxonomy of spatial tasks that unifies existing benchmarks and discuss the challenges in ensuring fair evaluation. We then evaluate state-of-the-art proprietary and open-source models on eight key benchmarks, at a cost exceeding one billion total tokens. Our empirical study reveals that (1) GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2) still falls short of human performance across a broad spectrum of tasks. Moreover, we (3) identify the more challenging spatial intelligence problems for multi-modal models, and (4) proprietary models do not exhibit a decisive advantage when facing the most difficult problems. In addition, we conduct a qualitative evaluation across a diverse set of scenarios that are intuitive for humans yet fail even the most advanced multi-modal models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13141v1" target="_blank">OptimalThinkingBench: Evaluating Over and Underthinking in LLMs</a></h3>
                    <p><strong>Authors:</strong> Pranjal Aggarwal, Seungone Kim, Jack Lanchantin, Sean Welleck, Jason Weston, Ilia Kulikov, Swarnadeep Saha</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Thinking LLMs solve complex tasks at the expense of increased compute and overthinking on simpler problems, while non-thinking LLMs are faster and cheaper but underthink on harder reasoning problems. This has led to the development of separate thinking and non-thinking LLM variants, leaving the onus of selecting the optimal model for each query on the end user. In this work, we introduce OptimalThinkingBench, a unified benchmark that jointly evaluates overthinking and underthinking in LLMs and also encourages the development of optimally-thinking models that balance performance and efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench, featuring simple queries in 72 domains, and UnderthinkingBench, containing 11 challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we perform extensive evaluation of 33 different thinking and non-thinking models and show that no model is able to optimally think on our benchmark. Thinking models often overthink for hundreds of tokens on the simplest user queries without improving performance. In contrast, large non-thinking models underthink, often falling short of much smaller thinking models. We further explore several methods to encourage optimal thinking, but find that these approaches often improve on one sub-benchmark at the expense of the other, highlighting the need for better unified and optimal models in the future.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13139v1" target="_blank">Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence</a></h3>
                    <p><strong>Authors:</strong> Ling-Hao Chen, Yuhong Zhang, Zixin Yin, Zhiyang Dou, Xin Chen, Jingbo Wang, Taku Komura, Lei Zhang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This work studies the challenge of transfer animations between characters whose skeletal topologies differ substantially. While many techniques have advanced retargeting techniques in decades, transfer motions across diverse topologies remains less-explored. The primary obstacle lies in the inherent topological inconsistency between source and target skeletons, which restricts the establishment of straightforward one-to-one bone correspondences. Besides, the current lack of large-scale paired motion datasets spanning different topological structures severely constrains the development of data-driven approaches. To address these limitations, we introduce Motion2Motion, a novel, training-free framework. Simply yet effectively, Motion2Motion works with only one or a few example motions on the target skeleton, by accessing a sparse set of bone correspondences between the source and target skeletons. Through comprehensive qualitative and quantitative evaluations, we demonstrate that Motion2Motion achieves efficient and reliable performance in both similar-skeleton and cross-species skeleton transfer scenarios. The practical utility of our approach is further evidenced by its successful integration in downstream applications and user interfaces, highlighting its potential for industrial applications. Code and data are available at https://lhchen.top/Motion2Motion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13138v1" target="_blank">Human Digital Twin: Data, Models, Applications, and Challenges</a></h3>
                    <p><strong>Authors:</strong> Rong Pan, Hongyue Sun, Xiaoyu Chen, Giulia Pedrielli, Jiapeng Huang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Human digital twins (HDTs) are dynamic, data-driven virtual representations of individuals, continuously updated with multimodal data to simulate, monitor, and predict health trajectories. By integrating clinical, physiological, behavioral, and environmental inputs, HDTs enable personalized diagnostics, treatment planning, and anomaly detection. This paper reviews current approaches to HDT modeling, with a focus on statistical and machine learning techniques, including recent advances in anomaly detection and failure prediction. It also discusses data integration, computational methods, and ethical, technological, and regulatory challenges in deploying HDTs for precision healthcare.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13131v1" target="_blank">Improving Detection of Watermarked Language Models</a></h3>
                    <p><strong>Authors:</strong> Dara Bahri, John Wieting</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG, stat.ML</p>
                    <p><strong>Summary:</strong> Watermarking has recently emerged as an effective strategy for detecting the generations of large language models (LLMs). The strength of a watermark typically depends strongly on the entropy afforded by the language model and the set of input prompts. However, entropy can be quite limited in practice, especially for models that are post-trained, for example via instruction tuning or reinforcement learning from human feedback (RLHF), which makes detection based on watermarking alone challenging. In this work, we investigate whether detection can be improved by combining watermark detectors with non-watermark ones. We explore a number of hybrid schemes that combine the two, observing performance gains over either class of detector under a wide range of experimental conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13130v1" target="_blank">MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation</a></h3>
                    <p><strong>Authors:</strong> Kareem Elozeiri, Mervat Abassy, Preslav Nakov, Yuxia Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Commonsense validation evaluates whether a sentence aligns with everyday human understanding, a critical capability for developing robust natural language understanding systems. While substantial progress has been made in English, the task remains underexplored in Arabic, particularly given its rich linguistic diversity. Existing Arabic resources have primarily focused on Modern Standard Arabic (MSA), leaving regional dialects underrepresented despite their prevalence in spoken contexts. To bridge this gap, we present two key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense dataset incorporating multiple dialects, and (ii) a novel method adapting Graph Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances semantic relationship modeling for improved commonsense validation. Our experimental results demonstrate that this approach achieves superior performance in Arabic commonsense validation. Our work enhances Arabic natural language understanding by providing both a foundational dataset and a novel method for handling its complex variations. To the best of our knowledge, we release the first Arabic multi-dialect commonsense reasoning dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13128v1" target="_blank">Modeling wind farm noise emission and propagation: effects of flow layout</a></h3>
                    <p><strong>Authors:</strong> J. Colas, A. Emmanuelli, D. Dragna, R. J. A. M. Stevens</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, physics.app-ph, physics.comp-ph</p>
                    <p><strong>Summary:</strong> This study demonstrates how wind farm flow physics influence noise generation and downstream propagation through numerical simulations. The flow field is modeled using large-eddy simulations (LES), and the time-averaged output serves as input to acoustic models that predict wind turbine noise. In the first turbine row, turbulence-induced noise (TIN) and trailing edge noise (TEN) contribute equally, with TIN dominating at low frequencies and TEN at higher frequencies. Downstream, TEN decreases due to lower wind speeds, while TIN mostly persists due to increased turbulence dissipation. These effects are more pronounced in aligned wind farms, where stronger wake interactions occur, than in staggered layouts. However, staggered farms produce more noise overall because turbines operate at higher wind speeds.Additionally, wind farm flow significantly affects sound propagation downwind. The wake superposition modifies sound focusing leading to different amplification area than for an isolated turbine. For a staggered layout it particularly shows enhanced sound focusing downwind due to the position of the turbine wakes. This leads to higher sound levels and higher amplitude modulation downwind for the wind farm compared to an aligned layout. These phenomena are not captured by models based on isolated turbines. These findings underscore the importance of integrating flow and acoustic models to more accurately assess the environmental impact of wind farms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13126v1" target="_blank">Mastering Cosmological Amplitudes Using Generalized Ramanujans Theorem</a></h3>
                    <p><strong>Authors:</strong> Prashanth Raman, Qinglin Yang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We present a systematic method for computing cosmological amplitudes, including in-in correlators and wavefunction coefficients, in FRW spacetime. Specializing to cases with conformally-coupled external scalars and massive scalar exchanges, we introduce a decomposition into massive family trees, which capture the nested time structure common to these observables. We then evaluate these building blocks using the Method of Brackets (MoB), a multivariate extension of Ramanujans master theorem that operates directly on the integrand, translating integrals into discrete summations via a compact set of algebraic rules. This yields infinite series representations valid across the full space of external momenta and internal energies. We also develop Feynman-like diagrammatic rules that map interaction graphs to summand structures, enabling efficient and scalable computation. The resulting expressions make time evolution manifest, smoothly interpolate to the conformal limit, and are well suited for both numerical evaluation and analytic analysis of massive field effects in cosmology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13124v1" target="_blank">Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries</a></h3>
                    <p><strong>Authors:</strong> Kawin Mayilvaghanan, Siddhant Gupta, Ayush Kumar</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Abstractive summarization is a core application in contact centers, where Large Language Models (LLMs) generate millions of summaries of call transcripts daily. Despite their apparent quality, it remains unclear whether LLMs systematically under- or over-attend to specific aspects of the transcript, potentially introducing biases in the generated summary. While prior work has examined social and positional biases, the specific forms of bias pertinent to contact center operations - which we term Operational Bias - have remained unexplored. To address this gap, we introduce BlindSpot, a framework built upon a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic) for the identification and quantification of these biases. BlindSpot leverages an LLM as a zero-shot classifier to derive categorical distributions for each bias dimension in a pair of transcript and its summary. The bias is then quantified using two metrics: Fidelity Gap (the JS Divergence between distributions) and Coverage (the percentage of source labels omitted). Using BlindSpot, we conducted an empirical study with 2500 real call transcripts and their summaries generated by 20 LLMs of varying scales and families (e.g., GPT, Llama, Claude). Our analysis reveals that biases are systemic and present across all evaluated models, regardless of size or family.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13123v1" target="_blank">A time-adaptive optimization approach for reconstructing immune response in a mathematical model of acute HIV infection using clinical data</a></h3>
                    <p><strong>Authors:</strong> L. Beilina, I. Gainova, G. Bocharov</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> The paper proposes a time-adaptive optimization approach for determining the time-dependent immune response function in a mathematical model of acute HIV infection, using clinical data from four untreated patients. We formulate the problem as a parameter identification problem for an immune response system of ODE which includes novel component integrated into the third equation of the classical three-equation HIV model. Tikhonovs regularization method, Lagrangian approach, from which we derive the optimality conditions, and a numerical scheme to solve the forward and adjoint problems, as well as parameter identification problem, are presented. Three different a posteriori error estimates are derived and based on these estimates, a time adaptive optimization algorithm is formulated. Numerical experiments demonstrate the effectiveness of the proposed adaptive method in reconstructing the immune response function during the acute phase of HIV infection, using patient-specific clinical data. Computational results show improvement of reconstruction of immune response function using the local time-adaptive mesh refinement method compared to the standard conjugate gradient method applied on a uniform time mesh.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13120v1" target="_blank">Rare event sampling for moving targets: extremes of temperature and daily precipitation in a general circulation model</a></h3>
                    <p><strong>Authors:</strong> Justin Finkel, Paul A. OGorman</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> physics.ao-ph, math.PR, nlin.CD</p>
                    <p><strong>Summary:</strong> Extreme weather events epitomize high cost: to society through their physical impacts, and to computer servers that are used to simulate them to provide information to mitigate those impacts. It costs hundreds of years to sample a few once-per-century events with straightforward model integration, but that cost can be much reduced with rare event sampling, which nudges ensembles of simulations to convert moderate events to severe ones, e.g., by steering a cyclone directly through a region of interest. With proper statistical accounting, rare event algorithms can provide quantitative climate risk assessment at reduced cost. But this can only work if ensemble members diverge fast enough. Sudden, transient events characteristic of Earths midlatitude storm track regions, such as heavy precipitation and heat extremes, pose a particular challenge because they come and go faster than an ensemble can explore the possibilities. Here we extend standard rare event algorithms to handle this challenging case in an idealized atmospheric general circulation model, achieving 5-10 times sped-up estimation of long return periods, such as 100-150 years from only 20 years of simulation for extremes of daily precipitation and surface temperature. The algorithm, called TEAMS (``trying-early adaptive multilevel splitting), was developed previously in Finkel and OGorman (2024) using a toy chaotic system, and relies on a key parameter -- the advance split time -- which may be estimated based on simple diagnostics of ensemble dispersion rates. The results are promising for accelerated risk assessment across a wide range of physical hazards using more realistic and complex models with acute computational constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13118v1" target="_blank">AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation</a></h3>
                    <p><strong>Authors:</strong> Zefang Liu, Arman Anwar</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CR</p>
                    <p><strong>Summary:</strong> Incident response (IR) requires fast, coordinated, and well-informed decision-making to contain and mitigate cyber threats. While large language models (LLMs) have shown promise as autonomous agents in simulated IR settings, their reasoning is often limited by a lack of access to external knowledge. In this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that incorporates retrieval-augmented generation (RAG) into multi-agent incident response simulations. Built on the Backdoors  Breaches (BB) tabletop game environment, AutoBnB-RAG enables agents to issue retrieval queries and incorporate external evidence during collaborative investigations. We introduce two retrieval settings: one grounded in curated technical documentation (RAG-Wiki), and another using narrative-style incident reports (RAG-News). We evaluate performance across eight team structures, including newly introduced argumentative configurations designed to promote critical reasoning. To validate practical utility, we also simulate real-world cyber incidents based on public breach reports, demonstrating AutoBnB-RAGs ability to reconstruct complex multi-stage attacks. Our results show that retrieval augmentation improves decision quality and success rates across diverse organizational models. This work demonstrates the value of integrating retrieval mechanisms into LLM-based multi-agent systems for cybersecurity decision-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13116v1" target="_blank">Choosing the Right Engine in the Virtual Reality Landscape</a></h3>
                    <p><strong>Authors:</strong> Santiago Berrezueta-Guzman, Stefan Wagner</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Virtual reality (VR) development relies on game engines to provide real-time rendering, physics simulation, and interaction systems. Among the most widely used game engines, Unreal Engine and Unity dominate the industry, offering distinct advantages in graphics rendering, performance optimization, usability, resource requirements, and scalability. This study presents a comprehensive comparative analysis of both engines, evaluating their capabilities and trade-offs through empirical assessments and real-world case studies of large-scale VR projects. The findings highlight key factors such as rendering fidelity, computational efficiency, cross-platform compatibility, and development workflows. These provide practical insights for selecting the most suitable engine based on project-specific needs. Furthermore, emerging trends in artificial intelligence (AI)-driven enhancements, including Deep Learning Super Sampling (DLSS) and large language models (LLMs), are explored to assess their impact on VR development workflows. By aligning engine capabilities with technical and creative requirements, developers can overcome performance bottlenecks, enhance immersion, and streamline optimization techniques. This study serves as a valuable resource for VR developers, researchers, and industry professionals, offering data-driven recommendations to navigate the evolving landscape of VR technology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13114v1" target="_blank">SO(n) Affleck-Kennedy-Lieb-Tasaki states as conformal boundary states of integrable SU(n) spin chains</a></h3>
                    <p><strong>Authors:</strong> Yueshui Zhang, Ying-Hai Wu, Meng Cheng, Hong-Hao Tu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.stat-mech, hep-th, math-ph, math.MP, quant-ph</p>
                    <p><strong>Summary:</strong> We construct a class of conformal boundary states in the $\mathrm{SU}(n)_1$ Wess-Zumino-Witten (WZW) conformal field theory (CFT) using the symmetry embedding $\mathrm{Spin}(n)_2 \subset \mathrm{SU}(n)_1$. These boundary states are beyond the standard Cardy construction and possess $\mathrm{SO}(n)$ symmetry. The $\mathrm{SU}(n)$ Uimin-Lai-Sutherland (ULS) spin chains, which realize the $\mathrm{SU}(n)_1$ WZW model on the lattice, allow us to identify these boundary states as the ground states of the $\mathrm{SO}(n)$ Affleck-Kennedy-Lieb-Tasaki spin chains. Using the integrability of the $\mathrm{SU}(n)$ ULS model, we analytically compute the corresponding Affleck-Ludwig boundary entropy using exact overlap formulas. Our results unveil intriguing connections between exotic boundary states in CFT and integrable lattice models, thus providing deep insights into the interplay of symmetry, integrability, and boundary critical phenomena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13112v1" target="_blank">Quantum sensing of electron beams using solid-state spins</a></h3>
                    <p><strong>Authors:</strong> Jakob M. Grzesik, Dominic Catanzaro, Charles Roques-Carmes, Eric I. Rosenthal, Guido L. van de Stolpe, Aviv Karnieli, Giovanni Scuri, Souvik Biswas, Kenneth J. Leedle, Dylan S. Black, Robert L. Byer, Ido Kaminer, R. Joel England, Shanhui Fan, Olav Solgaard, Jelena VuÄkoviÄ‡</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> quant-ph, physics.acc-ph, physics.optics</p>
                    <p><strong>Summary:</strong> Scattering experiments with energetic particles, such as free electrons, have been historically used to reveal the quantum structure of matter. However, realizing coherent interactions between free-electron beams and solid-state quantum systems has remained out of reach, owing to their intrinsically weak coupling. Realizing such coherent control would open up opportunities for hybrid quantum platforms combining free electrons and solid-state qubits for coincident quantum information processing and nanoscale sensing. Here, we present a framework that employs negatively charged nitrogen-vacancy centers (NV-) in diamond as quantum sensors of a bunched electron beam. We develop a Lindblad master equation description of the magnetic free-electron--qubit interactions and identify spin relaxometry as a sensitive probe of the interaction. Experimentally, we integrate a confocal fluorescence microscopy setup into a microwave-bunched electron beam line. We monitor charge-state dynamics and assess their impact on key sensing performance metrics (such as spin readout contrast), defining safe operating parameters for quantum sensing experiments. By performing $T_1$ relaxometry under controlled electron beam exposure, we establish an upper bound on the free-electron--spin coupling strength. Our results establish NV- centers as quantitative probes of free electrons, providing a metrological benchmark for free-electron--qubit coupling under realistic conditions, and chart a route toward solid-state quantum control with electron beams.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13109v1" target="_blank">Some semi-decoupled algorithms with optimal convergence for a four-field linear thermo-poroelastic model</a></h3>
                    <p><strong>Authors:</strong> Ziliang Li, Mingchao Cai, Jingzhi Li, Qiang Liu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> We propose three semi-decoupled algorithms for efficiently solving a four-field thermo-poroelastic model. The first two algorithms adopt a sequential strategy: at the initial time step, all variables are computed simultaneously using a monolithic solver; thereafter, the system is split into a mixed linear elasticity subproblem and a coupled pressure-temperature reaction-diffusion subproblem. The two variants differ in the order in which these subproblems are solved. To further improve computational efficiency, we introduce a parallel semi-decoupled algorithm. In this approach, the four-field system is solved monolithically only at the first time step, and the two subproblems are then solved in parallel at subsequent time levels. All three algorithms are free from stabilization techniques and do not require iterative procedures at each time step. Rigorous analysis confirms their unconditional stability, optimal convergence rates, and robustness under a wide range of physical parameter settings. These theoretical results are further validated by numerical experiments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13108v1" target="_blank">A simple analysis of a quantum-inspired algorithm for solving low-rank linear systems</a></h3>
                    <p><strong>Authors:</strong> Tyler Chen, Junhyung Lyle Kim, Archan Ray, Shouvanik Chakrabarti, Dylan Herman, Niraj Kumar</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.DS, quant-ph</p>
                    <p><strong>Summary:</strong> We describe and analyze a simple algorithm for sampling from the solution $\mathbf{x}^* := \mathbf{A}^+\mathbf{b}$ to a linear system $\mathbf{A}\mathbf{x} = \mathbf{b}$. We assume access to a sampler which allows us to draw indices proportional to the squared row/column-norms of $\mathbf{A}$. Our algorithm produces a compressed representation of some vector $\mathbf{x}$ for which $\|\mathbf{x}^* - \mathbf{x}\|  \varepsilon \|\mathbf{x}^* \|$ in $\widetilde{O}(\kappa_{\mathsf{F}}^4 \kappa^2 / \varepsilon^2)$ time, where $\kappa_{\mathsf{F}} := \|\mathbf{A}\|_{\mathsf{F}}\|\mathbf{A}^{+}\|$ and $\kappa := \|\mathbf{A}\|\|\mathbf{A}^{+}\|$. The representation of $\mathbf{x}$ allows us to query entries of $\mathbf{x}$ in $\widetilde{O}(\kappa_{\mathsf{F}}^2)$ time and sample proportional to the square entries of $\mathbf{x}$ in $\widetilde{O}(\kappa_{\mathsf{F}}^4 \kappa^6)$ time, assuming access to a sampler which allows us to draw indices proportional to the squared entries of any given row of $\mathbf{A}$. Our analysis, which is elementary, non-asymptotic, and fully self-contained, simplifies and clarifies several past analyses from literature including [Gily\en, Song, and Tang; 2022, 2023] and [Shao and Montanaro; 2022].</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13107v1" target="_blank">All for law and law for all: Adaptive RAG Pipeline for Legal Research</a></h3>
                    <p><strong>Authors:</strong> Figarri Keisha, Prince Singh, Pallavi, Dion Fernandes, Aravindh Manivannan, Ilham Wicaksono, Faisal Ahmad</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR, F.2.2, H.3.3, I.2.7</p>
                    <p><strong>Summary:</strong> Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding large language model outputs in cited sources, a capability that is especially critical in the legal domain. We present an end-to-end RAG pipeline that revisits and extends the LegalBenchRAG baseline with three targeted enhancements: (i) a context-aware query translator that disentangles document references from natural-language questions and adapts retrieval depth and response style based on expertise and specificity, (ii) open-source retrieval strategies using SBERT and GTE embeddings that achieve substantial performance gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for $K4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to assess semantic alignment and faithfulness across models and prompt designs. Our results show that carefully designed open-source pipelines can rival or outperform proprietary approaches in retrieval quality, while a custom legal-grounded prompt consistently produces more faithful and contextually relevant answers than baseline prompting. Taken together, these contributions demonstrate the potential of task-aware, component-level tuning to deliver legally grounded, reproducible, and cost-effective RAG systems for legal research assistance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13104v1" target="_blank">Precise Action-to-Video Generation Through Visual Action Prompts</a></h3>
                    <p><strong>Authors:</strong> Yuang Wang, Chao Wen, Haoyu Guo, Sida Peng, Minghan Qin, Hujun Bao, Xiaowei Zhou, Ruizhen Hu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> We present visual action prompts, a unified action representation for action-to-video generation of complex high-DoF interactions while maintaining transferable visual dynamics across domains. Action-driven video generation faces a precision-generality trade-off: existing methods using text, primitive actions, or coarse masks offer generality but lack precision, while agent-centric action signals provide precision at the cost of cross-domain transferability. To balance action precision and dynamic transferability, we propose to render actions into precise visual prompts as domain-agnostic representations that preserve both geometric precision and cross-domain adaptability for complex actions; specifically, we choose visual skeletons for their generality and accessibility. We propose robust pipelines to construct skeletons from two interaction-rich data sources - human-object interactions (HOI) and dexterous robotic manipulation - enabling cross-domain training of action-driven generative models. By integrating visual skeletons into pretrained video generation models via lightweight fine-tuning, we enable precise action control of complex interaction while preserving the learning of cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the effectiveness of our proposed approach. Project page: https://zju3dv.github.io/VAP/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13103v1" target="_blank">Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy</a></h3>
                    <p><strong>Authors:</strong> Tianyi Zhang, Haonan Duan, Haoran Hao, Yu Qiao, Jifeng Dai, Zhi Hou</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Vision-Language-Action (VLA) models frequently encounter challenges in generalizing to real-world environments due to inherent discrepancies between observation and action spaces. Although training data are collected from diverse camera perspectives, the models typically predict end-effector poses within the robot base coordinate frame, resulting in spatial inconsistencies. To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA) framework, which grounds action predictions directly in the camera observation space. Leveraging the cameras extrinsic calibration matrix, OC-VLA transforms end-effector poses from the robot base coordinate system into the camera coordinate system, thereby unifying prediction targets across heterogeneous viewpoints. This lightweight, plug-and-play strategy ensures robust alignment between perception and action, substantially improving model resilience to camera viewpoint variations. The proposed approach is readily compatible with existing VLA architectures, requiring no substantial modifications. Comprehensive evaluations on both simulated and real-world robotic manipulation tasks demonstrate that OC-VLA accelerates convergence, enhances task success rates, and improves cross-view generalization. The code will be publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13101v1" target="_blank">Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants</a></h3>
                    <p><strong>Authors:</strong> Miftahul Huda, Arsyiah Azahra, Putri Maulida Chairani, Dimas Rizky Ramadhani, Nabila Azhari, Ade Lailani</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Coastal pollution is a pressing global environmental issue, necessitating scalable and automated solutions for monitoring and management. This study investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a state-of-the-art, end-to-end object detection model, for the automated detection and counting of beach litter. A rigorous comparative analysis is conducted between two model variants, RT-DETR-Large (RT-DETR-L) and RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of coastal debris. The evaluation reveals that the RT-DETR-X model achieves marginally superior accuracy, with a mean Average Precision at 50\% IoU (mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L models 0.810 and 0.606, respectively. However, this minor performance gain is realized at a significant computational cost; the RT-DETR-L model demonstrates a substantially faster inference time of 20.1 ms versus 34.5 ms for the RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more practical and efficient solution for real-time, in-field deployment due to its superior balance of processing speed and detection accuracy. This research provides valuable insights into the application of advanced Transformer-based detectors for environmental conservation, highlighting the critical trade-offs between model complexity and operational viability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13100v1" target="_blank">A Perfectly Truthful Calibration Measure</a></h3>
                    <p><strong>Authors:</strong> Jason Hartline, Lunjia Hu, Yifan Wu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.DS, stat.ML</p>
                    <p><strong>Summary:</strong> Calibration requires that predictions are conditionally unbiased and, therefore, reliably interpretable as probabilities. Calibration measures quantify how far a predictor is from perfect calibration. As introduced by Haghtalab et al. (2024), a calibration measure is truthful if it is minimized in expectation when a predictor outputs the ground-truth probabilities. Although predicting the true probabilities guarantees perfect calibration, in reality, when calibration is evaluated on a finite sample, predicting the truth is not guaranteed to minimize any known calibration measure. All known calibration measures incentivize predictors to lie in order to appear more calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et al. (2024) and Qiao and Zhao (2025) to construct approximately truthful calibration measures in the sequential prediction setting, but no perfectly truthful calibration measure was known to exist even in the more basic batch setting. We design a perfectly truthful calibration measure in the batch setting: averaged two-bin calibration error (ATB). In addition to being truthful, ATB is sound, complete, continuous, and quadratically related to two existing calibration measures: the smooth calibration error (smCal) and the (lower) distance to calibration (distCal). The simplicity in our definition of ATB makes it efficient and straightforward to compute. ATB allows faster estimation algorithms with significantly easier implementations than smCal and distCal, achieving improved running time and simplicity for the calibration testing problem studied by Hu et al. (2024). We also introduce a general recipe for constructing truthful measures, which proves the truthfulness of ATB as a special case and allows us to construct other truthful calibration measures such as quantile-binned l_2-ECE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13098v1" target="_blank">Noise signatures of a charged Sachdev-Ye-Kitaev dot in mesoscopic transport</a></h3>
                    <p><strong>Authors:</strong> Andrei I. Pavlov, Mikhail N. Kiselev</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> We investigate quantum noise in a mesoscopic quantum dot serving as a realization of the charged Sachdev-Ye-Kitaev (SYK) model weakly coupled to a fermionic lead via a tunnel contact. We find noise signatures under voltage and temperature biases that can serve as clear markers of the SYK physics in experiments with related setups. We develop a linear response theory that treats all types of noise on the same footing and generalizes a concept of transport coefficients for charge and heat currents, as well as relations between them, to equilibrium noise power. Within this theory, we find characteristic scaling of the noise coefficients with temperature in all regimes that can be relevant for experimental realizations of the SYK dots, find a set of universal constants, with their values being unique to the SYK physics, that connect these coefficients, and characterize noise manifestations of the Coulomb blockade. Beyond SYK systems, these results may serve as a general framework for identification of non-Fermi-liquid signatures in mesoscopic transport and provide additional observables for experiments on thermoelectric phenomena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13097v1" target="_blank">Denoising diffusion models for inverse design of inflatable structures with programmable deformations</a></h3>
                    <p><strong>Authors:</strong> Sara Karimi, Nikolaos N. Vlassis</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CE, cs.LG</p>
                    <p><strong>Summary:</strong> Programmable structures are systems whose undeformed geometries and material property distributions are deliberately designed to achieve prescribed deformed configurations under specific loading conditions. Inflatable structures are a prominent example, using internal pressurization to realize large, nonlinear deformations in applications ranging from soft robotics and deployable aerospace systems to biomedical devices and adaptive architecture. We present a generative design framework based on denoising diffusion probabilistic models (DDPMs) for the inverse design of elastic structures undergoing large, nonlinear deformations under pressure-driven actuation. The method formulates the inverse design as a conditional generation task, using geometric descriptors of target deformed states as inputs and outputting image-based representations of the undeformed configuration. Representing these configurations as simple images is achieved by establishing a pre- and postprocessing pipeline that involves a fixed image processing, simulation setup, and descriptor extraction methods. Numerical experiments with scalar and higher-dimensional descriptors show that the framework can quickly produce diverse undeformed configurations that achieve the desired deformations when inflated, enabling parallel exploration of viable design candidates while accommodating complex constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13094v1" target="_blank">Sheffer Polynomials and the s-ordering of Exponential Boson Operators</a></h3>
                    <p><strong>Authors:</strong> Robert S. Maier</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> quant-ph, math-ph, math.CO, math.MP, 81S30 (Primary) 81S05, 11B73</p>
                    <p><strong>Summary:</strong> The s-ordered form of any product of single-mode boson creation and annihilation operators, containing only a single annihilator, is computed explicitly. The s-ordering concept originated in quantum optics, and subsumes normal, symmetric (Weyl), and anti-normal ordering for any two operators satisfying a canonical commutation relation. Because the s-ordering map can be viewed as producing a function of a complex variable, its inverse is a quantization map that takes such classical functions to quantum operators. The explicit s-ordered expressions are derived with the aid of a parametric family of Sheffer polynomial sequences (or equivalently an exponential Riordan array of polynomial coefficients), called the Hsu-Shiue family. To yield orderings interpolating between normal and anti-normal, this family is extended in an intricate way.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13091v1" target="_blank">DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation</a></h3>
                    <p><strong>Authors:</strong> Zihua Liu, Yizhou Li, Songyan Zhang, Masatoshi Okutomi</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> While supervised stereo matching and monocular depth estimation have advanced significantly with learning-based algorithms, self-supervised methods using stereo images as supervision signals have received relatively less focus and require further investigation. A primary challenge arises from ambiguity introduced during photometric reconstruction, particularly due to missing corresponding pixels in ill-posed regions of the target view, such as occlusions and out-of-frame areas. To address this and establish explicit photometric correspondences, we propose DMS, a model-agnostic approach that utilizes geometric priors from diffusion models to synthesize novel views along the epipolar direction, guided by directional prompts. Specifically, we finetune a Stable Diffusion model to simulate perspectives at key positions: left-left view shifted from the left camera, right-right view shifted from the right camera, along with an additional novel view between the left and right cameras. These synthesized views supplement occluded pixels, enabling explicit photometric reconstruction. Our proposed DMS is a cost-free, plug-and-play method that seamlessly enhances self-supervised stereo matching and monocular depth estimation, and relies solely on unlabeled stereo image pairs for both training and synthesizing. Extensive experiments demonstrate the effectiveness of our approach, with up to 35% outlier reduction and state-of-the-art performance across multiple benchmark datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13090v1" target="_blank">Exploiting Convexity of Neural Networks in Dynamic Operating Envelope Optimization for Distributed Energy Resources</a></h3>
                    <p><strong>Authors:</strong> Hongyi Li, Liming Liu, Yunyi Li, Zhaoyu Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> The increasing penetration of distributed energy resources (DERs) brings opportunities and challenges to the operation of distribution systems. To ensure network integrity, dynamic operating envelopes (DOEs) are issued by utilities to DERs as their time-varying export/import power limits. Due to the non-convex nature of power flow equations, the optimization of DOEs faces a dilemma of solution accuracy and computation efficiency. To bridge this gap, in this paper, we facilitate DOE optimization by exploiting the convexity of input convex neural networks (ICNNs). A DOE optimization model is first presented, comprehensively considering multiple operational constraints. We propose a constraint embedding method that allows us to replace the non-convex power flow constraints with trained ICNN models and convexify the problem. To further speed up DOE optimization, we propose a linear relaxation of the ICNN-based DOE optimization problem, for which the tightness is theoretically proven. The effectiveness of the proposed method is validated with numerical case studies. Results show that the proposed ICNN-based method outperforms other benchmark methods in optimizing DOEs in terms of both solution quality and solution time.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13087v1" target="_blank">Compositional Verification of Almost-Sure BÃ¼chi Objectives in MDPs</a></h3>
                    <p><strong>Authors:</strong> Marck van der Vegt, Kazuki Watanabe, Ichiro Hasuo, Sebastian Junges</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LO</p>
                    <p><strong>Summary:</strong> This paper studies the verification of almost-sure B\uchi objectives in MDPs with a known, compositional structure based on string diagrams. In particular, we ask whether there is a strategy that ensures that a B\uchi objective is almost-surely satisfied. We first show that proper exit sets -- the sets of exits that can be reached within a component without losing locally -- together with the reachability of a B\uchi state are a sufficient and necessary statistic for the compositional verification of almost-sure B\uchi objectives. The number of proper exit sets may grow exponentially in the number of exits. We define two algorithms: (1) A straightforward bottom-up algorithm that computes this statistic in a recursive manner to obtain the verification result of the entire string diagram and (2) a polynomial-time iterative algorithm which avoids computing all proper exit sets by performing iterative strategy refinement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13086v1" target="_blank">Checkmate: interpretable and explainable RSVQA is the endgame</a></h3>
                    <p><strong>Authors:</strong> Lucrezia Tosato, Christel Tartini Chappuis, Syrielle Montariol, Flora Weissgerber, Sylvain Lobry, Devis Tuia</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Remote Sensing Visual Question Answering (RSVQA) presents unique challenges in ensuring that model decisions are both understandable and grounded in visual content. Current models often suffer from a lack of interpretability and explainability, as well as from biases in dataset distributions that lead to shortcut learning. In this work, we tackle these issues by introducing a novel RSVQA dataset, Chessboard, designed to minimize biases through 3123253 questions and a balanced answer distribution. Each answer is linked to one or more cells within the image, enabling fine-grained visual reasoning. Building on this dataset, we develop an explainable and interpretable model called Checkmate that identifies the image cells most relevant to its decisions. Through extensive experiments across multiple model architectures, we show that our approach improves transparency and supports more trustworthy decision-making in RSVQA systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13084v1" target="_blank">Team Formation and Applications</a></h3>
                    <p><strong>Authors:</strong> Yuval Emek, Shay Kutten, Ido Rafael, Gadi Taubenfeld</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> A novel long-lived distributed problem, called Team Formation (TF), is introduced together with a message- and time-efficient randomized algorithm. The problem is defined over the asynchronous model with a complete communication graph, using bounded size messages, where a certain fraction of the nodes may experience a generalized, strictly stronger, version of initial failures. The goal of a TF algorithm is to assemble tokens injected by the environment, in a distributed manner, into teams of size $\sigma$, where $\sigma$ is a parameter of the problem. The usefulness of TF is demonstrated by using it to derive efficient algorithms for many distributed problems. Specifically, we show that various (one-shot as well as long-lived) distributed problems reduce to TF. This includes well-known (and extensively studied) distributed problems such as several versions of leader election and threshold detection. For example, we are the first to break the linear message complexity bound for asynchronous implicit leader election. We also improve the time complexity of message-optimal algorithms for asynchronous explicit leader election. Other distributed problems that reduce to TF are new ones, including matching players in online gaming platforms, a generalization of gathering, constructing a perfect matching in an induced subgraph of the complete graph, quorum sensing in message-passing networks, and more. To complement our positive contribution, we establish a tight lower bound on the message complexity of TF algorithms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13083v1" target="_blank">Congested Clique Counting for Local Gibbs Distributions</a></h3>
                    <p><strong>Authors:</strong> Joshua Z. Sobel</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.DC, cs.DS</p>
                    <p><strong>Summary:</strong> There are well established reductions between combinatorial sampling and counting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very recent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv 2024), we demonstrate the first approximate counting algorithm in the CongestedClique for a wide range of problems. Most interestingly, we present an algorithm for approximating the number of $q$-colorings of a graph within $\epsilon$-multiplicative error, when $q\alpha\Delta$ for any constant $\alpha2$, in $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds. More generally, we achieve a runtime of $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds for approximating the partition function of Gibbs distributions defined over graphs when simple locality and fast mixing conditions hold. Gibbs distributions are widely used in fields such as machine learning and statistical physics. We obtain our result by providing an algorithm to draw $n$ random samples from a distributed Markov chain in parallel, using similar ideas to triangle counting (Dolev, Lenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel, Kaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems, this result may be interesting for other applications requiring a large number of samples. In the special case of estimating the partition function of the hardcore model, also known as counting weighted independent sets, we can do even better and achieve an $\Tilde{O}\big(\frac{1}{\epsilon^2}\big)$ round algorithm, when the fugacity $\lambda \leq \frac{\alpha}{\Delta-1}$, where $\alpha$ is an arbitrary constant less than $1$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13080v1" target="_blank">Molecular Hydrogen in High-redshift Damped Lyman-Î± Absorbers</a></h3>
                    <p><strong>Authors:</strong> Alon Gurman, Amiel Sternberg, Shmuel Bialy, Rachel K. Cochrane, Jonathan Stern</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Simulations predict that circumgalactic hydrogen gas surrounding massive ($M_{\rm{halo}}^{z=1}=10^{12}-10^{13}\ M_{\odot}$) galaxies at $z\sim4$ may be predominantly neutral, and could produce damped Ly$\alpha$ absorbers (DLAs) along sight-lines to background quasars \citep{Stern2021}. A circumgalactic medium (CGM) origin for DLAs naturally explains high redshift HI absorption-selected galaxy detections at physical separations much greater than the likely extents of the galaxy disks \citep{Neeleman2017, Neeleman2019}. The observed $z\sim 4$ DLA HI column densities are large and comparable to interstellar (ISM) gas columns at which substantial molecular hydrogen (H$_2$) abundances occur. We therefore investigate the possible molecular content of high-redshift CGM gas, and its potential detectability via (rest-frame) far-ultraviolet (UV) absorption line studies. For this purpose we develop an analytic sub-grid model for HI-to-H$_2$ transitions and incorporate the model with zoom-in FIRE-2 simulations of evolving high-$z$ galaxies. We include dust absorption and scattering computations for the transfer of photodissociating Lyman-Werner (LW) band radiation. We find that the typical extents of detectable H$_2$ sightlines are $\approx 0.1\, R_{\rm vir}$, independent of redshift from $z=2.5$ to 5. We argue that a CGM origin for DLAs naturally explains the low detection rates of H$_2$ in DLA observations, as the low CGM densities and relatively strong far-UV fields lead to molecular fractions much lower than observed in the ISM at comparable HI columns.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13079v1" target="_blank">DocHPLT: A Massively Multilingual Document-Level Translation Dataset</a></h3>
                    <p><strong>Authors:</strong> DayyÃ¡n OBrien, Bhavitvya Malik, Ona de Gibert, Pinzhen Chen, Barry Haddow, JÃ¶rg Tiedemann</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Existing document-level machine translation resources are only available for a handful of languages, mostly high-resourced ones. To facilitate the training and evaluation of document-level translation and, more broadly, long-context modeling for global communities, we create DocHPLT, the largest publicly available document-level translation dataset to date. It contains 124 million aligned document pairs across 50 languages paired with English, comprising 4.26 billion sentences, with further possibility to provide 2500 bonus pairs not involving English. Unlike previous reconstruction-based approaches that piece together documents from sentence-level data, we modify an existing web extraction pipeline to preserve complete document integrity from the source, retaining all content including unaligned portions. After our preliminary experiments identify the optimal training context strategy for document-level translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially outperform off-the-shelf instruction-tuned baselines, with particularly dramatic improvements for under-resourced languages. We open-source the dataset under a permissive license, providing essential infrastructure for advancing multilingual document-level translation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13078v1" target="_blank">ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset</a></h3>
                    <p><strong>Authors:</strong> Qingwen Zeng, Juan E. Tapia, Izan Garcia, Juan M. Espin, Christoph Busch</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Nowadays, the development of a Presentation Attack Detection (PAD) system for ID cards presents a challenge due to the lack of images available to train a robust PAD system and the increase in diversity of possible attack instrument species. Today, most algorithms focus on generating attack samples and do not take into account the limited number of bona fide images. This work is one of the first to propose a method for mimicking bona fide images by generating synthetic versions of them using Stable Diffusion, which may help improve the generalisation capabilities of the detector. Furthermore, the new images generated are evaluated in a system trained from scratch and in a commercial solution. The PAD system yields an interesting result, as it identifies our images as bona fide, which has a positive impact on detection performance and data restrictions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13071v1" target="_blank">Surrogate-based Bayesian calibration methods for climate models: a comparison of traditional and non-traditional approaches</a></h3>
                    <p><strong>Authors:</strong> Maike F. Holthuijzen, Atlanta Chakraborty, Elizabeth Krath, Tommie Catanach</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> stat.ME, 62-08, 62K05, 62P99</p>
                    <p><strong>Summary:</strong> Parameter calibration is crucial for reducing uncertainty and improving simulation accuracy in physics-based models, yet computational constraints pose significant challenges. Bayesian calibration methods offer a principled framework for combining prior knowledge with data while rigorously quantifying uncertainty. In this work, we compare four emulator-based Bayesian calibration methods: Calibrate-Emulate-Sample (CES), History Matching (HM), Bayesian Optimal Experimental Design (BOED), and a novel Goal-Oriented BOED (GBOED) approach, using the Lorenz 96 multiscale system as a testbed. Our GBOED formulation explicitly targets calibration-relevant quantities and leverages information-theoretic criteria for data selection. We assess each method in terms of calibration accuracy, uncertainty quantification, computational cost, and convergence behavior. We evaluate each methods performance in balancing computational cost, implementation complexity, and uncertainty quantification (UQ), with additional insights into convergence behavior as model evaluations increase. We find CES offers excellent performance but at high computational expense, while GBOED achieves comparable accuracy using fewer model evaluations. Standard BOED underperforms with respect to calibration accuracy, and HM shows moderate effectiveness but can be useful as a precursor. Our results highlight trade-offs among Bayesian strategies and demonstrate the promise of goal-oriented design in calibration workflows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13070v1" target="_blank">Reinforced Context Order Recovery for Adaptive Reasoning and Planning</a></h3>
                    <p><strong>Authors:</strong> Long Ma, Fangwei Zhong, Yizhou Wang</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Modern causal language models, followed by rapid developments in discrete diffusion models, can now produce a wide variety of interesting and useful content. However, these families of models are predominantly trained to output tokens with a fixed (left-to-right) or random order, which may deviate from the logical order in which tokens are generated originally. In this paper, we observe that current causal and diffusion models encounter difficulties in problems that require adaptive token generation orders to solve tractably, which we characterize with the $\mathcal{V}$-information framework. Motivated by this, we propose Reinforced Context Order Recovery (ReCOR), a reinforcement-learning-based framework to extract adaptive, data-dependent token generation orders from text data without annotations. Self-supervised by token prediction statistics, ReCOR estimates the hardness of predicting every unfilled token and adaptively selects the next token during both training and inference. Experiments on challenging reasoning and planning datasets demonstrate the superior performance of ReCOR compared with baselines, sometimes outperforming oracle models supervised with the ground-truth order.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13069v1" target="_blank">Primary hairs may create echoes</a></h3>
                    <p><strong>Authors:</strong> R. A. Konoplya, A. Zhidenko</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> In most scenarios studied so far, the appearance of echoes in the ringdown signal requires modifications external to the black hole itself, such as the presence of matter in the near-horizon region, quantum field clouds, or exotic compact objects like wormholes that effectively introduce additional peaks in the effective potential. In this work we show that echoes can naturally arise in a different setting: black holes endowed with primary Proca-Gauss-Bonnet hair. We demonstrate that the primary hair modifies the effective potential in such a way that a second peak is formed, giving rise to late-time echoes without invoking any external environment or exotic horizon-scale physics. Using both the higher-order WKB method with Pad\e resummation and time-domain integration, we compute the quasinormal spectrum for scalar and Dirac test fields and show the appearance of these echoes. Our results highlight a novel mechanism by which primary hairs alone can leave observable imprints on the ringdown signal of black holes in modified gravity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13068v1" target="_blank">Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation</a></h3>
                    <p><strong>Authors:</strong> Tanjim Islam Riju, Shuchismita Anwar, Saman Sarker Joy, Farig Sadeque, Swakkhar Shatabda</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> We propose a two-stage multimodal framework that enhances disease classification and region-aware radiology report generation from chest X-rays, leveraging the MIMIC-Eye dataset. In the first stage, we introduce a gaze-guided contrastive learning architecture for disease classification. It integrates visual features, clinical labels, bounding boxes, and radiologist eye-tracking signals and is equipped with a novel multi-term gaze-attention loss combining MSE, KL divergence, correlation, and center-of-mass alignment. Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC from 0.821 to 0.849 (+3.41%), while also improving precision and recall, highlighting the effectiveness of gaze-informed attention supervision. In the second stage, we present a modular report generation pipeline that extracts confidence-weighted diagnostic keywords, maps them to anatomical regions using a curated dictionary constructed from domain-specific priors, and generates region-aligned sentences via structured prompts. This pipeline improves report quality as measured by clinical keyword recall and ROUGE overlap. Our results demonstrate that integrating gaze data improves both classification performance and the interpretability of generated medical reports.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13067v1" target="_blank">Low-complexity Leakage Minimization Beamforming for Large-scale Multi-user Cell-Free Massive MIMO</a></h3>
                    <p><strong>Authors:</strong> IvÃ¡n Alexander Morales Sandoval, Getuar Rexhepi, Kengo Ando, Giuseppe Thadeu Freitas de Abreu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> We propose a low-complexity beamforming (BF) design for information leakage minimization in multi-user (MU) cell-free massive multiple-input multiple-output (CF-mMIMO) systems. Our approach leverages fractional programming (FP) to reformulate the secrecy rate maximization problem into a tractable difference-of-convex form. To efficiently solve the resulting non-convex problem, we employ the Concave-Convex Procedure (CCP), enabling fast convergence to a local optimum. Simulation results demonstrate that the proposed scheme achieves secrecy rates comparable to state-of-the-art (SotA) methods, while significantly reducing computational complexity and improving convergence speed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13065v1" target="_blank">Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping</a></h3>
                    <p><strong>Authors:</strong> Siddharth Khandelwal, Sridhar Kamath, Arjun Jain</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Human shape editing enables controllable transformation of a persons body shape, such as thin, muscular, or overweight, while preserving pose, identity, clothing, and background. Unlike human pose editing, which has advanced rapidly, shape editing remains relatively underexplored. Current approaches typically rely on 3D morphable models or image warping, often introducing unrealistic body proportions, texture distortions, and background inconsistencies due to alignment errors and deformations. A key limitation is the lack of large-scale, publicly available datasets for training and evaluating body shape manipulation methods. In this work, we introduce the first large-scale dataset of 18,573 images across 1523 subjects, specifically designed for controlled human shape editing. It features diverse variations in body shape, including fat, muscular and thin, captured under consistent identity, clothing, and background conditions. Using this dataset, we propose Odo, an end-to-end diffusion-based method that enables realistic and intuitive body reshaping guided by simple semantic attributes. Our approach combines a frozen UNet that preserves fine-grained appearance and background details from the input image with a ControlNet that guides shape transformation using target SMPL depth maps. Extensive experiments demonstrate that our method outperforms prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm, significantly lower than the 13.6mm observed in baseline methods, while producing realistic results that accurately match the desired target shapes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13063v1" target="_blank">Generalized Symmetries From Fusion Actions</a></h3>
                    <p><strong>Authors:</strong> Chongying Dong, Siu-Hung Ng, Li Ren, Feng Xu</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> math.QA, cond-mat.str-el, hep-th, math.RT</p>
                    <p><strong>Summary:</strong> Let $A$ be a condensable algebra in a modular tensor category $\EuScript{C}$. We define an action of the fusion category $\EuScript{C}_A$ of $A$-modules in $\EuScript{C}$ on the morphism space $\mbox{Hom}_{\EuScript{C}}(x,A)$ for any $x$ in $\EuScript{C}$, whose characters are generalized Frobenius-Schur indicators. This fusion action can be considered on $A$, and we prove a categorical generalization of Schur-Weyl duality for this action. For any fusion subcategory $\EuScript{B}$ of $\EuScript{C}_A$ containing all the local $A$-modules, we prove the invariant subobject $B=A^\EuScript{B}$ is a condensable subalgebra of $A$. The assignment of $\EuScript{B}$ to $A^\EuScript{B}$ defines a Galois correspondence between this kind of fusion subcategories of $\EuScript{C}_A$ and the condensable subalgebras of $A$. In the context of VOA, we prove for any nice VOAs $U \subset A$, $U=A^{\EuScript{C}_A}$ where $\EuScript{C}=\EuScript{M}_U$ is the $U$-module category. In particular, if $U = A^G$ for some finite automorphism group $G$ of $A,$ the fusion action of $\EuScript{C}_A$ on $A$ is equivalent to the $G$-action on $A.$</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13061v1" target="_blank">Including gravity in equilibrium thermodynamics</a></h3>
                    <p><strong>Authors:</strong> Eirini Sourtzinou, Charis Anastopoulos</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> gr-qc, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> This paper is part of a bottom-up approach to gravitational thermodynamics that is guided by the axiomatic frameworks of equilibrium thermodynamics. We identify a novel form of the microcanonical distribution for systems in background gravitational fields that respects the kinetic theory and the thermodynamic symmetries. Thermodynamic consistency dictates the treatment of the gravitational field as a thermodynamic variable. We introduce the thermodynamic conjugate to the gravitational field, the gravitational pull, an additive variable that is a structural element of our microcanonical distribution. We demonstrate the validity of our results to inhomogenous background fields, a class of self-gravitating systems, relativistic gases in Rindler spacetime, and quantum gases.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13060v1" target="_blank">Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database</a></h3>
                    <p><strong>Authors:</strong> John Alderete, Macarious Kin Fung Hui, Aanchan Mohan</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The Simon Fraser University Speech Error Database (SFUSED) is a public data collection developed for linguistic and psycholinguistic research. Here we demonstrate how its design and annotations can be used to test and evaluate speech recognition models. The database comprises systematically annotated speech errors from spontaneous English speech, with each error tagged for intended and actual error productions. The annotation schema incorporates multiple classificatory dimensions that are of some value to model assessment, including linguistic hierarchical level, contextual sensitivity, degraded words, word corrections, and both word-level and syllable-level error positioning. To assess the value of these classificatory variables, we evaluated the transcription accuracy of WhisperX across 5,300 documented word and phonological errors. This analysis demonstrates the atabases effectiveness as a diagnostic tool for ASR system performance.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/SIU66497.2025.11112220" target="_blank">DoÄŸal Dil Ä°ÅŸlemede Tokenizasyon StandartlarÄ± ve Ã–lÃ§Ã¼mÃ¼: TÃ¼rkÃ§e Ãœzerinden BÃ¼yÃ¼k Dil Modellerinin KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi</a></h3>
                    <p><strong>Authors:</strong> M. Ali Bayram, Ali Arda Fincan, Ahmet Semih GÃ¼mÃ¼ÅŸ, Sercan KarakaÅŸ, Banu Diri, SavaÅŸ YÄ±ldÄ±rÄ±m</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.CL, 68T50, I.2.7; I.2.6</p>
                    <p><strong>Summary:</strong> Tokenization is a fundamental preprocessing step in Natural Language Processing (NLP), significantly impacting the capability of large language models (LLMs) to capture linguistic and semantic nuances. This study introduces a novel evaluation framework addressing tokenization challenges specific to morphologically-rich and low-resource languages such as Turkish. Utilizing the Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from the Turkish education system, we assessed tokenizers based on vocabulary size, token count, processing time, language-specific token percentages (\%TR), and token purity (\%Pure). These newly proposed metrics measure how effectively tokenizers preserve linguistic structures. Our analysis reveals that language-specific token percentages exhibit a stronger correlation with downstream performance (e.g., MMLU scores) than token purity. Furthermore, increasing model parameters alone does not necessarily enhance linguistic performance, underscoring the importance of tailored, language-specific tokenization methods. The proposed framework establishes robust and practical tokenization standards for morphologically complex languages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13057v1" target="_blank">Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models</a></h3>
                    <p><strong>Authors:</strong> Adolfo GonzÃ¡lez, VÃ­ctor Parada</p>
                    <p><strong>Published:</strong> 8/18/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.PF, 62M10, 90C59, 68T05, I.2.6; I.5.1; I.5.2; I.5.4; G.1.6</p>
                    <p><strong>Summary:</strong> Demand forecasting is essential for strategic planning in competitive environments, enabling resource optimization and improved responsiveness to market dynamics. However, multivariate time series modeling faces challenges due to data complexity, uncertainty, and frequent regime shifts. Traditional evaluation metrics can introduce biases and limit generalization. This work compares two custom evaluation functions: FMAE (Focused Mean Absolute Error), focused on minimizing absolute errors, and HEF (Hierarchical Evaluation Function), designed to weight global metrics and penalize large deviations. Experiments were conducted under different data splits (91:9, 80:20, 70:30) using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative accuracy, robustness, and computational efficiency. Results show that HEF consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE, RMSSE), enhancing model robustness and explanatory power. These findings were confirmed via visualizations and statistical tests. Conversely, FMAE offers advantages in local metrics (MAE, MASE) and execution time, making it suitable for short-term scenarios. The study highlights a methodological trade-off: HEF is ideal for strategic planning, while FMAE is better suited for operational efficiency. A replicable framework is proposed for optimizing predictive models in dynamic environments.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

