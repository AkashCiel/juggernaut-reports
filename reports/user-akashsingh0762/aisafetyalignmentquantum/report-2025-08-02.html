
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-02<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The selected papers on AI safety research highlight emerging trends, breakthroughs, and implications across various domains, emphasizing the pursuit of robust, interpretable, and context-aware AI systems. A key trend is the development of benchmarks and frameworks aimed at enhancing the interpretability and robustness of AI models. For instance, the SUB benchmark evaluates the generalization of Concept Bottleneck Models (CBMs) to distribution shifts, advancing interpretability in tasks like medical diagnostics. Similarly, SimuRA explores simulative reasoning to improve the adaptability and decision-making capabilities of AI agents, addressing the limitations of task-specific AI applications.

Another significant focus is on the integration of AI systems in high-stakes environments, such as medical imaging and autonomous driving, where safety and risk mitigation are critical. Papers like DICOM De-Identification via Hybrid AI and CFDagent demonstrate AIs role in ensuring privacy and performing complex simulations, respectively, while highlighting uncertainty quantification and user-friendly interaction as pivotal components in trustworthy AI deployment. Furthermore, the exploration of AI in social contexts, such as Informing AI Risk Assessment with News Media, underscores the importance of understanding societal impacts and perceptions of AI risks, advocating for a more holistic view in AI governance. Collectively, these works underscore the necessity of developing AI systems that are not only functionally robust but also contextually aware and ethically aligned with societal values.

*Based on 50 research papers*

---

## ai alignment research

The research papers related to AI alignment showcase a diverse range of approaches aimed at addressing challenges in AI transparency, robustness, and interpretabilityâ€”key components of AI alignment. The study on Concept Bottleneck Models (CBMs) highlights the need for models that can maintain robustness in identifying correct concepts even under distribution shifts, proposing the SUB benchmark for rigorous evaluation. This contributes to the broader goal of ensuring AI systems remain aligned with human expectations across varying conditions. Similarly, the work on SimuRA introduces a goal-oriented agent architecture that leverages LLMs for planning tasks, suggesting a move towards more general AI agents that can simulate outcomes and reason effectively like humans, thus improving alignment with complex real-world tasks.

The paper on Rule2Text illustrates efforts to enhance the interpretability of AI systems by translating logical rules in knowledge graphs into natural language explanations, which can aid in understanding and debugging AI decisionsâ€”a crucial aspect of alignment. Additionally, the study on personalized education through the Ranking Alignment Recommendation framework and the development of AI-based frameworks for automated semantic association in AI failure tracking both underscore the importance of aligning AI systems outputs with human values and needs through transparency and personalized adaptation. Collectively, these works reflect a significant trend in AI alignment research towards creating more interpretable, robust, and adaptable systems that align closely with human goals and ethical standards.

*Based on 50 research papers*

---

## quantum computing

In the realm of quantum computing, several key papers highlight the current trends and breakthroughs that are shaping the field. One significant finding is by Ewin Tang and John Wright, who analyze the limitations of quantum speedups in specific computational settings. Their work demonstrates that the quadratic speedups provided by amplitude amplification and estimation are contingent upon the ability to efficiently implement both a unitary operation and its inverse. This insight explains why quantum speedups are more challenging to achieve in fields like quantum learning and metrology, where reversing operations is analogous to reversing time, suggesting that without inverse access, quantum speedups are rare.

Another critical advancement is the exploration of topological order in quantum systems, as seen in the work on non-Abelian topological order by Dian Jing and colleagues. They propose a novel error correction approach that leverages non-Abelian anyons, which can enhance the stability of quantum information beyond what is achievable with Abelian systems. This work underscores the potential for non-Abelian properties to improve quantum error correction and stability, which is crucial for developing robust quantum computing systems. Together, these studies showcase ongoing efforts to understand and overcome the operational challenges in quantum computing, emphasizing the importance of algorithmic efficiency and topological stability in advancing the field.

*Based on 50 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2507.23784v1" target="_blank">SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions</a></h3>
                    <p><strong>Authors:</strong> Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Concept Bottleneck Models (CBMs) and other concept-based interpretable models show great promise for making AI applications more transparent, which is essential in fields like medicine. Despite their success, we demonstrate that CBMs struggle to reliably identify the correct concepts under distribution shifts. To assess the robustness of CBMs to concept variations, we introduce SUB: a fine-grained image and concept benchmark containing 38,400 synthetic images based on the CUB dataset. To create SUB, we select a CUB subset of 33 bird classes and 45 concepts to generate images which substitute a specific concept, such as wing color or belly pattern. We introduce a novel Tied Diffusion Guidance (TDG) method to precisely control generated images, where noise sharing for two parallel denoising processes ensures that both the correct bird class and the correct attribute are generated. This novel benchmark enables rigorous evaluation of CBMs and similar interpretable models, contributing to the development of more robust methods. Our code is available at https://github.com/ExplainableML/sub and the dataset at http://huggingface.co/datasets/Jessica-bader/SUB.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23773v1" target="_blank">SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model</a></h3>
                    <p><strong>Authors:</strong> Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG, cs.RO</p>
                    <p><strong>Summary:</strong> AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \modelname improves the success of flight search from 0\% to 32.2\%. World-model-based planning, in particular, shows consistent advantage of up to 124\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \modelname with pretrained LLMs, available as a research demo for public testing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23772v1" target="_blank">SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Di Li, Jie Feng, Jiahao Chen, Weisheng Dong, Guanbin Li, Yuhui Zheng, Mingtao Feng, Guangming Shi</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D affordance reasoning, the task of associating human instructions with the functional regions of 3D objects, is a critical capability for embodied agents. Current methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited to single-object, single-step interactions, a paradigm that falls short of addressing the long-horizon, multi-object tasks required for complex real-world applications. To bridge this gap, we introduce the novel task of Sequential 3D Gaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale benchmark featuring 1800+ scenes to support research on long-horizon affordance understanding in complex 3DGS environments. We then propose SeqSplatNet, an end-to-end framework that directly maps an instruction to a sequence of 3D affordance masks. SeqSplatNet employs a large language model that autoregressively generates text interleaved with special segmentation tokens, guiding a conditional decoder to produce the corresponding 3D mask. To handle complex scene geometry, we introduce a pre-training strategy, Conditional Geometric Reconstruction, where the model learns to reconstruct complete affordance region masks from known geometric observations, thereby building a robust geometric prior. Furthermore, to resolve semantic ambiguities, we design a feature injection mechanism that lifts rich semantic features from 2D Vision Foundation Models (VFM) and fuses them into the 3D decoder at multiple scales. Extensive experiments demonstrate that our method sets a new state-of-the-art on our challenging benchmark, effectively advancing affordance reasoning from single-step interactions to complex, sequential tasks at the scene level.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23750v1" target="_blank">Deformations of Reproducing Kernel Hilbert Spaces on Homogeneous Varieties</a></h3>
                    <p><strong>Authors:</strong> Yasin Watted</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> math.FA, math.OA</p>
                    <p><strong>Summary:</strong> We study the relationships between a subvariety of the open unit ball in the complex $d$-dimensional space $\mathbb{C}^{d}$, the reproducing kernel Hilbert space (RKHS) obtained by restricting the Drury-Arveson space to the variety, and its multiplier algebra. Davidson, Ramsey, and Shalit showed that given two subvarieties, one is the image of the other under an automorphism of the ball if and only if the RKHSs corresponding to the varieties are isometrically isomorphic as RKHSs, and this holds if and only if their multiplier algebras are isometrically isomorphic as multiplier algebras. We observe that whenever two such RKHSs are close to being isometrically isomorphic, their multiplier algebras are close to being isometrically isomorphic as well. In this case, the underlying varieties are close to being automorphically equivalent. For homogeneous varieties satisfying some additional conditions, we show that if one variety is close to being the image of the other under a unitary, then the RKHSs are close to being isometrically isomorphic as RKHSs. This continues work by Ofek, Pandey and Shalit, who showed that for two finite subsets in the open unit ball $B_{d}$, one set is close to being the image of the other under an automorphism of $B_{d}$, if and only if the RKHSs defined on these sets, are close to being isometrically isomorphic, and that happens if and only if their multiplier algebras are close to being completely isometrically isomorphic.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23743v1" target="_blank">Relative Bias Under Imperfect Identification in Observational Causal Inference</a></h3>
                    <p><strong>Authors:</strong> Melody Huang, Cory McCartan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ME, econ.EM</p>
                    <p><strong>Summary:</strong> To conduct causal inference in observational settings, researchers must rely on certain identifying assumptions. In practice, these assumptions are unlikely to hold exactly. This paper considers the bias of selection-on-observables, instrumental variables, and proximal inference estimates under violations of their identifying assumptions. We develop bias expressions for IV and proximal inference that show how violations of their respective assumptions are amplified by any unmeasured confounding in the outcome variable. We propose a set of sensitivity tools that quantify the sensitivity of different identification strategies, and an augmented bias contour plot visualizes the relationship between these strategies. We argue that the act of choosing an identification strategy implicitly expresses a belief about the degree of violations that must be present in alternative identification strategies. Even when researchers intend to conduct an IV or proximal analysis, a sensitivity analysis comparing different identification strategies can help to better understand the implications of each set of assumptions. Throughout, we compare the different approaches on a re-analysis of the impact of state surveillance on the incidence of protest in Communist Poland.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23740v1" target="_blank">Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs</a></h3>
                    <p><strong>Authors:</strong> Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of-thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use of large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23736v1" target="_blank">DICOM De-Identification via Hybrid AI and Rule-Based Framework for Scalable, Uncertainty-Aware Redaction</a></h3>
                    <p><strong>Authors:</strong> Kyle Naddeo, Nikolas Koutsoubis, Rahul Krish, Ghulam Rasool, Nidhal Bouaynaya, Tony OSullivan, Raj Krish</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Access to medical imaging and associated text data has the potential to drive major advances in healthcare research and patient outcomes. However, the presence of Protected Health Information (PHI) and Personally Identifiable Information (PII) in Digital Imaging and Communications in Medicine (DICOM) files presents a significant barrier to the ethical and secure sharing of imaging datasets. This paper presents a hybrid de-identification framework developed by Impact Business Information Solutions (IBIS) that combines rule-based and AI-driven techniques, and rigorous uncertainty quantification for comprehensive PHI/PII removal from both metadata and pixel data. Our approach begins with a two-tiered rule-based system targeting explicit and inferred metadata elements, further augmented by a large language model (LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of synthetic datasets simulating realistic clinical PHI/PII. For pixel data, we employ an uncertainty-aware Faster R-CNN model to localize embedded text, extract candidate PHI via Optical Character Recognition (OCR), and apply the NER pipeline for final redaction. Crucially, uncertainty quantification provides confidence measures for AI-based detections to enhance automation reliability and enable informed human-in-the-loop verification to manage residual risks. This uncertainty-aware deidentification framework achieves robust performance across benchmark datasets and regulatory standards, including DICOM, HIPAA, and TCIA compliance metrics. By combining scalable automation, uncertainty quantification, and rigorous quality assurance, our solution addresses critical challenges in medical data de-identification and supports the secure, ethical, and trustworthy release of imaging data for research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23735v1" target="_blank">Distributed AI Agents for Cognitive Underwater Robot Autonomy</a></h3>
                    <p><strong>Authors:</strong> Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.MA</p>
                    <p><strong>Summary:</strong> Achieving robust cognitive autonomy in robots navigating complex, unpredictable environments remains a fundamental challenge in robotics. This paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a groundbreaking architecture leveraging distributed Large Language Model AI agents integrated within the Robot Operating System 2 (ROS 2) framework to enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA decentralises cognition into specialised AI agents responsible for multimodal perception, adaptive reasoning, dynamic mission planning, and real-time decision-making. Central innovations include flexible agents dynamically adapting their roles, retrieval-augmented generation utilising vector databases for efficient knowledge management, reinforcement learning-driven behavioural optimisation, and autonomous on-the-fly ROS 2 node generation for runtime functional extensibility. Extensive empirical validation demonstrates UROSAs promising adaptability and reliability through realistic underwater missions in simulation and real-world deployments, showing significant advantages over traditional rule-based architectures in handling unforeseen scenarios, environmental uncertainties, and novel mission objectives. This work not only advances underwater autonomy but also establishes a scalable, safe, and versatile cognitive robotics framework capable of generalising to a diverse array of real-world applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23718v1" target="_blank">Informing AI Risk Assessment with News Media: Analyzing National and Political Variation in the Coverage of AI Risks</a></h3>
                    <p><strong>Authors:</strong> Mowafak Allaham, Kimon Kieslich, Nicholas Diakopoulos</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Risk-based approaches to AI governance often center the technological artifact as the primary focus of risk assessments, overlooking systemic risks that emerge from the complex interaction between AI systems and society. One potential source to incorporate more societal context into these approaches is the news media, as it embeds and reflects complex interactions between AI systems, human stakeholders, and the larger society. News media is influential in terms of which AI risks are emphasized and discussed in the public sphere, and thus which risks are deemed important. Yet, variations in the news media between countries and across different value systems (e.g. political orientations) may differentially shape the prioritization of risks through the medias agenda setting and framing processes. To better understand these variations, this work presents a comparative analysis of a cross-national sample of news media spanning 6 countries (the U.S., the U.K., India, Australia, Israel, and South Africa). Our findings show that AI risks are prioritized differently across nations and shed light on how left vs. right leaning U.S. based outlets not only differ in the prioritization of AI risks in their coverage, but also use politicized language in the reporting of these risks. These findings can inform risk assessors and policy-makers about the nuances they should account for when considering news media as a supplementary source for risk-based governance approaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23701v1" target="_blank">TextQuests: How Good are LLMs at Text-Based Video Games?</a></h3>
                    <p><strong>Authors:</strong> Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agents ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agents capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at https://textquests.ai.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23699v1" target="_blank">Exploring Left-Wing Extremism on the Decentralized Web: An Analysis of Lemmygrad.ml</a></h3>
                    <p><strong>Authors:</strong> Utkucan Balci, Michael Sirivianos, Jeremy Blackburn</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.SI</p>
                    <p><strong>Summary:</strong> This study investigates the presence of left-wing extremism on the Lemmygrad.ml instance of the decentralized social media platform Lemmy, from its launch in 2019 up to a month after the bans of the subreddits r/GenZedong and r/GenZhou. We conduct a temporal analysis on Lemmygrad.mls user activity, with also measuring the degree of highly abusive or hateful content. Furthermore, we explore the content of their posts using a transformer-based topic modeling approach. Our findings reveal a substantial increase in user activity and toxicity levels following the migration of these subreddits to Lemmygrad.ml. We also identify posts that support authoritarian regimes, endorse the Russian invasion of Ukraine, and feature anti-Zionist and antisemitic content. Overall, our findings contribute to a more nuanced understanding of political extremism within decentralized social networks and emphasize the necessity of analyzing both ends of the political spectrum in research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23693v1" target="_blank">CFDagent: A Language-Guided, Zero-Shot Multi-Agent System for Complex Flow Simulation</a></h3>
                    <p><strong>Authors:</strong> Zhaoyue Xu, Long Wang, Chunyu Wang, Yixin Chen, Qingyong Luo, Hua-Dong Yao, Shizhao Wang, Guowei He</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn</p>
                    <p><strong>Summary:</strong> We introduce CFDagent, a zero-shot, multi-agent system that enables fully autonomous computational fluid dynamics (CFD) simulations from natural language prompts. CFDagent integrates three specialized LLM-driven agents: (i) the Preprocessing Agent that generates 3D geometries from textual or visual inputs using a hybrid text-to-3D diffusion model (Point-E) and automatically meshes the geometries; (ii) the Solver Agent that configures and executes an immersed boundary flow solver; and (iii) the Postprocessing Agent that analyzes and visualizes the results, including multimodal renderings. These agents are interactively guided by GPT-4o via conversational prompts, enabling intuitive and user-friendly interaction. We validate CFDagent by reproducing canonical sphere flows at Reynolds numbers of 100 and 300 using three distinct inputs: a simple text prompt (i.e., sphere), an image-based input, and a standard sphere model. The computed drag and lift coefficients from meshes produced by each input approach closely match available data. The proposed system enables synthesization of flow simulations and photorealistic visualizations for complex geometries. Through extensive tests on canonical and realistic scenarios, we demonstrate the robustness, versatility, and practical applicability of CFDagent. By bridging generative AI with high-fidelity simulations, CFDagent significantly lowers barriers to expert-level CFD, unlocking broad opportunities in education, scientific research, and practical engineering applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23685v1" target="_blank">UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration</a></h3>
                    <p><strong>Authors:</strong> Zihan Cheng, Liangtai Zhou, Dian Chen, Ni Tang, Xiaotong Luo, Yanyun Qu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> All-in-One Image Restoration (AiOIR) has emerged as a promising yet challenging research direction. To address its core challenges, we propose a novel unified image restoration framework based on latent diffusion models (LDMs). Our approach structurally integrates low-quality visual priors into the diffusion process, unlocking the powerful generative capacity of diffusion models for diverse degradations. Specifically, we design a Degradation-Aware Feature Fusion (DAFF) module to enable adaptive handling of diverse degradation types. Furthermore, to mitigate detail loss caused by the high compression and iterative sampling of LDMs, we design a Detail-Aware Expert Module (DAEM) in the decoder to enhance texture and fine-structure recovery. Extensive experiments across multi-task and mixed degradation settings demonstrate that our method consistently achieves state-of-the-art performance, highlighting the practical potential of diffusion priors for unified image restoration. Our code will be released.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23682v1" target="_blank">villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models</a></h3>
                    <p><strong>Authors:</strong> Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies that can follow language instructions and generalize to novel scenarios. Recent work has begun to explore the incorporation of latent actions, an abstract representation of visual change between two frames, into VLA pre-training. In this paper, we introduce villa-X, a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent action modeling for learning generalizable robot manipulation policies. Our approach improves both how latent actions are learned and how they are incorporated into VLA pre-training. Together, these contributions enable villa-X to achieve superior performance across simulated environments including SIMPLER and LIBERO, as well as on two real-world robot setups including gripper and dexterous hand manipulation. We believe the ViLLA paradigm holds significant promise, and that our villa-X provides a strong foundation for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23669v1" target="_blank">Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database</a></h3>
                    <p><strong>Authors:</strong> Diego Russo, Gian Marco Orlando, Valerio La Gatta, Vincenzo Moscato</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> Artificial Intelligence (AI) systems are transforming critical sectors such as healthcare, finance, and transportation, enhancing operational efficiency and decision-making processes. However, their deployment in high-stakes domains has exposed vulnerabilities that can result in significant societal harm. To systematically study and mitigate these risk, initiatives like the AI Incident Database (AIID) have emerged, cataloging over 3,000 real-world AI failure reports. Currently, associating a new report with the appropriate AI Incident relies on manual expert intervention, limiting scalability and delaying the identification of emerging failure patterns. To address this limitation, we propose a retrieval-based framework that automates the association of new reports with existing AI Incidents through semantic similarity modeling. We formalize the task as a ranking problem, where each report-comprising a title and a full textual description-is compared to previously documented AI Incidents based on embedding cosine similarity. Benchmarking traditional lexical methods, cross-encoder architectures, and transformer-based sentence embedding models, we find that the latter consistently achieve superior performance. Our analysis further shows that combining titles and descriptions yields substantial improvements in ranking accuracy compared to using titles alone. Moreover, retrieval performance remains stable across variations in description length, highlighting the robustness of the framework. Finally, we find that retrieval performance consistently improves as the training set expands. Our approach provides a scalable and efficient solution for supporting the maintenance of the AIID.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23661v1" target="_blank">Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning</a></h3>
                    <p><strong>Authors:</strong> Salam Thabet Doghmash, Motaz Saad</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL, I.2.7</p>
                    <p><strong>Summary:</strong> Hate speech identification in social media has become an increasingly important issue in recent years. In this research, we address two problems: 1) to detect hate speech in Arabic text, 2) to clean a given text from hate speech. The meaning of cleaning here is replacing each bad word with stars based on the number of letters for each word. Regarding the first problem, we conduct several experiments using deep learning models and transformers to determine the best model in terms of the F1 score. Regarding second problem, we consider it as a machine translation task, where the input is a sentence containing dirty text and the output is the same sentence with masking the dirty text. The presented methods achieve the best model in hate speech detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text cleaning experiment, the best result in the hate speech masking model reached 0.3 in BLEU score with 1-gram, which is a good result compared with the state of the art machine translation systems.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1515/eng-2024-0098" target="_blank">Architectural practice process and artificial intelligence -- an evolving practice</a></h3>
                    <p><strong>Authors:</strong> Mustapha El Moussaoui</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> In an era of exponential technological advancement, artificial intelligence (AI) has emerged as a transformative force in architecture, reshaping traditional design and construction practices. This article explores the multifaceted roles of AI in the architectural process, emphasizing its potential to enhance creativity and efficiency while addressing its limitations in capturing multisensory and experiential dimensions of space. Historically, architectural innovation has paralleled technological progress, from basic tools to advanced computer-aided design systems. However, the integration of AI presents unique challenges, requiring architects to critically evaluate its role in design. A narrative review methodology was adopted, focusing on academic sources selected for their relevance, recency, and credibility. The findings reveal that AI is increasingly integrated across various stages of the architectural process, from early conceptualization and site analysis to generative design and construction detailing. AI tools excel at automating repetitive tasks and generating innovative design solutions, freeing architects to focus on creativity and problem-solving. Additionally, AIs (text- toimage) visual representation strength challenges the ocularcentric approaches in architecture, which should push future architects to address the holistic sensory and experiential qualities of space or the critical thinking inherent to architectural design. While AI offers transformative potential, architects must view it as a collaborative partner rather than a passive tool.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23648v1" target="_blank">Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach</a></h3>
                    <p><strong>Authors:</strong> Louise Guillon, Soheib Biga, Yendoube E. Kantchire, Mouhamadou Lamine Sane, GrÃ©goire Pasquier, Kossi Yakpa, StÃ©phane E. Sossou, Marc Thellier, Laurent Bonnardot, Laurence Lachaud, Renaud Piarroux, Ameyo M. Dorkenoo</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Malaria remains a major global health challenge, particularly in low-resource settings where access to expert microscopy may be limited. Deep learning-based computer-aided diagnosis (CAD) systems have been developed and demonstrate promising performance on thin blood smear images. However, their clinical deployment may be hindered by limited generalization across sites with varying conditions. Yet very few practical solutions have been proposed. In this work, we investigate continual learning (CL) as a strategy to enhance the robustness of malaria CAD models to domain shifts. We frame the problem as a domain-incremental learning scenario, where a YOLO-based object detector must adapt to new acquisition sites while retaining performance on previously seen domains. We evaluate four CL strategies, two rehearsal-based and two regularization-based methods, on real-life conditions thanks to a multi-site clinical dataset of thin blood smear images. Our results suggest that CL, and rehearsal-based methods in particular, can significantly improve performance. These findings highlight the potential of continual learning to support the development of deployable, field-ready CAD tools for malaria.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23633v1" target="_blank">MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying</a></h3>
                    <p><strong>Authors:</strong> Qian Zhao, Zhuo Sun, Bin Guo, Zhiwen Yu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Agent-assisted memory recall is one critical research problem in the field of human-computer interaction. In conventional methods, the agent can retrieve information from its equipped memory module to help the person recall incomplete or vague memories. The limited size of memory module hinders the acquisition of complete memories and impacts the memory recall performance in practice. Memory theories suggest that the persons relevant memory can be proactively activated through some effective cues. Inspired by this, we propose a novel strategy-guided agent-assisted memory recall method, allowing the agent to transform an original query into a cue-rich one via the judiciously designed strategy to help the person recall memories. To this end, there are two key challenges. (1) How to choose the appropriate recall strategy for diverse forgetting scenarios with distinct memory-recall characteristics? (2) How to obtain the high-quality responses leveraging recall strategies, given only abstract and sparsely annotated strategy patterns? To address the challenges, we propose a Recall Router framework. Specifically, we design a 5W Recall Map to classify memory queries into five typical scenarios and define fifteen recall strategy patterns across the corresponding scenarios. We then propose a hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to optimize the selection of strategy and the generation of strategy responses. We construct an instruction tuning dataset and fine-tune multiple open-source large language models (LLMs) to develop MemoCue, an agent that excels in providing memory-inspired responses. Experiments on three representative datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall inspiration. Further human evaluation highlights its advantages in memory-recall applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23611v1" target="_blank">LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora</a></h3>
                    <p><strong>Authors:</strong> Estelle Ruellan, Eric Clay, Nicholas Ascoli</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Infostealers exfiltrate credentials, session cookies, and sensitive data from infected systems. With over 29 million stealer logs reported in 2024, manual analysis and mitigation at scale are virtually unfeasible/unpractical. While most research focuses on proactive malware detection, a significant gap remains in leveraging reactive analysis of stealer logs and their associated artifacts. Specifically, infection artifacts such as screenshots, image captured at the point of compromise, are largely overlooked by the current literature. This paper introduces a novel approach leveraging Large Language Models (LLMs), more specifically gpt-4o-mini, to analyze infection screenshots to extract potential Indicators of Compromise (IoCs), map infection vectors, and track campaigns. Focusing on the Aurora infostealer, we demonstrate how LLMs can process screenshots to identify infection vectors, such as malicious URLs, installer files, and exploited software themes. Our method extracted 337 actionable URLs and 246 relevant files from 1000 screenshots, revealing key malware distribution methods and social engineering tactics. By correlating extracted filenames, URLs, and infection themes, we identified three distinct malware campaigns, demonstrating the potential of LLM-driven analysis for uncovering infection workflows and enhancing threat intelligence. By shifting malware analysis from traditional log-based detection methods to a reactive, artifact-driven approach that leverages infection screenshots, this research presents a scalable method for identifying infection vectors and enabling early intervention.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23608v1" target="_blank">Medical Image De-Identification Benchmark Challenge</a></h3>
                    <p><strong>Authors:</strong> Linmin Pei, Granger Sutton, Michael Rutherford, Ulrike Wagner, Tracy Nolan, Kirk Smith, Phillip Farmer, Peter Gu, Ambar Rana, Kailing Chen, Thomas Ferleman, Brian Park, Ye Wu, Jordan Kojouharov, Gargi Singh, Jon Lemon, Tyler Willis, Milos Vukadinovic, Grant Duffy, Bryan He, David Ouyang, Marco Pereanez, Daniel Samber, Derek A. Smith, Christopher Cannistraci, Zahi Fayad, David S. Mendelson, Michele Bufano, Elmar Kotter, Hamideh Haghiri, Rajesh Baidya, Stefan Dvoretskii, Klaus H. Maier-Hein, Marco Nolden, Christopher Ablett, Silvia Siggillino, Sandeep Kaushik, Hongzhu Jiang, Sihan Xie, Zhiyu Wan, Alex Michie, Simon J Doran, Angeline Aurelia Waly, Felix A. Nathaniel Liang, Humam Arshad Mustagfirin, Michelle Grace Felicia, Kuo Po Chih, Rahul Krish, Ghulam Rasool, Nidhal Bouaynaya, Nikolas Koutsoubis, Kyle Naddeo, Kartik Pandit, Tony OSullivan, Raj Krish, Qinyan Pan, Scott Gustafson, Benjamin Kopchick, Laura Opsahl-Ong, Andrea Olvera-Morales, Jonathan Pinney, Kathryn Johnson, Theresa Do, Juergen Klenk, Maria Diaz, Arti Singh, Rong Chai, David A. Clunie, Fred Prior, Keyvan Farahani</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CR</p>
                    <p><strong>Summary:</strong> The de-identification (deID) of protected health information (PHI) and personally identifiable information (PII) is a fundamental requirement for sharing medical images, particularly through public repositories, to ensure compliance with patient privacy laws. In addition, preservation of non-PHI metadata to inform and enable downstream development of imaging artificial intelligence (AI) is an important consideration in biomedical research. The goal of MIDI-B was to provide a standardized platform for benchmarking of DICOM image deID tools based on a set of rules conformant to the HIPAA Safe Harbor regulation, the DICOM Attribute Confidentiality Profiles, and best practices in preservation of research-critical metadata, as defined by The Cancer Imaging Archive (TCIA). The challenge employed a large, diverse, multi-center, and multi-modality set of real de-identified radiology images with synthetic PHI/PII inserted. The MIDI-B Challenge consisted of three phases: training, validation, and test. Eighty individuals registered for the challenge. In the training phase, we encouraged participants to tune their algorithms using their in-house or public data. The validation and test phases utilized the DICOM images containing synthetic identifiers (of 216 and 322 subjects, respectively). Ten teams successfully completed the test phase of the challenge. To measure success of a rule-based approach to image deID, scores were computed as the percentage of correct actions from the total number of required actions. The scores ranged from 97.91% to 99.93%. Participants employed a variety of open-source and proprietary tools with customized configurations, large language models, and optical character recognition (OCR). In this paper we provide a comprehensive report on the MIDI-B Challenges design, implementation, results, and lessons learned.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23607v1" target="_blank">Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates</a></h3>
                    <p><strong>Authors:</strong> Tien Huu Do, Antoine Masquelier, Nae Eoun Lee, Jonathan Crowther</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Clinical trials are a systematic endeavor to assess the safety and efficacy of new drugs or treatments. Conducting such trials typically demands significant financial investment and meticulous planning, highlighting the need for accurate predictions of trial outcomes. Accurately predicting patient enrollment, a key factor in trial success, is one of the primary challenges during the planning phase. In this work, we propose a novel deep learning-based method to address this critical challenge. Our method, implemented as a neural network model, leverages pre-trained language models (PLMs) to capture the complexities and nuances of clinical documents, transforming them into expressive representations. These representations are then combined with encoded tabular features via an attention mechanism. To account for uncertainties in enrollment prediction, we enhance the model with a probabilistic layer based on the Gamma distribution, which enables range estimation. We apply the proposed model to predict clinical trial duration, assuming site-level enrollment follows a Poisson-Gamma process. We carry out extensive experiments on real-world clinical trial data, and show that the proposed method can effectively predict the number of patients enrolled at a number of sites for a given clinical trial, outperforming established baseline models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23603v1" target="_blank">Explanations for Unrealizability of Infinite-State Safety Shields</a></h3>
                    <p><strong>Authors:</strong> Andoni Rodriguez, Irfansha Shaik, Davide Corsi, Roy Fox, Cesar Sanchez</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LO</p>
                    <p><strong>Summary:</strong> Safe Reinforcement Learning focuses on developing optimal policies while ensuring safety. A popular method to address such task is shielding, in which a correct-by-construction safety component is synthesized from logical specifications. Recently, shield synthesis has been extended to infinite-state domains, such as continuous environments. This makes shielding more applicable to realistic scenarios. However, often shields might be unrealizable because the specification is inconsistent (e.g., contradictory). In order to address this gap, we present a method to obtain simple unconditional and conditional explanations that witness unrealizability, which goes by temporal formula unrolling. In this paper, we show different variants of the technique and its applicability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23600v1" target="_blank">EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution</a></h3>
                    <p><strong>Authors:</strong> Yu-Tang Chang, Shih-Fang Chen</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CE, G.1.6; G.3; G.4; I.6.5</p>
                    <p><strong>Summary:</strong> Signal unmixing analysis decomposes data into basic patterns and is widely applied in chemical and biological research. Multivariate curve resolution (MCR), a branch of signal unmixing, separates mixed chemical signals into base patterns (components) and their concentrations, playing a key role in understanding composition. Classical MCR is typically framed as matrix factorization (MF) and requires a user-specified component count, usually unknown in real data. As dataset size or component count increases, the scalability and reliability of MF-based MCR face significant challenges. This study reformulates MCR as a generative process (gMCR), and introduces an energy-based deep learning solver, EB-gMCR, that automatically discovers the smallest component set able to reconstruct the data faithfully. EB-gMCR starts from a large candidate pool (e.g., 1024 spectra) and employs a differentiable gating network to retain only active components while estimating their concentrations. On noisy synthetic datasets containing up to 256 latent sources, EB-gMCR maintained R^2 = 0.98 and recovered the component count within 5% of the ground truth; at lower noise it achieved R^2 = 0.99 with near exact component estimation. Additional chemical priors, such as non-negativity or nonlinear mixing, enter as simple plug-in functions, enabling adaptation to other instruments or domains without altering the core learning process. By uniting high-capacity generative modeling and hard component selection, EB-gMCR offers a practical route to large-scale signal unmixing analysis, including chemical library-driven scenarios. The source code is available at https://github.com/b05611038/ebgmcr_solver.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23598v1" target="_blank">Fast prediction of the hydrodynamic QGP evolution in ultra-relativistic heavy-ion collisions using Fourier Neural Operators</a></h3>
                    <p><strong>Authors:</strong> David Stewart, Joern Putschke</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> nucl-th, hep-ex</p>
                    <p><strong>Summary:</strong> Recent research in machine learning has employed neural networks to learn mappings between function spaces on bounded domains termed ``neural operators. As such, these operators can provide alternatives to standard numerical methods for partial differential equation (PDE) solutions. In particular, the Fourier Neural Operator (FNO) has been shown to map solutions for classical fluid flow problems with accuracy competitive with traditional PDE solvers and with much greater computing speed. This paper explores the first application of FNOs to model ultra-relativistic hydrodynamic flow of the quark-gluon plasma (QGP) generated in relativistic heavy-ion collisions. The application in ultra-relativistic flow is novel relative to classical flow, due to the hydrodynamic evolution of the QGP occurring in femtometer-scaled explosions characterized by rapid expansion cooling. In this study we investigate the applicability of FNOs as computationally fast alternatives to standard numerical PDE solvers. The FNO predictions are evaluated by comparing to standard PDE solutions, using \MUSIC in the \JETSCAPE Monte Carlo event generator framework. The performance of calculating established experimental observables for flow and jet quenching using FNOs in the MC framework are also reported.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23589v1" target="_blank">Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study</a></h3>
                    <p><strong>Authors:</strong> Kai Goebel, Patrik Zips</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models have sparked interest in their potential for robotic task planning. While these models demonstrate strong generative capabilities, their effectiveness in producing structured and executable plans remains uncertain. This paper presents a systematic evaluation of a broad spectrum of current state of the art language models, each directly prompted using Planning Domain Definition Language domain and problem files, and compares their planning performance with the Fast Downward planner across a variety of benchmarks. In addition to measuring success rates, we assess how faithfully the generated plans translate into sequences of actions that can actually be executed, identifying both strengths and limitations of using these models in this setting. Our findings show that while the models perform well on simpler planning tasks, they continue to struggle with more complex scenarios that require precise resource management, consistent state tracking, and strict constraint compliance. These results underscore fundamental challenges in applying language models to robotic planning in real world environments. By outlining the gaps that emerge during execution, we aim to guide future research toward combined approaches that integrate language models with classical planners in order to enhance the reliability and scalability of planning in autonomous robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23565v1" target="_blank">Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI</a></h3>
                    <p><strong>Authors:</strong> Botao Zhu, Xianbin Wang, Dusit Niyato</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> In collaborative systems, the effective completion of tasks hinges on task-specific trust evaluations of potential devices for distributed collaboration. However, the complexity of tasks, the spatiotemporal dynamism of distributed device resources, and the inevitable assessment overhead dramatically increase the complexity and resource consumption of the trust evaluation process. As a result, ill-timed or overly frequent trust evaluations can reduce utilization rate of constrained resources, negatively affecting collaborative task execution. To address this challenge, this paper proposes an autonomous trust orchestration method based on a new concept of semantic chain-of-trust. Our technique employs agentic AI and hypergraph to establish and maintain trust relationships among devices. By leveraging its strengths in autonomous perception, task decomposition, and semantic reasoning, we propose agentic AI to perceive device states and autonomously perform trust evaluations of collaborators based on historical performance data only during device idle periods, thereby enabling efficient utilization of distributed resources. In addition, agentic AI performs task-specific trust evaluations on collaborator resources by analyzing the alignment between resource capabilities and task requirements. Moreover, by maintaining a trust hypergraph embedded with trust semantics for each device, agentic AI enables hierarchical management of collaborators and identifies collaborators requiring trust evaluation based on trust semantics, thereby achieving a balance between overhead and trust accuracy. Furthermore, local trust hypergraphs from multiple devices can be chained together to support multi-hop collaboration, enabling efficient coordination in large-scale systems. Experimental results demonstrate that the proposed method achieves resource-efficient trust evaluation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23555v1" target="_blank">Magnetic and magnetocaloric properties of the amorphous Tb$_{31}$Co$_{69}$ and Dy$_{31}$Co$_{69}$ thin films deposited on Si substrates</a></h3>
                    <p><strong>Authors:</strong> P. Skokowski, M. Matczak, Å. FrÄ…ckowiak, T. Bednarchuk, M. Kowacz, B. Anastaziak, K. Synoradzki</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> We present the structural, magnetic, and magnetocaloric properties of amorphous thin films Tb-Co and Dy-Co with stoichiometry Tb$_{31}$Co$_{69}$ and Dy$_{31}$Co$_{69}$, deposited on naturally oxidized silicon Si (100) substrates. Samples with a thickness $d=50$ nm covered with a protective Au overlayer with a thickness $d_{\rm Au} =5 $ nm were produced using the pulsed laser deposition technique. The X-ray diffraction analysis indicated the presence of a crystallized Laves phase in the prepared materials. Magnetization measurements as a function of temperature revealed ferrimagnetic behavior in both samples. We estimated the compensation temperature $T_{\rm comp}$ of the amorphous phase for Tb$_{31}$Co$_{69}$ at 81.5 K and for Dy$_{31}$Co$_{69}$ at 88.5 K, while we found the Curie temperature $T_{\rm C,\ Laves}$ of the crystallized Laves phases at 204.5 K and at 117 K, respectively. We investigated the magnetocaloric effect in a wide temperature range, covering $T_{\rm comp}$ of amorphous phases and $T_{\rm C,\ Laves}$ of crystallized Laves phases. The analysis for the magnetic field change of $\Delta \mu_0H=5$ T showed values of the magnetic entropy change of $-\Delta S_{\rm M}=4.9$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm comp}$ and $-\Delta S_{\rm M}=6.6$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm C,\ Laves}$ for Tb$_{31}$Co$_{69}$, while for Dy$_{31}$Co$_{69}$, we determined the values of $-\Delta S_{\rm M}=35$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm comp}$ and $-\Delta S_{\rm M}=28$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm C,\ Laves}$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23552v1" target="_blank">Latest neutrino results from the FASER experiment and their implications for forward hadron production</a></h3>
                    <p><strong>Authors:</strong> FASER Collaboration, Roshan Mammen Abraham, Xiaocong Ai, Saul Alonso Monsalve, John Anders, Claire Antel, Akitaka Ariga, Tomoko Ariga, Jeremy Atkinson, Florian U. Bernlochner, Tobias Boeckh, Jamie Boyd, Lydia Brenner, Angela Burger, Franck Cadoux, Roberto Cardella, David W. Casper, Charlotte Cavanagh, Xin Chen, Dhruv Chouhan, Andrea Coccaro, Stephane DÃ©bieux, Ansh Desai, Sergey Dmitrievsky, Radu Dobre, Monica DOnofrio, Sinead Eley, Yannick Favre, Jonathan L. Feng, Carlo Alberto Fenoglio, Didier Ferrere, Max Fieg, Wissal Filali, Elena Firu, Haruhi Fujimori, Edward Galantay, Ali Garabaglu, Stephen Gibson, Sergio Gonzalez-Sevilla, Yuri Gornushkin, Yotam Granov, Carl Gwilliam, Daiki Hayakawa, Michael Holzbock, Shih-Chieh Hsu, Zhen Hu, Giuseppe Iacobucci, Tomohiro Inada, Luca Iodice, Sune Jakobsen, Hans Joos, Enrique Kajomovitz, Hiroaki Kawahara, Alex Keyken, Felix Kling, Daniela KÃ¶ck, Pantelis Kontaxakis, Umut Kose, Rafaella Kotitsa, Peter Krack, Susanne Kuehn, Thanushan Kugathasan, Sebastian Laudage, Lorne Levinson, Botao Li, Jinfeng Liu, Yi Liu, Margaret S. Lutz, Jack MacDonald, Chiara Magliocca, Toni MÃ¤kelÃ¤, Lawson McCoy, Josh McFayden, Andrea Pizarro Medina, Matteo Milanesio, ThÃ©o Moretti, Keiko Moriyama, Mitsuhiro Nakamura, Toshiyuki Nakano, Laurie Nevay, Ken Ohashi, Hidetoshi Otono, Lorenzo Paolozzi, Pawan Pawan, Brian Petersen, Titi Preda, Markus Prim, Michaela Queitsch-Maitland, Juan Rojo, Hiroki Rokujo, AndrÃ© Rubbia, Jorge Sabater-Iglesias, Osamu Sato, Paola Scampoli, Kristof Schmieden, Matthias Schott, Christiano Sebastiani, Anna Sfyrla, Davide Sgalaberna, Mansoora Shamim, Savannah Shively, Yosuke Takubo, Noshin Tarannum, Ondrej Theiner, Simon Thor, Eric Torrence, Oscar Ivan Valdes Martinez, Svetlana Vasina, Benedikt Vormwald, Yuxiao Wang, Eli Welch, Monika Wielers, Benjamin James Wilson, Jialin Wu, Johannes Martin Wuthrich, Yue Xu, Daichi Yoshikawa, Stefano Zambito, Shunliang Zhang, Xingyu Zhao</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> The muon puzzle -- an excess of muons relative to simulation predictions in ultra-high-energy cosmic-ray air showers -- has been reported by many experiments. This suggests that forward particle production in hadronic interactions is not fully understood. Some of the scenarios proposed to resolve this predict reduced production of forward neutral pions and enhanced production of forward kaons (or other particles). The FASER experiment at the LHC is located 480 m downstream of the ATLAS interaction point and is sensitive to neutrinos and muons, which are the decay products of forward charged pions and kaons. In this study, the latest measurements of electron and muon neutrino fluxes are presented using the data corresponding to 9.5 $\mathrm{fb^{-1}}$ and 65.6 $\mathrm{fb^{-1}}$ of proton-proton collisions with $\sqrt{s}=13.6~\mathrm{TeV}$ by the FASER$\nu$ and the FASER electronic detector, respectively. These fluxes are compared with predictions from recent hadronic interaction models, including EPOS-LHCr, SIBYLL 2.3e, and QGSJET 3. The predictions are generally consistent with the measured fluxes from FASER, although some discrepancies appear in certain energy bins. More precise flux measurements with additional data will follow soon, enabling validation of pion, kaon, and charm meson production with finer energy binning, reduced uncertainties, and multi-differential analyses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23548v1" target="_blank">A decomposition of Fishers information to inform sample size for developing or updating fair and precise clinical prediction models -- Part 3: continuous outcomes</a></h3>
                    <p><strong>Authors:</strong> Rebecca Whittle, Richard D Riley, Lucinda Archer, Gary S Collins, Amardeep Legha, Kym IE Snell, Joie Ensor</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> Clinical prediction models enable healthcare professionals to estimate individual outcomes using patient characteristics. Current sample size guidelines for developing or updating models with continuous outcomes aim to minimise overfitting and ensure accurate estimation of population-level parameters, but do not explicitly address the precision of predictions. This is a critical limitation, as wide confidence intervals around predictions can undermine clinical utility and fairness, particularly if precision varies across subgroups. We propose methodology for calculating the sample size required to ensure precise and fair predictions in models with continuous outcomes. Building on linear regression theory and the Fishers unit information matrix, our approach calculates how sample size impacts the epistemic (model-based) uncertainty of predictions and allows researchers to either (i) evaluate whether an existing dataset is sufficiently large, or (ii) determine the sample size needed to target a particular confidence interval width around predictions. The method requires real or synthetic data representing the target population. To assess fairness,the approach can evaluate prediction precision across subgroups. Extensions to prediction intervals are included to additionally address aleatoric uncertainty. Our methodology provides a practical framework for examining required sample sizes when developing or updating prediction models with continuous outcomes, focusing on achieving precise and equitable predictions. It supports the development of more reliable and fair models, enhancing their clinical applicability and trustworthiness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23540v1" target="_blank">A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving</a></h3>
                    <p><strong>Authors:</strong> Yi Zhang, Erik Leo HaÃŸ, Kuo-Yi Chao, Nenad Petrovic, Yinglei Song, Chengdong Wu, Alois Knoll</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Autonomous driving systems face significant challenges in achieving human-like adaptability, robustness, and interpretability in complex, open-world environments. These challenges stem from fragmented architectures, limited generalization to novel scenarios, and insufficient semantic extraction from perception. To address these limitations, we propose a unified Perception-Language-Action (PLA) framework that integrates multi-sensor fusion (cameras, LiDAR, radar) with a large language model (LLM)-augmented Vision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered reasoning core. This framework unifies low-level sensory processing with high-level contextual reasoning, tightly coupling perception with natural language-based semantic understanding and decision-making to enable context-aware, explainable, and safety-bounded autonomous driving. Evaluations on an urban intersection scenario with a construction zone demonstrate superior performance in trajectory tracking, speed prediction, and adaptive planning. The results highlight the potential of language-augmented cognitive frameworks for advancing the safety, interpretability, and scalability of autonomous driving systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23536v1" target="_blank">From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices</a></h3>
                    <p><strong>Authors:</strong> Georg Slamanig, Francesco Corti, Olga Saukh</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs of updating deep learning models by minimizing the number of additional parameters used to adapt a model to a down- stream task. While extensively researched in large language models (LLMs), their application to smaller models used on edge devices, such as convolutional neural networks, remains underexplored. This paper benchmarks and analyzes popular PEFT methods on convolutional architectures typically deployed in resource-constrained edge environments. We evaluate LoRA, DoRA, and GaLore for updating standard and depthwise convolutional architectures to handle distribution shifts and accommodate unseen classes. We utilize recently proposed PyTorch profilers to compare the updated model performance and computational costs of these PEFT methods with traditional fine-tuning approaches. With resource efficiency in mind, we investigate their update behavior across different rank dimensions. We find that the evaluated PEFT methods are only half as memory-efficient when applied to depthwise-separable convolution architectures, compared to their efficiency with LLMs. Conversely, when targeting convolu- tional architectures optimized for edge deployment, adapter-based PEFT methods can reduce floating point operations (FLOPs) during model updates by up to 95%. These insights offer valuable guidance for selecting PEFT methods based on hardware constraints, performance requirements, and application needs. Our code is online.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23535v1" target="_blank">Transparent AI: The Case for Interpretability and Explainability</a></h3>
                    <p><strong>Authors:</strong> Dhanesh Ramachandram, Himanshu Joshi, Judy Zhu, Dhari Gandhi, Lucas Hartman, Ananya Raval</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> As artificial intelligence systems increasingly inform high-stakes decisions across sectors, transparency has become foundational to responsible and trustworthy AI implementation. Leveraging our role as a leading institute in advancing AI research and enabling industry adoption, we present key insights and lessons learned from practical interpretability applications across diverse domains. This paper offers actionable strategies and implementation guidance tailored to organizations at varying stages of AI maturity, emphasizing the integration of interpretability as a core design principle rather than a retrospective add-on.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23532v1" target="_blank">Viscosity variation in fluid flows across scale</a></h3>
                    <p><strong>Authors:</strong> Arjun Sharma, Ritabrata Thakur, Sharath Jose, Rama Govindarajan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, cond-mat.soft</p>
                    <p><strong>Summary:</strong> A wide range of natural and engineered fluid flows exhibit spatial or temporal viscosity variations, spanning scales from microbial locomotion to planetary mantle convection. These variations introduce qualitatively new physical mechanisms absent in constant-viscosity flows. This review surveys such phenomena across scales. In low Reynolds number (Stokes) flows, viscosity gradients couple translation and rotation, enabling novel particle responses to uniform forcing-- mechanisms that microorganisms may exploit. In shear flows, viscosity variation alters base flow profiles and breaks symmetries, modifying stability and transition dynamics. At high Reynolds numbers, stratification fundamentally changes the singular perturbation structure governing energy production, enhancing or suppressing canonical instabilities and introducing new ones. Viscosity variation also affects nonnormal growth and nonlinear interactions that drive transition to turbulence. While laminar and fully developed turbulence have been extensively studied, transitional processes remain poorly understood in variable-viscosity flows. In turbulent regimes, viscosity variation impacts jets, wall-bounded flows, and mixing layers. At geophysical scales, incorporating eddy viscosity stratification in climate models may improve predictions, while in Earths mantle, viscosity contrasts drive large-scale convection and geological evolution. Particle-laden flows, common across contexts, can generate effective viscosity stratification through inhomogeneous loading. Throughout, we highlight cases where viscosity variation alters flow behavior qualitatively, and point to open questions. This review aims to guide graduate students and researchers toward tractable, cross-disciplinary problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23528v1" target="_blank">Hybrid Generative Semantic and Bit Communications in Satellite Networks: Trade-offs in Latency, Generation Quality, and Computation</a></h3>
                    <p><strong>Authors:</strong> Chong Huang, Gaojie Chen, Jing Zhu, Qu Luo, Pei Xiao, Wei Huang, Rahim Tafazolli</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> As satellite communications play an increasingly important role in future wireless networks, the issue of limited link budget in satellite systems has attracted significant attention in current research. Although semantic communications emerge as a promising solution to address these constraints, it introduces the challenge of increased computational resource consumption in wireless communications. To address these challenges, we propose a multi-layer hybrid bit and generative semantic communication framework which can adapt to the dynamic satellite communication networks. Furthermore, to balance the semantic communication efficiency and performance in satellite-to-ground transmissions, we introduce a novel semantic communication efficiency metric (SEM) that evaluates the trade-offs among latency, computational consumption, and semantic reconstruction quality in the proposed framework. Moreover, we utilize a novel deep reinforcement learning (DRL) algorithm group relative policy optimization (GRPO) to optimize the resource allocation in the proposed network. Simulation results demonstrate the flexibility of our proposed transmission framework and the effectiveness of the proposed metric SEM, illustrate the relationships among various semantic communication metrics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23526v1" target="_blank">Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey</a></h3>
                    <p><strong>Authors:</strong> Wen-Xuan Long, Shengyu Ye, Marco Moretti, Michele Morelli, Luca Sanguinetti, Rui Chen, Cheng-Xiang Wang</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.SP, cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> The sixth-generation (6G) wireless systems are expected to adopt extremely large aperture arrays (ELAAs), novel antenna architectures, and operate in extremely high-frequency bands to meet growing data demands. ELAAs significantly increase the number of antennas, enabling finer spatial resolution and improved beamforming. At high frequencies, ELAAs shift communication from the conventional far-field to near-field regime, where spherical wavefronts dominate and the channel response depends on both angle and distance, increasing channel dimensionality. Conventional far-field channel estimation methods, which rely on angular information, struggle in near-field scenarios due to increased pilot overhead and computational complexity. This paper presents a comprehensive survey of recent advances in near-field channel estimation. It first defines the near- and far-field boundary from an electromagnetic perspective and discusses key propagation differences, alongside a brief review of ELAA developments. Then, it introduces mainstream near-field channel models and compares them with far-field models. Major estimation techniques are reviewed under different configurations (single/multi-user, single/multi-carrier), including both direct estimation and RIS-assisted cascaded estimation. These techniques reveal trade-offs among estimation accuracy, complexity, and overhead. This survey aims to provide insights and foundations for efficient and scalable near-field channel estimation in 6G systems, while identifying key challenges and future research directions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23511v1" target="_blank">MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks</a></h3>
                    <p><strong>Authors:</strong> Yadong Niu, Tianzi Wang, Heinrich Dinkel, Xingwei Sun, Jiahao Zhou, Gang Li, Jizhong Liu, Xunying Liu, Junbo Zhang, Jian Luan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.AS, cs.AI, cs.CL, cs.SD</p>
                    <p><strong>Summary:</strong> While large audio-language models have advanced open-ended audio understanding, they still fall short of nuanced human-level comprehension. This gap persists largely because current benchmarks, limited by data annotations and evaluation metrics, fail to reliably distinguish between generic and highly detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via a pipeline that integrates analysis from specialized expert models with Chain-of-Thought large language model reasoning, MECAT provides multi-perspective, fine-grained captions and open-set question-answering pairs. The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced Audio Text Evaluation). This metric penalizes generic terms and rewards detailed descriptions by combining single-sample semantic similarity with cross-sample discriminability. A comprehensive evaluation of state-of-the-art audio models is also presented, providing new insights into their current capabilities and limitations. The data and code are available at https://github.com/xiaomi-research/mecat</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23492v1" target="_blank">Digital literacy interventions can boost humans in discerning deepfakes</a></h3>
                    <p><strong>Authors:</strong> Dominique Geissler, Claire Robertson, Stefan Feuerriegel</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> Deepfakes, i.e., images generated by artificial intelligence (AI), can erode trust in institutions and compromise election outcomes, as people often struggle to discern real images from deepfakes. Improving digital literacy can help address these challenges, yet scalable and effective approaches remain largely unexplored. Here, we compare the efficacy of five digital literacy interventions to boost peoples ability to discern deepfakes: (1) textual guidance on common indicators of deepfakes; (2) visual demonstrations of these indicators; (3) a gamified exercise for identifying deepfakes; (4) implicit learning through repeated exposure and feedback; and (5) explanations of how deepfakes are generated with the help of AI. We conducted an experiment with N=1,200 participants from the United States to test the immediate and long-term effectiveness of our interventions. Our results show that our interventions can boost deepfake discernment by up to 13 percentage points while maintaining trust in real images. Altogether, our approach is scalable, suitable for diverse populations, and highly effective for boosting deepfake detection while maintaining trust in truthful information.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23491v1" target="_blank">Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus</a></h3>
                    <p><strong>Authors:</strong> Olga Vershinina, Jacopo Sabbatinelli, Anna Rita Bonfigli, Dalila Colombaretti, Angelica Giuliani, Mikhail Krivonosov, Arseniy Trukhanov, Claudio Franceschi, Mikhail Ivanchenko, Fabiola Olivieri</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent non-communicable chronic disease that substantially reduces life expectancy. Accurate estimation of all-cause mortality risk in T2DM patients is crucial for personalizing and optimizing treatment strategies. Research Design and Methods. This study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed T2DM over a maximum follow-up period of 16.8 years, during which 202 patients (36%) died. Key survival-associated features were identified, and multiple machine learning (ML) models were trained and validated to predict all-cause mortality risk. To improve model interpretability, Shapley additive explanations (SHAP) was applied to the best-performing model. Results. The extra survival trees (EST) model, incorporating ten key features, demonstrated the best predictive performance. The model achieved a C-statistic of 0.776, with the area under the receiver operating characteristic curve (AUC) values of 0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause mortality predictions, respectively. The SHAP approach was employed to interpret the models individual decision-making processes. Conclusions. The developed model exhibited strong predictive performance for mortality risk assessment. Its clinically interpretable outputs enable potential bedside application, improving the identification of high-risk patients and supporting timely treatment optimization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23489v1" target="_blank">Distributionally Robust Cascading Risk Quantification in Multi-Agent Rendezvous: Effects of Time Delay and Network Connectivity</a></h3>
                    <p><strong>Authors:</strong> Vivek Pandey, Nader Motee</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Achieving safety in autonomous multi-agent systems, particularly in time-critical tasks like rendezvous, is a critical challenge. In this paper, we propose a distributionally robust risk framework for analyzing cascading failures in multi-agent rendezvous. To capture the complex interactions between network connectivity, system dynamics, and communication delays, we use a time-delayed network model as a benchmark. We introduce a conditional distributionally robust functional to quantify cascading effects between agents, utilizing a bi-variate normal distribution. Our approach yields closed-form risk expressions that reveal the impact of time delay, noise statistics, communication topology, and failure modes on rendezvous risk. The insights derived inform the design of resilient networks that mitigate the risk of cascading failures. We validate our theoretical results through extensive simulations, demonstrating the effectiveness of our framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23486v1" target="_blank">A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains</a></h3>
                    <p><strong>Authors:</strong> Shirui Wang, Zhihui Tang, Huaxia Yang, Qiuhong Gong, Tiantian Gu, Hongyang Ma, Yongxin Wang, Wubin Sun, Zeliang Lian, Kehang Mao, Yinan Jiang, Zhicheng Huang, Lingyun Ma, Wenjie Shen, Yajie Ji, Yunhui Tan, Chunbo Wang, Yunlu Gao, Qianling Ye, Rui Lin, Mingyu Chen, Lijuan Niu, Zhihao Wang, Peng Yu, Mengran Lang, Yue Liu, Huimin Zhang, Haitao Shen, Long Chen, Qiguang Zhao, Si-Xuan Liu, Lina Zhou, Hua Gao, Dongqiang Ye, Lingmin Meng, Youtao Yu, Naixin Liang, Jianxiong Wu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) hold promise in clinical decision support but face major challenges in safety evaluation and effectiveness validation. We developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a multidimensional framework built on clinical expert consensus, encompassing 30 criteria covering critical areas like critical illness recognition, guideline adherence, and medication safety, with weighted consequence measures. Thirty-two specialist physicians developed and reviewed 2,069 open-ended QA items aligned with these criteria, spanning 26 clinical departments to simulate real-world scenarios. Benchmark testing of six LLMs revealed moderate overall performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%), with a significant 13.3% performance drop in high-risk scenarios (p  0.0001). Domain-specific medical LLMs showed consistent performance advantages over general-purpose models, with relatively higher top scores in safety (0.912) and effectiveness (0.861). The findings of this study not only provide a standardized metric for evaluating the clinical application of medical LLMs, facilitating comparative analyses, risk exposure identification, and improvement directions across different scenarios, but also hold the potential to promote safer and more effective deployment of large language models in healthcare environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23479v1" target="_blank">Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning</a></h3>
                    <p><strong>Authors:</strong> Julia Werner, Oliver Bause, Julius Oexle, Maxime Le Floch, Franz Brinkmann, Jochen Hampe, Oliver Bringmann</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video capsule endoscopy has become increasingly important for investigating the small intestine within the gastrointestinal tract. However, a persistent challenge remains the short battery lifetime of such compact sensor edge devices. Integrating artificial intelligence can help overcome this limitation by enabling intelligent real-time decision- making, thereby reducing the energy consumption and prolonging the battery life. However, this remains challenging due to data sparsity and the limited resources of the device restricting the overall model size. In this work, we introduce a multi-task neural network that combines the functionalities of precise self-localization within the gastrointestinal tract with the ability to detect anomalies in the small intestine within a single model. Throughout the development process, we consistently restricted the total number of parameters to ensure the feasibility to deploy such model in a small capsule. We report the first multi-task results using the recently published Galar dataset, integrating established multi-task methods and Viterbi decoding for subsequent time-series analysis. This outperforms current single-task models and represents a significant ad- vance in AI-based approaches in this field. Our model achieves an accu- racy of 93.63% on the localization task and an accuracy of 87.48% on the anomaly detection task. The approach requires only 1 million parameters while surpassing the current baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23473v1" target="_blank">CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes</a></h3>
                    <p><strong>Authors:</strong> Bin Xie, Congxuan Zhang, Fagan Wang, Peng Liu, Feng Lu, Zhen Chen, Weiming Hu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The widespread application of Unmanned Aerial Vehicles (UAVs) has raised serious public safety and privacy concerns, making UAV perception crucial for anti-UAV tasks. However, existing UAV tracking datasets predominantly feature conspicuous objects and lack diversity in scene complexity and attribute representation, limiting their applicability to real-world scenarios. To overcome these limitations, we present the CST Anti-UAV, a new thermal infrared dataset specifically designed for Single Object Tracking (SOT) in Complex Scenes with Tiny UAVs (CST). It contains 220 video sequences with over 240k high-quality bounding box annotations, highlighting two key properties: a significant number of tiny-sized UAV targets and the diverse and complex scenes. To the best of our knowledge, CST Anti-UAV is the first dataset to incorporate complete manual frame-level attribute annotations, enabling precise evaluations under varied challenges. To conduct an in-depth performance analysis for CST Anti-UAV, we evaluate 20 existing SOT methods on the proposed dataset. Experimental results demonstrate that tracking tiny UAVs in complex environments remains a challenge, as the state-of-the-art method achieves only 35.92% state accuracy, much lower than the 67.69% observed on the Anti-UAV410 dataset. These findings underscore the limitations of existing benchmarks and the need for further advancements in UAV tracking research. The CST Anti-UAV benchmark is about to be publicly released, which not only fosters the development of more robust SOT methods but also drives innovation in anti-UAV systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23465v1" target="_blank">Role-Aware Language Models for Secure and Contextualized Access Control in Organizations</a></h3>
                    <p><strong>Authors:</strong> Saeed Almheiri, Yerulan Kongrat, Adrian Santosh, Ruslan Tasmukhanov, Josemaria Vera, Muhammad Dehan Al Kautsar, Fajri Koto</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) are increasingly deployed in enterprise settings, controlling model behavior based on user roles becomes an essential requirement. Existing safety methods typically assume uniform access and focus on preventing harmful or toxic outputs, without addressing role-specific access constraints. In this work, we investigate whether LLMs can be fine-tuned to generate responses that reflect the access privileges associated with different organizational roles. We explore three modeling strategies: a BERT-based classifier, an LLM-based classifier, and role-conditioned generation. To evaluate these approaches, we construct two complementary datasets. The first is adapted from existing instruction-tuning corpora through clustering and role labeling, while the second is synthetically generated to reflect realistic, role-sensitive enterprise scenarios. We assess model performance across varying organizational structures and analyze robustness to prompt injection, role mismatch, and jailbreak attempts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23461v1" target="_blank">Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection</a></h3>
                    <p><strong>Authors:</strong> Taeheon Lim, Joohyung Lee, Kyungjae Lee, Jungchan Cho</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> The Federated Learning (FL) approach enables effective learning across distributed systems, while preserving user data privacy. To date, research has primarily focused on addressing statistical heterogeneity and communication efficiency, through which FL has achieved success in classification tasks. However, its application to non-classification tasks, such as human pose estimation, remains underexplored. This paper identifies and investigates a critical issue termed ``resolution-drift, where performance degrades significantly due to resolution variability across clients. Unlike class-level heterogeneity, resolution drift highlights the importance of resolution as another axis of not independent or identically distributed (non-IID) data. To address this issue, we present resolution-adaptive federated learning (RAF), a method that leverages heatmap-based knowledge distillation. Through multi-resolution knowledge distillation between higher-resolution outputs (teachers) and lower-resolution outputs (students), our approach enhances resolution robustness without overfitting. Extensive experiments and theoretical analysis demonstrate that RAF not only effectively mitigates resolution drift and achieves significant performance improvements, but also can be integrated seamlessly into existing FL frameworks. Furthermore, although this paper focuses on human pose estimation, our t-SNE analysis reveals distinct characteristics between classification and high-resolution representation tasks, supporting the generalizability of RAF to other tasks that rely on preserving spatial detail.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23459v1" target="_blank">KLAN: Kuaishou Landing-page Adaptive Navigator</a></h3>
                    <p><strong>Authors:</strong> Fan Li, Chang Meng, Jiaqi Fu, Shuchang Liu, Jiashuo Zhang, Tianke Zhang, Xueliang Wang, Xiaoqiang Feng</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI</p>
                    <p><strong>Summary:</strong> Modern online platforms configure multiple pages to accommodate diverse user needs. This multi-page architecture inherently establishes a two-stage interaction paradigm between the user and the platform: (1) Stage I: page navigation, navigating users to a specific page and (2) Stage II: in-page interaction, where users engage with customized content within the specific page. While the majority of research has been focusing on the sequential recommendation task that improves users feedback in Stage II, there has been little investigation on how to achieve better page navigation in Stage I. To fill this gap, we formally define the task of Personalized Landing Page Modeling (PLPM) into the field of recommender systems: Given a user upon app entry, the goal of PLPM is to proactively select the most suitable landing page from a set of candidates (e.g., functional tabs, content channels, or aggregation pages) to optimize the short-term PDR metric and the long-term user engagement and satisfaction metrics, while adhering to industrial constraints. Additionally, we propose KLAN (Kuaishou Landing-page Adaptive Navigator), a hierarchical solution framework designed to provide personalized landing pages under the formulation of PLPM. KLAN comprises three key components: (1) KLAN-ISP captures inter-day static page preference; (2) KLAN-IIT captures intra-day dynamic interest transitions and (3) KLAN-AM adaptively integrates both components for optimal navigation decisions. Extensive online experiments conducted on the Kuaishou platform demonstrate the effectiveness of KLAN, obtaining +0.205% and +0.192% improvements on in Daily Active Users (DAU) and user Lifetime (LT). Our KLAN is ultimately deployed on the online platform at full traffic, serving hundreds of millions of users. To promote further research in this important area, we will release our dataset and code upon paper acceptance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23455v1" target="_blank">Machine learning and machine learned prediction in chest X-ray images</a></h3>
                    <p><strong>Authors:</strong> Shereiff Garrett, Abhinav Adhikari, Sarina Gautam, DaShawn Marquis Morris, Chandra Mani Adhikari</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Machine learning and artificial intelligence are fast-growing fields of research in which data is used to train algorithms, learn patterns, and make predictions. This approach helps to solve seemingly intricate problems with significant accuracy without explicit programming by recognizing complex relationships in data. Taking an example of 5824 chest X-ray images, we implement two machine learning algorithms, namely, a baseline convolutional neural network (CNN) and a DenseNet-121, and present our analysis in making machine-learned predictions in predicting patients with ailments. Both baseline CNN and DenseNet-121 perform very well in the binary classification problem presented in this work. Gradient-weighted class activation mapping shows that DenseNet-121 correctly focuses on essential parts of the input chest X-ray images in its decision-making more than the baseline CNN.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23454v1" target="_blank">Breaking the mould of Social Mixed Reality -- State-of-the-Art and Glossary</a></h3>
                    <p><strong>Authors:</strong> Marta BieÅ„kiewicz, Julia Ayache, Panayiotis Charalambous, Cristina Becchio, Marco Corragio, Bertram Taetz, Francesco De Lellis, Antonio Grotta, Anna Server, Daniel Rammer, Richard Kulpa, Franck Multon, Azucena Garcia-Palacios, Jessica Sutherland, Kathleen Bryson, StÃ©phane Donikian, Didier Stricker, BenoÃ®t Bardy</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY, cs.ET, cs.GR, q-bio.NC, I.3.0; I.2; J.4; K.4</p>
                    <p><strong>Summary:</strong> This article explores a critical gap in Mixed Reality (MR) technology: while advances have been made, MR still struggles to authentically replicate human embodiment and socio-motor interaction. For MR to enable truly meaningful social experiences, it needs to incorporate multi-modal data streams and multi-agent interaction capabilities. To address this challenge, we present a comprehensive glossary covering key topics such as Virtual Characters and Autonomisation, Responsible AI, Ethics by Design, and the Scientific Challenges of Social MR within Neuroscience, Embodiment, and Technology. Our aim is to drive the transformative evolution of MR technologies that prioritize human-centric innovation, fostering richer digital connections. We advocate for MR systems that enhance social interaction and collaboration between humans and virtual autonomous agents, ensuring inclusivity, ethical design and psychological safety in the process.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23450v1" target="_blank">The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization</a></h3>
                    <p><strong>Authors:</strong> Dilshanie Prasikala, Joonas Lahtinen, Alexandra Koulouri, Sampsa Pursiainen</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> EEG Source localization is a critical tool in neuroscience, with applications ranging from epilepsy diagnosis to cognitive research. It involves solving an ill-posed inverse problem that lacks a unique solution unless constrained by prior knowledge. The Bayesian framework enables the incorporation of such knowledge, typically encoded through prior models. Various algorithms have been proposed for source localization, and they differ significantly in how prior knowledge is incorporated. Some approaches rely on anatomical or functional constraints, while others use statistical distributions or sampling-based techniques. In this landscape, the Standardized Kalman Filter (SKF) represents a dynamic Bayesian approach that integrates temporal modeling with a Gaussian prior structure. It addresses the depth bias, a common limitation in source localization, through a post-hoc standardization step that equalizes sensitivity across cortical depths and makes deep activity detection feasible. This study focuses on the development and optimization of Gaussian prior models within the SKF framework for simultaneous cortical and sub-cortical activity detection. Synthetic data similar to the P20 / N20 component of the somatosensory evoked potentials (SEP) was used to identify effective prior parameter configurations for reconstructing both deep and superficial sources under different noise levels. We also investigated the role of RTS smoothing in enhancing source separability. Our results indicate that raising the standardization exponent to 1.25, along with smoothing, significantly improves depth localization accuracy at low noise levels.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23446v1" target="_blank">Miscellanea: Within-trial prognostic score adjustment is targeted maximum likelihood estimation</a></h3>
                    <p><strong>Authors:</strong> Emilie HÃ¸jbjerre-Frandsen, Alejandro Schuler</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> Adjustment for ``super or ``prognostic composite covariates has become more popular in randomized trials recently. These prognostic covariates are often constructed from historical data by fitting a predictive model of the outcome on the raw covariates. A natural question that we have been asked by applied researchers is whether this can be done without the historical data: can the prognostic covariate be constructed or derived from the trial data itself, possibly using different folds of the data, before adjusting for it? Here we clarify that such ``within-trial prognostic adjustment is nothing more than a form of targeted maximum likelihood estimation (TMLE), a well-studied procedure for optimal inference. We demonstrate the equivalence with a simulation study and discuss the pros and cons of within-trial prognostic adjustment (standard efficient estimation) relative to standard TMLE and standard prognostic adjustment with historical data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23784v1" target="_blank">SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions</a></h3>
                    <p><strong>Authors:</strong> Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Concept Bottleneck Models (CBMs) and other concept-based interpretable models show great promise for making AI applications more transparent, which is essential in fields like medicine. Despite their success, we demonstrate that CBMs struggle to reliably identify the correct concepts under distribution shifts. To assess the robustness of CBMs to concept variations, we introduce SUB: a fine-grained image and concept benchmark containing 38,400 synthetic images based on the CUB dataset. To create SUB, we select a CUB subset of 33 bird classes and 45 concepts to generate images which substitute a specific concept, such as wing color or belly pattern. We introduce a novel Tied Diffusion Guidance (TDG) method to precisely control generated images, where noise sharing for two parallel denoising processes ensures that both the correct bird class and the correct attribute are generated. This novel benchmark enables rigorous evaluation of CBMs and similar interpretable models, contributing to the development of more robust methods. Our code is available at https://github.com/ExplainableML/sub and the dataset at http://huggingface.co/datasets/Jessica-bader/SUB.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23782v1" target="_blank">MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion</a></h3>
                    <p><strong>Authors:</strong> Zihan Wang, Jeff Tan, Tarasha Khurana, Neehar Peri, Deva Ramanan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We address the problem of dynamic scene reconstruction from sparse-view videos. Prior work often requires dense multi-view captures with hundreds of calibrated cameras (e.g. Panoptic Studio). Such multi-view setups are prohibitively expensive to build and cannot capture diverse scenes in-the-wild. In contrast, we aim to reconstruct dynamic human behaviors, such as repairing a bike or dancing, from a small set of sparse-view cameras with complete scene coverage (e.g. four equidistant inward-facing static cameras). We find that dense multi-view reconstruction methods struggle to adapt to this sparse-view setup due to limited overlap between viewpoints. To address these limitations, we carefully align independent monocular reconstructions of each camera to produce time- and view-consistent dynamic scene reconstructions. Extensive experiments on PanopticStudio and Ego-Exo4D demonstrate that our method achieves higher quality reconstructions than prior art, particularly when rendering novel views. Code, data, and data-processing scripts are available on https://github.com/ImNotPrepared/MonoFusion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23777v1" target="_blank">XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding</a></h3>
                    <p><strong>Authors:</strong> Dian Chen, Yansong Qu, Xinyang Li, Ming Li, Shengchuan Zhang</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Current auto-regressive models can generate high-quality, topologically precise meshes; however, they necessitate thousands-or even tens of thousands-of next-token predictions during inference, resulting in substantial latency. We introduce XSpecMesh, a quality-preserving acceleration method for auto-regressive mesh generation models. XSpecMesh employs a lightweight, multi-head speculative decoding scheme to predict multiple tokens in parallel within a single forward pass, thereby accelerating inference. We further propose a verification and resampling strategy: the backbone model verifies each predicted token and resamples any tokens that do not meet the quality criteria. In addition, we propose a distillation strategy that trains the lightweight decoding heads by distilling from the backbone model, encouraging their prediction distributions to align and improving the success rate of speculative predictions. Extensive experiments demonstrate that our method achieves a 1.7x speedup without sacrificing generation quality. Our code will be released.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23773v1" target="_blank">SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model</a></h3>
                    <p><strong>Authors:</strong> Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG, cs.RO</p>
                    <p><strong>Summary:</strong> AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \modelname improves the success of flight search from 0\% to 32.2\%. World-model-based planning, in particular, shows consistent advantage of up to 124\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \modelname with pretrained LLMs, available as a research demo for public testing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23772v1" target="_blank">SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Di Li, Jie Feng, Jiahao Chen, Weisheng Dong, Guanbin Li, Yuhui Zheng, Mingtao Feng, Guangming Shi</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D affordance reasoning, the task of associating human instructions with the functional regions of 3D objects, is a critical capability for embodied agents. Current methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited to single-object, single-step interactions, a paradigm that falls short of addressing the long-horizon, multi-object tasks required for complex real-world applications. To bridge this gap, we introduce the novel task of Sequential 3D Gaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale benchmark featuring 1800+ scenes to support research on long-horizon affordance understanding in complex 3DGS environments. We then propose SeqSplatNet, an end-to-end framework that directly maps an instruction to a sequence of 3D affordance masks. SeqSplatNet employs a large language model that autoregressively generates text interleaved with special segmentation tokens, guiding a conditional decoder to produce the corresponding 3D mask. To handle complex scene geometry, we introduce a pre-training strategy, Conditional Geometric Reconstruction, where the model learns to reconstruct complete affordance region masks from known geometric observations, thereby building a robust geometric prior. Furthermore, to resolve semantic ambiguities, we design a feature injection mechanism that lifts rich semantic features from 2D Vision Foundation Models (VFM) and fuses them into the 3D decoder at multiple scales. Extensive experiments demonstrate that our method sets a new state-of-the-art on our challenging benchmark, effectively advancing affordance reasoning from single-step interactions to complex, sequential tasks at the scene level.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23768v1" target="_blank">Formal Bayesian Transfer Learning via the Total Risk Prior</a></h3>
                    <p><strong>Authors:</strong> Nathan Wycoff, Ali Arab, Lisa O. Singh</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> In analyses with severe data-limitations, augmenting the target dataset with information from ancillary datasets in the application domain, called source datasets, can lead to significantly improved statistical procedures. However, existing methods for this transfer learning struggle to deal with situations where the source datasets are also limited and not guaranteed to be well-aligned with the target dataset. A typical strategy is to use the empirical loss minimizer on the source data as a prior mean for the target parameters, which places the estimation of source parameters outside of the Bayesian formalism. Our key conceptual contribution is to use a risk minimizer conditional on source parameters instead. This allows us to construct a single joint prior distribution for all parameters from the source datasets as well as the target dataset. As a consequence, we benefit from full Bayesian uncertainty quantification and can perform model averaging via Gibbs sampling over indicator variables governing the inclusion of each source dataset. We show how a particular instantiation of our prior leads to a Bayesian Lasso in a transformed coordinate system and discuss computational techniques to scale our approach to moderately sized datasets. We also demonstrate that recently proposed minimax-frequentist transfer learning techniques may be viewed as an approximate Maximum a Posteriori approach to our model. Finally, we demonstrate superior predictive performance relative to the frequentist baseline on a genetics application, especially when the source data are limited.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23764v1" target="_blank">M2-brane indices on Higgs vacua</a></h3>
                    <p><strong>Authors:</strong> Chiung Hwang, Chang Lei, Yuezhang Tang</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> As an exact count of protected states, the superconformal index provides a powerful probe into holography and quantum aspects of gravity, reproducing the Bekenstein-Hawking entropy of supersymmetric AdS black holes in the large-$N$ limit. As a step toward understanding quantum black hole microstates, we study the finite-$N$ index of the 3d ADHM quiver gauge theory, a UV description of the 3d $\mathcal N=8$ SCFT dual to M-theory on AdS$_4 \times S^7$. In this note, we analyze both microcanonical and canonical features of the superconformal index. By computing the index to sufficiently high orders, we identify signatures of quantum black hole states in the finite-$N$ spectrum of the ADHM quiver, which align with the leading large-$N$ contribution reflecting the holographic dual black hole entropy. Furthermore, we introduce the complex-$\beta$ phase diagram of the index, which exhibits distinct peaks potentially associated with different gravitational saddles. To enable high-order computations, we employ the factorized index and also examine its Higgs branch Hilbert series limit. Our results demonstrate that the finite-$N$ index encodes rich information about black hole microstates and their quantum gravitational interpretation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23750v1" target="_blank">Deformations of Reproducing Kernel Hilbert Spaces on Homogeneous Varieties</a></h3>
                    <p><strong>Authors:</strong> Yasin Watted</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> math.FA, math.OA</p>
                    <p><strong>Summary:</strong> We study the relationships between a subvariety of the open unit ball in the complex $d$-dimensional space $\mathbb{C}^{d}$, the reproducing kernel Hilbert space (RKHS) obtained by restricting the Drury-Arveson space to the variety, and its multiplier algebra. Davidson, Ramsey, and Shalit showed that given two subvarieties, one is the image of the other under an automorphism of the ball if and only if the RKHSs corresponding to the varieties are isometrically isomorphic as RKHSs, and this holds if and only if their multiplier algebras are isometrically isomorphic as multiplier algebras. We observe that whenever two such RKHSs are close to being isometrically isomorphic, their multiplier algebras are close to being isometrically isomorphic as well. In this case, the underlying varieties are close to being automorphically equivalent. For homogeneous varieties satisfying some additional conditions, we show that if one variety is close to being the image of the other under a unitary, then the RKHSs are close to being isometrically isomorphic as RKHSs. This continues work by Ofek, Pandey and Shalit, who showed that for two finite subsets in the open unit ball $B_{d}$, one set is close to being the image of the other under an automorphism of $B_{d}$, if and only if the RKHSs defined on these sets, are close to being isometrically isomorphic, and that happens if and only if their multiplier algebras are close to being completely isometrically isomorphic.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23743v1" target="_blank">Relative Bias Under Imperfect Identification in Observational Causal Inference</a></h3>
                    <p><strong>Authors:</strong> Melody Huang, Cory McCartan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ME, econ.EM</p>
                    <p><strong>Summary:</strong> To conduct causal inference in observational settings, researchers must rely on certain identifying assumptions. In practice, these assumptions are unlikely to hold exactly. This paper considers the bias of selection-on-observables, instrumental variables, and proximal inference estimates under violations of their identifying assumptions. We develop bias expressions for IV and proximal inference that show how violations of their respective assumptions are amplified by any unmeasured confounding in the outcome variable. We propose a set of sensitivity tools that quantify the sensitivity of different identification strategies, and an augmented bias contour plot visualizes the relationship between these strategies. We argue that the act of choosing an identification strategy implicitly expresses a belief about the degree of violations that must be present in alternative identification strategies. Even when researchers intend to conduct an IV or proximal analysis, a sensitivity analysis comparing different identification strategies can help to better understand the implications of each set of assumptions. Throughout, we compare the different approaches on a re-analysis of the impact of state surveillance on the incidence of protest in Communist Poland.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23740v1" target="_blank">Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs</a></h3>
                    <p><strong>Authors:</strong> Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of-thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use of large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23736v1" target="_blank">DICOM De-Identification via Hybrid AI and Rule-Based Framework for Scalable, Uncertainty-Aware Redaction</a></h3>
                    <p><strong>Authors:</strong> Kyle Naddeo, Nikolas Koutsoubis, Rahul Krish, Ghulam Rasool, Nidhal Bouaynaya, Tony OSullivan, Raj Krish</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Access to medical imaging and associated text data has the potential to drive major advances in healthcare research and patient outcomes. However, the presence of Protected Health Information (PHI) and Personally Identifiable Information (PII) in Digital Imaging and Communications in Medicine (DICOM) files presents a significant barrier to the ethical and secure sharing of imaging datasets. This paper presents a hybrid de-identification framework developed by Impact Business Information Solutions (IBIS) that combines rule-based and AI-driven techniques, and rigorous uncertainty quantification for comprehensive PHI/PII removal from both metadata and pixel data. Our approach begins with a two-tiered rule-based system targeting explicit and inferred metadata elements, further augmented by a large language model (LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of synthetic datasets simulating realistic clinical PHI/PII. For pixel data, we employ an uncertainty-aware Faster R-CNN model to localize embedded text, extract candidate PHI via Optical Character Recognition (OCR), and apply the NER pipeline for final redaction. Crucially, uncertainty quantification provides confidence measures for AI-based detections to enhance automation reliability and enable informed human-in-the-loop verification to manage residual risks. This uncertainty-aware deidentification framework achieves robust performance across benchmark datasets and regulatory standards, including DICOM, HIPAA, and TCIA compliance metrics. By combining scalable automation, uncertainty quantification, and rigorous quality assurance, our solution addresses critical challenges in medical data de-identification and supports the secure, ethical, and trustworthy release of imaging data for research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23735v1" target="_blank">Distributed AI Agents for Cognitive Underwater Robot Autonomy</a></h3>
                    <p><strong>Authors:</strong> Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.MA</p>
                    <p><strong>Summary:</strong> Achieving robust cognitive autonomy in robots navigating complex, unpredictable environments remains a fundamental challenge in robotics. This paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a groundbreaking architecture leveraging distributed Large Language Model AI agents integrated within the Robot Operating System 2 (ROS 2) framework to enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA decentralises cognition into specialised AI agents responsible for multimodal perception, adaptive reasoning, dynamic mission planning, and real-time decision-making. Central innovations include flexible agents dynamically adapting their roles, retrieval-augmented generation utilising vector databases for efficient knowledge management, reinforcement learning-driven behavioural optimisation, and autonomous on-the-fly ROS 2 node generation for runtime functional extensibility. Extensive empirical validation demonstrates UROSAs promising adaptability and reliability through realistic underwater missions in simulation and real-world deployments, showing significant advantages over traditional rule-based architectures in handling unforeseen scenarios, environmental uncertainties, and novel mission objectives. This work not only advances underwater autonomy but also establishes a scalable, safe, and versatile cognitive robotics framework capable of generalising to a diverse array of real-world applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23723v1" target="_blank">Search for $t\bar tt\bar tW$ Production at $\sqrt{s} = 13$ TeV Using a Modified Graph Neural Network at the LHC</a></h3>
                    <p><strong>Authors:</strong> Syed Haider Ali, Ashfaq Ahmad, Muhammad Saiel, Nadeem Shaukat</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-ex, hep-ph</p>
                    <p><strong>Summary:</strong> The simultaneous production of four top quarks in association with a ($W$) boson at $(\sqrt{s} = 13)$ TeV is an rare SM process with a next-to-leading-order (NLO) cross-section of $(6.6^{+2.4}_{-2.6} {ab})$\cite{saiel}. Identifying this process in the fully hadronic decay channel is particularly challenging due to overwhelming backgrounds from $t\bar{t}, t\bar{t}W, t\bar{t}Z$, and triple-top production processes. This study introduces a modified physics informed Neural Network, a hybrid graph neural network (GNN) enhancing event classification. The proposed model integrates Graph layers for particle-level features, a custom Multi Layer Perceptron(MLP) based global stream with a quantum circuit and cross-attention fusion to combine local and global representations. Physics-informed Loss function enforce jet multiplicity constraints, derived from event decay dynamics. Benchmarked against conventional methods, the GNN achieves a signal significance $(S/\sqrt{S+B})$ of $0.174$ and ROC-AUC of 0.974, surpassing BDTs significance of $0.148$ and ROC of $0.913$, while Xgboost achieves a significance of $0.149$ and ROC of $0.920$. The classification models are trained on Monte Carlo (MC) simulations, with events normalized using cross-section-based reweighting to reflect their expected contributions in a dataset corresponding to $350\;$fb$^{-1}$ of integrated luminosity. This enhanced approach offers a framework for precision event selection at the LHC, leveraging high dimensional statistical learning and physics informed inference to tackle fundamental HEP challenges, aligning with ML developments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23718v1" target="_blank">Informing AI Risk Assessment with News Media: Analyzing National and Political Variation in the Coverage of AI Risks</a></h3>
                    <p><strong>Authors:</strong> Mowafak Allaham, Kimon Kieslich, Nicholas Diakopoulos</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Risk-based approaches to AI governance often center the technological artifact as the primary focus of risk assessments, overlooking systemic risks that emerge from the complex interaction between AI systems and society. One potential source to incorporate more societal context into these approaches is the news media, as it embeds and reflects complex interactions between AI systems, human stakeholders, and the larger society. News media is influential in terms of which AI risks are emphasized and discussed in the public sphere, and thus which risks are deemed important. Yet, variations in the news media between countries and across different value systems (e.g. political orientations) may differentially shape the prioritization of risks through the medias agenda setting and framing processes. To better understand these variations, this work presents a comparative analysis of a cross-national sample of news media spanning 6 countries (the U.S., the U.K., India, Australia, Israel, and South Africa). Our findings show that AI risks are prioritized differently across nations and shed light on how left vs. right leaning U.S. based outlets not only differ in the prioritization of AI risks in their coverage, but also use politicized language in the reporting of these risks. These findings can inform risk assessors and policy-makers about the nuances they should account for when considering news media as a supplementary source for risk-based governance approaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23701v1" target="_blank">TextQuests: How Good are LLMs at Text-Based Video Games?</a></h3>
                    <p><strong>Authors:</strong> Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agents ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agents capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at https://textquests.ai.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23699v1" target="_blank">Exploring Left-Wing Extremism on the Decentralized Web: An Analysis of Lemmygrad.ml</a></h3>
                    <p><strong>Authors:</strong> Utkucan Balci, Michael Sirivianos, Jeremy Blackburn</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.SI</p>
                    <p><strong>Summary:</strong> This study investigates the presence of left-wing extremism on the Lemmygrad.ml instance of the decentralized social media platform Lemmy, from its launch in 2019 up to a month after the bans of the subreddits r/GenZedong and r/GenZhou. We conduct a temporal analysis on Lemmygrad.mls user activity, with also measuring the degree of highly abusive or hateful content. Furthermore, we explore the content of their posts using a transformer-based topic modeling approach. Our findings reveal a substantial increase in user activity and toxicity levels following the migration of these subreddits to Lemmygrad.ml. We also identify posts that support authoritarian regimes, endorse the Russian invasion of Ukraine, and feature anti-Zionist and antisemitic content. Overall, our findings contribute to a more nuanced understanding of political extremism within decentralized social networks and emphasize the necessity of analyzing both ends of the political spectrum in research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23693v1" target="_blank">CFDagent: A Language-Guided, Zero-Shot Multi-Agent System for Complex Flow Simulation</a></h3>
                    <p><strong>Authors:</strong> Zhaoyue Xu, Long Wang, Chunyu Wang, Yixin Chen, Qingyong Luo, Hua-Dong Yao, Shizhao Wang, Guowei He</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn</p>
                    <p><strong>Summary:</strong> We introduce CFDagent, a zero-shot, multi-agent system that enables fully autonomous computational fluid dynamics (CFD) simulations from natural language prompts. CFDagent integrates three specialized LLM-driven agents: (i) the Preprocessing Agent that generates 3D geometries from textual or visual inputs using a hybrid text-to-3D diffusion model (Point-E) and automatically meshes the geometries; (ii) the Solver Agent that configures and executes an immersed boundary flow solver; and (iii) the Postprocessing Agent that analyzes and visualizes the results, including multimodal renderings. These agents are interactively guided by GPT-4o via conversational prompts, enabling intuitive and user-friendly interaction. We validate CFDagent by reproducing canonical sphere flows at Reynolds numbers of 100 and 300 using three distinct inputs: a simple text prompt (i.e., sphere), an image-based input, and a standard sphere model. The computed drag and lift coefficients from meshes produced by each input approach closely match available data. The proposed system enables synthesization of flow simulations and photorealistic visualizations for complex geometries. Through extensive tests on canonical and realistic scenarios, we demonstrate the robustness, versatility, and practical applicability of CFDagent. By bridging generative AI with high-fidelity simulations, CFDagent significantly lowers barriers to expert-level CFD, unlocking broad opportunities in education, scientific research, and practical engineering applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23685v1" target="_blank">UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration</a></h3>
                    <p><strong>Authors:</strong> Zihan Cheng, Liangtai Zhou, Dian Chen, Ni Tang, Xiaotong Luo, Yanyun Qu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> All-in-One Image Restoration (AiOIR) has emerged as a promising yet challenging research direction. To address its core challenges, we propose a novel unified image restoration framework based on latent diffusion models (LDMs). Our approach structurally integrates low-quality visual priors into the diffusion process, unlocking the powerful generative capacity of diffusion models for diverse degradations. Specifically, we design a Degradation-Aware Feature Fusion (DAFF) module to enable adaptive handling of diverse degradation types. Furthermore, to mitigate detail loss caused by the high compression and iterative sampling of LDMs, we design a Detail-Aware Expert Module (DAEM) in the decoder to enhance texture and fine-structure recovery. Extensive experiments across multi-task and mixed degradation settings demonstrate that our method consistently achieves state-of-the-art performance, highlighting the practical potential of diffusion priors for unified image restoration. Our code will be released.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23682v1" target="_blank">villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models</a></h3>
                    <p><strong>Authors:</strong> Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies that can follow language instructions and generalize to novel scenarios. Recent work has begun to explore the incorporation of latent actions, an abstract representation of visual change between two frames, into VLA pre-training. In this paper, we introduce villa-X, a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent action modeling for learning generalizable robot manipulation policies. Our approach improves both how latent actions are learned and how they are incorporated into VLA pre-training. Together, these contributions enable villa-X to achieve superior performance across simulated environments including SIMPLER and LIBERO, as well as on two real-world robot setups including gripper and dexterous hand manipulation. We believe the ViLLA paradigm holds significant promise, and that our villa-X provides a strong foundation for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23669v1" target="_blank">Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database</a></h3>
                    <p><strong>Authors:</strong> Diego Russo, Gian Marco Orlando, Valerio La Gatta, Vincenzo Moscato</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> Artificial Intelligence (AI) systems are transforming critical sectors such as healthcare, finance, and transportation, enhancing operational efficiency and decision-making processes. However, their deployment in high-stakes domains has exposed vulnerabilities that can result in significant societal harm. To systematically study and mitigate these risk, initiatives like the AI Incident Database (AIID) have emerged, cataloging over 3,000 real-world AI failure reports. Currently, associating a new report with the appropriate AI Incident relies on manual expert intervention, limiting scalability and delaying the identification of emerging failure patterns. To address this limitation, we propose a retrieval-based framework that automates the association of new reports with existing AI Incidents through semantic similarity modeling. We formalize the task as a ranking problem, where each report-comprising a title and a full textual description-is compared to previously documented AI Incidents based on embedding cosine similarity. Benchmarking traditional lexical methods, cross-encoder architectures, and transformer-based sentence embedding models, we find that the latter consistently achieve superior performance. Our analysis further shows that combining titles and descriptions yields substantial improvements in ranking accuracy compared to using titles alone. Moreover, retrieval performance remains stable across variations in description length, highlighting the robustness of the framework. Finally, we find that retrieval performance consistently improves as the training set expands. Our approach provides a scalable and efficient solution for supporting the maintenance of the AIID.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23664v1" target="_blank">Personalized Education with Ranking Alignment Recommendation</a></h3>
                    <p><strong>Authors:</strong> Haipeng Liu, Yuxuan Liu, Ting Long</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> Personalized question recommendation aims to guide individual students through questions to enhance their mastery of learning targets. Most previous methods model this task as a Markov Decision Process and use reinforcement learning to solve, but they struggle with efficient exploration, failing to identify the best questions for each student during training. To address this, we propose Ranking Alignment Recommendation (RAR), which incorporates collaborative ideas into the exploration mechanism, enabling more efficient exploration within limited training episodes. Experiments show that RAR effectively improves recommendation performance, and our framework can be applied to any RL-based question recommender. Our code is available in https://github.com/wuming29/RAR.git.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23661v1" target="_blank">Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning</a></h3>
                    <p><strong>Authors:</strong> Salam Thabet Doghmash, Motaz Saad</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL, I.2.7</p>
                    <p><strong>Summary:</strong> Hate speech identification in social media has become an increasingly important issue in recent years. In this research, we address two problems: 1) to detect hate speech in Arabic text, 2) to clean a given text from hate speech. The meaning of cleaning here is replacing each bad word with stars based on the number of letters for each word. Regarding the first problem, we conduct several experiments using deep learning models and transformers to determine the best model in terms of the F1 score. Regarding second problem, we consider it as a machine translation task, where the input is a sentence containing dirty text and the output is the same sentence with masking the dirty text. The presented methods achieve the best model in hate speech detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text cleaning experiment, the best result in the hate speech masking model reached 0.3 in BLEU score with 1-gram, which is a good result compared with the state of the art machine translation systems.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1515/eng-2024-0098" target="_blank">Architectural practice process and artificial intelligence -- an evolving practice</a></h3>
                    <p><strong>Authors:</strong> Mustapha El Moussaoui</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> In an era of exponential technological advancement, artificial intelligence (AI) has emerged as a transformative force in architecture, reshaping traditional design and construction practices. This article explores the multifaceted roles of AI in the architectural process, emphasizing its potential to enhance creativity and efficiency while addressing its limitations in capturing multisensory and experiential dimensions of space. Historically, architectural innovation has paralleled technological progress, from basic tools to advanced computer-aided design systems. However, the integration of AI presents unique challenges, requiring architects to critically evaluate its role in design. A narrative review methodology was adopted, focusing on academic sources selected for their relevance, recency, and credibility. The findings reveal that AI is increasingly integrated across various stages of the architectural process, from early conceptualization and site analysis to generative design and construction detailing. AI tools excel at automating repetitive tasks and generating innovative design solutions, freeing architects to focus on creativity and problem-solving. Additionally, AIs (text- toimage) visual representation strength challenges the ocularcentric approaches in architecture, which should push future architects to address the holistic sensory and experiential qualities of space or the critical thinking inherent to architectural design. While AI offers transformative potential, architects must view it as a collaborative partner rather than a passive tool.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23652v1" target="_blank">Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis</a></h3>
                    <p><strong>Authors:</strong> Kunpeng Qiu, Zhiying Zhou, Yongxin Guo</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Medical image annotation is constrained by privacy concerns and labor-intensive labeling, significantly limiting the performance and generalization of segmentation models. While mask-controllable diffusion models excel in synthesis, they struggle with precise lesion-mask alignment. We propose \textbf{Adaptively Distilled ControlNet}, a task-agnostic framework that accelerates training and optimization through dual-model distillation. Specifically, during training, a teacher model, conditioned on mask-image pairs, regularizes a mask-only student model via predicted noise alignment in parameter space, further enhanced by adaptive regularization based on lesion-background ratios. During sampling, only the student model is used, enabling privacy-preserving medical image generation. Comprehensive evaluations on two distinct medical datasets demonstrate state-of-the-art performance: TransUNet improves mDice/mIoU by 2.4%/4.2% on KiTS19, while SANet achieves 2.6%/3.5% gains on Polyps, highlighting its effectiveness and superiority. Code is available at GitHub.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23648v1" target="_blank">Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach</a></h3>
                    <p><strong>Authors:</strong> Louise Guillon, Soheib Biga, Yendoube E. Kantchire, Mouhamadou Lamine Sane, GrÃ©goire Pasquier, Kossi Yakpa, StÃ©phane E. Sossou, Marc Thellier, Laurent Bonnardot, Laurence Lachaud, Renaud Piarroux, Ameyo M. Dorkenoo</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Malaria remains a major global health challenge, particularly in low-resource settings where access to expert microscopy may be limited. Deep learning-based computer-aided diagnosis (CAD) systems have been developed and demonstrate promising performance on thin blood smear images. However, their clinical deployment may be hindered by limited generalization across sites with varying conditions. Yet very few practical solutions have been proposed. In this work, we investigate continual learning (CL) as a strategy to enhance the robustness of malaria CAD models to domain shifts. We frame the problem as a domain-incremental learning scenario, where a YOLO-based object detector must adapt to new acquisition sites while retaining performance on previously seen domains. We evaluate four CL strategies, two rehearsal-based and two regularization-based methods, on real-life conditions thanks to a multi-site clinical dataset of thin blood smear images. Our results suggest that CL, and rehearsal-based methods in particular, can significantly improve performance. These findings highlight the potential of continual learning to support the development of deployable, field-ready CAD tools for malaria.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23644v1" target="_blank">Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity</a></h3>
                    <p><strong>Authors:</strong> Alba Aguilera, Georgina Curto, Nardine Osman</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.MA</p>
                    <p><strong>Summary:</strong> Agent-based simulations have an enormous potential as tools to evaluate social policies in a non-invasive way, before these are implemented to real-world populations. However, the recommendations that these computational approaches may offer to tackle urgent human development challenges can vary substantially depending on how we model agents (people) behaviour and the criteria that we use to measure inequity. In this paper, we integrate the conceptual framework of the capability approach (CA), which is explicitly designed to promote and assess human well-being, to guide the simulation and evaluate the effectiveness of policies. We define a reinforcement learning environment where agents behave to restore their capabilities under the constraints of a specific policy. Working in collaboration with local stakeholders, non-profits and domain experts, we apply our model in a case study to mitigate health inequity among the population experiencing homelessness (PEH) in Barcelona. By doing so, we present the first proof of concept simulation, aligned with the CA for human development, to assess the impact of policies under parliamentary discussion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23633v1" target="_blank">MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying</a></h3>
                    <p><strong>Authors:</strong> Qian Zhao, Zhuo Sun, Bin Guo, Zhiwen Yu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Agent-assisted memory recall is one critical research problem in the field of human-computer interaction. In conventional methods, the agent can retrieve information from its equipped memory module to help the person recall incomplete or vague memories. The limited size of memory module hinders the acquisition of complete memories and impacts the memory recall performance in practice. Memory theories suggest that the persons relevant memory can be proactively activated through some effective cues. Inspired by this, we propose a novel strategy-guided agent-assisted memory recall method, allowing the agent to transform an original query into a cue-rich one via the judiciously designed strategy to help the person recall memories. To this end, there are two key challenges. (1) How to choose the appropriate recall strategy for diverse forgetting scenarios with distinct memory-recall characteristics? (2) How to obtain the high-quality responses leveraging recall strategies, given only abstract and sparsely annotated strategy patterns? To address the challenges, we propose a Recall Router framework. Specifically, we design a 5W Recall Map to classify memory queries into five typical scenarios and define fifteen recall strategy patterns across the corresponding scenarios. We then propose a hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to optimize the selection of strategy and the generation of strategy responses. We construct an instruction tuning dataset and fine-tune multiple open-source large language models (LLMs) to develop MemoCue, an agent that excels in providing memory-inspired responses. Experiments on three representative datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall inspiration. Further human evaluation highlights its advantages in memory-recall applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23620v1" target="_blank">DivControl: Knowledge Diversion for Controllable Image Generation</a></h3>
                    <p><strong>Authors:</strong> Yucheng Xie, Fu Feng, Ruixiao Shi, Jing Wang, Yong Rui, Xin Geng</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Diffusion models have advanced from text-to-image (T2I) to image-to-image (I2I) generation by incorporating structured inputs such as depth maps, enabling fine-grained spatial control. However, existing methods either train separate models for each condition or rely on unified architectures with entangled representations, resulting in poor generalization and high adaptation costs for novel conditions. To this end, we propose DivControl, a decomposable pretraining framework for unified controllable generation and efficient adaptation. DivControl factorizes ControlNet via SVD into basic components-pairs of singular vectors-which are disentangled into condition-agnostic learngenes and condition-specific tailors through knowledge diversion during multi-condition training. Knowledge diversion is implemented via a dynamic gate that performs soft routing over tailors based on the semantics of condition instructions, enabling zero-shot generalization and parameter-efficient adaptation to novel conditions. To further improve condition fidelity and training efficiency, we introduce a representation alignment loss that aligns condition embeddings with early diffusion features. Extensive experiments demonstrate that DivControl achieves state-of-the-art controllability with 36.4$\times$ less training cost, while simultaneously improving average performance on basic conditions. It also delivers strong zero-shot and few-shot performance on unseen conditions, demonstrating superior scalability, modularity, and transferability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23616v1" target="_blank">Active Filaments on Curved Surfaces: From Single Filaments to Dilute Suspensions</a></h3>
                    <p><strong>Authors:</strong> Giulia Janzen, Euan D. Mackay, Rastko Sknepnek, D. A. Matoz-Fernandez</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft</p>
                    <p><strong>Summary:</strong> Curvature plays a central organizational role in active polymer dynamics. Using large-scale Langevin-dynamics simulations, we study active semiflexible filaments confined to smooth curved surfaces and map how curvature, bending rigidity, and activity interact. We find geodesic alignment, curvature lensing, and curvature-induced trapping. In particular, regions of negative Gaussian curvature localize filaments and hinder global surface exploration. These results show how surface geometry can be used to control the organization and transport of active matter on curved substrates</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23611v1" target="_blank">LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora</a></h3>
                    <p><strong>Authors:</strong> Estelle Ruellan, Eric Clay, Nicholas Ascoli</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Infostealers exfiltrate credentials, session cookies, and sensitive data from infected systems. With over 29 million stealer logs reported in 2024, manual analysis and mitigation at scale are virtually unfeasible/unpractical. While most research focuses on proactive malware detection, a significant gap remains in leveraging reactive analysis of stealer logs and their associated artifacts. Specifically, infection artifacts such as screenshots, image captured at the point of compromise, are largely overlooked by the current literature. This paper introduces a novel approach leveraging Large Language Models (LLMs), more specifically gpt-4o-mini, to analyze infection screenshots to extract potential Indicators of Compromise (IoCs), map infection vectors, and track campaigns. Focusing on the Aurora infostealer, we demonstrate how LLMs can process screenshots to identify infection vectors, such as malicious URLs, installer files, and exploited software themes. Our method extracted 337 actionable URLs and 246 relevant files from 1000 screenshots, revealing key malware distribution methods and social engineering tactics. By correlating extracted filenames, URLs, and infection themes, we identified three distinct malware campaigns, demonstrating the potential of LLM-driven analysis for uncovering infection workflows and enhancing threat intelligence. By shifting malware analysis from traditional log-based detection methods to a reactive, artifact-driven approach that leverages infection screenshots, this research presents a scalable method for identifying infection vectors and enabling early intervention.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23608v1" target="_blank">Medical Image De-Identification Benchmark Challenge</a></h3>
                    <p><strong>Authors:</strong> Linmin Pei, Granger Sutton, Michael Rutherford, Ulrike Wagner, Tracy Nolan, Kirk Smith, Phillip Farmer, Peter Gu, Ambar Rana, Kailing Chen, Thomas Ferleman, Brian Park, Ye Wu, Jordan Kojouharov, Gargi Singh, Jon Lemon, Tyler Willis, Milos Vukadinovic, Grant Duffy, Bryan He, David Ouyang, Marco Pereanez, Daniel Samber, Derek A. Smith, Christopher Cannistraci, Zahi Fayad, David S. Mendelson, Michele Bufano, Elmar Kotter, Hamideh Haghiri, Rajesh Baidya, Stefan Dvoretskii, Klaus H. Maier-Hein, Marco Nolden, Christopher Ablett, Silvia Siggillino, Sandeep Kaushik, Hongzhu Jiang, Sihan Xie, Zhiyu Wan, Alex Michie, Simon J Doran, Angeline Aurelia Waly, Felix A. Nathaniel Liang, Humam Arshad Mustagfirin, Michelle Grace Felicia, Kuo Po Chih, Rahul Krish, Ghulam Rasool, Nidhal Bouaynaya, Nikolas Koutsoubis, Kyle Naddeo, Kartik Pandit, Tony OSullivan, Raj Krish, Qinyan Pan, Scott Gustafson, Benjamin Kopchick, Laura Opsahl-Ong, Andrea Olvera-Morales, Jonathan Pinney, Kathryn Johnson, Theresa Do, Juergen Klenk, Maria Diaz, Arti Singh, Rong Chai, David A. Clunie, Fred Prior, Keyvan Farahani</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CR</p>
                    <p><strong>Summary:</strong> The de-identification (deID) of protected health information (PHI) and personally identifiable information (PII) is a fundamental requirement for sharing medical images, particularly through public repositories, to ensure compliance with patient privacy laws. In addition, preservation of non-PHI metadata to inform and enable downstream development of imaging artificial intelligence (AI) is an important consideration in biomedical research. The goal of MIDI-B was to provide a standardized platform for benchmarking of DICOM image deID tools based on a set of rules conformant to the HIPAA Safe Harbor regulation, the DICOM Attribute Confidentiality Profiles, and best practices in preservation of research-critical metadata, as defined by The Cancer Imaging Archive (TCIA). The challenge employed a large, diverse, multi-center, and multi-modality set of real de-identified radiology images with synthetic PHI/PII inserted. The MIDI-B Challenge consisted of three phases: training, validation, and test. Eighty individuals registered for the challenge. In the training phase, we encouraged participants to tune their algorithms using their in-house or public data. The validation and test phases utilized the DICOM images containing synthetic identifiers (of 216 and 322 subjects, respectively). Ten teams successfully completed the test phase of the challenge. To measure success of a rule-based approach to image deID, scores were computed as the percentage of correct actions from the total number of required actions. The scores ranged from 97.91% to 99.93%. Participants employed a variety of open-source and proprietary tools with customized configurations, large language models, and optical character recognition (OCR). In this paper we provide a comprehensive report on the MIDI-B Challenges design, implementation, results, and lessons learned.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23600v1" target="_blank">EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution</a></h3>
                    <p><strong>Authors:</strong> Yu-Tang Chang, Shih-Fang Chen</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CE, G.1.6; G.3; G.4; I.6.5</p>
                    <p><strong>Summary:</strong> Signal unmixing analysis decomposes data into basic patterns and is widely applied in chemical and biological research. Multivariate curve resolution (MCR), a branch of signal unmixing, separates mixed chemical signals into base patterns (components) and their concentrations, playing a key role in understanding composition. Classical MCR is typically framed as matrix factorization (MF) and requires a user-specified component count, usually unknown in real data. As dataset size or component count increases, the scalability and reliability of MF-based MCR face significant challenges. This study reformulates MCR as a generative process (gMCR), and introduces an energy-based deep learning solver, EB-gMCR, that automatically discovers the smallest component set able to reconstruct the data faithfully. EB-gMCR starts from a large candidate pool (e.g., 1024 spectra) and employs a differentiable gating network to retain only active components while estimating their concentrations. On noisy synthetic datasets containing up to 256 latent sources, EB-gMCR maintained R^2 = 0.98 and recovered the component count within 5% of the ground truth; at lower noise it achieved R^2 = 0.99 with near exact component estimation. Additional chemical priors, such as non-negativity or nonlinear mixing, enter as simple plug-in functions, enabling adaptation to other instruments or domains without altering the core learning process. By uniting high-capacity generative modeling and hard component selection, EB-gMCR offers a practical route to large-scale signal unmixing analysis, including chemical library-driven scenarios. The source code is available at https://github.com/b05611038/ebgmcr_solver.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23598v1" target="_blank">Fast prediction of the hydrodynamic QGP evolution in ultra-relativistic heavy-ion collisions using Fourier Neural Operators</a></h3>
                    <p><strong>Authors:</strong> David Stewart, Joern Putschke</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> nucl-th, hep-ex</p>
                    <p><strong>Summary:</strong> Recent research in machine learning has employed neural networks to learn mappings between function spaces on bounded domains termed ``neural operators. As such, these operators can provide alternatives to standard numerical methods for partial differential equation (PDE) solutions. In particular, the Fourier Neural Operator (FNO) has been shown to map solutions for classical fluid flow problems with accuracy competitive with traditional PDE solvers and with much greater computing speed. This paper explores the first application of FNOs to model ultra-relativistic hydrodynamic flow of the quark-gluon plasma (QGP) generated in relativistic heavy-ion collisions. The application in ultra-relativistic flow is novel relative to classical flow, due to the hydrodynamic evolution of the QGP occurring in femtometer-scaled explosions characterized by rapid expansion cooling. In this study we investigate the applicability of FNOs as computationally fast alternatives to standard numerical PDE solvers. The FNO predictions are evaluated by comparing to standard PDE solutions, using \MUSIC in the \JETSCAPE Monte Carlo event generator framework. The performance of calculating established experimental observables for flow and jet quenching using FNOs in the MC framework are also reported.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23589v1" target="_blank">Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study</a></h3>
                    <p><strong>Authors:</strong> Kai Goebel, Patrik Zips</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models have sparked interest in their potential for robotic task planning. While these models demonstrate strong generative capabilities, their effectiveness in producing structured and executable plans remains uncertain. This paper presents a systematic evaluation of a broad spectrum of current state of the art language models, each directly prompted using Planning Domain Definition Language domain and problem files, and compares their planning performance with the Fast Downward planner across a variety of benchmarks. In addition to measuring success rates, we assess how faithfully the generated plans translate into sequences of actions that can actually be executed, identifying both strengths and limitations of using these models in this setting. Our findings show that while the models perform well on simpler planning tasks, they continue to struggle with more complex scenarios that require precise resource management, consistent state tracking, and strict constraint compliance. These results underscore fundamental challenges in applying language models to robotic planning in real world environments. By outlining the gaps that emerge during execution, we aim to guide future research toward combined approaches that integrate language models with classical planners in order to enhance the reliability and scalability of planning in autonomous robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23575v1" target="_blank">Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation</a></h3>
                    <p><strong>Authors:</strong> Sobhan Asasi, Mohamed Ilyas Lakhal, Ozge Mercanoglu Sincan, Richard Bowden</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Sign Language Translation (SLT) is a challenging task that requires bridging the modality gap between visual and linguistic information while capturing subtle variations in hand shapes and movements. To address these challenges, we introduce \textbf{BeyondGloss}, a novel gloss-free SLT framework that leverages the spatio-temporal reasoning capabilities of Video Large Language Models (VideoLLMs). Since existing VideoLLMs struggle to model long videos in detail, we propose a novel approach to generate fine-grained, temporally-aware textual descriptions of hand motion. A contrastive alignment module aligns these descriptions with video features during pre-training, encouraging the model to focus on hand-centric temporal dynamics and distinguish signs more effectively. To further enrich hand-specific representations, we distill fine-grained features from HaMeR. Additionally, we apply a contrastive loss between sign video representations and target language embeddings to reduce the modality gap in pre-training. \textbf{BeyondGloss} achieves state-of-the-art performance on the Phoenix14T and CSL-Daily benchmarks, demonstrating the effectiveness of the proposed framework. We will release the code upon acceptance of the paper.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23574v1" target="_blank">Unveiling ZIF-8 nucleation mechanisms through molecular simulation: role of temperature, solvent and reactant concentration</a></h3>
                    <p><strong>Authors:</strong> Sahar Andarzi Gargari, Rocio Semino</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph</p>
                    <p><strong>Summary:</strong> Synthesizing new metal-organic frameworks (MOFs) is a challenging task, as the size, morphology, polymorph and type and number of defects present on the synthesis product may depend on many variables, including temperature, solvent, concentration and nature of reactants, among others. A deeper understanding on how synthesis conditions determine the obtained material is crucial to optimize the use of resources when synthesizing new MOFs. In this contribution, we study the impact of changing concentration, solvent and temperature on the molecular level mechanisms of the solvothermal nucleation process of ZIF-8 relying on molecular dynamics simulations using a force field that incorporates metal-ligand reactivity. We find that the nucleation is faster when the synthesis is performed in dimethylsulfoxide than when it is performed in methanol, in alignment with experimental observations. In the early steps of the nucleation process, we observe the formation of linear oligomers containing metal ions and ligands, which start forming cycles later on. All simulations lead to the formation of a final state that is highly-connected and partially amorphous, which could be correlated to an intermediate species observed in direct experiments. The mechanism of formation of this phase mainly consists of the merging of smaller nuclei. Even though increasing temperature and the reactants concentration lead to a similar nucleation speedup, there are differences in ring populations and lifetimes within the highly-connected amorphous intermediate phases that are formed in each case. Finally, important differences in the free energy of Zn-2-methylimidazolate versus Zn-imidazolate subsequent binding events are revealed and discussed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23569v1" target="_blank">Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization</a></h3>
                    <p><strong>Authors:</strong> Maxime Pietrantoni, Gabriela Csurka, Torsten Sattler</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Visual localization is the task of estimating a camera pose in a known environment. In this paper, we utilize 3D Gaussian Splatting (3DGS)-based representations for accurate and privacy-preserving visual localization. We propose Gaussian Splatting Feature Fields (GSFFs), a scene representation for visual localization that combines an explicit geometry model (3DGS) with an implicit feature field. We leverage the dense geometric information and differentiable rasterization algorithm from 3DGS to learn robust feature representations grounded in 3D. In particular, we align a 3D scale-aware feature field and a 2D feature encoder in a common embedding space through a contrastive framework. Using a 3D structure-informed clustering procedure, we further regularize the representation learning and seamlessly convert the features to segmentations, which can be used for privacy-preserving visual localization. Pose refinement, which involves aligning either feature maps or segmentations from a query image with those rendered from the GSFFs scene representation, is used to achieve localization. The resulting privacy- and non-privacy-preserving localization pipelines, evaluated on multiple real-world datasets, show state-of-the-art performances.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23565v1" target="_blank">Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI</a></h3>
                    <p><strong>Authors:</strong> Botao Zhu, Xianbin Wang, Dusit Niyato</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> In collaborative systems, the effective completion of tasks hinges on task-specific trust evaluations of potential devices for distributed collaboration. However, the complexity of tasks, the spatiotemporal dynamism of distributed device resources, and the inevitable assessment overhead dramatically increase the complexity and resource consumption of the trust evaluation process. As a result, ill-timed or overly frequent trust evaluations can reduce utilization rate of constrained resources, negatively affecting collaborative task execution. To address this challenge, this paper proposes an autonomous trust orchestration method based on a new concept of semantic chain-of-trust. Our technique employs agentic AI and hypergraph to establish and maintain trust relationships among devices. By leveraging its strengths in autonomous perception, task decomposition, and semantic reasoning, we propose agentic AI to perceive device states and autonomously perform trust evaluations of collaborators based on historical performance data only during device idle periods, thereby enabling efficient utilization of distributed resources. In addition, agentic AI performs task-specific trust evaluations on collaborator resources by analyzing the alignment between resource capabilities and task requirements. Moreover, by maintaining a trust hypergraph embedded with trust semantics for each device, agentic AI enables hierarchical management of collaborators and identifies collaborators requiring trust evaluation based on trust semantics, thereby achieving a balance between overhead and trust accuracy. Furthermore, local trust hypergraphs from multiple devices can be chained together to support multi-hop collaboration, enabling efficient coordination in large-scale systems. Experimental results demonstrate that the proposed method achieves resource-efficient trust evaluation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23555v1" target="_blank">Magnetic and magnetocaloric properties of the amorphous Tb$_{31}$Co$_{69}$ and Dy$_{31}$Co$_{69}$ thin films deposited on Si substrates</a></h3>
                    <p><strong>Authors:</strong> P. Skokowski, M. Matczak, Å. FrÄ…ckowiak, T. Bednarchuk, M. Kowacz, B. Anastaziak, K. Synoradzki</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> We present the structural, magnetic, and magnetocaloric properties of amorphous thin films Tb-Co and Dy-Co with stoichiometry Tb$_{31}$Co$_{69}$ and Dy$_{31}$Co$_{69}$, deposited on naturally oxidized silicon Si (100) substrates. Samples with a thickness $d=50$ nm covered with a protective Au overlayer with a thickness $d_{\rm Au} =5 $ nm were produced using the pulsed laser deposition technique. The X-ray diffraction analysis indicated the presence of a crystallized Laves phase in the prepared materials. Magnetization measurements as a function of temperature revealed ferrimagnetic behavior in both samples. We estimated the compensation temperature $T_{\rm comp}$ of the amorphous phase for Tb$_{31}$Co$_{69}$ at 81.5 K and for Dy$_{31}$Co$_{69}$ at 88.5 K, while we found the Curie temperature $T_{\rm C,\ Laves}$ of the crystallized Laves phases at 204.5 K and at 117 K, respectively. We investigated the magnetocaloric effect in a wide temperature range, covering $T_{\rm comp}$ of amorphous phases and $T_{\rm C,\ Laves}$ of crystallized Laves phases. The analysis for the magnetic field change of $\Delta \mu_0H=5$ T showed values of the magnetic entropy change of $-\Delta S_{\rm M}=4.9$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm comp}$ and $-\Delta S_{\rm M}=6.6$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm C,\ Laves}$ for Tb$_{31}$Co$_{69}$, while for Dy$_{31}$Co$_{69}$, we determined the values of $-\Delta S_{\rm M}=35$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm comp}$ and $-\Delta S_{\rm M}=28$ mJ cm$^{-3}$ K$^{-1}$ at $T_{\rm C,\ Laves}$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23552v1" target="_blank">Latest neutrino results from the FASER experiment and their implications for forward hadron production</a></h3>
                    <p><strong>Authors:</strong> FASER Collaboration, Roshan Mammen Abraham, Xiaocong Ai, Saul Alonso Monsalve, John Anders, Claire Antel, Akitaka Ariga, Tomoko Ariga, Jeremy Atkinson, Florian U. Bernlochner, Tobias Boeckh, Jamie Boyd, Lydia Brenner, Angela Burger, Franck Cadoux, Roberto Cardella, David W. Casper, Charlotte Cavanagh, Xin Chen, Dhruv Chouhan, Andrea Coccaro, Stephane DÃ©bieux, Ansh Desai, Sergey Dmitrievsky, Radu Dobre, Monica DOnofrio, Sinead Eley, Yannick Favre, Jonathan L. Feng, Carlo Alberto Fenoglio, Didier Ferrere, Max Fieg, Wissal Filali, Elena Firu, Haruhi Fujimori, Edward Galantay, Ali Garabaglu, Stephen Gibson, Sergio Gonzalez-Sevilla, Yuri Gornushkin, Yotam Granov, Carl Gwilliam, Daiki Hayakawa, Michael Holzbock, Shih-Chieh Hsu, Zhen Hu, Giuseppe Iacobucci, Tomohiro Inada, Luca Iodice, Sune Jakobsen, Hans Joos, Enrique Kajomovitz, Hiroaki Kawahara, Alex Keyken, Felix Kling, Daniela KÃ¶ck, Pantelis Kontaxakis, Umut Kose, Rafaella Kotitsa, Peter Krack, Susanne Kuehn, Thanushan Kugathasan, Sebastian Laudage, Lorne Levinson, Botao Li, Jinfeng Liu, Yi Liu, Margaret S. Lutz, Jack MacDonald, Chiara Magliocca, Toni MÃ¤kelÃ¤, Lawson McCoy, Josh McFayden, Andrea Pizarro Medina, Matteo Milanesio, ThÃ©o Moretti, Keiko Moriyama, Mitsuhiro Nakamura, Toshiyuki Nakano, Laurie Nevay, Ken Ohashi, Hidetoshi Otono, Lorenzo Paolozzi, Pawan Pawan, Brian Petersen, Titi Preda, Markus Prim, Michaela Queitsch-Maitland, Juan Rojo, Hiroki Rokujo, AndrÃ© Rubbia, Jorge Sabater-Iglesias, Osamu Sato, Paola Scampoli, Kristof Schmieden, Matthias Schott, Christiano Sebastiani, Anna Sfyrla, Davide Sgalaberna, Mansoora Shamim, Savannah Shively, Yosuke Takubo, Noshin Tarannum, Ondrej Theiner, Simon Thor, Eric Torrence, Oscar Ivan Valdes Martinez, Svetlana Vasina, Benedikt Vormwald, Yuxiao Wang, Eli Welch, Monika Wielers, Benjamin James Wilson, Jialin Wu, Johannes Martin Wuthrich, Yue Xu, Daichi Yoshikawa, Stefano Zambito, Shunliang Zhang, Xingyu Zhao</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> The muon puzzle -- an excess of muons relative to simulation predictions in ultra-high-energy cosmic-ray air showers -- has been reported by many experiments. This suggests that forward particle production in hadronic interactions is not fully understood. Some of the scenarios proposed to resolve this predict reduced production of forward neutral pions and enhanced production of forward kaons (or other particles). The FASER experiment at the LHC is located 480 m downstream of the ATLAS interaction point and is sensitive to neutrinos and muons, which are the decay products of forward charged pions and kaons. In this study, the latest measurements of electron and muon neutrino fluxes are presented using the data corresponding to 9.5 $\mathrm{fb^{-1}}$ and 65.6 $\mathrm{fb^{-1}}$ of proton-proton collisions with $\sqrt{s}=13.6~\mathrm{TeV}$ by the FASER$\nu$ and the FASER electronic detector, respectively. These fluxes are compared with predictions from recent hadronic interaction models, including EPOS-LHCr, SIBYLL 2.3e, and QGSJET 3. The predictions are generally consistent with the measured fluxes from FASER, although some discrepancies appear in certain energy bins. More precise flux measurements with additional data will follow soon, enabling validation of pion, kaon, and charm meson production with finer energy binning, reduced uncertainties, and multi-differential analyses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23548v1" target="_blank">A decomposition of Fishers information to inform sample size for developing or updating fair and precise clinical prediction models -- Part 3: continuous outcomes</a></h3>
                    <p><strong>Authors:</strong> Rebecca Whittle, Richard D Riley, Lucinda Archer, Gary S Collins, Amardeep Legha, Kym IE Snell, Joie Ensor</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ME</p>
                    <p><strong>Summary:</strong> Clinical prediction models enable healthcare professionals to estimate individual outcomes using patient characteristics. Current sample size guidelines for developing or updating models with continuous outcomes aim to minimise overfitting and ensure accurate estimation of population-level parameters, but do not explicitly address the precision of predictions. This is a critical limitation, as wide confidence intervals around predictions can undermine clinical utility and fairness, particularly if precision varies across subgroups. We propose methodology for calculating the sample size required to ensure precise and fair predictions in models with continuous outcomes. Building on linear regression theory and the Fishers unit information matrix, our approach calculates how sample size impacts the epistemic (model-based) uncertainty of predictions and allows researchers to either (i) evaluate whether an existing dataset is sufficiently large, or (ii) determine the sample size needed to target a particular confidence interval width around predictions. The method requires real or synthetic data representing the target population. To assess fairness,the approach can evaluate prediction precision across subgroups. Extensions to prediction intervals are included to additionally address aleatoric uncertainty. Our methodology provides a practical framework for examining required sample sizes when developing or updating prediction models with continuous outcomes, focusing on achieving precise and equitable predictions. It supports the development of more reliable and fair models, enhancing their clinical applicability and trustworthiness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23541v1" target="_blank">Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Keer Lu, Zheng Liang, Youquan Li, Jiejun Tan, Da Pan, Shusen Zhang, Guosheng Dong, Huang Leng</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In medical scenarios, effectively retrieving external knowledge and leveraging it for rigorous logical reasoning is of significant importance. Despite their potential, existing work has predominantly focused on enhancing either retrieval or reasoning capabilities of the models in isolation, with little attention given to their joint optimization, which leads to limited coordination between the two processes. Additionally, current methods rely heavily on supervised fine-tuning (SFT), which can cause models to memorize existing problem-solving pathways, thereby restricting their generalization ability when confronted with novel problem contexts. Furthermore, while some studies have explored to improve retrieval-augmented reasoning in general domains via reinforcement learning, their reward function designs do not adequately capture the specific demands of the medical domain. To address these challenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented **R**easoning framework driven by progressive **R**einforcement learning. In this framework, we first develop the models ability to perform logical reasoning over medical problems. Subsequently, on the basis of this foundation, we adaptively optimize the retrieval capability to better align with the characteristics of knowledge corpus and external information utilization throughout the reasoning process. Finally, we conduct joint optimization of the models retrieval and reasoning coordination. Extensive experiments indicate that **Med-R$^3$** could achieve state-of-the-art performances, with LLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by 3.93\% at a comparable parameter scale, while Qwen2.5-14B augmented with Med-R$^3$ shows a more substantial gain of 13.53\%.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23536v1" target="_blank">From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices</a></h3>
                    <p><strong>Authors:</strong> Georg Slamanig, Francesco Corti, Olga Saukh</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs of updating deep learning models by minimizing the number of additional parameters used to adapt a model to a down- stream task. While extensively researched in large language models (LLMs), their application to smaller models used on edge devices, such as convolutional neural networks, remains underexplored. This paper benchmarks and analyzes popular PEFT methods on convolutional architectures typically deployed in resource-constrained edge environments. We evaluate LoRA, DoRA, and GaLore for updating standard and depthwise convolutional architectures to handle distribution shifts and accommodate unseen classes. We utilize recently proposed PyTorch profilers to compare the updated model performance and computational costs of these PEFT methods with traditional fine-tuning approaches. With resource efficiency in mind, we investigate their update behavior across different rank dimensions. We find that the evaluated PEFT methods are only half as memory-efficient when applied to depthwise-separable convolution architectures, compared to their efficiency with LLMs. Conversely, when targeting convolu- tional architectures optimized for edge deployment, adapter-based PEFT methods can reduce floating point operations (FLOPs) during model updates by up to 95%. These insights offer valuable guidance for selecting PEFT methods based on hardware constraints, performance requirements, and application needs. Our code is online.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23535v1" target="_blank">Transparent AI: The Case for Interpretability and Explainability</a></h3>
                    <p><strong>Authors:</strong> Dhanesh Ramachandram, Himanshu Joshi, Judy Zhu, Dhari Gandhi, Lucas Hartman, Ananya Raval</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> As artificial intelligence systems increasingly inform high-stakes decisions across sectors, transparency has become foundational to responsible and trustworthy AI implementation. Leveraging our role as a leading institute in advancing AI research and enabling industry adoption, we present key insights and lessons learned from practical interpretability applications across diverse domains. This paper offers actionable strategies and implementation guidance tailored to organizations at varying stages of AI maturity, emphasizing the integration of interpretability as a core design principle rather than a retrospective add-on.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23532v1" target="_blank">Viscosity variation in fluid flows across scale</a></h3>
                    <p><strong>Authors:</strong> Arjun Sharma, Ritabrata Thakur, Sharath Jose, Rama Govindarajan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, cond-mat.soft</p>
                    <p><strong>Summary:</strong> A wide range of natural and engineered fluid flows exhibit spatial or temporal viscosity variations, spanning scales from microbial locomotion to planetary mantle convection. These variations introduce qualitatively new physical mechanisms absent in constant-viscosity flows. This review surveys such phenomena across scales. In low Reynolds number (Stokes) flows, viscosity gradients couple translation and rotation, enabling novel particle responses to uniform forcing-- mechanisms that microorganisms may exploit. In shear flows, viscosity variation alters base flow profiles and breaks symmetries, modifying stability and transition dynamics. At high Reynolds numbers, stratification fundamentally changes the singular perturbation structure governing energy production, enhancing or suppressing canonical instabilities and introducing new ones. Viscosity variation also affects nonnormal growth and nonlinear interactions that drive transition to turbulence. While laminar and fully developed turbulence have been extensively studied, transitional processes remain poorly understood in variable-viscosity flows. In turbulent regimes, viscosity variation impacts jets, wall-bounded flows, and mixing layers. At geophysical scales, incorporating eddy viscosity stratification in climate models may improve predictions, while in Earths mantle, viscosity contrasts drive large-scale convection and geological evolution. Particle-laden flows, common across contexts, can generate effective viscosity stratification through inhomogeneous loading. Throughout, we highlight cases where viscosity variation alters flow behavior qualitatively, and point to open questions. This review aims to guide graduate students and researchers toward tractable, cross-disciplinary problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23528v1" target="_blank">Hybrid Generative Semantic and Bit Communications in Satellite Networks: Trade-offs in Latency, Generation Quality, and Computation</a></h3>
                    <p><strong>Authors:</strong> Chong Huang, Gaojie Chen, Jing Zhu, Qu Luo, Pei Xiao, Wei Huang, Rahim Tafazolli</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> As satellite communications play an increasingly important role in future wireless networks, the issue of limited link budget in satellite systems has attracted significant attention in current research. Although semantic communications emerge as a promising solution to address these constraints, it introduces the challenge of increased computational resource consumption in wireless communications. To address these challenges, we propose a multi-layer hybrid bit and generative semantic communication framework which can adapt to the dynamic satellite communication networks. Furthermore, to balance the semantic communication efficiency and performance in satellite-to-ground transmissions, we introduce a novel semantic communication efficiency metric (SEM) that evaluates the trade-offs among latency, computational consumption, and semantic reconstruction quality in the proposed framework. Moreover, we utilize a novel deep reinforcement learning (DRL) algorithm group relative policy optimization (GRPO) to optimize the resource allocation in the proposed network. Simulation results demonstrate the flexibility of our proposed transmission framework and the effectiveness of the proposed metric SEM, illustrate the relationships among various semantic communication metrics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23526v1" target="_blank">Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey</a></h3>
                    <p><strong>Authors:</strong> Wen-Xuan Long, Shengyu Ye, Marco Moretti, Michele Morelli, Luca Sanguinetti, Rui Chen, Cheng-Xiang Wang</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.SP, cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> The sixth-generation (6G) wireless systems are expected to adopt extremely large aperture arrays (ELAAs), novel antenna architectures, and operate in extremely high-frequency bands to meet growing data demands. ELAAs significantly increase the number of antennas, enabling finer spatial resolution and improved beamforming. At high frequencies, ELAAs shift communication from the conventional far-field to near-field regime, where spherical wavefronts dominate and the channel response depends on both angle and distance, increasing channel dimensionality. Conventional far-field channel estimation methods, which rely on angular information, struggle in near-field scenarios due to increased pilot overhead and computational complexity. This paper presents a comprehensive survey of recent advances in near-field channel estimation. It first defines the near- and far-field boundary from an electromagnetic perspective and discusses key propagation differences, alongside a brief review of ELAA developments. Then, it introduces mainstream near-field channel models and compares them with far-field models. Major estimation techniques are reviewed under different configurations (single/multi-user, single/multi-carrier), including both direct estimation and RIS-assisted cascaded estimation. These techniques reveal trade-offs among estimation accuracy, complexity, and overhead. This survey aims to provide insights and foundations for efficient and scalable near-field channel estimation in 6G systems, while identifying key challenges and future research directions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23511v1" target="_blank">MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks</a></h3>
                    <p><strong>Authors:</strong> Yadong Niu, Tianzi Wang, Heinrich Dinkel, Xingwei Sun, Jiahao Zhou, Gang Li, Jizhong Liu, Xunying Liu, Junbo Zhang, Jian Luan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.AS, cs.AI, cs.CL, cs.SD</p>
                    <p><strong>Summary:</strong> While large audio-language models have advanced open-ended audio understanding, they still fall short of nuanced human-level comprehension. This gap persists largely because current benchmarks, limited by data annotations and evaluation metrics, fail to reliably distinguish between generic and highly detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via a pipeline that integrates analysis from specialized expert models with Chain-of-Thought large language model reasoning, MECAT provides multi-perspective, fine-grained captions and open-set question-answering pairs. The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced Audio Text Evaluation). This metric penalizes generic terms and rewards detailed descriptions by combining single-sample semantic similarity with cross-sample discriminability. A comprehensive evaluation of state-of-the-art audio models is also presented, providing new insights into their current capabilities and limitations. The data and code are available at https://github.com/xiaomi-research/mecat</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23508v1" target="_blank">Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion</a></h3>
                    <p><strong>Authors:</strong> Timing Li, Bing Cao, Jiahe Feng, Haifang Cao, Qinghau Hu, Pengfei Zhu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Image fusion synthesizes complementary information from multiple sources, mitigating the inherent limitations of unimodal imaging systems. Accurate image registration is essential for effective multi-source data fusion. However, existing registration methods, often based on image translation in Euclidean space, fail to handle cross-modal misalignment effectively, resulting in suboptimal alignment and fusion quality. To overcome this limitation, we explore image alignment in non-Euclidean space and propose a Hyperbolic Cycle Alignment Network (Hy-CycleAlign). To the best of our knowledge, Hy-CycleAlign is the first image registration method based on hyperbolic space. It introduces a dual-path cross-modal cyclic registration framework, in which a forward registration network aligns cross-modal inputs, while a backward registration network reconstructs the original image, forming a closed-loop registration structure with geometric consistency. Additionally, we design a Hyperbolic Hierarchy Contrastive Alignment (H$^{2}$CA) module, which maps images into hyperbolic space and imposes registration constraints, effectively reducing interference caused by modality discrepancies. We further analyze image registration in both Euclidean and hyperbolic spaces, demonstrating that hyperbolic space enables more sensitive and effective multi-modal image registration. Extensive experiments on misaligned multi-modal images demonstrate that our method significantly outperforms existing approaches in both image alignment and fusion. Our code will be publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23492v1" target="_blank">Digital literacy interventions can boost humans in discerning deepfakes</a></h3>
                    <p><strong>Authors:</strong> Dominique Geissler, Claire Robertson, Stefan Feuerriegel</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> Deepfakes, i.e., images generated by artificial intelligence (AI), can erode trust in institutions and compromise election outcomes, as people often struggle to discern real images from deepfakes. Improving digital literacy can help address these challenges, yet scalable and effective approaches remain largely unexplored. Here, we compare the efficacy of five digital literacy interventions to boost peoples ability to discern deepfakes: (1) textual guidance on common indicators of deepfakes; (2) visual demonstrations of these indicators; (3) a gamified exercise for identifying deepfakes; (4) implicit learning through repeated exposure and feedback; and (5) explanations of how deepfakes are generated with the help of AI. We conducted an experiment with N=1,200 participants from the United States to test the immediate and long-term effectiveness of our interventions. Our results show that our interventions can boost deepfake discernment by up to 13 percentage points while maintaining trust in real images. Altogether, our approach is scalable, suitable for diverse populations, and highly effective for boosting deepfake detection while maintaining trust in truthful information.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23787v1" target="_blank">Amplitude amplification and estimation require inverses</a></h3>
                    <p><strong>Authors:</strong> Ewin Tang, John Wright</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.CC, cs.DS</p>
                    <p><strong>Summary:</strong> We prove that the generic quantum speedups for brute-force search and counting only hold when the process we apply them to can be efficiently inverted. The algorithms speeding up these problems, amplitude amplification and amplitude estimation, assume the ability to apply a state preparation unitary $U$ and its inverse $U^\dagger$; we give problem instances based on trace estimation where no algorithm which uses only $U$ beats the naive, quadratically slower approach. Our proof of this is simple and goes through the compressed oracle method introduced by Zhandry. Since these two subroutines are responsible for the ubiquity of the quadratic Grover speedup in quantum algorithms, our result explains why such speedups are far harder to come by in the settings of quantum learning, metrology, and sensing. In these settings, $U$ models the evolution of an experimental system, so implementing $U^\dagger$ can be much harder -- tantamount to reversing time within the system. Our result suggests a dichotomy: without inverse access, quantum speedups are scarce; with it, quantum speedups abound.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23785v1" target="_blank">Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</a></h3>
                    <p><strong>Authors:</strong> Bowen Zhang, Sicheng Xu, Chuxin Wang, Jiaolong Yang, Feng Zhao, Dong Chen, Baining Guo</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this paper, we present a novel framework for video-to-4D generation that creates high-quality dynamic 3D content from single video inputs. Direct 4D diffusion modeling is extremely challenging due to costly data construction and the high-dimensional nature of jointly representing 3D shape, appearance, and motion. We address these challenges by introducing a Direct 4DMesh-to-GS Variation Field VAE that directly encodes canonical Gaussian Splats (GS) and their temporal variations from 3D animation data without per-instance fitting, and compresses high-dimensional animations into a compact latent space. Building upon this efficient representation, we train a Gaussian Variation Field diffusion model with temporal-aware Diffusion Transformer conditioned on input videos and canonical GS. Trained on carefully-curated animatable 3D objects from the Objaverse dataset, our model demonstrates superior generation quality compared to existing methods. It also exhibits remarkable generalization to in-the-wild video inputs despite being trained exclusively on synthetic data, paving the way for generating high-quality animated 3D content. Project page: https://gvfdiffusion.github.io/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23784v1" target="_blank">SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions</a></h3>
                    <p><strong>Authors:</strong> Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Concept Bottleneck Models (CBMs) and other concept-based interpretable models show great promise for making AI applications more transparent, which is essential in fields like medicine. Despite their success, we demonstrate that CBMs struggle to reliably identify the correct concepts under distribution shifts. To assess the robustness of CBMs to concept variations, we introduce SUB: a fine-grained image and concept benchmark containing 38,400 synthetic images based on the CUB dataset. To create SUB, we select a CUB subset of 33 bird classes and 45 concepts to generate images which substitute a specific concept, such as wing color or belly pattern. We introduce a novel Tied Diffusion Guidance (TDG) method to precisely control generated images, where noise sharing for two parallel denoising processes ensures that both the correct bird class and the correct attribute are generated. This novel benchmark enables rigorous evaluation of CBMs and similar interpretable models, contributing to the development of more robust methods. Our code is available at https://github.com/ExplainableML/sub and the dataset at http://huggingface.co/datasets/Jessica-bader/SUB.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23782v1" target="_blank">MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion</a></h3>
                    <p><strong>Authors:</strong> Zihan Wang, Jeff Tan, Tarasha Khurana, Neehar Peri, Deva Ramanan</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We address the problem of dynamic scene reconstruction from sparse-view videos. Prior work often requires dense multi-view captures with hundreds of calibrated cameras (e.g. Panoptic Studio). Such multi-view setups are prohibitively expensive to build and cannot capture diverse scenes in-the-wild. In contrast, we aim to reconstruct dynamic human behaviors, such as repairing a bike or dancing, from a small set of sparse-view cameras with complete scene coverage (e.g. four equidistant inward-facing static cameras). We find that dense multi-view reconstruction methods struggle to adapt to this sparse-view setup due to limited overlap between viewpoints. To address these limitations, we carefully align independent monocular reconstructions of each camera to produce time- and view-consistent dynamic scene reconstructions. Extensive experiments on PanopticStudio and Ego-Exo4D demonstrate that our method achieves higher quality reconstructions than prior art, particularly when rendering novel views. Code, data, and data-processing scripts are available on https://github.com/ImNotPrepared/MonoFusion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23783v1" target="_blank">Projected branes as platforms for crystalline, superconducting, and higher-order topological phases</a></h3>
                    <p><strong>Authors:</strong> Archisman Panigrahi, Bitan Roy</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.dis-nn, cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> Projected branes are constituted by only a small subset of sites of a higher-dimensional crystal, otherwise placed on a hyperplane oriented at an irrational or a rational slope therein, for which the effective Hamiltonian is constructed by systematically integrating out the sites of the parent lattice that fall outside such branes [Commun. Phys. 5, 230 (2022)]. Specifically, when such a brane is constructed from a square lattice, it gives rise to an aperiodic Fibonacci quasi-crystal or its rational approximant in one dimension. In this work, starting from square lattice-based models for topological crystalline insulators, protected by the discrete four-fold rotational ($C_4$) symmetry, we show that the resulting one-dimensional projected topological branes encode all the salient signatures of such phases in terms of robust endpoint zero-energy modes, quantized local topological markers, and mid-gap modes bound to dislocation lattice defects, despite such linear branes being devoid of the $C_4$ symmetry of the original lattice. Furthermore, we show that such branes can also feature all the hallmarks of two-dimensional strong and weak topological superconductors through Majorana zero-energy bound states residing near their endpoints and at the core of dislocation lattice defects, besides possessing suitable quantized local topological markers. Finally, we showcase a successful incarnation of a square lattice-based second-order topological insulator with the characteristic corner-localized zero modes in its geometric descendant one-dimensional quasi-crystalline or crystalline branes that feature a quantized localizer index and endpoint zero-energy modes only when one of its end points passes through a corner of the parent crystal. Possible designer quantum and meta material-based platforms to experimentally harness our theoretically proposed topological branes are discussed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23781v1" target="_blank">Graded Unitarity in the SCFT/VOA Correspondence</a></h3>
                    <p><strong>Authors:</strong> Arash Arabi Ardehali, Christopher Beem, Madalena Lemos, Leonardo Rastelli</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-th, math.QA, math.RT</p>
                    <p><strong>Summary:</strong> Vertex algebras that arise from four-dimensional, $\mathcal{N}=2$ superconformal field theories inherit a collection of novel structural properties from their four-dimensional ancestors. Crucially, when the parent SCFT is unitary, the corresponding vertex algebra is not unitary in the conventional sense. In this paper, we motivate and define a generalized notion of unitarity for vertex algebras that we call \emph{graded unitarity}, and which captures the consequences of four-dimensional unitarity under this correspondence. We also take the first steps towards a classification program for graded-unitary vertex algebras whose underlying vertex algebras are Virasoro or affine Kac--Moody vertex algebras. Remarkably, under certain natural assumptions about the $\mathfrak{R}$-filtration for these vertex algebras, we show that only the $(2,p)$ central charges for Virasoro VOAs and boundary admissible levels for $\mathfrak{sl}_2$ and $\mathfrak{sl}_3$ Kac--Moody vertex algebras can possibly be compatible with graded unitarity. These are precisely the cases of these vertex algebras that are known to arise from four dimensions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23780v1" target="_blank">Two-dimensional Disordered Projected Branes: Stability and Quantum Criticality via Dimensional Reduction</a></h3>
                    <p><strong>Authors:</strong> Alexander C. Tyner, Vladimir Juricic, Bitan Roy</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.dis-nn, cond-mat.mes-hall, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> The interplay of disorder and dimensionality governs the emergence and stability of electronic phases in quantum materials and quantum phase transitions among them. While three-dimensional (3D) dirty Fermi liquids and Weyl semimetals support robust metallic states, undergoing disorder-driven Anderson localization transitions at strong disorder and the later ones exhibiting additional semimetal-to-metal transition at moderate disorder, conventional two-dimensional (2D) non-interacting systems localize for arbitrarily weak disorder. Here, we show that 2D disordered projected branes, constructed by systematically integrating out degrees of freedom from a 3D cubic lattice via the Schur decomposition, faithfully reproduce the full quantum phase diagram of their 3D parent systems. Using large-scale exact diagonalization and kernel polynomial method, we numerically demonstrate that 2D projected branes host stable metallic and semimetallic phases. Remarkably, the critical exponents governing the semimetal-to-metal and metal-insulator transitions on such 2D projected branes are sufficiently close to those of their 3D counterparts. Our findings thus establish 2D projected branes as genuine quantum holographic images of their higher-dimensional disordered parent crystals, supporting stable semimetallic and metallic phases that are otherwise inaccessible in conventional 2D lattices. Finally, we point to experimentally accessible metamaterial platforms, most notably the photonic lattices with tunable refractive-index disorder, as promising systems to realize and probe these phenomena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23779v1" target="_blank">Phi-Ground Tech Report: Advancing Perception in GUI Grounding</a></h3>
                    <p><strong>Authors:</strong> Miaosen Zhang, Ziqiang Xu, Jialiang Zhu, Qi Dai, Kai Qiu, Yifan Yang, Chong Luo, Tianyi Chen, Justin Wagle, Tim Franklin, Baining Guo</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.MM</p>
                    <p><strong>Summary:</strong> With the development of multimodal reasoning models, Computer Use Agents (CUAs), akin to Jarvis from \textit{Iron Man}, are becoming a reality. GUI grounding is a core component for CUAs to execute actual actions, similar to mechanical control in robotics, and it directly leads to the success or failure of the system. It determines actions such as clicking and typing, as well as related parameters like the coordinates for clicks. Current end-to-end grounding models still achieve less than 65\% accuracy on challenging benchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from being ready for deployment. % , as a single misclick can result in unacceptable consequences. In this work, we conduct an empirical study on the training of grounding models, examining details from data collection to model training. Ultimately, we developed the \textbf{Phi-Ground} model family, which achieves state-of-the-art performance across all five grounding benchmarks for models under $10B$ parameters in agent settings. In the end-to-end model setting, our model still achieves SOTA results with scores of \textit{\textbf{43.2}} on ScreenSpot-pro and \textit{\textbf{27.2}} on UI-Vision. We believe that the various details discussed in this paper, along with our successes and failures, not only clarify the construction of grounding models but also benefit other perception tasks. Project homepage: \href{https://zhangmiaosen2000.github.io/Phi-Ground/}{https://zhangmiaosen2000.github.io/Phi-Ground/}</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23778v1" target="_blank">Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions</a></h3>
                    <p><strong>Authors:</strong> Li Siyao, Yao Feng, Omid Tehari, Chen Change Loy, Michael J. Black</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> While current general-purpose 3D human models (e.g., SMPL-X) efficiently represent accurate human shape and pose, they lacks the ability to physically interact with the environment due to the kinematic nature. As a result, kinematic-based interaction models often suffer from issues such as interpenetration and unrealistic object dynamics. To address this limitation, we introduce a novel approach that embeds SMPL-X into a tangible entity capable of dynamic physical interactions with its surroundings. Specifically, we propose a half-physics mechanism that transforms 3D kinematic motion into a physics simulation. Our approach maintains kinematic control over inherent SMPL-X poses while ensuring physically plausible interactions with scenes and objects, effectively eliminating penetration and unrealistic object dynamics. Unlike reinforcement learning-based methods, which demand extensive and complex training, our half-physics method is learning-free and generalizes to any body shape and motion; meanwhile, it operates in real time. Moreover, it preserves the fidelity of the original kinematic motion while seamlessly integrating physical interactions</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23777v1" target="_blank">XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding</a></h3>
                    <p><strong>Authors:</strong> Dian Chen, Yansong Qu, Xinyang Li, Ming Li, Shengchuan Zhang</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Current auto-regressive models can generate high-quality, topologically precise meshes; however, they necessitate thousands-or even tens of thousands-of next-token predictions during inference, resulting in substantial latency. We introduce XSpecMesh, a quality-preserving acceleration method for auto-regressive mesh generation models. XSpecMesh employs a lightweight, multi-head speculative decoding scheme to predict multiple tokens in parallel within a single forward pass, thereby accelerating inference. We further propose a verification and resampling strategy: the backbone model verifies each predicted token and resamples any tokens that do not meet the quality criteria. In addition, we propose a distillation strategy that trains the lightweight decoding heads by distilling from the backbone model, encouraging their prediction distributions to align and improving the success rate of speculative predictions. Extensive experiments demonstrate that our method achieves a 1.7x speedup without sacrificing generation quality. Our code will be released.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23776v1" target="_blank">Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities</a></h3>
                    <p><strong>Authors:</strong> Yunxiang Yan, Tomohiro Sawada, Kartik Goyal</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> While question-answering~(QA) benchmark performance is an automatic and scalable method to compare LLMs, it is an indirect method of evaluating their underlying problem-solving capabilities. Therefore, we propose a holistic and generalizable framework based on \emph{cascaded question disclosure} that provides a more accurate estimate of the models problem-solving capabilities while maintaining the scalability and automation. This approach collects model responses in a stagewise manner with each stage revealing partial information about the question designed to elicit generalized reasoning in LLMs. We find that our approach not only provides a better comparison between LLMs, but also induces better intermediate traces in models compared to the standard QA paradigm. We empirically verify this behavior on diverse reasoning and knowledge-heavy QA datasets by comparing LLMs of varying sizes and families. Our approach narrows the performance gap observed in the standard QA evaluation settings, indicating that the prevalent indirect QA paradigm of evaluation overestimates the differences in performance between models. We further validate our findings by extensive ablation studies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23773v1" target="_blank">SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model</a></h3>
                    <p><strong>Authors:</strong> Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.LG, cs.RO</p>
                    <p><strong>Summary:</strong> AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \modelname improves the success of flight search from 0\% to 32.2\%. World-model-based planning, in particular, shows consistent advantage of up to 124\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \modelname with pretrained LLMs, available as a research demo for public testing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23772v1" target="_blank">SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Di Li, Jie Feng, Jiahao Chen, Weisheng Dong, Guanbin Li, Yuhui Zheng, Mingtao Feng, Guangming Shi</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D affordance reasoning, the task of associating human instructions with the functional regions of 3D objects, is a critical capability for embodied agents. Current methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited to single-object, single-step interactions, a paradigm that falls short of addressing the long-horizon, multi-object tasks required for complex real-world applications. To bridge this gap, we introduce the novel task of Sequential 3D Gaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale benchmark featuring 1800+ scenes to support research on long-horizon affordance understanding in complex 3DGS environments. We then propose SeqSplatNet, an end-to-end framework that directly maps an instruction to a sequence of 3D affordance masks. SeqSplatNet employs a large language model that autoregressively generates text interleaved with special segmentation tokens, guiding a conditional decoder to produce the corresponding 3D mask. To handle complex scene geometry, we introduce a pre-training strategy, Conditional Geometric Reconstruction, where the model learns to reconstruct complete affordance region masks from known geometric observations, thereby building a robust geometric prior. Furthermore, to resolve semantic ambiguities, we design a feature injection mechanism that lifts rich semantic features from 2D Vision Foundation Models (VFM) and fuses them into the 3D decoder at multiple scales. Extensive experiments demonstrate that our method sets a new state-of-the-art on our challenging benchmark, effectively advancing affordance reasoning from single-step interactions to complex, sequential tasks at the scene level.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23771v1" target="_blank">Consensus-Driven Active Model Selection</a></h3>
                    <p><strong>Authors:</strong> Justin Kay, Grant Van Horn, Subhransu Maji, Daniel Sheldon, Sara Beery</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The widespread availability of off-the-shelf machine learning models poses a challenge: which model, of the many available candidates, should be chosen for a given data analysis task? This question of model selection is traditionally answered by collecting and annotating a validation dataset -- a costly and time-intensive process. We propose a method for active model selection, using predictions from candidate models to prioritize the labeling of test data points that efficiently differentiate the best candidate. Our method, CODA, performs consensus-driven active model selection by modeling relationships between classifiers, categories, and data points within a probabilistic framework. The framework uses the consensus and disagreement between models in the candidate pool to guide the label acquisition process, and Bayesian inference to update beliefs about which model is best as more information is collected. We validate our approach by curating a collection of 26 benchmark tasks capturing a range of model selection scenarios. CODA outperforms existing methods for active model selection significantly, reducing the annotation effort required to discover the best model by upwards of 70% compared to the previous state-of-the-art. Code and data are available at https://github.com/justinkay/coda.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23770v1" target="_blank">Transport-Induced Decoherence of the Entangled Triplet Exciton Pair</a></h3>
                    <p><strong>Authors:</strong> Gerald Curran III, Luke J. Weaver, Zachary Rex, Ivan Biaggio</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.mes-hall, physics.optics</p>
                    <p><strong>Summary:</strong> Decoherence effects for entangled triplet pairs in organic molecular crystals are analyzed for the case when excitons can hop between inequivalent lattice sites. The fluorescence quantum beats caused by quantum interference upon triplet-triplet recombination into an emissive singlet state are predicted as a function of hopping time and magnetic field based on a Monte Carlo analysis. Depending on exciton hopping rates, it is possible to have complete global decoherence and suppression of fluorescence quantum beats in the limit of zero magnetic field, and to have quantum beats that decay at different rates depending on magnetic field strength.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23768v1" target="_blank">Formal Bayesian Transfer Learning via the Total Risk Prior</a></h3>
                    <p><strong>Authors:</strong> Nathan Wycoff, Ali Arab, Lisa O. Singh</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> In analyses with severe data-limitations, augmenting the target dataset with information from ancillary datasets in the application domain, called source datasets, can lead to significantly improved statistical procedures. However, existing methods for this transfer learning struggle to deal with situations where the source datasets are also limited and not guaranteed to be well-aligned with the target dataset. A typical strategy is to use the empirical loss minimizer on the source data as a prior mean for the target parameters, which places the estimation of source parameters outside of the Bayesian formalism. Our key conceptual contribution is to use a risk minimizer conditional on source parameters instead. This allows us to construct a single joint prior distribution for all parameters from the source datasets as well as the target dataset. As a consequence, we benefit from full Bayesian uncertainty quantification and can perform model averaging via Gibbs sampling over indicator variables governing the inclusion of each source dataset. We show how a particular instantiation of our prior leads to a Bayesian Lasso in a transformed coordinate system and discuss computational techniques to scale our approach to moderately sized datasets. We also demonstrate that recently proposed minimax-frequentist transfer learning techniques may be viewed as an approximate Maximum a Posteriori approach to our model. Finally, we demonstrate superior predictive performance relative to the frequentist baseline on a genetics application, especially when the source data are limited.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23765v1" target="_blank">Intrinsic Heralding and Optimal Decoders for Non-Abelian Topological Order</a></h3>
                    <p><strong>Authors:</strong> Dian Jing, Pablo Sala, Liang Jiang, Ruben Verresen</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Topological order (TO) provides a natural platform for storing and manipulating quantum information. However, its stability to noise has only been systematically understood for Abelian TOs. In this work, we exploit the non-deterministic fusion of non-Abelian anyons to inform active error correction and design decoders where the fusion products, instead of flag qubits, herald the noise. This intrinsic heralding enhances thresholds over those of Abelian counterparts when noise is dominated by a single non-Abelian anyon type. Furthermore, we present an approach for determining the optimal threshold for non-Abelian TOs with perfect anyon syndromes for any noise model, formulated as a statistical mechanics model using Bayesian inference. We numerically illustrate these results for $D_4 \cong \mathbb Z_4 \rtimes \mathbb Z_2$ TO. In particular, for non-Abelian charge noise and perfect syndrome measurement, we find an optimal threshold $p_c=0.218(1)$, whereas an intrinsically heralded minimal-weight perfect-matching (MWPM) decoder already gives $p_c=0.20842(2)$, outperforming standard MWPM with $p_c = 0.15860(1)$. Our work highlights how non-Abelian properties can enhance stability, rather than reduce it, and discusses potential generalizations for achieving fault tolerance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23764v1" target="_blank">M2-brane indices on Higgs vacua</a></h3>
                    <p><strong>Authors:</strong> Chiung Hwang, Chang Lei, Yuezhang Tang</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> As an exact count of protected states, the superconformal index provides a powerful probe into holography and quantum aspects of gravity, reproducing the Bekenstein-Hawking entropy of supersymmetric AdS black holes in the large-$N$ limit. As a step toward understanding quantum black hole microstates, we study the finite-$N$ index of the 3d ADHM quiver gauge theory, a UV description of the 3d $\mathcal N=8$ SCFT dual to M-theory on AdS$_4 \times S^7$. In this note, we analyze both microcanonical and canonical features of the superconformal index. By computing the index to sufficiently high orders, we identify signatures of quantum black hole states in the finite-$N$ spectrum of the ADHM quiver, which align with the leading large-$N$ contribution reflecting the holographic dual black hole entropy. Furthermore, we introduce the complex-$\beta$ phase diagram of the index, which exhibits distinct peaks potentially associated with different gravitational saddles. To enable high-order computations, we employ the factorized index and also examine its Higgs branch Hilbert series limit. Our results demonstrate that the finite-$N$ index encodes rich information about black hole microstates and their quantum gravitational interpretation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23763v1" target="_blank">Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic</a></h3>
                    <p><strong>Authors:</strong> Liu Li, Qiang Ma, Cheng Ouyang, Johannes C. Paetzold, Daniel Rueckert, Bernhard Kainz</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Deep learning-based medical image segmentation techniques have shown promising results when evaluated based on conventional metrics such as the Dice score or Intersection-over-Union. However, these fully automatic methods often fail to meet clinically acceptable accuracy, especially when topological constraints should be observed, e.g., continuous boundaries or closed surfaces. In medical image segmentation, the correctness of a segmentation in terms of the required topological genus sometimes is even more important than the pixel-wise accuracy. Existing topology-aware approaches commonly estimate and constrain the topological structure via the concept of persistent homology (PH). However, these methods are difficult to implement for high dimensional data due to their polynomial computational complexity. To overcome this problem, we propose a novel and fast approach for topology-aware segmentation based on the Euler Characteristic ($\chi$). First, we propose a fast formulation for $\chi$ computation in both 2D and 3D. The scalar $\chi$ error between the prediction and ground-truth serves as the topological evaluation metric. Then we estimate the spatial topology correctness of any segmentation network via a so-called topological violation map, i.e., a detailed map that highlights regions with $\chi$ errors. Finally, the segmentation results from the arbitrary network are refined based on the topological violation maps by a topology-aware correction network. Our experiments are conducted on both 2D and 3D datasets and show that our method can significantly improve topological correctness while preserving pixel-wise segmentation accuracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23760v1" target="_blank">Universal tradeoff relations between resource cost and irreversibility of channels: General-resource Wigner-Araki-Yanase theorems and beyond</a></h3>
                    <p><strong>Authors:</strong> Hiroyasu Tajima, Koji Yamaguchi, Ryuji Takagi, Yui Kuramochi</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech, hep-th</p>
                    <p><strong>Summary:</strong> Quantum technologies offer exceptional -- sometimes almost magical -- speed and performance, yet every quantum process costs physical resources. Designing next-generation quantum devices, therefore, depends on solving the following question: which resources, and in what amount, are required to implement a desired quantum process? Casting the problem in the language of quantum resource theories, we prove a universal cost-irreversibility tradeoff: the lower the irreversibility of a quantum process, the greater the required resource cost for its realization. The trade-off law holds for a broad range of resources -- energy, magic, asymmetry, coherence, athermality, and others -- yielding lower bounds on resource cost of any quantum channel. Its broad scope positions this result as a foundation for deriving the following key results: (1) we show a universal relation between the energetic cost and the irreversibility for arbitrary channels, encompassing the energy-error tradeoff for any measurement or unitary gate; (2) we extend the energy-error tradeoff to free energy and work costs; (3) we extend the Wigner-Araki-Yanase theorem, which is the universal limitation on measurements under conservation laws, to a wide class of resource theories: the probability of failure in distinguishing resourceful states via a measurement is inversely proportional to its resource cost; (4) we prove that infinitely many resource-non-increasing operations in fact require an infinite implementation cost. These findings reveal a universal relationship between quantumness and irreversibility, providing a first step toward a general theory that explains when -- and how -- quantumness can suppress irreversibility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23757v1" target="_blank">Quantum scarring enhances non-Markovianity of subsystem dynamics</a></h3>
                    <p><strong>Authors:</strong> Aditya Banerjee</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.quant-gas, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Given that any subsystem of a closed out-of-equilibrium quantum system is an open quantum system, its dynamics (reduced from the full systems unitary evolution) can be either Markovian (memory-less) or non-Markovian, with the latter necessarily impeding the process of relaxation and thermalization. Seemingly independently, such non-ergodic dynamics occurs when an initial state has spectral weight on the so-called quantum scar states, which are non-thermalizing states embedded deep in the spectrum of otherwise thermal states. In this article, we present numerical evidence that the presence of quantum scars is a microscopic ingredient that enables and enhances non-Markovianity of the dynamics of subsystems. We exemplify this with the PXP model and its deformations which either enhance or erase the signatures of scarred dynamics when quenched from a simple product state that is known to have significant overlaps with the scarred subspace in the spectrum. By probing information backflows with the dynamical behaviour of the distances between temporally-separated states of small subsystems, systematic signatures of subsystem non-Markovianity in these models are presented, and it is seen that scarring-enhancing (erasing) deformations also exhibit enhanced (diminished) subsystem non-Markovianity. This sheds new light on the dynamical memories associated with quantum scarring, and opens interesting new questions at the interface of quantum scarring and an open quantum systems approach to investigating far-from-equilibrium and non-thermalizing isolated quantum many-body systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23755v1" target="_blank">Slot Attention with Re-Initialization and Self-Distillation</a></h3>
                    <p><strong>Authors:</strong> Rongzhen Zhao, Yi Zhao, Juho Kannala, Joni Pajarinen</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Unlike popular solutions based on dense feature maps, Object-Centric Learning (OCL) represents visual scenes as sub-symbolic object-level feature vectors, termed slots, which are highly versatile for tasks involving visual modalities. OCL typically aggregates object superpixels into slots by iteratively applying competitive cross attention, known as Slot Attention, with the slots as the query. However, once initialized, these slots are reused naively, causing redundant slots to compete with informative ones for representing objects. This often results in objects being erroneously segmented into parts. Additionally, mainstream methods derive supervision signals solely from decoding slots into the inputs reconstruction, overlooking potential supervision based on internal information. To address these issues, we propose Slot Attention with re-Initialization and self-Distillation (DIAS): $\emph{i)}$ We reduce redundancy in the aggregated slots and re-initialize extra aggregation to update the remaining slots; $\emph{ii)}$ We drive the bad attention map at the first aggregation iteration to approximate the good at the last iteration to enable self-distillation. Experiments demonstrate that DIAS achieves state-of-the-art on OCL tasks like object discovery and recognition, while also improving advanced visual prediction and reasoning. Our code is available on https://github.com/Genera1Z/DIAS.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23753v1" target="_blank">Compatible Instability: Gauge Constraints of Elasticity Inherited by Electronic Nematic Criticality</a></h3>
                    <p><strong>Authors:</strong> W. Joe Meese, Rafael M. Fernandes</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mtrl-sci, cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> Electronic nematicity is widely observed in quantum materials with varying degrees of electronic correlation, manifesting through charge, spin, orbital, or superconducting degrees of freedom. A phenomenological model capable of describing this broad set of systems must also account for nemato-elasticity, by which nematic and elastic degrees of freedom become intertwined. However, being a tensor gauge field theory, elasticity must satisfy the compatibility relations which guarantee the integrability of lattice deformations. Here, we develop a formalism for nemato-elasticity that manifestly respects the elastic compatibility relations. We show that these constraints bifurcate the phase space of nematic fluctuations into two orthogonal sectors: one compatible and thus critical, the other incompatible and therefore gapped. The suppression of the latter leads to universal direction-selective nematic criticality in any crystal lattice. Moreover, the critical nematic modes are protected from pinning effects induced by microscopic defect strains, which necessarily induce both longitudinal and transverse correlated random fields. Finally, our results also reconcile seemingly contradictory nematic phenomena, such as the mean-field character of the nematic transition and the widespread presence of domain formation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23751v1" target="_blank">CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks</a></h3>
                    <p><strong>Authors:</strong> Ping Yu, Jack Lanchantin, Tianlu Wang, Weizhe Yuan, Olga Golovneva, Ilia Kulikov, Sainbayar Sukhbaatar, Jason Weston, Jing Xu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> We propose CoT-Self-Instruct, a synthetic data generation method that instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the given seed tasks, and then to generate a new synthetic prompt of similar quality and complexity for use in LLM training, followed by filtering for high-quality data with automatic metrics. In verifiable reasoning, our synthetic data significantly outperforms existing training datasets, such as s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For non-verifiable instruction-following tasks, our method surpasses the performance of human or standard self-instruct prompts on both AlpacaEval 2.0 and Arena-Hard.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23748v1" target="_blank">Applying the Worldvolume Hybrid Monte Carlo method to the Hubbard model away from half filling</a></h3>
                    <p><strong>Authors:</strong> Masafumi Fukuma, Yusuke Namekawa</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, hep-lat, hep-th</p>
                    <p><strong>Summary:</strong> The Worldvolume Hybrid Monte Carlo (WV-HMC) method [arXiv:2012.08468] is an efficient and low-cost algorithm for addressing the sign problem. It mitigates the sign problem while avoiding the ergodicity issues that are intrinsic to algorithms based on Lefschetz thimbles. In this study, we apply the WV-HMC method to the Hubbard model away from half filling, which is known to suffer from a severe sign problem. We compute the number density on lattices of spatial size $6 \times 6$ and $8 \times 8$ at inverse temperature $\beta = 6.4$ using $N_t = 20$ Trotter steps. Our results show that the WV-HMC method remains effective even in parameter regions where non-thimble Monte Carlo methods fail due to severe sign problems. In this work, we employ direct solvers for fermion matrix inversion, with a computational cost of $O(N^3)$, where $N$ is the number of degrees of freedom and proportional to the spacetime lattice volume. An alternative algorithm employing pseudofermions and iterative solvers, which reduces the cost to $O(N^2)$ at the expense of careful parameter tuning, will be discussed in a separate publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23745v1" target="_blank">Particle localization on helical nanoribbons: Quantum analog of the Coriolis effect</a></h3>
                    <p><strong>Authors:</strong> Radha Balakrishnan, Rossen Dandoloff, Victor Atanasov, Avadh Saxena</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, quant-ph</p>
                    <p><strong>Summary:</strong> We derive the Schr\odinger equation for a particle confined to the surface of a normal and a binormal helical nanoribbon, obtain the quantum potentials induced by their respective curved surface geometries, and study the localized states of the particle for each ribbon. When the particle momentum satisfies a certain geometric condition, the particle localizes near the inner edge for a normal ribbon, and on the central helix for a binormal ribbon. This result suggests the presence of a pseudo-force that pushes the particle transversely along the width of the ribbon. We show that this phenomenon can be interpreted as a quantum analog of the Coriolis effect, which causes a transverse deflection of a classical particle moving in a rotating frame. We invoke Ehrenfests theorem applicable to localized states and identify the quantized angular velocities of the rotating frames for the two ribbons. If the particle is an electron, its localization at a specific width gives rise to a Hall-like voltage difference across the ribbons width. However, unlike in the Hall effect, its origin is not an applied magnetic field, but the ribbons curved surface geometry. When a normal helical ribbon is mechanically flipped to a binormal configuration in a periodic fashion, it results in a periodic electron transport from the inner edge to the center, giving rise to a quantum AC voltage. This can be used for designing nanoscale electromechanical devices. Quantum transport on a helical nanoribbon can be controlled by tuning the bends and twists of its surface, suggesting diverse applications in biopolymers and nanotechnology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23744v1" target="_blank">Floquet Non-Bloch Formalism for a Non-Hermitian Ladder: From Theoretical Framework to Topolectrical Circuits</a></h3>
                    <p><strong>Authors:</strong> Koustav Roy, Dipendu Halder, Koustabh Gogoi, B. Tanatar, Saurabh Basu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.other, physics.app-ph, quant-ph</p>
                    <p><strong>Summary:</strong> Periodically driven systems intertwined with non-Hermiticity opens a rich arena for topological phases that transcend conventional Hermitian limits. The physical significance of these phases hinges on obtaining the topological invariants that restore the bulk-boundary correspondence, a task well explored for static non-Hermitian (NH) systems, while it remains elusive for the driven scenario. Here, we address this problem by constructing a generalized Floquet non-Bloch framework that analytically captures the spectral and topological properties of time-periodic NH systems. Em- ploying a high-frequency Magnus expansion, we analytically derive an effective Floquet Hamiltonian and formulate the generalized Brillouin zone for a periodically driven quasi-one-dimensional system, namely, the Creutz ladder with a staggered complex potential. Our study demonstrates that the skin effect remains robust (despite the absence of non-reciprocal hopping) across a broad range of driving parameters, and is notably amplified in the low-frequency regime due to emergent longer- range couplings. We further employ a symmetric time frame approach that generates chiral-partner Hamiltonians, whose invariants, when appropriately combined, account for the full edge-state struc- ture. To substantiate the theoretical framework, we propose a topolectrical circuit (TEC) that serves as a viable experimental setting. Apart from capturing the skin modes, the proposed TEC design faithfully reproduces the presence of distinct Floquet edge states, as revealed through the voltage and impedance profiles, respectively. Thus, our work not only offers a theoretical framework for exploring NH-driven systems, but also provides an experimentally feasible TEC architecture for realizing these phenomena stated above in a laboratory.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23740v1" target="_blank">Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs</a></h3>
                    <p><strong>Authors:</strong> Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of-thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use of large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23739v1" target="_blank">Generalized Krylov Complexity</a></h3>
                    <p><strong>Authors:</strong> Amin Faraji Astaneh, Niloofar Vardian</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-th, quant-ph</p>
                    <p><strong>Summary:</strong> We extend the concept of Krylov complexity to include general unitary evolutions involving multiple generators. This generalization enables us to formulate a framework for generalized Krylov complexity, which serves as a measure of the complexity of states associated with continuous symmetries within a model. Furthermore, we investigate scenarios where different directions of transformation lead to varying degrees of complexity, which can be compared to geometric approaches to understanding complexity, such as Nielsen complexity. In this context, we introduce a generalized orthogonalization algorithm and delineate its computational framework, which is structured as a network of orthogonal blocks rather than a simple linear chain. Additionally, we provide explicit evaluations of specific illustrative examples to demonstrate the practical application of this framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23734v1" target="_blank">RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping</a></h3>
                    <p><strong>Authors:</strong> Dongming Wu, Yanping Fu, Saike Huang, Yingfei Liu, Fan Jia, Nian Liu, Feng Dai, Tiancai Wang, Rao Muhammad Anwer, Fahad Shahbaz Khan, Jianbing Shen</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> General robotic grasping systems require accurate object affordance perception in diverse open-world scenarios following human instructions. However, current studies suffer from the problem of lacking reasoning-based large-scale affordance prediction data, leading to considerable concern about open-world effectiveness. To address this limitation, we build a large-scale grasping-oriented affordance segmentation benchmark with human-like instructions, named RAGNet. It contains 273k images, 180 categories, and 26k reasoning instructions. The images cover diverse embodied data domains, such as wild, robot, ego-centric, and even simulation data. They are carefully annotated with an affordance map, while the difficulty of language instructions is largely increased by removing their category name and only providing functional descriptions. Furthermore, we propose a comprehensive affordance-based grasping framework, named AffordanceNet, which consists of a VLM pre-trained on our massive affordance data and a grasping network that conditions an affordance map to grasp the target. Extensive experiments on affordance segmentation benchmarks and real-robot manipulation tasks show that our model has a powerful open-world generalization ability. Our data and code is available at https://github.com/wudongming97/AffordanceNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23730v1" target="_blank">Pointed Hopf algebras, the Dixmier-Moeglin Equivalence and Noetherian group algebras</a></h3>
                    <p><strong>Authors:</strong> Jason P. Bell, Ken A. Brown, J. Toby Stafford</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> math.RA, math.GR, math.QA, math.RT, Primary 16R20, Secondary 16T20, 17B35</p>
                    <p><strong>Summary:</strong> This paper addresses the interactions between three properties that a group algebra or more generally a pointed Hopf algebra may possess: being noetherian, having finite Gelfand-Kirillov dimension, and satisfying the Dixmier-Moeglin equivalence. First it is shown that the second and third of these properties are equivalent for group algebras $kG$ of polycyclic-by-finite groups, and are, in turn, equivalent to $G$ being nilpotent-by-finite. In characteristic 0, this enables us to extend this equivalence to certain cocommutative Hopf algebras. In the second and third parts of the paper finiteness conditions for group algebras are studied. In the second section we examine when a group algebra satisfies the Goldie conditions, while in the final section we discuss what can be said about a minimal counterexample to the conjecture that if $kG$ is noetherian then G is polycyclic-by-finite.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23729v1" target="_blank">Entanglement Suppression Due to Black Hole Scattering</a></h3>
                    <p><strong>Authors:</strong> Kazuki Doi, Tadashi Takayanagi</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-th, cond-mat.str-el, quant-ph</p>
                    <p><strong>Summary:</strong> We consider the evolution of entanglement entropy in a two-dimensional conformal field theory with a holographic dual. Specifically, we are interested in a class of excited states produced by a combination of pure-state (local operator) and mixed-state local quenches. We employ a method that allows us to determine the full time evolution analytically. While a single insertion of a local operator gives rise to a logarithmic time profile of entanglement entropy relative to the vacuum, we find that this growth is heavily suppressed in the presence of a mixed-state quench, reducing it to a time-independent constant bump. The degree of suppression depends on the relative position of the quenches as well as the ratio of regularization parameters associated with the quenches. This work sheds light on the interesting properties of gravitational scattering involving black holes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23728v1" target="_blank">Symbolic Computation with Symmetric Polynomials in Real Algebraic Geometry</a></h3>
                    <p><strong>Authors:</strong> Cordian Riener, Thi Xuan Vu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> math.AG</p>
                    <p><strong>Summary:</strong> Symmetry plays a central role in accelerating symbolic computation involving polynomials. This chapter surveys recent developments and foundational methods that leverage the inherent symmetries of polynomial systems to reduce complexity, improve algorithmic efficiency, and reveal deeper structural insights. The main focus is on symmetry by the permutation of variables.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23727v1" target="_blank">Boosting Photodetection via Plasmonic Coupling in Quasi-2D Mixed-n Ruddlesden-Popper Perovskite Nanostripes</a></h3>
                    <p><strong>Authors:</strong> Brindhu Malani S, Eugen Klein, Ronja Maria Piehler, Rostyslav Lesyuk, Christian Klinke</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, physics.app-ph</p>
                    <p><strong>Summary:</strong> Quasi-2D metal halide perovskites have emerged as a promising material for photodetection due to excellent optoelectronic properties, simple synthesis, and robust stability. Albeit, developing high-performance photodetectors based on low-dimensional quasi-2D metal halide perovskite nanoparticles remains challenging due to quantum and dielectric confinement effects. Several approaches have been employed to improve efficiency, with plasmonic nanostructures being among the most effective ones. The resonant energy transfer and coupling between plasmons and excitons play a vital role in enhancing device performance. Here, we demonstrate enhanced photodetection of quasi-2D perovskite nanostripes resulting from the incorporation of octadecanethiol (ODT) functionalized Ag nanostructure arrays (ANA). Using colloidal lithography, ANA were fabricated. Reflectance spectroscopy and finite element method (FEM) simulations show that ANA supports localised surface plasmon resonance (LSPR) modes that spectrally coincide with the absorption and emission band of the perovskite. This spectral overlap enables interesting coupling interactions between the excitons and plasmons. The ODT-functionalized ANA photodetectors exhibit weak to intermediate coupling, resulting in a photocurrent enhancement factor of 838 %. They achieve photoresponsivities of up to 70.41 mA W^-1, detectivities of 1.48*10^11 Jones and external quantum efficiencies of 21.55 %, which are approximately 10 times higher than those of the reference photodetector. We present an approach to optimize the plasmon-exciton coupling and non-radiative energy transfer for developing high-performance plasmonic-perovskite hybrid photodetectors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23726v1" target="_blank">Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving</a></h3>
                    <p><strong>Authors:</strong> Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, Thomas Hanwen Zhu</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> LLMs have demonstrated strong mathematical reasoning abilities by leveraging reinforcement learning with long chain-of-thought, yet they continue to struggle with theorem proving due to the lack of clear supervision signals when solely using natural language. Dedicated domain-specific languages like Lean provide clear supervision via formal verification of proofs, enabling effective training through reinforcement learning. In this work, we propose \textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover can iteratively refine its proof based on Lean feedback, proved lemmas, and self-summarization. To solve IMO-level contest problems, we design three test-time inference strategies that enable both deep and broad reasoning. Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F, and achieves over 50\% on PutnamBench, outperforming the previous state-of-the-art by a large margin. To address the lack of geometry support in Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which outperforms previous formal geometry engines. We use these two systems to participate in IMO 2025 and fully prove 5 out of 6 problems. This work represents a significant advancement in automated mathematical reasoning, demonstrating the effectiveness of formal verification with long chain-of-thought reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23723v1" target="_blank">Search for $t\bar tt\bar tW$ Production at $\sqrt{s} = 13$ TeV Using a Modified Graph Neural Network at the LHC</a></h3>
                    <p><strong>Authors:</strong> Syed Haider Ali, Ashfaq Ahmad, Muhammad Saiel, Nadeem Shaukat</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> hep-ex, hep-ph</p>
                    <p><strong>Summary:</strong> The simultaneous production of four top quarks in association with a ($W$) boson at $(\sqrt{s} = 13)$ TeV is an rare SM process with a next-to-leading-order (NLO) cross-section of $(6.6^{+2.4}_{-2.6} {ab})$\cite{saiel}. Identifying this process in the fully hadronic decay channel is particularly challenging due to overwhelming backgrounds from $t\bar{t}, t\bar{t}W, t\bar{t}Z$, and triple-top production processes. This study introduces a modified physics informed Neural Network, a hybrid graph neural network (GNN) enhancing event classification. The proposed model integrates Graph layers for particle-level features, a custom Multi Layer Perceptron(MLP) based global stream with a quantum circuit and cross-attention fusion to combine local and global representations. Physics-informed Loss function enforce jet multiplicity constraints, derived from event decay dynamics. Benchmarked against conventional methods, the GNN achieves a signal significance $(S/\sqrt{S+B})$ of $0.174$ and ROC-AUC of 0.974, surpassing BDTs significance of $0.148$ and ROC of $0.913$, while Xgboost achieves a significance of $0.149$ and ROC of $0.920$. The classification models are trained on Monte Carlo (MC) simulations, with events normalized using cross-section-based reweighting to reflect their expected contributions in a dataset corresponding to $350\;$fb$^{-1}$ of integrated luminosity. This enhanced approach offers a framework for precision event selection at the LHC, leveraging high dimensional statistical learning and physics informed inference to tackle fundamental HEP challenges, aligning with ML developments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23718v1" target="_blank">Informing AI Risk Assessment with News Media: Analyzing National and Political Variation in the Coverage of AI Risks</a></h3>
                    <p><strong>Authors:</strong> Mowafak Allaham, Kimon Kieslich, Nicholas Diakopoulos</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Risk-based approaches to AI governance often center the technological artifact as the primary focus of risk assessments, overlooking systemic risks that emerge from the complex interaction between AI systems and society. One potential source to incorporate more societal context into these approaches is the news media, as it embeds and reflects complex interactions between AI systems, human stakeholders, and the larger society. News media is influential in terms of which AI risks are emphasized and discussed in the public sphere, and thus which risks are deemed important. Yet, variations in the news media between countries and across different value systems (e.g. political orientations) may differentially shape the prioritization of risks through the medias agenda setting and framing processes. To better understand these variations, this work presents a comparative analysis of a cross-national sample of news media spanning 6 countries (the U.S., the U.K., India, Australia, Israel, and South Africa). Our findings show that AI risks are prioritized differently across nations and shed light on how left vs. right leaning U.S. based outlets not only differ in the prioritization of AI risks in their coverage, but also use politicized language in the reporting of these risks. These findings can inform risk assessors and policy-makers about the nuances they should account for when considering news media as a supplementary source for risk-based governance approaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23716v1" target="_blank">Sandwich test for Quantum Phase Estimation</a></h3>
                    <p><strong>Authors:</strong> Avatar Tulsi</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum Phase Estimation (QPE) has potential for a scientific revolution through numerous practical applications like finding better medicines, batteries, materials, catalysts etc. Many QPE algorithms use the Hadamard test to estimate $\langle \psi|U^{k}|\psi\rangle$ for a large integer $k$ for an efficiently preparable initial state $|\psi\rangle$ and an efficiently implementable unitary operator $U$. The Hadamard test is hard to implement because it requires controlled applications of $U^{k}$. Recently, a Sequential Hadamard test (SHT) was proposed (arXiv:2506.18765) which requires controlled application of $U$ only but its total run time $T_{\rm tot}$ scales as $\mathcal{O}(k^{3}/\epsilon^{2}r_{\rm min}^{2})$ where $r_{\rm min}$ is the minimum value of $|\langle \psi|U^{k}|\psi\rangle|$ among all integers $k \leq k$. Typically $r_{\rm min}$ is exponentially low and SHT becomes too slow. We present a new algorithm, the SANDWICH test to address this bottleneck. Our algorithm uses efficient preparation of the initial state $|\psi\rangle$ to efficiently implement the SPROTIS operator $R_{\psi}^{\phi}$ where SPROTIS stands for the Selective Phase Rotation of the Initial State. It sandwiches the SPROTIS operator between $U^{a}$ and $U^{b}$ for integers $\{a,b\} \leq k$ to estimate $\langle \psi|U^{k}|\psi\rangle$. The total run time $T_{\rm tot}$ is $\mathcal{O}(k^{2}\ln k/ \epsilon^{2} s_{\rm min}^{6})$. Here $s_{\rm min}$ is the minimum value of $|\langle \psi|U^{\hat{k}}|\psi\rangle$ among all integers $\hat{k}$ which are values of the nodes of a random binary sum tree whose root node value is $k$ and leaf nodes values are $1$ or $0$. It can be reasonably expected that $s_{\rm min} \not\ll 1$ in typical cases because there is wide freedom in choosing the random binary sum tree.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23715v1" target="_blank">DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching</a></h3>
                    <p><strong>Authors:</strong> Emery Pierson, Lei Li, Angela Dai, Maks Ovsjanikov</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep functional maps have recently emerged as a powerful tool for solving non-rigid shape correspondence tasks. Methods that use this approach combine the power and flexibility of the functional map framework, with data-driven learning for improved accuracy and generality. However, most existing methods in this area restrict the learning aspect only to the feature functions and still rely on axiomatic modeling for formulating the training loss or for functional map regularization inside the networks. This limits both the accuracy and the applicability of the resulting approaches only to scenarios where assumptions of the axiomatic models hold. In this work, we show, for the first time, that both in-network regularization and functional map training can be replaced with data-driven methods. For this, we first train a generative model of functional maps in the spectral domain using score-based generative modeling, built from a large collection of high-quality maps. We then exploit the resulting model to promote the structural properties of ground truth functional maps on new shape collections. Remarkably, we demonstrate that the learned models are category-agnostic, and can fully replace commonly used strategies such as enforcing Laplacian commutativity or orthogonality of functional maps. Our key technical contribution is a novel distillation strategy from diffusion models in the spectral domain. Experiments demonstrate that our learned regularization leads to better results than axiomatic approaches for zero-shot non-rigid shape matching. Our code is available at: https://github.com/daidedou/diffumatch/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23710v1" target="_blank">Structural Distortions Control Scaling of Exciton Binding Energies in Two-Dimensional Ag/Bi Double Perovskites</a></h3>
                    <p><strong>Authors:</strong> Pierre Lechifflart, Raisa-Ioana Biega, Linn Leppert</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Three-dimensional metal halide double perovskites such as Cs$_2$AgBiBr$_6$ exhibit pronounced excitonic effects due to their anisotropic electronic structure and chemical localization effects. Their two-dimensional derivatives, formed by inserting organic spacer molecules between perovskite layers, were expected to follow well-established trends seen in Pb-based 2D perovskites, namely, increasing exciton binding energies with decreasing layer thickness due to enhanced quantum and dielectric confinement. However, recent experimental and computational studies have revealed anomalous behavior in Ag/Bi-based 2D perovskites, where this trend is reversed. Using ab initio many-body perturbation theory within the $GW$ and Bethe-Salpeter Equation frameworks, we resolve this puzzle by systematically comparing experimental structures with idealized models designed to isolate the effects of octahedral distortions, interlayer separation, and stacking. We find that structural distortions, driven by directional Ag d orbital bonding, govern the momentum-space origin and character of the exciton, and are the primary cause of the observed non-monotonic trends. Furthermore, we explore how interlayer distance and stacking influence band gaps and exciton binding energies, showing that, despite different chemistry, the underlying confinement physics mirrors that of Pb-based 2D perovskites. Our results establish design principles for tuning excitonic properties in this broader class of layered, lead-free materials.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1007/978-3-031-43895-0_54" target="_blank">Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation</a></h3>
                    <p><strong>Authors:</strong> Alfie Roddan, Chi Xu, Serine Ajlouni, Irini Kakaletri, Patra Charalampaki, Stamatia Giannarou</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The deployment of Machine Learning models intraoperatively for tissue characterisation can assist decision making and guide safe tumour resections. For image classification models, pixel attribution methods are popular to infer explainability. However, overconfidence in deep learning models predictions translates to overconfidence in pixel attribution. In this paper, we propose the first approach which incorporates risk estimation into a pixel attribution method for improved image classification explainability. The proposed method iteratively applies a classification model with a pixel attribution method to create a volume of PA maps. This volume is used for the first time, to generate a pixel-wise distribution of PA values. We introduce a method to generate an enhanced PA map by estimating the expectation values of the pixel-wise distributions. In addition, the coefficient of variation (CV) is used to estimate pixel-wise risk of this enhanced PA map. Hence, the proposed method not only provides an improved PA map but also produces an estimation of risk on the output PA values. Performance evaluation on probe-based Confocal Laser Endomicroscopy (pCLE) data and ImageNet verifies that our improved explainability method outperforms the state-of-the-art.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23704v1" target="_blank">Enhanced Velocity Field Modeling for Gaussian Video Reconstruction</a></h3>
                    <p><strong>Authors:</strong> Zhenyang Li, Xiaoyang Bai, Tongchen Zhang, Pengfei Shen, Weiwei Xu, Yifan Peng</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> High-fidelity 3D video reconstruction is essential for enabling real-time rendering of dynamic scenes with realistic motion in virtual and augmented reality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has achieved near-photorealistic results in video reconstruction due to the great representation capability of deep deformation networks. However, in videos with complex motion and significant scale variations, deformation networks often overfit to irregular Gaussian trajectories, leading to suboptimal visual quality. Moreover, the gradient-based densification strategy designed for static scene reconstruction proves inadequate to address the absence of dynamic content. In light of these challenges, we propose a flow-empowered velocity field modeling scheme tailored for Gaussian video reconstruction, dubbed FlowGaussian-VR. It consists of two core components: a velocity field rendering (VFR) pipeline which enables optical flow-based optimization, and a flow-assisted adaptive densification (FAD) strategy that adjusts the number and size of Gaussians in dynamic regions. We validate our models effectiveness on multi-view dynamic reconstruction and novel view synthesis with multiple real-world datasets containing challenging motion scenarios, demonstrating not only notable visual improvements (over 2.5 dB gain in PSNR) and less blurry artifacts in dynamic textures, but also regularized and trackable per-Gaussian trajectories.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23703v1" target="_blank">Operator identities of multiplicity 3 for associative algebras</a></h3>
                    <p><strong>Authors:</strong> Murray R. Bremner</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> math.RA, math.OA, Primary 47C05. Secondary 13P10, 13P15, 18M70, 39B42, 47-08</p>
                    <p><strong>Summary:</strong> We consider algebraic identities for linear operators on associative algebras in which each term has degree 2 (the number of variables) and multiplicity 3 (the number of occurrences of the operator). We apply the methods of earlier work by the author and Elgendy which classified operator identities of degree 2, multiplicities 1 and 2. We begin with the general operator identity of multiplicity 3 which has 10 terms and indeterminate coefficients. We use the operadic concept of partial composition to generate all consequences of this identity in degree 3, multiplicity 4. The coefficient matrix of these consequences has size $105 \times 20$ and indeterminate entries. We compute the partial Smith form of this matrix and use Gr\obner bases for determinantal ideals to discover which values of the indeterminates produce a matrix of submaximal rank. The only possible submaximal values of the rank are 16 and 19: there are 6 new identities of rank 16, and 8 new identities of rank 19.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23701v1" target="_blank">TextQuests: How Good are LLMs at Text-Based Video Games?</a></h3>
                    <p><strong>Authors:</strong> Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agents ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agents capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at https://textquests.ai.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23700v1" target="_blank">The ArborX library: version 2.0</a></h3>
                    <p><strong>Authors:</strong> Andrey Prokopenko, Daniel Arndt, Damien Lebrun-GrandiÃ©, Bruno Turcksin</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> This paper provides an overview of the 2.0 release of the ArborX library, a performance portable geometric search library based on Kokkos. We describe the major changes in ArborX 2.0 including a new interface for the library to support a wider range of user problems, new search data structures (brute force, distributed), support for user functions to be executed on the results (callbacks), and an expanded set of the supported algorithms (ray tracing, clustering).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23695v1" target="_blank">On the Achievable Rate of Satellite Quantum Communication Channel using Deep Autoencoder Gaussian Mixture Model</a></h3>
                    <p><strong>Authors:</strong> Mouli Chakraborty, Subhash Chandra, Avishek Nag, Anshu Mukherjee</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> We present a comparative study of the Gaussian mixture model (GMM) and the Deep Autoencoder Gaussian Mixture Model (DAGMM) for estimating satellite quantum channel capacity, considering hybrid quantum noise (HQN) and transmission constraints. While GMM is simple and interpretable, DAGMM better captures non-linear variations and noise distributions. Simulations show that DAGMM provides tighter capacity bounds and improved clustering. This introduces the Deep Cluster Gaussian Mixture Model (DCGMM) for high-dimensional quantum data analysis in quantum satellite communication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23693v1" target="_blank">CFDagent: A Language-Guided, Zero-Shot Multi-Agent System for Complex Flow Simulation</a></h3>
                    <p><strong>Authors:</strong> Zhaoyue Xu, Long Wang, Chunyu Wang, Yixin Chen, Qingyong Luo, Hua-Dong Yao, Shizhao Wang, Guowei He</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn</p>
                    <p><strong>Summary:</strong> We introduce CFDagent, a zero-shot, multi-agent system that enables fully autonomous computational fluid dynamics (CFD) simulations from natural language prompts. CFDagent integrates three specialized LLM-driven agents: (i) the Preprocessing Agent that generates 3D geometries from textual or visual inputs using a hybrid text-to-3D diffusion model (Point-E) and automatically meshes the geometries; (ii) the Solver Agent that configures and executes an immersed boundary flow solver; and (iii) the Postprocessing Agent that analyzes and visualizes the results, including multimodal renderings. These agents are interactively guided by GPT-4o via conversational prompts, enabling intuitive and user-friendly interaction. We validate CFDagent by reproducing canonical sphere flows at Reynolds numbers of 100 and 300 using three distinct inputs: a simple text prompt (i.e., sphere), an image-based input, and a standard sphere model. The computed drag and lift coefficients from meshes produced by each input approach closely match available data. The proposed system enables synthesization of flow simulations and photorealistic visualizations for complex geometries. Through extensive tests on canonical and realistic scenarios, we demonstrate the robustness, versatility, and practical applicability of CFDagent. By bridging generative AI with high-fidelity simulations, CFDagent significantly lowers barriers to expert-level CFD, unlocking broad opportunities in education, scientific research, and practical engineering applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23691v1" target="_blank">Accretion Regimes of Neutrino-Cooled Flows onto Black Holes</a></h3>
                    <p><strong>Authors:</strong> Javiera HernÃ¡ndez-Morales, Daniel M. Siegel</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, astro-ph.GA, astro-ph.SR, gr-qc</p>
                    <p><strong>Summary:</strong> Neutrino-cooled accretion disks can form in the aftermath of neutron-star mergers as well as during the collapse of rapidly rotating massive stars (collapsars) and the accretion-induced collapse of rapidly rotating white dwarfs. Due to Pauli blocking as electrons become degenerate at sufficiently high accretion rates $\dot{M}$, the resulting self-neutronization of the dissociated accreting plasma makes these astrophysical systems promising sources of rapid neutron capture nucleosynthesis (the r-process). We present a one-dimensional general-relativistic, viscous-hydrodynamic model of neutrino-cooled accretion disks around black holes. With collapsars, super-collapsars and very massive star collapse in mind, we chart the composition of the accretion flow and systematically explore different radiatively efficient and inefficient accretion regimes with increasing $\dot M$, across a vast parameter space of $\dot{M}\sim 10^{-6}-10^6 M_\odot \,\text{s}^{-1}$, black hole masses of $M_\bullet\sim 1 - 10^4 M_\odot$ and dimensionless spins of $\chi_\bullet \in [0,1)$, as well as $\alpha$-viscosity values of $\alpha\sim 10^{-3}-1$. We show that these accretion regimes are separated by characteristic thresholds $\dot{M}_{\rm char}$ that follow power laws $\dot M_{\rm char}\propto M_{\bullet}^\alpha \alpha^\beta$ and that can be understood based on analytic approximations we derive. We find that outflows from such disks are promising sites of r-process nucleosynthesis up to $M_\bullet \lesssim 3000 M_\odot$. These give rise to lanthanide-bearing red super-kilonovae transients mostly for $M_\bullet \lesssim 200-500 M_\odot$ and lanthanide suppressed blue super-kilonovae for larger $M_\bullet$. Proton-rich outflows can develop specifically for large black hole masses ($M_\bullet \gtrsim 100 M_\odot$) in certain accretion regimes, which may give rise to proton-rich isotopes via the $\nu$p-process.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23689v1" target="_blank">Probing graph topology from local quantum measurements</a></h3>
                    <p><strong>Authors:</strong> F. Romeo, J. Settino</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.dis-nn</p>
                    <p><strong>Summary:</strong> We show that global properties of an unknown quantum network, such as the average degree, hub density, and the number of closed paths of fixed length, can be inferred from strictly local quantum measurements. In particular, we demonstrate that a malicious agent with access to only a small subset of nodes can initialize quantum states locally and, through repeated short-time measurements, extract sensitive structural information about the entire network. The intrusion strategy is inspired by extreme learning and quantum reservoir computing and combines short-time quantum evolution with a non-iterative linear readout with trainable weights. These results suggest new strategies for intrusion detection and structural diagnostics in future quantum Internet infrastructures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.23687v1" target="_blank">X-ray polarization of reflected thermal emission</a></h3>
                    <p><strong>Authors:</strong> J. PodgornÃ½, M. DovÄiak, R. Goosmann, F. Marin, L. Marra, G. Matt, A. RÃ³Å¼aÅ„ska, R. Taverna</p>
                    <p><strong>Published:</strong> 7/31/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE</p>
                    <p><strong>Summary:</strong> X-ray thermal emission is inherent in neutron-star and black-hole X-ray binary systems. Within these systems, it may reflect from optically thick matter, which will create characteristic observable X-ray spectro-polarimetric features. We compute rest-frame reflection spectra and the corresponding energy-dependent linear polarization degree and angle for (un)polarized single-temperature black-body spectra impinging on a partially ionized constant-density optically thick slab. We use a combination of a Monte Carlo simulation that takes into account scattering, absorption, and spectral lines, with a non-LTE radiative transfer pre-computation of the ionization structure of the slab in photo-ionization equilibrium. We discuss the impact of the reflectors ionization and of the incident spectral shape on the obtained energy dependence of polarization. Despite the presence of highly polarized absorption features and low-polarized spectral lines, an underlying scattering-induced increase of polarization degree with energy in mid to hard X-rays naturally arises due to multiple Compton-scattering energy shifts. Such re-processing effect is particularly apparent in 2-8 keV for steep incident X-ray spectra reflecting from highly-ionized optically thick media. Integration of the resulting local reflection tables in specific large-scale reflection geometries occurring in X-ray binary systems, including relativistic effects, will be presented in a follow-up paper. Nonetheless, we anticipate that the obtained local energy-dependent features will imprint at large distances from the source to the observed X-ray polarization, and could contribute to the observed increase of total polarization degree with energy in 2-8 keV in many accreting systems by the IXPE mission.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

