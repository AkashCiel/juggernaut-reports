
    
        <h1>🤖 AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-27<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>🤖 AI Summary</h2>
                <p>## ai safety research

AI safety research is gaining momentum with a focus on ensuring robust, reliable, and interpretable AI systems across various applications. A significant trend is the development of frameworks and methodologies to enhance the safety and reliability of AI systems in safety-critical environments. For instance, Get Global Guarantees introduces a novel approach, tower robustness, to evaluate the robustness of deep learning models against input perturbations, aiming to balance computational cost and measurement precision, which is crucial for pre-deployment assessments in safety-critical domains.

Another noteworthy advancement is in the domain of autonomous systems and navigation, where ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments proposes a method leveraging large language models to generate traversability maps without risking physical harm to robots. This approach not only enhances safety but also accelerates the development of advanced navigation systems by reducing the need for hazardous real-world data collection.

Furthermore, the integration of AI into healthcare and clinical settings highlights the need for reliable and explainable AI systems. The MATRIX framework exemplifies this by combining structured safety evaluations with conversational AI to ensure safety in clinical dialogue systems. This integration is crucial for maintaining patient safety and improving the trustworthiness of AI systems in medical applications.

Overall, these developments underscore the importance of building AI systems that are not only efficient and effective but also adhere to stringent safety and reliability standards. This trend is critical as AI systems continue to be deployed in increasingly complex and sensitive environments, where safety cannot be compromised.

*Based on 50 research papers*

---

## ai alignment research

In the context of AI alignment research, the field is witnessing significant advancements across various domains, highlighting the ongoing effort to ensure that AI systems act in ways that are aligned with human intentions and ethical standards. Papers such as StepWiser: Stepwise Generative Judges for Wiser Reasoning and Trustworthy Agents for Electronic Health Records through Confidence Estimation illustrate the trend of enhancing AI systems reasoning and decision-making capabilities while emphasizing transparency and reliability. The former introduces a model that supervises the logical validity of AIs reasoning steps, enhancing judgment accuracy and improving policy models. The latter focuses on building trust in AI systems used in healthcare by estimating confidence in decision-making, thereby addressing the risks of misinformation or hallucination.

Additionally, the exploration of AIs role in democratic processes and social norms, as seen in Of the People, By the Algorithm: How AI Transforms Democratic Representation and AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms, underscores the broader implications of AI alignment. These studies suggest that AI can facilitate more inclusive and transparent democratic participation while also challenging traditional notions of social cognition by demonstrating that AI can predict human social appropriateness with remarkable accuracy. The integration of these AI capabilities into societal frameworks raises critical questions about accountability, ethical governance, and the potential for AI to serve as intermediaries in decision-making processes. Overall, these studies reflect a growing emphasis on aligning AI with human values, ensuring that these technologies act not only effectively but also ethically in diverse contexts.

*Based on 50 research papers*</p>
            
        
        
        <h2>📚 Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.19243v1" target="_blank">Style4D-Bench: A Benchmark Suite for 4D Stylization</a></h3>
                    <p><strong>Authors:</strong> Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, 2) a strong baseline that make an initial attempt for 4D stylization, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes. Project page: https://becky-catherine.github.io/Style4D . Code: https://github.com/Becky-catherine/Style4D-Bench .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19239v1" target="_blank">Model Context Protocols in Adaptive Transport Systems: A Survey</a></h3>
                    <p><strong>Authors:</strong> Gaurab Chhetri, Shriyank Somvanshi, Md Monzurul Islam, Shamyo Brotee, Mahmuda Sultana Mimi, Dipti Koirala, Biplov Pandey, Subasish Das</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The rapid expansion of interconnected devices, autonomous systems, and AI applications has created severe fragmentation in adaptive transport systems, where diverse protocols and context sources remain isolated. This survey provides the first systematic investigation of the Model Context Protocol (MCP) as a unifying paradigm, highlighting its ability to bridge protocol-level adaptation with context-aware decision making. Analyzing established literature, we show that existing efforts have implicitly converged toward MCP-like architectures, signaling a natural evolution from fragmented solutions to standardized integration frameworks. We propose a five-category taxonomy covering adaptive mechanisms, context-aware frameworks, unification models, integration strategies, and MCP-enabled architectures. Our findings reveal three key insights: traditional transport protocols have reached the limits of isolated adaptation, MCPs client-server and JSON-RPC structure enables semantic interoperability, and AI-driven transport demands integration paradigms uniquely suited to MCP. Finally, we present a research roadmap positioning MCP as a foundation for next-generation adaptive, context-aware, and intelligent transport infrastructures.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3744736.3749343" target="_blank">Beyond Competitive Gaming: How Casual Players Evaluate and Respond to Teammate Performance</a></h3>
                    <p><strong>Authors:</strong> Kaushall Senthil Nathan, Jieun Lee, Derrick M. Wang, Geneva M. Smith, Eugene Kukshinov, Daniel Harley, Lennart E. Nacke</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Teammate performance evaluation fundamentally shapes intervention design in video games. However, our current understanding stems primarily from competitive E-Sports contexts where individual performance directly impacts outcomes. This research addresses whether performance evaluation mechanisms and behavioural responses identified in competitive games generalize to casual cooperative games. We investigated how casual players evaluate teammate competence and respond behaviourally in a controlled between-subjects experiment (N=23). We manipulated confederate performance in Overcooked 2, combining observations, NASA TLX self-reports, and interviews. We present two key findings. (1) Observations revealed frustration behaviours completely absent in self-report data. Thus, these instruments assess fundamentally distinct constructs. (2) Participants consistently evaluated teammate performance through relative comparison rather than absolute metrics. This contradicts task-performance operationalizations dominant in competitive gaming research. Hence, performance evaluation frameworks from competitive contexts cannot be directly applied to casual cooperative games. We provide empirical evidence that performance evaluation in casual games requires a comparative operationalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19229v1" target="_blank">StepWiser: Stepwise Generative Judges for Wiser Reasoning</a></h3>
                    <p><strong>Authors:</strong> Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As models increasingly leverage multi-step reasoning strategies to solve complex problems, supervising the logical validity of these intermediate steps has become a critical research challenge. Process reward models address this by providing step-by-step feedback, but current approaches have two major drawbacks: they typically function as classifiers without providing explanations, and their reliance on supervised fine-tuning with static datasets limits generalization. Inspired by recent advances, we reframe stepwise reward modeling from a classification task to a reasoning task itself. We thus propose a generative judge that reasons about the policy models reasoning steps (i.e., meta-reasons), outputting thinking tokens before delivering a final verdict. Our model, StepWiser, is trained by reinforcement learning using relative outcomes of rollouts. We show it provides (i) better judgment accuracy on intermediate steps than existing methods; (ii) can be used to improve the policy model at training time; and (iii) improves inference-time search.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19227v1" target="_blank">Generative Interfaces for Language Models</a></h3>
                    <p><strong>Authors:</strong> Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn, information-dense, and exploratory tasks. To address these limitations, we propose Generative Interfaces for Language Models, a paradigm in which LLMs respond to user queries by proactively generating user interfaces (UIs) that enable more adaptive and interactive engagement. Our framework leverages structured interface-specific representations and iterative refinements to translate user queries into task-specific UIs. For systematic evaluation, we introduce a multidimensional assessment framework that compares generative interfaces with traditional chat-based ones across diverse tasks, interaction patterns, and query types, capturing functional, interactive, and emotional aspects of user experience. Results show that generative interfaces consistently outperform conversational ones, with humans preferring them in over 70% of cases. These findings clarify when and why users favor generative interfaces, paving the way for future advancements in human-AI interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19200v1" target="_blank">The Ramon Llulls Thinking Machine for Automated Ideation</a></h3>
                    <p><strong>Authors:</strong> Xinran Zhao, Boyuan Zheng, Chenglei Si, Haofei Yu, Ken Liu, Runlong Zhou, Ruochen Li, Tong Chen, Xiang Li, Yiming Zhang, Tongshuang Wu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> This paper revisits Ramon Llulls Ars combinatoria - a medieval framework for generating knowledge through symbolic recombination - as a conceptual foundation for building a modern Llulls thinking machine for research ideation. Our approach defines three compositional axes: Theme (e.g., efficiency, adaptivity), Domain (e.g., question answering, machine translation), and Method (e.g., adversarial training, linear attention). These elements represent high-level abstractions common in scientific work - motivations, problem settings, and technical approaches - and serve as building blocks for LLM-driven exploration. We mine elements from human experts or conference papers and show that prompting LLMs with curated combinations produces research ideas that are diverse, relevant, and grounded in current literature. This modern thinking machine offers a lightweight, interpretable tool for augmenting scientific creativity and suggests a path toward collaborative ideation between humans and AI.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.2139/ssrn.5006698" target="_blank">Profit-Aware Graph Framework for Cross-Platform Ride-Sharing: Analyzing Allocation Mechanisms and Efficiency Gains</a></h3>
                    <p><strong>Authors:</strong> Xin Dong, Jose Ventura, Vikash V. Gayah</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Ride-hailing platforms (e.g., Uber, Lyft) have transformed urban mobility by enabling ride-sharing, which holds considerable promise for reducing both travel costs and total vehicle miles traveled (VMT). However, the fragmentation of these platforms impedes system-wide efficiency by restricting ride-matching to intra-platform requests. Cross-platform collaboration could unlock substantial efficiency gains, but its realization hinges on fair and sustainable profit allocation mechanisms that can align the incentives of competing platforms. This study introduces a graph-theoretic framework that embeds profit-aware constraints into network optimization, facilitating equitable and efficient cross-platform ride-sharing. Within this framework, we evaluate three allocation schemes -- equal-profit-based, market-share-based, and Shapley-value-based -- through large-scale simulations. Results show that the Shapley-value-based mechanism consistently outperforms the alternatives across six key metrics. Notably, system efficiency and rider service quality improve with increasing demand, reflecting clear economies of scale. The observed economies of scale, along with their diminishing returns, can be understood with the structural evolution of rider-request graphs, where super-linear edge growth expands feasible matches and sub-linear degree scaling limits per-rider connectivity.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746252.3761039" target="_blank">Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness</a></h3>
                    <p><strong>Authors:</strong> Wenchuan Mu, Kwan Hui Lim</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In safety-critical deep learning applications, robustness measures the ability of neural models that handle imperceptible perturbations in input data, which may lead to potential safety hazards. Existing pre-deployment robustness assessment methods typically suffer from significant trade-offs between computational cost and measurement precision, limiting their practical utility. To address these limitations, this paper conducts a comprehensive comparative analysis of existing robustness definitions and associated assessment methodologies. We propose tower robustness to evaluate robustness, which is a novel, practical metric based on hypothesis testing to quantitatively evaluate probabilistic robustness, enabling more rigorous and efficient pre-deployment assessments. Our extensive comparative evaluation illustrates the advantages and applicability of our proposed approach, thereby advancing the systematic understanding and enhancement of model robustness in safety-critical deep learning applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19182v1" target="_blank">SoccerNet 2025 Challenges Results</a></h3>
                    <p><strong>Authors:</strong> Silvio Giancola, Anthony Cioppa, Marc Gutiérrez-Pérez, Jan Held, Carlos Hinojosa, Victor Joos, Arnaud Leduc, Floriane Magera, Karen Sanchez, Vladimir Somers, Artur Xarles, Antonio Agudo, Alexandre Alahi, Olivier Barnich, Albert Clapés, Christophe De Vleeschouwer, Sergio Escalera, Bernard Ghanem, Thomas B. Moeslund, Marc Van Droogenbroeck, Tomoki Abe, Saad Alotaibi, Faisal Altawijri, Steven Araujo, Xiang Bai, Xiaoyang Bi, Jiawang Cao, Vanyi Chao, Kamil Czarnogórski, Fabian Deuser, Mingyang Du, Tianrui Feng, Patrick Frenzel, Mirco Fuchs, Jorge García, Konrad Habel, Takaya Hashiguchi, Sadao Hirose, Xinting Hu, Yewon Hwang, Ririko Inoue, Riku Itsuji, Kazuto Iwai, Hongwei Ji, Yangguang Ji, Licheng Jiao, Yuto Kageyama, Yuta Kamikawa, Yuuki Kanasugi, Hyungjung Kim, Jinwook Kim, Takuya Kurihara, Bozheng Li, Lingling Li, Xian Li, Youxing Lian, Dingkang Liang, Hongkai Lin, Jiadong Lin, Jian Liu, Liang Liu, Shuaikun Liu, Zhaohong Liu, Yi Lu, Federico Méndez, Huadong Ma, Wenping Ma, Jacek Maksymiuk, Henry Mantilla, Ismail Mathkour, Daniel Matthes, Ayaha Motomochi, Amrulloh Robbani Muhammad, Haruto Nakayama, Joohyung Oh, Yin May Oo, Marcelo Ortega, Norbert Oswald, Rintaro Otsubo, Fabian Perez, Mengshi Qi, Cristian Rey, Abel Reyes-Angulo, Oliver Rose, Hoover Rueda-Chacón, Hideo Saito, Jose Sarmiento, Kanta Sawafuji, Atom Scott, Xi Shen, Pragyan Shrestha, Jae-Young Sim, Long Sun, Yuyang Sun, Tomohiro Suzuki, Licheng Tang, Masato Tonouchi, Ikuma Uchida, Henry O. Velesaca, Tiancheng Wang, Rio Watanabe, Jay Wu, Yongliang Wu, Shunzo Yamagishi, Di Yang, Xu Yang, Yuxin Yang, Hao Ye, Xinyu Ye, Calvin Yeung, Xuanlong Yu, Chao Zhang, Dingyuan Zhang, Kexing Zhang, Zhe Zhao, Xin Zhou, Wenbo Zhu, Julian Ziegler</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This years challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, targeting the recovery of scene geometry from single-camera broadcast clips through relative depth estimation for each pixel; (3) Multi-View Foul Recognition, requiring the analysis of multiple synchronized camera views to classify fouls and their severity; and (4) Game State Reconstruction, aimed at localizing and identifying all players from a broadcast video to reconstruct the game state on a 2D top-view of the field. Across all tasks, participants were provided with large-scale annotated datasets, unified evaluation protocols, and strong baselines as starting points. This report presents the results of each challenge, highlights the top-performing solutions, and provides insights into the progress made by the community. The SoccerNet Challenges continue to serve as a driving force for reproducible, open research at the intersection of computer vision, artificial intelligence, and sports. Detailed information about the tasks, challenges, and leaderboards can be found at https://www.soccer-net.org, with baselines and development kits available at https://github.com/SoccerNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19173v1" target="_blank">Leveraging Evolutionary Surrogate-Assisted Prescription in Multi-Objective Chlorination Control Systems</a></h3>
                    <p><strong>Authors:</strong> Rivaaj Monsia, Olivier Francon, Daniel Young, Risto Miikkulainen</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.NE, cs.LG</p>
                    <p><strong>Summary:</strong> This short, written report introduces the idea of Evolutionary Surrogate-Assisted Prescription (ESP) and presents preliminary results on its potential use in training real-world agents as a part of the 1st AI for Drinking Water Chlorination Challenge at IJCAI-2025. This work was done by a team from Project Resilience, an organization interested in bridging AI to real-world problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19172v1" target="_blank">From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity</a></h3>
                    <p><strong>Authors:</strong> Luca Grillotti, Lisa Coiffard, Oscar Pang, Maxence Faldor, Antoine Cully</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Autonomous skill discovery aims to enable robots to acquire diverse behaviors without explicit supervision. Learning such behaviors directly on physical hardware remains challenging due to safety and data efficiency constraints. Existing methods, including Quality-Diversity Actor-Critic (QDAC), require manually defined skill spaces and carefully tuned heuristics, limiting real-world applicability. We propose Unsupervised Real-world Skill Acquisition (URSA), an extension of QDAC that enables robots to autonomously discover and master diverse, high-performing skills directly in the real world. We demonstrate that URSA successfully discovers diverse locomotion skills on a Unitree A1 quadruped in both simulation and the real world. Our approach supports both heuristic-driven skill discovery and fully unsupervised settings. We also show that the learned skill repertoire can be reused for downstream tasks such as real-world damage adaptation, where URSA outperforms all baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios. Our results establish a new framework for real-world robot learning that enables continuous skill discovery with limited human intervention, representing a significant step toward more autonomous and adaptable robotic systems. Demonstration videos are available at http://adaptive-intelligent-robotics.github.io/URSA .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19170v1" target="_blank">Stellar Mass Assembly History of Massive Quiescent Galaxies since $z\sim4$: Insights from Spatially Resolved SED Fitting with JWST Data</a></h3>
                    <p><strong>Authors:</strong> Novan Saputra Haryana, Masayuki Akiyama, Abdurrouf, Hesti Retno Tri Wulandari, Juan Pablo Alfonzo, Kianhong Lee, Naoki Matsumoto, Ryo Albert Sutanto, Muhammad Nur Ihsan Effendi, Itsna Khoirul Fitriana, Ibnu Nurul Huda, Anton Timur Jaelani, Sultan Hadi Kusuma, Lucky Puspitarini, Dian Puspita Triani</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Massive quiescent galaxies at high redshift show significantly more compact morphology than their local counterparts. To examine their internal structure across a wide redshift range and investigate potential redshift dependence, we performed spatially resolved SED fitting using pixedfit software on massive $(\log(M_*/M_\odot)\sim11)$ quiescent galaxies at $0 4$ kpc), while the central regions ($r \sim 1$ kpc) remain largely unchanged, with stellar mass surface density similar to local quiescent galaxies. The estimated star formation rates are too low to explain the stellar mass growth, indicating an additional stellar mass accumulation process, such as mergers, is necessary. We parameterize the size-mass relation of the most massive galaxies in our sample as $\log(R_{e,mass}) \propto \alpha \log(M_*)$, and find $\alpha = 2.67^{+1.14}_{-1.17}$ for $z\lessapprox2$, consistent with growth dominated by minor mergers, and $\alpha = 0.91^{+0.20}_{-0.16}$ for $z\gtrapprox2$, consistent with growth dominated by major mergers. These results indicate that massive quiescent galaxies originate from compact quenched systems and grow through combinations of minor and major mergers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19163v1" target="_blank">MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation</a></h3>
                    <p><strong>Authors:</strong> Ernest Lim, Yajie Vera He, Jared Joselowitz, Kate Preston, Mohita Chowdhury, Louis Williams, Aisling Higham, Katrina Mason, Mariane Melo, Tom Lawton, Yan Jia, Ibrahim Habli</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, cs.MA, 68T50, 68T42, 92C50, 68Q60, I.2.0; J.3</p>
                    <p><strong>Summary:</strong> Despite the growing use of large language models (LLMs) in clinical dialogue systems, existing evaluations focus on task completion or fluency, offering little insight into the behavioral and risk management requirements essential for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation), a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents. MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical scenarios, expected system behaviors and failure modes derived through structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator for detecting safety-relevant dialogue failures, validated against expert clinician annotations; and (3) PatBot, a simulated patient agent capable of producing diverse, scenario-conditioned responses, evaluated for realism and behavioral fidelity with human factors expertise, and a patient-preference study. Across three experiments, we show that MATRIX enables systematic, scalable safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded assessment of 240 dialogues. We also conducted one of the first realism analyses of LLM-based patient simulation, showing that PatBot reliably simulates realistic patient behavior in quantitative and qualitative evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios and 10 clinical domains. MATRIX is the first framework to unify structured safety engineering with scalable, validated conversational AI evaluation, enabling regulator-aligned safety auditing. We release all evaluation tools, prompts, structured scenarios, and datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19159v1" target="_blank">Safe Navigation under State Uncertainty: Online Adaptation for Robust Control Barrier Functions</a></h3>
                    <p><strong>Authors:</strong> Ersin Das, Rahal Nanayakkara, Xiao Tan, Ryan M. Bena, Joel W. Burdick, Paulo Tabuada, Aaron D. Ames</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.RO, cs.SY</p>
                    <p><strong>Summary:</strong> Measurements and state estimates are often imperfect in control practice, posing challenges for safety-critical applications, where safety guarantees rely on accurate state information. In the presence of estimation errors, several prior robust control barrier function (R-CBF) formulations have imposed strict conditions on the input. These methods can be overly conservative and can introduce issues such as infeasibility, high control effort, etc. This work proposes a systematic method to improve R-CBFs, and demonstrates its advantages on a tracked vehicle that navigates among multiple obstacles. A primary contribution is a new optimization-based online parameter adaptation scheme that reduces the conservativeness of existing R-CBFs. In order to reduce the complexity of the parameter optimization, we merge several safety constraints into one unified numerical CBF via Poissons equation. We further address the dual relative degree issue that typically causes difficulty in vehicle tracking. Experimental trials demonstrate the overall performance improvement of our approach over existing formulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19152v1" target="_blank">Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games</a></h3>
                    <p><strong>Authors:</strong> Chiu-Chou Lin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG, cs.MA, cs.SC</p>
                    <p><strong>Summary:</strong> Contemporary artificial intelligence (AI) development largely centers on rational decision-making, valued for its measurability and suitability for objective evaluation. Yet in real-world contexts, an intelligent agents decisions are shaped not only by logic but also by deeper influences such as beliefs, values, and preferences. The diversity of human decision-making styles emerges from these differences, highlighting that style is an essential but often overlooked dimension of intelligence. This dissertation introduces playstyle as an alternative lens for observing and analyzing the decision-making behavior of intelligent agents, and examines its foundational meaning and historical context from a philosophical perspective. By analyzing how beliefs and values drive intentions and actions, we construct a two-tier framework for style formation: the external interaction loop with the environment and the internal cognitive loop of deliberation. On this basis, we formalize style-related characteristics and propose measurable indicators such as style capacity, style popularity, and evolutionary dynamics. The study focuses on three core research directions: (1) Defining and measuring playstyle, proposing a general playstyle metric based on discretized state spaces, and extending it to quantify strategic diversity and competitive balance; (2) Expressing and generating playstyle, exploring how reinforcement learning and imitation learning can be used to train agents exhibiting specific stylistic tendencies, and introducing a novel approach for human-like style learning and modeling; and (3) Practical applications, analyzing the potential of these techniques in domains such as game design and interactive entertainment. Finally, the dissertation outlines future extensions, including the role of style as a core element in building artificial general intelligence (AGI).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19145v1" target="_blank">Echoes of the past: A unified perspective on fading memory and echo states</a></h3>
                    <p><strong>Authors:</strong> Juan-Pablo Ortega, Florian Rossmannek</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG, math.DS, 37N35, 68T05, 93B03</p>
                    <p><strong>Summary:</strong> Recurrent neural networks (RNNs) have become increasingly popular in information processing tasks involving time series and temporal data. A fundamental property of RNNs is their ability to create reliable input/output responses, often linked to how the network handles its memory of the information it processed. Various notions have been proposed to conceptualize the behavior of memory in RNNs, including steady states, echo states, state forgetting, input forgetting, and fading memory. Although these notions are often used interchangeably, their precise relationships remain unclear. This work aims to unify these notions in a common language, derive new implications and equivalences between them, and provide alternative proofs to some existing results. By clarifying the relationships between these concepts, this research contributes to a deeper understanding of RNNs and their temporal information processing capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19136v1" target="_blank">Using Machine Learning to Generate, Clarify, and Improve Economic Models</a></h3>
                    <p><strong>Authors:</strong> Annie Liang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> econ.TH</p>
                    <p><strong>Summary:</strong> Machine learning algorithms can now outperform classic economic models in predicting quantities ranging from bargaining outcomes, to choice under uncertainty, to an individuals future jobs and wages. Yet this predictive accuracy comes at a cost: most machine learning algorithms function as black boxes, offering little insight into \emph{why} outcomes occur. This article asks whether machine learning can guide the development of new economic theories. Economic models serve an important purpose beyond prediction -- they uncover the general mechanisms behind observed behaviors. A model that identifies the causal pathways of economic development is more valuable than one that merely predicts which countries will escape poverty, because it enables policymakers to encourage that development in countries where it might not have happened otherwise. Similarly, a model that predicts imperfectly across many domains can be more valuable than one that is highly accurate in a specific domain, since the former allows insights and data obtained from one setting to inform decisions and policy in another. Applying machine learning algorithms off-the-shelf is unlikely to yield such models. But recent work shows that, when reconceived with the aims of an economic modeler in mind, machine learning methods can improve both prediction and understanding. These approaches range from adversarially training algorithms to expose the limits of existing models, to imposing economic theory as a constraint on algorithmic search. Advances in large language models complement these strategies and open new research directions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19131v1" target="_blank">ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments</a></h3>
                    <p><strong>Authors:</strong> Shreya Gummadi, Mateus V. Gasparino, Gianluca Capezzuto, Marcelo Becker, Girish Chowdhary</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The advancement of robotics and autonomous navigation systems hinges on the ability to accurately predict terrain traversability. Traditional methods for generating datasets to train these prediction models often involve putting robots into potentially hazardous environments, posing risks to equipment and safety. To solve this problem, we present ZeST, a novel approach leveraging visual reasoning capabilities of Large Language Models (LLMs) to create a traversability map in real-time without exposing robots to danger. Our approach not only performs zero-shot traversability and mitigates the risks associated with real-world data collection but also accelerates the development of advanced navigation systems, offering a cost-effective and scalable solution. To support our findings, we present navigation results, in both controlled indoor and unstructured outdoor environments. As shown in the experiments, our method provides safer navigation when compared to other state-of-the-art methods, constantly reaching the final goal.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1515/ms-2025-0015" target="_blank">Comparison of Topologies on Fundamental Groups with Subgroup Topology Viewpoint</a></h3>
                    <p><strong>Authors:</strong> Naghme Shahami, Behrooz Mashayekhy</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.AT, 57M05, 55Q05, 57M07, 57M10, 57M12</p>
                    <p><strong>Summary:</strong> In order to make the fundamental group, one of the most well known invariants in algebraic topology, more useful and powerful some researchers have been introduced and studied various topologies on the fundamental group from the beginning of the 21st century onwards. In this paper by reviewing these topologies, using the concept of subgroup topology, we are going to compare these topologies in order to present some results on topologized fundamental groups.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19121v1" target="_blank">Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings</a></h3>
                    <p><strong>Authors:</strong> Xiaolin He, Zirui Li, Xinwei Wang, Riender Happee, Meng Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Perceived risk in automated vehicles (AVs) can create the very danger that automation is meant to prevent: a frightened rider may hesitate when seconds matter, misjudge hazards, or disengage. However, measuring how perceived risk evolves in real time during driving remains challenging, leaving a gap in decoding such hidden psychological states. Here, we present a novel method to time-continuously measure and decode perceived risk. We conducted a controlled experiment where 2,164 participants viewed high-fidelity videos of common highway driving scenes and provided 141,628 discrete safety ratings. Through continuous-signal reconstruction of the discrete ratings, we obtained 236 hours of time-continuous perceived risk data - the largest perceived risk dataset to date. Leveraging this dataset, we trained deep neural networks that predict moment-by-moment perceived risk from vehicle kinematics with a mean relative error below $3\%$. Explainable AI analysis uncovers which factors determine perceived risk in real time. Our findings demonstrate a new paradigm for quantifying dynamic passenger experience and psychological constructs in real time. These findings can guide the design of AVs and other machines that operate in close proximity to people, adjusting behaviour before trust erodes, and help realise automations benefits in transport, healthcare, and service robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19115v1" target="_blank">SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications</a></h3>
                    <p><strong>Authors:</strong> Joshua Lee, Ali Arastehfard, Weiran Liu, Xuegang Ban, Yuan Hong</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, E.3; I.2.6; I.5.1; F.1.2</p>
                    <p><strong>Summary:</strong> Autonomous driving and V2X technologies have developed rapidly in the past decade, leading to improved safety and efficiency in modern transportation. These systems interact with extensive networks of vehicles, roadside infrastructure, and cloud resources to support their machine learning capabilities. However, the widespread use of machine learning in V2X systems raises issues over the privacy of the data involved. This is particularly concerning for smart-transit and driver safety applications which can implicitly reveal user locations or explicitly disclose medical data such as EEG signals. To resolve these issues, we propose SecureV2X, a scalable, multi-agent system for secure neural network inferences deployed between the server and each vehicle. Under this setting, we study two multi-agent V2X applications: secure drowsiness detection, and secure red-light violation detection. Our system achieves strong performance relative to baselines, and scales efficiently to support a large number of secure computation interactions simultaneously. For instance, SecureV2X is $9.4 \times$ faster, requires $143\times$ fewer computational rounds, and involves $16.6\times$ less communication on drowsiness detection compared to other secure systems. Moreover, it achieves a runtime nearly $100\times$ faster than state-of-the-art benchmarks in object detection tasks for red light violation detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19099v1" target="_blank">Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic</a></h3>
                    <p><strong>Authors:</strong> Thomas Compton</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Quantitative Discourse Analysis has seen growing adoption with the rise of Large Language Models and computational tools. However, reliance on black box software such as MAXQDA and NVivo risks undermining methodological transparency and alignment with research goals. This paper presents a hybrid, transparent framework for QDA that combines lexical and semantic methods to enable triangulation, reproducibility, and interpretability. Drawing from a case study in historical political discourse, we demonstrate how custom Python pipelines using NLTK, spaCy, and Sentence Transformers allow fine-grained control over preprocessing, lemmatisation, and embedding generation. We further detail our iterative BERTopic modelling process, incorporating UMAP dimensionality reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised through parameter tuning and multiple runs to enhance topic coherence and coverage. By juxtaposing precise lexical searches with context-aware semantic clustering, we argue for a multi-layered approach that mitigates the limitations of either method in isolation. Our workflow underscores the importance of code-level transparency, researcher agency, and methodological triangulation in computational discourse studies. Code and supplementary materials are available via GitHub.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19097v1" target="_blank">Reasoning LLMs in the Medical Domain: A Literature Survey</a></h3>
                    <p><strong>Authors:</strong> Armin Berger, Sarthak Khanna, David Berghaus, Rafet Sifa</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The emergence of advanced reasoning capabilities in Large Language Models (LLMs) marks a transformative development in healthcare applications. Beyond merely expanding functional capabilities, these reasoning mechanisms enhance decision transparency and explainability-critical requirements in medical contexts. This survey examines the transformation of medical LLMs from basic information retrieval tools to sophisticated clinical reasoning systems capable of supporting complex healthcare decisions. We provide a thorough analysis of the enabling technological foundations, with a particular focus on specialized prompting techniques like Chain-of-Thought and recent breakthroughs in Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates purpose-built medical frameworks while also examining emerging paradigms such as multi-agent collaborative systems and innovative prompting architectures. The survey critically assesses current evaluation methodologies for medical validation and addresses persistent challenges in field interpretation limitations, bias mitigation strategies, patient safety frameworks, and integration of multimodal clinical data. Through this survey, we seek to establish a roadmap for developing reliable LLMs that can serve as effective partners in clinical practice and medical research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19096v1" target="_blank">Trustworthy Agents for Electronic Health Records through Confidence Estimation</a></h3>
                    <p><strong>Authors:</strong> Yongwoo Song, Minbyul Jeong, Mujeen Sung</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) show promise for extracting information from Electronic Health Records (EHR) and supporting clinical decisions. However, deployment in clinical settings faces challenges due to hallucination risks. We propose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric quantifying the accuracy-reliability trade-off at varying confidence thresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating stepwise confidence estimation for clinical question answering. Experiments on MIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under strict reliability constraints, achieving improvements of 44.23%p and 25.34%p at HCAcc@70% while baseline methods fail at these thresholds. These results highlight limitations of traditional accuracy metrics in evaluating healthcare AI agents. Our work contributes to developing trustworthy clinical agents that deliver accurate information or transparently express uncertainty when confidence is low.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19093v1" target="_blank">Retrieval-Augmented Generation for Natural Language Art Provenance Searches in the Getty Provenance Index</a></h3>
                    <p><strong>Authors:</strong> Mathew Henrickson</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This research presents a Retrieval-Augmented Generation (RAG) framework for art provenance studies, focusing on the Getty Provenance Index. Provenance research establishes the ownership history of artworks, which is essential for verifying authenticity, supporting restitution and legal claims, and understanding the cultural and historical context of art objects. The process is complicated by fragmented, multilingual archival data that hinders efficient retrieval. Current search portals require precise metadata, limiting exploratory searches. Our method enables natural-language and multilingual searches through semantic retrieval and contextual summarization, reducing dependence on metadata structures. We assess RAGs capability to retrieve and summarize auction records using a 10,000-record sample from the Getty Provenance Index - German Sales. The results show this approach provides a scalable solution for navigating art market archives, offering a practical tool for historians and cultural heritage professionals conducting historically sensitive research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19092v1" target="_blank">Measurement of the branching fraction of $\psip \to ωηη$</a></h3>
                    <p><strong>Authors:</strong> BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. Chen, Z. J. Chen, Z. K. Chen, J. C. Cheng, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. C. Liu, Lu Liu, M. H. Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. L. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, Heng Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, Zirong Song, S. Sosio, S. Spataro, S Stansilaus, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, S. H. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, Zhang, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> Using a sample of (2.712 $\pm$ 0.014)$\times 10^{9}$ $\psip$ events collected with the BESIII detector at the BEPCII collider in 2009, 2012, and 2021, the decay $\psip \to \omega \eta \eta $ is observed for the first time. The branching fraction of the $\psi(3686)\to\omega\eta\eta$ decay is measured to be (1.65 $\pm$ 0.02 $\pm$ 0.21)$\times 10^{-5}$, where the first uncertainty is statistical and the second systematic. Clear structures associated with the well-established $\omega(1420)$ and $f_{0}(1710)$ resonances are observed in the $\omega\eta$ and $\eta\eta$ invariant-mass spectra, respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19090v1" target="_blank">Building an Open CGRA Ecosystem for Agile Innovation</a></h3>
                    <p><strong>Authors:</strong> Rohan Juneja, Pranav Dangi, Thilini Kaushalya Bandara, Zhaoying Li, Dhananjaya Wijerathne, Li-Shiuan Peh, Tulika Mitra</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> Modern computing workloads, particularly in AI and edge applications, demand hardware-software co-design to meet aggressive performance and energy targets. Such co-design benefits from open and agile platforms that replace closed, vertically integrated development with modular, community-driven ecosystems. Coarse-Grained Reconfigurable Architectures (CGRAs), with their unique balance of flexibility and efficiency are particularly well-suited for this paradigm. When built on open-source hardware generators and software toolchains, CGRAs provide a compelling foundation for architectural exploration, cross-layer optimization, and real-world deployment. In this paper, we will present an open CGRA ecosystem that we have developed to support agile innovation across the stack. Our contributions include HyCUBE, a CGRA with a reconfigurable single-cycle multi-hop interconnect for efficient data movement; PACE, which embeds a power-efficient HyCUBE within a RISC-V SoC targeting edge computing; and Morpher, a fully open-source, architecture-adaptive CGRA design framework that supports design space exploration, compilation, simulation, and validation. By embracing openness at every layer, we aim to lower barriers to innovation, enable reproducible research, and demonstrate how CGRAs can anchor the next wave of agile hardware development. We will conclude with a call for a unified abstraction layer for CGRAs and spatial accelerators, one that decouples hardware specialization from software development. Such a representation would unlock architectural portability, compiler innovation, and a scalable, open foundation for spatial computing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19087v1" target="_blank">APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration</a></h3>
                    <p><strong>Authors:</strong> Shaobo Ma, Chao Fang, Haikuo Shao, Zhongfeng Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.AR</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup over CUTLASS integer baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19060v1" target="_blank">No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes</a></h3>
                    <p><strong>Authors:</strong> Blaž Rolih, Matic Fučka, Danijel Skočaj</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Surface defect detection is a critical task across numerous industries, aimed at efficiently identifying and localising imperfections or irregularities on manufactured components. While numerous methods have been proposed, many fail to meet industrial demands for high performance, efficiency, and adaptability. Existing approaches are often constrained to specific supervision scenarios and struggle to adapt to the diverse data annotations encountered in real-world manufacturing processes, such as unsupervised, weakly supervised, mixed supervision, and fully supervised settings. To address these challenges, we propose SuperSimpleNet, a highly efficient and adaptable discriminative model built on the foundation of SimpleNet. SuperSimpleNet incorporates a novel synthetic anomaly generation process, an enhanced classification head, and an improved learning procedure, enabling efficient training in all four supervision scenarios, making it the first model capable of fully leveraging all available data annotations. SuperSimpleNet sets a new standard for performance across all scenarios, as demonstrated by its results on four challenging benchmark datasets. Beyond accuracy, it is very fast, achieving an inference time below 10 ms. With its ability to unify diverse supervision paradigms while maintaining outstanding speed and reliability, SuperSimpleNet represents a promising step forward in addressing real-world manufacturing challenges and bridging the gap between academic research and industrial applications. Code: https://github.com/blaz-r/SuperSimpleNet</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19042v1" target="_blank">A Concurrent Modular Agent: Framework for Autonomous LLM Agents</a></h3>
                    <p><strong>Authors:</strong> Norihiro Maruyama, Takahide Yoshida, Hiroki Sato, Atsushi Masumori, Johnsmith, Takashi Ikegami</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We introduce the Concurrent Modular Agent (CMA), a framework that orchestrates multiple Large-Language-Model (LLM)-based modules that operate fully asynchronously yet maintain a coherent and fault-tolerant behavioral loop. This framework addresses long-standing difficulties in agent architectures by letting intention emerge from language-mediated interactions among autonomous processes. This approach enables flexible, adaptive, and context-dependent behavior through the combination of concurrently executed modules that offload reasoning to an LLM, inter-module communication, and a single shared global state.We consider this approach to be a practical realization of Minskys Society of Mind theory. We demonstrate the viability of our system through two practical use-case studies. The emergent properties observed in our system suggest that complex cognitive phenomena like self-awareness may indeed arise from the organized interaction of simpler processes, supporting Minsky-Society of Mind concept and opening new avenues for artificial intelligence research. The source code for our work is available at: https://github.com/AlternativeMachine/concurrent-modular-agent.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19036v1" target="_blank">Of the People, By the Algorithm: How AI Transforms Democratic Representation</a></h3>
                    <p><strong>Authors:</strong> Yuval Rymon</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This review examines how AI technologies are transforming democratic representation, focusing on citizen participation and algorithmic decision-making. The analysis reveals that AI technologies are reshaping democratic processes in fundamental ways: enabling mass-scale deliberation, changing how citizens access and engage with political information, and transforming how representatives make and implement decisions. While AI offers unprecedented opportunities for enhancing democratic participation and governance efficiency, it also presents significant challenges to democratic legitimacy and accountability. Social media platforms AI-driven algorithms currently mediate much political discourse, creating concerns about information manipulation and privacy. Large Language Models introduce both epistemic challenges and potential tools for improving democratic dialogue. The emergence of Mass Online Deliberation platforms suggests possibilities for scaling up meaningful citizen participation, while Algorithmic Decision-Making systems promise more efficient policy implementation but face limitations in handling complex political trade-offs. As these systems become prevalent, representatives may assume the role of architects of automated decision frameworks, responsible for guiding the translation of politically contested concepts into technical parameters and metrics. Advanced deliberation platforms offering real-time insights into citizen preferences will challenge traditional representative independence and discretion to interpret public will. The institutional integration of these participation mechanisms requires frameworks that balance the benefits with democratic stability through hybrid systems weighting different forms of democratic expression.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19029v1" target="_blank">When recalling in-context, Transformers are not SSMs</a></h3>
                    <p><strong>Authors:</strong> Destiny Okpekpe, Antonio Orvieto</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite the advantageous subquadratic complexity of modern recurrent deep learning models -- such as state-space models (SSMs) -- recent studies have highlighted their potential shortcomings compared to transformers on reasoning and memorization tasks. In this paper, we dive deeper into one of such benchmarks: associative recall (AR), which has been shown to correlate well with language modeling performance, and inspect in detail the effects of scaling and optimization issues in recently proposed token mixing strategies. We first demonstrate that, unlike standard transformers, the choice of learning rate plays a critical role in the performance of modern recurrent models: an issue that can severely affect reported performance in previous works and suggests further research is needed to stabilize training. Next, we show that recurrent and attention-based models exhibit contrasting benefits when scaling in width as opposed to depth, with attention being notably unable to solve AR when limited to a single layer. We then further inspect 1-layer transformers, revealing that despite their poor performance, their training dynamics surprisingly resemble the formation of induction heads, a phenomenon previously observed only in their 2-layer counterparts. Finally, through architectural ablations, we study how components affects Transformer and Mambas performance and optimization stability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19026v1" target="_blank">MovieCORE: COgnitive REasoning in Movies</a></h3>
                    <p><strong>Authors:</strong> Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at https://joslefaure.github.io/assets/html/moviecore.html.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19021v1" target="_blank">MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis</a></h3>
                    <p><strong>Authors:</strong> Riju Marwah, Riya Arora, Navneet Yadav, Himank Arora</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the prevalence of plastics exceeding 368 million tons yearly, microplastic pollution has grown to an extent where air, water, soil, and living organisms have all tested positive for microplastic presence. These particles, which are smaller than 5 millimeters in size, are no less harmful to humans than to the environment. Toxicity research on microplastics has shown that exposure may cause liver infection, intestinal injuries, and gut flora imbalance, leading to numerous potential health hazards. This paper presents a new model, MicroDetect-Net (MDN), which applies fluorescence microscopy with Nile Red dye staining and deep learning to scan blood samples for microplastics. Although clam blood has certain limitations in replicating real human blood, this study opens avenues for applying the approach to human samples, which are more consistent for preliminary data collection. The MDN model integrates dataset preparation, fluorescence imaging, and segmentation using a convolutional neural network to localize and count microplastic fragments. The combination of convolutional networks and Nile Red dye for segmentation produced strong image detection and accuracy. MDN was evaluated on a dataset of 276 Nile Red-stained fluorescent blood images and achieved an accuracy of ninety two percent. Robust performance was observed with an Intersection over Union of 87.4 percent, F1 score of 92.1 percent, Precision of 90.6 percent, and Recall of 93.7 percent. These metrics demonstrate the effectiveness of MDN in the detection of microplastics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19016v1" target="_blank">Working My Way Back to You: Resource-Centric Next-Activity Prediction</a></h3>
                    <p><strong>Authors:</strong> Kelly Kurowski, Xixi Lu, Hajo A Reijers</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Predictive Process Monitoring (PPM) aims to train models that forecast upcoming events in process executions. These predictions support early bottleneck detection, improved scheduling, proactive interventions, and timely communication with stakeholders. While existing research adopts a control-flow perspective, we investigate next-activity prediction from a resource-centric viewpoint, which offers additional benefits such as improved work organization, workload balancing, and capacity forecasting. Although resource information has been shown to enhance tasks such as process performance analysis, its role in next-activity prediction remains unexplored. In this study, we evaluate four prediction models and three encoding strategies across four real-life datasets. Compared to the baseline, our results show that LightGBM and Transformer models perform best with an encoding based on 2-gram activity transitions, while Random Forest benefits most from an encoding that combines 2-gram transitions and activity repetition features. This combined encoding also achieves the highest average accuracy. This resource-centric approach could enable smarter resource allocation, strategic workforce planning, and personalized employee support by analyzing individual behavior rather than case-level progression. The findings underscore the potential of resource-centric next-activity prediction, opening up new venues for research on PPM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19009v1" target="_blank">FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning</a></h3>
                    <p><strong>Authors:</strong> Md Anwar Hossen, Fatema Siddika, Wensheng Zhang, Anuj Sharma, Ali Jannesari</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.DC</p>
                    <p><strong>Summary:</strong> Heterogeneous Federated Learning (HFL) has gained attention for its ability to accommodate diverse models and heterogeneous data across clients. Prototype-based HFL methods emerge as a promising solution to address statistical heterogeneity and privacy challenges, paving the way for new advancements in HFL research. This method focuses on sharing only class-representative prototypes among heterogeneous clients. However, these prototypes are often aggregated on the server using weighted averaging, leading to sub-optimal global knowledge; these cause the shrinking of aggregated prototypes, which negatively affects the model performance in scenarios when models are heterogeneous and data distributions are extremely non-IID. We propose FedProtoKD in a Heterogeneous Federated Learning setting, using an enhanced dual-knowledge distillation mechanism to improve the system performance with clients logits and prototype feature representation. We aim to resolve the prototype margin-shrinking problem using a contrastive learning-based trainable server prototype by leveraging a class-wise adaptive prototype margin. Furthermore, we assess the importance of public samples using the closeness of the samples prototype to its class representative prototypes, which enhances learning performance. FedProtoKD achieved average improvements of 1.13% up to 34.13% accuracy across various settings and significantly outperforms existing state-of-the-art HFL methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19008v1" target="_blank">Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI</a></h3>
                    <p><strong>Authors:</strong> Marcin Moskalewicz, Anna Sterna, Marek Pokropski, Paula Flores</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This study examines the capacity of large language models (LLMs) to support phenomenological qualitative analysis of first-person experience in Borderline Personality Disorder (BPD), understood as a disorder of temporality and selfhood. Building on a prior human-led thematic analysis of 24 inpatients life-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5 Pro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the original investigators. The models were evaluated with blinded and non-blinded expert judges in phenomenology and clinical psychology. Assessments included semantic congruence, Jaccard coefficients, and multidimensional validity ratings (credibility, coherence, substantiveness, and groundness in data). Results showed variable overlap with the human analysis, from 0 percent in GPT to 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient (0.21-0.28). However, the models recovered themes omitted by humans. Geminis output most closely resembled the human analysis, with validity scores significantly higher than GPT and Claude (p  0.78) with the quantity of text and words per theme, highlighting both the variability and potential of AI-augmented thematic analysis to mitigate human interpretative bias.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19005v1" target="_blank">Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark</a></h3>
                    <p><strong>Authors:</strong> Yuxuan Cai, Yipeng Hao, Jie Zhou, Hang Yan, Zhikai Lei, Rui Zhen, Zhenhua Han, Yutao Yang, Junsong Li, Qianjun Pan, Tianyu Huai, Qin Chen, Xin Li, Kai Chen, Bo Zhang, Xipeng Qiu, Liang He</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as second nature. We also introduce StuLife, a benchmark dataset for ELL that simulates a students holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around three key paradigm shifts: From Passive to Proactive, From Context to Memory, and From Imitation to Learning. In this dynamic environment, agents must acquire and distill practical skills and maintain persistent memory to make decisions based on evolving state variables. StuLife provides a comprehensive platform for evaluating lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior. Beyond evaluating SOTA LLMs on the StuLife benchmark, we also explore the role of context engineering in advancing AGI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19006v1" target="_blank">Is attention truly all we need? An empirical study of asset pricing in pretrained RNN sparse and global attention models</a></h3>
                    <p><strong>Authors:</strong> Shanyan Lai</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> q-fin.PR, cs.LG, econ.EM, q-fin.CP, 62M10, 62P20, 91G70, 68T07, I.2.6; I.5.1; J.4; G.3</p>
                    <p><strong>Summary:</strong> This study investigates the pretrained RNN attention models with the mainstream attention mechanisms such as additive attention, Luongs three attentions, global self-attention (Self-att) and sliding window sparse attention (Sparse-att) for the empirical asset pricing research on top 420 large-cap US stocks. This is the first paper on the large-scale state-of-the-art (SOTA) attention mechanisms applied in the asset pricing context. They overcome the limitations of the traditional machine learning (ML) based asset pricing, such as mis-capturing the temporal dependency and short memory. Moreover, the enforced causal masks in the attention mechanisms address the future data leaking issue ignored by the more advanced attention-based models, such as the classic Transformer. The proposed attention models also consider the temporal sparsity characteristic of asset pricing data and mitigate potential overfitting issues by deploying the simplified model structures. This provides some insights for future empirical economic research. All models are examined in three periods, which cover pre-COVID-19 (mild uptrend), COVID-19 (steep uptrend with a large drawdown) and one year post-COVID-19 (sideways movement with high fluctuations), for testing the stability of these models under extreme market conditions. The study finds that in value-weighted portfolio back testing, Model Self-att and Model Sparse-att exhibit great capabilities in deriving the absolute returns and hedging downside risks, while they achieve an annualized Sortino ratio of 2.0 and 1.80 respectively in the period with COVID-19. And Model Sparse-att performs more stably than Model Self-att from the perspective of absolute portfolio returns with respect to the size of stocks market capitalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19004v1" target="_blank">AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms</a></h3>
                    <p><strong>Authors:</strong> Pontus Strimling, Simon Karlsson, Irina Vartanova, Kimmo Eriksson</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> A fundamental question in cognitive science concerns how social norms are acquired and represented. While humans typically learn norms through embodied social experience, we investigated whether large language models can achieve sophisticated norm understanding through statistical learning alone. Across two studies, we systematically evaluated multiple AI systems ability to predict human social appropriateness judgments for 555 everyday scenarios by examining how closely they predicted the average judgment compared to each human participant. In Study 1, GPT-4.5s accuracy in predicting the collective judgment on a continuous scale exceeded that of every human participant (100th percentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7% of humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive power, all models showed systematic, correlated errors. These findings demonstrate that sophisticated models of social cognition can emerge from statistical learning over linguistic data alone, challenging strong versions of theories emphasizing the exclusive necessity of embodied experience for cultural competence. The systematic nature of AI limitations across different architectures indicates potential boundaries of pattern-based social understanding, while the models ability to outperform nearly all individual humans in this predictive task suggests that language serves as a remarkably rich repository for cultural knowledge transmission.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19001v1" target="_blank">Bayesian Joint Modeling of Zero-Inflated Longitudinal Data and Survival with a Cure Fraction: Application to AIDS Data</a></h3>
                    <p><strong>Authors:</strong> Taban Baghfalaki, Mojtaba Ganjali</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.AP</p>
                    <p><strong>Summary:</strong> We propose a comprehensive Bayesian joint modeling framework for zero-inflated longitudinal count data and time-to-event outcomes, explicitly incorporating a cure fraction to account for subjects who never experience the event. The longitudinal sub-model employs a flexible mixed-effects Hurdle model, with distributional options including zero-inflated Poisson and zero-inflated negative binomial, accommodating excess zeros and overdispersion common in count data. The survival component is modeled using a Cox proportional hazards model combined with a mixture cure model to distinguish cured from susceptible individuals. To link the longitudinal and survival processes, we include a linear combination of current longitudinal values as predictors in the survival model. Inference is performed via Hamiltonian Monte Carlo, enabling efficient and robust parameter estimation. The joint model supports dynamic predictions, facilitating real-time risk assessment and personalized medicine. Model performance and estimation accuracy are validated through simulation studies. Finally, we illustrate the methodology using a real-world HIV cohort dataset, demonstrating its practical utility in predicting patient survival outcomes and supporting personalized treatment decisions. Our results highlight the benefits of integrating complex longitudinal count data with survival information in clinical research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18997v1" target="_blank">Carathéodory-type selection and random fixed point theorems for discontinuous correspondences</a></h3>
                    <p><strong>Authors:</strong> Anuj Bhowmik, Nicholas C. Yannelis</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.GN, math.PR</p>
                    <p><strong>Summary:</strong> Research in Economics and Game theory has necessitated results on Carath\eodory-type selections. In particular, one has to obtain Carath\eodory type-selections from correspondences that need not be continuous (neither lower-semicontinuous nor upper-semicontinuous). We provide new theorems on Carath\eodory type-selections that include as corollaries the results in Kim-Prikry-Yannelis \cite{KPY:87}. We also, obtain new random fixed-point theorems, random maximal elements, random (Nash) equilibrium and Bayesian equilibrium extending and generalizing theorems of Browder \cite{Browder:68}, Fan \cite{Fan:52} and Nash \cite{Nash}, among others.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18992v1" target="_blank">Automatic Prompt Optimization with Prompt Distillation</a></h3>
                    <p><strong>Authors:</strong> Viktor N. Zhuravlev, Artur R. Khairullin, Ernest A. Dyagin, Alena N. Sitkina, Nikita I. Kulin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Autoprompting is the process of automatically selecting optimized prompts for language models, which is gaining popularity due to the rapid development of prompt engineering driven by extensive research in the field of large language models (LLMs). This paper presents DistillPrompt -- a novel autoprompting method based on large language models that employs a multi-stage integration of task-specific information into prompts using training data. DistillPrompt utilizes distillation, compression, and aggregation operations to explore the prompt space more thoroughly. The method was tested on different datasets for text classification and generation tasks using the t-lite-instruct-0.1 language model. The results demonstrate a significant average improvement (e.g., 20.12% across the entire dataset compared to Grips) in key metrics over existing methods in the field, establishing DistillPrompt as one of the most effective non-gradient approaches in autoprompting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18988v1" target="_blank">Interpretable by AI Mother Tongue: Native Symbolic Reasoning in Neural Models</a></h3>
                    <p><strong>Authors:</strong> Hung Ming Liu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> We present a framework where neural models develop an AI Mother Tongue, a native symbolic language that simultaneously supports intuitive reasoning, compositional symbol chains, and inherent interpretability. Unlike post-hoc explanation methods, our approach embeds reasoning directly into the models representations: symbols capture meaningful semantic patterns, chains trace decision paths, and gated induction mechanisms guide selective focus, yielding transparent yet flexible reasoning. We introduce complementary training objectives to enhance symbol purity and decision sparsity, and employ a sequential specialization strategy to first build broad symbolic competence and then refine intuitive judgments. Experiments on AI tasks demonstrate competitive accuracy alongside verifiable reasoning traces, showing that AI Mother Tongue can serve as a unified mechanism for interpretability, intuition, and symbolic reasoning in neural models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18975v1" target="_blank">Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data</a></h3>
                    <p><strong>Authors:</strong> Jan Nikolas Morshuis, Matthias Hein, Christian F. Baumgartner</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> MR imaging is a valuable diagnostic tool allowing to non-invasively visualize patient anatomy and pathology with high soft-tissue contrast. However, MRI acquisition is typically time-consuming, leading to patient discomfort and increased costs to the healthcare system. Recent years have seen substantial research effort into the development of methods that allow for accelerated MRI acquisition while still obtaining a reconstruction that appears similar to the fully-sampled MR image. However, for many applications a perfectly reconstructed MR image may not be necessary, particularly, when the primary goal is a downstream task such as segmentation. This has led to growing interest in methods that aim to perform segmentation directly on accelerated MRI data. Despite recent advances, existing methods have largely been developed in isolation, without direct comparison to one another, often using separate or private datasets, and lacking unified evaluation standards. To date, no high-quality, comprehensive comparison of these methods exists, and the optimal strategy for segmenting accelerated MR data remains unknown. This paper provides the first unified benchmark for the segmentation of undersampled MRI data comparing 7 approaches. A particular focus is placed on comparing \textit{one-stage approaches}, that combine reconstruction and segmentation into a unified model, with \textit{two-stage approaches}, that utilize established MRI reconstruction methods followed by a segmentation network. We test these methods on two MRI datasets that include multi-coil k-space data as well as a human-annotated segmentation ground-truth. We find that simple two-stage methods that consider data-consistency lead to the best segmentation scores, surpassing complex specialized methods that are developed specifically for this task.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18966v1" target="_blank">USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning</a></h3>
                    <p><strong>Authors:</strong> Shaojin Wu, Mengqi Huang, Yufeng Cheng, Wenxu Wu, Jiahe Tian, Yiming Luo, Fei Ding, Qian He</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Existing literature typically treats style-driven and subject-driven generation as two disjoint tasks: the former prioritizes stylistic similarity, whereas the latter insists on subject consistency, resulting in an apparent antagonism. We argue that both objectives can be unified under a single framework because they ultimately concern the disentanglement and re-composition of content and style, a long-standing theme in style-driven research. To this end, we present USO, a Unified Style-Subject Optimized customization model. First, we construct a large-scale triplet dataset consisting of content images, style images, and their corresponding stylized content images. Second, we introduce a disentangled learning scheme that simultaneously aligns style features and disentangles content from style through two complementary objectives, style-alignment training and content-style disentanglement training. Third, we incorporate a style reward-learning paradigm denoted as SRL to further enhance the models performance. Finally, we release USO-Bench, the first benchmark that jointly evaluates style similarity and subject fidelity across multiple metrics. Extensive experiments demonstrate that USO achieves state-of-the-art performance among open-source models along both dimensions of subject consistency and style similarity. Code and model: https://github.com/bytedance/USO</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3748636.3764154" target="_blank">Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers</a></h3>
                    <p><strong>Authors:</strong> Claudio Affolter, Sidi Wu, Yizi Chen, Lorenz Hurni</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Traditional map-making relies heavily on Geographic Information Systems (GIS), requiring domain expertise and being time-consuming, especially for repetitive tasks. Recent advances in generative AI (GenAI), particularly image diffusion models, offer new opportunities for automating and democratizing the map-making process. However, these models struggle with accurate map creation due to limited control over spatial composition and semantic layout. To address this, we integrate vector data to guide map generation in different styles, specified by the textual prompts. Our model is the first to generate accurate maps in controlled styles, and we have integrated it into a web application to improve its usability and accessibility. We conducted a user study with professional cartographers to assess the fidelity of generated maps, the usability of the web application, and the implications of ever-emerging GenAI in map-making. The findings have suggested the potential of our developed application and, more generally, the GenAI models in helping both non-expert users and professionals in creating maps more efficiently. We have also outlined further technical improvements and emphasized the new role of cartographers to advance the paradigm of AI-assisted map-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18955v1" target="_blank">Interleaving Large Language Models for Compiler Testing</a></h3>
                    <p><strong>Authors:</strong> Yunbo Ni, Shaohua Li</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Testing compilers with AI models, especially large language models (LLMs), has shown great promise. However, current approaches struggle with two key problems: The generated programs for testing compilers are often too simple, and extensive testing with the LLMs is computationally expensive. In this paper, we propose a novel compiler testing framework that decouples the testing process into two distinct phases: an offline phase and an online phase. In the offline phase, we use LLMs to generate a collection of small but feature-rich code pieces. In the online phase, we reuse these code pieces by strategically combining them to build high-quality and valid test programs, which are then used to test compilers. We implement this idea in a tool, LegoFuzz, for testing C compilers. The results are striking: we found 66 bugs in GCC and LLVM, the most widely used C compilers. Almost half of the bugs are miscompilation bugs, which are serious and hard-to-find bugs that none of the existing LLM-based tools could find. We believe this efficient design opens up new possibilities for using AI models in software testing beyond just C compilers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18954v1" target="_blank">On the Generalisation of Koopman Representations for Chaotic System Control</a></h3>
                    <p><strong>Authors:</strong> Kyriakos Hjikakou, Juan Diego Cardenas Cartagena, Matthia Sabatelli</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> This paper investigates the generalisability of Koopman-based representations for chaotic dynamical systems, focusing on their transferability across prediction and control tasks. Using the Lorenz system as a testbed, we propose a three-stage methodology: learning Koopman embeddings through autoencoding, pre-training a transformer on next-state prediction, and fine-tuning for safety-critical control. Our results show that Koopman embeddings outperform both standard and physics-informed PCA baselines, achieving accurate and data-efficient performance. Notably, fixing the pre-trained transformer weights during fine-tuning leads to no performance degradation, indicating that the learned representations capture reusable dynamical structure rather than task-specific patterns. These findings support the use of Koopman embeddings as a foundation for multi-task learning in physics-informed machine learning. A project page is available at https://kikisprdx.github.io/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18953v1" target="_blank">Novel Approaches to Artificial Intelligence Development Based on the Nearest Neighbor Method</a></h3>
                    <p><strong>Authors:</strong> I. I. Priezzhev, D. A. Danko, A. V. Shubin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, I.2.6; I.2.8; I.5.1</p>
                    <p><strong>Summary:</strong> Modern neural network technologies, including large language models, have achieved remarkable success in various applied artificial intelligence applications, however, they face a range of fundamental limitations. Among them are hallucination effects, high computational complexity of training and inference, costly fine-tuning, and catastrophic forgetting issues. These limitations significantly hinder the use of neural networks in critical areas such as medicine, industrial process management, and scientific research. This article proposes an alternative approach based on the nearest neighbors method with hierarchical clustering structures. Employing the k-nearest neighbors algorithm significantly reduces or completely eliminates hallucination effects while simplifying model expansion and fine-tuning without the need for retraining the entire network. To overcome the high computational load of the k-nearest neighbors method, the paper proposes using tree-like data structures based on Kohonen self-organizing maps, thereby greatly accelerating nearest neighbor searches. Tests conducted on handwritten digit recognition and simple subtitle translation tasks confirmed the effectiveness of the proposed approach. With only a slight reduction in accuracy, the nearest neighbor search time was reduced hundreds of times compared to exhaustive search methods. The proposed method features transparency and interpretability, closely aligns with human cognitive mechanisms, and demonstrates potential for extensive use in tasks requiring high reliability and explainable results.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19243v1" target="_blank">Style4D-Bench: A Benchmark Suite for 4D Stylization</a></h3>
                    <p><strong>Authors:</strong> Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, 2) a strong baseline that make an initial attempt for 4D stylization, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes. Project page: https://becky-catherine.github.io/Style4D . Code: https://github.com/Becky-catherine/Style4D-Bench .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19244v1" target="_blank">Articulate3D: Zero-Shot Text-Driven 3D Object Posing</a></h3>
                    <p><strong>Authors:</strong> Oishi Deb, Anjun Hu, Ashkan Khakzar, Philip Torr, Christian Rupprecht</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We propose a training-free method, Articulate3D, to pose a 3D asset through language control. Despite advances in vision and language models, this task remains surprisingly challenging. To achieve this goal, we decompose the problem into two steps. We modify a powerful image-generator to create target images conditioned on the input image and a text instruction. We then align the mesh to the target images through a multi-view pose optimisation step. In detail, we introduce a self-attention rewiring mechanism (RSActrl) that decouples the source structure from pose within an image generative model, allowing it to maintain a consistent structure across varying poses. We observed that differentiable rendering is an unreliable signal for articulation optimisation; instead, we use keypoints to establish correspondences between input and target images. The effectiveness of Articulate3D is demonstrated across a diverse range of 3D objects and free-form text prompts, successfully manipulating poses while maintaining the original identity of the mesh. Quantitative evaluations and a comparative user study, in which our method was preferred over 85\% of the time, confirm its superiority over existing approaches. Project page:https://odeb1.github.io/articulate3d_page_deb/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19239v1" target="_blank">Model Context Protocols in Adaptive Transport Systems: A Survey</a></h3>
                    <p><strong>Authors:</strong> Gaurab Chhetri, Shriyank Somvanshi, Md Monzurul Islam, Shamyo Brotee, Mahmuda Sultana Mimi, Dipti Koirala, Biplov Pandey, Subasish Das</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The rapid expansion of interconnected devices, autonomous systems, and AI applications has created severe fragmentation in adaptive transport systems, where diverse protocols and context sources remain isolated. This survey provides the first systematic investigation of the Model Context Protocol (MCP) as a unifying paradigm, highlighting its ability to bridge protocol-level adaptation with context-aware decision making. Analyzing established literature, we show that existing efforts have implicitly converged toward MCP-like architectures, signaling a natural evolution from fragmented solutions to standardized integration frameworks. We propose a five-category taxonomy covering adaptive mechanisms, context-aware frameworks, unification models, integration strategies, and MCP-enabled architectures. Our findings reveal three key insights: traditional transport protocols have reached the limits of isolated adaptation, MCPs client-server and JSON-RPC structure enables semantic interoperability, and AI-driven transport demands integration paradigms uniquely suited to MCP. Finally, we present a research roadmap positioning MCP as a foundation for next-generation adaptive, context-aware, and intelligent transport infrastructures.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3744736.3749343" target="_blank">Beyond Competitive Gaming: How Casual Players Evaluate and Respond to Teammate Performance</a></h3>
                    <p><strong>Authors:</strong> Kaushall Senthil Nathan, Jieun Lee, Derrick M. Wang, Geneva M. Smith, Eugene Kukshinov, Daniel Harley, Lennart E. Nacke</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Teammate performance evaluation fundamentally shapes intervention design in video games. However, our current understanding stems primarily from competitive E-Sports contexts where individual performance directly impacts outcomes. This research addresses whether performance evaluation mechanisms and behavioural responses identified in competitive games generalize to casual cooperative games. We investigated how casual players evaluate teammate competence and respond behaviourally in a controlled between-subjects experiment (N=23). We manipulated confederate performance in Overcooked 2, combining observations, NASA TLX self-reports, and interviews. We present two key findings. (1) Observations revealed frustration behaviours completely absent in self-report data. Thus, these instruments assess fundamentally distinct constructs. (2) Participants consistently evaluated teammate performance through relative comparison rather than absolute metrics. This contradicts task-performance operationalizations dominant in competitive gaming research. Hence, performance evaluation frameworks from competitive contexts cannot be directly applied to casual cooperative games. We provide empirical evidence that performance evaluation in casual games requires a comparative operationalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19229v1" target="_blank">StepWiser: Stepwise Generative Judges for Wiser Reasoning</a></h3>
                    <p><strong>Authors:</strong> Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As models increasingly leverage multi-step reasoning strategies to solve complex problems, supervising the logical validity of these intermediate steps has become a critical research challenge. Process reward models address this by providing step-by-step feedback, but current approaches have two major drawbacks: they typically function as classifiers without providing explanations, and their reliance on supervised fine-tuning with static datasets limits generalization. Inspired by recent advances, we reframe stepwise reward modeling from a classification task to a reasoning task itself. We thus propose a generative judge that reasons about the policy models reasoning steps (i.e., meta-reasons), outputting thinking tokens before delivering a final verdict. Our model, StepWiser, is trained by reinforcement learning using relative outcomes of rollouts. We show it provides (i) better judgment accuracy on intermediate steps than existing methods; (ii) can be used to improve the policy model at training time; and (iii) improves inference-time search.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19227v1" target="_blank">Generative Interfaces for Language Models</a></h3>
                    <p><strong>Authors:</strong> Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn, information-dense, and exploratory tasks. To address these limitations, we propose Generative Interfaces for Language Models, a paradigm in which LLMs respond to user queries by proactively generating user interfaces (UIs) that enable more adaptive and interactive engagement. Our framework leverages structured interface-specific representations and iterative refinements to translate user queries into task-specific UIs. For systematic evaluation, we introduce a multidimensional assessment framework that compares generative interfaces with traditional chat-based ones across diverse tasks, interaction patterns, and query types, capturing functional, interactive, and emotional aspects of user experience. Results show that generative interfaces consistently outperform conversational ones, with humans preferring them in over 70% of cases. These findings clarify when and why users favor generative interfaces, paving the way for future advancements in human-AI interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19220v1" target="_blank">The 2025 Roadmaps for the US Magnet Development Program</a></h3>
                    <p><strong>Authors:</strong> Lance Cooley, Paolo Ferracin, Steve Gourlay, David Larbalestier, Mark Palmer, Soren Prestemon, George Velev, Giorgio Ambrosio, Diego Arbelaez, Karie Badgley, Lucas Brouwer, Daniel Davis, Jose Luis Fernandez, Vadim Kashikhin, Steven Krave, Maxim Marchevsky, Igor Novitski, Ian Pong, Tengming Shen, Stoyan Stoynev, Reed Teyber, Giorgio Vallone, Xiaorong Wang, Xingchen Xu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> physics.acc-ph</p>
                    <p><strong>Summary:</strong> The US Physics community completed the Snowmass planning process in 2022, culminating in the HEPAP Particle Physics Project Prioritization Panel (P5) publishing its summary report at the end of 2023. Building on this, the US Magnet Development Program, a national accelerator magnet RD program established by DOE-OHEP in 2016, has updated its strategic plan to align with the 2023 P5 report, resulting in this roadmap document.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19200v1" target="_blank">The Ramon Llulls Thinking Machine for Automated Ideation</a></h3>
                    <p><strong>Authors:</strong> Xinran Zhao, Boyuan Zheng, Chenglei Si, Haofei Yu, Ken Liu, Runlong Zhou, Ruochen Li, Tong Chen, Xiang Li, Yiming Zhang, Tongshuang Wu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> This paper revisits Ramon Llulls Ars combinatoria - a medieval framework for generating knowledge through symbolic recombination - as a conceptual foundation for building a modern Llulls thinking machine for research ideation. Our approach defines three compositional axes: Theme (e.g., efficiency, adaptivity), Domain (e.g., question answering, machine translation), and Method (e.g., adversarial training, linear attention). These elements represent high-level abstractions common in scientific work - motivations, problem settings, and technical approaches - and serve as building blocks for LLM-driven exploration. We mine elements from human experts or conference papers and show that prompting LLMs with curated combinations produces research ideas that are diverse, relevant, and grounded in current literature. This modern thinking machine offers a lightweight, interpretable tool for augmenting scientific creativity and suggests a path toward collaborative ideation between humans and AI.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.2139/ssrn.5006698" target="_blank">Profit-Aware Graph Framework for Cross-Platform Ride-Sharing: Analyzing Allocation Mechanisms and Efficiency Gains</a></h3>
                    <p><strong>Authors:</strong> Xin Dong, Jose Ventura, Vikash V. Gayah</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Ride-hailing platforms (e.g., Uber, Lyft) have transformed urban mobility by enabling ride-sharing, which holds considerable promise for reducing both travel costs and total vehicle miles traveled (VMT). However, the fragmentation of these platforms impedes system-wide efficiency by restricting ride-matching to intra-platform requests. Cross-platform collaboration could unlock substantial efficiency gains, but its realization hinges on fair and sustainable profit allocation mechanisms that can align the incentives of competing platforms. This study introduces a graph-theoretic framework that embeds profit-aware constraints into network optimization, facilitating equitable and efficient cross-platform ride-sharing. Within this framework, we evaluate three allocation schemes -- equal-profit-based, market-share-based, and Shapley-value-based -- through large-scale simulations. Results show that the Shapley-value-based mechanism consistently outperforms the alternatives across six key metrics. Notably, system efficiency and rider service quality improve with increasing demand, reflecting clear economies of scale. The observed economies of scale, along with their diminishing returns, can be understood with the structural evolution of rider-request graphs, where super-linear edge growth expands feasible matches and sub-linear degree scaling limits per-rider connectivity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19189v1" target="_blank">Reconstructing graphs and their connectivity using graphlets</a></h3>
                    <p><strong>Authors:</strong> David Hartman, Aneta Pokorná, Daniel Trlifaj</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.CO, cs.DM, cs.SI, 05C60, G.2.2</p>
                    <p><strong>Summary:</strong> Graphlets are small subgraphs rooted at a fixed vertex. The number of occurrences of graphlets aligned to a particular vertex, called graphlet degree sequence, gives a topological description of the surrounding of the analyzed vertex. In this article, we study properties and uniqueness of graphlet degree sequences. The information given by graphlets up to size (n-1) is utilized graphs having certain type of asymmetric vertex-deleted subgraphs. Moreover, we show a reconstruction of trees from their (= n-1)-graphlet degree sequences, which is much easier compared to the standard reconstruction from vertex-deleted subgraphs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19184v1" target="_blank">Separating Intent from Execution: A Probabilistic Approach to Pitch Location Accuracy</a></h3>
                    <p><strong>Authors:</strong> Matt Ludwig, Ryan S. Brill, Abraham J. Wyner</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> stat.AP</p>
                    <p><strong>Summary:</strong> Control has long been recognized as a critical component of pitcher performance, reflecting a pitchers ability to execute pitches in alignment with his intended targets. However, accurately inferring a pitchers intentions presents a persistent challenge. Traditional metrics typically rely on uniformity assumptions, inferring intent based on the behavior of a ``typical pitcher across similar situations. In this study, we propose an alternative, individualized approach to measuring control, one that eschews such assumptions in favor of personalized inference. We estimate a pitchers intended location on a pitch-by-pitch basis, conditioning on both individual tendencies and specific game contexts. This allows us to assess control by comparing the actual pitch location to the inferred intended target, thereby aligning measurement more closely with the unique strategies of each pitcher. We introduce xCTRL, a novel metric that quantifies control as the distance between a pitchs actual location and its estimated intended location. We find that xCTRL exhibits strong stability and greater predictive power than existing control metrics. By capturing pitcher-specific intent, xCTRL enhances our understanding of control and offers a more intuitive and accurate representation of pitching performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19182v1" target="_blank">SoccerNet 2025 Challenges Results</a></h3>
                    <p><strong>Authors:</strong> Silvio Giancola, Anthony Cioppa, Marc Gutiérrez-Pérez, Jan Held, Carlos Hinojosa, Victor Joos, Arnaud Leduc, Floriane Magera, Karen Sanchez, Vladimir Somers, Artur Xarles, Antonio Agudo, Alexandre Alahi, Olivier Barnich, Albert Clapés, Christophe De Vleeschouwer, Sergio Escalera, Bernard Ghanem, Thomas B. Moeslund, Marc Van Droogenbroeck, Tomoki Abe, Saad Alotaibi, Faisal Altawijri, Steven Araujo, Xiang Bai, Xiaoyang Bi, Jiawang Cao, Vanyi Chao, Kamil Czarnogórski, Fabian Deuser, Mingyang Du, Tianrui Feng, Patrick Frenzel, Mirco Fuchs, Jorge García, Konrad Habel, Takaya Hashiguchi, Sadao Hirose, Xinting Hu, Yewon Hwang, Ririko Inoue, Riku Itsuji, Kazuto Iwai, Hongwei Ji, Yangguang Ji, Licheng Jiao, Yuto Kageyama, Yuta Kamikawa, Yuuki Kanasugi, Hyungjung Kim, Jinwook Kim, Takuya Kurihara, Bozheng Li, Lingling Li, Xian Li, Youxing Lian, Dingkang Liang, Hongkai Lin, Jiadong Lin, Jian Liu, Liang Liu, Shuaikun Liu, Zhaohong Liu, Yi Lu, Federico Méndez, Huadong Ma, Wenping Ma, Jacek Maksymiuk, Henry Mantilla, Ismail Mathkour, Daniel Matthes, Ayaha Motomochi, Amrulloh Robbani Muhammad, Haruto Nakayama, Joohyung Oh, Yin May Oo, Marcelo Ortega, Norbert Oswald, Rintaro Otsubo, Fabian Perez, Mengshi Qi, Cristian Rey, Abel Reyes-Angulo, Oliver Rose, Hoover Rueda-Chacón, Hideo Saito, Jose Sarmiento, Kanta Sawafuji, Atom Scott, Xi Shen, Pragyan Shrestha, Jae-Young Sim, Long Sun, Yuyang Sun, Tomohiro Suzuki, Licheng Tang, Masato Tonouchi, Ikuma Uchida, Henry O. Velesaca, Tiancheng Wang, Rio Watanabe, Jay Wu, Yongliang Wu, Shunzo Yamagishi, Di Yang, Xu Yang, Yuxin Yang, Hao Ye, Xinyu Ye, Calvin Yeung, Xuanlong Yu, Chao Zhang, Dingyuan Zhang, Kexing Zhang, Zhe Zhao, Xin Zhou, Wenbo Zhu, Julian Ziegler</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This years challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, targeting the recovery of scene geometry from single-camera broadcast clips through relative depth estimation for each pixel; (3) Multi-View Foul Recognition, requiring the analysis of multiple synchronized camera views to classify fouls and their severity; and (4) Game State Reconstruction, aimed at localizing and identifying all players from a broadcast video to reconstruct the game state on a 2D top-view of the field. Across all tasks, participants were provided with large-scale annotated datasets, unified evaluation protocols, and strong baselines as starting points. This report presents the results of each challenge, highlights the top-performing solutions, and provides insights into the progress made by the community. The SoccerNet Challenges continue to serve as a driving force for reproducible, open research at the intersection of computer vision, artificial intelligence, and sports. Detailed information about the tasks, challenges, and leaderboards can be found at https://www.soccer-net.org, with baselines and development kits available at https://github.com/SoccerNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19173v1" target="_blank">Leveraging Evolutionary Surrogate-Assisted Prescription in Multi-Objective Chlorination Control Systems</a></h3>
                    <p><strong>Authors:</strong> Rivaaj Monsia, Olivier Francon, Daniel Young, Risto Miikkulainen</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.NE, cs.LG</p>
                    <p><strong>Summary:</strong> This short, written report introduces the idea of Evolutionary Surrogate-Assisted Prescription (ESP) and presents preliminary results on its potential use in training real-world agents as a part of the 1st AI for Drinking Water Chlorination Challenge at IJCAI-2025. This work was done by a team from Project Resilience, an organization interested in bridging AI to real-world problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19170v1" target="_blank">Stellar Mass Assembly History of Massive Quiescent Galaxies since $z\sim4$: Insights from Spatially Resolved SED Fitting with JWST Data</a></h3>
                    <p><strong>Authors:</strong> Novan Saputra Haryana, Masayuki Akiyama, Abdurrouf, Hesti Retno Tri Wulandari, Juan Pablo Alfonzo, Kianhong Lee, Naoki Matsumoto, Ryo Albert Sutanto, Muhammad Nur Ihsan Effendi, Itsna Khoirul Fitriana, Ibnu Nurul Huda, Anton Timur Jaelani, Sultan Hadi Kusuma, Lucky Puspitarini, Dian Puspita Triani</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Massive quiescent galaxies at high redshift show significantly more compact morphology than their local counterparts. To examine their internal structure across a wide redshift range and investigate potential redshift dependence, we performed spatially resolved SED fitting using pixedfit software on massive $(\log(M_*/M_\odot)\sim11)$ quiescent galaxies at $0 4$ kpc), while the central regions ($r \sim 1$ kpc) remain largely unchanged, with stellar mass surface density similar to local quiescent galaxies. The estimated star formation rates are too low to explain the stellar mass growth, indicating an additional stellar mass accumulation process, such as mergers, is necessary. We parameterize the size-mass relation of the most massive galaxies in our sample as $\log(R_{e,mass}) \propto \alpha \log(M_*)$, and find $\alpha = 2.67^{+1.14}_{-1.17}$ for $z\lessapprox2$, consistent with growth dominated by minor mergers, and $\alpha = 0.91^{+0.20}_{-0.16}$ for $z\gtrapprox2$, consistent with growth dominated by major mergers. These results indicate that massive quiescent galaxies originate from compact quenched systems and grow through combinations of minor and major mergers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19167v1" target="_blank">Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions</a></h3>
                    <p><strong>Authors:</strong> Zhihang Xin, Xitong Hu, Rui Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Vision Transformers have demonstrated remarkable success in computer vision tasks, yet their reliance on learnable one-dimensional positional embeddings fundamentally disrupts the inherent two-dimensional spatial structure of images through patch flattening procedures. Traditional positional encoding approaches lack geometric constraints and fail to establish monotonic correspondence between Euclidean spatial distances and sequential index distances, thereby limiting the models capacity to leverage spatial proximity priors effectively. We propose Weierstrass Elliptic Function Positional Encoding (WEF-PE), a mathematically principled approach that directly addresses two-dimensional coordinates through natural complex domain representation, where the doubly periodic properties of elliptic functions align remarkably with translational invariance patterns commonly observed in visual data. Our method exploits the non-linear geometric nature of elliptic functions to encode spatial distance relationships naturally, while the algebraic addition formula enables direct derivation of relative positional information between arbitrary patch pairs from their absolute encodings. Comprehensive experiments demonstrate that WEF-PE achieves superior performance across diverse scenarios, including 63.78\% accuracy on CIFAR-100 from-scratch training with ViT-Tiny architecture, 93.28\% on CIFAR-100 fine-tuning with ViT-Base, and consistent improvements on VTAB-1k benchmark tasks. Theoretical analysis confirms the distance-decay property through rigorous mathematical proof, while attention visualization reveals enhanced geometric inductive bias and more coherent semantic focus compared to conventional approaches.The source code implementing the methods described in this paper is publicly available on GitHub.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19163v1" target="_blank">MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation</a></h3>
                    <p><strong>Authors:</strong> Ernest Lim, Yajie Vera He, Jared Joselowitz, Kate Preston, Mohita Chowdhury, Louis Williams, Aisling Higham, Katrina Mason, Mariane Melo, Tom Lawton, Yan Jia, Ibrahim Habli</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, cs.MA, 68T50, 68T42, 92C50, 68Q60, I.2.0; J.3</p>
                    <p><strong>Summary:</strong> Despite the growing use of large language models (LLMs) in clinical dialogue systems, existing evaluations focus on task completion or fluency, offering little insight into the behavioral and risk management requirements essential for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation), a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents. MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical scenarios, expected system behaviors and failure modes derived through structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator for detecting safety-relevant dialogue failures, validated against expert clinician annotations; and (3) PatBot, a simulated patient agent capable of producing diverse, scenario-conditioned responses, evaluated for realism and behavioral fidelity with human factors expertise, and a patient-preference study. Across three experiments, we show that MATRIX enables systematic, scalable safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded assessment of 240 dialogues. We also conducted one of the first realism analyses of LLM-based patient simulation, showing that PatBot reliably simulates realistic patient behavior in quantitative and qualitative evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios and 10 clinical domains. MATRIX is the first framework to unify structured safety engineering with scalable, validated conversational AI evaluation, enabling regulator-aligned safety auditing. We release all evaluation tools, prompts, structured scenarios, and datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19153v1" target="_blank">QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Allen Wang, Gavin Tao</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> We address vision-guided quadruped motion control with reinforcement learning (RL) and highlight the necessity of combining proprioception with vision for robust control. We propose QuadKAN, a spline-parameterized cross-modal policy instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates a spline encoder for proprioception and a spline fusion head for proprioception-vision inputs. This structured function class aligns the state-to-action mapping with the piecewise-smooth nature of gait, improving sample efficiency, reducing action jitter and energy consumption, and providing interpretable posture-action sensitivities. We adopt Multi-Modal Delay Randomization (MMDR) and perform end-to-end training with Proximal Policy Optimization (PPO). Evaluations across diverse terrains, including both even and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate that QuadKAN achieves consistently higher returns, greater distances, and fewer collisions than state-of-the-art (SOTA) baselines. These results show that spline-parameterized policies offer a simple, effective, and interpretable alternative for robust vision-guided locomotion. A repository will be made available upon acceptance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19152v1" target="_blank">Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games</a></h3>
                    <p><strong>Authors:</strong> Chiu-Chou Lin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG, cs.MA, cs.SC</p>
                    <p><strong>Summary:</strong> Contemporary artificial intelligence (AI) development largely centers on rational decision-making, valued for its measurability and suitability for objective evaluation. Yet in real-world contexts, an intelligent agents decisions are shaped not only by logic but also by deeper influences such as beliefs, values, and preferences. The diversity of human decision-making styles emerges from these differences, highlighting that style is an essential but often overlooked dimension of intelligence. This dissertation introduces playstyle as an alternative lens for observing and analyzing the decision-making behavior of intelligent agents, and examines its foundational meaning and historical context from a philosophical perspective. By analyzing how beliefs and values drive intentions and actions, we construct a two-tier framework for style formation: the external interaction loop with the environment and the internal cognitive loop of deliberation. On this basis, we formalize style-related characteristics and propose measurable indicators such as style capacity, style popularity, and evolutionary dynamics. The study focuses on three core research directions: (1) Defining and measuring playstyle, proposing a general playstyle metric based on discretized state spaces, and extending it to quantify strategic diversity and competitive balance; (2) Expressing and generating playstyle, exploring how reinforcement learning and imitation learning can be used to train agents exhibiting specific stylistic tendencies, and introducing a novel approach for human-like style learning and modeling; and (3) Practical applications, analyzing the potential of these techniques in domains such as game design and interactive entertainment. Finally, the dissertation outlines future extensions, including the role of style as a core element in building artificial general intelligence (AGI).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19149v1" target="_blank">Algorithmic Collective Action with Multiple Collectives</a></h3>
                    <p><strong>Authors:</strong> Claudio Battiloro, Pietro Greiner, Bret Nestor, Oumaima Amezgar, Francesca Dominici</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> As learning systems increasingly influence everyday decisions, user-side steering via Algorithmic Collective Action (ACA)-coordinated changes to shared data-offers a complement to regulator-side policy and firm-side model design. Although real-world actions have been traditionally decentralized and fragmented into multiple collectives despite sharing overarching objectives-with each collective differing in size, strategy, and actionable goals, most of the ACA literature focused on single collective settings. In this work, we present the first theoretical framework for ACA with multiple collectives acting on the same system. In particular, we focus on collective action in classification, studying how multiple collectives can plant signals, i.e., bias a classifier to learn an association between an altered version of the features and a chosen, possibly overlapping, set of target classes. We provide quantitative results about the role and the interplay of collectives sizes and their alignment of goals. Our framework, by also complementing previous empirical results, opens a path for a holistic treatment of ACA with multiple collectives.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19145v1" target="_blank">Echoes of the past: A unified perspective on fading memory and echo states</a></h3>
                    <p><strong>Authors:</strong> Juan-Pablo Ortega, Florian Rossmannek</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG, math.DS, 37N35, 68T05, 93B03</p>
                    <p><strong>Summary:</strong> Recurrent neural networks (RNNs) have become increasingly popular in information processing tasks involving time series and temporal data. A fundamental property of RNNs is their ability to create reliable input/output responses, often linked to how the network handles its memory of the information it processed. Various notions have been proposed to conceptualize the behavior of memory in RNNs, including steady states, echo states, state forgetting, input forgetting, and fading memory. Although these notions are often used interchangeably, their precise relationships remain unclear. This work aims to unify these notions in a common language, derive new implications and equivalences between them, and provide alternative proofs to some existing results. By clarifying the relationships between these concepts, this research contributes to a deeper understanding of RNNs and their temporal information processing capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19136v1" target="_blank">Using Machine Learning to Generate, Clarify, and Improve Economic Models</a></h3>
                    <p><strong>Authors:</strong> Annie Liang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> econ.TH</p>
                    <p><strong>Summary:</strong> Machine learning algorithms can now outperform classic economic models in predicting quantities ranging from bargaining outcomes, to choice under uncertainty, to an individuals future jobs and wages. Yet this predictive accuracy comes at a cost: most machine learning algorithms function as black boxes, offering little insight into \emph{why} outcomes occur. This article asks whether machine learning can guide the development of new economic theories. Economic models serve an important purpose beyond prediction -- they uncover the general mechanisms behind observed behaviors. A model that identifies the causal pathways of economic development is more valuable than one that merely predicts which countries will escape poverty, because it enables policymakers to encourage that development in countries where it might not have happened otherwise. Similarly, a model that predicts imperfectly across many domains can be more valuable than one that is highly accurate in a specific domain, since the former allows insights and data obtained from one setting to inform decisions and policy in another. Applying machine learning algorithms off-the-shelf is unlikely to yield such models. But recent work shows that, when reconceived with the aims of an economic modeler in mind, machine learning methods can improve both prediction and understanding. These approaches range from adversarially training algorithms to expose the limits of existing models, to imposing economic theory as a constraint on algorithmic search. Advances in large language models complement these strategies and open new research directions.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1515/ms-2025-0015" target="_blank">Comparison of Topologies on Fundamental Groups with Subgroup Topology Viewpoint</a></h3>
                    <p><strong>Authors:</strong> Naghme Shahami, Behrooz Mashayekhy</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.AT, 57M05, 55Q05, 57M07, 57M10, 57M12</p>
                    <p><strong>Summary:</strong> In order to make the fundamental group, one of the most well known invariants in algebraic topology, more useful and powerful some researchers have been introduced and studied various topologies on the fundamental group from the beginning of the 21st century onwards. In this paper by reviewing these topologies, using the concept of subgroup topology, we are going to compare these topologies in order to present some results on topologized fundamental groups.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19121v1" target="_blank">Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings</a></h3>
                    <p><strong>Authors:</strong> Xiaolin He, Zirui Li, Xinwei Wang, Riender Happee, Meng Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Perceived risk in automated vehicles (AVs) can create the very danger that automation is meant to prevent: a frightened rider may hesitate when seconds matter, misjudge hazards, or disengage. However, measuring how perceived risk evolves in real time during driving remains challenging, leaving a gap in decoding such hidden psychological states. Here, we present a novel method to time-continuously measure and decode perceived risk. We conducted a controlled experiment where 2,164 participants viewed high-fidelity videos of common highway driving scenes and provided 141,628 discrete safety ratings. Through continuous-signal reconstruction of the discrete ratings, we obtained 236 hours of time-continuous perceived risk data - the largest perceived risk dataset to date. Leveraging this dataset, we trained deep neural networks that predict moment-by-moment perceived risk from vehicle kinematics with a mean relative error below $3\%$. Explainable AI analysis uncovers which factors determine perceived risk in real time. Our findings demonstrate a new paradigm for quantifying dynamic passenger experience and psychological constructs in real time. These findings can guide the design of AVs and other machines that operate in close proximity to people, adjusting behaviour before trust erodes, and help realise automations benefits in transport, healthcare, and service robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19105v1" target="_blank">Dual-polarization structure and nuclear structure effect on $Λ$ polarization</a></h3>
                    <p><strong>Authors:</strong> X. G. Deng, Y. G. Ma</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> nucl-th, nucl-ex</p>
                    <p><strong>Summary:</strong> We report a novel manifestation of spin-vorticity interplay in relativistic heavy-ion collisions. Using $^{16}$O+$^{197}$Au at $\sqrt{s_{\rm NN}}=7.7$ GeV as a test case, we show that the $\Lambda$ hyperon exhibits a clear dual-polarization structure, observed here in central $^{16}$O + $^{197}$Au collisions for the first time. The polarization is further highly sensitive to the intrinsic nuclear geometry: different $\alpha$-cluster configurations of $^{16}$O, ranging from chain-like to tetrahedral, lead to distinct polarization patterns across centralities. In particular, the backward rapidity region and peripheral events display striking structure-dependent variations, including opposite angular distributions of local polarizations $P_x$ and $P_y$ compared with a spherical reference. These findings reveal that nuclear clustering leaves measurable imprints on hyperon spin alignment in relativistic collisions. Our results open a promising avenue for probing nuclear structure in short-lived systems and highlight a new spin-sensitive mechanism relevant for upcoming experiments at RHIC and future facilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19104v1" target="_blank">Composition and Alignment of Diffusion Models using Constrained Learning</a></h3>
                    <p><strong>Authors:</strong> Shervin Khalafi, Ignacio Hounie, Dongsheng Ding, Alejandro Ribeiro</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, eess.IV, stat.ML</p>
                    <p><strong>Summary:</strong> Diffusion models have become prevalent in generative modeling due to their ability to sample from complex distributions. To improve the quality of generated samples and their compliance with user requirements, two commonly used methods are: (i) Alignment, which involves fine-tuning a diffusion model to align it with a reward; and (ii) Composition, which combines several pre-trained diffusion models, each emphasizing a desirable attribute in the generated outputs. However, trade-offs often arise when optimizing for multiple rewards or combining multiple models, as they can often represent competing properties. Existing methods cannot guarantee that the resulting model faithfully generates samples with all the desired properties. To address this gap, we propose a constrained optimization framework that unifies alignment and composition of diffusion models by enforcing that the aligned model satisfies reward constraints and/or remains close to (potentially multiple) pre-trained models. We provide a theoretical characterization of the solutions to the constrained alignment and composition problems and develop a Lagrangian-based primal-dual training algorithm to approximate these solutions. Empirically, we demonstrate the effectiveness and merits of our proposed approach in image generation, applying it to alignment and composition, and show that our aligned or composed model satisfies constraints effectively, and improves on the equally-weighted approach. Our implementation can be found at https://github.com/shervinkhalafi/constrained_comp_align.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19099v1" target="_blank">Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic</a></h3>
                    <p><strong>Authors:</strong> Thomas Compton</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Quantitative Discourse Analysis has seen growing adoption with the rise of Large Language Models and computational tools. However, reliance on black box software such as MAXQDA and NVivo risks undermining methodological transparency and alignment with research goals. This paper presents a hybrid, transparent framework for QDA that combines lexical and semantic methods to enable triangulation, reproducibility, and interpretability. Drawing from a case study in historical political discourse, we demonstrate how custom Python pipelines using NLTK, spaCy, and Sentence Transformers allow fine-grained control over preprocessing, lemmatisation, and embedding generation. We further detail our iterative BERTopic modelling process, incorporating UMAP dimensionality reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised through parameter tuning and multiple runs to enhance topic coherence and coverage. By juxtaposing precise lexical searches with context-aware semantic clustering, we argue for a multi-layered approach that mitigates the limitations of either method in isolation. Our workflow underscores the importance of code-level transparency, researcher agency, and methodological triangulation in computational discourse studies. Code and supplementary materials are available via GitHub.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19097v1" target="_blank">Reasoning LLMs in the Medical Domain: A Literature Survey</a></h3>
                    <p><strong>Authors:</strong> Armin Berger, Sarthak Khanna, David Berghaus, Rafet Sifa</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The emergence of advanced reasoning capabilities in Large Language Models (LLMs) marks a transformative development in healthcare applications. Beyond merely expanding functional capabilities, these reasoning mechanisms enhance decision transparency and explainability-critical requirements in medical contexts. This survey examines the transformation of medical LLMs from basic information retrieval tools to sophisticated clinical reasoning systems capable of supporting complex healthcare decisions. We provide a thorough analysis of the enabling technological foundations, with a particular focus on specialized prompting techniques like Chain-of-Thought and recent breakthroughs in Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates purpose-built medical frameworks while also examining emerging paradigms such as multi-agent collaborative systems and innovative prompting architectures. The survey critically assesses current evaluation methodologies for medical validation and addresses persistent challenges in field interpretation limitations, bias mitigation strategies, patient safety frameworks, and integration of multimodal clinical data. Through this survey, we seek to establish a roadmap for developing reliable LLMs that can serve as effective partners in clinical practice and medical research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19096v1" target="_blank">Trustworthy Agents for Electronic Health Records through Confidence Estimation</a></h3>
                    <p><strong>Authors:</strong> Yongwoo Song, Minbyul Jeong, Mujeen Sung</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) show promise for extracting information from Electronic Health Records (EHR) and supporting clinical decisions. However, deployment in clinical settings faces challenges due to hallucination risks. We propose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric quantifying the accuracy-reliability trade-off at varying confidence thresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating stepwise confidence estimation for clinical question answering. Experiments on MIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under strict reliability constraints, achieving improvements of 44.23%p and 25.34%p at HCAcc@70% while baseline methods fail at these thresholds. These results highlight limitations of traditional accuracy metrics in evaluating healthcare AI agents. Our work contributes to developing trustworthy clinical agents that deliver accurate information or transparently express uncertainty when confidence is low.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19093v1" target="_blank">Retrieval-Augmented Generation for Natural Language Art Provenance Searches in the Getty Provenance Index</a></h3>
                    <p><strong>Authors:</strong> Mathew Henrickson</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This research presents a Retrieval-Augmented Generation (RAG) framework for art provenance studies, focusing on the Getty Provenance Index. Provenance research establishes the ownership history of artworks, which is essential for verifying authenticity, supporting restitution and legal claims, and understanding the cultural and historical context of art objects. The process is complicated by fragmented, multilingual archival data that hinders efficient retrieval. Current search portals require precise metadata, limiting exploratory searches. Our method enables natural-language and multilingual searches through semantic retrieval and contextual summarization, reducing dependence on metadata structures. We assess RAGs capability to retrieve and summarize auction records using a 10,000-record sample from the Getty Provenance Index - German Sales. The results show this approach provides a scalable solution for navigating art market archives, offering a practical tool for historians and cultural heritage professionals conducting historically sensitive research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19092v1" target="_blank">Measurement of the branching fraction of $\psip \to ωηη$</a></h3>
                    <p><strong>Authors:</strong> BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. Chen, Z. J. Chen, Z. K. Chen, J. C. Cheng, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. C. Liu, Lu Liu, M. H. Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. L. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, Heng Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, Zirong Song, S. Sosio, S. Spataro, S Stansilaus, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, S. H. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, Zhang, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> Using a sample of (2.712 $\pm$ 0.014)$\times 10^{9}$ $\psip$ events collected with the BESIII detector at the BEPCII collider in 2009, 2012, and 2021, the decay $\psip \to \omega \eta \eta $ is observed for the first time. The branching fraction of the $\psi(3686)\to\omega\eta\eta$ decay is measured to be (1.65 $\pm$ 0.02 $\pm$ 0.21)$\times 10^{-5}$, where the first uncertainty is statistical and the second systematic. Clear structures associated with the well-established $\omega(1420)$ and $f_{0}(1710)$ resonances are observed in the $\omega\eta$ and $\eta\eta$ invariant-mass spectra, respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19090v1" target="_blank">Building an Open CGRA Ecosystem for Agile Innovation</a></h3>
                    <p><strong>Authors:</strong> Rohan Juneja, Pranav Dangi, Thilini Kaushalya Bandara, Zhaoying Li, Dhananjaya Wijerathne, Li-Shiuan Peh, Tulika Mitra</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> Modern computing workloads, particularly in AI and edge applications, demand hardware-software co-design to meet aggressive performance and energy targets. Such co-design benefits from open and agile platforms that replace closed, vertically integrated development with modular, community-driven ecosystems. Coarse-Grained Reconfigurable Architectures (CGRAs), with their unique balance of flexibility and efficiency are particularly well-suited for this paradigm. When built on open-source hardware generators and software toolchains, CGRAs provide a compelling foundation for architectural exploration, cross-layer optimization, and real-world deployment. In this paper, we will present an open CGRA ecosystem that we have developed to support agile innovation across the stack. Our contributions include HyCUBE, a CGRA with a reconfigurable single-cycle multi-hop interconnect for efficient data movement; PACE, which embeds a power-efficient HyCUBE within a RISC-V SoC targeting edge computing; and Morpher, a fully open-source, architecture-adaptive CGRA design framework that supports design space exploration, compilation, simulation, and validation. By embracing openness at every layer, we aim to lower barriers to innovation, enable reproducible research, and demonstrate how CGRAs can anchor the next wave of agile hardware development. We will conclude with a call for a unified abstraction layer for CGRAs and spatial accelerators, one that decouples hardware specialization from software development. Such a representation would unlock architectural portability, compiler innovation, and a scalable, open foundation for spatial computing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19089v1" target="_blank">Its All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs</a></h3>
                    <p><strong>Authors:</strong> Yue Li, Zhixue Zhao, Carolina Scarton</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Extremely low-resource languages, especially those written in rare scripts, as shown in Figure 1, remain largely unsupported by large language models (LLMs). This is due in part to compounding factors such as the lack of training data. This paper delivers the first comprehensive analysis of whether LLMs can acquire such languages purely via in-context learning (ICL), with or without auxiliary alignment signals, and how these methods compare to parameter-efficient fine-tuning (PEFT). We systematically evaluate 20 under-represented languages across three state-of-the-art multilingual LLMs. Our findings highlight the limitation of PEFT when both language and its script are extremely under-represented by the LLM. In contrast, zero-shot ICL with language alignment is impressively effective on extremely low-resource languages, while few-shot ICL or PEFT is more beneficial for languages relatively better represented by LLMs. For LLM practitioners working on extremely low-resource languages, we summarise guidelines grounded by our results on adapting LLMs to low-resource languages, e.g., avoiding fine-tuning a multilingual model on languages of unseen scripts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19087v1" target="_blank">APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration</a></h3>
                    <p><strong>Authors:</strong> Shaobo Ma, Chao Fang, Haikuo Shao, Zhongfeng Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.AR</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup over CUTLASS integer baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19076v1" target="_blank">HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance</a></h3>
                    <p><strong>Authors:</strong> Ziyue Li, Yuan Chang, Gaihong Yu, Xiaoqiu Le</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Large language model (LLM)-based agents have demonstrated remarkable capabilities in decision-making tasks, but struggle significantly with complex, long-horizon planning scenarios. This arises from their lack of macroscopic guidance, causing disorientation and failures in complex tasks, as well as insufficient continuous oversight during execution, rendering them unresponsive to environmental changes and prone to deviations. To tackle these challenges, we introduce HiPlan, a hierarchical planning framework that provides adaptive global-local guidance to boost LLM-based agentsdecision-making. HiPlan decomposes complex tasks into milestone action guides for general direction and step-wise hints for detailed actions. During the offline phase, we construct a milestone library from expert demonstrations, enabling structured experience reuse by retrieving semantically similar tasks and milestones. In the execution phase, trajectory segments from past milestones are dynamically adapted to generate step-wise hints that align current observations with the milestone objectives, bridging gaps and correcting deviations. Extensive experiments across two challenging benchmarks demonstrate that HiPlan substantially outperforms strong baselines, and ablation studies validate the complementary benefits of its hierarchical components.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19060v1" target="_blank">No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes</a></h3>
                    <p><strong>Authors:</strong> Blaž Rolih, Matic Fučka, Danijel Skočaj</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Surface defect detection is a critical task across numerous industries, aimed at efficiently identifying and localising imperfections or irregularities on manufactured components. While numerous methods have been proposed, many fail to meet industrial demands for high performance, efficiency, and adaptability. Existing approaches are often constrained to specific supervision scenarios and struggle to adapt to the diverse data annotations encountered in real-world manufacturing processes, such as unsupervised, weakly supervised, mixed supervision, and fully supervised settings. To address these challenges, we propose SuperSimpleNet, a highly efficient and adaptable discriminative model built on the foundation of SimpleNet. SuperSimpleNet incorporates a novel synthetic anomaly generation process, an enhanced classification head, and an improved learning procedure, enabling efficient training in all four supervision scenarios, making it the first model capable of fully leveraging all available data annotations. SuperSimpleNet sets a new standard for performance across all scenarios, as demonstrated by its results on four challenging benchmark datasets. Beyond accuracy, it is very fast, achieving an inference time below 10 ms. With its ability to unify diverse supervision paradigms while maintaining outstanding speed and reliability, SuperSimpleNet represents a promising step forward in addressing real-world manufacturing challenges and bridging the gap between academic research and industrial applications. Code: https://github.com/blaz-r/SuperSimpleNet</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19042v1" target="_blank">A Concurrent Modular Agent: Framework for Autonomous LLM Agents</a></h3>
                    <p><strong>Authors:</strong> Norihiro Maruyama, Takahide Yoshida, Hiroki Sato, Atsushi Masumori, Johnsmith, Takashi Ikegami</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We introduce the Concurrent Modular Agent (CMA), a framework that orchestrates multiple Large-Language-Model (LLM)-based modules that operate fully asynchronously yet maintain a coherent and fault-tolerant behavioral loop. This framework addresses long-standing difficulties in agent architectures by letting intention emerge from language-mediated interactions among autonomous processes. This approach enables flexible, adaptive, and context-dependent behavior through the combination of concurrently executed modules that offload reasoning to an LLM, inter-module communication, and a single shared global state.We consider this approach to be a practical realization of Minskys Society of Mind theory. We demonstrate the viability of our system through two practical use-case studies. The emergent properties observed in our system suggest that complex cognitive phenomena like self-awareness may indeed arise from the organized interaction of simpler processes, supporting Minsky-Society of Mind concept and opening new avenues for artificial intelligence research. The source code for our work is available at: https://github.com/AlternativeMachine/concurrent-modular-agent.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19036v1" target="_blank">Of the People, By the Algorithm: How AI Transforms Democratic Representation</a></h3>
                    <p><strong>Authors:</strong> Yuval Rymon</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This review examines how AI technologies are transforming democratic representation, focusing on citizen participation and algorithmic decision-making. The analysis reveals that AI technologies are reshaping democratic processes in fundamental ways: enabling mass-scale deliberation, changing how citizens access and engage with political information, and transforming how representatives make and implement decisions. While AI offers unprecedented opportunities for enhancing democratic participation and governance efficiency, it also presents significant challenges to democratic legitimacy and accountability. Social media platforms AI-driven algorithms currently mediate much political discourse, creating concerns about information manipulation and privacy. Large Language Models introduce both epistemic challenges and potential tools for improving democratic dialogue. The emergence of Mass Online Deliberation platforms suggests possibilities for scaling up meaningful citizen participation, while Algorithmic Decision-Making systems promise more efficient policy implementation but face limitations in handling complex political trade-offs. As these systems become prevalent, representatives may assume the role of architects of automated decision frameworks, responsible for guiding the translation of politically contested concepts into technical parameters and metrics. Advanced deliberation platforms offering real-time insights into citizen preferences will challenge traditional representative independence and discretion to interpret public will. The institutional integration of these participation mechanisms requires frameworks that balance the benefits with democratic stability through hybrid systems weighting different forms of democratic expression.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19034v1" target="_blank">Fast Vortex Beam Alignment for OAM Mode Multiplexing in LOS MIMO Networks</a></h3>
                    <p><strong>Authors:</strong> Poorya Mollahosseini, Yasaman Ghasempour</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> Orbital Angular Momentum (OAM)-based communication systems offer high-capacity multiplexing in line-of-sight (LOS) scenarios; yet, their performance is sensitive to nodal misalignment, which disrupts modal orthogonality, hindering the data multiplexing gain. To tackle this challenge, we present OrthoVortex, a novel framework that estimates the misalignment angles and applies the appropriate phase correction to restore orthogonality between modes. Unlike purely theoretical prior efforts that rely on impractical fully digital arrays or exhaustive beam scans, OrthoVortex introduces and leverages the cross-modal phase, as a unique signature for identifying the misalignment angles. OrthoVortex is a few-shot alignment technique, making it feasible for real-world implementations. Our key contributions include: (i) a robust angle estimation and phase correction framework based on the physics of OAM propagation that estimates the misalignment and restores modal orthogonality, (ii) the first-ever experimental validation of OAM beam alignment with RF transceivers, and (iii) a comprehensive analysis of practical constraints, including the impact of antenna count and bandwidth. Simulations and over-the-air measurements using low-cost, rapidly prototyped metasurfaces operating at 120 GHz demonstrate that OrthoVortex achieves fast and precise misalignment estimation (mean absolute error of $0.69^{\circ}$ for azimuth and $2.54^{\circ}$ for elevation angle). Further, OrthoVortex can mitigate the inter-modal interference, yielding more than 12 dB increase in signal-to-interference ratio and more than 4.5-fold improvement in link capacity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19029v1" target="_blank">When recalling in-context, Transformers are not SSMs</a></h3>
                    <p><strong>Authors:</strong> Destiny Okpekpe, Antonio Orvieto</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite the advantageous subquadratic complexity of modern recurrent deep learning models -- such as state-space models (SSMs) -- recent studies have highlighted their potential shortcomings compared to transformers on reasoning and memorization tasks. In this paper, we dive deeper into one of such benchmarks: associative recall (AR), which has been shown to correlate well with language modeling performance, and inspect in detail the effects of scaling and optimization issues in recently proposed token mixing strategies. We first demonstrate that, unlike standard transformers, the choice of learning rate plays a critical role in the performance of modern recurrent models: an issue that can severely affect reported performance in previous works and suggests further research is needed to stabilize training. Next, we show that recurrent and attention-based models exhibit contrasting benefits when scaling in width as opposed to depth, with attention being notably unable to solve AR when limited to a single layer. We then further inspect 1-layer transformers, revealing that despite their poor performance, their training dynamics surprisingly resemble the formation of induction heads, a phenomenon previously observed only in their 2-layer counterparts. Finally, through architectural ablations, we study how components affects Transformer and Mambas performance and optimization stability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19026v1" target="_blank">MovieCORE: COgnitive REasoning in Movies</a></h3>
                    <p><strong>Authors:</strong> Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at https://joslefaure.github.io/assets/html/moviecore.html.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19021v1" target="_blank">MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis</a></h3>
                    <p><strong>Authors:</strong> Riju Marwah, Riya Arora, Navneet Yadav, Himank Arora</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the prevalence of plastics exceeding 368 million tons yearly, microplastic pollution has grown to an extent where air, water, soil, and living organisms have all tested positive for microplastic presence. These particles, which are smaller than 5 millimeters in size, are no less harmful to humans than to the environment. Toxicity research on microplastics has shown that exposure may cause liver infection, intestinal injuries, and gut flora imbalance, leading to numerous potential health hazards. This paper presents a new model, MicroDetect-Net (MDN), which applies fluorescence microscopy with Nile Red dye staining and deep learning to scan blood samples for microplastics. Although clam blood has certain limitations in replicating real human blood, this study opens avenues for applying the approach to human samples, which are more consistent for preliminary data collection. The MDN model integrates dataset preparation, fluorescence imaging, and segmentation using a convolutional neural network to localize and count microplastic fragments. The combination of convolutional networks and Nile Red dye for segmentation produced strong image detection and accuracy. MDN was evaluated on a dataset of 276 Nile Red-stained fluorescent blood images and achieved an accuracy of ninety two percent. Robust performance was observed with an Intersection over Union of 87.4 percent, F1 score of 92.1 percent, Precision of 90.6 percent, and Recall of 93.7 percent. These metrics demonstrate the effectiveness of MDN in the detection of microplastics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19016v1" target="_blank">Working My Way Back to You: Resource-Centric Next-Activity Prediction</a></h3>
                    <p><strong>Authors:</strong> Kelly Kurowski, Xixi Lu, Hajo A Reijers</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Predictive Process Monitoring (PPM) aims to train models that forecast upcoming events in process executions. These predictions support early bottleneck detection, improved scheduling, proactive interventions, and timely communication with stakeholders. While existing research adopts a control-flow perspective, we investigate next-activity prediction from a resource-centric viewpoint, which offers additional benefits such as improved work organization, workload balancing, and capacity forecasting. Although resource information has been shown to enhance tasks such as process performance analysis, its role in next-activity prediction remains unexplored. In this study, we evaluate four prediction models and three encoding strategies across four real-life datasets. Compared to the baseline, our results show that LightGBM and Transformer models perform best with an encoding based on 2-gram activity transitions, while Random Forest benefits most from an encoding that combines 2-gram transitions and activity repetition features. This combined encoding also achieves the highest average accuracy. This resource-centric approach could enable smarter resource allocation, strategic workforce planning, and personalized employee support by analyzing individual behavior rather than case-level progression. The findings underscore the potential of resource-centric next-activity prediction, opening up new venues for research on PPM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19014v1" target="_blank">MAB Optimizer for Estimating Math Question Difficulty via Inverse CV without NLP</a></h3>
                    <p><strong>Authors:</strong> Surajit Das, Gourav Roy, Aleksei Eliseev, Ram Kumar Rajendran</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The evolution of technology and education is driving the emergence of Intelligent  Autonomous Tutoring Systems (IATS), where objective and domain-agnostic methods for determining question difficulty are essential. Traditional human labeling is subjective, and existing NLP-based approaches fail in symbolic domains like algebra. This study introduces the Approach of Passive Measures among Educands (APME), a reinforcement learning-based Multi-Armed Bandit (MAB) framework that estimates difficulty solely from solver performance data -- marks obtained and time taken -- without requiring linguistic features or expert labels. By leveraging the inverse coefficient of variation as a risk-adjusted metric, the model provides an explainable and scalable mechanism for adaptive assessment. Empirical validation was conducted on three heterogeneous datasets. Across these diverse contexts, the model achieved an average R2 of 0.9213 and an average RMSE of 0.0584, confirming its robustness, accuracy, and adaptability to different educational levels and assessment formats. Compared with baseline approaches-such as regression-based, NLP-driven, and IRT models-the proposed framework consistently outperformed alternatives, particularly in purely symbolic domains. The findings highlight that (i) item heterogeneity strongly influences perceived difficulty, and (ii) variance in solver outcomes is as critical as mean performance for adaptive allocation. Pedagogically, the model aligns with Vygotskys Zone of Proximal Development by identifying tasks that balance challenge and attainability, supporting motivation while minimizing disengagement. This domain-agnostic, self-supervised approach advances difficulty tagging in IATS and can be extended beyond algebra wherever solver interaction data is available</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19013v1" target="_blank">Channel flows of deformable nematics</a></h3>
                    <p><strong>Authors:</strong> Ioannis Hadjifrangiskou, Sumesh P. Thampi, Julia M. Yeomans</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft</p>
                    <p><strong>Summary:</strong> We describe channel flows in a continuum model of deformable nematic particles. In a simple shear flow, deformability leads to a nonlinear coupling of strain rate and vorticity, and results in shape oscillations or flow alignment. The final steady state can depend on initial conditions, and we explain this behaviour by considering a phase space representation of the dynamics. In Poiseuille flow, particle deformability and nematic elasticity induce banding, where particles near the walls are aligned, and those near the centre of the channel oscillate in direction and shape. Our results show that particle deformability can lead to complex behaviour even in simple flows, suggesting new microfluidic experiments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19011v1" target="_blank">STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems</a></h3>
                    <p><strong>Authors:</strong> Gary Simethy, Daniel Ortiz-Arroyo, Petar Durdevic</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Most deep learning methods for imputing missing values treat the task as completing patterns within a fixed time window. This assumption often fails in industrial systems, where dynamics are driven by control actions, are highly non-stationary, and can experience long, uninterrupted gaps. We propose STDiff, which reframes imputation as learning how the system evolves from one state to the next. STDiff uses a conditional denoising diffusion model with a causal bias aligned to control theory, generating missing values step-by-step based on the most recent known state and relevant control or environmental inputs. On a public wastewater treatment dataset with simulated missing blocks, STDiff consistently achieves the lowest errors, with its advantage increasing for longer gaps. On a raw industrial dataset with substantial real gaps, it produces trajectories that remain dynamically plausible, in contrast to window-based models that tend to flatten or over-smooth. These results support dynamics-aware, explicitly conditioned imputation as a robust approach for industrial time series, and we discuss computational trade-offs and extensions to broader domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19009v1" target="_blank">FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning</a></h3>
                    <p><strong>Authors:</strong> Md Anwar Hossen, Fatema Siddika, Wensheng Zhang, Anuj Sharma, Ali Jannesari</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.DC</p>
                    <p><strong>Summary:</strong> Heterogeneous Federated Learning (HFL) has gained attention for its ability to accommodate diverse models and heterogeneous data across clients. Prototype-based HFL methods emerge as a promising solution to address statistical heterogeneity and privacy challenges, paving the way for new advancements in HFL research. This method focuses on sharing only class-representative prototypes among heterogeneous clients. However, these prototypes are often aggregated on the server using weighted averaging, leading to sub-optimal global knowledge; these cause the shrinking of aggregated prototypes, which negatively affects the model performance in scenarios when models are heterogeneous and data distributions are extremely non-IID. We propose FedProtoKD in a Heterogeneous Federated Learning setting, using an enhanced dual-knowledge distillation mechanism to improve the system performance with clients logits and prototype feature representation. We aim to resolve the prototype margin-shrinking problem using a contrastive learning-based trainable server prototype by leveraging a class-wise adaptive prototype margin. Furthermore, we assess the importance of public samples using the closeness of the samples prototype to its class representative prototypes, which enhances learning performance. FedProtoKD achieved average improvements of 1.13% up to 34.13% accuracy across various settings and significantly outperforms existing state-of-the-art HFL methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19008v1" target="_blank">Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI</a></h3>
                    <p><strong>Authors:</strong> Marcin Moskalewicz, Anna Sterna, Marek Pokropski, Paula Flores</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This study examines the capacity of large language models (LLMs) to support phenomenological qualitative analysis of first-person experience in Borderline Personality Disorder (BPD), understood as a disorder of temporality and selfhood. Building on a prior human-led thematic analysis of 24 inpatients life-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5 Pro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the original investigators. The models were evaluated with blinded and non-blinded expert judges in phenomenology and clinical psychology. Assessments included semantic congruence, Jaccard coefficients, and multidimensional validity ratings (credibility, coherence, substantiveness, and groundness in data). Results showed variable overlap with the human analysis, from 0 percent in GPT to 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient (0.21-0.28). However, the models recovered themes omitted by humans. Geminis output most closely resembled the human analysis, with validity scores significantly higher than GPT and Claude (p  0.78) with the quantity of text and words per theme, highlighting both the variability and potential of AI-augmented thematic analysis to mitigate human interpretative bias.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19005v1" target="_blank">Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark</a></h3>
                    <p><strong>Authors:</strong> Yuxuan Cai, Yipeng Hao, Jie Zhou, Hang Yan, Zhikai Lei, Rui Zhen, Zhenhua Han, Yutao Yang, Junsong Li, Qianjun Pan, Tianyu Huai, Qin Chen, Xin Li, Kai Chen, Bo Zhang, Xipeng Qiu, Liang He</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as second nature. We also introduce StuLife, a benchmark dataset for ELL that simulates a students holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around three key paradigm shifts: From Passive to Proactive, From Context to Memory, and From Imitation to Learning. In this dynamic environment, agents must acquire and distill practical skills and maintain persistent memory to make decisions based on evolving state variables. StuLife provides a comprehensive platform for evaluating lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior. Beyond evaluating SOTA LLMs on the StuLife benchmark, we also explore the role of context engineering in advancing AGI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19006v1" target="_blank">Is attention truly all we need? An empirical study of asset pricing in pretrained RNN sparse and global attention models</a></h3>
                    <p><strong>Authors:</strong> Shanyan Lai</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> q-fin.PR, cs.LG, econ.EM, q-fin.CP, 62M10, 62P20, 91G70, 68T07, I.2.6; I.5.1; J.4; G.3</p>
                    <p><strong>Summary:</strong> This study investigates the pretrained RNN attention models with the mainstream attention mechanisms such as additive attention, Luongs three attentions, global self-attention (Self-att) and sliding window sparse attention (Sparse-att) for the empirical asset pricing research on top 420 large-cap US stocks. This is the first paper on the large-scale state-of-the-art (SOTA) attention mechanisms applied in the asset pricing context. They overcome the limitations of the traditional machine learning (ML) based asset pricing, such as mis-capturing the temporal dependency and short memory. Moreover, the enforced causal masks in the attention mechanisms address the future data leaking issue ignored by the more advanced attention-based models, such as the classic Transformer. The proposed attention models also consider the temporal sparsity characteristic of asset pricing data and mitigate potential overfitting issues by deploying the simplified model structures. This provides some insights for future empirical economic research. All models are examined in three periods, which cover pre-COVID-19 (mild uptrend), COVID-19 (steep uptrend with a large drawdown) and one year post-COVID-19 (sideways movement with high fluctuations), for testing the stability of these models under extreme market conditions. The study finds that in value-weighted portfolio back testing, Model Self-att and Model Sparse-att exhibit great capabilities in deriving the absolute returns and hedging downside risks, while they achieve an annualized Sortino ratio of 2.0 and 1.80 respectively in the period with COVID-19. And Model Sparse-att performs more stably than Model Self-att from the perspective of absolute portfolio returns with respect to the size of stocks market capitalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19004v1" target="_blank">AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms</a></h3>
                    <p><strong>Authors:</strong> Pontus Strimling, Simon Karlsson, Irina Vartanova, Kimmo Eriksson</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> A fundamental question in cognitive science concerns how social norms are acquired and represented. While humans typically learn norms through embodied social experience, we investigated whether large language models can achieve sophisticated norm understanding through statistical learning alone. Across two studies, we systematically evaluated multiple AI systems ability to predict human social appropriateness judgments for 555 everyday scenarios by examining how closely they predicted the average judgment compared to each human participant. In Study 1, GPT-4.5s accuracy in predicting the collective judgment on a continuous scale exceeded that of every human participant (100th percentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7% of humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive power, all models showed systematic, correlated errors. These findings demonstrate that sophisticated models of social cognition can emerge from statistical learning over linguistic data alone, challenging strong versions of theories emphasizing the exclusive necessity of embodied experience for cultural competence. The systematic nature of AI limitations across different architectures indicates potential boundaries of pattern-based social understanding, while the models ability to outperform nearly all individual humans in this predictive task suggests that language serves as a remarkably rich repository for cultural knowledge transmission.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19248v1" target="_blank">Disorder-induced proximate quantum spin ice phase in Pr$_2$Sn$_2$O$_7$</a></h3>
                    <p><strong>Authors:</strong> Yi Luo, Joseph A. M. Paddison, Brenden R. Ortiz, Miles Knudtson, Stephen D. Wilson, Jue Liu, Benjamin A. Frandsen, Si Athena Chen, Matthias Frontzek, Andrey Podlesnyak, Adam A. Aczel</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> We report a comprehensive bulk characterization and neutron scattering investigation of single-crystalline Pr$_2$Sn$_2$O$_7$, a magnetic pyrochlore synthesized via a flux-growth method. Unpolarized neutron diffuse scattering reveals the emergence of spin-ice correlations below $T \sim 1$ K, evidenced by the development of anisotropic pinch-point features that are consistent with quantum-spin-ice (QSI) behavior. A.C. susceptibility measurements indicate a progressive slowing of spin dynamics in this regime, culminating in complete spin freezing below $T_f \approx 0.15$ K. Inelastic neutron scattering at $T = 0.5$ K reveals a broad spectrum of quasi-elastic magnetic excitations, with intensity in the low-energy range $[0, 0.2]$ meV significantly suppressed below $T_f$. Meanwhile, an incipient (100)-type magnetic order begins to nucleate, and a gapped excitation centered at $\hbar\omega = 0.23$ meV persists. We further identify two distinct dynamical timescales above $T_f$, a slow component $\tau_{\mathrm{slow}} \sim 10^{-5}$ s and a fast component $\tau_{\mathrm{fast}} \sim 10^{-10}$ s, in quantitative agreement with theoretical predictions for QSI systems. Taken together, these results indicate that Pr$_2$Sn$_2$O$_7$ enters a disorder-induced spin-frozen phase below $T_f$, lying in close proximity to a $U(1)$ quantum spin liquid.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19247v1" target="_blank">VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space</a></h3>
                    <p><strong>Authors:</strong> Lin Li, Zehuan Huang, Haoran Feng, Gengxiong Zhuang, Rui Chen, Chunchao Guo, Lu Sheng</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D local editing of specified regions is crucial for game industry and robot interaction. Recent methods typically edit rendered multi-view images and then reconstruct 3D models, but they face challenges in precisely preserving unedited regions and overall coherence. Inspired by structured 3D generative models, we propose VoxHammer, a novel training-free approach that performs precise and coherent editing in 3D latent space. Given a 3D model, VoxHammer first predicts its inversion trajectory and obtains its inverted latents and key-value tokens at each timestep. Subsequently, in the denoising and editing phase, we replace the denoising features of preserved regions with the corresponding inverted latents and cached key-value tokens. By retaining these contextual features, this approach ensures consistent reconstruction of preserved areas and coherent integration of edited parts. To evaluate the consistency of preserved regions, we constructed Edit3D-Bench, a human-annotated dataset comprising hundreds of samples, each with carefully labeled 3D editing regions. Experiments demonstrate that VoxHammer significantly outperforms existing methods in terms of both 3D consistency of preserved regions and overall quality. Our method holds promise for synthesizing high-quality edited paired data, thereby laying the data foundation for in-context 3D generation. See our project page at https://huanngzh.github.io/VoxHammer-Page/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19245v1" target="_blank">New Twists on Topological Quantum Error Correcting Codes</a></h3>
                    <p><strong>Authors:</strong> Mohamad Mousa, Amit Jamadagni, Eugene Dumitrescu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.other, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We derive a new family of quantum error-correcting codes. The main technical tool used to do so is the physically intuitive concept of condensation, which is employed to create new domain walls between the quantum double of $\Z_4$ and an instance of the doubled semion phase. Specifically, we provide explicit constructions, first at the lattice-level and then subsequently at the macroscopic logical-level. To provide intuition, we provide a series of explicit examples using the derived topological interfaces. We discuss the codes utility in the burgeoning area of quantum error-correction with an emphasis on the interplay between logical error rates and decoding. We conclude by outlining how such codes representation and design can be automated. We expect our results, which provide explicit step-by-step instructions in the form of algorithms, to pave the path for new higher-algebraic-dimensional codes to be discovered and implemented in configurations that take advantage of various hardwares distinct strengths.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19243v1" target="_blank">Style4D-Bench: A Benchmark Suite for 4D Stylization</a></h3>
                    <p><strong>Authors:</strong> Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, 2) a strong baseline that make an initial attempt for 4D stylization, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes. Project page: https://becky-catherine.github.io/Style4D . Code: https://github.com/Becky-catherine/Style4D-Bench .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19244v1" target="_blank">Articulate3D: Zero-Shot Text-Driven 3D Object Posing</a></h3>
                    <p><strong>Authors:</strong> Oishi Deb, Anjun Hu, Ashkan Khakzar, Philip Torr, Christian Rupprecht</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We propose a training-free method, Articulate3D, to pose a 3D asset through language control. Despite advances in vision and language models, this task remains surprisingly challenging. To achieve this goal, we decompose the problem into two steps. We modify a powerful image-generator to create target images conditioned on the input image and a text instruction. We then align the mesh to the target images through a multi-view pose optimisation step. In detail, we introduce a self-attention rewiring mechanism (RSActrl) that decouples the source structure from pose within an image generative model, allowing it to maintain a consistent structure across varying poses. We observed that differentiable rendering is an unreliable signal for articulation optimisation; instead, we use keypoints to establish correspondences between input and target images. The effectiveness of Articulate3D is demonstrated across a diverse range of 3D objects and free-form text prompts, successfully manipulating poses while maintaining the original identity of the mesh. Quantitative evaluations and a comparative user study, in which our method was preferred over 85\% of the time, confirm its superiority over existing approaches. Project page:https://odeb1.github.io/articulate3d_page_deb/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19242v1" target="_blank">Autoregressive Universal Video Segmentation Model</a></h3>
                    <p><strong>Authors:</strong> Miran Heo, Sukjun Hwang, Min-Hung Chen, Yu-Chiang Frank Wang, Albert Gu, Seon Joo Kim, Ryo Hachiuma</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent video foundation models such as SAM2 excel at prompted video segmentation by treating masks as a general-purpose primitive. However, many real-world settings require unprompted segmentation that aims to detect and track all objects in a video without external cues, leaving todays landscape fragmented across task-specific models and pipelines. We recast streaming video segmentation as sequential mask prediction, analogous to language modeling, and introduce the Autoregressive Universal Segmentation Model (AUSM), a single architecture that unifies both prompted and unprompted video segmentation. Built on recent state-space models, AUSM maintains a fixed-size spatial state and scales to video streams of arbitrary length. Furthermore, all components of AUSM are designed for parallel training across frames, yielding substantial speedups over iterative training. On standard benchmarks (DAVIS17, YouTube-VOS 2018  2019, MOSE, YouTube-VIS 2019  2021, and OVIS) AUSM outperforms prior universal streaming video segmentation methods and achieves up to 2.5x faster training on 16-frame sequences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19241v1" target="_blank">Phase Coherent Transport in Two-Dimensional Tellurium Flakes</a></h3>
                    <p><strong>Authors:</strong> Mohammad Hafijur Rahaman, Nathan Sawyers, Mourad Benamara, Trudie Culverhouse, Repaka Maheswar, Qiyuan He, Hugh Churchill, Dharmraj Kotekar Patil</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.soft, quant-ph</p>
                    <p><strong>Summary:</strong> Elemental tellurium (Te) is a compelling van der Waals material due to its interesting chiral crystal structure and predicted topological properties. Here, we report the fabrication and comprehensive quantum transport study of devices based on Te flakes with varying thicknesses. We demonstrate a hole mobility reaching up to 1000 cm2/V.s in a 17 nm thick flake at 30 Kelvin. At deep cryogenic temperatures ( 50mK), the transport characteristics transition from Coulomb blockade in the low carrier density regime to pronounced Fabry-P\erot (F-P) interference at higher densities. Notably, the visibility of these F-P oscillations is significantly enhanced in the thinner flake device. The application of a magnetic field reveals a clear Zeeman splitting of the conductance peaks. The rich variety of quantum transport phenomena observed underscores the high quality of our thin Te flakes and establishes them as a promising platform for exploring novel physics and device concepts, such as topological superconductivity and low-power spintronic applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19240v1" target="_blank">Large $n$-point Functions in Resonant Inflation</a></h3>
                    <p><strong>Authors:</strong> Paolo Creminelli, Sébastien Renaux-Petel, Giovanni Tambalo, Vicharit Yingcharoenrat</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> We investigate a qualitatively new regime of inflationary models with small and rapid oscillations in the potential--resonant non-Gaussianity. In contrast to the standard scenario, where most of the observable information is encoded in the power spectrum, in this regime the oscillatory signal predominantly appears in higher-order correlation functions with large $n$. This behavior emerges when the oscillation frequency $\omega$ exceeds the naive cutoff of the theory, $4\pi f$. However, as noted by Hook and Rattazzi [2306.12489], the actual cutoff is somewhat higher -- though only logarithmically -- when the amplitude of the oscillations is small. We identify a phenomenologically relevant window in which $n$-point functions with $3 \lesssim n \lesssim 9$ are potentially observable. In this regime, the signal exhibits 350-1000 oscillations per decade in $k$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19238v1" target="_blank">Optimal quantum simulation of linear non-unitary dynamics</a></h3>
                    <p><strong>Authors:</strong> Guang Hao Low, Rolando D. Somma</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We present a quantum algorithm for simulating the time evolution generated by any bounded, time-dependent operator $-A$ with non-positive logarithmic norm, thereby serving as a natural generalization of the Hamiltonian simulation problem. Our method generalizes the recent Linear-Combination-of-Hamiltonian-Simulation (LCHS) framework. In instances where $A$ is time-independent, we provide a block-encoding of the evolution operator $e^{-At}$ with $\mathcal{O}\big(t\log\frac{1}{\epsilon})$ queries to the block-encoding oracle for $A$. We also show how the normalized evolved state can be prepared with $\mathcal{O}(1/\|e^{-At}|{\vec{u}_0}\rangle\|)$ queries to the oracle that prepares the normalized initial state $|{\vec{u}_0}\rangle$. These complexities are optimal in all parameters and improve the error scaling over prior results. Furthermore, we show that any improvement of our approach exceeding a constant factor of approximately 3 is infeasible. For general time-dependent operators $A$, we also prove that a uniform trapezoidal rule on our LCHS construction yields exponential convergence, leading to simplified quantum circuits with improved gate complexity compared to prior nonuniform-quadrature methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19236v1" target="_blank">MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation</a></h3>
                    <p><strong>Authors:</strong> Hao Shi, Bin Xie, Yingfei Liu, Lin Sun, Fengrong Liu, Tiancai Wang, Erjin Zhou, Haoqiang Fan, Xiangyu Zhang, Gao Huang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Temporal context is essential for robotic manipulation because such tasks are inherently non-Markovian, yet mainstream VLA models typically overlook it and struggle with long-horizon, temporally dependent tasks. Cognitive science suggests that humans rely on working memory to buffer short-lived representations for immediate control, while the hippocampal system preserves verbatim episodic details and semantic gist of past experience for long-term memory. Inspired by these mechanisms, we propose MemoryVLA, a Cognition-Memory-Action framework for long-horizon robotic manipulation. A pretrained VLM encodes the observation into perceptual and cognitive tokens that form working memory, while a Perceptual-Cognitive Memory Bank stores low-level details and high-level semantics consolidated from it. Working memory retrieves decision-relevant entries from the bank, adaptively fuses them with current tokens, and updates the bank by merging redundancies. Using these tokens, a memory-conditioned diffusion action expert yields temporally aware action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on Bridge. On 12 real-world tasks spanning general skills and long-horizon temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon tasks showing a +26 improvement over state-of-the-art baseline. Project Page: https://shihao1895.github.io/MemoryVLA</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19235v1" target="_blank">Silane-Methane Competition in Sub-Neptune Atmospheres as a Diagnostic of Metallicity and Magma Oceans</a></h3>
                    <p><strong>Authors:</strong> Kaustubh Hakim, Dan J. Bower, Fabian Seidler, Paolo A. Sossi</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> astro-ph.EP</p>
                    <p><strong>Summary:</strong> The James Webb Space Telescope is characterising the atmospheres of sub-Neptunes. The presence of magma oceans on sub-Neptunes is expected to strongly alter the chemistry of their envelopes (100 bar-100 kbar) and atmospheres (1 mbar-100 bar). At the magma ocean-envelope boundary (MEB, 10 kbar), gas properties deviate from ideality, yet the effects of real gas behaviour on chemical equilibria remain underexplored. Here, we compute equilibrium between magma-gas and gas-gas reactions using real gas equations of state in the H-He-C-N-O-Si system for TOI-421b, a canonical hot sub-Neptune potentially hosting a magma ocean. We find that H and N are the most soluble in magma, followed by He and C. We fit real gas equations of state to experimental data on SiH$_4$, and show that, for a fully molten mantle, SiH$_4$ dominates at the MEB under accreted gas metallicity of 1$\times$ solar, but is supplanted by CH$_4$ at 100$\times$ solar. Lower mantle melt fractions lower both magma-derived Si abundances in the envelope and the solubility of H and He in magma, yielding H$_2$- and He-rich envelopes. Projecting equilibrium chemistry through the atmosphere (1 mbar-100 bar), we find that condensation of $\beta$-quartz clouds depletes Si-bearing gases, although SiH$_4$ remains abundant at solar metallicity. SiH$_4$/CH$_4$ ratios increase with mantle melt fraction and decrease with metallicity. These effects also deplete H$_2$ via CH$_4$ and SiH$_4$ formation and the dissolution of H$_2$ into magma. The competition between SiH$_4$ and CH$_4$ presents a diagnostic of metallicity and magma oceans. The corollary is that H$_2$- and He-rich, SiH$_4$- and CH$_4$-poor (5%) atmospheres may indicate a limited role or absence of magma oceans on sub-Neptunes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19233v1" target="_blank">Temperature dependence in Krylov space</a></h3>
                    <p><strong>Authors:</strong> Nikolaos Angelinos, Debarghya Chakraborty, Anatoly Dymarsky</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-th, cond-mat.stat-mech, quant-ph</p>
                    <p><strong>Summary:</strong> We consider the recursion method applied to a generic 2pt function of a quantum system and show, in full generality, that the temperature dependence of the corresponding Lanczos coefficients is governed by integrable dynamics. After an appropriate change of variables, Lanczos coefficients with even and odd indices are described by two independent Toda chains, related at the level of the initial conditions. Consistency of the resulting equations can be used to show that certain scale-invariant models necessarily have a degenerate spectrum. We dub this self-consistency-based approach the Krylov bootstrap. The known analytic behavior of the Toda chain at late times translates into analytic control over the 2pt function and Krylov complexity at very low temperatures. We also discuss the behavior of Lanczos coefficients when the temperature is low but not much smaller than the spectral gap, and elucidate the origin of the staggering behavior of Lanczos coefficients in this regime.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19232v1" target="_blank">Automated Feature Tracking for Real-Time Kinematic Analysis and Shape Estimation of Carbon Nanotube Growth</a></h3>
                    <p><strong>Authors:</strong> Kaveh Safavigerdini, Ramakrishna Surya, Jaired Collins, Prasad Calyam, Filiz Bunyak, Matthew R. Maschmann, Kannappan Palaniappan</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Carbon nanotubes (CNTs) are critical building blocks in nanotechnology, yet the characterization of their dynamic growth is limited by the experimental challenges in nanoscale motion measurement using scanning electron microscopy (SEM) imaging. Existing ex situ methods offer only static analysis, while in situ techniques often require manual initialization and lack continuous per-particle trajectory decomposition. We present Visual Feature Tracking (VFTrack) an in-situ real-time particle tracking framework that automatically detects and tracks individual CNT particles in SEM image sequences. VFTrack integrates handcrafted or deep feature detectors and matchers within a particle tracking framework to enable kinematic analysis of CNT micropillar growth. A systematic using 13,540 manually annotated trajectories identifies the ALIKED detector with LightGlue matcher as an optimal combination (F1-score of 0.78, $\alpha$-score of 0.89). VFTrack motion vectors decomposed into axial growth, lateral drift, and oscillations, facilitate the calculation of heterogeneous regional growth rates and the reconstruction of evolving CNT pillar morphologies. This work enables advancement in automated nano-material characterization, bridging the gap between physics-based models and experimental observation to enable real-time optimization of CNT synthesis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19231v1" target="_blank">On the Dynamics of Extended Bodies and the GravoThermo Memory Effect</a></h3>
                    <p><strong>Authors:</strong> Raihaneh Moti, Ali Shojai</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> The non-linearity of the theory of gravity induces a hysteresis effect in both the systems interacting with gravity and in the gravitational field. The effect is usually referred to as the memory effect. In this paper, we explore this phenomenon in the context of the dynamics of extended rotating objects in the presence of a gravitational wave pulse. Then, we consider an ensemble of such objects and show that a redistribution of spin orientations takes place as a gravitational wave passes through. We examine how this redistribution, changes the partition function and the thermodynamic quantities including entropy and energy of the system. The result shows that some information about the source of the gravitation wave is encoded in the thermodynamics of the system.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19229v1" target="_blank">StepWiser: Stepwise Generative Judges for Wiser Reasoning</a></h3>
                    <p><strong>Authors:</strong> Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As models increasingly leverage multi-step reasoning strategies to solve complex problems, supervising the logical validity of these intermediate steps has become a critical research challenge. Process reward models address this by providing step-by-step feedback, but current approaches have two major drawbacks: they typically function as classifiers without providing explanations, and their reliance on supervised fine-tuning with static datasets limits generalization. Inspired by recent advances, we reframe stepwise reward modeling from a classification task to a reasoning task itself. We thus propose a generative judge that reasons about the policy models reasoning steps (i.e., meta-reasons), outputting thinking tokens before delivering a final verdict. Our model, StepWiser, is trained by reinforcement learning using relative outcomes of rollouts. We show it provides (i) better judgment accuracy on intermediate steps than existing methods; (ii) can be used to improve the policy model at training time; and (iii) improves inference-time search.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19227v1" target="_blank">Generative Interfaces for Language Models</a></h3>
                    <p><strong>Authors:</strong> Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn, information-dense, and exploratory tasks. To address these limitations, we propose Generative Interfaces for Language Models, a paradigm in which LLMs respond to user queries by proactively generating user interfaces (UIs) that enable more adaptive and interactive engagement. Our framework leverages structured interface-specific representations and iterative refinements to translate user queries into task-specific UIs. For systematic evaluation, we introduce a multidimensional assessment framework that compares generative interfaces with traditional chat-based ones across diverse tasks, interaction patterns, and query types, capturing functional, interactive, and emotional aspects of user experience. Results show that generative interfaces consistently outperform conversational ones, with humans preferring them in over 70% of cases. These findings clarify when and why users favor generative interfaces, paving the way for future advancements in human-AI interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19226v1" target="_blank">The Quark Jet Function for $k_T$-like Variables in NNLO QCD</a></h3>
                    <p><strong>Authors:</strong> Luca Buonocore, Massimiliano Grazzini, Flavio Guadagni, Jürg Haag, Luca Rottoli</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-ph</p>
                    <p><strong>Summary:</strong> The precise description of jet processes requires observables capable of efficiently capturing the dynamics of the energy flow in hadronic final states. We consider a class of tranverse-momentum like resolution variables that smoothly describe the $n+1$ to $n$ jet transition in multi-jet processes. We discuss a general method for the computation of the corresponding quark jet function at next-to-next-to-leading order in perturbative QCD. Rapidity divergences are regulated by using a time-like auxiliary vector. We present explicit results for a variant of $y_{23}$ in the $E$-scheme and in the WTA scheme.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19223v1" target="_blank">MC3D: The Materials Cloud computational database of experimentally known stoichiometric inorganics</a></h3>
                    <p><strong>Authors:</strong> Sebastiaan P. Huber, Michail Minotakis, Marnik Bercx, Timo Reents, Kristjan Eimre, Nataliya Paulish, Nicolas Hörmann, Martin Uhrin, Nicola Marzari, Giovanni Pizzi</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, physics.comp-ph</p>
                    <p><strong>Summary:</strong> DFT is a widely used method to compute properties of materials, which are often collected in databases and serve as valuable starting points for further studies. In this article, we present the Materials Cloud Three-Dimensional Structure Database (MC3D), an online database of computed three-dimensional (3D) inorganic crystal structures. Close to a million experimentally reported structures were imported from the COD, ICSD and MPDS databases; these were parsed and filtered to yield a collection of 72589 unique and stoichiometric structures, of which 95% are, to date, classified as experimentally known. The geometries of structures with up to 64 atoms were then optimized using density-functional theory (DFT) with automated workflows and curated input protocols. The procedure was repeated for different functionals (and computational protocols), with the latest version (MC3D PBEsol-v2) comprising 32013 unique structures. All versions of the MC3D are made available on the Materials Cloud portal, which provides a graphical interface to explore and download the data. The database includes the full provenance graph of all the calculations driven by the automated workflows, thus establishing full reproducibility of the results and more-than-FAIR procedures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19222v1" target="_blank">Classification of color superconductivity by one-gluon exchange helicity amplitudes and renormalization group equations</a></h3>
                    <p><strong>Authors:</strong> Yuki Fujimoto</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-ph, nucl-th</p>
                    <p><strong>Summary:</strong> Quark matter at high baryon density exhibits diverse pairing patterns classified by color, flavor, and angular momentum quantum numbers. We compute one-gluon exchange (OGE) helicity amplitudes and introduce a nonrelativistic classification of the pairing channel, justified by the channel decomposition in a Lorentz-noninvariant medium and the decoupling of renormalization group flows at leading order. We find the new attractive channel in OGE; the medium effects can render the vacuum-repulsive color $\boldsymbol{6}$ channel attractive in the spin-triplet sector. For color $\boldsymbol{\bar{3}}$ with antisymmetric flavor, the dominant pairing is ${}^1S_0$, while for symmetric flavor the same-helicity $^1P_1$ prevails over $^3S_1$, revising the conventional single-flavor picture. With a mismatch of the Fermi momenta, $^1S_0$ channel, leading to color-flavor locked or two-flavor color superconductor, remains most stable when the separation is small, and the color-spin locked pairing becomes favored as the mismatch gets large. We suggest there are possible quark-hadron continuity in certain cases as expected in the literature.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19221v1" target="_blank">Evaluating the Evaluators: Are readability metrics good measures of readability?</a></h3>
                    <p><strong>Authors:</strong> Isabel Cachola, Daniel Khashabi, Mark Dredze</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Plain Language Summarization (PLS) aims to distill complex documents into accessible summaries for non-expert audiences. In this paper, we conduct a thorough survey of PLS literature, and identify that the current standard practice for readability evaluation is to use traditional readability metrics, such as Flesch-Kincaid Grade Level (FKGL). However, despite proven utility in other fields, these metrics have not been compared to human readability judgments in PLS. We evaluate 8 readability metrics and show that most correlate poorly with human judgments, including the most popular metric, FKGL. We then show that Language Models (LMs) are better judges of readability, with the best-performing model achieving a Pearson correlation of 0.56 with human judgments. Extending our analysis to PLS datasets, which contain summaries aimed at non-expert audiences, we find that LMs better capture deeper measures of readability, such as required background knowledge, and lead to different conclusions than the traditional metrics. Based on these findings, we offer recommendations for best practices in the evaluation of plain language summaries. We release our analysis code and survey data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19213v1" target="_blank">Single pion-production and pion propagation in Achilles</a></h3>
                    <p><strong>Authors:</strong> Joshua Isaacson, William Jay, Alessandro Lovato, Pedro Machado, Alexis Nikolakopoulos, Noemi Rocco, Noah Steinberg</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-ex, nucl-th</p>
                    <p><strong>Summary:</strong> We extend the applicability of Achilles (A CHIcagoLand Lepton Event Simulator) by incorporating the single-pion production mechanism in a fully exclusive fashion. The electroweak interaction vertex is modeled by combining the state-of-the-art Dynamical Coupled-Channels approach with realistic hole spectral functions, which account for correlations in both the initial target state and the residual spectator system. Final-state interactions are treated using a semi-classical intranuclear cascade that leverages nuclear configurations to determine the correlated spatial distribution of protons and neutrons. The meson-baryon scattering amplitudes used in the cascade are computed within the Dynamical Coupled-Channels framework, consistent with the electroweak vertex. To model pion absorption, we employ the optical potential approach of Oset and Salcedo. As an alternative approach, we explicitly model the production and propagation of resonances which mediate pion-nucleon scattering and pion absorption. We validate out approach against pion-nucleon and pion-nucleus scattering data, and present comparisons with electron- and neutrino-nucleus measurements from e4$\nu$, T2K, MINER$\nu$A, and MicroBooNE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19210v1" target="_blank">Interpolating Speaker Identities in Embedding Space for Data Expansion</a></h3>
                    <p><strong>Authors:</strong> Tianchi Liu, Ruijie Tao, Qiongqiong Wang, Yidi Jiang, Hardik B. Sailor, Ke Zhang, Jingru Lin, Haizhou Li</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.AS, cs.AI</p>
                    <p><strong>Summary:</strong> The success of deep learning-based speaker verification systems is largely attributed to access to large-scale and diverse speaker identity data. However, collecting data from more identities is expensive, challenging, and often limited by privacy concerns. To address this limitation, we propose INSIDE (Interpolating Speaker Identities in Embedding Space), a novel data expansion method that synthesizes new speaker identities by interpolating between existing speaker embeddings. Specifically, we select pairs of nearby speaker embeddings from a pretrained speaker embedding space and compute intermediate embeddings using spherical linear interpolation. These interpolated embeddings are then fed to a text-to-speech system to generate corresponding speech waveforms. The resulting data is combined with the original dataset to train downstream models. Experiments show that models trained with INSIDE-expanded data outperform those trained only on real data, achieving 3.06\% to 5.24\% relative improvements. While INSIDE is primarily designed for speaker verification, we also validate its effectiveness on gender classification, where it yields a 13.44\% relative improvement. Moreover, INSIDE is compatible with other augmentation techniques and can serve as a flexible, scalable addition to existing training pipelines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19209v1" target="_blank">OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation</a></h3>
                    <p><strong>Authors:</strong> Jianwen Jiang, Weihong Zeng, Zerong Zheng, Jiaqi Yang, Chao Liang, Wang Liao, Han Liang, Yuan Zhang, Mingyuan Gao</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Existing video avatar models can produce fluid human animations, yet they struggle to move beyond mere physical likeness to capture a characters authentic essence. Their motions typically synchronize with low-level cues like audio rhythm, lacking a deeper semantic understanding of emotion, intent, or context. To bridge this gap, \textbf{we propose a framework designed to generate character animations that are not only physically plausible but also semantically coherent and expressive.} Our model, \textbf{OmniHuman-1.5}, is built upon two key technical contributions. First, we leverage Multimodal Large Language Models to synthesize a structured textual representation of conditions that provides high-level semantic guidance. This guidance steers our motion generator beyond simplistic rhythmic synchronization, enabling the production of actions that are contextually and emotionally resonant. Second, to ensure the effective fusion of these multimodal inputs and mitigate inter-modality conflicts, we introduce a specialized Multimodal DiT architecture with a novel Pseudo Last Frame design. The synergy of these components allows our model to accurately interpret the joint semantics of audio, images, and text, thereby generating motions that are deeply coherent with the character, scene, and linguistic content. Extensive experiments demonstrate that our model achieves leading performance across a comprehensive set of metrics, including lip-sync accuracy, video quality, motion naturalness and semantic consistency with textual prompts. Furthermore, our approach shows remarkable extensibility to complex scenarios, such as those involving multi-person and non-human subjects. Homepage: \href{https://omnihuman-lab.github.io/v1_5/}</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19207v1" target="_blank">Unquestionable Bell theorem for interwoven frustrated down conversion processes</a></h3>
                    <p><strong>Authors:</strong> Paweł Cieśliński, Marcin Markiewicz, Konrad Schlichtholz, Jan-Åke Larsson, Marek Żukowski</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> In the Wang et al. paper Violation of Bell inequality with unentangled photons [Science Advances, 1 Aug 2025 Vol 11, Issue 31], in which a brilliant experiment involving two interwoven frustrated down conversion processes is reported, Bell non-classicality of the observed interference processes is conjectured under some tacit additional assumptions. To clear any doubts about Bell non-classicality of the interference processes observed by Wang et al., we give an unconditional Bell-type proof that a modified version of the experiment indeed would reveal a violation of local realism. The data of the Wang et al. experiment show destructive interference which surpasses the required threshold for Bell non-classicality in the modified version, and thus effectively constitutes a positive experimental Bell non-classicality test employing our proposal. The essence of our method is to abandon the usual approach in which macroscopically controlled optical phases define the measurement settings in a Bell experiment. Instead, in our case, the local settings are determined by switching on or off the local pumping fields of the parametric down conversion crystals at the local measuring stations of Alice and Bob. We also show that in a standard framework of local hidden variable theories that do not require any additional assumptions, it is possible to construct a local realistic model which exactly reproduces the probabilities on which the conjecture by Wang et al. violation of local realism was based. Thus, we prove that the tacit additional assumptions in the Bell analysis of Wang et al. constrain the class of local realistic models refuted by the experiment. Also, we claim that the non-classical effects in the Wang et al. experiment cannot be ascribed to unentangled photons.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19206v1" target="_blank">Decidability of Extensions of Presburger Arithmetic by Hardy Field Functions</a></h3>
                    <p><strong>Authors:</strong> Hera Brown, Jakub Konieczny</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LO, math.LO, math.NT, 11U05, 03B10, 03B25, 11J54</p>
                    <p><strong>Summary:</strong> We study the extension of Presburger arithmetic by the class of sub-polynomial Hardy field functions, and show the majority of these extensions to be undecidable. More precisely, we show that the theory $\mathrm{Th}(\mathbb{Z}; , +, \lfloor f \rceil)$, where $f$ is a Hardy field function and $\lfloor \cdot \rceil$ the nearest integer operator, is undecidable when $f$ grows polynomially faster than $x$. Further, we show that when $f$ grows sub-linearly quickly, but still as fast as some polynomial, the theory $\mathrm{Th}(\mathbb{Z}; , +, \lfloor f \rceil)$ is undecidable.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19205v1" target="_blank">VibeVoice Technical Report</a></h3>
                    <p><strong>Authors:</strong> Zhiliang Peng, Jianwei Yu, Wenhui Wang, Yaoyao Chang, Yutao Sun, Li Dong, Yi Zhu, Weijiang Xu, Hangbo Bao, Zehua Wang, Shaohan Huang, Yan Xia, Furu Wei</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> This report presents VibeVoice, a novel model designed to synthesize long-form speech with multiple speakers by employing next-token diffusion, which is a unified method for modeling continuous data by autoregressively generating latent vectors via diffusion. To enable this, we introduce a novel continuous speech tokenizer that, when compared to the popular Encodec model, improves data compression by 80 times while maintaining comparable performance. The tokenizer effectively preserves audio fidelity while significantly boosting computational efficiency for processing long sequences. Thus, VibeVoice can synthesize long-form speech for up to 90 minutes (in a 64K context window length) with a maximum of 4 speakers, capturing the authentic conversational ``vibe and surpassing open-source and proprietary dialogue models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19204v1" target="_blank">LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding</a></h3>
                    <p><strong>Authors:</strong> Julian Ost, Andrea Ramazzina, Amogh Joshi, Maximilian Bömer, Mario Bijelic, Felix Heide</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.GR</p>
                    <p><strong>Summary:</strong> Large-scale scene data is essential for training and testing in robot learning. Neural reconstruction methods have promised the capability of reconstructing large physically-grounded outdoor scenes from captured sensor data. However, these methods have baked-in static environments and only allow for limited scene control -- they are functionally constrained in scene and trajectory diversity by the captures from which they are reconstructed. In contrast, generating driving data with recent image or video diffusion models offers control, however, at the cost of geometry grounding and causality. In this work, we aim to bridge this gap and present a method that directly generates large-scale 3D driving scenes with accurate geometry, allowing for causal novel view synthesis with object permanence and explicit 3D geometry estimation. The proposed method combines the generation of a proxy geometry and environment representation with score distillation from learned 2D image priors. We find that this approach allows for high controllability, enabling the prompt-guided geometry and high-fidelity texture and structure that can be conditioned on map layouts -- producing realistic and geometrically consistent 3D generations of complex driving scenes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19203v1" target="_blank">Optimizing Highway Traffic Flow in Mixed Autonomy: A Multiagent Truncated Rollout Approach</a></h3>
                    <p><strong>Authors:</strong> Lu Liu, Chi Xie, Xi Xiong</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.MA</p>
                    <p><strong>Summary:</strong> The development of connected and autonomous vehicles (CAVs) offers substantial opportunities to enhance traffic efficiency. However, in mixed autonomy environments where CAVs coexist with human-driven vehicles (HDVs), achieving efficient coordination among CAVs remains challenging due to heterogeneous driving behaviors. To address this, this paper proposes a multiagent truncated rollout approach that enhances CAV speed coordination to improve highway throughput while reducing computational overhead. In this approach, a traffic density evolution equation is formulated that comprehensively accounts for the presence or absence of CAVs, and a distributed coordination control framework is established accordingly. By incorporating kinematic information from neighbor agents and employing an agent-by-agent sequential solution mechanism, our method enables explicit cooperation among CAVs. Furthermore, we introduce a truncated rollout scheme that adaptively shortens the optimization horizon based on the evaluation of control sequences. This significantly reduces the time complexity, thereby improving real-time performance and scalability. Theoretical analysis provides rigorous guarantees on the stability and performance improvement of the system. Simulations conducted on real-world bottleneck scenarios demonstrate that, in large-scale mixed traffic flows, the proposed method outperforms conventional model predictive control methods by reducing both the average travel time in the bottleneck area and overall computational time, highlighting its strong potential for practical deployment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19202v1" target="_blank">Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning</a></h3>
                    <p><strong>Authors:</strong> Alan Li, Yixin Liu, Arpan Sarkar, Doug Downey, Arman Cohan</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Scientific problem solving poses unique challenges for LLMs, requiring both deep domain knowledge and the ability to apply such knowledge through complex reasoning. While automated scientific reasoners hold great promise for assisting human scientists, there is currently no widely adopted holistic benchmark for evaluating scientific reasoning, and few approaches systematically disentangle the distinct roles of knowledge and reasoning in these tasks. To address these gaps, we introduce SciReas, a diverse suite of existing benchmarks for scientific reasoning tasks, and SciReas-Pro, a selective subset that requires more complex reasoning. Our holistic evaluation surfaces insights about scientific reasoning performance that remain hidden when relying on individual benchmarks alone. We then propose KRUX, a probing framework for studying the distinct roles of reasoning and knowledge in scientific tasks. Combining the two, we conduct an in-depth analysis that yields several key findings: (1) Retrieving task-relevant knowledge from model parameters is a critical bottleneck for LLMs in scientific reasoning; (2) Reasoning models consistently benefit from external knowledge added in-context on top of the reasoning enhancement; (3) Enhancing verbalized reasoning improves LLMs ability to surface task-relevant knowledge. Finally, we conduct a lightweight analysis, comparing our science-focused data composition with concurrent efforts on long CoT SFT, and release SciLit01, a strong 8B baseline for scientific reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19200v1" target="_blank">The Ramon Llulls Thinking Machine for Automated Ideation</a></h3>
                    <p><strong>Authors:</strong> Xinran Zhao, Boyuan Zheng, Chenglei Si, Haofei Yu, Ken Liu, Runlong Zhou, Ruochen Li, Tong Chen, Xiang Li, Yiming Zhang, Tongshuang Wu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> This paper revisits Ramon Llulls Ars combinatoria - a medieval framework for generating knowledge through symbolic recombination - as a conceptual foundation for building a modern Llulls thinking machine for research ideation. Our approach defines three compositional axes: Theme (e.g., efficiency, adaptivity), Domain (e.g., question answering, machine translation), and Method (e.g., adversarial training, linear attention). These elements represent high-level abstractions common in scientific work - motivations, problem settings, and technical approaches - and serve as building blocks for LLM-driven exploration. We mine elements from human experts or conference papers and show that prompting LLMs with curated combinations produces research ideas that are diverse, relevant, and grounded in current literature. This modern thinking machine offers a lightweight, interpretable tool for augmenting scientific creativity and suggests a path toward collaborative ideation between humans and AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19196v1" target="_blank">String Corrected Scalar Field Inflation Compatible with the ACT Data</a></h3>
                    <p><strong>Authors:</strong> V. K. Oikonomou</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.CO, hep-th</p>
                    <p><strong>Summary:</strong> We consider the impact of the first string corrections of minimally coupled single scalar field theory on inflationary dynamics. Specifically we consider separately the string corrections $\sim \alpha\xi(\phi)c_2\,\left( \partial_{\mu}\phi \partial^{\mu}\phi\right)^2$ and $\sim \alphac \square \phi \partial_{\mu}\phi \partial^{\mu}\phi$, where $\alpha$ is the square of the string scale. Our aim is to develop a theory which is self consistent in the sense that the field equations reproduce themselves in the slow-roll approximation. Such a requirement for the theory with $\sim \alpha\xi(\phi) c_2\left( \partial_{\mu}\phi \partial^{\mu}\phi\right)^2$ resulted to a trivial non-minimal coupling function $\xi(\phi)$, however a self-consistent framework emerged from the theory with correction term $\sim \alpha c \square \phi \partial_{\mu}\phi \partial^{\mu}\phi$. The resulting theory can easily be worked out analytically and we obtained an inflationary theory that can easily be fitted with the Atacama Cosmology Telescope constraints on the scalar spectral index and the updated Planck constraints on the tensor-to-scalar ratio.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19195v1" target="_blank">All-in-One Slider for Attribute Manipulation in Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Weixin Ye, Hongguang Zhu, Wei Wang, Yahui Liu, Mengyu Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-image (T2I) diffusion models have made significant strides in generating high-quality images. However, progressively manipulating certain attributes of generated images to meet the desired user expectations remains challenging, particularly for content with rich details, such as human faces. Some studies have attempted to address this by training slider modules. However, they follow a One-for-One manner, where an independent slider is trained for each attribute, requiring additional training whenever a new attribute is introduced. This not only results in parameter redundancy accumulated by sliders but also restricts the flexibility of practical applications and the scalability of attribute manipulation. To address this issue, we introduce the All-in-One Slider, a lightweight module that decomposes the text embedding space into sparse, semantically meaningful attribute directions. Once trained, it functions as a general-purpose slider, enabling interpretable and fine-grained continuous control over various attributes. Moreover, by recombining the learned directions, the All-in-One Slider supports zero-shot manipulation of unseen attributes (e.g., races and celebrities) and the composition of multiple attributes. Extensive experiments demonstrate that our method enables accurate and scalable attribute manipulation, achieving notable improvements compared to previous methods. Furthermore, our method can be extended to integrate with the inversion framework to perform attribute manipulation on real images, broadening its applicability to various real-world scenarios. The code and trained model will be released at: https://github.com/ywxsuperstar/KSAE-FaceSteer.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19194v1" target="_blank">Long-lived quasinormal modes and echoes in the Einstein-Gauss-Bonnet-Proca theory</a></h3>
                    <p><strong>Authors:</strong> B. C. Lütfüoğlu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We study quasinormal modes and time-domain profiles of a massive scalar field in the background of black holes arising in Einstein--Gauss--Bonnet--Proca gravity. The black holes in this theory possess \emph{primary Proca hair}, which modifies the effective potential and gives rise to distinctive dynamical phenomena. Using three complementary numerical techniques -- the WKB method with Pad\e resummation, time-domain integration, and the Frobenius (Leaver) method -- we obtain accurate spectra of quasinormal frequencies. Our analysis shows that increasing the scalar-field mass leads to arbitrarily long-lived states, known as quasi-resonances, a behavior shared by both the fundamental mode and the first overtone. The real part of the quasinormal mode decreases for the first and higher overtones and starting from the second overtone it reaches zero at some critical value of mass of the field. When the effective potential develops an additional peak, the late-time signal exhibits a sequence of echoes. Furthermore, the time-domain evolution reveals distinct regimes of intermediate power-law tails $\sim t^{-4/3-\ell}\sin(A(\mu)t)$ and a universal asymptotic tails $\sim t^{-5/6}\sin(\mu t)$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19188v1" target="_blank">FastMesh:Efficient Artistic Mesh Generation via Component Decoupling</a></h3>
                    <p><strong>Authors:</strong> Jeonghwan Kim, Yushi Lan, Armando Fortes, Yongwei Chen, Xingang Pan</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent mesh generation approaches typically tokenize triangle meshes into sequences of tokens and train autoregressive models to generate these tokens sequentially. Despite substantial progress, such token sequences inevitably reuse vertices multiple times to fully represent manifold meshes, as each vertex is shared by multiple faces. This redundancy leads to excessively long token sequences and inefficient generation processes. In this paper, we propose an efficient framework that generates artistic meshes by treating vertices and faces separately, significantly reducing redundancy. We employ an autoregressive model solely for vertex generation, decreasing the token count to approximately 23\% of that required by the most compact existing tokenizer. Next, we leverage a bidirectional transformer to complete the mesh in a single step by capturing inter-vertex relationships and constructing the adjacency matrix that defines the mesh faces. To further improve the generation quality, we introduce a fidelity enhancer to refine vertex positioning into more natural arrangements and propose a post-processing framework to remove undesirable edge connections. Experimental results show that our method achieves more than 8$\times$ faster speed on mesh generation compared to state-of-the-art approaches, while producing higher mesh quality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19186v1" target="_blank">Real-Time Model Checking for Closed-Loop Robot Reactive Planning</a></h3>
                    <p><strong>Authors:</strong> Christopher Chandler, Bernd Porr, Giulia Lafratta, Alice Miller</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.FL, I.2.9; I.2; D.2.4</p>
                    <p><strong>Summary:</strong> We present a new application of model checking which achieves real-time multi-step planning and obstacle avoidance on a real autonomous robot. We have developed a small, purpose-built model checking algorithm which generates plans in situ based on core knowledge and attention as found in biological agents. This is achieved in real-time using no pre-computed data on a low-powered device. Our approach is based on chaining temporary control systems which are spawned to counteract disturbances in the local environment that disrupt an autonomous agent from its preferred action (or resting state). A novel discretization of 2D LiDAR data sensitive to bounded variations in the local environment is used. Multi-step planning using model checking by forward depth-first search is applied to cul-de-sac and playground scenarios. Both empirical results and informal proofs of two fundamental properties of our approach demonstrate that model checking can be used to create efficient multi-step plans for local obstacle avoidance, improving on the performance of a reactive agent which can only plan one step. Our approach is an instructional case study for the development of safe, reliable and explainable planning in the context of autonomous vehicles.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19185v1" target="_blank">Instantaneous Polarimetry with Zak-OTFS</a></h3>
                    <p><strong>Authors:</strong> Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.SP, cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> Polarimetry, which is the ability to measure the scattering response of the environment across orthogonal polarizations, is fundamental to enhancing wireless communication and radar system performance. In this paper, we utilize the Zak-OTFS modulation to enable instantaneous polarimetry within a single transmission frame. We transmit a Zak-OTFS carrier waveform and a spread carrier waveform mutually unbiased to it simultaneously over orthogonal polarizations. The mutual unbiasedness of the two waveforms enables the receiver to estimate the full polarimetric response of the scattering environment from a single received frame. Unlike existing methods for instantaneous polarimetry with computational complexity quadratic in the time-bandwidth product, the proposed method enables instantaneous polarimetry at complexity that is only sublinear in the time-bandwidth product. Via numerical simulations, we show ideal polarimetric target detection and parameter estimation results with the proposed method, with improvements in performance and computational complexity over comparable baselines.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746252.3761039" target="_blank">Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness</a></h3>
                    <p><strong>Authors:</strong> Wenchuan Mu, Kwan Hui Lim</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In safety-critical deep learning applications, robustness measures the ability of neural models that handle imperceptible perturbations in input data, which may lead to potential safety hazards. Existing pre-deployment robustness assessment methods typically suffer from significant trade-offs between computational cost and measurement precision, limiting their practical utility. To address these limitations, this paper conducts a comprehensive comparative analysis of existing robustness definitions and associated assessment methodologies. We propose tower robustness to evaluate robustness, which is a novel, practical metric based on hypothesis testing to quantitatively evaluate probabilistic robustness, enabling more rigorous and efficient pre-deployment assessments. Our extensive comparative evaluation illustrates the advantages and applicability of our proposed approach, thereby advancing the systematic understanding and enhancement of model robustness in safety-critical deep learning applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19182v1" target="_blank">SoccerNet 2025 Challenges Results</a></h3>
                    <p><strong>Authors:</strong> Silvio Giancola, Anthony Cioppa, Marc Gutiérrez-Pérez, Jan Held, Carlos Hinojosa, Victor Joos, Arnaud Leduc, Floriane Magera, Karen Sanchez, Vladimir Somers, Artur Xarles, Antonio Agudo, Alexandre Alahi, Olivier Barnich, Albert Clapés, Christophe De Vleeschouwer, Sergio Escalera, Bernard Ghanem, Thomas B. Moeslund, Marc Van Droogenbroeck, Tomoki Abe, Saad Alotaibi, Faisal Altawijri, Steven Araujo, Xiang Bai, Xiaoyang Bi, Jiawang Cao, Vanyi Chao, Kamil Czarnogórski, Fabian Deuser, Mingyang Du, Tianrui Feng, Patrick Frenzel, Mirco Fuchs, Jorge García, Konrad Habel, Takaya Hashiguchi, Sadao Hirose, Xinting Hu, Yewon Hwang, Ririko Inoue, Riku Itsuji, Kazuto Iwai, Hongwei Ji, Yangguang Ji, Licheng Jiao, Yuto Kageyama, Yuta Kamikawa, Yuuki Kanasugi, Hyungjung Kim, Jinwook Kim, Takuya Kurihara, Bozheng Li, Lingling Li, Xian Li, Youxing Lian, Dingkang Liang, Hongkai Lin, Jiadong Lin, Jian Liu, Liang Liu, Shuaikun Liu, Zhaohong Liu, Yi Lu, Federico Méndez, Huadong Ma, Wenping Ma, Jacek Maksymiuk, Henry Mantilla, Ismail Mathkour, Daniel Matthes, Ayaha Motomochi, Amrulloh Robbani Muhammad, Haruto Nakayama, Joohyung Oh, Yin May Oo, Marcelo Ortega, Norbert Oswald, Rintaro Otsubo, Fabian Perez, Mengshi Qi, Cristian Rey, Abel Reyes-Angulo, Oliver Rose, Hoover Rueda-Chacón, Hideo Saito, Jose Sarmiento, Kanta Sawafuji, Atom Scott, Xi Shen, Pragyan Shrestha, Jae-Young Sim, Long Sun, Yuyang Sun, Tomohiro Suzuki, Licheng Tang, Masato Tonouchi, Ikuma Uchida, Henry O. Velesaca, Tiancheng Wang, Rio Watanabe, Jay Wu, Yongliang Wu, Shunzo Yamagishi, Di Yang, Xu Yang, Yuxin Yang, Hao Ye, Xinyu Ye, Calvin Yeung, Xuanlong Yu, Chao Zhang, Dingyuan Zhang, Kexing Zhang, Zhe Zhao, Xin Zhou, Wenbo Zhu, Julian Ziegler</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This years challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, targeting the recovery of scene geometry from single-camera broadcast clips through relative depth estimation for each pixel; (3) Multi-View Foul Recognition, requiring the analysis of multiple synchronized camera views to classify fouls and their severity; and (4) Game State Reconstruction, aimed at localizing and identifying all players from a broadcast video to reconstruct the game state on a 2D top-view of the field. Across all tasks, participants were provided with large-scale annotated datasets, unified evaluation protocols, and strong baselines as starting points. This report presents the results of each challenge, highlights the top-performing solutions, and provides insights into the progress made by the community. The SoccerNet Challenges continue to serve as a driving force for reproducible, open research at the intersection of computer vision, artificial intelligence, and sports. Detailed information about the tasks, challenges, and leaderboards can be found at https://www.soccer-net.org, with baselines and development kits available at https://github.com/SoccerNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19178v1" target="_blank">Gravitational perturbations of the Hayward spacetime and testing the correspondence between quasinormal modes and grey-body factors</a></h3>
                    <p><strong>Authors:</strong> Zainab Malik</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> The paper studies axial gravitational perturbations of the Hayward black hole, a regular geometry that also arises as an effective solution in asymptotically safe gravity. By computing grey-body factors with the 6th-order WKB method and comparing them to predictions based on the quasinormal modes, the correspondence between transmission coefficients and quasinormal spectra is verified. Quantum corrections, parametrized by $\gamma$, are shown to suppress both the grey-body factors and the absorption cross-section, while the correspondence remains accurate at the percent level for low multipoles and essentially exact for higher ones.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19173v1" target="_blank">Leveraging Evolutionary Surrogate-Assisted Prescription in Multi-Objective Chlorination Control Systems</a></h3>
                    <p><strong>Authors:</strong> Rivaaj Monsia, Olivier Francon, Daniel Young, Risto Miikkulainen</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.NE, cs.LG</p>
                    <p><strong>Summary:</strong> This short, written report introduces the idea of Evolutionary Surrogate-Assisted Prescription (ESP) and presents preliminary results on its potential use in training real-world agents as a part of the 1st AI for Drinking Water Chlorination Challenge at IJCAI-2025. This work was done by a team from Project Resilience, an organization interested in bridging AI to real-world problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19171v1" target="_blank">Short presentations for crystallographic groups</a></h3>
                    <p><strong>Authors:</strong> Igor A. Baburin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.GR, math.CO, 20-04</p>
                    <p><strong>Summary:</strong> A practical approach is proposed to construct short presentations for Euclidean crystallographic groups in terms of generators and relations. For our purposes a short presentation is the one with a small number of short relators for a given generating set. The connection is emphasized between relators of a group presentation and cycles in the associated Cayley graph. It is shown by examples that a short presentation is usually the one where relators correspond to strong rings in the Cayley graph and therefore provide a natural upper bound for their size. Presentations are computed for vertex-transitive groups which act with trivial vertex stabilizers on a number of high-symmetry 2-, 3- and 4-periodic graphs. Higher-dimensional as well as subperiodic examples are also considered. Relations are explored between geodesics in periodic graphs and corresponding cycles in their quotients.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19169v1" target="_blank">Graph Neural Network-Based Topology Optimization for Self-Supporting Structures in Additive Manufacturing</a></h3>
                    <p><strong>Authors:</strong> Alireza Tabarraei, Saquib Ahmad Bhuiyan</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> This paper presents a machine learning-based framework for topology optimization of self-supporting structures, specifically tailored for additive manufacturing (AM). By employing a graph neural network (GNN) that acts as a neural field over the finite element mesh, the framework effectively learns and predicts continuous material distributions. An integrated AM filter ensures printability by eliminating unsupported overhangs, while the optimization process minimizes structural compliance under volume and stress constraints. The stress constraint is enforced using a differentiable p-norm aggregation of von Mises stress, promoting mechanical reliability in the optimized designs. A key advantage of the approach lies in its fully differentiable architecture, which leverages automatic differentiation throughout the optimization loop--eliminating the need for explicit sensitivity derivation for both the filter and the stress constraint. Numerical experiments demonstrate the ability of the framework to generate stress-constrained manufacturable topologies under various loading and boundary conditions, offering a practical pathway toward AM-ready high-performance designs with reduced post-processing requirements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19167v1" target="_blank">Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions</a></h3>
                    <p><strong>Authors:</strong> Zhihang Xin, Xitong Hu, Rui Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Vision Transformers have demonstrated remarkable success in computer vision tasks, yet their reliance on learnable one-dimensional positional embeddings fundamentally disrupts the inherent two-dimensional spatial structure of images through patch flattening procedures. Traditional positional encoding approaches lack geometric constraints and fail to establish monotonic correspondence between Euclidean spatial distances and sequential index distances, thereby limiting the models capacity to leverage spatial proximity priors effectively. We propose Weierstrass Elliptic Function Positional Encoding (WEF-PE), a mathematically principled approach that directly addresses two-dimensional coordinates through natural complex domain representation, where the doubly periodic properties of elliptic functions align remarkably with translational invariance patterns commonly observed in visual data. Our method exploits the non-linear geometric nature of elliptic functions to encode spatial distance relationships naturally, while the algebraic addition formula enables direct derivation of relative positional information between arbitrary patch pairs from their absolute encodings. Comprehensive experiments demonstrate that WEF-PE achieves superior performance across diverse scenarios, including 63.78\% accuracy on CIFAR-100 from-scratch training with ViT-Tiny architecture, 93.28\% on CIFAR-100 fine-tuning with ViT-Base, and consistent improvements on VTAB-1k benchmark tasks. Theoretical analysis confirms the distance-decay property through rigorous mathematical proof, while attention visualization reveals enhanced geometric inductive bias and more coherent semantic focus compared to conventional approaches.The source code implementing the methods described in this paper is publicly available on GitHub.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19165v1" target="_blank">Dual Enhancement on 3D Vision-Language Perception for Monocular 3D Visual Grounding</a></h3>
                    <p><strong>Authors:</strong> Yuzhen Li, Min Liu, Yuan Bian, Xueping Wang, Zhaoyang Li, Gen Li, Yaonan Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, Information systems~Multimedia and multimodal retrieval</p>
                    <p><strong>Summary:</strong> Monocular 3D visual grounding is a novel task that aims to locate 3D objects in RGB images using text descriptions with explicit geometry information. Despite the inclusion of geometry details in the text, we observe that the text embeddings are sensitive to the magnitude of numerical values but largely ignore the associated measurement units. For example, simply equidistant mapping the length with unit meter to decimeters or centimeters leads to severe performance degradation, even though the physical length remains equivalent. This observation signifies the weak 3D comprehension of pre-trained language model, which generates misguiding text features to hinder 3D perception. Therefore, we propose to enhance the 3D perception of model on text embeddings and geometry features with two simple and effective methods. Firstly, we introduce a pre-processing method named 3D-text Enhancement (3DTE), which enhances the comprehension of mapping relationships between different units by augmenting the diversity of distance descriptors in text queries. Next, we propose a Text-Guided Geometry Enhancement (TGE) module to further enhance the 3D-text information by projecting the basic text features into geometrically consistent space. These 3D-enhanced text features are then leveraged to precisely guide the attention of geometry features. We evaluate the proposed method through extensive comparisons and ablation studies on the Mono3DRefer dataset. Experimental results demonstrate substantial improvements over previous methods, achieving new state-of-the-art results with a notable accuracy gain of 11.94\% in the Far scenario. Our code will be made publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19164v1" target="_blank">Real-time Testing of Satellite Attitude Control With a Reaction Wheel Hardware-In-the-Loop Platform</a></h3>
                    <p><strong>Authors:</strong> Morokot Sakal, George Nehma, Camilo Riano-Rios, Madhur Tiwari</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> We propose the Hardware-in-the-Loop (HIL) test of an adaptive satellite attitude control system with reaction wheel health estimation capabilities. Previous simulations and Software-in-the-Loop testing have prompted further experiments to explore the validity of the controller with real momentum exchange devices in the loop. This work is a step toward a comprehensive testing framework for validation of spacecraft attitude control algorithms. The proposed HIL testbed includes brushless DC motors and drivers that communicate using a CAN bus, an embedded computer that executes control and adaptation laws, and a satellite simulator that produces simulated sensor data, estimated attitude states, and responds to actions of the external actuators. We propose methods to artificially induce failures on the reaction wheels, and present related issues and lessons learned.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19162v1" target="_blank">Few-Shot Connectivity-Aware Text Line Segmentation in Historical Documents</a></h3>
                    <p><strong>Authors:</strong> Rafael Sterzinger, Tingyu Lin, Robert Sablatnig</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> A foundational task for the digital analysis of documents is text line segmentation. However, automating this process with deep learning models is challenging because it requires large, annotated datasets that are often unavailable for historical documents. Additionally, the annotation process is a labor- and cost-intensive task that requires expert knowledge, which makes few-shot learning a promising direction for reducing data requirements. In this work, we demonstrate that small and simple architectures, coupled with a topology-aware loss function, are more accurate and data-efficient than more complex alternatives. We pair a lightweight UNet++ with a connectivity-aware loss, initially developed for neuron morphology, which explicitly penalizes structural errors like line fragmentation and unintended line merges. To increase our limited data, we train on small patches extracted from a mere three annotated pages per manuscript. Our methodology significantly improves upon the current state-of-the-art on the U-DIADS-TL dataset, with a 200% increase in Recognition Accuracy and a 75% increase in Line Intersection over Union. Our method also achieves an F-Measure score on par with or even exceeding that of the competition winner of the DIVA-HisDB baseline detection task, all while requiring only three annotated pages, exemplifying the efficacy of our approach. Our implementation is publicly available at: https://github.com/RafaelSterzinger/acpr_few_shot_hist.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19161v1" target="_blank">The charge-carrier trapping effect on 1/f noise in monolayer graphene</a></h3>
                    <p><strong>Authors:</strong> K. A. Kazakov, T. M. Valitov</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> The frequency exponent of 1/f noise in graphene-boron nitride heterostructures is known to have multiple extrema in its dependence on the charge carrier concentration. This behavior is explained in the present paper as a result of the charge carrier trapping by impurities in the boron nitride. A kinetic equation for the charge carriers subject to trapping and interacting with acoustic phonons is derived. This equation is solved numerically, and the equilibrium solutions are used to evaluate the frequency exponent according to the quantum theory of 1/f noise. It is found that the frequency exponent does develop several minima and maxima, provided that the trapping probability is sufficiently wide and has a threshold with respect to the charge carrier energy. A detailed comparison with the experimental data is made, and the results are used to estimate the energy threshold and the trapping cross-section.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19160v1" target="_blank">Architecting Distributed Quantum Computers: Design Insights from Resource Estimation</a></h3>
                    <p><strong>Authors:</strong> Dmitry Filippov, Peter Yang, Prakash Murali</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.AR, cs.DC, cs.ET</p>
                    <p><strong>Summary:</strong> To enable practically useful quantum computing, we require hundreds to thousands of logical qubits (collections of physical qubits with error correction). Current monolithic device architectures have scaling limits beyond few tens of logical qubits. To scale up, we require architectures that orchestrate several monolithic devices into a distributed quantum computing system. Currently, resource estimation, which is crucial for determining hardware needs and bottlenecks, focuses exclusively on monolithic systems. Our work fills this gap and answers key architectural design questions about distributed systems, including the impact of distribution on application resource needs, the organization of qubits across nodes and the requirements of entanglement distillation (quantum network). To answer these questions, we develop a novel resource estimation framework that models the key components of the distributed execution stack. We analyse the performance of practical quantum algorithms on various hardware configurations, spanning different qubit speeds, entanglement generation rates and distillation protocols. We show that distributed architectures have practically feasible resource requirements; for a node size of 45K qubits, distributed systems need on average 1.4X higher number of physical qubits and 4X higher execution time compared to monolithic architectures, but with more favourable hardware implementation prospects. Our insights on entanglement generation rates, node sizes and architecture have the potential to inform system designs in the coming years.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19158v1" target="_blank">Pointer Chasing with Unlimited Interaction</a></h3>
                    <p><strong>Authors:</strong> Orr Fischer, Rotem Oshman, Adi Rosen, Tal Roth</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CC</p>
                    <p><strong>Summary:</strong> Pointer-chasing is a central problem in two-party communication complexity: given input size $n$ and a parameter $k$, the two players Alice and Bob are given functions $N_A, N_B: [n] \rightarrow [n]$, respectively, and their goal is to compute the value of $p_k$, where $p_0 = 1$, $p_1 = N_A(p_0)$, $p_2 = N_B(p_1) = N_B(N_A(p_0))$, $p_3 = N_A(p_2) = N_A(N_B(N_A(p_0)))$ and so on, applying $N_A$ in even steps and $N_B$ in odd steps, for a total of $k$ steps. It is trivial to solve the problem using $k$ communication rounds, with Alice speaking first, by simply ``chasing the function for $k$ steps. Many works have studied the communication complexity of pointer chasing, although the focus has always been on protocols with $k-1$ communication rounds, or with $k$ rounds where Bob (the ``wrong player) speaks first. Many works have studied this setting giving sometimes tight or near-tight results. In this paper we study the communication complexity of the pointer chasing problem when the interaction between the two players is unlimited, i.e., without any restriction on the number of rounds. Perhaps surprisingly, this question was not studied before, to the best of our knowledge. Our main result is that the trivial $k$-round protocol is nearly tight (even) when the number of rounds is not restricted: we give a lower bound of $\Omega(k \log (n/k))$ on the randomized communication complexity of the pointer chasing problem with unlimited interaction, and a somewhat stronger lower bound of $\Omega(k \log \log{k})$ for protocols with zero error. When combined with prior work, our results also give a nearly-tight bound on the communication complexity of protocols using at most $k-1$ rounds, across all regimes of $k$; for $k  \sqrt{n}$ there was previously a significant gap between the upper and lower bound.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19156v1" target="_blank">Measuring high field gradients of cobalt nanomagnets in a spin-mechanical setup</a></h3>
                    <p><strong>Authors:</strong> Felix Hahne, Teresa Klara Pfau, Liza Žaper, Lucio Stefan, Thibault Capelle, Andrea Ranfagni, Martino Poggio, Albert Schliesser</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, quant-ph</p>
                    <p><strong>Summary:</strong> Hybrid systems composed of a single nitrogen-vacancy center spin magnetically coupled to a macroscopic mechanical resonator constitute promising platforms for the realization of quantum information protocols and for quantum sensing applications. The magnetic structure that mediates the interaction must ensure high field gradients while preserving the spin and mechanical properties. We present a spin-mechanical setup built around a cobalt nanomagnet grown with focused electron beam-induced deposition. The magnetic structure is fully characterized, and a maximum gradient of $170\,\mathrm{kT/m}$ is directly measured at a spin-oscillator distance of a few hundred nanometers. Spin coherence was preserved at the value of $20\,\mathrm{ \mu s}$ up to a gradient of $25\,\mathrm{kT/m}$. The effect of the mechanical motion onto the spin dynamics was observed, thus signifying the presence of spin-mechanics coupling. Given the noninvasive nature of the nanomagnet deposition process, we foresee the adoption of such structures in hybrid platforms with high-quality factor resonators, in the magnet on oscillator configuration.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

