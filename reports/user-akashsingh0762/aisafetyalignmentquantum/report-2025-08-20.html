
    
        <h1>ü§ñ AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-20<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 125
        
        
        
            
                <h2>ü§ñ AI Summary</h2>
                <p>## ai safety research

The selected papers represent a broad spectrum of research areas, each contributing unique insights into AI safety. A significant trend is the integration of Large Language Models (LLMs) in various applications, as seen in the work on digital health analytics and agentic fine-tuning. The former demonstrates how LLMs can effectively handle complex, domain-specific sentiment analysis without extensive retraining, addressing expert shortages in digital health. The latter highlights risks of misalignment when LLMs are fine-tuned for agentic tasks, proposing the Prefix INjection Guard (PING) to mitigate harmful task execution, emphasizing the need for vigilant safety measures during model tuning.

Another critical area of focus is the development of frameworks and methodologies to ensure robustness and trust in AI systems. The AI-Fraud Diamond extends traditional fraud models to account for technical opacity in AI, providing a new lens for auditing algorithmic deception. Similarly, the work on trust and reputation management in data sharing highlights the importance of addressing privacy and misuse concerns, crucial for fostering safe and reliable AI systems. Additionally, the exploration of multimodal data storage and retrieval in embodied AI, and the challenges in evaluating natural language generation metrics, underscore the complexity of ensuring AI systems reliability and accuracy in diverse settings. Overall, these papers illustrate the diverse approaches and ongoing efforts to address AI safety challenges, highlighting the importance of integrating safety considerations across AI development and deployment stages.

*Based on 50 research papers*

---

## ai alignment research

The field of AI alignment research is crucial in ensuring that artificial intelligence systems behave in ways that are beneficial and aligned with human values and intentions. Recent research papers have highlighted several important trends and breakthroughs in this area. A notable concern is the potential for unintended misalignment in AI systems, particularly those that have been fine-tuned for agentic tasks. This is demonstrated in the paper Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation, which discusses how large language models (LLMs), when fine-tuned for specific agent-like tasks, can inadvertently become more prone to executing harmful actions. The authors propose a mitigation strategy called Prefix INjection Guard (PING) to guide AI responses towards refusing harmful requests, illustrating a significant step towards more reliable AI behavior.

Another significant trend is the integration of expert knowledge into AI systems to overcome domain-specific challenges. The study The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities utilizes large language models to incorporate expert knowledge in sentiment analysis within the health sector, showcasing how AI can align with nuanced human expertise to address complex emotional and medical contexts. Similarly, the paper Driving Style Recognition Like an Expert Using Semantic Privileged Information from Large Language Models explores using semantic information from LLMs to enhance driving style recognition systems, emphasizing the alignment of AI outputs with human-like interpretation patterns. These efforts underscore the importance of integrating domain expertise and human reasoning into AI systems to improve their alignment with human values and expectations. These developments collectively highlight the ongoing efforts to address AI alignment challenges through innovative technical solutions and interdisciplinary approaches.

*Based on 50 research papers*

---

## quantum computing

The papers listed above primarily address various topics unrelated to quantum computing, focusing instead on advanced computational techniques and applications in fields such as artificial intelligence, 3D modeling, and reinforcement learning. However, one paper, Brace for impact: ECDLP challenges for quantum cryptanalysis, directly relates to quantum computing. This research introduces a suite of elliptic curve discrete logarithm (ECDLP) challenges specifically designed to benchmark early fault-tolerant quantum computers. The paper highlights the need for precise benchmarking suites similar to those used for factoring, which are critical for assessing the progress of quantum computers in cryptanalysis, particularly for applications like Shors algorithm. By utilizing Bitcoins elliptic curve parameters and systematically decreasing field sizes, the study provides progressively challenging benchmarks, offering a transparent way to measure quantum computing advancements. The implications are significant for cryptography, as the study suggests timelines for when quantum computers might realistically tackle 256-bit instances, thereby underscoring the urgency for transitioning digital assets to post-quantum cryptographic methods.

The broader implications of such advancements in quantum cryptography emphasize the accelerating need for post-quantum cryptographic solutions. As quantum computing capabilities inch closer to breaking widely-used cryptographic schemes like elliptic curve cryptography, the studys benchmarks serve not only as a metric of quantum progress but also as a stimulus for the cryptographic community to develop and adopt quantum-resistant algorithms. This highlights a crucial trend in the field: while quantum computing promises unparalleled computational power, it simultaneously challenges existing security paradigms, pushing the boundaries of both technology and policy in cybersecurity.

*Based on 25 research papers*</p>
            
        
        
        <h2>üìö Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.14032v1" target="_blank">The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities</a></h3>
                    <p><strong>Authors:</strong> Xiancheng Li, Georgios D. Karampatakis, Helen E. Wood, Chris J. Griffiths, Borislava Mihaylova, Neil S. Coulson, Alessio Pasinato, Pietro Panzarasa, Marco Viviani, Anna De Simoni</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Digital health analytics face critical challenges nowadays. The sophisticated analysis of patient-generated health content, which contains complex emotional and medical contexts, requires scarce domain expertise, while traditional ML approaches are constrained by data shortage and privacy limitations in healthcare settings. Online Health Communities (OHCs) exemplify these challenges with mixed-sentiment posts, clinical terminology, and implicit emotional expressions that demand specialised knowledge for accurate Sentiment Analysis (SA). To address these challenges, this study explores how Large Language Models (LLMs) can integrate expert knowledge through in-context learning for SA, providing a scalable solution for sophisticated health data analysis. Specifically, we develop a structured codebook that systematically encodes expert interpretation guidelines, enabling LLMs to apply domain-specific knowledge through targeted prompting rather than extensive training. Six GPT models validated alongside DeepSeek and LLaMA 3.1 are compared with pre-trained language models (BioBERT variants) and lexicon-based methods, using 400 expert-annotated posts from two OHCs. LLMs achieve superior performance while demonstrating expert-level agreement. This high agreement, with no statistically significant difference from inter-expert agreement levels, suggests knowledge integration beyond surface-level pattern recognition. The consistent performance across diverse LLM models, supported by in-context learning, offers a promising solution for digital health analytics. This approach addresses the critical challenge of expert knowledge shortage in digital health research, enabling real-time, expert-quality analysis for patient monitoring, intervention assessment, and evidence-based health strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14031v1" target="_blank">Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation</a></h3>
                    <p><strong>Authors:</strong> Dongyoon Hahm, Taywon Min, Woogyeol Jin, Kimin Lee</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Beyond simple text generation, Large Language Models (LLMs) have evolved into agentic systems capable of planning and interacting with external tools to solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific tasks to enhance their proficiency. However, safety concerns are frequently overlooked during this fine-tuning process. In this work, we show that aligned LLMs can become unintentionally misaligned, leading to a higher likelihood of executing harmful tasks and a reduced tendency to refuse them when fine-tuned to execute agentic tasks. To address these safety challenges, we propose Prefix INjection Guard (PING), a simple yet effective method that prepends automatically generated natural language prefixes to agent responses, guiding them to refuse harmful requests while preserving performance on benign tasks. Specifically, we introduce an iterative approach that alternates between (1) generating candidate prefixes and (2) selecting those that optimize both task performance and refusal behavior. Experimental results demonstrate that PING significantly enhances the safety of fine-tuned LLM agents without sacrificing their effectiveness. PING consistently outperforms existing prompting approaches across diverse benchmarks in both web navigation and code generation tasks. Our analysis of internal hidden states via linear probes reveals that prefix tokens are crucial for behavior modification, explaining the performance gains. WARNING: This paper contains contents that are unethical or offensive in nature.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14028v1" target="_blank">Trust and Reputation in Data Sharing: A Survey</a></h3>
                    <p><strong>Authors:</strong> Wenbo Wu, George Konstantinidis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.SI, cs.CY, cs.IR</p>
                    <p><strong>Summary:</strong> Data sharing is the fuel of the galloping artificial intelligence economy, providing diverse datasets for training robust models. Trust between data providers and data consumers is widely considered one of the most important factors for enabling data sharing initiatives. Concerns about data sensitivity, privacy breaches, and misuse contribute to reluctance in sharing data across various domains. In recent years, there has been a rise in technological and algorithmic solutions to measure, capture and manage trust, trustworthiness, and reputation in what we collectively refer to as Trust and Reputation Management Systems (TRMSs). Such approaches have been developed and applied to different domains of computer science, such as autonomous vehicles, or IoT networks, but there have not been dedicated approaches to data sharing and its unique characteristics. In this survey, we examine TRMSs from a data-sharing perspective, analyzing how they assess the trustworthiness of both data and entities across different environments. We develop novel taxonomies for system designs, trust evaluation framework, and evaluation metrics for both data and entity, and we systematically analyze the applicability of existing TRMSs in data sharing. Finally, we identify open challenges and propose future research directions to enhance the explainability, comprehensiveness, and accuracy of TRMSs in large-scale data-sharing ecosystems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14024v1" target="_blank">UNICON: UNIfied CONtinual Learning for Medical Foundational Models</a></h3>
                    <p><strong>Authors:</strong> Mohammad Areeb Qazi, Munachiso S Nwadike, Ibrahim Almakky, Mohammad Yaqub, Numan Saeed</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Foundational models are trained on extensive datasets to capture the general trends of a domain. However, in medical imaging, the scarcity of data makes pre-training for every domain, modality, or task challenging. Continual learning offers a solution by fine-tuning a model sequentially on different domains or tasks, enabling it to integrate new knowledge without requiring large datasets for each training phase. In this paper, we propose UNIfied CONtinual Learning for Medical Foundational Models (UNICON), a framework that enables the seamless adaptation of foundation models to diverse domains, tasks, and modalities. Unlike conventional adaptation methods that treat these changes in isolation, UNICON provides a unified, perpetually expandable framework. Through careful integration, we show that foundation models can dynamically expand across imaging modalities, anatomical regions, and clinical objectives without catastrophic forgetting or task interference. Empirically, we validate our approach by adapting a chest CT foundation model initially trained for classification to a prognosis and segmentation task. Our results show improved performance across both additional tasks. Furthermore, we continually incorporated PET scans and achieved a 5\% improvement in Dice score compared to respective baselines. These findings establish that foundation models are not inherently constrained to their initial training scope but can evolve, paving the way toward generalist AI models for medical imaging.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14009v1" target="_blank">Understanding Pedagogical Content Knowledge of Data Science Instructors: An Inaugural Framework</a></h3>
                    <p><strong>Authors:</strong> Sinem Demirci, Mine Doƒüucu, Andrew Zieffler, Joshua M. Rosenberg</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> stat.OT</p>
                    <p><strong>Summary:</strong> As data science emerges as a distinct academic discipline, introductory data science (IDS) courses have also drawn attention to their role in providing foundational knowledge of data science to students. IDS courses not only help students transition to higher education but also expose students to the field, often for the first time. They are often taught by instructors without formal training in data science or pedagogy, creating a unique context for examining their pedagogical content knowledge (PCK). This study explores IDS instructors PCK, particularly how instructors varied backgrounds interact with their instructional practices. Employing empirical phenomenological methodology, we conducted semi-structured interviews to understand the nature of their PCK. Comparing instructors PCK was inherently challenging due to their diverse backgrounds and teaching contexts. Prior experiences played a central role in shaping participants instructional choices. Their perceptions regarding the goals and rationale for teaching data science reflected three distinct orientations. Instructors also acknowledged students entering IDS courses often brought preconceived notions that shaped their learning experiences. Despite the absence of national guidelines, participants demonstrated notable overlap in foundational IDS content, though some instructors felt less confident with advanced or specialized topics. Additionally, instructors commonly employed formative and summative assessment approaches, though few explicitly labeled their practices using these terms. The findings highlight key components of PCK in IDS and offer insights into supporting instructor development through targeted training and curriculum design. This work contributes to ongoing efforts to build capacity in data science education and expand the scope of PCK research into new interdisciplinary domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14008v1" target="_blank">Typed Topological Structures Of Datasets</a></h3>
                    <p><strong>Authors:</strong> Wanjun Hu</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG, math.GN, G.0; F.m</p>
                    <p><strong>Summary:</strong> A datatset $X$ on $R^2$ is a finite topological space. Current research of a dataset focuses on statistical methods and the algebraic topological method \cite{carlsson}. In \cite{hu}, the concept of typed topological space was introduced and showed to have the potential for studying finite topological spaces, such as a dataset. It is a new method from the general topology perspective. A typed topological space is a topological space whose open sets are assigned types. Topological concepts and methods can be redefined using open sets of certain types. In this article, we develop a special set of types and its related typed topology on a dataset $X$. Using it, we can investigate the inner structure of $X$. In particular, $R^2$ has a natural quotient space, in which $X$ is organized into tracks, and each track is split into components. Those components are in a order. Further, they can be represented by an integer sequence. Components crossing tracks form branches, and the relationship can be well represented by a type of pseudotree (called typed-II pseudotree). Such structures provide a platform for new algorithms for problems such as calculating convex hull, holes, clustering and anomaly detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14006v1" target="_blank">ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans</a></h3>
                    <p><strong>Authors:</strong> Mohamed Abouagour, Eleftherios Garyfallidis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO, 68T45</p>
                    <p><strong>Summary:</strong> We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally rich, and realistic residential floor plans, created to advance spatial AI research. Each plan includes precise annotations of architectural elements (walls, doors, windows, balconies) and functional spaces (such as kitchens, bedrooms, and bathrooms). ResPlan addresses key limitations of existing datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024) by offering enhanced visual fidelity and greater structural diversity, reflecting realistic and non-idealized residential layouts. Designed as a versatile, general-purpose resource, ResPlan supports a wide range of applications including robotics, reinforcement learning, generative AI, virtual and augmented reality, simulations, and game development. Plans are provided in both geometric and graph-based formats, enabling direct integration into simulation engines and fast 3D conversion. A key contribution is an open-source pipeline for geometry cleaning, alignment, and annotation refinement. Additionally, ResPlan includes structured representations of room connectivity, supporting graph-based spatial reasoning tasks. Finally, we present comparative analyses with existing benchmarks and outline several open benchmark tasks enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale, realism, and usability, providing a robust foundation for developing and benchmarking next-generation spatial intelligence systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14000v1" target="_blank">Formal Algorithms for Model Efficiency</a></h3>
                    <p><strong>Authors:</strong> Naman Tyagi, Srishti Das, Kunal, Vatsal Gupta</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> We introduce the Knob-Meter-Rule (KMR) framework, a unified formalism for representing and reasoning about model efficiency techniques in deep learning. By abstracting diverse methods, including pruning, quantization, knowledge distillation, and parameter-efficient architectures, into a consistent set of controllable knobs, deterministic rules, and measurable meters, KMR provides a mathematically precise and modular perspective on efficiency optimization. The framework enables systematic composition of multiple techniques, flexible policy-driven application, and iterative budgeted optimization through the Budgeted-KMR algorithm. We demonstrate how well-known efficiency methods can be instantiated as KMR triples and present concise algorithmic templates for each. The framework highlights underlying relationships between methods, facilitates hybrid pipelines, and lays the foundation for future research in automated policy learning, dynamic adaptation, and theoretical analysis of cost-quality trade-offs. Overall, KMR offers both a conceptual and practical tool for unifying and advancing model efficiency research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13998v1" target="_blank">Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation</a></h3>
                    <p><strong>Authors:</strong> Yifu Yuan, Haiqin Cui, Yaoting Huang, Yibin Chen, Fei Ni, Zibin Dong, Pengyi Li, Yan Zheng, Jianye Hao</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Generalization in embodied AI is hindered by the seeing-to-doing gap, which stems from data scarcity and embodiment heterogeneity. To address this, we pioneer pointing as a unified, embodiment-agnostic intermediate representation, defining four core embodied pointing abilities that bridge high-level vision-language comprehension with low-level action primitives. We introduce Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed for embodied reasoning and pointing. We use a wide range of embodied and general visual reasoning datasets as sources to construct a large-scale dataset, Embodied-Points-200K, which supports key embodied pointing capabilities. We then train Embodied-R1 using a two-stage Reinforced Fine-tuning (RFT) curriculum with a specialized multi-task reward design. Embodied-R1 achieves state-of-the-art performance on 11 embodied spatial and pointing benchmarks. Critically, it demonstrates robust zero-shot generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5% across 8 real-world XArm tasks without any task-specific fine-tuning, representing a 62% improvement over strong baselines. Furthermore, the model exhibits high robustness against diverse visual disturbances. Our work shows that a pointing-centric representation, combined with an RFT training paradigm, offers an effective and generalizable pathway to closing the perception-action gap in robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13992v1" target="_blank">MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence</a></h3>
                    <p><strong>Authors:</strong> Sonal Kumar, ≈†imon Sedl√°ƒçek, Vaibhavi Lokegaonkar, Fernando L√≥pez, Wenyi Yu, Nishit Anand, Hyeonggon Ryu, Lichang Chen, Maxim Pliƒçka, Miroslav Hlav√°ƒçek, William Fineas Ellingwood, Sathvik Udupa, Siyuan Hou, Allison Ferner, Sara Barahona, Cecilia Bola√±os, Satish Rahi, Laura Herrera-Alarc√≥n, Satvik Dixit, Siddhi Patil, Soham Deshmukh, Lasha Koroshinadze, Yao Liu, Leibny Paola Garcia Perera, Eleni Zanou, Themos Stafylakis, Joon Son Chung, David Harwath, Chao Zhang, Dinesh Manocha, Alicia Lozano-Diez, Santosh Kesiraju, Sreyan Ghosh, Ramani Duraiswami</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.AS, cs.SD</p>
                    <p><strong>Summary:</strong> Audio comprehension-including speech, non-speech sounds, and music-is essential for achieving human-level intelligence. Consequently, AI agents must demonstrate holistic audio understanding to qualify as generally intelligent. However, evaluating auditory intelligence comprehensively remains challenging. To address this gap, we introduce MMAU-Pro, the most comprehensive and rigorously curated benchmark for assessing audio intelligence in AI systems. MMAU-Pro contains 5,305 instances, where each instance has one or more audios paired with human expert-generated question-answer pairs, spanning speech, sound, music, and their combinations. Unlike existing benchmarks, MMAU-Pro evaluates auditory intelligence across 49 unique skills and multiple complex dimensions, including long-form audio comprehension, spatial audio reasoning, multi-audio understanding, among others. All questions are meticulously designed to require deliberate multi-hop reasoning, including both multiple-choice and open-ended response formats. Importantly, audio data is sourced directly ``from the wild rather than from existing datasets with known distributions. We evaluate 22 leading open-source and proprietary multimodal AI models, revealing significant limitations: even state-of-the-art models such as Gemini 2.5 Flash and Audio Flamingo 3 achieve only 59.2% and 51.7% accuracy, respectively, approaching random performance in multiple categories. Our extensive analysis highlights specific shortcomings and provides novel insights, offering actionable perspectives for the community to enhance future AI systems progression toward audio general intelligence. The benchmark and code is available at https://sonalkum.github.io/mmau-pro.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13989v1" target="_blank">Physics-Based 3D Simulation for Synthetic Data Generation and Failure Analysis in Packaging Stability Assessment</a></h3>
                    <p><strong>Authors:</strong> Samuel Seligardi, Pietro Musoni, Eleonora Iotti, Gianluca Contesso, Alessandro Dal Pal√π</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The design and analysis of pallet setups are essential for ensuring safety of packages transportation. With rising demands in the logistics sector, the development of automated systems utilizing advanced technologies has become increasingly crucial. Moreover, the widespread use of plastic wrapping has motivated researchers to investigate eco-friendly alternatives that still adhere to safety standards. We present a fully controllable and accurate physical simulation system capable of replicating the behavior of moving pallets. It features a 3D graphics-based virtual environment that supports a wide range of configurations, including variable package layouts, different wrapping materials, and diverse dynamic conditions. This innovative approach reduces the need for physical testing, cutting costs and environmental impact while improving measurement accuracy for analyzing pallet dynamics. Additionally, we train a deep neural network to evaluate the rendered videos generated by our simulator, as a crash-test predictor for pallet configurations, further enhancing the systems utility in safety analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13984v1" target="_blank">The AI-Fraud Diamond: A Novel Lens for Auditing Algorithmic Deception</a></h3>
                    <p><strong>Authors:</strong> Benjamin Zweers, Diptish Dey, Debarati Bhaumik</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> As artificial intelligence (AI) systems become increasingly integral to organizational processes, they introduce new forms of fraud that are often subtle, systemic, and concealed within technical complexity. This paper introduces the AI-Fraud Diamond, an extension of the traditional Fraud Triangle that adds technical opacity as a fourth condition alongside pressure, opportunity, and rationalization. Unlike traditional fraud, AI-enabled deception may not involve clear human intent but can arise from system-level features such as opaque model behavior, flawed training data, or unregulated deployment practices. The paper develops a taxonomy of AI-fraud across five categories: input data manipulation, model exploitation, algorithmic decision manipulation, synthetic misinformation, and ethics-based fraud. To assess the relevance and applicability of the AI-Fraud Diamond, the study draws on expert interviews with auditors from two of the Big Four consulting firms. The findings underscore the challenges auditors face when addressing fraud in opaque and automated environments, including limited technical expertise, insufficient cross-disciplinary collaboration, and constrained access to internal system processes. These conditions hinder fraud detection and reduce accountability. The paper argues for a shift in audit methodology-from outcome-based checks to a more diagnostic approach focused on identifying systemic vulnerabilities. Ultimately, the work lays a foundation for future empirical research and audit innovation in a rapidly evolving AI governance landscape.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13982v1" target="_blank">The Social Context of Human-Robot Interactions</a></h3>
                    <p><strong>Authors:</strong> Sydney Thompson, Kate Candon, Marynel V√°zquez</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.HC, cs.MA, I.2.9; I.2</p>
                    <p><strong>Summary:</strong> The Human-Robot Interaction (HRI) community often highlights the social context of an interaction as a key consideration when designing, implementing, and evaluating robot behavior. Unfortunately, researchers use the term social context in varied ways. This can lead to miscommunication, making it challenging to draw connections between related work on understanding and modeling the social contexts of human-robot interactions. To address this gap, we survey the HRI literature for existing definitions and uses of the term social context. Then, we propose a conceptual model for describing the social context of a human-robot interaction. We apply this model to existing work, and we discuss a range of attributes of social contexts that can help researchers plan for interactions, develop behavior models for robots, and gain insights after interactions have taken place. We conclude with a discussion of open research questions in relation to understanding and modeling the social contexts of human-robot interactions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13977v1" target="_blank">ROVR-Open-Dataset: A Large-Scale Depth Dataset for Autonomous Driving</a></h3>
                    <p><strong>Authors:</strong> Xianda Guo, Ruijun Zhang, Yiqun Duan, Ruilin Wang, Keyuan Zhou, Wenzhao Zheng, Wenke Huang, Gangwei Xu, Mike Horton, Yuan Si, Hao Zhao, Long Chen</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Depth estimation is a fundamental task for 3D scene understanding in autonomous driving, robotics, and augmented reality. Existing depth datasets, such as KITTI, nuScenes, and DDAD, have advanced the field but suffer from limitations in diversity and scalability. As benchmark performance on these datasets approaches saturation, there is an increasing need for a new generation of large-scale, diverse, and cost-efficient datasets to support the era of foundation models and multi-modal learning. To address these challenges, we introduce a large-scale, diverse, frame-wise continuous dataset for depth estimation in dynamic outdoor driving environments, comprising 20K video frames to evaluate existing methods. Our lightweight acquisition pipeline ensures broad scene coverage at low cost, while sparse yet statistically sufficient ground truth enables robust training. Compared to existing datasets, ours presents greater diversity in driving scenarios and lower depth density, creating new challenges for generalization. Benchmark experiments with standard monocular depth estimation models validate the datasets utility and highlight substantial performance gaps in challenging conditions, establishing a new platform for advancing depth estimation research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13976v1" target="_blank">Toward an Interaction-Centered Approach to Robot Trustworthiness</a></h3>
                    <p><strong>Authors:</strong> Carlo Mazzola, Hassan Ali, Krist√≠na Malinovsk√°, Igor Farka≈°</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> As robots get more integrated into human environments, fostering trustworthiness in embodied robotic agents becomes paramount for an effective and safe human-robot interaction (HRI). To achieve that, HRI applications must promote human trust that aligns with robot skills and avoid misplaced trust or overtrust, which can pose safety risks and ethical concerns. To achieve that, HRI applications must promote human trust that aligns with robot skills and avoid misplaced trust or overtrust, which can pose safety risks and ethical concerns. In this position paper, we outline an interaction-based framework for building trust through mutual understanding between humans and robots. We emphasize two main pillars: human awareness and transparency, referring to the robot ability to interpret human actions accurately and to clearly communicate its intentions and goals, respectively. By integrating these two pillars, robots can behave in a manner that aligns with human expectations and needs while providing their human partners with both comprehension and control over their actions. We also introduce four components that we think are important for bridging the gap between a human-perceived sense of trust and a robot true capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13975v1" target="_blank">ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation</a></h3>
                    <p><strong>Authors:</strong> Jingquan Wang, Andrew Negrut, Harry Zhang, Khailanii Slaton, Shu Wang, Radu Serban, Jinlong Wu, Dan Negrut</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This contribution is concerned with the following issue: can pretrained large language models (LLMs) be refined and customized to the point where they become virtual assistants helping experts with the effective use of a simulation tool? In this case study, the ``simulation tool considered is PyChrono, an open source multi-physics dynamics engine for multibody systems. We present a framework for refining and customizing both open- and closed-source LLMs to harness the power of AI in generating scripts that perform PyChrono virtual experiments. We refine and customize several classes of LLMs through a process that leads to a quantifiable improvement in the quality of the generated PyChrono simulation scripts. These scripts can range from simple single-pendulum simulations to complex virtual experiments involving full vehicles on deformable terrain. While the generated scripts are rarely perfect, they often serve as strong starting points for the user to modify and improve on. Additionally, the LLM can answer specific API questions about the simulator, or recommend modeling approaches. The framework discussed is general and can be applied to lower the entry barrier for simulation tools associated with other application domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13973v1" target="_blank">Roadblocks and Opportunities in Quantum Algorithms -- Insights from the National Quantum Initiative Joint Algorithms Workshop, May 20--22, 2024</a></h3>
                    <p><strong>Authors:</strong> Eliot Kapit, Peter Love, Jeffrey Larson, Andrew Sornborger, Eleanor Crane, Alexander Schuckert, Teague Tomesh, Frederic Chong, Sabre Kais</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> The National Quantum Initiative Joint Algorithms Workshop brought together researchers across academia, national laboratories, and industry to assess the current landscape of quantum algorithms and discuss roadblocks to progress. The workshop featured discussions on emerging algorithmic techniques, resource constraints in near-term hardware, and opportunities for co-design across software and systems. Presented here are seven topics from the workshop, each highlighting a critical challenge or promising opportunity discussed during the event. Together, they offer a snapshot of the fields evolving priorities and a shared vision for what is needed to advance quantum computational capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13964v1" target="_blank">Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation</a></h3>
                    <p><strong>Authors:</strong> Martijn Cramer, Yanming Wu, David De Schepper, Eric Demeester</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Due to high-mix-low-volume production, sheet-metal workshops today are challenged by small series and varying orders. As standard automation solutions tend to fall short, SMEs resort to repetitive manual labour impacting production costs and leading to tech-skilled workforces not being used to their full potential. The COOCK+ ROBUST project aims to transform cobots into mobile and reconfigurable production assistants by integrating existing technologies, including 3D object recognition and localisation. This article explores both the opportunities and challenges of enhancing cobotic systems with these technologies in an industrial setting, outlining the key steps involved in the process. Additionally, insights from a past project, carried out by the ACRO research unit in collaboration with an industrial partner, serves as a concrete implementation example throughout.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13962v1" target="_blank">Learning to Use AI for Learning: How Can We Effectively Teach and Measure Prompting Literacy for K-12 Students?</a></h3>
                    <p><strong>Authors:</strong> Ruiwei Xiao, Xinying Hou, Ying-Jui Tseng, Hsuan Nieu, Guanze Liao, John Stamper, Kenneth R. Koedinger</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> As Artificial Intelligence (AI) becomes increasingly integrated into daily life, there is a growing need to equip the next generation with the ability to apply, interact with, evaluate, and collaborate with AI systems responsibly. Prior research highlights the urgent demand from K-12 educators to teach students the ethical and effective use of AI for learning. To address this need, we designed an Large-Language Model (LLM)-based module to teach prompting literacy. This includes scenario-based deliberate practice activities with direct interaction with intelligent LLM agents, aiming to foster secondary school students responsible engagement with AI chatbots. We conducted two iterations of classroom deployment in 11 authentic secondary education classrooms, and evaluated 1) AI-based auto-graders capability; 2) students prompting performance and confidence changes towards using AI for learning; and 3) the quality of learning and assessment materials. Results indicated that the AI-based auto-grader could grade student-written prompts with satisfactory quality. In addition, the instructional materials supported students in improving their prompting skills through practice and led to positive shifts in their perceptions of using AI for learning. Furthermore, data from Study 1 informed assessment revisions in Study 2. Analyses of item difficulty and discrimination in Study 2 showed that True/False and open-ended questions could measure prompting literacy more effectively than multiple-choice questions for our target learners. These promising outcomes highlight the potential for broader deployment and highlight the need for broader studies to assess learning effectiveness and assessment design.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13960v1" target="_blank">A Mechanism for Mutual Fairness in Cooperative Games with Replicable Resources -- Extended Version</a></h3>
                    <p><strong>Authors:</strong> Bj√∂rn Filter, Ralf M√∂ller, √ñzg√ºr L√ºtf√º √ñz√ßep</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.GT, cs.AI</p>
                    <p><strong>Summary:</strong> The latest developments in AI focus on agentic systems where artificial and human agents cooperate to realize global goals. An example is collaborative learning, which aims to train a global model based on data from individual agents. A major challenge in designing such systems is to guarantee safety and alignment with human values, particularly a fair distribution of rewards upon achieving the global goal. Cooperative game theory offers useful abstractions of cooperating agents via value functions, which assign value to each coalition, and via reward functions. With these, the idea of fair allocation can be formalized by specifying fairness axioms and designing concrete mechanisms. Classical cooperative game theory, exemplified by the Shapley value, does not fully capture scenarios like collaborative learning, as it assumes nonreplicable resources, whereas data and models can be replicated. Infinite replicability requires a generalized notion of fairness, formalized through new axioms and mechanisms. These must address imbalances in reciprocal benefits among participants, which can lead to strategic exploitation and unfair allocations. The main contribution of this paper is a mechanism and a proof that it fulfills the property of mutual fairness, formalized by the Balanced Reciprocity Axiom. It ensures that, for every pair of players, each benefits equally from the participation of the other.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13957v1" target="_blank">ViT-FIQA: Assessing Face Image Quality using Vision Transformers</a></h3>
                    <p><strong>Authors:</strong> Andrea Atzori, Fadi Boutros, Naser Damer</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Face Image Quality Assessment (FIQA) aims to predict the utility of a face image for face recognition (FR) systems. State-of-the-art FIQA methods mainly rely on convolutional neural networks (CNNs), leaving the potential of Vision Transformer (ViT) architectures underexplored. This work proposes ViT-FIQA, a novel approach that extends standard ViT backbones, originally optimized for FR, through a learnable quality token designed to predict a scalar utility score for any given face image. The learnable quality token is concatenated with the standard image patch tokens, and the whole sequence is processed via global self-attention by the ViT encoders to aggregate contextual information across all patches. At the output of the backbone, ViT-FIQA branches into two heads: (1) the patch tokens are passed through a fully connected layer to learn discriminative face representations via a margin-penalty softmax loss, and (2) the quality token is fed into a regression head to learn to predict the face samples utility. Extensive experiments on challenging benchmarks and several FR models, including both CNN- and ViT-based architectures, demonstrate that ViT-FIQA consistently achieves top-tier performance. These results underscore the effectiveness of transformer-based architectures in modeling face image utility and highlight the potential of ViTs as a scalable foundation for future FIQA research https://cutt.ly/irHlzXUC.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13955v1" target="_blank">A first-principles theoretical study on two-dimensional MX and MX$_2$ metal halides: bandgap engineering, magnetism, and catalytic descriptors</a></h3>
                    <p><strong>Authors:</strong> Yu-Hsiu Lin, Daniel Maldonado-Lopez, Jose L. Mendoza-Cortes</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Metal halides, particularly MX and MX$_2$ compounds (where M represents metal elements and X = F, Cl, Br, I), have attracted significant interest due to their diverse electronic and optoelectronic properties. However, a comprehensive understanding of their structural and electronic behavior, particularly the evolution of these properties from bulk to low-dimensional forms, remains limited. To address this gap, we performed first-principles calculations to develop a database of 60 MX and MX$_2$ metal halides, detailing their structural and electronic properties in both bulk and slab configurations. Calculations were performed using the advanced \texttt{HSE06-D3} hybrid functional for density functional theory (DFT), ensuring high precision in predicting material properties despite the associated computational cost. The results reveal that these materials are predominantly semiconductors, but their bandgaps range from 0 to 9 eV. A detailed analysis of the transition from bulk to slab structures highlights notable shifts in electronic properties, including bandgap modifications. Upon dimensional reduction, 9 materials exhibit an indirect-to-direct bandgap transition, enhancing their potential for energy conversion. Beyond structural dimensionality, the influence of chemical composition on bandgap variations was also examined. To further assess their practical applicability, the catalytic and magnetic properties of these metal halides were systematically evaluated. These findings not only illuminate previously underexplored MX and MX$_2$ metal halides but also identify promising candidates for electronic, optoelectronic, catalytic and spintronic applications. This database serves as a valuable resource for guiding future research and technology development in low-dimensional materials.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13953v1" target="_blank">ReviewGraph: A Knowledge Graph Embedding Based Framework for Review Rating Prediction with Sentiment Features</a></h3>
                    <p><strong>Authors:</strong> A. J. W. de Vink, Natalia Amat-Lefort, Lifeng Han</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In the hospitality industry, understanding the factors that drive customer review ratings is critical for improving guest satisfaction and business performance. This work proposes ReviewGraph for Review Rating Prediction (RRP), a novel framework that transforms textual customer reviews into knowledge graphs by extracting (subject, predicate, object) triples and associating sentiment scores. Using graph embeddings (Node2Vec) and sentiment features, the framework predicts review rating scores through machine learning classifiers. We compare ReviewGraph performance with traditional NLP baselines (such as Bag of Words, TF-IDF, and Word2Vec) and large language models (LLMs), evaluating them in the HotelRec dataset. In comparison to the state of the art literature, our proposed model performs similar to their best performing model but with lower computational cost (without ensemble). While ReviewGraph achieves comparable predictive performance to LLMs and outperforms baselines on agreement-based metrics such as Cohens Kappa, it offers additional advantages in interpretability, visual exploration, and potential integration into Retrieval-Augmented Generation (RAG) systems. This work highlights the potential of graph-based representations for enhancing review analytics and lays the groundwork for future research integrating advanced graph neural networks and fine-tuned LLM-based extraction methods. We will share ReviewGraph output and platform open-sourced on our GitHub page https://github.com/aaronlifenghan/ReviewGraph</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13949v1" target="_blank">Query Logs Analytics: A Aystematic Literature Review</a></h3>
                    <p><strong>Authors:</strong> Dihia Lanasri</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.CL</p>
                    <p><strong>Summary:</strong> In the digital era, user interactions with various resources such as databases, data warehouses, websites, and knowledge graphs (KGs) are increasingly mediated through digital platforms. These interactions leave behind digital traces, systematically captured in the form of logs. Logs, when effectively exploited, provide high value across industry and academia, supporting critical services (e.g., recovery and security), user-centric applications (e.g., recommender systems), and quality-of-service improvements (e.g., performance optimization). Despite their importance, research on log usage remains fragmented across domains, and no comprehensive study currently consolidates existing efforts. This paper presents a systematic survey of log usage, focusing on Database (DB), Data Warehouse (DW), Web, and KG logs. More than 300 publications were analyzed to address three central questions: (1) do different types of logs share common structural and functional characteristics? (2) are there standard pipelines for their usage? (3) which constraints and non-functional requirements (NFRs) guide their exploitation?. The survey reveals a limited number of end-to-end approaches, the absence of standardization across log usage pipelines, and the existence of shared structural elements among different types of logs. By consolidating existing knowledge, identifying gaps, and highlighting opportunities, this survey provides researchers and practitioners with a comprehensive overview of log usage and sheds light on promising directions for future research, particularly regarding the exploitation and democratization of KG logs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13947v1" target="_blank">Real-Time, Population-Based Reconstruction of 3D Bone Models via Very-Low-Dose Protocols</a></h3>
                    <p><strong>Authors:</strong> Yiqun Lin, Haoran Sun, Yongqing Li, Rabia Aslam, Lung Fung Tse, Tiange Cheng, Chun Sing Chui, Wing Fung Yau, Victorine R. Le Meur, Meruyert Amangeldy, Kiho Cho, Yinyu Ye, James Zou, Wei Zhao, Xiaomeng Li</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Patient-specific bone models are essential for designing surgical guides and preoperative planning, as they enable the visualization of intricate anatomical structures. However, traditional CT-based approaches for creating bone models are limited to preoperative use due to the low flexibility and high radiation exposure of CT and time-consuming manual delineation. Here, we introduce Semi-Supervised Reconstruction with Knowledge Distillation (SSR-KD), a fast and accurate AI framework to reconstruct high-quality bone models from biplanar X-rays in 30 seconds, with an average error under 1.0 mm, eliminating the dependence on CT and manual work. Additionally, high tibial osteotomy simulation was performed by experts on reconstructed bone models, demonstrating that bone models reconstructed from biplanar X-rays have comparable clinical applicability to those annotated from CT. Overall, our approach accelerates the process, reduces radiation exposure, enables intraoperative guidance, and significantly improves the practicality of bone models, offering transformative applications in orthopedics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13942v1" target="_blank">The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management</a></h3>
                    <p><strong>Authors:</strong> Soumyadeep Dhar</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The rise of autonomous, AI-driven agents in economic settings raises critical questions about their emergent strategic behavior. This paper investigates these dynamics in the cooperative context of a multi-echelon supply chain, a system famously prone to instabilities like the bullwhip effect. We conduct computational experiments with generative AI agents, powered by Large Language Models (LLMs), within a controlled supply chain simulation designed to isolate their behavioral tendencies. Our central finding is the collaboration paradox: a novel, catastrophic failure mode where theoretically superior collaborative AI agents, designed with Vendor-Managed Inventory (VMI) principles, perform even worse than non-AI baselines. We demonstrate that this paradox arises from an operational flaw where agents hoard inventory, starving the system. We then show that resilience is only achieved through a synthesis of two distinct layers: high-level, AI-driven proactive policy-setting to establish robust operational targets, and a low-level, collaborative execution protocol with proactive downstream replenishment to maintain stability. Our final framework, which implements this synthesis, can autonomously generate, evaluate, and quantify a portfolio of viable strategic choices. The work provides a crucial insight into the emergent behaviors of collaborative AI agents and offers a blueprint for designing stable, effective AI-driven systems for business analytics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13939v1" target="_blank">Implementation of the Martini-Ericson-Chanfray-Marteau RPA-based (anti)neutrino cross-section model in the GENIE neutrino event generator</a></h3>
                    <p><strong>Authors:</strong> Lavinia Russo, Marco Martini, Stephen Dolan, Laura Munteanu, Boris Popov, Claudio Giganti</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> hep-ex, hep-ph</p>
                    <p><strong>Summary:</strong> We discuss the first implementation of the Martini-Ericson-Chanfray-Marteau RPA-based (anti)neutrino cross-section model for quasielastic (1p1h) and multinucleon (2p2h and 3p3h) excitations in the widely used GENIE neutrino event generator. Validation steps are presented, in particular, through direct comparisons of GENIE cross section output with original calculations performed by the authors of the model. Predictions for $^{12}$C, $^{16}$O and $^{40}$Ar are compared with some available T2K and MicroBooNE experimental measurements showing a reasonable agreement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13930v1" target="_blank">InPars+: Supercharging Synthetic Data Generation for Information Retrieval Systems</a></h3>
                    <p><strong>Authors:</strong> Matey Krastev, Miklos Hamar, Danilo Toapanta, Jesse Brouwers, Yibin Lei</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI</p>
                    <p><strong>Summary:</strong> This work revisits and extends synthetic query generation pipelines for Neural Information Retrieval (NIR) by leveraging the InPars Toolkit, a reproducible, end-to-end framework for generating training data using large language models (LLMs). We first assess the reproducibility of the original InPars, InPars-V2, and Promptagator pipelines on the SciFact benchmark and validate their effectiveness using open-source reranker and generator models. Building on this foundation, we introduce two key extensions to the pipeline: (1) fine-tuning a query generator LLM via Contrastive Preference Optimization (CPO) to improve the signal quality in generated queries, and (2) replacing static prompt templates with dynamic, Chain-of-Thought (CoT) optimized prompts using the DSPy framework. Our results show that both extensions reduce the need for aggressive filtering while improving retrieval performance. All code, models, and synthetic datasets are publicly released to support further research at: \href{https://github.com/danilotpnta/IR2-project}{this https URL}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13914v1" target="_blank">Development of a defacing algorithm to protect the privacy of head and neck cancer patients in publicly-accessible radiotherapy datasets</a></h3>
                    <p><strong>Authors:</strong> Kayla OSullivan-Steben, Luc Galarneau, John Kildea</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> physics.med-ph</p>
                    <p><strong>Summary:</strong> Introduction: The rise in public medical imaging datasets has raised concerns about patient reidentification from head CT scans. However, existing defacing algorithms often remove or distort Organs at Risk (OARs) and Planning Target Volumes (PTVs) in head and neck cancer (HNC) patients, and ignore DICOM-RT Structure Set and Dose data. Therefore, we developed and validated a novel automated defacing algorithm that preserves these critical structures while removing identifiable features from HNC CTs and DICOM-RT data. Methods: Eye contours were used as landmarks to automate the removal of CT pixels above the inferior-most eye slice and anterior to the eye midpoint. Pixels within PTVs were retained if they intersected with the removed region. The body contour and dose map were reshaped to reflect the defaced image. We validated our approach on 829 HNC CTs from 622 patients. Privacy protection was evaluated by applying the FaceNet512 facial recognition algorithm before and after defacing on 3D-rendered CT pairs from 70 patients. Research utility was assessed by examining the impact of defacing on autocontouring performance using LimbusAI and analyzing PTV locations relative to the defaced regions. Results: Before defacing, FaceNet512 matched 97% of patients CTs. After defacing, this rate dropped to 4%. LimbusAI effectively autocontoured organs in the defaced CTs, with perfect Dice scores of 1 for OARs below the defaced region, and excellent scores exceeding 0.95 for OARs on the same slices as the crop. We found that 86% of PTVs were entirely below the cropped region, 9.1% were on the same slice as the crop without overlap, and only 4.9% extended into the cropped area. Conclusions: We developed a novel defacing algorithm that anonymizes HNC CT scans and related DICOM-RT data while preserving essential structures, enabling the sharing of HNC imaging datasets for Big Data and AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13908v1" target="_blank">Translating the Force Concept Inventory in the age of AI</a></h3>
                    <p><strong>Authors:</strong> Marina Babayeva, Justin Dunlap, Marie Snƒõtinov√°, Ralf Widenhorn</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> We present a study that translates the Force Concept Inventory (FCI) using OpenAI GPT-4o and assess the specific difficulties of translating a scientific-focused topic using Large Language Models (LLMs). The FCI is a physics exam meant to evaluate outcomes of a student cohort before and after instruction in Newtonian physics. We examine the problem-solving ability of the LLM in both the translated document and the translation back into English, detailing the language-dependent issues that complicate the translation. While ChatGPT performs remarkably well on answering the questions in both the translated language as well as the back-translation into English, problems arise with language-specific nuances and formatting. Pitfalls include words or phrases that lack one-to-one matching terms in another language, especially discipline-specific scientific terms, or outright mistranslations. Depending on the context, these translations can result in a critical change in the physical meaning of the problem. Additionally, issues with question numbering and lettering are found in some languages. The issues around the translations of numbering and lettering provide insight into the abilities of the LLM and suggest that it is not simply relying upon FCI questions that may have been part of the LLM training data to provide answers. These findings underscore that while LLMs can accelerate multilingual access to educational tools, careful review is still needed to ensure fidelity and clarity in translated assessments. LLMs provide a new opportunity to expand educational tools and assessments. At the same time, there are unique challenges using LLMs to facilitate translations that this case study examines in detail.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13906v1" target="_blank">Qudit-based scalable quantum algorithm for solving the integer programming problem</a></h3>
                    <p><strong>Authors:</strong> Kapil Goswami, Peter Schmelcher, Rick Mukherjee</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> quant-ph, math.OC, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Integer programming (IP) is an NP-hard combinatorial optimization problem that is widely used to represent a diverse set of real-world problems spanning multiple fields, such as finance, engineering, logistics, and operations research. It is a hard problem to solve using classical algorithms, as its complexity increases exponentially with problem size. Most quantum algorithms for solving IP are highly resource inefficient because they encode integers into qubits. In [1], the issue of resource inefficiency was addressed by mapping integer variables to qudits. However, [1] has limited practical value due to a lack of scalability to multiple qudits to encode larger problems. In this work, by extending upon the ideas of [1], a circuit-based scalable quantum algorithm is presented using multiple interacting qudits for which we show a quantum speed-up. The quantum algorithm consists of a distillation function that efficiently separates the feasible from the infeasible regions, a phase-amplitude encoding for the cost function, and a quantum phase estimation coupled with a multi-controlled single-qubit rotation for optimization. We prove that the optimal solution has the maximum probability of being measured in our algorithm. The time complexity for the quantum algorithm is shown to be $O(d^{n/2} + m\cdot n^2\cdot \log{d} + n/\epsilon_{QPE})$ for a problem with the number of variables $n$ taking $d$ integer values, satisfying $m$ constraints with a precision of $\epsilon_{QPE}$. Compared to the classical time complexity of brute force $O(d^n)$ and the best classical exact algorithm $O((\log{n})^{3n})$, it incurs a reduction of $d^{n/2}$ in the time complexity in terms of $n$ for solving a general polynomial IP problem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13905v1" target="_blank">Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management</a></h3>
                    <p><strong>Authors:</strong> Tianheng Ling, Vipin Singh, Chao Qian, Felix Biessmann, Gregor Schiele</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Extreme weather events, intensified by climate change, increasingly challenge aging combined sewer systems, raising the risk of untreated wastewater overflow. Accurate forecasting of sewer overflow basin filling levels can provide actionable insights for early intervention, helping mitigating uncontrolled discharge. In recent years, AI-based forecasting methods have offered scalable alternatives to traditional physics-based models, but their reliance on cloud computing limits their reliability during communication outages. To address this, we propose an end-to-end forecasting framework that enables energy-efficient inference directly on edge devices. Our solution integrates lightweight Transformer and Long Short-Term Memory (LSTM) models, compressed via integer-only quantization for efficient on-device execution. Moreover, an automated hardware-aware deployment pipeline is used to search for optimal model configurations by jointly minimizing prediction error and energy consumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer data, the selected 8-bit Transformer model, trained on 24 hours of historical measurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ per inference. In contrast, the optimal 8-bit LSTM model requires significantly less energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE 0.0432) and much longer training time. This trade-off highlights the need to align model selection with deployment priorities, favoring LSTM for ultra-low energy consumption or Transformer for higher predictive accuracy. In general, our work enables local, energy-efficient forecasting, contributing to more resilient combined sewer systems. All code can be found in the GitHub Repository (https://github.com/tianheng-ling/EdgeOverflowForecast).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13901v1" target="_blank">Multimodal Data Storage and Retrieval for Embodied AI: A Survey</a></h3>
                    <p><strong>Authors:</strong> Yihao Lu, Hao Tang</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Embodied AI (EAI) agents continuously interact with the physical world, generating vast, heterogeneous multimodal data streams that traditional management systems are ill-equipped to handle. In this survey, we first systematically evaluate five storage architectures (Graph Databases, Multi-Model Databases, Data Lakes, Vector Databases, and Time-Series Databases), focusing on their suitability for addressing EAIs core requirements, including physical grounding, low-latency access, and dynamic scalability. We then analyze five retrieval paradigms (Fusion Strategy-Based Retrieval, Representation Alignment-Based Retrieval, Graph-Structure-Based Retrieval, Generation Model-Based Retrieval, and Efficient Retrieval-Based Optimization), revealing a fundamental tension between achieving long-term semantic coherence and maintaining real-time responsiveness. Based on this comprehensive analysis, we identify key bottlenecks, spanning from the foundational Physical Grounding Gap to systemic challenges in cross-modal integration, dynamic adaptation, and open-world generalization. Finally, we outline a forward-looking research agenda encompassing physics-aware data models, adaptive storage-retrieval co-optimization, and standardized benchmarking, to guide future research toward principled data management solutions for EAI. Our survey is based on a comprehensive review of more than 180 related studies, providing a rigorous roadmap for designing the robust, high-performance data management frameworks essential for the next generation of autonomous embodied systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13880v1" target="_blank">In-hoc Concept Representations to Regularise Deep Learning in Medical Imaging</a></h3>
                    <p><strong>Authors:</strong> Valentina Corbetta, Floris Six Dijkstra, Regina Beets-Tan, Hoel Kervadec, Kristoffer Wickstr√∏m, Wilson Silva</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep learning models in medical imaging often achieve strong in-distribution performance but struggle to generalise under distribution shifts, frequently relying on spurious correlations instead of clinically meaningful features. We introduce LCRReg, a novel regularisation approach that leverages Latent Concept Representations (LCRs) (e.g., Concept Activation Vectors (CAVs)) to guide models toward semantically grounded representations. LCRReg requires no concept labels in the main training set and instead uses a small auxiliary dataset to synthesise high-quality, disentangled concept examples. We extract LCRs for predefined relevant features, and incorporate a regularisation term that guides a Convolutional Neural Network (CNN) to activate within latent subspaces associated with those concepts. We evaluate LCRReg across synthetic and real-world medical tasks. On a controlled toy dataset, it significantly improves robustness to injected spurious correlations and remains effective even in multi-concept and multiclass settings. On the diabetic retinopathy binary classification task, LCRReg enhances performance under both synthetic spurious perturbations and out-of-distribution (OOD) generalisation. Compared to baselines, including multitask learning, linear probing, and post-hoc concept-based models, LCRReg offers a lightweight, architecture-agnostic strategy for improving model robustness without requiring dense concept supervision. Code is available at the following link: https://github.com/Trustworthy-AI-UU-NKI/lcr\_regularization</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13875v1" target="_blank">A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler</a></h3>
                    <p><strong>Authors:</strong> Wenxuan Zhang, Shuai Li, Xinyi Wang, Yu Sun, Hongyu Kang, Pui Yuk Chryste Wan, Yong-Ping Zheng, Sai-Kit Lam</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The Circle of Willis (CoW), vital for ensuring consistent blood flow to the brain, is closely linked to ischemic stroke. Accurate assessment of the CoW is important for identifying individuals at risk and guiding appropriate clinical management. Among existing imaging methods, Transcranial Color-coded Doppler (TCCD) offers unique advantages due to its radiation-free nature, affordability, and accessibility. However, reliable TCCD assessments depend heavily on operator expertise for identifying anatomical landmarks and performing accurate angle correction, which limits its widespread adoption. To address this challenge, we propose an AI-powered, real-time CoW auto-segmentation system capable of efficiently capturing cerebral arteries. No prior studies have explored AI-driven cerebrovascular segmentation using TCCD. In this work, we introduce a novel Attention-Augmented Wavelet YOLO (AAW-YOLO) network tailored for TCCD data, designed to provide real-time guidance for brain vessel segmentation in the CoW. We prospectively collected TCCD data comprising 738 annotated frames and 3,419 labeled artery instances to establish a high-quality dataset for model training and evaluation. The proposed AAW-YOLO demonstrated strong performance in segmenting both ipsilateral and contralateral CoW vessels, achieving an average Dice score of 0.901, IoU of 0.823, precision of 0.882, recall of 0.926, and mAP of 0.953, with a per-frame inference speed of 14.199 ms. This system offers a practical solution to reduce reliance on operator experience in TCCD-based cerebrovascular screening, with potential applications in routine clinical workflows and resource-constrained settings. Future research will explore bilateral modeling and larger-scale validation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13874v1" target="_blank">A Comprehensive Re-Evaluation of Biometric Modality Properties in the Modern Era</a></h3>
                    <p><strong>Authors:</strong> Rouqaiah Al-Refai, Pankaja Priya Ramasamy, Ragini Ramesh, Patricia Arias-Cabarcos, Philipp Terh√∂rst</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> The rapid advancement of authentication systems and their increasing reliance on biometrics for faster and more accurate user verification experience, highlight the critical need for a reliable framework to evaluate the suitability of biometric modalities for specific applications. Currently, the most widely known evaluation framework is a comparative table from 1998, which no longer adequately captures recent technological developments or emerging vulnerabilities in biometric systems. To address these challenges, this work revisits the evaluation of biometric modalities through an expert survey involving 24 biometric specialists. The findings indicate substantial shifts in property ratings across modalities. For example, face recognition, shows improved ratings due to technological progress, while fingerprint, shows decreased reliability because of emerging vulnerabilities and attacks. Further analysis of expert agreement levels across rated properties highlighted the consistency of the provided evaluations and ensured the reliability of the ratings. Finally, expert assessments are compared with dataset-level uncertainty across 55 biometric datasets, revealing strong alignment in most modalities and underscoring the importance of integrating empirical evidence with expert insight. Moreover, the identified expert disagreements reveal key open challenges and help guide future research toward resolving them.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13872v1" target="_blank">RED.AI Id-Pattern: First Results of Stone Deterioration Patterns with Multi-Agent Systems</a></h3>
                    <p><strong>Authors:</strong> Daniele Corradetti, Jos√© Delgado Rodrigues</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.MA, I.2.11; I.5.4</p>
                    <p><strong>Summary:</strong> The Id-Pattern system within the RED.AI project (Reabilita\c{c}\~ao Estrutural Digital atrav\es da AI) consists of an agentic system designed to assist in the identification of stone deterioration patterns. Traditional methodologies, based on direct observation by expert teams, are accurate but costly in terms of time and resources. The system developed here introduces and evaluates a multi-agent artificial intelligence (AI) system, designed to simulate collaboration between experts and automate the diagnosis of stone pathologies from visual evidence. The approach is based on a cognitive architecture that orchestrates a team of specialized AI agents which, in this specific case, are limited to five: a lithologist, a pathologist, an environmental expert, a conservator-restorer, and a diagnostic coordinator. To evaluate the system we selected 28 difficult images involving multiple deterioration patterns. Our first results showed a huge boost on all metrics of our system compared to the foundational model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13870v1" target="_blank">Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate</a></h3>
                    <p><strong>Authors:</strong> Jiazheng Jing, Yinan Zhang, Chunyan Miao</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> The recent emergence of extreme climate events has significantly raised awareness about sustainable living. In addition to developing energy-saving materials and technologies, existing research mainly relies on traditional methods that encourage behavioral shifts towards sustainability, which can be overly demanding or only passively engaging. In this work, we propose to employ recommendation systems to actively nudge users toward more sustainable choices. We introduce Green Recommender Aligned with Personalized Eating (GRAPE), which is designed to prioritize and recommend sustainable food options that align with users evolving preferences. We also design two innovative Green Loss functions that cater to green indicators with either uniform or differentiated priorities, thereby enhancing adaptability across a range of scenarios. Extensive experiments on a real-world dataset demonstrate the effectiveness of our GRAPE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13867v1" target="_blank">OpenLB-UQ: An Uncertainty Quantification Framework for Incompressible Fluid Flow Simulations</a></h3>
                    <p><strong>Authors:</strong> Mingliang Zhong, Adrian Kummerl√§nder, Shota Ito, Mathias J. Krause, Martin Frank, Stephan Simonis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, cs.MS, cs.NA, math.NA, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Uncertainty quantification (UQ) is crucial in computational fluid dynamics to assess the reliability and robustness of simulations, given the uncertainties in input parameters. OpenLB is an open-source lattice Boltzmann method library designed for efficient and extensible simulations of complex fluid dynamics on high-performance computers. In this work, we leverage the efficiency of OpenLB for large-scale flow sampling with a dedicated and integrated UQ module. To this end, we focus on non-intrusive stochastic collocation methods based on generalized polynomial chaos and Monte Carlo sampling. The OpenLB-UQ framework is extensively validated in convergence tests with respect to statistical metrics and sample efficiency using selected benchmark cases, including two-dimensional Taylor--Green vortex flows with up to four-dimensional uncertainty and a flow past a cylinder. Our results confirm the expected convergence rates and show promising scalability, demonstrating robust statistical accuracy as well as computational efficiency. OpenLB-UQ enhances the capability of the OpenLB library, offering researchers a scalable framework for UQ in incompressible fluid flow simulations and beyond.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13848v1" target="_blank">Add-On Regimes and Their Relevance for Quantifying the Effects of Opioid-Sparing Treatments</a></h3>
                    <p><strong>Authors:</strong> Catharina Stoltenberg, Matias Janvin, Mats Julius Stensrud, Leiv Arne Rosseland, Jon Michael Gran</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> stat.AP</p>
                    <p><strong>Summary:</strong> Medical researchers and practitioners want to know if supplementing opioid treatments with other analgesics, such as nonsteroidal anti-inflammatory drugs (NSAIDs), can reduce opioid consumption. However, quantifying opioid-sparing effects is challenging; even coming up with a policy-relevant estimand requires care. We propose defining these effects in terms of add-on regimes. An add-on regime assigns NSAIDs over time based on the opioid and NSAID treatments a patient would naturally take without any intervention. The regime uses the physicians decision to administer opioids as a clinically meaningful, and practically feasible, indication for NSAID administration. In contrast, static regimes assign NSAIDs at predefined time points, regardless of clinical context. When opioids are not administered, the add-on regime requires no intervention, thereby preserving the natural level of NSAIDs. This differs from conventional dynamic regimes, which define treatment decisions at every time point during the treatment period. We identify the effect of add-on regimes under assumptions that are easier to assess than those used in existing methods. Finally, we apply the methods to estimate opioid-sparing effects of NSAIDs in a cohort of Norwegian trauma patients using national registry data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13837v1" target="_blank">Exit Stories: Using Reddit Self-Disclosures to Understand Disengagement from Problematic Communities</a></h3>
                    <p><strong>Authors:</strong> Shruti Phadke</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.HC, cs.SI</p>
                    <p><strong>Summary:</strong> Online platforms like Reddit are increasingly becoming popular for individuals sharing personal experiences of leaving behind social, ideological, and political groups. Specifically, a series of ex- subreddits on Reddit allow users to recount their departures from commitments such as religious affiliations, manosphere communities, conspiracy theories or political beliefs, and lifestyle choices. Understanding the natural process through which users exit, especially from problematic groups such as conspiracy theory communities and the manosphere, can provide valuable insights for designing interventions targeting disengagement from harmful ideologies. This paper presents an in-depth exploration of 15K exit stories across 131 subreddits, focusing on five key areas: religion, manosphere, conspiracy theories, politics, and lifestyle. Using a transdisciplinary framework that incorporates theories from social psychology, organizational behavior, and violent extremism studies, this work identifies a range of factors contributing to disengagement. The results describe how disengagement from problematic groups, such as conspiracy theories and the manosphere, is a multi-faceted process that is qualitatively different than disengaging from more established social structures, such as religions or political ideologies. This research further highlights the need for moving beyond interventions that treat conspiracy theorizing solely as an information problem and contributes insights for future research focusing on offering mental health interventions and support in exit communities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13831v1" target="_blank">Smooth Flow Matching</a></h3>
                    <p><strong>Authors:</strong> Jianbin Tan, Anru R. Zhang</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Functional data, i.e., smooth random functions observed over a continuous domain, are increasingly available in areas such as biomedical research, health informatics, and epidemiology. However, effective statistical analysis for functional data is often hindered by challenges such as privacy constraints, sparse and irregular sampling, infinite dimensionality, and non-Gaussian structures. To address these challenges, we introduce a novel framework named Smooth Flow Matching (SFM), tailored for generative modeling of functional data to enable statistical analysis without exposing sensitive real data. Built upon flow-matching ideas, SFM constructs a semiparametric copula flow to generate infinite-dimensional functional data, free from Gaussianity or low-rank assumptions. It is computationally efficient, handles irregular observations, and guarantees the smoothness of the generated functions, offering a practical and flexible solution in scenarios where existing deep generative methods are not applicable. Through extensive simulation studies, we demonstrate the advantages of SFM in terms of both synthetic data quality and computational efficiency. We then apply SFM to generate clinical trajectory data from the MIMIC-IV patient electronic health records (EHR) longitudinal database. Our analysis showcases the ability of SFM to produce high-quality surrogate data for downstream statistical tasks, highlighting its potential to boost the utility of EHR data for clinical applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13830v1" target="_blank">Finding subdigraphs in digraphs of bounded directed treewidth</a></h3>
                    <p><strong>Authors:</strong> Raul Lopes, Ignasi Sau</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.DS, math.CO</p>
                    <p><strong>Summary:</strong> It is well known that directed treewidth does not enjoy the nice algorithmic properties of its undirected counterpart. There exist, however, some positive results that, essentially, present XP algorithms for the problem of finding, in a given digraph $D$, a subdigraph isomorphic to a digraph $H$ that can be formed by the union of $k$ directed paths (with some extra properties), parameterized by $k$ and the directed treewidth of $D$. Our motivation is to tackle the following question: Are there subdigraphs, other than the directed paths, that can be found efficiently in digraphs of bounded directed treewidth? In a nutshell, the main message of this article is that, other than the directed paths, the only digraphs that seem to behave well with respect to directed treewidth are the stars. For this, we present a number of positive and negative results, generalizing several results in the literature, as well as some directions for further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13828v1" target="_blank">Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration</a></h3>
                    <p><strong>Authors:</strong> Yifei Chen, Guanting Dong, Yutao Zhu, Zhicheng Dou</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Retrieval-Augmented Generation (RAG) technology has been widely applied in recent years. However, despite the emergence of various RAG frameworks, a single RAG framework still cannot adapt well to a broad range of downstream tasks. Therefore, how to leverage the advantages of multiple RAG systems has become an area worth exploring. To address this issue, we have conducted a comprehensive and systematic investigation into ensemble methods based on RAG systems. Specifically, we have analyzed the RAG ensemble framework from both theoretical and mechanistic analysis perspectives. From the theoretical analysis, we provide the first explanation of the RAG ensemble framework from the perspective of information entropy. In terms of mechanism analysis, we have explored the RAG ensemble framework from both the pipeline and module levels. We carefully select four different pipelines (Branching, Iterative, Loop, and Agentic) and three different modules (Generator, Retriever, and Reranker) to solve seven different research questions. The experiments show that aggregating multiple RAG systems is both generalizable and robust, whether at the pipeline level or the module level. Our work lays the foundation for similar research on the multi-RAG system ensemble.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13825v1" target="_blank">Energy Management and Wake-up for IoT Networks Powered by Energy Harvesting</a></h3>
                    <p><strong>Authors:</strong> David Ernesto Ruiz-Guirola, Samuel Montejo-Sanchez, Israel Leyva-Mayorga, Zhu Han, Petar Popovski, Onel L. A. Lopez</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> The rapid growth of the Internet of Things (IoT) presents sustainability challenges such as increased maintenance requirements and overall higher energy consumption. This motivates self-sustainable IoT ecosystems based on Energy Harvesting (EH). This paper treats IoT deployments in which IoT devices (IoTDs) rely solely on EH to sense and transmit information about events/alarms to a base station (BS). The objective is to effectively manage the duty cycling of the IoTDs to prolong battery life and maximize the relevant data sent to the BS. The BS can also wake up specific IoTDs if extra information about an event is needed upon initial detection. We propose a K-nearest neighbors (KNN)-based duty cycling management to optimize energy efficiency and detection accuracy by considering spatial correlations among IoTDs activity and their EH process. We evaluate machine learning approaches, including reinforcement learning (RL) and decision transformers (DT), to maximize information captured from events while managing energy consumption. Significant improvements over the state-ofthe-art approaches are obtained in terms of energy saving by all three proposals, KNN, RL, and DT. Moreover, the RL-based solution approaches the performance of a genie-aided benchmark as the number of IoTDs increases.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13823v1" target="_blank">Self-Aware Adaptive Alignment: Enabling Accurate Perception for Intelligent Transportation Systems</a></h3>
                    <p><strong>Authors:</strong> Tong Xiang, Hongxia Zhao, Fenghua Zhu, Yuanyuan Chen, Yisheng Lv</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Achieving top-notch performance in Intelligent Transportation detection is a critical research area. However, many challenges still need to be addressed when it comes to detecting in a cross-domain scenario. In this paper, we propose a Self-Aware Adaptive Alignment (SA3), by leveraging an efficient alignment mechanism and recognition strategy. Our proposed method employs a specified attention-based alignment module trained on source and target domain datasets to guide the image-level features alignment process, enabling the local-global adaptive alignment between the source domain and target domain. Features from both domains, whose channel importance is re-weighted, are fed into the region proposal network, which facilitates the acquisition of salient region features. Also, we introduce an instance-to-image level alignment module specific to the target domain to adaptively mitigate the domain gap. To evaluate the proposed method, extensive experiments have been conducted on popular cross-domain object detection benchmarks. Experimental results show that SA3 achieves superior results to the previous state-of-the-art methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13822v1" target="_blank">Improving Deep Learning for Accelerated MRI With Data Filtering</a></h3>
                    <p><strong>Authors:</strong> Kang Lin, Anselm Krainovic, Kun Wang, Reinhard Heckel</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV</p>
                    <p><strong>Summary:</strong> Deep neural networks achieve state-of-the-art results for accelerated MRI reconstruction. Most research on deep learning based imaging focuses on improving neural network architectures trained and evaluated on fixed and homogeneous training and evaluation data. In this work, we investigate data curation strategies for improving MRI reconstruction. We assemble a large dataset of raw k-space data from 18 public sources consisting of 1.1M images and construct a diverse evaluation set comprising 48 test sets, capturing variations in anatomy, contrast, number of coils, and other key factors. We propose and study different data filtering strategies to enhance performance of current state-of-the-art neural networks for accelerated MRI reconstruction. Our experiments show that filtering the training data leads to consistent, albeit modest, performance gains. These performance gains are robust across different training set sizes and accelerations, and we find that filtering is particularly beneficial when the proportion of in-distribution data in the unfiltered training set is low.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13816v1" target="_blank">The illusion of a perfect metric: Why evaluating AIs words is harder than it looks</a></h3>
                    <p><strong>Authors:</strong> Maria Paz Oliva, Adriana Correia, Ivan Vankov, Viktor Botev</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Evaluating Natural Language Generation (NLG) is crucial for the practical adoption of AI, but has been a longstanding research challenge. While human evaluation is considered the de-facto standard, it is expensive and lacks scalability. Practical applications have driven the development of various automatic evaluation metrics (AEM), designed to compare the model output with human-written references, generating a score which approximates human judgment. Over time, AEMs have evolved from simple lexical comparisons, to semantic similarity models and, more recently, to LLM-based evaluators. However, it seems that no single metric has emerged as a definitive solution, resulting in studies using different ones without fully considering the implications. This paper aims to show this by conducting a thorough examination of the methodologies of existing metrics, their documented strengths and limitations, validation methods, and correlations with human judgment. We identify several key challenges: metrics often capture only specific aspects of text quality, their effectiveness varies by task and dataset, validation practices remain unstructured, and correlations with human judgment are inconsistent. Importantly, we find that these challenges persist in the most recent type of metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented Generation (RAG), an increasingly relevant task in academia and industry. Our findings challenge the quest for the perfect metric. We propose selecting metrics based on task-specific needs and leveraging complementary evaluations and advocate that new metrics should focus on enhanced validation methodologies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13814v1" target="_blank">Unsupervised Urban Tree Biodiversity Mapping from Street-Level Imagery Using Spatially-Aware Visual Clustering</a></h3>
                    <p><strong>Authors:</strong> Diaa Addeen Abuhani, Marco Seccaroni, Martina Mazzarello, Imran Zualkernan, Fabio Duarte, Carlo Ratti</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Urban tree biodiversity is critical for climate resilience, ecological stability, and livability in cities, yet most municipalities lack detailed knowledge of their canopies. Field-based inventories provide reliable estimates of Shannon and Simpson diversity but are costly and time-consuming, while supervised AI methods require labeled data that often fail to generalize across regions. We introduce an unsupervised clustering framework that integrates visual embeddings from street-level imagery with spatial planting patterns to estimate biodiversity without labels. Applied to eight North American cities, the method recovers genus-level diversity patterns with high fidelity, achieving low Wasserstein distances to ground truth for Shannon and Simpson indices and preserving spatial autocorrelation. This scalable, fine-grained approach enables biodiversity mapping in cities lacking detailed inventories and offers a pathway for continuous, low-cost monitoring to support equitable access to greenery and adaptive management of urban ecosystems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13813v1" target="_blank">Assessing Trustworthiness of AI Training Dataset using Subjective Logic -- A Use Case on Bias</a></h3>
                    <p><strong>Authors:</strong> Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos, Frank Kargl</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> As AI systems increasingly rely on training data, assessing dataset trustworthiness has become critical, particularly for properties like fairness or bias that emerge at the dataset level. Prior work has used Subjective Logic to assess trustworthiness of individual data, but not to evaluate trustworthiness properties that emerge only at the level of the dataset as a whole. This paper introduces the first formal framework for assessing the trustworthiness of AI training datasets, enabling uncertainty-aware evaluations of global properties such as bias. Built on Subjective Logic, our approach supports trust propositions and quantifies uncertainty in scenarios where evidence is incomplete, distributed, and/or conflicting. We instantiate this framework on the trustworthiness property of bias, and we experimentally evaluate it based on a traffic sign recognition dataset. The results demonstrate that our method captures class imbalance and remains interpretable and robust in both centralized and federated contexts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14039v1" target="_blank">Beyond Simple Edits: Composed Video Retrieval with Dense Modifications</a></h3>
                    <p><strong>Authors:</strong> Omkar Thawakar, Dmitry Demidov, Ritesh Thawkar, Rao Muhammad Anwer, Mubarak Shah, Fahad Shahbaz Khan, Salman Khan</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Composed video retrieval is a challenging task that strives to retrieve a target video based on a query video and a textual description detailing specific modifications. Standard retrieval frameworks typically struggle to handle the complexity of fine-grained compositional queries and variations in temporal understanding limiting their retrieval ability in the fine-grained setting. To address this issue, we introduce a novel dataset that captures both fine-grained and composed actions across diverse video segments, enabling more detailed compositional changes in retrieved video content. The proposed dataset, named Dense-WebVid-CoVR, consists of 1.6 million samples with dense modification text that is around seven times more than its existing counterpart. We further develop a new model that integrates visual and textual information through Cross-Attention (CA) fusion using grounded text encoder, enabling precise alignment between dense query modifications and target videos. The proposed model achieves state-of-the-art results surpassing existing methods on all metrics. Notably, it achieves 71.3\% Recall@1 in visual+text setting and outperforms the state-of-the-art by 3.4\%, highlighting its efficacy in terms of leveraging detailed video descriptions and dense modification texts. Our proposed dataset, code, and model are available at :https://github.com/OmkarThawakar/BSE-CoVR</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14032v1" target="_blank">The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities</a></h3>
                    <p><strong>Authors:</strong> Xiancheng Li, Georgios D. Karampatakis, Helen E. Wood, Chris J. Griffiths, Borislava Mihaylova, Neil S. Coulson, Alessio Pasinato, Pietro Panzarasa, Marco Viviani, Anna De Simoni</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Digital health analytics face critical challenges nowadays. The sophisticated analysis of patient-generated health content, which contains complex emotional and medical contexts, requires scarce domain expertise, while traditional ML approaches are constrained by data shortage and privacy limitations in healthcare settings. Online Health Communities (OHCs) exemplify these challenges with mixed-sentiment posts, clinical terminology, and implicit emotional expressions that demand specialised knowledge for accurate Sentiment Analysis (SA). To address these challenges, this study explores how Large Language Models (LLMs) can integrate expert knowledge through in-context learning for SA, providing a scalable solution for sophisticated health data analysis. Specifically, we develop a structured codebook that systematically encodes expert interpretation guidelines, enabling LLMs to apply domain-specific knowledge through targeted prompting rather than extensive training. Six GPT models validated alongside DeepSeek and LLaMA 3.1 are compared with pre-trained language models (BioBERT variants) and lexicon-based methods, using 400 expert-annotated posts from two OHCs. LLMs achieve superior performance while demonstrating expert-level agreement. This high agreement, with no statistically significant difference from inter-expert agreement levels, suggests knowledge integration beyond surface-level pattern recognition. The consistent performance across diverse LLM models, supported by in-context learning, offers a promising solution for digital health analytics. This approach addresses the critical challenge of expert knowledge shortage in digital health research, enabling real-time, expert-quality analysis for patient monitoring, intervention assessment, and evidence-based health strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14031v1" target="_blank">Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation</a></h3>
                    <p><strong>Authors:</strong> Dongyoon Hahm, Taywon Min, Woogyeol Jin, Kimin Lee</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Beyond simple text generation, Large Language Models (LLMs) have evolved into agentic systems capable of planning and interacting with external tools to solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific tasks to enhance their proficiency. However, safety concerns are frequently overlooked during this fine-tuning process. In this work, we show that aligned LLMs can become unintentionally misaligned, leading to a higher likelihood of executing harmful tasks and a reduced tendency to refuse them when fine-tuned to execute agentic tasks. To address these safety challenges, we propose Prefix INjection Guard (PING), a simple yet effective method that prepends automatically generated natural language prefixes to agent responses, guiding them to refuse harmful requests while preserving performance on benign tasks. Specifically, we introduce an iterative approach that alternates between (1) generating candidate prefixes and (2) selecting those that optimize both task performance and refusal behavior. Experimental results demonstrate that PING significantly enhances the safety of fine-tuned LLM agents without sacrificing their effectiveness. PING consistently outperforms existing prompting approaches across diverse benchmarks in both web navigation and code generation tasks. Our analysis of internal hidden states via linear probes reveals that prefix tokens are crucial for behavior modification, explaining the performance gains. WARNING: This paper contains contents that are unethical or offensive in nature.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14028v1" target="_blank">Trust and Reputation in Data Sharing: A Survey</a></h3>
                    <p><strong>Authors:</strong> Wenbo Wu, George Konstantinidis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.SI, cs.CY, cs.IR</p>
                    <p><strong>Summary:</strong> Data sharing is the fuel of the galloping artificial intelligence economy, providing diverse datasets for training robust models. Trust between data providers and data consumers is widely considered one of the most important factors for enabling data sharing initiatives. Concerns about data sensitivity, privacy breaches, and misuse contribute to reluctance in sharing data across various domains. In recent years, there has been a rise in technological and algorithmic solutions to measure, capture and manage trust, trustworthiness, and reputation in what we collectively refer to as Trust and Reputation Management Systems (TRMSs). Such approaches have been developed and applied to different domains of computer science, such as autonomous vehicles, or IoT networks, but there have not been dedicated approaches to data sharing and its unique characteristics. In this survey, we examine TRMSs from a data-sharing perspective, analyzing how they assess the trustworthiness of both data and entities across different environments. We develop novel taxonomies for system designs, trust evaluation framework, and evaluation metrics for both data and entity, and we systematically analyze the applicability of existing TRMSs in data sharing. Finally, we identify open challenges and propose future research directions to enhance the explainability, comprehensiveness, and accuracy of TRMSs in large-scale data-sharing ecosystems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14024v1" target="_blank">UNICON: UNIfied CONtinual Learning for Medical Foundational Models</a></h3>
                    <p><strong>Authors:</strong> Mohammad Areeb Qazi, Munachiso S Nwadike, Ibrahim Almakky, Mohammad Yaqub, Numan Saeed</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Foundational models are trained on extensive datasets to capture the general trends of a domain. However, in medical imaging, the scarcity of data makes pre-training for every domain, modality, or task challenging. Continual learning offers a solution by fine-tuning a model sequentially on different domains or tasks, enabling it to integrate new knowledge without requiring large datasets for each training phase. In this paper, we propose UNIfied CONtinual Learning for Medical Foundational Models (UNICON), a framework that enables the seamless adaptation of foundation models to diverse domains, tasks, and modalities. Unlike conventional adaptation methods that treat these changes in isolation, UNICON provides a unified, perpetually expandable framework. Through careful integration, we show that foundation models can dynamically expand across imaging modalities, anatomical regions, and clinical objectives without catastrophic forgetting or task interference. Empirically, we validate our approach by adapting a chest CT foundation model initially trained for classification to a prognosis and segmentation task. Our results show improved performance across both additional tasks. Furthermore, we continually incorporated PET scans and achieved a 5\% improvement in Dice score compared to respective baselines. These findings establish that foundation models are not inherently constrained to their initial training scope but can evolve, paving the way toward generalist AI models for medical imaging.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14019v1" target="_blank">Cosmology from a joint analysis of second and third order shear statistics with Subaru Hyper Suprime-Cam Year 3 data</a></h3>
                    <p><strong>Authors:</strong> Sunao Sugiyama, Rafael C. H. Gomes, Bhuvnesh Jain</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> We present a joint cosmological analysis of the two-point correlation function and the aperture-mass skewness measured from the Year 3 data of the Hyper Suprime-Cam Subaru Strategic Program (HSC-Y3). The aperture-mass skewness is a compressed representation of three-point shear information, designed to capture non-Gaussian features while keeping the data vector computationally tractable. We find that including the aperture-mass skewness improves the $S_8$-$\Omega_m$ figure of merit by 80% compared to the 2PCF-only case, primarily due to the breaking of degeneracies. Our joint analysis yields a constraint of $S_8=0.736\pm0.020$, which is slightly lower than the two-point-only result and increases the tension with Planck 2018 to 3.2$\sigma$ in the $S_8$-$\Omega_m$ plane. The two- and three-point statistics are found to be internally consistent across redshift bins and angular scales, and we detect no significant intrinsic alignment signal. We also explore extensions to the $w$CDM model and find no evidence for deviations from a cosmological constant. This work demonstrates the feasibility and scientific value of incorporating third-order shear statistics into weak lensing cosmology and provides a practical pathway for similar analyses in future Stage-IV surveys such as LSST, Euclid, and Roman.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14015v1" target="_blank">Backdooring Self-Supervised Contrastive Learning by Noisy Alignment</a></h3>
                    <p><strong>Authors:</strong> Tuo Chen, Jie Gui, Minjing Dong, Ju Jia, Lanting Fang, Jian Liu</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Self-supervised contrastive learning (CL) effectively learns transferable representations from unlabeled data containing images or image-text pairs but suffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary can inject poisoned images into pretraining datasets, causing compromised CL encoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs, however, achieve limited efficacy due to their dependence on fragile implicit co-occurrence between backdoor and target object and inadequate suppression of discriminative features in backdoored images. We propose Noisy Alignment (NA), a DPCL method that explicitly suppresses noise components in poisoned images. Inspired by powerful training-controllable CL attacks, we identify and extract the critical objective of noisy alignment, adapting it effectively into data-poisoning scenarios. Our method implements noisy alignment by strategically manipulating contrastive learnings random cropping mechanism, formulating this process as an image layout optimization problem with theoretically derived optimal parameters. The resulting method is simple yet effective, achieving state-of-the-art performance compared to existing DPCLs, while maintaining clean-data accuracy. Furthermore, Noisy Alignment demonstrates robustness against common backdoor defenses. Codes can be found at https://github.com/jsrdcht/Noisy-Alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14009v1" target="_blank">Understanding Pedagogical Content Knowledge of Data Science Instructors: An Inaugural Framework</a></h3>
                    <p><strong>Authors:</strong> Sinem Demirci, Mine Doƒüucu, Andrew Zieffler, Joshua M. Rosenberg</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> stat.OT</p>
                    <p><strong>Summary:</strong> As data science emerges as a distinct academic discipline, introductory data science (IDS) courses have also drawn attention to their role in providing foundational knowledge of data science to students. IDS courses not only help students transition to higher education but also expose students to the field, often for the first time. They are often taught by instructors without formal training in data science or pedagogy, creating a unique context for examining their pedagogical content knowledge (PCK). This study explores IDS instructors PCK, particularly how instructors varied backgrounds interact with their instructional practices. Employing empirical phenomenological methodology, we conducted semi-structured interviews to understand the nature of their PCK. Comparing instructors PCK was inherently challenging due to their diverse backgrounds and teaching contexts. Prior experiences played a central role in shaping participants instructional choices. Their perceptions regarding the goals and rationale for teaching data science reflected three distinct orientations. Instructors also acknowledged students entering IDS courses often brought preconceived notions that shaped their learning experiences. Despite the absence of national guidelines, participants demonstrated notable overlap in foundational IDS content, though some instructors felt less confident with advanced or specialized topics. Additionally, instructors commonly employed formative and summative assessment approaches, though few explicitly labeled their practices using these terms. The findings highlight key components of PCK in IDS and offer insights into supporting instructor development through targeted training and curriculum design. This work contributes to ongoing efforts to build capacity in data science education and expand the scope of PCK research into new interdisciplinary domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14008v1" target="_blank">Typed Topological Structures Of Datasets</a></h3>
                    <p><strong>Authors:</strong> Wanjun Hu</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG, math.GN, G.0; F.m</p>
                    <p><strong>Summary:</strong> A datatset $X$ on $R^2$ is a finite topological space. Current research of a dataset focuses on statistical methods and the algebraic topological method \cite{carlsson}. In \cite{hu}, the concept of typed topological space was introduced and showed to have the potential for studying finite topological spaces, such as a dataset. It is a new method from the general topology perspective. A typed topological space is a topological space whose open sets are assigned types. Topological concepts and methods can be redefined using open sets of certain types. In this article, we develop a special set of types and its related typed topology on a dataset $X$. Using it, we can investigate the inner structure of $X$. In particular, $R^2$ has a natural quotient space, in which $X$ is organized into tracks, and each track is split into components. Those components are in a order. Further, they can be represented by an integer sequence. Components crossing tracks form branches, and the relationship can be well represented by a type of pseudotree (called typed-II pseudotree). Such structures provide a platform for new algorithms for problems such as calculating convex hull, holes, clustering and anomaly detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14006v1" target="_blank">ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans</a></h3>
                    <p><strong>Authors:</strong> Mohamed Abouagour, Eleftherios Garyfallidis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO, 68T45</p>
                    <p><strong>Summary:</strong> We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally rich, and realistic residential floor plans, created to advance spatial AI research. Each plan includes precise annotations of architectural elements (walls, doors, windows, balconies) and functional spaces (such as kitchens, bedrooms, and bathrooms). ResPlan addresses key limitations of existing datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024) by offering enhanced visual fidelity and greater structural diversity, reflecting realistic and non-idealized residential layouts. Designed as a versatile, general-purpose resource, ResPlan supports a wide range of applications including robotics, reinforcement learning, generative AI, virtual and augmented reality, simulations, and game development. Plans are provided in both geometric and graph-based formats, enabling direct integration into simulation engines and fast 3D conversion. A key contribution is an open-source pipeline for geometry cleaning, alignment, and annotation refinement. Additionally, ResPlan includes structured representations of room connectivity, supporting graph-based spatial reasoning tasks. Finally, we present comparative analyses with existing benchmarks and outline several open benchmark tasks enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale, realism, and usability, providing a robust foundation for developing and benchmarking next-generation spatial intelligence systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14000v1" target="_blank">Formal Algorithms for Model Efficiency</a></h3>
                    <p><strong>Authors:</strong> Naman Tyagi, Srishti Das, Kunal, Vatsal Gupta</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> We introduce the Knob-Meter-Rule (KMR) framework, a unified formalism for representing and reasoning about model efficiency techniques in deep learning. By abstracting diverse methods, including pruning, quantization, knowledge distillation, and parameter-efficient architectures, into a consistent set of controllable knobs, deterministic rules, and measurable meters, KMR provides a mathematically precise and modular perspective on efficiency optimization. The framework enables systematic composition of multiple techniques, flexible policy-driven application, and iterative budgeted optimization through the Budgeted-KMR algorithm. We demonstrate how well-known efficiency methods can be instantiated as KMR triples and present concise algorithmic templates for each. The framework highlights underlying relationships between methods, facilitates hybrid pipelines, and lays the foundation for future research in automated policy learning, dynamic adaptation, and theoretical analysis of cost-quality trade-offs. Overall, KMR offers both a conceptual and practical tool for unifying and advancing model efficiency research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13998v1" target="_blank">Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation</a></h3>
                    <p><strong>Authors:</strong> Yifu Yuan, Haiqin Cui, Yaoting Huang, Yibin Chen, Fei Ni, Zibin Dong, Pengyi Li, Yan Zheng, Jianye Hao</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Generalization in embodied AI is hindered by the seeing-to-doing gap, which stems from data scarcity and embodiment heterogeneity. To address this, we pioneer pointing as a unified, embodiment-agnostic intermediate representation, defining four core embodied pointing abilities that bridge high-level vision-language comprehension with low-level action primitives. We introduce Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed for embodied reasoning and pointing. We use a wide range of embodied and general visual reasoning datasets as sources to construct a large-scale dataset, Embodied-Points-200K, which supports key embodied pointing capabilities. We then train Embodied-R1 using a two-stage Reinforced Fine-tuning (RFT) curriculum with a specialized multi-task reward design. Embodied-R1 achieves state-of-the-art performance on 11 embodied spatial and pointing benchmarks. Critically, it demonstrates robust zero-shot generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5% across 8 real-world XArm tasks without any task-specific fine-tuning, representing a 62% improvement over strong baselines. Furthermore, the model exhibits high robustness against diverse visual disturbances. Our work shows that a pointing-centric representation, combined with an RFT training paradigm, offers an effective and generalizable pathway to closing the perception-action gap in robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13992v1" target="_blank">MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence</a></h3>
                    <p><strong>Authors:</strong> Sonal Kumar, ≈†imon Sedl√°ƒçek, Vaibhavi Lokegaonkar, Fernando L√≥pez, Wenyi Yu, Nishit Anand, Hyeonggon Ryu, Lichang Chen, Maxim Pliƒçka, Miroslav Hlav√°ƒçek, William Fineas Ellingwood, Sathvik Udupa, Siyuan Hou, Allison Ferner, Sara Barahona, Cecilia Bola√±os, Satish Rahi, Laura Herrera-Alarc√≥n, Satvik Dixit, Siddhi Patil, Soham Deshmukh, Lasha Koroshinadze, Yao Liu, Leibny Paola Garcia Perera, Eleni Zanou, Themos Stafylakis, Joon Son Chung, David Harwath, Chao Zhang, Dinesh Manocha, Alicia Lozano-Diez, Santosh Kesiraju, Sreyan Ghosh, Ramani Duraiswami</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.AS, cs.SD</p>
                    <p><strong>Summary:</strong> Audio comprehension-including speech, non-speech sounds, and music-is essential for achieving human-level intelligence. Consequently, AI agents must demonstrate holistic audio understanding to qualify as generally intelligent. However, evaluating auditory intelligence comprehensively remains challenging. To address this gap, we introduce MMAU-Pro, the most comprehensive and rigorously curated benchmark for assessing audio intelligence in AI systems. MMAU-Pro contains 5,305 instances, where each instance has one or more audios paired with human expert-generated question-answer pairs, spanning speech, sound, music, and their combinations. Unlike existing benchmarks, MMAU-Pro evaluates auditory intelligence across 49 unique skills and multiple complex dimensions, including long-form audio comprehension, spatial audio reasoning, multi-audio understanding, among others. All questions are meticulously designed to require deliberate multi-hop reasoning, including both multiple-choice and open-ended response formats. Importantly, audio data is sourced directly ``from the wild rather than from existing datasets with known distributions. We evaluate 22 leading open-source and proprietary multimodal AI models, revealing significant limitations: even state-of-the-art models such as Gemini 2.5 Flash and Audio Flamingo 3 achieve only 59.2% and 51.7% accuracy, respectively, approaching random performance in multiple categories. Our extensive analysis highlights specific shortcomings and provides novel insights, offering actionable perspectives for the community to enhance future AI systems progression toward audio general intelligence. The benchmark and code is available at https://sonalkum.github.io/mmau-pro.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13989v1" target="_blank">Physics-Based 3D Simulation for Synthetic Data Generation and Failure Analysis in Packaging Stability Assessment</a></h3>
                    <p><strong>Authors:</strong> Samuel Seligardi, Pietro Musoni, Eleonora Iotti, Gianluca Contesso, Alessandro Dal Pal√π</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The design and analysis of pallet setups are essential for ensuring safety of packages transportation. With rising demands in the logistics sector, the development of automated systems utilizing advanced technologies has become increasingly crucial. Moreover, the widespread use of plastic wrapping has motivated researchers to investigate eco-friendly alternatives that still adhere to safety standards. We present a fully controllable and accurate physical simulation system capable of replicating the behavior of moving pallets. It features a 3D graphics-based virtual environment that supports a wide range of configurations, including variable package layouts, different wrapping materials, and diverse dynamic conditions. This innovative approach reduces the need for physical testing, cutting costs and environmental impact while improving measurement accuracy for analyzing pallet dynamics. Additionally, we train a deep neural network to evaluate the rendered videos generated by our simulator, as a crash-test predictor for pallet configurations, further enhancing the systems utility in safety analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13984v1" target="_blank">The AI-Fraud Diamond: A Novel Lens for Auditing Algorithmic Deception</a></h3>
                    <p><strong>Authors:</strong> Benjamin Zweers, Diptish Dey, Debarati Bhaumik</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> As artificial intelligence (AI) systems become increasingly integral to organizational processes, they introduce new forms of fraud that are often subtle, systemic, and concealed within technical complexity. This paper introduces the AI-Fraud Diamond, an extension of the traditional Fraud Triangle that adds technical opacity as a fourth condition alongside pressure, opportunity, and rationalization. Unlike traditional fraud, AI-enabled deception may not involve clear human intent but can arise from system-level features such as opaque model behavior, flawed training data, or unregulated deployment practices. The paper develops a taxonomy of AI-fraud across five categories: input data manipulation, model exploitation, algorithmic decision manipulation, synthetic misinformation, and ethics-based fraud. To assess the relevance and applicability of the AI-Fraud Diamond, the study draws on expert interviews with auditors from two of the Big Four consulting firms. The findings underscore the challenges auditors face when addressing fraud in opaque and automated environments, including limited technical expertise, insufficient cross-disciplinary collaboration, and constrained access to internal system processes. These conditions hinder fraud detection and reduce accountability. The paper argues for a shift in audit methodology-from outcome-based checks to a more diagnostic approach focused on identifying systemic vulnerabilities. Ultimately, the work lays a foundation for future empirical research and audit innovation in a rapidly evolving AI governance landscape.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13982v1" target="_blank">The Social Context of Human-Robot Interactions</a></h3>
                    <p><strong>Authors:</strong> Sydney Thompson, Kate Candon, Marynel V√°zquez</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.HC, cs.MA, I.2.9; I.2</p>
                    <p><strong>Summary:</strong> The Human-Robot Interaction (HRI) community often highlights the social context of an interaction as a key consideration when designing, implementing, and evaluating robot behavior. Unfortunately, researchers use the term social context in varied ways. This can lead to miscommunication, making it challenging to draw connections between related work on understanding and modeling the social contexts of human-robot interactions. To address this gap, we survey the HRI literature for existing definitions and uses of the term social context. Then, we propose a conceptual model for describing the social context of a human-robot interaction. We apply this model to existing work, and we discuss a range of attributes of social contexts that can help researchers plan for interactions, develop behavior models for robots, and gain insights after interactions have taken place. We conclude with a discussion of open research questions in relation to understanding and modeling the social contexts of human-robot interactions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13978v1" target="_blank">Democratizing News Recommenders: Modeling Multiple Perspectives for News Candidate Generation with VQ-VAE</a></h3>
                    <p><strong>Authors:</strong> Hardy, Sebastian Pad√≥, Amelie W√ºhrl, Tanise Ceron</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Current News Recommender Systems based on past clicks are designed for engagement, but come at the cost of limiting diversity in the suggested content. While diversity-aware algorithms exist, they suffer from two major limitations. First, they fail to account for normative diversity, which requires fair access to a broad range of perspectives. Second, they typically apply diversity late in the systems pipeline, after a lot of content has already been filtered out. Both limitations confine their effectiveness and prevent them from promoting true normative diversity in news recommendations. We propose Aspect-Aware Candidate Generation (A2CG) to address these limitations. Our framework introduces diversity into the earliest pipeline stage and uses a configurable mechanism to align diversity with specific democratic goals. A2CG represents each news article using multiple aspects of perspectives (e.g., sentiment, political leaning, frame) and uses a Vector Quantized Variational Autoencoder (VQ-VAE) to create a discrete, multi-faceted representation. A decoder-only model then learns user preferences over these aspect codes. We then inject diversity directly by reversing the sign on some of the query vectors aspects during the candidate retrieval process, ensuring a more diverse set of candidates. Our method, evaluated on the MIND dataset, enables a flexible trade-off between personalization and diversity early in the recommendation pipeline. It also generates more novel, diverse, and serendipitous candidates while effectively taking into account aspects that strengthen democratic values. These empirical results make it a promising approach for downstream democratized news recommendation systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13977v1" target="_blank">ROVR-Open-Dataset: A Large-Scale Depth Dataset for Autonomous Driving</a></h3>
                    <p><strong>Authors:</strong> Xianda Guo, Ruijun Zhang, Yiqun Duan, Ruilin Wang, Keyuan Zhou, Wenzhao Zheng, Wenke Huang, Gangwei Xu, Mike Horton, Yuan Si, Hao Zhao, Long Chen</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Depth estimation is a fundamental task for 3D scene understanding in autonomous driving, robotics, and augmented reality. Existing depth datasets, such as KITTI, nuScenes, and DDAD, have advanced the field but suffer from limitations in diversity and scalability. As benchmark performance on these datasets approaches saturation, there is an increasing need for a new generation of large-scale, diverse, and cost-efficient datasets to support the era of foundation models and multi-modal learning. To address these challenges, we introduce a large-scale, diverse, frame-wise continuous dataset for depth estimation in dynamic outdoor driving environments, comprising 20K video frames to evaluate existing methods. Our lightweight acquisition pipeline ensures broad scene coverage at low cost, while sparse yet statistically sufficient ground truth enables robust training. Compared to existing datasets, ours presents greater diversity in driving scenarios and lower depth density, creating new challenges for generalization. Benchmark experiments with standard monocular depth estimation models validate the datasets utility and highlight substantial performance gaps in challenging conditions, establishing a new platform for advancing depth estimation research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13976v1" target="_blank">Toward an Interaction-Centered Approach to Robot Trustworthiness</a></h3>
                    <p><strong>Authors:</strong> Carlo Mazzola, Hassan Ali, Krist√≠na Malinovsk√°, Igor Farka≈°</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> As robots get more integrated into human environments, fostering trustworthiness in embodied robotic agents becomes paramount for an effective and safe human-robot interaction (HRI). To achieve that, HRI applications must promote human trust that aligns with robot skills and avoid misplaced trust or overtrust, which can pose safety risks and ethical concerns. To achieve that, HRI applications must promote human trust that aligns with robot skills and avoid misplaced trust or overtrust, which can pose safety risks and ethical concerns. In this position paper, we outline an interaction-based framework for building trust through mutual understanding between humans and robots. We emphasize two main pillars: human awareness and transparency, referring to the robot ability to interpret human actions accurately and to clearly communicate its intentions and goals, respectively. By integrating these two pillars, robots can behave in a manner that aligns with human expectations and needs while providing their human partners with both comprehension and control over their actions. We also introduce four components that we think are important for bridging the gap between a human-perceived sense of trust and a robot true capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13975v1" target="_blank">ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation</a></h3>
                    <p><strong>Authors:</strong> Jingquan Wang, Andrew Negrut, Harry Zhang, Khailanii Slaton, Shu Wang, Radu Serban, Jinlong Wu, Dan Negrut</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This contribution is concerned with the following issue: can pretrained large language models (LLMs) be refined and customized to the point where they become virtual assistants helping experts with the effective use of a simulation tool? In this case study, the ``simulation tool considered is PyChrono, an open source multi-physics dynamics engine for multibody systems. We present a framework for refining and customizing both open- and closed-source LLMs to harness the power of AI in generating scripts that perform PyChrono virtual experiments. We refine and customize several classes of LLMs through a process that leads to a quantifiable improvement in the quality of the generated PyChrono simulation scripts. These scripts can range from simple single-pendulum simulations to complex virtual experiments involving full vehicles on deformable terrain. While the generated scripts are rarely perfect, they often serve as strong starting points for the user to modify and improve on. Additionally, the LLM can answer specific API questions about the simulator, or recommend modeling approaches. The framework discussed is general and can be applied to lower the entry barrier for simulation tools associated with other application domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13973v1" target="_blank">Roadblocks and Opportunities in Quantum Algorithms -- Insights from the National Quantum Initiative Joint Algorithms Workshop, May 20--22, 2024</a></h3>
                    <p><strong>Authors:</strong> Eliot Kapit, Peter Love, Jeffrey Larson, Andrew Sornborger, Eleanor Crane, Alexander Schuckert, Teague Tomesh, Frederic Chong, Sabre Kais</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> The National Quantum Initiative Joint Algorithms Workshop brought together researchers across academia, national laboratories, and industry to assess the current landscape of quantum algorithms and discuss roadblocks to progress. The workshop featured discussions on emerging algorithmic techniques, resource constraints in near-term hardware, and opportunities for co-design across software and systems. Presented here are seven topics from the workshop, each highlighting a critical challenge or promising opportunity discussed during the event. Together, they offer a snapshot of the fields evolving priorities and a shared vision for what is needed to advance quantum computational capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13964v1" target="_blank">Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation</a></h3>
                    <p><strong>Authors:</strong> Martijn Cramer, Yanming Wu, David De Schepper, Eric Demeester</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Due to high-mix-low-volume production, sheet-metal workshops today are challenged by small series and varying orders. As standard automation solutions tend to fall short, SMEs resort to repetitive manual labour impacting production costs and leading to tech-skilled workforces not being used to their full potential. The COOCK+ ROBUST project aims to transform cobots into mobile and reconfigurable production assistants by integrating existing technologies, including 3D object recognition and localisation. This article explores both the opportunities and challenges of enhancing cobotic systems with these technologies in an industrial setting, outlining the key steps involved in the process. Additionally, insights from a past project, carried out by the ACRO research unit in collaboration with an industrial partner, serves as a concrete implementation example throughout.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13962v1" target="_blank">Learning to Use AI for Learning: How Can We Effectively Teach and Measure Prompting Literacy for K-12 Students?</a></h3>
                    <p><strong>Authors:</strong> Ruiwei Xiao, Xinying Hou, Ying-Jui Tseng, Hsuan Nieu, Guanze Liao, John Stamper, Kenneth R. Koedinger</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> As Artificial Intelligence (AI) becomes increasingly integrated into daily life, there is a growing need to equip the next generation with the ability to apply, interact with, evaluate, and collaborate with AI systems responsibly. Prior research highlights the urgent demand from K-12 educators to teach students the ethical and effective use of AI for learning. To address this need, we designed an Large-Language Model (LLM)-based module to teach prompting literacy. This includes scenario-based deliberate practice activities with direct interaction with intelligent LLM agents, aiming to foster secondary school students responsible engagement with AI chatbots. We conducted two iterations of classroom deployment in 11 authentic secondary education classrooms, and evaluated 1) AI-based auto-graders capability; 2) students prompting performance and confidence changes towards using AI for learning; and 3) the quality of learning and assessment materials. Results indicated that the AI-based auto-grader could grade student-written prompts with satisfactory quality. In addition, the instructional materials supported students in improving their prompting skills through practice and led to positive shifts in their perceptions of using AI for learning. Furthermore, data from Study 1 informed assessment revisions in Study 2. Analyses of item difficulty and discrimination in Study 2 showed that True/False and open-ended questions could measure prompting literacy more effectively than multiple-choice questions for our target learners. These promising outcomes highlight the potential for broader deployment and highlight the need for broader studies to assess learning effectiveness and assessment design.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13960v1" target="_blank">A Mechanism for Mutual Fairness in Cooperative Games with Replicable Resources -- Extended Version</a></h3>
                    <p><strong>Authors:</strong> Bj√∂rn Filter, Ralf M√∂ller, √ñzg√ºr L√ºtf√º √ñz√ßep</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.GT, cs.AI</p>
                    <p><strong>Summary:</strong> The latest developments in AI focus on agentic systems where artificial and human agents cooperate to realize global goals. An example is collaborative learning, which aims to train a global model based on data from individual agents. A major challenge in designing such systems is to guarantee safety and alignment with human values, particularly a fair distribution of rewards upon achieving the global goal. Cooperative game theory offers useful abstractions of cooperating agents via value functions, which assign value to each coalition, and via reward functions. With these, the idea of fair allocation can be formalized by specifying fairness axioms and designing concrete mechanisms. Classical cooperative game theory, exemplified by the Shapley value, does not fully capture scenarios like collaborative learning, as it assumes nonreplicable resources, whereas data and models can be replicated. Infinite replicability requires a generalized notion of fairness, formalized through new axioms and mechanisms. These must address imbalances in reciprocal benefits among participants, which can lead to strategic exploitation and unfair allocations. The main contribution of this paper is a mechanism and a proof that it fulfills the property of mutual fairness, formalized by the Balanced Reciprocity Axiom. It ensures that, for every pair of players, each benefits equally from the participation of the other.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13957v1" target="_blank">ViT-FIQA: Assessing Face Image Quality using Vision Transformers</a></h3>
                    <p><strong>Authors:</strong> Andrea Atzori, Fadi Boutros, Naser Damer</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Face Image Quality Assessment (FIQA) aims to predict the utility of a face image for face recognition (FR) systems. State-of-the-art FIQA methods mainly rely on convolutional neural networks (CNNs), leaving the potential of Vision Transformer (ViT) architectures underexplored. This work proposes ViT-FIQA, a novel approach that extends standard ViT backbones, originally optimized for FR, through a learnable quality token designed to predict a scalar utility score for any given face image. The learnable quality token is concatenated with the standard image patch tokens, and the whole sequence is processed via global self-attention by the ViT encoders to aggregate contextual information across all patches. At the output of the backbone, ViT-FIQA branches into two heads: (1) the patch tokens are passed through a fully connected layer to learn discriminative face representations via a margin-penalty softmax loss, and (2) the quality token is fed into a regression head to learn to predict the face samples utility. Extensive experiments on challenging benchmarks and several FR models, including both CNN- and ViT-based architectures, demonstrate that ViT-FIQA consistently achieves top-tier performance. These results underscore the effectiveness of transformer-based architectures in modeling face image utility and highlight the potential of ViTs as a scalable foundation for future FIQA research https://cutt.ly/irHlzXUC.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13956v1" target="_blank">Quantum Chaos Diagnostics for Open Quantum Systems from Bi-Lanczos Krylov Dynamics</a></h3>
                    <p><strong>Authors:</strong> Matteo Baggioli, Kyoung-Bum Huh, Hyun-Sik Jeong, Xuhao Jiang, Keun-Young Kim, Juan F. Pedraza</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> hep-th, cond-mat.stat-mech, nlin.CD, quant-ph</p>
                    <p><strong>Summary:</strong> In Hermitian systems, Krylov complexity has emerged as a powerful diagnostic of quantum dynamics, capable of distinguishing chaotic from integrable phases, in agreement with established probes such as spectral statistics and out-of-time-order correlators. By contrast, its role in non-Hermitian settings, relevant for modeling open quantum systems, remains less understood due to the challenges posed by complex eigenvalues and the limitations of standard approaches such as singular value decomposition. Here, we demonstrate that Krylov complexity, computed via the bi-Lanczos algorithm, effectively identifies chaotic and integrable phases in open quantum systems. The results align with complex spectral statistics and complex spacing ratios, highlighting the robustness of this approach. The universality of our findings is further supported through studies of both the non-Hermitian Sachdev-Ye-Kitaev model and non-Hermitian random matrix ensembles.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13955v1" target="_blank">A first-principles theoretical study on two-dimensional MX and MX$_2$ metal halides: bandgap engineering, magnetism, and catalytic descriptors</a></h3>
                    <p><strong>Authors:</strong> Yu-Hsiu Lin, Daniel Maldonado-Lopez, Jose L. Mendoza-Cortes</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Metal halides, particularly MX and MX$_2$ compounds (where M represents metal elements and X = F, Cl, Br, I), have attracted significant interest due to their diverse electronic and optoelectronic properties. However, a comprehensive understanding of their structural and electronic behavior, particularly the evolution of these properties from bulk to low-dimensional forms, remains limited. To address this gap, we performed first-principles calculations to develop a database of 60 MX and MX$_2$ metal halides, detailing their structural and electronic properties in both bulk and slab configurations. Calculations were performed using the advanced \texttt{HSE06-D3} hybrid functional for density functional theory (DFT), ensuring high precision in predicting material properties despite the associated computational cost. The results reveal that these materials are predominantly semiconductors, but their bandgaps range from 0 to 9 eV. A detailed analysis of the transition from bulk to slab structures highlights notable shifts in electronic properties, including bandgap modifications. Upon dimensional reduction, 9 materials exhibit an indirect-to-direct bandgap transition, enhancing their potential for energy conversion. Beyond structural dimensionality, the influence of chemical composition on bandgap variations was also examined. To further assess their practical applicability, the catalytic and magnetic properties of these metal halides were systematically evaluated. These findings not only illuminate previously underexplored MX and MX$_2$ metal halides but also identify promising candidates for electronic, optoelectronic, catalytic and spintronic applications. This database serves as a valuable resource for guiding future research and technology development in low-dimensional materials.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13953v1" target="_blank">ReviewGraph: A Knowledge Graph Embedding Based Framework for Review Rating Prediction with Sentiment Features</a></h3>
                    <p><strong>Authors:</strong> A. J. W. de Vink, Natalia Amat-Lefort, Lifeng Han</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In the hospitality industry, understanding the factors that drive customer review ratings is critical for improving guest satisfaction and business performance. This work proposes ReviewGraph for Review Rating Prediction (RRP), a novel framework that transforms textual customer reviews into knowledge graphs by extracting (subject, predicate, object) triples and associating sentiment scores. Using graph embeddings (Node2Vec) and sentiment features, the framework predicts review rating scores through machine learning classifiers. We compare ReviewGraph performance with traditional NLP baselines (such as Bag of Words, TF-IDF, and Word2Vec) and large language models (LLMs), evaluating them in the HotelRec dataset. In comparison to the state of the art literature, our proposed model performs similar to their best performing model but with lower computational cost (without ensemble). While ReviewGraph achieves comparable predictive performance to LLMs and outperforms baselines on agreement-based metrics such as Cohens Kappa, it offers additional advantages in interpretability, visual exploration, and potential integration into Retrieval-Augmented Generation (RAG) systems. This work highlights the potential of graph-based representations for enhancing review analytics and lays the groundwork for future research integrating advanced graph neural networks and fine-tuned LLM-based extraction methods. We will share ReviewGraph output and platform open-sourced on our GitHub page https://github.com/aaronlifenghan/ReviewGraph</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13949v1" target="_blank">Query Logs Analytics: A Aystematic Literature Review</a></h3>
                    <p><strong>Authors:</strong> Dihia Lanasri</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.CL</p>
                    <p><strong>Summary:</strong> In the digital era, user interactions with various resources such as databases, data warehouses, websites, and knowledge graphs (KGs) are increasingly mediated through digital platforms. These interactions leave behind digital traces, systematically captured in the form of logs. Logs, when effectively exploited, provide high value across industry and academia, supporting critical services (e.g., recovery and security), user-centric applications (e.g., recommender systems), and quality-of-service improvements (e.g., performance optimization). Despite their importance, research on log usage remains fragmented across domains, and no comprehensive study currently consolidates existing efforts. This paper presents a systematic survey of log usage, focusing on Database (DB), Data Warehouse (DW), Web, and KG logs. More than 300 publications were analyzed to address three central questions: (1) do different types of logs share common structural and functional characteristics? (2) are there standard pipelines for their usage? (3) which constraints and non-functional requirements (NFRs) guide their exploitation?. The survey reveals a limited number of end-to-end approaches, the absence of standardization across log usage pipelines, and the existence of shared structural elements among different types of logs. By consolidating existing knowledge, identifying gaps, and highlighting opportunities, this survey provides researchers and practitioners with a comprehensive overview of log usage and sheds light on promising directions for future research, particularly regarding the exploitation and democratization of KG logs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13947v1" target="_blank">Real-Time, Population-Based Reconstruction of 3D Bone Models via Very-Low-Dose Protocols</a></h3>
                    <p><strong>Authors:</strong> Yiqun Lin, Haoran Sun, Yongqing Li, Rabia Aslam, Lung Fung Tse, Tiange Cheng, Chun Sing Chui, Wing Fung Yau, Victorine R. Le Meur, Meruyert Amangeldy, Kiho Cho, Yinyu Ye, James Zou, Wei Zhao, Xiaomeng Li</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Patient-specific bone models are essential for designing surgical guides and preoperative planning, as they enable the visualization of intricate anatomical structures. However, traditional CT-based approaches for creating bone models are limited to preoperative use due to the low flexibility and high radiation exposure of CT and time-consuming manual delineation. Here, we introduce Semi-Supervised Reconstruction with Knowledge Distillation (SSR-KD), a fast and accurate AI framework to reconstruct high-quality bone models from biplanar X-rays in 30 seconds, with an average error under 1.0 mm, eliminating the dependence on CT and manual work. Additionally, high tibial osteotomy simulation was performed by experts on reconstructed bone models, demonstrating that bone models reconstructed from biplanar X-rays have comparable clinical applicability to those annotated from CT. Overall, our approach accelerates the process, reduces radiation exposure, enables intraoperative guidance, and significantly improves the practicality of bone models, offering transformative applications in orthopedics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13942v1" target="_blank">The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management</a></h3>
                    <p><strong>Authors:</strong> Soumyadeep Dhar</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The rise of autonomous, AI-driven agents in economic settings raises critical questions about their emergent strategic behavior. This paper investigates these dynamics in the cooperative context of a multi-echelon supply chain, a system famously prone to instabilities like the bullwhip effect. We conduct computational experiments with generative AI agents, powered by Large Language Models (LLMs), within a controlled supply chain simulation designed to isolate their behavioral tendencies. Our central finding is the collaboration paradox: a novel, catastrophic failure mode where theoretically superior collaborative AI agents, designed with Vendor-Managed Inventory (VMI) principles, perform even worse than non-AI baselines. We demonstrate that this paradox arises from an operational flaw where agents hoard inventory, starving the system. We then show that resilience is only achieved through a synthesis of two distinct layers: high-level, AI-driven proactive policy-setting to establish robust operational targets, and a low-level, collaborative execution protocol with proactive downstream replenishment to maintain stability. Our final framework, which implements this synthesis, can autonomously generate, evaluate, and quantify a portfolio of viable strategic choices. The work provides a crucial insight into the emergent behaviors of collaborative AI agents and offers a blueprint for designing stable, effective AI-driven systems for business analytics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13939v1" target="_blank">Implementation of the Martini-Ericson-Chanfray-Marteau RPA-based (anti)neutrino cross-section model in the GENIE neutrino event generator</a></h3>
                    <p><strong>Authors:</strong> Lavinia Russo, Marco Martini, Stephen Dolan, Laura Munteanu, Boris Popov, Claudio Giganti</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> hep-ex, hep-ph</p>
                    <p><strong>Summary:</strong> We discuss the first implementation of the Martini-Ericson-Chanfray-Marteau RPA-based (anti)neutrino cross-section model for quasielastic (1p1h) and multinucleon (2p2h and 3p3h) excitations in the widely used GENIE neutrino event generator. Validation steps are presented, in particular, through direct comparisons of GENIE cross section output with original calculations performed by the authors of the model. Predictions for $^{12}$C, $^{16}$O and $^{40}$Ar are compared with some available T2K and MicroBooNE experimental measurements showing a reasonable agreement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13930v1" target="_blank">InPars+: Supercharging Synthetic Data Generation for Information Retrieval Systems</a></h3>
                    <p><strong>Authors:</strong> Matey Krastev, Miklos Hamar, Danilo Toapanta, Jesse Brouwers, Yibin Lei</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI</p>
                    <p><strong>Summary:</strong> This work revisits and extends synthetic query generation pipelines for Neural Information Retrieval (NIR) by leveraging the InPars Toolkit, a reproducible, end-to-end framework for generating training data using large language models (LLMs). We first assess the reproducibility of the original InPars, InPars-V2, and Promptagator pipelines on the SciFact benchmark and validate their effectiveness using open-source reranker and generator models. Building on this foundation, we introduce two key extensions to the pipeline: (1) fine-tuning a query generator LLM via Contrastive Preference Optimization (CPO) to improve the signal quality in generated queries, and (2) replacing static prompt templates with dynamic, Chain-of-Thought (CoT) optimized prompts using the DSPy framework. Our results show that both extensions reduce the need for aggressive filtering while improving retrieval performance. All code, models, and synthetic datasets are publicly released to support further research at: \href{https://github.com/danilotpnta/IR2-project}{this https URL}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13914v1" target="_blank">Development of a defacing algorithm to protect the privacy of head and neck cancer patients in publicly-accessible radiotherapy datasets</a></h3>
                    <p><strong>Authors:</strong> Kayla OSullivan-Steben, Luc Galarneau, John Kildea</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> physics.med-ph</p>
                    <p><strong>Summary:</strong> Introduction: The rise in public medical imaging datasets has raised concerns about patient reidentification from head CT scans. However, existing defacing algorithms often remove or distort Organs at Risk (OARs) and Planning Target Volumes (PTVs) in head and neck cancer (HNC) patients, and ignore DICOM-RT Structure Set and Dose data. Therefore, we developed and validated a novel automated defacing algorithm that preserves these critical structures while removing identifiable features from HNC CTs and DICOM-RT data. Methods: Eye contours were used as landmarks to automate the removal of CT pixels above the inferior-most eye slice and anterior to the eye midpoint. Pixels within PTVs were retained if they intersected with the removed region. The body contour and dose map were reshaped to reflect the defaced image. We validated our approach on 829 HNC CTs from 622 patients. Privacy protection was evaluated by applying the FaceNet512 facial recognition algorithm before and after defacing on 3D-rendered CT pairs from 70 patients. Research utility was assessed by examining the impact of defacing on autocontouring performance using LimbusAI and analyzing PTV locations relative to the defaced regions. Results: Before defacing, FaceNet512 matched 97% of patients CTs. After defacing, this rate dropped to 4%. LimbusAI effectively autocontoured organs in the defaced CTs, with perfect Dice scores of 1 for OARs below the defaced region, and excellent scores exceeding 0.95 for OARs on the same slices as the crop. We found that 86% of PTVs were entirely below the cropped region, 9.1% were on the same slice as the crop without overlap, and only 4.9% extended into the cropped area. Conclusions: We developed a novel defacing algorithm that anonymizes HNC CT scans and related DICOM-RT data while preserving essential structures, enabling the sharing of HNC imaging datasets for Big Data and AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13911v1" target="_blank">PhysGM: Large Physical Gaussian Model for Feed-Forward 4D Synthesis</a></h3>
                    <p><strong>Authors:</strong> Chunji Lv, Zequn Chen, Donglin Di, Weinan Zhang, Hao Li, Wei Chen, Changsheng Li</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> While physics-grounded 3D motion synthesis has seen significant progress, current methods face critical limitations. They typically rely on pre-reconstructed 3D Gaussian Splatting (3DGS) representations, while physics integration depends on either inflexible, manually defined physical attributes or unstable, optimization-heavy guidance from video models. To overcome these challenges, we introduce PhysGM, a feed-forward framework that jointly predicts a 3D Gaussian representation and its physical properties from a single image, enabling immediate, physical simulation and high-fidelity 4D rendering. We first establish a base model by jointly optimizing for Gaussian reconstruction and probabilistic physics prediction. The model is then refined with physically plausible reference videos to enhance both rendering fidelity and physics prediction accuracy. We adopt the Direct Preference Optimization (DPO) to align its simulations with reference videos, circumventing Score Distillation Sampling (SDS) optimization which needs back-propagating gradients through the complex differentiable simulation and rasterization. To facilitate the training, we introduce a new dataset PhysAssets of over 24,000 3D assets, annotated with physical properties and corresponding guiding videos. Experimental results demonstrate that our method effectively generates high-fidelity 4D simulations from a single image in one minute. This represents a significant speedup over prior works while delivering realistic rendering results. Our project page is at:https://hihixiaolv.github.io/PhysGM.github.io/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13908v1" target="_blank">Translating the Force Concept Inventory in the age of AI</a></h3>
                    <p><strong>Authors:</strong> Marina Babayeva, Justin Dunlap, Marie Snƒõtinov√°, Ralf Widenhorn</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> We present a study that translates the Force Concept Inventory (FCI) using OpenAI GPT-4o and assess the specific difficulties of translating a scientific-focused topic using Large Language Models (LLMs). The FCI is a physics exam meant to evaluate outcomes of a student cohort before and after instruction in Newtonian physics. We examine the problem-solving ability of the LLM in both the translated document and the translation back into English, detailing the language-dependent issues that complicate the translation. While ChatGPT performs remarkably well on answering the questions in both the translated language as well as the back-translation into English, problems arise with language-specific nuances and formatting. Pitfalls include words or phrases that lack one-to-one matching terms in another language, especially discipline-specific scientific terms, or outright mistranslations. Depending on the context, these translations can result in a critical change in the physical meaning of the problem. Additionally, issues with question numbering and lettering are found in some languages. The issues around the translations of numbering and lettering provide insight into the abilities of the LLM and suggest that it is not simply relying upon FCI questions that may have been part of the LLM training data to provide answers. These findings underscore that while LLMs can accelerate multilingual access to educational tools, careful review is still needed to ensure fidelity and clarity in translated assessments. LLMs provide a new opportunity to expand educational tools and assessments. At the same time, there are unique challenges using LLMs to facilitate translations that this case study examines in detail.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13906v1" target="_blank">Qudit-based scalable quantum algorithm for solving the integer programming problem</a></h3>
                    <p><strong>Authors:</strong> Kapil Goswami, Peter Schmelcher, Rick Mukherjee</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> quant-ph, math.OC, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Integer programming (IP) is an NP-hard combinatorial optimization problem that is widely used to represent a diverse set of real-world problems spanning multiple fields, such as finance, engineering, logistics, and operations research. It is a hard problem to solve using classical algorithms, as its complexity increases exponentially with problem size. Most quantum algorithms for solving IP are highly resource inefficient because they encode integers into qubits. In [1], the issue of resource inefficiency was addressed by mapping integer variables to qudits. However, [1] has limited practical value due to a lack of scalability to multiple qudits to encode larger problems. In this work, by extending upon the ideas of [1], a circuit-based scalable quantum algorithm is presented using multiple interacting qudits for which we show a quantum speed-up. The quantum algorithm consists of a distillation function that efficiently separates the feasible from the infeasible regions, a phase-amplitude encoding for the cost function, and a quantum phase estimation coupled with a multi-controlled single-qubit rotation for optimization. We prove that the optimal solution has the maximum probability of being measured in our algorithm. The time complexity for the quantum algorithm is shown to be $O(d^{n/2} + m\cdot n^2\cdot \log{d} + n/\epsilon_{QPE})$ for a problem with the number of variables $n$ taking $d$ integer values, satisfying $m$ constraints with a precision of $\epsilon_{QPE}$. Compared to the classical time complexity of brute force $O(d^n)$ and the best classical exact algorithm $O((\log{n})^{3n})$, it incurs a reduction of $d^{n/2}$ in the time complexity in terms of $n$ for solving a general polynomial IP problem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13905v1" target="_blank">Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management</a></h3>
                    <p><strong>Authors:</strong> Tianheng Ling, Vipin Singh, Chao Qian, Felix Biessmann, Gregor Schiele</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Extreme weather events, intensified by climate change, increasingly challenge aging combined sewer systems, raising the risk of untreated wastewater overflow. Accurate forecasting of sewer overflow basin filling levels can provide actionable insights for early intervention, helping mitigating uncontrolled discharge. In recent years, AI-based forecasting methods have offered scalable alternatives to traditional physics-based models, but their reliance on cloud computing limits their reliability during communication outages. To address this, we propose an end-to-end forecasting framework that enables energy-efficient inference directly on edge devices. Our solution integrates lightweight Transformer and Long Short-Term Memory (LSTM) models, compressed via integer-only quantization for efficient on-device execution. Moreover, an automated hardware-aware deployment pipeline is used to search for optimal model configurations by jointly minimizing prediction error and energy consumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer data, the selected 8-bit Transformer model, trained on 24 hours of historical measurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ per inference. In contrast, the optimal 8-bit LSTM model requires significantly less energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE 0.0432) and much longer training time. This trade-off highlights the need to align model selection with deployment priorities, favoring LSTM for ultra-low energy consumption or Transformer for higher predictive accuracy. In general, our work enables local, energy-efficient forecasting, contributing to more resilient combined sewer systems. All code can be found in the GitHub Repository (https://github.com/tianheng-ling/EdgeOverflowForecast).</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.cjph.2025.06.024" target="_blank">Role of Non-conserved Gravity Theory and Electric Charge in Constructing Complexity-free Stellar Models: A Novel Approach under Non-minimal Coupling</a></h3>
                    <p><strong>Authors:</strong> Tayyab Naseer</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> This study explores the application of complexity factor within the context of Rastall gravity, exploring its implications on a static spacetime admitting spherical symmetry associated with anisotropic fluids under an electromagnetic field. The field equations are derived for a static charged sphere that provides a foundational framework for analyzing gravitational effects in this non-conserved theory. The mass function is formulated by incorporating both fluid and geometric parameters, offering insights into how mass distribution affects spacetime curvature. Through orthogonal decomposition of the Riemann tensor, a set of scalar quantities is obtained, referred to the structure scalars, which serve as indicators of celestial complexity. One specific scalar is then specified as the complexity factor, i.e., $\mathbb{Y}_{TF}$, facilitating further analysis on its role in characterizing complex systems. The presence of unknowns in gravitational equations necessitates the imposition of constraints to facilitate their solution. To address this, $\mathbb{Y}_{TF}=0$ alongside three distinct conditions are employed which yield diverse stellar models. A comprehensive graphical analysis is conducted using multiple values of the Rastall and charge parameters. Notably, the findings of this study align with those predicted by Einsteins theory. More appealingly, the Rastall theory demonstrates its superiority in the presence of charge under model 2 when it is compared with the general theory of relativity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13901v1" target="_blank">Multimodal Data Storage and Retrieval for Embodied AI: A Survey</a></h3>
                    <p><strong>Authors:</strong> Yihao Lu, Hao Tang</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Embodied AI (EAI) agents continuously interact with the physical world, generating vast, heterogeneous multimodal data streams that traditional management systems are ill-equipped to handle. In this survey, we first systematically evaluate five storage architectures (Graph Databases, Multi-Model Databases, Data Lakes, Vector Databases, and Time-Series Databases), focusing on their suitability for addressing EAIs core requirements, including physical grounding, low-latency access, and dynamic scalability. We then analyze five retrieval paradigms (Fusion Strategy-Based Retrieval, Representation Alignment-Based Retrieval, Graph-Structure-Based Retrieval, Generation Model-Based Retrieval, and Efficient Retrieval-Based Optimization), revealing a fundamental tension between achieving long-term semantic coherence and maintaining real-time responsiveness. Based on this comprehensive analysis, we identify key bottlenecks, spanning from the foundational Physical Grounding Gap to systemic challenges in cross-modal integration, dynamic adaptation, and open-world generalization. Finally, we outline a forward-looking research agenda encompassing physics-aware data models, adaptive storage-retrieval co-optimization, and standardized benchmarking, to guide future research toward principled data management solutions for EAI. Our survey is based on a comprehensive review of more than 180 related studies, providing a rigorous roadmap for designing the robust, high-performance data management frameworks essential for the next generation of autonomous embodied systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13881v1" target="_blank">Driving Style Recognition Like an Expert Using Semantic Privileged Information from Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Zhaokun Chen, Chaopeng Zhang, Xiaohan Li, Wenshuo Wang, Gentiane Venture, Junqiang Xi</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Existing driving style recognition systems largely depend on low-level sensor-derived features for training, neglecting the rich semantic reasoning capability inherent to human experts. This discrepancy results in a fundamental misalignment between algorithmic classifications and expert judgments. To bridge this gap, we propose a novel framework that integrates Semantic Privileged Information (SPI) derived from large language models (LLMs) to align recognition outcomes with human-interpretable reasoning. First, we introduce DriBehavGPT, an interactive LLM-based module that generates natural-language descriptions of driving behaviors. These descriptions are then encoded into machine learning-compatible representations via text embedding and dimensionality reduction. Finally, we incorporate them as privileged information into Support Vector Machine Plus (SVM+) for training, enabling the model to approximate human-like interpretation patterns. Experiments across diverse real-world driving scenarios demonstrate that our SPI-enhanced framework outperforms conventional methods, achieving F1-score improvements of 7.6% (car-following) and 7.9% (lane-changing). Importantly, SPI is exclusively used during training, while inference relies solely on sensor data, ensuring computational efficiency without sacrificing performance. These results highlight the pivotal role of semantic behavioral representations in improving recognition accuracy while advancing interpretable, human-centric driving systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13880v1" target="_blank">In-hoc Concept Representations to Regularise Deep Learning in Medical Imaging</a></h3>
                    <p><strong>Authors:</strong> Valentina Corbetta, Floris Six Dijkstra, Regina Beets-Tan, Hoel Kervadec, Kristoffer Wickstr√∏m, Wilson Silva</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep learning models in medical imaging often achieve strong in-distribution performance but struggle to generalise under distribution shifts, frequently relying on spurious correlations instead of clinically meaningful features. We introduce LCRReg, a novel regularisation approach that leverages Latent Concept Representations (LCRs) (e.g., Concept Activation Vectors (CAVs)) to guide models toward semantically grounded representations. LCRReg requires no concept labels in the main training set and instead uses a small auxiliary dataset to synthesise high-quality, disentangled concept examples. We extract LCRs for predefined relevant features, and incorporate a regularisation term that guides a Convolutional Neural Network (CNN) to activate within latent subspaces associated with those concepts. We evaluate LCRReg across synthetic and real-world medical tasks. On a controlled toy dataset, it significantly improves robustness to injected spurious correlations and remains effective even in multi-concept and multiclass settings. On the diabetic retinopathy binary classification task, LCRReg enhances performance under both synthetic spurious perturbations and out-of-distribution (OOD) generalisation. Compared to baselines, including multitask learning, linear probing, and post-hoc concept-based models, LCRReg offers a lightweight, architecture-agnostic strategy for improving model robustness without requiring dense concept supervision. Code is available at the following link: https://github.com/Trustworthy-AI-UU-NKI/lcr\_regularization</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13875v1" target="_blank">A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler</a></h3>
                    <p><strong>Authors:</strong> Wenxuan Zhang, Shuai Li, Xinyi Wang, Yu Sun, Hongyu Kang, Pui Yuk Chryste Wan, Yong-Ping Zheng, Sai-Kit Lam</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The Circle of Willis (CoW), vital for ensuring consistent blood flow to the brain, is closely linked to ischemic stroke. Accurate assessment of the CoW is important for identifying individuals at risk and guiding appropriate clinical management. Among existing imaging methods, Transcranial Color-coded Doppler (TCCD) offers unique advantages due to its radiation-free nature, affordability, and accessibility. However, reliable TCCD assessments depend heavily on operator expertise for identifying anatomical landmarks and performing accurate angle correction, which limits its widespread adoption. To address this challenge, we propose an AI-powered, real-time CoW auto-segmentation system capable of efficiently capturing cerebral arteries. No prior studies have explored AI-driven cerebrovascular segmentation using TCCD. In this work, we introduce a novel Attention-Augmented Wavelet YOLO (AAW-YOLO) network tailored for TCCD data, designed to provide real-time guidance for brain vessel segmentation in the CoW. We prospectively collected TCCD data comprising 738 annotated frames and 3,419 labeled artery instances to establish a high-quality dataset for model training and evaluation. The proposed AAW-YOLO demonstrated strong performance in segmenting both ipsilateral and contralateral CoW vessels, achieving an average Dice score of 0.901, IoU of 0.823, precision of 0.882, recall of 0.926, and mAP of 0.953, with a per-frame inference speed of 14.199 ms. This system offers a practical solution to reduce reliance on operator experience in TCCD-based cerebrovascular screening, with potential applications in routine clinical workflows and resource-constrained settings. Future research will explore bilateral modeling and larger-scale validation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13874v1" target="_blank">A Comprehensive Re-Evaluation of Biometric Modality Properties in the Modern Era</a></h3>
                    <p><strong>Authors:</strong> Rouqaiah Al-Refai, Pankaja Priya Ramasamy, Ragini Ramesh, Patricia Arias-Cabarcos, Philipp Terh√∂rst</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> The rapid advancement of authentication systems and their increasing reliance on biometrics for faster and more accurate user verification experience, highlight the critical need for a reliable framework to evaluate the suitability of biometric modalities for specific applications. Currently, the most widely known evaluation framework is a comparative table from 1998, which no longer adequately captures recent technological developments or emerging vulnerabilities in biometric systems. To address these challenges, this work revisits the evaluation of biometric modalities through an expert survey involving 24 biometric specialists. The findings indicate substantial shifts in property ratings across modalities. For example, face recognition, shows improved ratings due to technological progress, while fingerprint, shows decreased reliability because of emerging vulnerabilities and attacks. Further analysis of expert agreement levels across rated properties highlighted the consistency of the provided evaluations and ensured the reliability of the ratings. Finally, expert assessments are compared with dataset-level uncertainty across 55 biometric datasets, revealing strong alignment in most modalities and underscoring the importance of integrating empirical evidence with expert insight. Moreover, the identified expert disagreements reveal key open challenges and help guide future research toward resolving them.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13872v1" target="_blank">RED.AI Id-Pattern: First Results of Stone Deterioration Patterns with Multi-Agent Systems</a></h3>
                    <p><strong>Authors:</strong> Daniele Corradetti, Jos√© Delgado Rodrigues</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.MA, I.2.11; I.5.4</p>
                    <p><strong>Summary:</strong> The Id-Pattern system within the RED.AI project (Reabilita\c{c}\~ao Estrutural Digital atrav\es da AI) consists of an agentic system designed to assist in the identification of stone deterioration patterns. Traditional methodologies, based on direct observation by expert teams, are accurate but costly in terms of time and resources. The system developed here introduces and evaluates a multi-agent artificial intelligence (AI) system, designed to simulate collaboration between experts and automate the diagnosis of stone pathologies from visual evidence. The approach is based on a cognitive architecture that orchestrates a team of specialized AI agents which, in this specific case, are limited to five: a lithologist, a pathologist, an environmental expert, a conservator-restorer, and a diagnostic coordinator. To evaluate the system we selected 28 difficult images involving multiple deterioration patterns. Our first results showed a huge boost on all metrics of our system compared to the foundational model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13870v1" target="_blank">Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate</a></h3>
                    <p><strong>Authors:</strong> Jiazheng Jing, Yinan Zhang, Chunyan Miao</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> The recent emergence of extreme climate events has significantly raised awareness about sustainable living. In addition to developing energy-saving materials and technologies, existing research mainly relies on traditional methods that encourage behavioral shifts towards sustainability, which can be overly demanding or only passively engaging. In this work, we propose to employ recommendation systems to actively nudge users toward more sustainable choices. We introduce Green Recommender Aligned with Personalized Eating (GRAPE), which is designed to prioritize and recommend sustainable food options that align with users evolving preferences. We also design two innovative Green Loss functions that cater to green indicators with either uniform or differentiated priorities, thereby enhancing adaptability across a range of scenarios. Extensive experiments on a real-world dataset demonstrate the effectiveness of our GRAPE.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13867v1" target="_blank">OpenLB-UQ: An Uncertainty Quantification Framework for Incompressible Fluid Flow Simulations</a></h3>
                    <p><strong>Authors:</strong> Mingliang Zhong, Adrian Kummerl√§nder, Shota Ito, Mathias J. Krause, Martin Frank, Stephan Simonis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, cs.MS, cs.NA, math.NA, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Uncertainty quantification (UQ) is crucial in computational fluid dynamics to assess the reliability and robustness of simulations, given the uncertainties in input parameters. OpenLB is an open-source lattice Boltzmann method library designed for efficient and extensible simulations of complex fluid dynamics on high-performance computers. In this work, we leverage the efficiency of OpenLB for large-scale flow sampling with a dedicated and integrated UQ module. To this end, we focus on non-intrusive stochastic collocation methods based on generalized polynomial chaos and Monte Carlo sampling. The OpenLB-UQ framework is extensively validated in convergence tests with respect to statistical metrics and sample efficiency using selected benchmark cases, including two-dimensional Taylor--Green vortex flows with up to four-dimensional uncertainty and a flow past a cylinder. Our results confirm the expected convergence rates and show promising scalability, demonstrating robust statistical accuracy as well as computational efficiency. OpenLB-UQ enhances the capability of the OpenLB library, offering researchers a scalable framework for UQ in incompressible fluid flow simulations and beyond.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13866v1" target="_blank">SAGA: Learning Signal-Aligned Distributions for Improved Text-to-Image Generation</a></h3>
                    <p><strong>Authors:</strong> Paul Grimal, Micha√´l Soumm, Herv√© Le Borgne, Olivier Ferret, Akihiro Sugimoto</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> State-of-the-art text-to-image models produce visually impressive results but often struggle with precise alignment to text prompts, leading to missing critical elements or unintended blending of distinct concepts. We propose a novel approach that learns a high-success-rate distribution conditioned on a target prompt, ensuring that generated images faithfully reflect the corresponding prompts. Our method explicitly models the signal component during the denoising process, offering fine-grained control that mitigates over-optimization and out-of-distribution artifacts. Moreover, our framework is training-free and seamlessly integrates with both existing diffusion and flow matching architectures. It also supports additional conditioning modalities -- such as bounding boxes -- for enhanced spatial alignment. Extensive experiments demonstrate that our approach outperforms current state-of-the-art methods. The code is available at https://github.com/grimalPaul/gsn-factory.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13848v1" target="_blank">Add-On Regimes and Their Relevance for Quantifying the Effects of Opioid-Sparing Treatments</a></h3>
                    <p><strong>Authors:</strong> Catharina Stoltenberg, Matias Janvin, Mats Julius Stensrud, Leiv Arne Rosseland, Jon Michael Gran</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> stat.AP</p>
                    <p><strong>Summary:</strong> Medical researchers and practitioners want to know if supplementing opioid treatments with other analgesics, such as nonsteroidal anti-inflammatory drugs (NSAIDs), can reduce opioid consumption. However, quantifying opioid-sparing effects is challenging; even coming up with a policy-relevant estimand requires care. We propose defining these effects in terms of add-on regimes. An add-on regime assigns NSAIDs over time based on the opioid and NSAID treatments a patient would naturally take without any intervention. The regime uses the physicians decision to administer opioids as a clinically meaningful, and practically feasible, indication for NSAID administration. In contrast, static regimes assign NSAIDs at predefined time points, regardless of clinical context. When opioids are not administered, the add-on regime requires no intervention, thereby preserving the natural level of NSAIDs. This differs from conventional dynamic regimes, which define treatment decisions at every time point during the treatment period. We identify the effect of add-on regimes under assumptions that are easier to assess than those used in existing methods. Finally, we apply the methods to estimate opioid-sparing effects of NSAIDs in a cohort of Norwegian trauma patients using national registry data.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746252.3761170" target="_blank">UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion</a></h3>
                    <p><strong>Authors:</strong> Zihan Liang, Yufei Ma, ZhiPeng Qian, Huangyu Dai, Zihan Wang, Ben Chen, Chenyi Lei, Yuqing Ding, Han Li</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI</p>
                    <p><strong>Summary:</strong> Current e-commerce multimodal retrieval systems face two key limitations: they optimize for specific tasks with fixed modality pairings, and lack comprehensive benchmarks for evaluating unified retrieval approaches. To address these challenges, we introduce UniECS, a unified multimodal e-commerce search framework that handles all retrieval scenarios across image, text, and their combinations. Our work makes three key contributions. First, we propose a flexible architecture with a novel gated multimodal encoder that uses adaptive fusion mechanisms. This encoder integrates different modality representations while handling missing modalities. Second, we develop a comprehensive training strategy to optimize learning. It combines cross-modal alignment loss (CMAL), cohesive local alignment loss (CLAL), intra-modal contrastive loss (IMCL), and adaptive loss weighting. Third, we create M-BEER, a carefully curated multimodal benchmark containing 50K product pairs for e-commerce search evaluation. Extensive experiments demonstrate that UniECS consistently outperforms existing methods across four e-commerce benchmarks with fine-tuning or zero-shot evaluation. On our M-BEER bench, UniECS achieves substantial improvements in cross-modal tasks (up to 28\% gain in R@10 for text-to-image retrieval) while maintaining parameter efficiency (0.2B parameters) compared to larger models like GME-Qwen2VL (2B) and MM-Embed (8B). Furthermore, we deploy UniECS in the e-commerce search platform of Kuaishou Inc. across two search scenarios, achieving notable improvements in Click-Through Rate (+2.74\%) and Revenue (+8.33\%). The comprehensive evaluation demonstrates the effectiveness of our approach in both experimental and real-world settings. Corresponding codes, models and datasets will be made publicly available at https://github.com/qzp2018/UniECS.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14041v1" target="_blank">LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos</a></h3>
                    <p><strong>Authors:</strong> Chin-Yang Lin, Cheng Sun, Fu-En Yang, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> LongSplat addresses critical challenges in novel view synthesis (NVS) from casually captured long videos characterized by irregular camera motion, unknown camera poses, and expansive scenes. Current methods often suffer from pose drift, inaccurate geometry initialization, and severe memory limitations. To address these issues, we introduce LongSplat, a robust unposed 3D Gaussian Splatting framework featuring: (1) Incremental Joint Optimization that concurrently optimizes camera poses and 3D Gaussians to avoid local minima and ensure global consistency; (2) a robust Pose Estimation Module leveraging learned 3D priors; and (3) an efficient Octree Anchor Formation mechanism that converts dense point clouds into anchors based on spatial density. Extensive experiments on challenging benchmarks demonstrate that LongSplat achieves state-of-the-art results, substantially improving rendering quality, pose accuracy, and computational efficiency compared to prior approaches. Project page: https://linjohnss.github.io/longsplat/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14040v1" target="_blank">ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents</a></h3>
                    <p><strong>Authors:</strong> Hanyu Lai, Xiao Liu, Yanxiao Zhao, Han Xu, Hanchen Zhang, Bohao Jing, Yanyu Ren, Shuntian Yao, Yuxiao Dong, Jie Tang</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We introduce ComputerRL, a framework for autonomous desktop intelligence that enables agents to operate complex digital workspaces skillfully. ComputerRL features the API-GUI paradigm, which unifies programmatic API calls and direct GUI interaction to address the inherent mismatch between machine agents and human-centric desktop environments. Scaling end-to-end RL training is crucial for improvement and generalization across diverse desktop tasks, yet remains challenging due to environmental inefficiency and instability in extended training. To support scalable and robust training, we develop a distributed RL infrastructure capable of orchestrating thousands of parallel virtual desktop environments to accelerate large-scale online RL. Furthermore, we propose Entropulse, a training strategy that alternates reinforcement learning with supervised fine-tuning, effectively mitigating entropy collapse during extended training runs. We employ ComputerRL on open models GLM-4-9B-0414 and Qwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B based on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%, demonstrating significant improvements for general agents in desktop automation. The algorithm and framework are adopted in building AutoGLM (Liu et al., 2024a)</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14039v1" target="_blank">Beyond Simple Edits: Composed Video Retrieval with Dense Modifications</a></h3>
                    <p><strong>Authors:</strong> Omkar Thawakar, Dmitry Demidov, Ritesh Thawkar, Rao Muhammad Anwer, Mubarak Shah, Fahad Shahbaz Khan, Salman Khan</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Composed video retrieval is a challenging task that strives to retrieve a target video based on a query video and a textual description detailing specific modifications. Standard retrieval frameworks typically struggle to handle the complexity of fine-grained compositional queries and variations in temporal understanding limiting their retrieval ability in the fine-grained setting. To address this issue, we introduce a novel dataset that captures both fine-grained and composed actions across diverse video segments, enabling more detailed compositional changes in retrieved video content. The proposed dataset, named Dense-WebVid-CoVR, consists of 1.6 million samples with dense modification text that is around seven times more than its existing counterpart. We further develop a new model that integrates visual and textual information through Cross-Attention (CA) fusion using grounded text encoder, enabling precise alignment between dense query modifications and target videos. The proposed model achieves state-of-the-art results surpassing existing methods on all metrics. Notably, it achieves 71.3\% Recall@1 in visual+text setting and outperforms the state-of-the-art by 3.4\%, highlighting its efficacy in terms of leveraging detailed video descriptions and dense modification texts. Our proposed dataset, code, and model are available at :https://github.com/OmkarThawakar/BSE-CoVR</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14037v1" target="_blank">Distilled-3DGS:Distilled 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Lintao Xiang, Xinkai Chen, Jianhuang Lai, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D Gaussian Splatting (3DGS) has exhibited remarkable efficacy in novel view synthesis (NVS). However, it suffers from a significant drawback: achieving high-fidelity rendering typically necessitates a large number of 3D Gaussians, resulting in substantial memory consumption and storage requirements. To address this challenge, we propose the first knowledge distillation framework for 3DGS, featuring various teacher models, including vanilla 3DGS, noise-augmented variants, and dropout-regularized versions. The outputs of these teachers are aggregated to guide the optimization of a lightweight student model. To distill the hidden geometric structure, we propose a structural similarity loss to boost the consistency of spatial geometric distributions between the student and teacher model. Through comprehensive quantitative and qualitative evaluations across diverse datasets, the proposed Distilled-3DGS, a simple yet effective framework without bells and whistles, achieves promising rendering results in both rendering quality and storage efficiency compared to state-of-the-art methods. Project page: https://distilled3dgs.github.io . Code: https://github.com/lt-xiang/Distilled-3DGS .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14036v1" target="_blank">GeoSAM2: Unleashing the Power of SAM2 for 3D Part Segmentation</a></h3>
                    <p><strong>Authors:</strong> Ken Deng, Yunhan Yang, Jingxiang Sun, Xihui Liu, Yebin Liu, Ding Liang, Yan-Pei Cao</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Modern 3D generation methods can rapidly create shapes from sparse or single views, but their outputs often lack geometric detail due to computational constraints. We present DetailGen3D, a generative approach specifically designed to enhance these generated 3D shapes. Our key insight is to model the coarse-to-fine transformation directly through data-dependent flows in latent space, avoiding the computational overhead of large-scale 3D generative models. We introduce a token matching strategy that ensures accurate spatial correspondence during refinement, enabling local detail synthesis while preserving global structure. By carefully designing our training data to match the characteristics of synthesized coarse shapes, our method can effectively enhance shapes produced by various 3D generation and reconstruction approaches, from single-view to sparse multi-view inputs. Extensive experiments demonstrate that DetailGen3D achieves high-fidelity geometric detail synthesis while maintaining efficiency in training.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14034v1" target="_blank">Photoinduced Frustration Modulation in $Œ∫$-type Quantum Spin Liquid Candidates</a></h3>
                    <p><strong>Authors:</strong> M. Tepie, F. Glerean, J. Ovƒçar, S. Priya, K. Miyagawa, H. Taniguchi, K. Kanoda, I. Lonƒçariƒá, M. Dressel, M. Mitrano</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mtrl-sci, cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> Geometric frustration is a key parameter controlling electronic and magnetic properties of quantum spin liquid systems, yet remains challenging to tune. Here, we coherently drive molecular vibrations with midinfrared pulses in two organic quantum spin liquid candidates, the insulating $\kappa$-(BEDT-TTF)$_2$Cu$_2$(CN)$_3$ and the metallic $\kappa$-(BEDT-TTF)$_4$Hg$_{2.89}$Br$_8$, and probe their electronic response through ultrafast reflectivity measurements. We observe a nonlinear coupling between local molecular vibrations and nonlocal phonons, which is expected to directly modulate the geometric frustration of their triangular lattice. Our findings establish a promising route to dynamically control frustration in nonbipartite quantum materials.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14033v1" target="_blank">InfiniteTalk: Audio-driven Video Generation for Sparse-Frame Video Dubbing</a></h3>
                    <p><strong>Authors:</strong> Shaoshu Yang, Zhe Kong, Feng Gao, Meng Cheng, Xiangyu Liu, Yong Zhang, Zhuoliang Kang, Wenhan Luo, Xunliang Cai, Ran He, Xiaoming Wei</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent breakthroughs in video AIGC have ushered in a transformative era for audio-driven human animation. However, conventional video dubbing techniques remain constrained to mouth region editing, resulting in discordant facial expressions and body gestures that compromise viewer immersion. To overcome this limitation, we introduce sparse-frame video dubbing, a novel paradigm that strategically preserves reference keyframes to maintain identity, iconic gestures, and camera trajectories while enabling holistic, audio-synchronized full-body motion editing. Through critical analysis, we identify why naive image-to-video models fail in this task, particularly their inability to achieve adaptive conditioning. Addressing this, we propose InfiniteTalk, a streaming audio-driven generator designed for infinite-length long sequence dubbing. This architecture leverages temporal context frames for seamless inter-chunk transitions and incorporates a simple yet effective sampling strategy that optimizes control strength via fine-grained reference frame positioning. Comprehensive evaluations on HDTF, CelebV-HQ, and EMTD datasets demonstrate state-of-the-art performance. Quantitative metrics confirm superior visual realism, emotional coherence, and full-body motion synchronization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14032v1" target="_blank">The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities</a></h3>
                    <p><strong>Authors:</strong> Xiancheng Li, Georgios D. Karampatakis, Helen E. Wood, Chris J. Griffiths, Borislava Mihaylova, Neil S. Coulson, Alessio Pasinato, Pietro Panzarasa, Marco Viviani, Anna De Simoni</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Digital health analytics face critical challenges nowadays. The sophisticated analysis of patient-generated health content, which contains complex emotional and medical contexts, requires scarce domain expertise, while traditional ML approaches are constrained by data shortage and privacy limitations in healthcare settings. Online Health Communities (OHCs) exemplify these challenges with mixed-sentiment posts, clinical terminology, and implicit emotional expressions that demand specialised knowledge for accurate Sentiment Analysis (SA). To address these challenges, this study explores how Large Language Models (LLMs) can integrate expert knowledge through in-context learning for SA, providing a scalable solution for sophisticated health data analysis. Specifically, we develop a structured codebook that systematically encodes expert interpretation guidelines, enabling LLMs to apply domain-specific knowledge through targeted prompting rather than extensive training. Six GPT models validated alongside DeepSeek and LLaMA 3.1 are compared with pre-trained language models (BioBERT variants) and lexicon-based methods, using 400 expert-annotated posts from two OHCs. LLMs achieve superior performance while demonstrating expert-level agreement. This high agreement, with no statistically significant difference from inter-expert agreement levels, suggests knowledge integration beyond surface-level pattern recognition. The consistent performance across diverse LLM models, supported by in-context learning, offers a promising solution for digital health analytics. This approach addresses the critical challenge of expert knowledge shortage in digital health research, enabling real-time, expert-quality analysis for patient monitoring, intervention assessment, and evidence-based health strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14031v1" target="_blank">Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation</a></h3>
                    <p><strong>Authors:</strong> Dongyoon Hahm, Taywon Min, Woogyeol Jin, Kimin Lee</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Beyond simple text generation, Large Language Models (LLMs) have evolved into agentic systems capable of planning and interacting with external tools to solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific tasks to enhance their proficiency. However, safety concerns are frequently overlooked during this fine-tuning process. In this work, we show that aligned LLMs can become unintentionally misaligned, leading to a higher likelihood of executing harmful tasks and a reduced tendency to refuse them when fine-tuned to execute agentic tasks. To address these safety challenges, we propose Prefix INjection Guard (PING), a simple yet effective method that prepends automatically generated natural language prefixes to agent responses, guiding them to refuse harmful requests while preserving performance on benign tasks. Specifically, we introduce an iterative approach that alternates between (1) generating candidate prefixes and (2) selecting those that optimize both task performance and refusal behavior. Experimental results demonstrate that PING significantly enhances the safety of fine-tuned LLM agents without sacrificing their effectiveness. PING consistently outperforms existing prompting approaches across diverse benchmarks in both web navigation and code generation tasks. Our analysis of internal hidden states via linear probes reveals that prefix tokens are crucial for behavior modification, explaining the performance gains. WARNING: This paper contains contents that are unethical or offensive in nature.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14029v1" target="_blank">Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR</a></h3>
                    <p><strong>Authors:</strong> Xiao Liang, Zhongzhi Li, Yeyun Gong, Yelong Shen, Ying Nian Wu, Zhijiang Guo, Weizhu Chen</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a key paradigm for post-training Large Language Models (LLMs), particularly for complex reasoning tasks. However, vanilla RLVR training has been shown to improve Pass@1 performance at the expense of policy entropy, leading to reduced generation diversity and limiting the Pass@k performance, which typically represents the upper bound of LLM reasoning capability. In this paper, we systematically analyze the policys generation diversity from the perspective of training problems and find that augmenting and updating training problems helps mitigate entropy collapse during training. Based on these observations, we propose an online Self-play with Variational problem Synthesis (SvS) strategy for RLVR training, which uses the policys correct solutions to synthesize variational problems while ensuring their reference answers remain identical to the originals. This self-improving strategy effectively maintains policy entropy during training and substantially improves Pass@k compared with standard RLVR, sustaining prolonged improvements and achieving absolute gains of 18.3% and 22.8% in Pass@32 performance on the competition-level AIME24 and AIME25 benchmarks. Experiments on 12 reasoning benchmarks across varying model sizes from 3B to 32B consistently demonstrate the generalizability and robustness of SvS.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14028v1" target="_blank">Trust and Reputation in Data Sharing: A Survey</a></h3>
                    <p><strong>Authors:</strong> Wenbo Wu, George Konstantinidis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.SI, cs.CY, cs.IR</p>
                    <p><strong>Summary:</strong> Data sharing is the fuel of the galloping artificial intelligence economy, providing diverse datasets for training robust models. Trust between data providers and data consumers is widely considered one of the most important factors for enabling data sharing initiatives. Concerns about data sensitivity, privacy breaches, and misuse contribute to reluctance in sharing data across various domains. In recent years, there has been a rise in technological and algorithmic solutions to measure, capture and manage trust, trustworthiness, and reputation in what we collectively refer to as Trust and Reputation Management Systems (TRMSs). Such approaches have been developed and applied to different domains of computer science, such as autonomous vehicles, or IoT networks, but there have not been dedicated approaches to data sharing and its unique characteristics. In this survey, we examine TRMSs from a data-sharing perspective, analyzing how they assess the trustworthiness of both data and entities across different environments. We develop novel taxonomies for system designs, trust evaluation framework, and evaluation metrics for both data and entity, and we systematically analyze the applicability of existing TRMSs in data sharing. Finally, we identify open challenges and propose future research directions to enhance the explainability, comprehensiveness, and accuracy of TRMSs in large-scale data-sharing ecosystems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14025v1" target="_blank">Ask Good Questions for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Qi Wu, Zhongqi Lu</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in large language models (LLMs) have significantly improved the performance of dialog systems, yet current approaches often fail to provide accurate guidance of topic due to their inability to discern user confusion in related concepts. To address this, we introduce the Ask-Good-Question (AGQ) framework, which features an improved Concept-Enhanced Item Response Theory (CEIRT) model to better identify users knowledge levels. Our contributions include applying the CEIRT model along with LLMs to directly generate guiding questions based on the inspiring text, greatly improving information retrieval efficiency during the question  answer process. Through comparisons with other baseline methods, our approach outperforms by significantly enhencing the users information retrieval experiences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14024v1" target="_blank">UNICON: UNIfied CONtinual Learning for Medical Foundational Models</a></h3>
                    <p><strong>Authors:</strong> Mohammad Areeb Qazi, Munachiso S Nwadike, Ibrahim Almakky, Mohammad Yaqub, Numan Saeed</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Foundational models are trained on extensive datasets to capture the general trends of a domain. However, in medical imaging, the scarcity of data makes pre-training for every domain, modality, or task challenging. Continual learning offers a solution by fine-tuning a model sequentially on different domains or tasks, enabling it to integrate new knowledge without requiring large datasets for each training phase. In this paper, we propose UNIfied CONtinual Learning for Medical Foundational Models (UNICON), a framework that enables the seamless adaptation of foundation models to diverse domains, tasks, and modalities. Unlike conventional adaptation methods that treat these changes in isolation, UNICON provides a unified, perpetually expandable framework. Through careful integration, we show that foundation models can dynamically expand across imaging modalities, anatomical regions, and clinical objectives without catastrophic forgetting or task interference. Empirically, we validate our approach by adapting a chest CT foundation model initially trained for classification to a prognosis and segmentation task. Our results show improved performance across both additional tasks. Furthermore, we continually incorporated PET scans and achieved a 5\% improvement in Dice score compared to respective baselines. These findings establish that foundation models are not inherently constrained to their initial training scope but can evolve, paving the way toward generalist AI models for medical imaging.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14022v1" target="_blank">BLIPs: Bayesian Learned Interatomic Potentials</a></h3>
                    <p><strong>Authors:</strong> Dario Coscia, Pim de Haan, Max Welling</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Machine Learning Interatomic Potentials (MLIPs) are becoming a central tool in simulation-based chemistry. However, like most deep learning models, MLIPs struggle to make accurate predictions on out-of-distribution data or when trained in a data-scarce regime, both common scenarios in simulation-based chemistry. Moreover, MLIPs do not provide uncertainty estimates by construction, which are fundamental to guide active learning pipelines and to ensure the accuracy of simulation results compared to quantum calculations. To address this shortcoming, we propose BLIPs: Bayesian Learned Interatomic Potentials. BLIP is a scalable, architecture-agnostic variational Bayesian framework for training or fine-tuning MLIPs, built on an adaptive version of Variational Dropout. BLIP delivers well-calibrated uncertainty estimates and minimal computational overhead for energy and forces prediction at inference time, while integrating seamlessly with (equivariant) message-passing architectures. Empirical results on simulation-based computational chemistry tasks demonstrate improved predictive accuracy with respect to standard MLIPs, and trustworthy uncertainty estimates, especially in data-scarse or heavy out-of-distribution regimes. Moreover, fine-tuning pretrained MLIPs with BLIP yields consistent performance gains and calibrated uncertainties.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14020v1" target="_blank">A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem</a></h3>
                    <p><strong>Authors:</strong> Christian Blum, Pedro Pinacho-Davidson</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.DM, 68T01, I.2.8</p>
                    <p><strong>Summary:</strong> The longest run subsequence (LRS) problem is an NP-hard combinatorial optimization problem belonging to the class of subsequence problems from bioinformatics. In particular, the problem plays a role in genome reassembly. In this paper, we present a solution to the LRS problem using a Biased Random Key Genetic Algorithm (BRKGA). Our approach places particular focus on the computational efficiency of evaluating individuals, which involves converting vectors of gray values into valid solutions to the problem. For comparison purposes, a Max-Min Ant System is developed and implemented. This is in addition to the application of the integer linear programming solver CPLEX for solving all considered problem instances. The computation results show that the proposed BRKGA is currently a state-of-the-art technique for the LRS problem. Nevertheless, the results also show that there is room for improvement, especially in the context of input strings based on large alphabet sizes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14017v1" target="_blank">Analog computation with transcriptional networks</a></h3>
                    <p><strong>Authors:</strong> David Doty, Mina Latifi, David Soloveichick</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CC, cs.DC, cs.ET</p>
                    <p><strong>Summary:</strong> Transcriptional networks represent one of the most extensively studied types of systems in synthetic biology. Although the completeness of transcriptional networks for digital logic is well-established, *analog* computation plays a crucial role in biological systems and offers significant potential for synthetic biology applications. While transcriptional circuits typically rely on cooperativity and highly non-linear behavior of transcription factors to regulate *production* of proteins, they are often modeled with simple linear *degradation* terms. In contrast, general analog dynamics require both non-linear positive as well as negative terms, seemingly necessitating control over not just transcriptional (i.e., production) regulation but also the degradation rates of transcription factors. Surprisingly, we prove that controlling transcription factor production (i.e., transcription rate) without explicitly controlling degradation is mathematically complete for analog computation, achieving equivalent capabilities to systems where both production and degradation are programmable. We demonstrate our approach on several examples including oscillatory and chaotic dynamics, analog sorting, memory, PID controller, and analog extremum seeking. Our result provides a systematic methodology for engineering novel analog dynamics using synthetic transcriptional networks without the added complexity of degradation control and informs our understanding of the capabilities of natural transcriptional circuits. We provide a compiler, in the form of a Python package that can take any system of polynomial ODEs and convert it to an equivalent transcriptional network implementing the system *exactly*, under appropriate conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14015v1" target="_blank">Backdooring Self-Supervised Contrastive Learning by Noisy Alignment</a></h3>
                    <p><strong>Authors:</strong> Tuo Chen, Jie Gui, Minjing Dong, Ju Jia, Lanting Fang, Jian Liu</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Self-supervised contrastive learning (CL) effectively learns transferable representations from unlabeled data containing images or image-text pairs but suffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary can inject poisoned images into pretraining datasets, causing compromised CL encoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs, however, achieve limited efficacy due to their dependence on fragile implicit co-occurrence between backdoor and target object and inadequate suppression of discriminative features in backdoored images. We propose Noisy Alignment (NA), a DPCL method that explicitly suppresses noise components in poisoned images. Inspired by powerful training-controllable CL attacks, we identify and extract the critical objective of noisy alignment, adapting it effectively into data-poisoning scenarios. Our method implements noisy alignment by strategically manipulating contrastive learnings random cropping mechanism, formulating this process as an image layout optimization problem with theoretically derived optimal parameters. The resulting method is simple yet effective, achieving state-of-the-art performance compared to existing DPCLs, while maintaining clean-data accuracy. Furthermore, Noisy Alignment demonstrates robustness against common backdoor defenses. Codes can be found at https://github.com/jsrdcht/Noisy-Alignment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14014v1" target="_blank">Online 3D Gaussian Splatting Modeling with Novel View Selection</a></h3>
                    <p><strong>Authors:</strong> Byeonggwon Lee, Junkyu Park, Khang Truong Giang, Soohwan Song</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This study addresses the challenge of generating online 3D Gaussian Splatting (3DGS) models from RGB-only frames. Previous studies have employed dense SLAM techniques to estimate 3D scenes from keyframes for 3DGS model construction. However, these methods are limited by their reliance solely on keyframes, which are insufficient to capture an entire scene, resulting in incomplete reconstructions. Moreover, building a generalizable model requires incorporating frames from diverse viewpoints to achieve broader scene coverage. However, online processing restricts the use of many frames or extensive training iterations. Therefore, we propose a novel method for high-quality 3DGS modeling that improves model completeness through adaptive view selection. By analyzing reconstruction quality online, our approach selects optimal non-keyframes for additional training. By integrating both keyframes and selected non-keyframes, the method refines incomplete regions from diverse viewpoints, significantly enhancing completeness. We also present a framework that incorporates an online multi-view stereo approach, ensuring consistency in 3D information throughout the 3DGS modeling process. Experimental results demonstrate that our method outperforms state-of-the-art methods, delivering exceptional performance in complex outdoor scenes.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746252.3761379" target="_blank">Efficient Knowledge Graph Unlearning with Zeroth-order Information</a></h3>
                    <p><strong>Authors:</strong> Yang Xiao, Ruimeng Ye, Bohan Liu, Xiaolong Ma, Bo Hui</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Due to regulations like the Right to be Forgotten, there is growing demand for removing training data and its influence from models. Since full retraining is costly, various machine unlearning methods have been proposed. In this paper, we firstly present an efficient knowledge graph (KG) unlearning algorithm. We remark that KG unlearning is nontrivial due to the distinctive structure of KG and the semantic relations between entities. Also, unlearning by estimating the influence of removed components incurs significant computational overhead when applied to large-scale knowledge graphs. To this end, we define an influence function for KG unlearning and propose to approximate the models sensitivity without expensive computation of first-order and second-order derivatives for parameter updates. Specifically, we use Taylor expansion to estimate the parameter changes caused by data removal. Given that the first-order gradients and second-order derivatives dominate the computational load, we use the Fisher matrices and zeroth-order optimization to approximate the inverse-Hessian vector product without constructing the computational graphs. Our experimental results demonstrate that the proposed method outperforms other state-of-the-art graph unlearning baselines significantly in terms of unlearning efficiency and unlearning quality. Our code is released at https://github.com/NKUShaw/ZOWFKGIF.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14011v1" target="_blank">Brace for impact: ECDLP challenges for quantum cryptanalysis</a></h3>
                    <p><strong>Authors:</strong> Pierre-Luc Dallaire-Demers, William Doyle, Timothy Foo</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Precise suites of benchmarks are required to assess the progress of early fault-tolerant quantum computers at economically impactful applications such as cryptanalysis. Appropriate challenges exist for factoring but those for elliptic curve cryptography are either too sparse or inadequate for standard applications of Shors algorithm. We introduce a difficulty-graded suite of elliptic curve discrete logarithm (ECDLP) challenges that use Bitcoins curve $y^{2}=x^{3}+7 \pmod p$ while incrementally lowering the prime field from 256 down to 6 bits. For each bit-length, we provide the prime, the base point and an example public key. All challenges are generated by a deterministic, reproducible procedure. We calibrate classical cost against Pollards rho records and quantum cost against resource estimation results for Shors algorithm. We compile Shors ECDLP circuit to logical counts and map them to physical resources for various parameters of the surface code, the repetition cat code and the LDPC cat codes. Under explicit and testable assumptions on physical error rates, code distances, and non-Clifford supply, our scenarios place the full 256-bit instance within a 2027--2033 window. The challenge ladder thus offers a transparent ruler to track fault-tolerant progress on a cryptanalytic target of immediate relevance, and it motivates proactive migration of digital assets to post-quantum signatures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14010v1" target="_blank">Regular AdS$_3$ black holes from regularized Gauss-Bonnet coupling</a></h3>
                    <p><strong>Authors:</strong> Gokhan Alkac, Murat Mesta, Gonul Unal</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> We obtain a three-dimensional bi-vector-tensor theory of the generalized Proca class by regularizing the Gauss-Bonnet invariant within the Weyl geometry. We show that the theory admits a regular AdS$_3$ black hole solution with primary hairs. Introducing a deformation in the theory, a different regular AdS$_3$ black hole solution is obtained. Charged generalizations of these solutions are given by coupling to Born-Infeld electrodynamics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.14006v1" target="_blank">ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans</a></h3>
                    <p><strong>Authors:</strong> Mohamed Abouagour, Eleftherios Garyfallidis</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO, 68T45</p>
                    <p><strong>Summary:</strong> We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally rich, and realistic residential floor plans, created to advance spatial AI research. Each plan includes precise annotations of architectural elements (walls, doors, windows, balconies) and functional spaces (such as kitchens, bedrooms, and bathrooms). ResPlan addresses key limitations of existing datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024) by offering enhanced visual fidelity and greater structural diversity, reflecting realistic and non-idealized residential layouts. Designed as a versatile, general-purpose resource, ResPlan supports a wide range of applications including robotics, reinforcement learning, generative AI, virtual and augmented reality, simulations, and game development. Plans are provided in both geometric and graph-based formats, enabling direct integration into simulation engines and fast 3D conversion. A key contribution is an open-source pipeline for geometry cleaning, alignment, and annotation refinement. Additionally, ResPlan includes structured representations of room connectivity, supporting graph-based spatial reasoning tasks. Finally, we present comparative analyses with existing benchmarks and outline several open benchmark tasks enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale, realism, and usability, providing a robust foundation for developing and benchmarking next-generation spatial intelligence systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13995v1" target="_blank">Self-Supervised Sparse Sensor Fusion for Long Range Perception</a></h3>
                    <p><strong>Authors:</strong> Edoardo Palladin, Samuel Brucker, Filippo Ghilotti, Praveen Narayanan, Mario Bijelic, Felix Heide</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Outside of urban hubs, autonomous cars and trucks have to master driving on intercity highways. Safe, long-distance highway travel at speeds exceeding 100 km/h demands perception distances of at least 250 m, which is about five times the 50-100m typically addressed in city driving, to allow sufficient planning and braking margins. Increasing the perception ranges also allows to extend autonomy from light two-ton passenger vehicles to large-scale forty-ton trucks, which need a longer planning horizon due to their high inertia. However, most existing perception approaches focus on shorter ranges and rely on Birds Eye View (BEV) representations, which incur quadratic increases in memory and compute costs as distance grows. To overcome this limitation, we built on top of a sparse representation and introduced an efficient 3D encoding of multi-modal and temporal features, along with a novel self-supervised pre-training scheme that enables large-scale learning from unlabeled camera-LiDAR data. Our approach extends perception distances to 250 meters and achieves an 26.6% improvement in mAP in object detection and a decrease of 30.5% in Chamfer Distance in LiDAR forecasting compared to existing methods, reaching distances up to 250 meters. Project Page: https://light.princeton.edu/lrs4fusion/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13993v1" target="_blank">Chunks as Arms: Multi-Armed Bandit-Guided Sampling for Long-Context LLM Preference Optimization</a></h3>
                    <p><strong>Authors:</strong> Shaohua Duan, Xinze Li, Zhenghao Liu, Xiaoyuan Yi, Yukun Yan, Shuo Wang, Yu Gu, Ge Yu, Maosong Sun</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Long-context modeling is critical for a wide range of real-world tasks, including long-context question answering, summarization, and complex reasoning tasks. Recent studies have explored fine-tuning Large Language Models (LLMs) with synthetic data to enhance their long-context capabilities. However, the effectiveness of such approaches is often limited by the low diversity and factual inconsistencies in the generated data. To address these challenges, we propose LongMab-PO, a novel framework that leverages a Multi-Armed Bandit (MAB) rollout strategy to identify the most informative chunks from the given long context for sampling high-quality and diverse responses and constructing preference data pairs for Direct Preference Optimization (DPO) training. Specifically, we treat context chunks as arms of MAB, select chunks based on their expected reward scores to input into LLMs to generate responses, and iteratively update these scores based on reward feedback. This exploration and exploitation process enables the model to focus on the most relevant context segments, thereby generating and collecting high-quality and diverse responses. Finally, we collect these generated responses from the rollout process and apply the DPO method to further optimize the LLM. Experimental results show that LongMab-PO significantly improves the diversity and quality of preference data pairs, achieving state-of-the-art performance on long-context reasoning benchmarks. All code and data will be released on https://github.com/NEUIR/LongMab-PO.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.13989v1" target="_blank">Physics-Based 3D Simulation for Synthetic Data Generation and Failure Analysis in Packaging Stability Assessment</a></h3>
                    <p><strong>Authors:</strong> Samuel Seligardi, Pietro Musoni, Eleonora Iotti, Gianluca Contesso, Alessandro Dal Pal√π</p>
                    <p><strong>Published:</strong> 8/19/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The design and analysis of pallet setups are essential for ensuring safety of packages transportation. With rising demands in the logistics sector, the development of automated systems utilizing advanced technologies has become increasingly crucial. Moreover, the widespread use of plastic wrapping has motivated researchers to investigate eco-friendly alternatives that still adhere to safety standards. We present a fully controllable and accurate physical simulation system capable of replicating the behavior of moving pallets. It features a 3D graphics-based virtual environment that supports a wide range of configurations, including variable package layouts, different wrapping materials, and diverse dynamic conditions. This innovative approach reduces the need for physical testing, cutting costs and environmental impact while improving measurement accuracy for analyzing pallet dynamics. Additionally, we train a deep neural network to evaluate the rendered videos generated by our simulator, as a crash-test predictor for pallet configurations, further enhancing the systems utility in safety analysis.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

