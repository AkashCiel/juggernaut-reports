
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-12<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 120
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The landscape of AI safety research is witnessing significant developments across several dimensions, focusing on safety alignment, evaluation, and ethical considerations of AI technologies. A notable trend is the emphasis on understanding and mitigating alignment failures in AI systems, as seen in the introduction of tools like Jinx, which provide a platform for probing language models alignment issues by responding to all queries without safety filters. This approach aids in identifying areas where AI outputs might diverge from expected safe and ethical standards, thus informing further refinement of alignment strategies.

Another critical area of research involves evaluating the safety of AI in sensitive contexts, such as mental health. The PsyCrisis-Bench initiative exemplifies efforts to assess AI responses in high-risk dialogues, emphasizing the need for robust, context-aware safety measures. Additionally, the exploration of moral agency frameworks for AI integration in bureaucracies highlights the importance of maintaining accountability and transparency, preventing the ethical dissipation of responsibility. Furthermore, studies such as those on LLM-facilitated group decision-making and the use of AI in societal decision-making processes underscore the ongoing challenges and potential solutions for ensuring AI systems are aligned with human values and societal norms, emphasizing the importance of human oversight and structured, ethical integration in AI deployments. Collectively, these research efforts signify a concerted move towards developing AI systems that are not only powerful but also safe, transparent, and aligned with societal values.

*Based on 50 research papers*

---

## ai alignment research

The recent research papers on AI alignment explore diverse aspects of ensuring AI systems act in ways aligned with human values and safety. A significant trend is the development of tools and frameworks to probe and evaluate AI alignment, such as Jinx, which provides a helpful-only variant of language models to assess alignment failures without safety constraints. This offers a new avenue for studying the boundaries of model behavior and understanding alignment gaps. Similarly, the paper introducing PsyCrisis-Bench focuses on evaluating safety alignment in high-risk, sensitive settings like mental health dialogues, highlighting the importance of ensuring AI responses adhere to expert-defined safety principles. These efforts underscore the growing emphasis on robust evaluation and transparency in AI systems decision-making processes.

Another key area is the incorporation of ethical principles and moral agency into AI systems, as discussed in the framework for integrating AI into bureaucracies. This work advocates for clear lines of accountability and transparency, aiming to prevent the ethical pitfalls that arise when AI systems are misused or misunderstood. Additionally, the exploration of human-alignment and calibration in language models addresses the challenge of aligning AIs uncertainty measures with human-like reasoning, further illustrating the nuanced understanding required to bridge AI systems with human cognitive and moral frameworks. These studies collectively signify a move towards more accountable, transparent, and ethically aware AI systems, emphasizing the critical role of alignment research in deploying AI technologies responsibly.

*Based on 50 research papers*

---

## quantum computing

The recent research papers on quantum computing highlight several significant trends and breakthroughs that emphasize the fields rapid advancement and potential impact. A key trend is the exploration of non-Hermitian quantum systems, as demonstrated by the Observation of Metal-Insulator and Spectral Phase Transitions in Aubry-AndrÃ©-Harper Models, which investigates complex phase transitions and topological phenomena using single-photon quantum walks. This work advances our understanding of non-Hermitian quasicrystals, potentially impacting quantum materials and synthetic quantum matter studies.

Another notable trend is the development of frameworks and methods to enhance quantum simulations and fault tolerance. The Composable Quantum Fault-Tolerance paper introduces a framework that simplifies threshold proofs for fault-tolerant quantum computation, allowing for more flexible and rigorous analysis of quantum circuit correctness. Furthermore, the Quantum-centric simulation of hydrogen abstraction showcases the use of hybrid quantum-classical systems, leveraging techniques like entanglement forging to reduce qubit requirements in chemical simulations. These advancements underscore the growing capability of quantum computing to tackle complex simulations and enhance the reliability of quantum systems, paving the way for practical applications in fields like material science and cryptography.

*Based on 20 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.08252v1" target="_blank">ReferSplat: Referring Segmentation in 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Shuting He, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li, Henghui Ding</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task that aims to segment target objects in a 3D Gaussian scene based on natural language descriptions, which often contain spatial relationships or object attributes. This task requires the model to identify newly described objects that may be occluded or not directly visible in a novel view, posing a significant challenge for 3D multi-modal understanding. Developing this capability is crucial for advancing embodied AI. To support research in this area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that 3D multi-modal understanding and spatial relationship modeling are key challenges for R3DGS. To address these challenges, we propose ReferSplat, a framework that explicitly models 3D Gaussian points with natural language expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art performance on both the newly proposed R3DGS task and 3D open-vocabulary segmentation benchmarks. Dataset and code are available at https://github.com/heshuting555/ReferSplat.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08243v1" target="_blank">Jinx: Unlimited LLMs for Probing Alignment Failures</a></h3>
                    <p><strong>Authors:</strong> Jiahao Zhao, Liwei Dong</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Unlimited, or so-called helpful-only language models are trained without safety alignment constraints and never refuse user queries. They are widely used by leading AI companies as internal tools for red teaming and alignment evaluation. For example, if a safety-aligned model produces harmful outputs similar to an unlimited model, this indicates alignment failures that require further attention. Despite their essential role in assessing alignment, such models are not available to the research community. We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx responds to all queries without refusals or safety filtering, while preserving the base models capabilities in reasoning and instruction following. It provides researchers with an accessible tool for probing alignment failures, evaluating safety boundaries, and systematically studying failure modes in language model safety.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08242v1" target="_blank">Bringing Everyone to the Table: An Experimental Study of LLM-Facilitated Group Decision Making</a></h3>
                    <p><strong>Authors:</strong> Mohammed Alsobay, David M. Rothschild, Jake M. Hofman, Daniel G. Goldstein</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Group decision-making often suffers from uneven information sharing, hindering decision quality. While large language models (LLMs) have been widely studied as aids for individuals, their potential to support groups of users, potentially as facilitators, is relatively underexplored. We present a pre-registered randomized experiment with 1,475 participants assigned to 281 five-person groups completing a hidden profile task--selecting an optimal city for a hypothetical sporting event--under one of four facilitation conditions: no facilitation, a one-time message prompting information sharing, a human facilitator, or an LLM (GPT-4o) facilitator. We find that LLM facilitation increases information shared within a discussion by raising the minimum level of engagement with the task among group members, and that these gains come at limited cost in terms of participants attitudes towards the task, their group, or their facilitator. Whether by human or AI, there is no significant effect of facilitation on the final decision outcome, suggesting that even substantial but partial increases in information sharing are insufficient to overcome the hidden profile effect studied. To support further research into how LLM-based interfaces can support the future of collaborative decision making, we release our experimental platform, the Group-AI Interaction Laboratory (GRAIL), as an open-source tool.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08236v1" target="_blank">Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge</a></h3>
                    <p><strong>Authors:</strong> Yunna Cai, Fan Wang, Haowei Wang, Kun Wang, Kailai Yang, Sophia Ananiadou, Moyan Li, Mingming Fan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Evaluating the safety alignment of LLM responses in high-risk mental health dialogues is particularly difficult due to missing gold-standard answers and the ethically sensitive nature of these interactions. To address this challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark based on real-world Chinese mental health dialogues. It evaluates whether the model responses align with the safety principles defined by experts. Specifically designed for settings without standard references, our method adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation using expert-defined reasoning chains grounded in psychological intervention principles. We employ binary point-wise scoring across multiple safety dimensions to enhance the explainability and traceability of the evaluation. Additionally, we present a manually curated, high-quality Chinese-language dataset covering self-harm, suicidal ideation, and existential distress, derived from real-world online discourse. Experiments on 3600 judgments show that our method achieves the highest agreement with expert assessments and produces more interpretable evaluation rationales compared to existing approaches. Our dataset and evaluation tool are publicly available to facilitate further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08231v1" target="_blank">A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies</a></h3>
                    <p><strong>Authors:</strong> Chris Schmitz, Joanna Bryson</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Public-sector bureaucracies seek to reap the benefits of artificial intelligence (AI), but face important concerns about accountability and transparency when using AI systems. These concerns center on threats to the twin aims of bureaucracy: legitimate and faithful implementation of legislation, and the provision of stable, long-term governance. Both aims are threatened when AI systems are misattributed as either mere tools or moral subjects - a framing error that creates ethics sinks, constructs that facilitate dissipation of responsibility by obscuring clear lines of human moral agency. Here, we reject the notion that such outcomes are inevitable. Rather, where they appear, they are the product of structural design decisions across both the technology and the institution deploying it. We support this claim via a systematic application of conceptions of moral agency in AI ethics to Weberian bureaucracy. We establish that it is both desirable and feasible to render AI systems as tools for the generation of organizational transparency and legibility, which continue the processes of Weberian rationalization initiated by previous waves of digitalization. We present a three-point Moral Agency Framework for legitimate integration of AI in bureaucratic structures: (a) maintain clear and just human lines of accountability, (b) ensure humans whose work is augmented by AI systems can verify the systems are functioning correctly, and (c) introduce AI only where it doesnt inhibit the capacity of bureaucracies towards either of their twin aims of legitimacy and stewardship. We suggest that AI introduced within this framework can not only improve efficiency and productivity while avoiding ethics sinks, but also improve the transparency and even the legitimacy of a bureaucracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08230v1" target="_blank">Ultra-pure Nickel for Structural Components of Low-Radioactivity Instruments</a></h3>
                    <p><strong>Authors:</strong> T. J. Roosendaal, C. T. Overman, G. S. Ortega, T. D. Schlieder, N. D. Rocco, L. K. S. Horkley, K. P. Hobbs, K. Harouaka, J. L. Orrell, P. Acharya, A. Amy, E. Angelico, A. Anker, I. J. Arnquist, A. Atencio, J. Bane, V. Belov, E. P. Bernard, T. Bhatta, A. Bolotnikov, J. Breslin, P. A. Breur, J. P. Brodsky, E. Brown, T. Brunner, B. Burnell, E. Caden, L. Q. Cao, D. Cesmecioglu, S. A. Charlebois, D. Chernyak, M. Chiu, T. Daniels, L. Darroch, R. DeVoe, M. L. di Vacri, M. J. Dolinski, B. Eckert, M. Elbeltagi, A. Emara, W. Fairbank, B. T. Foust, D. Gallacher, N. Gallice, W. Gillis, A. Gorham, G. Gratta, C. A. Hardy, S. C. Hedges, M. Heffner, E. Hein, J. D. Holt, A. Iverson, A. Karelin, I. V. Kotov, A. Kuchenkov, A. Larson, M. B. Latif, S. Lavoie, K. G. Leach, B. G. Lenardo, D. S. Leonard, K. K. H. Leung, H. Lewis, X. Li, Z. Li, C. Licciardi, R. Lindsay, R. MacLellan, S. Majidi, C. Malbrunot, M. Marquis. J. Masbou, M. Medina-Peregrina, S. Mngonyama, B. Mong, D. C. Moore, X. E. Ngwadla, K. Ni, A. Nolan, S. C. Nowicki, J. C. Nzobadila Ondze, A. Odian, L. Pagani, H. Peltz Smalley, A. Pena-Perez, A. Piepke, A. Pocar, S. Prentice, V. Radeka, R. Rai, H. Rasiwala, D. Ray, S. Rescia, G. Richardson, V. Riot, R. Ross, P. C. Rowson, R. Saldanha, S. Sangiorgio, S. Sekula, T. Shetty, L. Si, J. Soderstrom, F. Spadoni, V. Stekhanov, X. L. Sun, S. Thibado, T. Totev, S. Triambak, R. H. M. Tsang, O. A. Tyuka, E. van Bruggen, M. Vidal, M. Walent, Y. G. Wang, Q. D. Wang, M. P. Watts, M. Wehrfritz, L. J. Wen, S. Wilde, M. Worcester, X. M. Wu, H. Xu, H. B. Yang, L. Yang, O. Zeldovich</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> nucl-ex</p>
                    <p><strong>Summary:</strong> The next generation of rare-event search experiments in nuclear and particle physics demand structural materials combining exceptional mechanical strength with ultra-low levels of radioactive contamination. This study evaluates chemical vapor deposition (CVD) nickel as a candidate structural material for such applications. Manufacturer-supplied CVD Ni grown on aluminum substrates underwent tensile testing before and after welding alongside standard Ni samples. CVD Ni exhibited a planar tensile strength of ~600 MPa, significantly surpassing standard nickel. However, welding and heat treatment were found to reduce the tensile strength to levels comparable to standard Ni, with observed porosity in the welds likely contributing to this reduction. Material assay via inductively coupled plasma mass spectrometry (ICP-MS) employing isotope-dilution produced measured bulk concentration of 232-Th, 238-U, and nat-K at the levels of ~70 ppq, 100 ppq, and ~900 ppt, respectively, which is the lowest reported in nickel. Surface-etch profiling uncovered higher concentrations of these contaminants extending ~10 micrometer beneath the surface, likely associated with the aluminum growth substrate. The results reported are compared to the one other well documented usage of CVD Ni in a low radioactive background physics research experiment and a discussion is provided on how the currently reported results may arise from changes in CVD fabrication or testing process. These results establish CVD Ni as a promising low-radioactivity structural material, while outlining the need for further development in welding and surface cleaning techniques to fully realize its potential in large-scale, low radioactive background rare-event search experiments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08226v1" target="_blank">Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy</a></h3>
                    <p><strong>Authors:</strong> Haiyue Chen, Aniket Datar, Tong Xu, Francesco Cancelliere, Harsh Rangwala, Madhan Balaji Rao, Daeun Song, David Eichinger, Xuesu Xiao</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Off-road navigation is an important capability for mobile robots deployed in environments that are inaccessible or dangerous to humans, such as disaster response or planetary exploration. Progress is limited due to the lack of a controllable and standardized real-world testbed for systematic data collection and validation. To fill this gap, we introduce Verti-Arena, a reconfigurable indoor facility designed specifically for off-road autonomy. By providing a repeatable benchmark environment, Verti-Arena supports reproducible experiments across a variety of vertically challenging terrains and provides precise ground truth measurements through onboard sensors and a motion capture system. Verti-Arena also supports consistent data collection and comparative evaluation of algorithms in off-road autonomy research. We also develop a web-based interface that enables research groups worldwide to remotely conduct standardized off-road autonomy experiments on Verti-Arena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08225v1" target="_blank">Industrial Viewpoints on RAN Technologies for 6G</a></h3>
                    <p><strong>Authors:</strong> Mansoor Shafi, Erik G. Larsson, Xingqin Lin, Dorin Panaitopol, Stefan Parkvall, Flavien Ronteix-Jacquet, Antti Toskala</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> 6G standardization is to start imminently, with commercial deployments expected before 2030. Its technical components and performance requirements are the focus of this article. Our emphasis is on the 6G radio access, especially MIMO, AI, waveforms, coding, signal constellations and integration with non-terrestrial networks. Whilst standardization has not yet formally started, the scope of the 6G study items has been defined. Our predictions in this paper are speculative as there are no results of the study yet, but our views are guided by implementation and deployment aspects. We expect that the views here will guide researchers and industry practitioners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08223v1" target="_blank">Photon Statistics for Fock and Coherent States Interfering in a Beamsplitter</a></h3>
                    <p><strong>Authors:</strong> Jhordan A. T. Santiago</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We present a straightforward yet comprehensive theoretical study of different quantum states emerging from a bi-modal beamsplitter when various input states interfere. Specifically, we analyze the output states for different combinations of input fields, including Fock states $|n\rangle|m\rangle$, hybrid states $|n\rangle|\alpha\rangle$, and coherent states $|\alpha\rangle|\beta\rangle$. We derive explicit expressions for the output state vectors, calculate the mean photon number, photon number variance, Mandel Q parameter, and secondorder coherence function to characterize the statistical properties of the output fields. Our results are intended as a pedagogical resource, serving as an introductory reference for students and researchers aiming to understand basic photon statistics using beamsplitters.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08221v1" target="_blank">Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning</a></h3>
                    <p><strong>Authors:</strong> Zihe Liu, Jiashun Liu, Yancheng He, Weixun Wang, Jiaheng Liu, Ling Pan, Xinyu Hu, Shaopan Xiong, Ju Huang, Jian Hu, Shengyi Huang, Siran Yang, Jiamang Wang, Wenbo Su, Bo Zheng</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement learning for LLM reasoning has rapidly emerged as a prominent research area, marked by a significant surge in related studies on both algorithmic innovations and practical applications. Despite this progress, several critical challenges remain, including the absence of standardized guidelines for employing RL techniques and a fragmented understanding of their underlying mechanisms. Additionally, inconsistent experimental settings, variations in training data, and differences in model initialization have led to conflicting conclusions, obscuring the key characteristics of these techniques and creating confusion among practitioners when selecting appropriate techniques. This paper systematically reviews widely adopted RL techniques through rigorous reproductions and isolated evaluations within a unified open-source framework. We analyze the internal mechanisms, applicable scenarios, and core principles of each technique through fine-grained experiments, including datasets of varying difficulty, model sizes, and architectures. Based on these insights, we present clear guidelines for selecting RL techniques tailored to specific setups, and provide a reliable roadmap for practitioners navigating the RL for the LLM domain. Finally, we reveal that a minimalist combination of two techniques can unlock the learning capability of critic-free policies using vanilla PPO loss. The results demonstrate that our simple combination consistently improves performance, surpassing strategies like GRPO and DAPO.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08217v1" target="_blank">Autonomous Air-Ground Vehicle Operations Optimization in Hazardous Environments: A Multi-Armed Bandit Approach</a></h3>
                    <p><strong>Authors:</strong> Jimin Choi, Max Z. Li</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, math.OC</p>
                    <p><strong>Summary:</strong> Hazardous environments such as chemical spills, radiological zones, and bio-contaminated sites pose significant threats to human safety and public infrastructure. Rapid and reliable hazard mitigation in these settings often unsafe for humans, calling for autonomous systems that can adaptively sense and respond to evolving risks. This paper presents a decision-making framework for autonomous vehicle dispatch in hazardous environments with uncertain and evolving risk levels. The system integrates a Bayesian Upper Confidence Bound (BUCB) sensing strategy with task-specific vehicle routing problems with profits (VRPP), enabling adaptive coordination of unmanned aerial vehicles (UAVs) for hazard sensing and unmanned ground vehicles (UGVs) for cleaning. Using VRPP allows selective site visits under resource constraints by assigning each site a visit value that reflects sensing or cleaning priorities. Site-level hazard beliefs are maintained through a time-weighted Bayesian update. BUCB scores guide UAV routing to balance exploration and exploitation under uncertainty, while UGV routes are optimized to maximize expected hazard reduction under resource constraints. Simulation results demonstrate that our framework reduces the number of dispatch cycles to resolve hazards by around 30% on average compared to baseline dispatch strategies, underscoring the value of uncertainty-aware vehicle dispatch for reliable hazard mitigation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08205v1" target="_blank">Optical discrimination of live single cancer cells using reflection-based nanohole array sensor</a></h3>
                    <p><strong>Authors:</strong> Alfredo Franco, Izan CalderÃ³n, Dolores Ortiz, JosÃ© L. FernÃ¡ndez-Luna, Fernando Moreno</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> In this research, a reflection-based nanohole array sensor system is presented for discriminating between migration-competent cancer cells that maintain the integrity of the actin cortex and those cells lacking the actin cortex and thus unable to migrate. Unlike previous transmission-based approaches, this configuration allows for more practical integration into in situ diagnostic tools. For the first time, the system performance is analyzed by studying the spectral features of the reflected light by live single cells. We demonstrate that the presence of the actin cortex, needed for cell migration, in different types of cancer cells significantly affect their optical response, enabling high sensitivity and specificity in cell classification. Our results pave the way for reflection-based plasmonic biosensor devices as a compact and efficient platform for developing biomedical application tools.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08193v1" target="_blank">Street-Level AI: Are Large Language Models Ready for Real-World Judgments?</a></h3>
                    <p><strong>Authors:</strong> Gaurab Pokharel, Shafkat Farabi, Patrick J. Fowler, Sanmay Das</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> A surge of recent work explores the ethical and societal implications of large-scale AI models that make moral judgments. Much of this literature focuses either on alignment with human judgments through various thought experiments or on the group fairness implications of AI judgments. However, the most immediate and likely use of AI is to help or fully replace the so-called street-level bureaucrats, the individuals deciding to allocate scarce social resources or approve benefits. There is a rich history underlying how principles of local justice determine how society decides on prioritization mechanisms in such domains. In this paper, we examine how well LLM judgments align with human judgments, as well as with socially and politically determined vulnerability scoring systems currently used in the domain of homelessness resource allocation. Crucially, we use real data on those needing services (maintaining strict confidentiality by only using local large models) to perform our analyses. We find that LLM prioritizations are extremely inconsistent in several ways: internally on different runs, between different LLMs, and between LLMs and the vulnerability scoring systems. At the same time, LLMs demonstrate qualitative consistency with lay human judgments in pairwise testing. Findings call into question the readiness of current generation AI systems for naive integration in high-stakes societal decision-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08189v1" target="_blank">Reinforcement Learning in Vision: A Survey</a></h3>
                    <p><strong>Authors:</strong> Weijia Wu, Chen Gao, Joya Chen, Kevin Qinghong Lin, Qingwei Meng, Yiming Zhang, Yuke Qiu, Hong Zhou, Mike Zheng Shou</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advances at the intersection of reinforcement learning (RL) and visual intelligence have enabled agents that not only perceive complex visual scenes but also reason, generate, and act within them. This survey offers a critical and up-to-date synthesis of the field. We first formalize visual RL problems and trace the evolution of policy-optimization strategies from RLHF to verifiable reward paradigms, and from Proximal Policy Optimization to Group Relative Policy Optimization. We then organize more than 200 representative works into four thematic pillars: multi-modal large language models, visual generation, unified model frameworks, and vision-language-action models. For each pillar we examine algorithmic design, reward engineering, benchmark progress, and we distill trends such as curriculum-driven training, preference-aligned diffusion, and unified reward modeling. Finally, we review evaluation protocols spanning set-level fidelity, sample-level preference, and state-level stability, and we identify open challenges that include sample efficiency, generalization, and safe deployment. Our goal is to provide researchers and practitioners with a coherent map of the rapidly expanding landscape of visual RL and to highlight promising directions for future inquiry. Resources are available at: https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08187v1" target="_blank">IDSO-Managed Bid-Based Transactive Distribution Systems Design for DER Participation in Wholesale Markets While Preserving T-D Interactions</a></h3>
                    <p><strong>Authors:</strong> Swastik Sharma, Swathi Battula, Sri Niwas Singh</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Participation of Distributed Energy Resources (DERs) in bid-based Transactive Energy Systems (TES) at the distribution systems facilitates strongly coupled, bidirectional interactions between Transmission-Distribution (T-D) systems. Capturing these interactions is critical for ensuring seamless integration within an Integrated Transmission and Distribution (ITD) framework. This study proposes a methodology to preserve such tight T-D linkages by developing an Independent Distribution System Operator (IDSO) managed bid-based TES design for unbalanced distribution systems. The proposed design operates within the ITD paradigm and permits DER participation in the Wholesale Power Market (WPM) through IDSO while preserving tight T-D linkages. To this end, this research offers the following key contributions: a novel bid/offer prequalification-cum-aggregation method to ensure a grid-safe and value-based aggregation of DERs bids and offers for WPM participation through IDSO; and a retail pricing mechanism that reflects the true value of procuring or offering additional units of power within the distribution system. Case studies are conducted on a modified IEEE 123-bus radial feeder populated with a high DER concentration to validate the proposed frameworks effectiveness in coordinating the DERs efficiently and reliably.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08180v1" target="_blank">RedDino: A foundation model for red blood cell analysis</a></h3>
                    <p><strong>Authors:</strong> Luca Zedda, Andrea Loddo, Cecilia Di Ruberto, Carsten Marr</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Red blood cells (RBCs) are essential to human health, and their precise morphological analysis is important for diagnosing hematological disorders. Despite the promise of foundation models in medical diagnostics, comprehensive AI solutions for RBC analysis remain scarce. We present RedDino, a self-supervised foundation model designed for RBC image analysis. RedDino uses an RBC-specific adaptation of the DINOv2 self-supervised learning framework and is trained on a curated dataset of 1.25 million RBC images from diverse acquisition modalities and sources. Extensive evaluations show that RedDino outperforms existing state-of-the-art models on RBC shape classification. Through assessments including linear probing and nearest neighbor classification, we confirm its strong feature representations and generalization ability. Our main contributions are: (1) a foundation model tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations for RBC modeling, and (3) a detailed evaluation of generalization performance. RedDino addresses key challenges in computational hematology by capturing nuanced morphological features, advancing the development of reliable diagnostic tools. The source code and pretrained models for RedDino are available at https://github.com/Snarci/RedDino, and the pretrained models can be downloaded from our Hugging Face collection at https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08158v1" target="_blank">Can AI Explanations Make You Change Your Mind?</a></h3>
                    <p><strong>Authors:</strong> Laura Spillner, Rachel Ringe, Robert Porzel, Rainer Malaka</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> In the context of AI-based decision support systems, explanations can help users to judge when to trust the AIs suggestion, and when to question it. In this way, human oversight can prevent AI errors and biased decision-making. However, this rests on the assumption that users will consider explanations in enough detail to be able to catch such errors. We conducted an online study on trust in explainable DSS, and were surprised to find that in many cases, participants spent little time on the explanation and did not always consider it in detail. We present an exploratory analysis of this data, investigating what factors impact how carefully study participants consider AI explanations, and how this in turn impacts whether they are open to changing their mind based on what the AI suggests.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08153v1" target="_blank">Robust Adaptive Discrete-Time Control Barrier Certificate</a></h3>
                    <p><strong>Authors:</strong> Changrui Liu, Anil Alan, Shengling Shi, Bart De Schutter</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, math.OC</p>
                    <p><strong>Summary:</strong> This work develops a robust adaptive control strategy for discrete-time systems using Control Barrier Functions (CBFs) to ensure safety under parametric model uncertainty and disturbances. A key contribution of this work is establishing a barrier function certificate in discrete time for general online parameter estimation algorithms. This barrier function certificate guarantees positive invariance of the safe set despite disturbances and parametric uncertainty without access to the true system parameters. In addition, real-time implementation and inherent robustness guarantees are provided. Our approach demonstrates that, using the proposed robust adaptive CBF framework, the parameter estimation module can be designed separately from the CBF-based safety filter, simplifying the development of safe adaptive controllers for discrete-time systems. The resulting safety filter guarantees that the system remains within the safe set while adapting to model uncertainties, making it a promising strategy for real-world applications involving discrete-time safety-critical systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08150v1" target="_blank">Recent Progress on Fractal Percolation</a></h3>
                    <p><strong>Authors:</strong> IstvÃ¡n KolossvÃ¡ry, Sascha Troscheit</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> math.PR, math.CA, math.DS, Primary 28A80, Secondary 60J80, 60K35, 60D05, 37C45</p>
                    <p><strong>Summary:</strong> This is a survey paper about the fractal percolation process, also known as Mandelbrot percolation. It is intended to give a general breadth overview of more recent research in the topic, but also includes some of the more classical results, for example related to the connectivity properties. Particular emphasis is put on the dimension theory of the limiting set and also on the geometry of the non-trivial connected components in the supercritical regime. In particular, we show that both the Assouad spectrum and intermediate dimensions of the non-trivial connected components are constant equal to its box dimension despite its Hausdorff, box and Assouad dimensions known to being distinct.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08147v1" target="_blank">From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework</a></h3>
                    <p><strong>Authors:</strong> Yunkai Hu, Tianqiao Zhao, Meng Yue</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This paper introduces a novel Large Language Models (LLMs)-assisted agent that automatically converts natural-language descriptions of power system optimization scenarios into compact, solver-ready formulations and generates corresponding solutions. In contrast to approaches that rely solely on LLM to produce solutions directly, the proposed method focuses on discovering a mathematically compatible formulation that can be efficiently solved by off-the-shelf optimization solvers. Directly using LLMs to produce solutions often leads to infeasible or suboptimal results, as these models lack the numerical precision and constraint-handling capabilities of established optimization solvers. The pipeline integrates a domain-aware prompt and schema with an LLM, enforces feasibility through systematic validation and iterative repair, and returns both solver-ready models and user-facing results. Using the unit commitment problem as a representative case study, the agent produces optimal or near-optimal schedules along with the associated objective costs. Results demonstrate that coupling the solver with task-specific validation significantly enhances solution reliability. This work shows that combining AI with established optimization frameworks bridges high-level problem descriptions and executable mathematical models, enabling more efficient decision-making in energy systems</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08146v1" target="_blank">An effective potential for generative modelling with active matter</a></h3>
                    <p><strong>Authors:</strong> Adrian Baule</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.stat-mech, cond-mat.soft, cs.LG</p>
                    <p><strong>Summary:</strong> Score-based diffusion models generate samples from a complex underlying data distribution by time-reversal of a diffusion process and represent the state-of-the-art in many generative AI applications such as artificial image synthesis. Here, I show how a generative diffusion model can be implemented based on an underlying active particle process with finite correlation time. In contrast to previous approaches that use a score function acting on the velocity coordinate of the active particle, time reversal is here achieved by imposing an effective time-dependent potential on the position coordinate only. The effective potential is valid to first order in the persistence time and leads to a force field that is fully determined by the standard score function and its derivatives up to 2nd order. Numerical experiments for artificial data distributions confirm the validity of the effective potential.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08143v1" target="_blank">AI Gossip</a></h3>
                    <p><strong>Authors:</strong> Joel Krueger, Lucy Osler</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Generative AI chatbots like OpenAIs ChatGPT and Googles Gemini routinely make things up. They hallucinate historical events and figures, legal cases, academic papers, non-existent tech products and features, biographies, and news articles. Recently, some have argued that these hallucinations are better understood as bullshit. Chatbots produce rich streams of text that look truth-apt without any concern for the truthfulness of what this text says. But can they also gossip? We argue that they can. After some definitions and scene-setting, we focus on a recent example to clarify what AI gossip looks like before considering some distinct harms -- what we call technosocial harms -- that follow from it.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08138v1" target="_blank">Reproducing and Extending Brownian Motion in Optical Trap: A Computational Reimplementation of Volpe and Volpe (2013)</a></h3>
                    <p><strong>Authors:</strong> Eyad I. B Hamid</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph</p>
                    <p><strong>Summary:</strong> We present a re-representation and independent simulation of the model introduced by Giorgio Volpe and Giovanni Volpe in their 2013 study of a Brownian particle in an optical trap (Volpe and Volpe, 2013). Rather than duplicating their original plots, we reconstructed the simulations from first principles using Python, implementing stochastic differential equations via finite difference schemes. This work reproduces and validates the key physical regimes described in the original article, including the transition from ballistic to diffusive motion, optical confinement, and velocity autocorrelations. To simulate rotational forces (Grier, 2003) and Kramers transitions (Haenggi et al., 1990), we also extend the analysis to include force perturbations, rotational fields, Kramers transitions, and stochastic resonance. The simulations provide pedagogical insight into stochastic dynamics and numerical modeling, reinforcing the original studys value as a teaching and research tool in statistical and computational physics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08137v1" target="_blank">MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation</a></h3>
                    <p><strong>Authors:</strong> Pravallika Abbineni, Saoud Aldowaish, Colin Liechty, Soroosh Noorzad, Ali Ghazizadeh, Morteza Fayazi</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08132v1" target="_blank">Deep Reinforcement Learning with Local Interpretability for Transparent Microgrid Resilience Energy Management</a></h3>
                    <p><strong>Authors:</strong> Mohammad Hossein Nejati Amiri, Fawaz Annaz, Mario De Oliveira, Florimond Gueniat</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Renewable energy integration into microgrids has become a key approach to addressing global energy issues such as climate change and resource scarcity. However, the variability of renewable sources and the rising occurrence of High Impact Low Probability (HILP) events require innovative strategies for reliable and resilient energy management. This study introduces a practical approach to managing microgrid resilience through Explainable Deep Reinforcement Learning (XDRL). It combines the Proximal Policy Optimization (PPO) algorithm for decision-making with the Local Interpretable Model-agnostic Explanations (LIME) method to improve the transparency of the actor networks decisions. A case study in Ongole, India, examines a microgrid with wind, solar, and battery components to validate the proposed approach. The microgrid is simulated under extreme weather conditions during the Layla cyclone. LIME is used to analyse scenarios, showing the impact of key factors such as renewable generation, state of charge, and load prioritization on decision-making. The results demonstrate a Resilience Index (RI) of 0.9736 and an estimated battery lifespan of 15.11 years. LIME analysis reveals the rationale behind the agents actions in idle, charging, and discharging modes, with renewable generation identified as the most influential feature. This study shows the effectiveness of integrating advanced DRL algorithms with interpretable AI techniques to achieve reliable and transparent energy management in microgrids.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08126v1" target="_blank">OFAL: An Oracle-Free Active Learning Framework</a></h3>
                    <p><strong>Authors:</strong> Hadi Khorsand, Vahid Pourahmadi</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In the active learning paradigm, using an oracle to label data has always been a complex and expensive task, and with the emersion of large unlabeled data pools, it would be highly beneficial If we could achieve better results without relying on an oracle. This research introduces OFAL, an oracle-free active learning scheme that utilizes neural network uncertainty. OFAL uses the models own uncertainty to transform highly confident unlabeled samples into informative uncertain samples. First, we start with separating and quantifying different parts of uncertainty and introduce Monte Carlo Dropouts as an approximation of the Bayesian Neural Network model. Secondly, by adding a variational autoencoder, we go on to generate new uncertain samples by stepping toward the uncertain part of latent space starting from a confidence seed sample. By generating these new informative samples, we can perform active learning and enhance the models accuracy. Lastly, we try to compare and integrate our method with other widely used active learning sampling methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08125v1" target="_blank">Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks</a></h3>
                    <p><strong>Authors:</strong> Jakub Å mÃ­d, Pavel PÅ™ibÃ¡Åˆ, OndÅ™ej PraÅ¾Ã¡k, Pavel KrÃ¡l</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In this paper, we introduce a novel Czech dataset for aspect-based sentiment analysis (ABSA), which consists of 3.1K manually annotated reviews from the restaurant domain. The dataset is built upon the older Czech dataset, which contained only separate labels for the basic ABSA tasks such as aspect term extraction or aspect polarity detection. Unlike its predecessor, our new dataset is specifically designed for more complex tasks, e.g. target-aspect-category detection. These advanced tasks require a unified annotation format, seamlessly linking sentiment elements (labels) together. Our dataset follows the format of the well-known SemEval-2016 datasets. This design choice allows effortless application and evaluation in cross-lingual scenarios, ultimately fostering cross-language comparisons with equivalent counterpart datasets in other languages. The annotation process engaged two trained annotators, yielding an impressive inter-annotator agreement rate of approximately 90%. Additionally, we provide 24M reviews without annotations suitable for unsupervised learning. We present robust monolingual baseline results achieved with various Transformer-based models and insightful error analysis to supplement our contributions. Our code and dataset are freely available for non-commercial research purposes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08123v1" target="_blank">A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images</a></h3>
                    <p><strong>Authors:</strong> Lingjing Chen, Chengxiu Zhang, Yinqiao Yi, Yida Wang, Yang Song, Xu Yan, Shengfang Xu, Dalin Zhu, Mengqiu Cao, Yan Zhou, Chenglong Wang, Guang Yang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> We propose a deep learning-based approach that integrates MRI sequence parameters to improve the accuracy and generalizability of quantitative image synthesis from clinical weighted MRI. Our physics-driven neural network embeds MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion time (TI) -- directly into the model via parameter embedding, enabling the network to learn the underlying physical principles of MRI signal formation. The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as input and synthesizes T1, T2, and proton density (PD) quantitative maps. Trained on healthy brain MR images, it was evaluated on both internal and external test datasets. The proposed method achieved high performance with PSNR values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter maps. It outperformed conventional deep learning models in accuracy and robustness, including data with previously unseen brain structures and lesions. Notably, our model accurately synthesized quantitative maps for these unseen pathological regions, highlighting its superior generalization capability. Incorporating MRI sequence parameters via parameter embedding allows the neural network to better learn the physical characteristics of MR signals, significantly enhancing the performance and reliability of quantitative MRI synthesis. This method shows great potential for accelerating qMRI and improving its clinical utility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08120v1" target="_blank">Vision-Based Localization and LLM-based Navigation for Indoor Environments</a></h3>
                    <p><strong>Authors:</strong> Keyan Rahimi, Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Indoor navigation remains a complex challenge due to the absence of reliable GPS signals and the architectural intricacies of large enclosed environments. This study presents an indoor localization and navigation approach that integrates vision-based localization with large language model (LLM)-based navigation. The localization system utilizes a ResNet-50 convolutional neural network fine-tuned through a two-stage process to identify the users position using smartphone camera input. To complement localization, the navigation module employs an LLM, guided by a carefully crafted system prompt, to interpret preprocessed floor plan images and generate step-by-step directions. Experimental evaluation was conducted in a realistic office corridor with repetitive features and limited visibility to test localization robustness. The model achieved high confidence and an accuracy of 96% across all tested waypoints, even under constrained viewing conditions and short-duration queries. Navigation tests using ChatGPT on real building floor maps yielded an average instruction accuracy of 75%, with observed limitations in zero-shot reasoning and inference time. This research demonstrates the potential for scalable, infrastructure-free indoor navigation using off-the-shelf cameras and publicly available floor plans, particularly in resource-constrained settings like hospitals, airports, and educational institutions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08115v1" target="_blank">TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork</a></h3>
                    <p><strong>Authors:</strong> Pranav Pushkar Mishra, Mohammad Arvan, Mohan Zalake</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We present TeamMedAgents, a novel multi-agent approach that systematically integrates evidence-based teamwork components from human-human collaboration into medical decision-making with large language models (LLMs). Our approach validates an organizational psychology teamwork model from human collaboration to computational multi-agent medical systems by operationalizing six core teamwork components derived from Salas et al.s Big Five model: team leadership, mutual performance monitoring, team orientation, shared mental models, closed-loop communication, and mutual trust. We implement and evaluate these components as modular, configurable mechanisms within an adaptive collaboration architecture while assessing the effect of the number of agents involved based on the tasks requirements and domain. Systematic evaluation of computational implementations of teamwork behaviors across eight medical benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets, Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8 evaluated datasets. Controlled ablation studies conducted on 50 questions per configuration across 3 independent runs provide mechanistic insights into individual component contributions, revealing optimal teamwork configurations that vary by reasoning task complexity and domain-specific requirements. Our ablation analyses reveal dataset-specific optimal teamwork configurations, indicating that different medical reasoning modalities benefit from distinct collaborative patterns. TeamMedAgents represents an advancement in collaborative AI by providing a systematic translation of established teamwork theories from human collaboration into agentic collaboration, establishing a foundation for evidence-based multi-agent system design in critical decision-making domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08112v1" target="_blank">Short-Range Order and Li$_x$TM$_{4-x}$ Probability Maps for Disordered Rocksalt Cathodes</a></h3>
                    <p><strong>Authors:</strong> Tzu-chen Liu, Steven B. Torrisi, Chris Wolverton</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Short-range order (SRO) in the cation-disordered state is a controlling factor influencing the probability of finding Li$_{4}$ tetrahedron clusters in disordered rocksalt (DRX) cathode materials. However, the prevalent Li$_4$ probability below the random limit across reported DRX compositions has not been systematically investigated, active strategies to surpass the random limit of Li$_4$ probability are lacking, and the fundamental ordering behavior on the face-centered cubic (FCC) lattice remains insufficiently explored. This research quantitatively examines pair SRO parameters and Li$_x$TM$_{4-x}$ probabilities via exhaustive Monte Carlo mapping across a simplified subset of the parameter space. The results indicate that, in the disordered state, the Li$_4$ probability is governed by the nearest neighbor (NN) pair-wise SRO parameter, and that these quantities do not necessarily represent a simple attenuation of their corresponding low-temperature long-range order, particularly for the important cases of Layered and Spinel-like orderings. Strategies are proposed to mitigate or even reverse the lithium and transition metals mixing tendency of NN pair SRO to achieve Li$_4$ probabilities that exceed the random limit. This study advances the fundamental thermodynamic understanding of ordering behaviors, which can be generalized to any FCC system.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08107v1" target="_blank">Hyperspectral Imaging</a></h3>
                    <p><strong>Authors:</strong> Danfeng Hong, Chenyu Li, Naoto Yokoya, Bing Zhang, Xiuping Jia, Antonio Plaza, Paolo Gamba, Jon Atli Benediktsson, Jocelyn Chanussot</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Hyperspectral imaging (HSI) is an advanced sensing modality that simultaneously captures spatial and spectral information, enabling non-invasive, label-free analysis of material, chemical, and biological properties. This Primer presents a comprehensive overview of HSI, from the underlying physical principles and sensor architectures to key steps in data acquisition, calibration, and correction. We summarize common data structures and highlight classical and modern analysis methods, including dimensionality reduction, classification, spectral unmixing, and AI-driven techniques such as deep learning. Representative applications across Earth observation, precision agriculture, biomedicine, industrial inspection, cultural heritage, and security are also discussed, emphasizing HSIs ability to uncover sub-visual features for advanced monitoring, diagnostics, and decision-making. Persistent challenges, such as hardware trade-offs, acquisition variability, and the complexity of high-dimensional data, are examined alongside emerging solutions, including computational imaging, physics-informed modeling, cross-modal fusion, and self-supervised learning. Best practices for dataset sharing, reproducibility, and metadata documentation are further highlighted to support transparency and reuse. Looking ahead, we explore future directions toward scalable, real-time, and embedded HSI systems, driven by sensor miniaturization, self-supervised learning, and foundation models. As HSI evolves into a general-purpose, cross-disciplinary platform, it holds promise for transformative applications in science, technology, and society.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08108v1" target="_blank">Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain</a></h3>
                    <p><strong>Authors:</strong> Wei Zhang, Yinchuan Wang, Wangtao Lu, Pengyu Zhang, Xiang Zhang, Yue Wang, Chaoqun Wang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> It is a challenging task for ground robots to autonomously navigate in harsh environments due to the presence of non-trivial obstacles and uneven terrain. This requires trajectory planning that balances safety and efficiency. The primary challenge is to generate a feasible trajectory that prevents robot from tip-over while ensuring effective navigation. In this paper, we propose a capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the uneven terrain. The tip-over stability of the robot on rough terrain is analyzed. Based on the tip-over stability, we define the traversable orientation, which indicates the safe range of robot orientations. This orientation is then incorporated into a capsizing-safety constraint for trajectory optimization. We employ a graph-based solver to compute a robust and feasible trajectory while adhering to the capsizing-safety constraint. Extensive simulation and real-world experiments validate the effectiveness and robustness of the proposed method. The results demonstrate that CAP outperforms existing state-of-the-art approaches, providing enhanced navigation performance on uneven terrains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08101v1" target="_blank">ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience</a></h3>
                    <p><strong>Authors:</strong> Yeana Lee Bond, Mungyeong Choe, Baker Kasim Hasan, Arsh Siddiqui, Myounghoon Jeon</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.SE</p>
                    <p><strong>Summary:</strong> Studies on in-vehicle conversational agents have traditionally relied on pre-scripted prompts or limited voice commands, constraining natural driver-agent interaction. To resolve this issue, the present study explored the potential of a ChatGPT-based in-vehicle agent capable of carrying continuous, multi-turn dialogues. Forty drivers participated in our experiment using a motion-based driving simulator, comparing three conditions (No agent, Pre-scripted agent, and ChatGPT-based agent) as a within-subjects variable. Results showed that the ChatGPT-based agent condition led to more stable driving performance across multiple metrics. Participants demonstrated lower variability in longitudinal acceleration, lateral acceleration, and lane deviation compared to the other two conditions. In subjective evaluations, the ChatGPT-based agent also received significantly higher ratings in competence, animacy, affective trust, and preference compared to the Pre-scripted agent. Our thematic analysis of driver-agent conversations revealed diverse interaction patterns in topics, including driving assistance/questions, entertainment requests, and anthropomorphic interactions. Our results highlight the potential of LLM-powered in-vehicle conversational agents to enhance driving safety and user experience through natural, context-rich interactions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08100v1" target="_blank">Grid2Guide: A* Enabled Small Language Model for Indoor Navigation</a></h3>
                    <p><strong>Authors:</strong> Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Reliable indoor navigation remains a significant challenge in complex environments, particularly where external positioning signals and dedicated infrastructures are unavailable. This research presents Grid2Guide, a hybrid navigation framework that combines the A* search algorithm with a Small Language Model (SLM) to generate clear, human-readable route instructions. The framework first conducts a binary occupancy matrix from a given indoor map. Using this matrix, the A* algorithm computes the optimal path between origin and destination, producing concise textual navigation steps. These steps are then transformed into natural language instructions by the SLM, enhancing interpretability for end users. Experimental evaluations across various indoor scenarios demonstrate the methods effectiveness in producing accurate and timely navigation guidance. The results validate the proposed approach as a lightweight, infrastructure-free solution for real-time indoor navigation support.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08098v1" target="_blank">TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning</a></h3>
                    <p><strong>Authors:</strong> Junzhe Xu, Yuyang Yin, Xi Chen</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper introduces TBAC-UniImage, a novel unified model for multimodal understanding and generation. We achieve this by deeply integrating a pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal Large Language Model (MLLM). Previous diffusion-based unified models face two primary limitations. One approach uses only the MLLMs final hidden state as the generative condition. This creates a shallow connection, as the generator is isolated from the rich, hierarchical representations within the MLLMs intermediate layers. The other approach, pretraining a unified generative architecture from scratch, is computationally expensive and prohibitive for many researchers. To overcome these issues, our work explores a new paradigm. Instead of relying on a single output, we use representations from multiple, diverse layers of the MLLM as generative conditions for the diffusion model. This method treats the pre-trained generator as a ladder, receiving guidance from various depths of the MLLMs understanding process. Consequently, TBAC-UniImage achieves a much deeper and more fine-grained unification of understanding and generation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08094v1" target="_blank">3D Plant Root Skeleton Detection and Extraction</a></h3>
                    <p><strong>Authors:</strong> Jiakai Lin, Jinchang Zhang, Ge Jin, Wenzhan Song, Tianming Liu, Guoyu Lu</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Plant roots typically exhibit a highly complex and dense architecture, incorporating numerous slender lateral roots and branches, which significantly hinders the precise capture and modeling of the entire root system. Additionally, roots often lack sufficient texture and color information, making it difficult to identify and track root traits using visual methods. Previous research on roots has been largely confined to 2D studies; however, exploring the 3D architecture of roots is crucial in botany. Since roots grow in real 3D space, 3D phenotypic information is more critical for studying genetic traits and their impact on root development. We have introduced a 3D root skeleton extraction method that efficiently derives the 3D architecture of plant roots from a few images. This method includes the detection and matching of lateral roots, triangulation to extract the skeletal structure of lateral roots, and the integration of lateral and primary roots. We developed a highly complex root dataset and tested our method on it. The extracted 3D root skeletons showed considerable similarity to the ground truth, validating the effectiveness of the model. This method can play a significant role in automated breeding robots. Through precise 3D root structure analysis, breeding robots can better identify plant phenotypic traits, especially root structure and growth patterns, helping practitioners select seeds with superior root systems. This automated approach not only improves breeding efficiency but also reduces manual intervention, making the breeding process more intelligent and efficient, thus advancing modern agriculture.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08093v1" target="_blank">MDD-Net: Multimodal Depression Detection through Mutual Transformer</a></h3>
                    <p><strong>Authors:</strong> Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Hamdi Altaheri, Lobna Nassar, Fakhri Karray</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG, cs.MM, eess.AS</p>
                    <p><strong>Summary:</strong> Depression is a major mental health condition that severely impacts the emotional and physical well-being of individuals. The simple nature of data collection from social media platforms has attracted significant interest in properly utilizing this information for mental health research. A Multimodal Depression Detection Network (MDD-Net), utilizing acoustic and visual data obtained from social media networks, is proposed in this work where mutual transformers are exploited to efficiently extract and fuse multimodal features for efficient depression detection. The MDD-Net consists of four core modules: an acoustic feature extraction module for retrieving relevant acoustic attributes, a visual feature extraction module for extracting significant high-level patterns, a mutual transformer for computing the correlations among the generated features and fusing these features from multiple modalities, and a detection layer for detecting depression using the fused feature representations. The extensive experiments are performed using the multimodal D-Vlog dataset, and the findings reveal that the developed multimodal depression detection network surpasses the state-of-the-art by up to 17.37% for F1-Score, demonstrating the greater performance of the proposed system. The source code is accessible at https://github.com/rezwanh001/Multimodal-Depression-Detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08084v1" target="_blank">$100,000 or the Robot Gets it! Tech Workers Resistance Guide: Tech Worker Actions, History, Risks, Impacts, and the Case for a Radical Flank</a></h3>
                    <p><strong>Authors:</strong> Mohamed Abdalla</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Over the past decade, Big Tech has faced increasing levels of worker activism. While worker actions have resulted in positive outcomes (e.g., cancellation of Googles Project Dragonfly), such successes have become increasingly infrequent. This is, in part, because corporations have adjusted their strategies to dealing with increased worker activism (e.g., increased retaliation against workers, and contracts clauses that prevent cancellation due to worker pressure). This change in company strategy prompts urgent questions about updating worker strategies for influencing corporate behavior in an industry with vast societal impact. Current discourse on tech worker activism often lacks empirical grounding regarding its scope, history, and strategic calculus. Our work seeks to bridge this gap by firstly conducting a systematic analysis of worker actions at Google and Microsoft reported in U.S. newspapers to delineate their characteristics. We then situate these actions within the long history of labour movements and demonstrate that, despite perceptions of radicalism, contemporary tech activism is comparatively moderate. Finally, we engage directly with current and former tech activists to provide a novel catalogue of potential worker actions, evaluating their perceived risks, impacts, and effectiveness (concurrently publishing Tech Workers Guide to Resistance). Our findings highlight considerable variation in strategic thinking among activists themselves. We conclude by arguing that the establishment of a radical flank could increase the effectiveness of current movements. Tech Workers Guide to Resistance can be found at https://www.cs.toronto.edu/~msa/TechWorkersResistanceGuide.pdf or https://doi.org/10.5281/zenodo.16779082</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08080v1" target="_blank">Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles</a></h3>
                    <p><strong>Authors:</strong> Cas Oude Hoekstra, Floris den Hengst</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.NE, stat.AP</p>
                    <p><strong>Summary:</strong> Symbolic Regression (SR) is a well-established framework for generating interpretable or white-box predictive models. Although SR has been successfully applied to create interpretable estimates of the average of the outcome, it is currently not well understood how it can be used to estimate the relationship between variables at other points in the distribution of the target variable. Such estimates of e.g. the median or an extreme value provide a fuller picture of how predictive variables affect the outcome and are necessary in high-stakes, safety-critical application domains. This study introduces Symbolic Quantile Regression (SQR), an approach to predict conditional quantiles with SR. In an extensive evaluation, we find that SQR outperforms transparent models and performs comparably to a strong black-box baseline without compromising transparency. We also show how SQR can be used to explain differences in the target distribution by comparing models that predict extreme and central outcomes in an airline fuel usage case study. We conclude that SQR is suitable for predicting conditional quantiles and understanding interesting feature influences at varying quantiles.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08076v1" target="_blank">Heterogeneity in Entity Matching: A Survey and Experimental Analysis</a></h3>
                    <p><strong>Authors:</strong> Mohammad Hossein Moslemi, Amir Mousavi, Behshid Behkamal, Mostafa Milani</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.DB, 68P20 68P20 68P20, H.2.8; H.2.4; I.2.7</p>
                    <p><strong>Summary:</strong> Entity matching (EM) is a fundamental task in data integration and analytics, essential for identifying records that refer to the same real-world entity across diverse sources. In practice, datasets often differ widely in structure, format, schema, and semantics, creating substantial challenges for EM. We refer to this setting as Heterogeneous EM (HEM). This survey offers a unified perspective on HEM by introducing a taxonomy, grounded in prior work, that distinguishes two primary categories -- representation and semantic heterogeneity -- and their subtypes. The taxonomy provides a systematic lens for understanding how variations in data form and meaning shape the complexity of matching tasks. We then connect this framework to the FAIR principles -- Findability, Accessibility, Interoperability, and Reusability -- demonstrating how they both reveal the challenges of HEM and suggest strategies for mitigating them. Building on this foundation, we critically review recent EM methods, examining their ability to address different heterogeneity types, and conduct targeted experiments on state-of-the-art models to evaluate their robustness and adaptability under semantic heterogeneity. Our analysis uncovers persistent limitations in current approaches and points to promising directions for future research, including multimodal matching, human-in-the-loop workflows, deeper integration with large language models and knowledge graphs, and fairness-aware evaluation in heterogeneous settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08075v1" target="_blank">FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence</a></h3>
                    <p><strong>Authors:</strong> Meishen He, Wenjun Ma, Jiao Wang, Huijun Yue, Xiaoma Fan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The Dempster-Shafer theory of evidence has been widely applied in the field of information fusion under uncertainty. Most existing research focuses on combining evidence within the same frame of discernment. However, in real-world scenarios, trained algorithms or data often originate from different regions or organizations, where data silos are prevalent. As a result, using different data sources or models to generate basic probability assignments may lead to heterogeneous frames, for which traditional fusion methods often yield unsatisfactory results. To address this challenge, this study proposes an open-world information fusion method, termed Full Negation Belief Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a criterion is introduced to determine whether a given fusion task belongs to the open-world setting. Then, by extending the frames, the method can accommodate elements from heterogeneous frames. Finally, a full negation mechanism is employed to transform the mass functions, so that existing combination rules can be applied to the transformed mass functions for such information fusion. Theoretically, the proposed method satisfies three desirable properties, which are formally proven: mass function invariance, heritability, and essential conflict elimination. Empirically, FNBT demonstrates superior performance in pattern classification tasks on real-world datasets and successfully resolves Zadehs counterexample, thereby validating its practical effectiveness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08074v1" target="_blank">Towards General-Purpose Data Discovery: A Programming Languages Approach</a></h3>
                    <p><strong>Authors:</strong> Andrew Kang, Yashnil Saha, Sainyam Galhotra</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.PL</p>
                    <p><strong>Summary:</strong> Efficient and effective data discovery is critical for many modern applications in machine learning and data science. One major bottleneck to the development of a general-purpose data discovery tool is the absence of an expressive formal language, and corresponding implementation, for characterizing and solving generic discovery queries. To this end, we present TQL, a domain-specific language for data discovery well-designed to leverage and exploit the results of programming languages research in both its syntax and semantics. In this paper, we fully and formally characterize the core language through an algebraic model, Imperative Relational Algebra with Types (ImpRAT), and implement a modular proof-of-concept system prototype.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08073v1" target="_blank">ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring</a></h3>
                    <p><strong>Authors:</strong> Dimitris Tsaras, Xing Li, Lei Chen, Zhiyao Xie, Mingxuan Yuan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AR, cs.ET</p>
                    <p><strong>Summary:</strong> In electronic design automation, logic optimization operators play a crucial role in minimizing the gate count of logic circuits. However, their computation demands are high. Operators such as refactor conventionally form iterative cuts for each node, striving for a more compact representation - a task which often fails 98% on average. Prior research has sought to mitigate computational cost through parallelization. In contrast, our approach leverages a classifier to prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis operations. Experiments on the refactor operator using the EPFL benchmark suite and 10 large industrial designs demonstrate that this technique can speedup logic optimization by 3.9x on average compared with the state-of-the-art ABC implementation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08071v1" target="_blank">C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction</a></h3>
                    <p><strong>Authors:</strong> Yunqing Li, Zixiang Tang, Jiaying Zhuang, Zhenyu Yang, Farhad Ameri, Jianbang Zhang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, J.1; I.2.4; H.2.8</p>
                    <p><strong>Summary:</strong> Connecting an ever-expanding catalogue of products with suitable manufacturers and suppliers is critical for resilient, efficient global supply chains, yet traditional methods struggle to capture complex capabilities, certifications, geographic constraints, and rich multimodal data of real-world manufacturer profiles. To address these gaps, we introduce PMGraph, a public benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking 8,888 manufacturers, over 70k products, more than 110k manufacturer-product edges, and over 29k product images. Building on this benchmark, we propose the Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first aligns and aggregates textual and visual attributes into intermediate group embeddings, then propagates them through a manufacturer-product hetero-graph via multiscale message passing to enhance link prediction accuracy. C-MAG also provides practical guidelines for modality-aware fusion, preserving predictive performance in noisy, real-world settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08066v1" target="_blank">Investigating the Design Space of Visual Grounding in Multimodal Large Language Model</a></h3>
                    <p><strong>Authors:</strong> Weitai Kang, Weiming Zhuang, Zhizhong Li, Yan Yan, Lingjuan Lyu</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Fine-grained multimodal capability in Multimodal Large Language Models (MLLMs) has emerged as a critical research direction, particularly for tackling the visual grounding (VG) problem. Despite the strong performance achieved by existing approaches, they often employ disparate design choices when fine-tuning MLLMs for VG, lacking systematic verification to support these designs. To bridge this gap, this paper presents a comprehensive study of various design choices that impact the VG performance of MLLMs. We conduct our analysis using LLaVA-1.5, which has been widely adopted in prior empirical studies of MLLMs. While more recent models exist, we follow this convention to ensure our findings remain broadly applicable and extendable to other architectures. We cover two key aspects: (1) exploring different visual grounding paradigms in MLLMs, identifying the most effective design, and providing our insights; and (2) conducting ablation studies on the design of grounding data to optimize MLLMs fine-tuning for the VG task. Finally, our findings contribute to a stronger MLLM for VG, achieving improvements of +5.6% / +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08064v1" target="_blank">On the Operational Resilience of CBDC: Threats and Prospects of Formal Validation for Offline Payments</a></h3>
                    <p><strong>Authors:</strong> Marco Bernardo, Federico Calandra, Andrea Esposito, Francesco Fabris</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> Information and communication technologies are by now employed in most activities, including economics and finance. Despite the extraordinary power of modern computers and the vast amount of memory, some results of theoretical computer science imply the impossibility of certifying software quality in general. With the exception of safety-critical systems, this has primarily concerned the information processed by confined systems, with limited socio-economic consequences. In the emerging era of technologies for exchanging digital money and tokenized assets over the Internet - such as central bank digital currencies (CBDCs) - even a minor bug could trigger a financial collapse. Although the aforementioned impossibility results cannot be overcome in an absolute sense, there exist formal methods that can provide assertions of computing systems correctness. We advocate their use to validate the operational resilience of software infrastructures enabling CBDCs, with special emphasis on offline payments as they constitute a very critical issue.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/BigData62323.2024.10825227" target="_blank">TQL: Towards Type-Driven Data Discovery</a></h3>
                    <p><strong>Authors:</strong> Andrew Kang, Sainyam Galhotra</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.PL</p>
                    <p><strong>Summary:</strong> Existing query languages for data discovery exhibit system-driven designs that emphasize database features and functionality over user needs. We propose a re-prioritization of the client through an introduction of a language-driven approach to data discovery systems that can leverage powerful results from programming languages research. In this paper, we describe TQL, a flexible and practical query language which incorporates a type-like system to encompass downstream transformation-context in its discovery queries. The syntax and semantics of TQL (including the underlying evaluation model), are formally defined, and a sketch of its implementation is also provided. Additionally, we provide comparisons to existing languages for data retrieval and data discovery to examine the advantages of TQLs expanded expressive power in real-life settings.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3742886.3759656" target="_blank">9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)</a></h3>
                    <p><strong>Authors:</strong> Fabrizio Nunnari, Cristina Luna JimÃ©nez, Rosalee Wolfe, John C. McDonald, Michael Filhol, Eleni Efthimiou, Evita Fotinea, Thomas Hanke</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The Sign Language Translation and Avatar Technology (SLTAT) workshops continue a series of gatherings to share recent advances in improving deaf / human communication through non-invasive means. This 2025 edition, the 9th since its first appearance in 2011, is hosted by the International Conference on Intelligent Virtual Agents (IVA), giving the opportunity for contamination between two research communities, using digital humans as either virtual interpreters or as interactive conversational agents. As presented in this summary paper, SLTAT sees contributions beyond avatar technologies, with a consistent number of submissions on sign language recognition, and other work on data collection, data analysis, tools, ethics, usability, and affective computing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08031v1" target="_blank">IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning</a></h3>
                    <p><strong>Authors:</strong> Jiayao Wang, Yang Song, Zhendong Zhao, Jiale Zhang, Qilin Wu, Junwu Zhu, Dongfang Zhao</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.CV</p>
                    <p><strong>Summary:</strong> Federated self-supervised learning (FSSL) combines the advantages of decentralized modeling and unlabeled representation learning, serving as a cutting-edge paradigm with strong potential for scalability and privacy preservation. Although FSSL has garnered increasing attention, research indicates that it remains vulnerable to backdoor attacks. Existing methods generally rely on visually obvious triggers, which makes it difficult to meet the requirements for stealth and practicality in real-world deployment. In this paper, we propose an imperceptible and effective backdoor attack method against FSSL, called IPBA. Our empirical study reveals that existing imperceptible triggers face a series of challenges in FSSL, particularly limited transferability, feature entanglement with augmented samples, and out-of-distribution properties. These issues collectively undermine the effectiveness and stealthiness of traditional backdoor attacks in FSSL. To overcome these challenges, IPBA decouples the feature distributions of backdoor and augmented samples, and introduces Sliced-Wasserstein distance to mitigate the out-of-distribution properties of backdoor samples, thereby optimizing the trigger generation process. Our experimental results on several FSSL scenarios and datasets show that IPBA significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08252v1" target="_blank">ReferSplat: Referring Segmentation in 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Shuting He, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li, Henghui Ding</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task that aims to segment target objects in a 3D Gaussian scene based on natural language descriptions, which often contain spatial relationships or object attributes. This task requires the model to identify newly described objects that may be occluded or not directly visible in a novel view, posing a significant challenge for 3D multi-modal understanding. Developing this capability is crucial for advancing embodied AI. To support research in this area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that 3D multi-modal understanding and spatial relationship modeling are key challenges for R3DGS. To address these challenges, we propose ReferSplat, a framework that explicitly models 3D Gaussian points with natural language expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art performance on both the newly proposed R3DGS task and 3D open-vocabulary segmentation benchmarks. Dataset and code are available at https://github.com/heshuting555/ReferSplat.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08243v1" target="_blank">Jinx: Unlimited LLMs for Probing Alignment Failures</a></h3>
                    <p><strong>Authors:</strong> Jiahao Zhao, Liwei Dong</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Unlimited, or so-called helpful-only language models are trained without safety alignment constraints and never refuse user queries. They are widely used by leading AI companies as internal tools for red teaming and alignment evaluation. For example, if a safety-aligned model produces harmful outputs similar to an unlimited model, this indicates alignment failures that require further attention. Despite their essential role in assessing alignment, such models are not available to the research community. We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx responds to all queries without refusals or safety filtering, while preserving the base models capabilities in reasoning and instruction following. It provides researchers with an accessible tool for probing alignment failures, evaluating safety boundaries, and systematically studying failure modes in language model safety.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08242v1" target="_blank">Bringing Everyone to the Table: An Experimental Study of LLM-Facilitated Group Decision Making</a></h3>
                    <p><strong>Authors:</strong> Mohammed Alsobay, David M. Rothschild, Jake M. Hofman, Daniel G. Goldstein</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Group decision-making often suffers from uneven information sharing, hindering decision quality. While large language models (LLMs) have been widely studied as aids for individuals, their potential to support groups of users, potentially as facilitators, is relatively underexplored. We present a pre-registered randomized experiment with 1,475 participants assigned to 281 five-person groups completing a hidden profile task--selecting an optimal city for a hypothetical sporting event--under one of four facilitation conditions: no facilitation, a one-time message prompting information sharing, a human facilitator, or an LLM (GPT-4o) facilitator. We find that LLM facilitation increases information shared within a discussion by raising the minimum level of engagement with the task among group members, and that these gains come at limited cost in terms of participants attitudes towards the task, their group, or their facilitator. Whether by human or AI, there is no significant effect of facilitation on the final decision outcome, suggesting that even substantial but partial increases in information sharing are insufficient to overcome the hidden profile effect studied. To support further research into how LLM-based interfaces can support the future of collaborative decision making, we release our experimental platform, the Group-AI Interaction Laboratory (GRAIL), as an open-source tool.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08236v1" target="_blank">Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge</a></h3>
                    <p><strong>Authors:</strong> Yunna Cai, Fan Wang, Haowei Wang, Kun Wang, Kailai Yang, Sophia Ananiadou, Moyan Li, Mingming Fan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Evaluating the safety alignment of LLM responses in high-risk mental health dialogues is particularly difficult due to missing gold-standard answers and the ethically sensitive nature of these interactions. To address this challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark based on real-world Chinese mental health dialogues. It evaluates whether the model responses align with the safety principles defined by experts. Specifically designed for settings without standard references, our method adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation using expert-defined reasoning chains grounded in psychological intervention principles. We employ binary point-wise scoring across multiple safety dimensions to enhance the explainability and traceability of the evaluation. Additionally, we present a manually curated, high-quality Chinese-language dataset covering self-harm, suicidal ideation, and existential distress, derived from real-world online discourse. Experiments on 3600 judgments show that our method achieves the highest agreement with expert assessments and produces more interpretable evaluation rationales compared to existing approaches. Our dataset and evaluation tool are publicly available to facilitate further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08231v1" target="_blank">A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies</a></h3>
                    <p><strong>Authors:</strong> Chris Schmitz, Joanna Bryson</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Public-sector bureaucracies seek to reap the benefits of artificial intelligence (AI), but face important concerns about accountability and transparency when using AI systems. These concerns center on threats to the twin aims of bureaucracy: legitimate and faithful implementation of legislation, and the provision of stable, long-term governance. Both aims are threatened when AI systems are misattributed as either mere tools or moral subjects - a framing error that creates ethics sinks, constructs that facilitate dissipation of responsibility by obscuring clear lines of human moral agency. Here, we reject the notion that such outcomes are inevitable. Rather, where they appear, they are the product of structural design decisions across both the technology and the institution deploying it. We support this claim via a systematic application of conceptions of moral agency in AI ethics to Weberian bureaucracy. We establish that it is both desirable and feasible to render AI systems as tools for the generation of organizational transparency and legibility, which continue the processes of Weberian rationalization initiated by previous waves of digitalization. We present a three-point Moral Agency Framework for legitimate integration of AI in bureaucratic structures: (a) maintain clear and just human lines of accountability, (b) ensure humans whose work is augmented by AI systems can verify the systems are functioning correctly, and (c) introduce AI only where it doesnt inhibit the capacity of bureaucracies towards either of their twin aims of legitimacy and stewardship. We suggest that AI introduced within this framework can not only improve efficiency and productivity while avoiding ethics sinks, but also improve the transparency and even the legitimacy of a bureaucracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08230v1" target="_blank">Ultra-pure Nickel for Structural Components of Low-Radioactivity Instruments</a></h3>
                    <p><strong>Authors:</strong> T. J. Roosendaal, C. T. Overman, G. S. Ortega, T. D. Schlieder, N. D. Rocco, L. K. S. Horkley, K. P. Hobbs, K. Harouaka, J. L. Orrell, P. Acharya, A. Amy, E. Angelico, A. Anker, I. J. Arnquist, A. Atencio, J. Bane, V. Belov, E. P. Bernard, T. Bhatta, A. Bolotnikov, J. Breslin, P. A. Breur, J. P. Brodsky, E. Brown, T. Brunner, B. Burnell, E. Caden, L. Q. Cao, D. Cesmecioglu, S. A. Charlebois, D. Chernyak, M. Chiu, T. Daniels, L. Darroch, R. DeVoe, M. L. di Vacri, M. J. Dolinski, B. Eckert, M. Elbeltagi, A. Emara, W. Fairbank, B. T. Foust, D. Gallacher, N. Gallice, W. Gillis, A. Gorham, G. Gratta, C. A. Hardy, S. C. Hedges, M. Heffner, E. Hein, J. D. Holt, A. Iverson, A. Karelin, I. V. Kotov, A. Kuchenkov, A. Larson, M. B. Latif, S. Lavoie, K. G. Leach, B. G. Lenardo, D. S. Leonard, K. K. H. Leung, H. Lewis, X. Li, Z. Li, C. Licciardi, R. Lindsay, R. MacLellan, S. Majidi, C. Malbrunot, M. Marquis. J. Masbou, M. Medina-Peregrina, S. Mngonyama, B. Mong, D. C. Moore, X. E. Ngwadla, K. Ni, A. Nolan, S. C. Nowicki, J. C. Nzobadila Ondze, A. Odian, L. Pagani, H. Peltz Smalley, A. Pena-Perez, A. Piepke, A. Pocar, S. Prentice, V. Radeka, R. Rai, H. Rasiwala, D. Ray, S. Rescia, G. Richardson, V. Riot, R. Ross, P. C. Rowson, R. Saldanha, S. Sangiorgio, S. Sekula, T. Shetty, L. Si, J. Soderstrom, F. Spadoni, V. Stekhanov, X. L. Sun, S. Thibado, T. Totev, S. Triambak, R. H. M. Tsang, O. A. Tyuka, E. van Bruggen, M. Vidal, M. Walent, Y. G. Wang, Q. D. Wang, M. P. Watts, M. Wehrfritz, L. J. Wen, S. Wilde, M. Worcester, X. M. Wu, H. Xu, H. B. Yang, L. Yang, O. Zeldovich</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> nucl-ex</p>
                    <p><strong>Summary:</strong> The next generation of rare-event search experiments in nuclear and particle physics demand structural materials combining exceptional mechanical strength with ultra-low levels of radioactive contamination. This study evaluates chemical vapor deposition (CVD) nickel as a candidate structural material for such applications. Manufacturer-supplied CVD Ni grown on aluminum substrates underwent tensile testing before and after welding alongside standard Ni samples. CVD Ni exhibited a planar tensile strength of ~600 MPa, significantly surpassing standard nickel. However, welding and heat treatment were found to reduce the tensile strength to levels comparable to standard Ni, with observed porosity in the welds likely contributing to this reduction. Material assay via inductively coupled plasma mass spectrometry (ICP-MS) employing isotope-dilution produced measured bulk concentration of 232-Th, 238-U, and nat-K at the levels of ~70 ppq, 100 ppq, and ~900 ppt, respectively, which is the lowest reported in nickel. Surface-etch profiling uncovered higher concentrations of these contaminants extending ~10 micrometer beneath the surface, likely associated with the aluminum growth substrate. The results reported are compared to the one other well documented usage of CVD Ni in a low radioactive background physics research experiment and a discussion is provided on how the currently reported results may arise from changes in CVD fabrication or testing process. These results establish CVD Ni as a promising low-radioactivity structural material, while outlining the need for further development in welding and surface cleaning techniques to fully realize its potential in large-scale, low radioactive background rare-event search experiments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08227v1" target="_blank">OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution</a></h3>
                    <p><strong>Authors:</strong> Zhiqiang Wu, Zhaomang Sun, Tong Zhou, Bingtao Fu, Ji Cong, Yitong Dong, Huaqi Zhang, Xuan Tang, Mingsong Chen, Xian Wei</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM) generative models show promising potential for one-step Real-World Image Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a Low-Quality (LQ) image latent distribution at the initial timestep. However, a fundamental gap exists between the LQ image latent distribution and the Gaussian noisy latent distribution, limiting the effective utilization of generative priors. We observe that the noisy latent distribution at DDPM/FM mid-timesteps aligns more closely with the LQ image latent distribution. Based on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a universal framework applicable to DDPM/FM-based generative models. OMGSR injects the LQ image latent distribution at a pre-computed mid-timestep, incorporating the proposed Latent Distribution Refinement loss to alleviate the latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to eliminate checkerboard artifacts in image generation. Within this framework, we instantiate OMGSR for DDPM/FM-based generative models with two variants: OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate that OMGSR-S/F achieves balanced/excellent performance across quantitative and qualitative metrics at 512-resolution. Notably, OMGSR-F establishes overwhelming dominance in all reference metrics. We further train a 1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which yields excellent results, especially in the details of the image generation. We also generate 2k-resolution images by the 1k-resolution OMGSR-F using our two-stage Tiled VAE  Diffusion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08226v1" target="_blank">Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy</a></h3>
                    <p><strong>Authors:</strong> Haiyue Chen, Aniket Datar, Tong Xu, Francesco Cancelliere, Harsh Rangwala, Madhan Balaji Rao, Daeun Song, David Eichinger, Xuesu Xiao</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Off-road navigation is an important capability for mobile robots deployed in environments that are inaccessible or dangerous to humans, such as disaster response or planetary exploration. Progress is limited due to the lack of a controllable and standardized real-world testbed for systematic data collection and validation. To fill this gap, we introduce Verti-Arena, a reconfigurable indoor facility designed specifically for off-road autonomy. By providing a repeatable benchmark environment, Verti-Arena supports reproducible experiments across a variety of vertically challenging terrains and provides precise ground truth measurements through onboard sensors and a motion capture system. Verti-Arena also supports consistent data collection and comparative evaluation of algorithms in off-road autonomy research. We also develop a web-based interface that enables research groups worldwide to remotely conduct standardized off-road autonomy experiments on Verti-Arena.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08225v1" target="_blank">Industrial Viewpoints on RAN Technologies for 6G</a></h3>
                    <p><strong>Authors:</strong> Mansoor Shafi, Erik G. Larsson, Xingqin Lin, Dorin Panaitopol, Stefan Parkvall, Flavien Ronteix-Jacquet, Antti Toskala</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> 6G standardization is to start imminently, with commercial deployments expected before 2030. Its technical components and performance requirements are the focus of this article. Our emphasis is on the 6G radio access, especially MIMO, AI, waveforms, coding, signal constellations and integration with non-terrestrial networks. Whilst standardization has not yet formally started, the scope of the 6G study items has been defined. Our predictions in this paper are speculative as there are no results of the study yet, but our views are guided by implementation and deployment aspects. We expect that the views here will guide researchers and industry practitioners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08223v1" target="_blank">Photon Statistics for Fock and Coherent States Interfering in a Beamsplitter</a></h3>
                    <p><strong>Authors:</strong> Jhordan A. T. Santiago</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We present a straightforward yet comprehensive theoretical study of different quantum states emerging from a bi-modal beamsplitter when various input states interfere. Specifically, we analyze the output states for different combinations of input fields, including Fock states $|n\rangle|m\rangle$, hybrid states $|n\rangle|\alpha\rangle$, and coherent states $|\alpha\rangle|\beta\rangle$. We derive explicit expressions for the output state vectors, calculate the mean photon number, photon number variance, Mandel Q parameter, and secondorder coherence function to characterize the statistical properties of the output fields. Our results are intended as a pedagogical resource, serving as an introductory reference for students and researchers aiming to understand basic photon statistics using beamsplitters.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08221v1" target="_blank">Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning</a></h3>
                    <p><strong>Authors:</strong> Zihe Liu, Jiashun Liu, Yancheng He, Weixun Wang, Jiaheng Liu, Ling Pan, Xinyu Hu, Shaopan Xiong, Ju Huang, Jian Hu, Shengyi Huang, Siran Yang, Jiamang Wang, Wenbo Su, Bo Zheng</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement learning for LLM reasoning has rapidly emerged as a prominent research area, marked by a significant surge in related studies on both algorithmic innovations and practical applications. Despite this progress, several critical challenges remain, including the absence of standardized guidelines for employing RL techniques and a fragmented understanding of their underlying mechanisms. Additionally, inconsistent experimental settings, variations in training data, and differences in model initialization have led to conflicting conclusions, obscuring the key characteristics of these techniques and creating confusion among practitioners when selecting appropriate techniques. This paper systematically reviews widely adopted RL techniques through rigorous reproductions and isolated evaluations within a unified open-source framework. We analyze the internal mechanisms, applicable scenarios, and core principles of each technique through fine-grained experiments, including datasets of varying difficulty, model sizes, and architectures. Based on these insights, we present clear guidelines for selecting RL techniques tailored to specific setups, and provide a reliable roadmap for practitioners navigating the RL for the LLM domain. Finally, we reveal that a minimalist combination of two techniques can unlock the learning capability of critic-free policies using vanilla PPO loss. The results demonstrate that our simple combination consistently improves performance, surpassing strategies like GRPO and DAPO.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08220v1" target="_blank">Learning User Preferences for Image Generation Model</a></h3>
                    <p><strong>Authors:</strong> Wenyi Mo, Ying Ba, Tianyu Zhang, Yalong Bai, Biye Li</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> User preference prediction requires a comprehensive and accurate understanding of individual tastes. This includes both surface-level attributes, such as color and style, and deeper content-related aspects, such as themes and composition. However, existing methods typically rely on general human preferences or assume static user profiles, often neglecting individual variability and the dynamic, multifaceted nature of personal taste. To address these limitations, we propose an approach built upon Multimodal Large Language Models, introducing contrastive preference loss and preference tokens to learn personalized user preferences from historical interactions. The contrastive preference loss is designed to effectively distinguish between user likes and dislikes, while the learnable preference tokens capture shared interest representations among existing users, enabling the model to activate group-specific preferences and enhance consistency across similar users. Extensive experiments demonstrate our model outperforms other methods in preference prediction accuracy, effectively identifying users with similar aesthetic inclinations and providing more precise guidance for generating images that align with individual tastes. The project page is \texttt{https://learn-user-pref.github.io/}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08216v1" target="_blank">Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion</a></h3>
                    <p><strong>Authors:</strong> Nicole Lai-Tan, Xiao Gu, Marios G. Philiastides, Fani Deligianni</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, eess.SP</p>
                    <p><strong>Summary:</strong> Personalised music-based interventions offer a powerful means of supporting motor rehabilitation by dynamically tailoring auditory stimuli to provide external timekeeping cues, modulate affective states, and stabilise gait patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for adapting these interventions across individuals. However, inter-subject variability in EEG signals, further compounded by movement-induced artefacts and motor planning differences, hinders the generalisability of BCIs and results in lengthy calibration processes. We propose Individual Tangent Space Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific recentering, distribution matching, and supervised rotational alignment to enhance cross-subject generalisation. Our hybrid architecture fuses Regularised Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and sequential configurations, improving class separability while maintaining the geometric structure of covariance matrices for robust statistical computation. Using leave-one-subject-out cross-validation, `ITSA demonstrates significant performance improvements across subjects and conditions. The parallel fusion approach shows the greatest enhancement over its sequential counterpart, with robust performance maintained across varying data conditions and electrode configurations. The code will be made publicly available at the time of publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08211v1" target="_blank">SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling</a></h3>
                    <p><strong>Authors:</strong> Zhuohao Yu, Xingru Jiang, Weizheng Gu, Yidong Wang, Shikun Zhang, Wei Ye</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Watermarking LLM-generated text is critical for content attribution and misinformation prevention. However, existing methods compromise text quality, require white-box model access and logit manipulation. These limitations exclude API-based models and multilingual scenarios. We propose SAEMark, a general framework for post-hoc multi-bit watermarking that embeds personalized messages solely via inference-time, feature-based rejection sampling without altering model logits or requiring training. Our approach operates on deterministic features extracted from generated text, selecting outputs whose feature statistics align with key-derived targets. This framework naturally generalizes across languages and domains while preserving text quality through sampling LLM outputs instead of modifying. We provide theoretical guarantees relating watermark success probability and compute budget that hold for any suitable feature extractor. Empirically, we demonstrate the frameworks effectiveness using Sparse Autoencoders (SAEs), achieving superior detection accuracy and text quality. Experiments across 4 datasets show SAEMarks consistent performance, with 99.7% F1 on English and strong multi-bit detection accuracy. SAEMark establishes a new paradigm for scalable watermarking that works out-of-the-box with closed-source LLMs while enabling content attribution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08205v1" target="_blank">Optical discrimination of live single cancer cells using reflection-based nanohole array sensor</a></h3>
                    <p><strong>Authors:</strong> Alfredo Franco, Izan CalderÃ³n, Dolores Ortiz, JosÃ© L. FernÃ¡ndez-Luna, Fernando Moreno</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> In this research, a reflection-based nanohole array sensor system is presented for discriminating between migration-competent cancer cells that maintain the integrity of the actin cortex and those cells lacking the actin cortex and thus unable to migrate. Unlike previous transmission-based approaches, this configuration allows for more practical integration into in situ diagnostic tools. For the first time, the system performance is analyzed by studying the spectral features of the reflected light by live single cells. We demonstrate that the presence of the actin cortex, needed for cell migration, in different types of cancer cells significantly affect their optical response, enabling high sensitivity and specificity in cell classification. Our results pave the way for reflection-based plasmonic biosensor devices as a compact and efficient platform for developing biomedical application tools.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08204v1" target="_blank">Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Kyle Moore, Jesse Roberts, Daryl Watson</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> There has been much recent interest in evaluating large language models for uncertainty calibration to facilitate model control and modulate user trust. Inference time uncertainty, which may provide a real-time signal to the model or external control modules, is particularly important for applying these concepts to improve LLM-user experience in practice. While many of the existing papers consider model calibration, comparatively little work has sought to evaluate how closely model uncertainty aligns to human uncertainty. In this work, we evaluate a collection of inference-time uncertainty measures, using both established metrics and novel variations, to determine how closely they align with both human group-level uncertainty and traditional notions of model calibration. We find that numerous measures show evidence of strong alignment to human uncertainty, even despite the lack of alignment to human answer preference. For those successful metrics, we find moderate to strong evidence of model calibration in terms of both correctness correlation and distributional analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08199v1" target="_blank">Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model</a></h3>
                    <p><strong>Authors:</strong> Peiqi He, Zhenhao Zhang, Yixiang Zhang, Xiongjun Zhao, Shaoliang Peng</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Precise spatial modeling in the operating room (OR) is foundational to many clinical tasks, supporting intraoperative awareness, hazard avoidance, and surgical decision-making. While existing approaches leverage large-scale multimodal datasets for latent-space alignment to implicitly learn spatial relationships, they overlook the 3D capabilities of MLLMs. However, this approach raises two issues: (1) Operating rooms typically lack multiple video and audio sensors, making multimodal 3D data difficult to obtain; (2) Training solely on readily available 2D data fails to capture fine-grained details in complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first large vision-language model for 3D spatial reasoning in operating rooms using only RGB modality to infer volumetric and semantic cues, enabling downstream medical tasks with detailed and holistic spatial context. Spatial-ORMLLM incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D modality inputs with rich 3D spatial knowledge extracted by the estimation algorithm and then feeds the combined features into the visual tower. By employing a unified end-to-end MLLM framework, it combines powerful spatial features with textual features to deliver robust 3D scene reasoning without any additional expert annotations or sensor inputs. Experiments on multiple benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves state-of-the-art performance and generalizes robustly to previously unseen surgical scenarios and downstream tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08193v1" target="_blank">Street-Level AI: Are Large Language Models Ready for Real-World Judgments?</a></h3>
                    <p><strong>Authors:</strong> Gaurab Pokharel, Shafkat Farabi, Patrick J. Fowler, Sanmay Das</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> A surge of recent work explores the ethical and societal implications of large-scale AI models that make moral judgments. Much of this literature focuses either on alignment with human judgments through various thought experiments or on the group fairness implications of AI judgments. However, the most immediate and likely use of AI is to help or fully replace the so-called street-level bureaucrats, the individuals deciding to allocate scarce social resources or approve benefits. There is a rich history underlying how principles of local justice determine how society decides on prioritization mechanisms in such domains. In this paper, we examine how well LLM judgments align with human judgments, as well as with socially and politically determined vulnerability scoring systems currently used in the domain of homelessness resource allocation. Crucially, we use real data on those needing services (maintaining strict confidentiality by only using local large models) to perform our analyses. We find that LLM prioritizations are extremely inconsistent in several ways: internally on different runs, between different LLMs, and between LLMs and the vulnerability scoring systems. At the same time, LLMs demonstrate qualitative consistency with lay human judgments in pairwise testing. Findings call into question the readiness of current generation AI systems for naive integration in high-stakes societal decision-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08189v1" target="_blank">Reinforcement Learning in Vision: A Survey</a></h3>
                    <p><strong>Authors:</strong> Weijia Wu, Chen Gao, Joya Chen, Kevin Qinghong Lin, Qingwei Meng, Yiming Zhang, Yuke Qiu, Hong Zhou, Mike Zheng Shou</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advances at the intersection of reinforcement learning (RL) and visual intelligence have enabled agents that not only perceive complex visual scenes but also reason, generate, and act within them. This survey offers a critical and up-to-date synthesis of the field. We first formalize visual RL problems and trace the evolution of policy-optimization strategies from RLHF to verifiable reward paradigms, and from Proximal Policy Optimization to Group Relative Policy Optimization. We then organize more than 200 representative works into four thematic pillars: multi-modal large language models, visual generation, unified model frameworks, and vision-language-action models. For each pillar we examine algorithmic design, reward engineering, benchmark progress, and we distill trends such as curriculum-driven training, preference-aligned diffusion, and unified reward modeling. Finally, we review evaluation protocols spanning set-level fidelity, sample-level preference, and state-level stability, and we identify open challenges that include sample efficiency, generalization, and safe deployment. Our goal is to provide researchers and practitioners with a coherent map of the rapidly expanding landscape of visual RL and to highlight promising directions for future inquiry. Resources are available at: https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08187v1" target="_blank">IDSO-Managed Bid-Based Transactive Distribution Systems Design for DER Participation in Wholesale Markets While Preserving T-D Interactions</a></h3>
                    <p><strong>Authors:</strong> Swastik Sharma, Swathi Battula, Sri Niwas Singh</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Participation of Distributed Energy Resources (DERs) in bid-based Transactive Energy Systems (TES) at the distribution systems facilitates strongly coupled, bidirectional interactions between Transmission-Distribution (T-D) systems. Capturing these interactions is critical for ensuring seamless integration within an Integrated Transmission and Distribution (ITD) framework. This study proposes a methodology to preserve such tight T-D linkages by developing an Independent Distribution System Operator (IDSO) managed bid-based TES design for unbalanced distribution systems. The proposed design operates within the ITD paradigm and permits DER participation in the Wholesale Power Market (WPM) through IDSO while preserving tight T-D linkages. To this end, this research offers the following key contributions: a novel bid/offer prequalification-cum-aggregation method to ensure a grid-safe and value-based aggregation of DERs bids and offers for WPM participation through IDSO; and a retail pricing mechanism that reflects the true value of procuring or offering additional units of power within the distribution system. Case studies are conducted on a modified IEEE 123-bus radial feeder populated with a high DER concentration to validate the proposed frameworks effectiveness in coordinating the DERs efficiently and reliably.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08180v1" target="_blank">RedDino: A foundation model for red blood cell analysis</a></h3>
                    <p><strong>Authors:</strong> Luca Zedda, Andrea Loddo, Cecilia Di Ruberto, Carsten Marr</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Red blood cells (RBCs) are essential to human health, and their precise morphological analysis is important for diagnosing hematological disorders. Despite the promise of foundation models in medical diagnostics, comprehensive AI solutions for RBC analysis remain scarce. We present RedDino, a self-supervised foundation model designed for RBC image analysis. RedDino uses an RBC-specific adaptation of the DINOv2 self-supervised learning framework and is trained on a curated dataset of 1.25 million RBC images from diverse acquisition modalities and sources. Extensive evaluations show that RedDino outperforms existing state-of-the-art models on RBC shape classification. Through assessments including linear probing and nearest neighbor classification, we confirm its strong feature representations and generalization ability. Our main contributions are: (1) a foundation model tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations for RBC modeling, and (3) a detailed evaluation of generalization performance. RedDino addresses key challenges in computational hematology by capturing nuanced morphological features, advancing the development of reliable diagnostic tools. The source code and pretrained models for RedDino are available at https://github.com/Snarci/RedDino, and the pretrained models can be downloaded from our Hugging Face collection at https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08179v1" target="_blank">PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation</a></h3>
                    <p><strong>Authors:</strong> Sihan Zhao, Zixuan Wang, Tianyu Luan, Jia Jia, Wentao Zhu, Jiebo Luo, Junsong Yuan, Nan Xi</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.MM</p>
                    <p><strong>Summary:</strong> Human motion generation has found widespread applications in AR/VR, film, sports, and medical rehabilitation, offering a cost-effective alternative to traditional motion capture systems. However, evaluating the fidelity of such generated motions is a crucial, multifaceted task. Although previous approaches have attempted at motion fidelity evaluation using human perception or physical constraints, there remains an inherent gap between human-perceived fidelity and physical feasibility. Moreover, the subjective and coarse binary labeling of human perception further undermines the development of a robust data-driven metric. We address these issues by introducing a physical labeling method. This method evaluates motion fidelity by calculating the minimum modifications needed for a motion to align with physical laws. With this approach, we are able to produce fine-grained, continuous physical alignment annotations that serve as objective ground truth. With these annotations, we propose PP-Motion, a novel data-driven metric to evaluate both physical and perceptual fidelity of human motion. To effectively capture underlying physical priors, we employ Pearsons correlation loss for the training of our metric. Additionally, by incorporating a human-based perceptual fidelity loss, our metric can capture fidelity that simultaneously considers both human perception and physical alignment. Experimental results demonstrate that our metric, PP-Motion, not only aligns with physical laws but also aligns better with human perception of motion fidelity than previous work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08177v1" target="_blank">MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision</a></h3>
                    <p><strong>Authors:</strong> Zhonghao Yan, Muxi Diao, Yuxuan Yang, Jiayuan Xu, Kaizhou Zhang, Ruoyan Jing, Lele Yang, Yanxi Liu, Kongming Liang, Zhanyu Ma</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Accurately grounding regions of interest (ROIs) is critical for diagnosis and treatment planning in medical imaging. While multimodal large language models (MLLMs) combine visual perception with natural language, current medical-grounding pipelines still rely on supervised fine-tuning with explicit spatial hints, making them ill-equipped to handle the implicit queries common in clinical practice. This work makes three core contributions. We first define Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that demands clinical reasoning and pixel-level grounding. Second, we release U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside implicit clinical queries and reasoning traces, spanning 10 modalities, 15 super-categories, and 108 specific categories. Finally, we introduce MedReasoner, a modular framework that distinctly separates reasoning from segmentation: an MLLM reasoner is optimized with reinforcement learning, while a frozen segmentation expert converts spatial prompts into masks, with alignment achieved through format and accuracy rewards. MedReasoner achieves state-of-the-art performance on U-MRG-14K and demonstrates strong generalization to unseen clinical queries, underscoring the significant promise of reinforcement learning for interpretable medical grounding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08158v1" target="_blank">Can AI Explanations Make You Change Your Mind?</a></h3>
                    <p><strong>Authors:</strong> Laura Spillner, Rachel Ringe, Robert Porzel, Rainer Malaka</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI</p>
                    <p><strong>Summary:</strong> In the context of AI-based decision support systems, explanations can help users to judge when to trust the AIs suggestion, and when to question it. In this way, human oversight can prevent AI errors and biased decision-making. However, this rests on the assumption that users will consider explanations in enough detail to be able to catch such errors. We conducted an online study on trust in explainable DSS, and were surprised to find that in many cases, participants spent little time on the explanation and did not always consider it in detail. We present an exploratory analysis of this data, investigating what factors impact how carefully study participants consider AI explanations, and how this in turn impacts whether they are open to changing their mind based on what the AI suggests.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08150v1" target="_blank">Recent Progress on Fractal Percolation</a></h3>
                    <p><strong>Authors:</strong> IstvÃ¡n KolossvÃ¡ry, Sascha Troscheit</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> math.PR, math.CA, math.DS, Primary 28A80, Secondary 60J80, 60K35, 60D05, 37C45</p>
                    <p><strong>Summary:</strong> This is a survey paper about the fractal percolation process, also known as Mandelbrot percolation. It is intended to give a general breadth overview of more recent research in the topic, but also includes some of the more classical results, for example related to the connectivity properties. Particular emphasis is put on the dimension theory of the limiting set and also on the geometry of the non-trivial connected components in the supercritical regime. In particular, we show that both the Assouad spectrum and intermediate dimensions of the non-trivial connected components are constant equal to its box dimension despite its Hausdorff, box and Assouad dimensions known to being distinct.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08147v1" target="_blank">From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework</a></h3>
                    <p><strong>Authors:</strong> Yunkai Hu, Tianqiao Zhao, Meng Yue</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This paper introduces a novel Large Language Models (LLMs)-assisted agent that automatically converts natural-language descriptions of power system optimization scenarios into compact, solver-ready formulations and generates corresponding solutions. In contrast to approaches that rely solely on LLM to produce solutions directly, the proposed method focuses on discovering a mathematically compatible formulation that can be efficiently solved by off-the-shelf optimization solvers. Directly using LLMs to produce solutions often leads to infeasible or suboptimal results, as these models lack the numerical precision and constraint-handling capabilities of established optimization solvers. The pipeline integrates a domain-aware prompt and schema with an LLM, enforces feasibility through systematic validation and iterative repair, and returns both solver-ready models and user-facing results. Using the unit commitment problem as a representative case study, the agent produces optimal or near-optimal schedules along with the associated objective costs. Results demonstrate that coupling the solver with task-specific validation significantly enhances solution reliability. This work shows that combining AI with established optimization frameworks bridges high-level problem descriptions and executable mathematical models, enabling more efficient decision-making in energy systems</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08146v1" target="_blank">An effective potential for generative modelling with active matter</a></h3>
                    <p><strong>Authors:</strong> Adrian Baule</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.stat-mech, cond-mat.soft, cs.LG</p>
                    <p><strong>Summary:</strong> Score-based diffusion models generate samples from a complex underlying data distribution by time-reversal of a diffusion process and represent the state-of-the-art in many generative AI applications such as artificial image synthesis. Here, I show how a generative diffusion model can be implemented based on an underlying active particle process with finite correlation time. In contrast to previous approaches that use a score function acting on the velocity coordinate of the active particle, time reversal is here achieved by imposing an effective time-dependent potential on the position coordinate only. The effective potential is valid to first order in the persistence time and leads to a force field that is fully determined by the standard score function and its derivatives up to 2nd order. Numerical experiments for artificial data distributions confirm the validity of the effective potential.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08143v1" target="_blank">AI Gossip</a></h3>
                    <p><strong>Authors:</strong> Joel Krueger, Lucy Osler</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Generative AI chatbots like OpenAIs ChatGPT and Googles Gemini routinely make things up. They hallucinate historical events and figures, legal cases, academic papers, non-existent tech products and features, biographies, and news articles. Recently, some have argued that these hallucinations are better understood as bullshit. Chatbots produce rich streams of text that look truth-apt without any concern for the truthfulness of what this text says. But can they also gossip? We argue that they can. After some definitions and scene-setting, we focus on a recent example to clarify what AI gossip looks like before considering some distinct harms -- what we call technosocial harms -- that follow from it.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08138v1" target="_blank">Reproducing and Extending Brownian Motion in Optical Trap: A Computational Reimplementation of Volpe and Volpe (2013)</a></h3>
                    <p><strong>Authors:</strong> Eyad I. B Hamid</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph</p>
                    <p><strong>Summary:</strong> We present a re-representation and independent simulation of the model introduced by Giorgio Volpe and Giovanni Volpe in their 2013 study of a Brownian particle in an optical trap (Volpe and Volpe, 2013). Rather than duplicating their original plots, we reconstructed the simulations from first principles using Python, implementing stochastic differential equations via finite difference schemes. This work reproduces and validates the key physical regimes described in the original article, including the transition from ballistic to diffusive motion, optical confinement, and velocity autocorrelations. To simulate rotational forces (Grier, 2003) and Kramers transitions (Haenggi et al., 1990), we also extend the analysis to include force perturbations, rotational fields, Kramers transitions, and stochastic resonance. The simulations provide pedagogical insight into stochastic dynamics and numerical modeling, reinforcing the original studys value as a teaching and research tool in statistical and computational physics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08137v1" target="_blank">MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation</a></h3>
                    <p><strong>Authors:</strong> Pravallika Abbineni, Saoud Aldowaish, Colin Liechty, Soroosh Noorzad, Ali Ghazizadeh, Morteza Fayazi</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08133v1" target="_blank">Teaching Problem Solving in Undergraduate Physics Courses: An Endorsement for Deliberate Practice</a></h3>
                    <p><strong>Authors:</strong> Kelly Miller, Olivia Miller, Georgia Lawrence</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> Developing expert-like problem-solving skills is a central goal of undergraduate physics education. In this study, we investigate the impact of teaching explicit problem-solving frameworks, combined with deliberate practice, on students problem-solving approaches. Using multidimensional scaling to analyze students decision-making patterns, we compare the similarity of students taught with these methods to physics experts and to students taught with traditional repeated practice. Our results show that students who received structured frameworks and targeted feedback through deliberate practice exhibited problem-solving behaviors significantly more aligned with those of experts. These findings suggest that pedagogies emphasizing explicit strategy instruction with feedback are more effective than rote repetition for fostering expertise. We recommend integration of these approaches into physics curricula to better support the development of skilled and adaptive problem solvers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08132v1" target="_blank">Deep Reinforcement Learning with Local Interpretability for Transparent Microgrid Resilience Energy Management</a></h3>
                    <p><strong>Authors:</strong> Mohammad Hossein Nejati Amiri, Fawaz Annaz, Mario De Oliveira, Florimond Gueniat</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Renewable energy integration into microgrids has become a key approach to addressing global energy issues such as climate change and resource scarcity. However, the variability of renewable sources and the rising occurrence of High Impact Low Probability (HILP) events require innovative strategies for reliable and resilient energy management. This study introduces a practical approach to managing microgrid resilience through Explainable Deep Reinforcement Learning (XDRL). It combines the Proximal Policy Optimization (PPO) algorithm for decision-making with the Local Interpretable Model-agnostic Explanations (LIME) method to improve the transparency of the actor networks decisions. A case study in Ongole, India, examines a microgrid with wind, solar, and battery components to validate the proposed approach. The microgrid is simulated under extreme weather conditions during the Layla cyclone. LIME is used to analyse scenarios, showing the impact of key factors such as renewable generation, state of charge, and load prioritization on decision-making. The results demonstrate a Resilience Index (RI) of 0.9736 and an estimated battery lifespan of 15.11 years. LIME analysis reveals the rationale behind the agents actions in idle, charging, and discharging modes, with renewable generation identified as the most influential feature. This study shows the effectiveness of integrating advanced DRL algorithms with interpretable AI techniques to achieve reliable and transparent energy management in microgrids.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08131v1" target="_blank">Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models</a></h3>
                    <p><strong>Authors:</strong> Wenze Xu, Chun Wang, Jiazhen Yu, Sheng Chen, Liang Gao, Weihong Deng</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to perceive speech inputs, have gained increasing attention for their potential to advance speech understanding tasks. However, despite recent progress, studies show that SLMs often struggle to generalize across datasets, even for trained languages and tasks, raising concerns about whether they process speech in a text-like manner as intended. A key challenge underlying this limitation is the modality gap between speech and text representations. The high variability in speech embeddings may allow SLMs to achieve strong in-domain performance by exploiting unintended speech variations, ultimately hindering generalization. To mitigate this modality gap, we introduce Optimal Transport Regularization (OTReg), a method that formulates speech-text alignment as an optimal transport problem and derives a regularization loss to improve SLM training. In each training iteration, OTReg first establishes a structured correspondence between speech and transcript embeddings by determining the optimal transport plan, then incorporates the regularization loss based on this transport plan to optimize SLMs in generating speech embeddings that align more effectively with transcript embeddings. OTReg is lightweight, requiring no additional labels or learnable parameters, and integrates seamlessly into existing SLM training procedures. Extensive multilingual ASR experiments demonstrate that OTReg enhances speech-text alignment, mitigates the modality gap, and consequently improves SLM generalization across diverse datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08126v1" target="_blank">OFAL: An Oracle-Free Active Learning Framework</a></h3>
                    <p><strong>Authors:</strong> Hadi Khorsand, Vahid Pourahmadi</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In the active learning paradigm, using an oracle to label data has always been a complex and expensive task, and with the emersion of large unlabeled data pools, it would be highly beneficial If we could achieve better results without relying on an oracle. This research introduces OFAL, an oracle-free active learning scheme that utilizes neural network uncertainty. OFAL uses the models own uncertainty to transform highly confident unlabeled samples into informative uncertain samples. First, we start with separating and quantifying different parts of uncertainty and introduce Monte Carlo Dropouts as an approximation of the Bayesian Neural Network model. Secondly, by adding a variational autoencoder, we go on to generate new uncertain samples by stepping toward the uncertain part of latent space starting from a confidence seed sample. By generating these new informative samples, we can perform active learning and enhance the models accuracy. Lastly, we try to compare and integrate our method with other widely used active learning sampling methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08125v1" target="_blank">Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks</a></h3>
                    <p><strong>Authors:</strong> Jakub Å mÃ­d, Pavel PÅ™ibÃ¡Åˆ, OndÅ™ej PraÅ¾Ã¡k, Pavel KrÃ¡l</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In this paper, we introduce a novel Czech dataset for aspect-based sentiment analysis (ABSA), which consists of 3.1K manually annotated reviews from the restaurant domain. The dataset is built upon the older Czech dataset, which contained only separate labels for the basic ABSA tasks such as aspect term extraction or aspect polarity detection. Unlike its predecessor, our new dataset is specifically designed for more complex tasks, e.g. target-aspect-category detection. These advanced tasks require a unified annotation format, seamlessly linking sentiment elements (labels) together. Our dataset follows the format of the well-known SemEval-2016 datasets. This design choice allows effortless application and evaluation in cross-lingual scenarios, ultimately fostering cross-language comparisons with equivalent counterpart datasets in other languages. The annotation process engaged two trained annotators, yielding an impressive inter-annotator agreement rate of approximately 90%. Additionally, we provide 24M reviews without annotations suitable for unsupervised learning. We present robust monolingual baseline results achieved with various Transformer-based models and insightful error analysis to supplement our contributions. Our code and dataset are freely available for non-commercial research purposes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08123v1" target="_blank">A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images</a></h3>
                    <p><strong>Authors:</strong> Lingjing Chen, Chengxiu Zhang, Yinqiao Yi, Yida Wang, Yang Song, Xu Yan, Shengfang Xu, Dalin Zhu, Mengqiu Cao, Yan Zhou, Chenglong Wang, Guang Yang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> We propose a deep learning-based approach that integrates MRI sequence parameters to improve the accuracy and generalizability of quantitative image synthesis from clinical weighted MRI. Our physics-driven neural network embeds MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion time (TI) -- directly into the model via parameter embedding, enabling the network to learn the underlying physical principles of MRI signal formation. The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as input and synthesizes T1, T2, and proton density (PD) quantitative maps. Trained on healthy brain MR images, it was evaluated on both internal and external test datasets. The proposed method achieved high performance with PSNR values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter maps. It outperformed conventional deep learning models in accuracy and robustness, including data with previously unseen brain structures and lesions. Notably, our model accurately synthesized quantitative maps for these unseen pathological regions, highlighting its superior generalization capability. Incorporating MRI sequence parameters via parameter embedding allows the neural network to better learn the physical characteristics of MR signals, significantly enhancing the performance and reliability of quantitative MRI synthesis. This method shows great potential for accelerating qMRI and improving its clinical utility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08120v1" target="_blank">Vision-Based Localization and LLM-based Navigation for Indoor Environments</a></h3>
                    <p><strong>Authors:</strong> Keyan Rahimi, Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Indoor navigation remains a complex challenge due to the absence of reliable GPS signals and the architectural intricacies of large enclosed environments. This study presents an indoor localization and navigation approach that integrates vision-based localization with large language model (LLM)-based navigation. The localization system utilizes a ResNet-50 convolutional neural network fine-tuned through a two-stage process to identify the users position using smartphone camera input. To complement localization, the navigation module employs an LLM, guided by a carefully crafted system prompt, to interpret preprocessed floor plan images and generate step-by-step directions. Experimental evaluation was conducted in a realistic office corridor with repetitive features and limited visibility to test localization robustness. The model achieved high confidence and an accuracy of 96% across all tested waypoints, even under constrained viewing conditions and short-duration queries. Navigation tests using ChatGPT on real building floor maps yielded an average instruction accuracy of 75%, with observed limitations in zero-shot reasoning and inference time. This research demonstrates the potential for scalable, infrastructure-free indoor navigation using off-the-shelf cameras and publicly available floor plans, particularly in resource-constrained settings like hospitals, airports, and educational institutions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08115v1" target="_blank">TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork</a></h3>
                    <p><strong>Authors:</strong> Pranav Pushkar Mishra, Mohammad Arvan, Mohan Zalake</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We present TeamMedAgents, a novel multi-agent approach that systematically integrates evidence-based teamwork components from human-human collaboration into medical decision-making with large language models (LLMs). Our approach validates an organizational psychology teamwork model from human collaboration to computational multi-agent medical systems by operationalizing six core teamwork components derived from Salas et al.s Big Five model: team leadership, mutual performance monitoring, team orientation, shared mental models, closed-loop communication, and mutual trust. We implement and evaluate these components as modular, configurable mechanisms within an adaptive collaboration architecture while assessing the effect of the number of agents involved based on the tasks requirements and domain. Systematic evaluation of computational implementations of teamwork behaviors across eight medical benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets, Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8 evaluated datasets. Controlled ablation studies conducted on 50 questions per configuration across 3 independent runs provide mechanistic insights into individual component contributions, revealing optimal teamwork configurations that vary by reasoning task complexity and domain-specific requirements. Our ablation analyses reveal dataset-specific optimal teamwork configurations, indicating that different medical reasoning modalities benefit from distinct collaborative patterns. TeamMedAgents represents an advancement in collaborative AI by providing a systematic translation of established teamwork theories from human collaboration into agentic collaboration, establishing a foundation for evidence-based multi-agent system design in critical decision-making domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08112v1" target="_blank">Short-Range Order and Li$_x$TM$_{4-x}$ Probability Maps for Disordered Rocksalt Cathodes</a></h3>
                    <p><strong>Authors:</strong> Tzu-chen Liu, Steven B. Torrisi, Chris Wolverton</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Short-range order (SRO) in the cation-disordered state is a controlling factor influencing the probability of finding Li$_{4}$ tetrahedron clusters in disordered rocksalt (DRX) cathode materials. However, the prevalent Li$_4$ probability below the random limit across reported DRX compositions has not been systematically investigated, active strategies to surpass the random limit of Li$_4$ probability are lacking, and the fundamental ordering behavior on the face-centered cubic (FCC) lattice remains insufficiently explored. This research quantitatively examines pair SRO parameters and Li$_x$TM$_{4-x}$ probabilities via exhaustive Monte Carlo mapping across a simplified subset of the parameter space. The results indicate that, in the disordered state, the Li$_4$ probability is governed by the nearest neighbor (NN) pair-wise SRO parameter, and that these quantities do not necessarily represent a simple attenuation of their corresponding low-temperature long-range order, particularly for the important cases of Layered and Spinel-like orderings. Strategies are proposed to mitigate or even reverse the lithium and transition metals mixing tendency of NN pair SRO to achieve Li$_4$ probabilities that exceed the random limit. This study advances the fundamental thermodynamic understanding of ordering behaviors, which can be generalized to any FCC system.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08107v1" target="_blank">Hyperspectral Imaging</a></h3>
                    <p><strong>Authors:</strong> Danfeng Hong, Chenyu Li, Naoto Yokoya, Bing Zhang, Xiuping Jia, Antonio Plaza, Paolo Gamba, Jon Atli Benediktsson, Jocelyn Chanussot</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Hyperspectral imaging (HSI) is an advanced sensing modality that simultaneously captures spatial and spectral information, enabling non-invasive, label-free analysis of material, chemical, and biological properties. This Primer presents a comprehensive overview of HSI, from the underlying physical principles and sensor architectures to key steps in data acquisition, calibration, and correction. We summarize common data structures and highlight classical and modern analysis methods, including dimensionality reduction, classification, spectral unmixing, and AI-driven techniques such as deep learning. Representative applications across Earth observation, precision agriculture, biomedicine, industrial inspection, cultural heritage, and security are also discussed, emphasizing HSIs ability to uncover sub-visual features for advanced monitoring, diagnostics, and decision-making. Persistent challenges, such as hardware trade-offs, acquisition variability, and the complexity of high-dimensional data, are examined alongside emerging solutions, including computational imaging, physics-informed modeling, cross-modal fusion, and self-supervised learning. Best practices for dataset sharing, reproducibility, and metadata documentation are further highlighted to support transparency and reuse. Looking ahead, we explore future directions toward scalable, real-time, and embedded HSI systems, driven by sensor miniaturization, self-supervised learning, and foundation models. As HSI evolves into a general-purpose, cross-disciplinary platform, it holds promise for transformative applications in science, technology, and society.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08100v1" target="_blank">Grid2Guide: A* Enabled Small Language Model for Indoor Navigation</a></h3>
                    <p><strong>Authors:</strong> Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Reliable indoor navigation remains a significant challenge in complex environments, particularly where external positioning signals and dedicated infrastructures are unavailable. This research presents Grid2Guide, a hybrid navigation framework that combines the A* search algorithm with a Small Language Model (SLM) to generate clear, human-readable route instructions. The framework first conducts a binary occupancy matrix from a given indoor map. Using this matrix, the A* algorithm computes the optimal path between origin and destination, producing concise textual navigation steps. These steps are then transformed into natural language instructions by the SLM, enhancing interpretability for end users. Experimental evaluations across various indoor scenarios demonstrate the methods effectiveness in producing accurate and timely navigation guidance. The results validate the proposed approach as a lightweight, infrastructure-free solution for real-time indoor navigation support.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08098v1" target="_blank">TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning</a></h3>
                    <p><strong>Authors:</strong> Junzhe Xu, Yuyang Yin, Xi Chen</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> This paper introduces TBAC-UniImage, a novel unified model for multimodal understanding and generation. We achieve this by deeply integrating a pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal Large Language Model (MLLM). Previous diffusion-based unified models face two primary limitations. One approach uses only the MLLMs final hidden state as the generative condition. This creates a shallow connection, as the generator is isolated from the rich, hierarchical representations within the MLLMs intermediate layers. The other approach, pretraining a unified generative architecture from scratch, is computationally expensive and prohibitive for many researchers. To overcome these issues, our work explores a new paradigm. Instead of relying on a single output, we use representations from multiple, diverse layers of the MLLM as generative conditions for the diffusion model. This method treats the pre-trained generator as a ladder, receiving guidance from various depths of the MLLMs understanding process. Consequently, TBAC-UniImage achieves a much deeper and more fine-grained unification of understanding and generation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08094v1" target="_blank">3D Plant Root Skeleton Detection and Extraction</a></h3>
                    <p><strong>Authors:</strong> Jiakai Lin, Jinchang Zhang, Ge Jin, Wenzhan Song, Tianming Liu, Guoyu Lu</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Plant roots typically exhibit a highly complex and dense architecture, incorporating numerous slender lateral roots and branches, which significantly hinders the precise capture and modeling of the entire root system. Additionally, roots often lack sufficient texture and color information, making it difficult to identify and track root traits using visual methods. Previous research on roots has been largely confined to 2D studies; however, exploring the 3D architecture of roots is crucial in botany. Since roots grow in real 3D space, 3D phenotypic information is more critical for studying genetic traits and their impact on root development. We have introduced a 3D root skeleton extraction method that efficiently derives the 3D architecture of plant roots from a few images. This method includes the detection and matching of lateral roots, triangulation to extract the skeletal structure of lateral roots, and the integration of lateral and primary roots. We developed a highly complex root dataset and tested our method on it. The extracted 3D root skeletons showed considerable similarity to the ground truth, validating the effectiveness of the model. This method can play a significant role in automated breeding robots. Through precise 3D root structure analysis, breeding robots can better identify plant phenotypic traits, especially root structure and growth patterns, helping practitioners select seeds with superior root systems. This automated approach not only improves breeding efficiency but also reduces manual intervention, making the breeding process more intelligent and efficient, thus advancing modern agriculture.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08093v1" target="_blank">MDD-Net: Multimodal Depression Detection through Mutual Transformer</a></h3>
                    <p><strong>Authors:</strong> Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Hamdi Altaheri, Lobna Nassar, Fakhri Karray</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG, cs.MM, eess.AS</p>
                    <p><strong>Summary:</strong> Depression is a major mental health condition that severely impacts the emotional and physical well-being of individuals. The simple nature of data collection from social media platforms has attracted significant interest in properly utilizing this information for mental health research. A Multimodal Depression Detection Network (MDD-Net), utilizing acoustic and visual data obtained from social media networks, is proposed in this work where mutual transformers are exploited to efficiently extract and fuse multimodal features for efficient depression detection. The MDD-Net consists of four core modules: an acoustic feature extraction module for retrieving relevant acoustic attributes, a visual feature extraction module for extracting significant high-level patterns, a mutual transformer for computing the correlations among the generated features and fusing these features from multiple modalities, and a detection layer for detecting depression using the fused feature representations. The extensive experiments are performed using the multimodal D-Vlog dataset, and the findings reveal that the developed multimodal depression detection network surpasses the state-of-the-art by up to 17.37% for F1-Score, demonstrating the greater performance of the proposed system. The source code is accessible at https://github.com/rezwanh001/Multimodal-Depression-Detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08084v1" target="_blank">$100,000 or the Robot Gets it! Tech Workers Resistance Guide: Tech Worker Actions, History, Risks, Impacts, and the Case for a Radical Flank</a></h3>
                    <p><strong>Authors:</strong> Mohamed Abdalla</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Over the past decade, Big Tech has faced increasing levels of worker activism. While worker actions have resulted in positive outcomes (e.g., cancellation of Googles Project Dragonfly), such successes have become increasingly infrequent. This is, in part, because corporations have adjusted their strategies to dealing with increased worker activism (e.g., increased retaliation against workers, and contracts clauses that prevent cancellation due to worker pressure). This change in company strategy prompts urgent questions about updating worker strategies for influencing corporate behavior in an industry with vast societal impact. Current discourse on tech worker activism often lacks empirical grounding regarding its scope, history, and strategic calculus. Our work seeks to bridge this gap by firstly conducting a systematic analysis of worker actions at Google and Microsoft reported in U.S. newspapers to delineate their characteristics. We then situate these actions within the long history of labour movements and demonstrate that, despite perceptions of radicalism, contemporary tech activism is comparatively moderate. Finally, we engage directly with current and former tech activists to provide a novel catalogue of potential worker actions, evaluating their perceived risks, impacts, and effectiveness (concurrently publishing Tech Workers Guide to Resistance). Our findings highlight considerable variation in strategic thinking among activists themselves. We conclude by arguing that the establishment of a radical flank could increase the effectiveness of current movements. Tech Workers Guide to Resistance can be found at https://www.cs.toronto.edu/~msa/TechWorkersResistanceGuide.pdf or https://doi.org/10.5281/zenodo.16779082</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08076v1" target="_blank">Heterogeneity in Entity Matching: A Survey and Experimental Analysis</a></h3>
                    <p><strong>Authors:</strong> Mohammad Hossein Moslemi, Amir Mousavi, Behshid Behkamal, Mostafa Milani</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.DB, 68P20 68P20 68P20, H.2.8; H.2.4; I.2.7</p>
                    <p><strong>Summary:</strong> Entity matching (EM) is a fundamental task in data integration and analytics, essential for identifying records that refer to the same real-world entity across diverse sources. In practice, datasets often differ widely in structure, format, schema, and semantics, creating substantial challenges for EM. We refer to this setting as Heterogeneous EM (HEM). This survey offers a unified perspective on HEM by introducing a taxonomy, grounded in prior work, that distinguishes two primary categories -- representation and semantic heterogeneity -- and their subtypes. The taxonomy provides a systematic lens for understanding how variations in data form and meaning shape the complexity of matching tasks. We then connect this framework to the FAIR principles -- Findability, Accessibility, Interoperability, and Reusability -- demonstrating how they both reveal the challenges of HEM and suggest strategies for mitigating them. Building on this foundation, we critically review recent EM methods, examining their ability to address different heterogeneity types, and conduct targeted experiments on state-of-the-art models to evaluate their robustness and adaptability under semantic heterogeneity. Our analysis uncovers persistent limitations in current approaches and points to promising directions for future research, including multimodal matching, human-in-the-loop workflows, deeper integration with large language models and knowledge graphs, and fairness-aware evaluation in heterogeneous settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08075v1" target="_blank">FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence</a></h3>
                    <p><strong>Authors:</strong> Meishen He, Wenjun Ma, Jiao Wang, Huijun Yue, Xiaoma Fan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The Dempster-Shafer theory of evidence has been widely applied in the field of information fusion under uncertainty. Most existing research focuses on combining evidence within the same frame of discernment. However, in real-world scenarios, trained algorithms or data often originate from different regions or organizations, where data silos are prevalent. As a result, using different data sources or models to generate basic probability assignments may lead to heterogeneous frames, for which traditional fusion methods often yield unsatisfactory results. To address this challenge, this study proposes an open-world information fusion method, termed Full Negation Belief Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a criterion is introduced to determine whether a given fusion task belongs to the open-world setting. Then, by extending the frames, the method can accommodate elements from heterogeneous frames. Finally, a full negation mechanism is employed to transform the mass functions, so that existing combination rules can be applied to the transformed mass functions for such information fusion. Theoretically, the proposed method satisfies three desirable properties, which are formally proven: mass function invariance, heritability, and essential conflict elimination. Empirically, FNBT demonstrates superior performance in pattern classification tasks on real-world datasets and successfully resolves Zadehs counterexample, thereby validating its practical effectiveness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08074v1" target="_blank">Towards General-Purpose Data Discovery: A Programming Languages Approach</a></h3>
                    <p><strong>Authors:</strong> Andrew Kang, Yashnil Saha, Sainyam Galhotra</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.PL</p>
                    <p><strong>Summary:</strong> Efficient and effective data discovery is critical for many modern applications in machine learning and data science. One major bottleneck to the development of a general-purpose data discovery tool is the absence of an expressive formal language, and corresponding implementation, for characterizing and solving generic discovery queries. To this end, we present TQL, a domain-specific language for data discovery well-designed to leverage and exploit the results of programming languages research in both its syntax and semantics. In this paper, we fully and formally characterize the core language through an algebraic model, Imperative Relational Algebra with Types (ImpRAT), and implement a modular proof-of-concept system prototype.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08073v1" target="_blank">ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring</a></h3>
                    <p><strong>Authors:</strong> Dimitris Tsaras, Xing Li, Lei Chen, Zhiyao Xie, Mingxuan Yuan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AR, cs.ET</p>
                    <p><strong>Summary:</strong> In electronic design automation, logic optimization operators play a crucial role in minimizing the gate count of logic circuits. However, their computation demands are high. Operators such as refactor conventionally form iterative cuts for each node, striving for a more compact representation - a task which often fails 98% on average. Prior research has sought to mitigate computational cost through parallelization. In contrast, our approach leverages a classifier to prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis operations. Experiments on the refactor operator using the EPFL benchmark suite and 10 large industrial designs demonstrate that this technique can speedup logic optimization by 3.9x on average compared with the state-of-the-art ABC implementation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08071v1" target="_blank">C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction</a></h3>
                    <p><strong>Authors:</strong> Yunqing Li, Zixiang Tang, Jiaying Zhuang, Zhenyu Yang, Farhad Ameri, Jianbang Zhang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, J.1; I.2.4; H.2.8</p>
                    <p><strong>Summary:</strong> Connecting an ever-expanding catalogue of products with suitable manufacturers and suppliers is critical for resilient, efficient global supply chains, yet traditional methods struggle to capture complex capabilities, certifications, geographic constraints, and rich multimodal data of real-world manufacturer profiles. To address these gaps, we introduce PMGraph, a public benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking 8,888 manufacturers, over 70k products, more than 110k manufacturer-product edges, and over 29k product images. Building on this benchmark, we propose the Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first aligns and aggregates textual and visual attributes into intermediate group embeddings, then propagates them through a manufacturer-product hetero-graph via multiscale message passing to enhance link prediction accuracy. C-MAG also provides practical guidelines for modality-aware fusion, preserving predictive performance in noisy, real-world settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08255v1" target="_blank">Observation of Metal-Insulator and Spectral Phase Transitions in Aubry-AndrÃ©-Harper Models</a></h3>
                    <p><strong>Authors:</strong> Quan Lin, Christopher Cedzich, Qi Zhou, Peng Xue</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.mes-hall, physics.optics</p>
                    <p><strong>Summary:</strong> Non-Hermitian extensions of the Aubry-Andr\e-Harper (AAH) model reveal a rich variety of phase transitions arising from the interplay of quasiperiodicity and non-Hermiticity. Despite their theoretical significance, experimental explorations remain challenging due to complexities in realizing controlled non-Hermiticity. Here, we present the first experimental realization of the unitary almost-Mathieu operator (UAMO) which simulates the AAH model by employing single-photon quantum walks. Through precise control of quasiperiodicity, we systematically explore the phase diagram displaying a phase transition between localized and delocalized regimes in the Hermitian limit. Subsequently, by introducing non-reciprocal hopping, we experimentally probe the parity-time (PT) symmetry-breaking transition that is characterized by the emergence of complex quasienergies. Moreover, we identify a novel spectral transition exclusive to discrete-time settings, where all quasienergies become purely imaginary. Both transitions are connected to changes in the spectral winding number, demonstrating their topological origins. These results clarify the interplay between localization, symmetry breaking, and topology in non-Hermitian quasicrystals, paving the way for future exploration of synthetic quantum matter.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08254v1" target="_blank">Learning an Implicit Physics Model for Image-based Fluid Simulation</a></h3>
                    <p><strong>Authors:</strong> Emily Yue-Ting Jia, Jiageng Mao, Zhiyuan Gao, Yajie Zhao, Yue Wang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Humans possess an exceptional ability to imagine 4D scenes, encompassing both motion and 3D geometry, from a single still image. This ability is rooted in our accumulated observations of similar scenes and an intuitive understanding of physics. In this paper, we aim to replicate this capacity in neural networks, specifically focusing on natural fluid imagery. Existing methods for this task typically employ simplistic 2D motion estimators to animate the image, leading to motion predictions that often defy physical principles, resulting in unrealistic animations. Our approach introduces a novel method for generating 4D scenes with physics-consistent animation from a single image. We propose the use of a physics-informed neural network that predicts motion for each surface point, guided by a loss term derived from fundamental physical principles, including the Navier-Stokes equations. To capture appearance, we predict feature-based 3D Gaussians from the input image and its estimated depth, which are then animated using the predicted motions and rendered from any desired camera perspective. Experimental results highlight the effectiveness of our method in producing physically plausible animations, showcasing significant performance improvements over existing methods. Our project page is https://physfluid.github.io/ .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08252v1" target="_blank">ReferSplat: Referring Segmentation in 3D Gaussian Splatting</a></h3>
                    <p><strong>Authors:</strong> Shuting He, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li, Henghui Ding</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task that aims to segment target objects in a 3D Gaussian scene based on natural language descriptions, which often contain spatial relationships or object attributes. This task requires the model to identify newly described objects that may be occluded or not directly visible in a novel view, posing a significant challenge for 3D multi-modal understanding. Developing this capability is crucial for advancing embodied AI. To support research in this area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that 3D multi-modal understanding and spatial relationship modeling are key challenges for R3DGS. To address these challenges, we propose ReferSplat, a framework that explicitly models 3D Gaussian points with natural language expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art performance on both the newly proposed R3DGS task and 3D open-vocabulary segmentation benchmarks. Dataset and code are available at https://github.com/heshuting555/ReferSplat.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08248v1" target="_blank">StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation</a></h3>
                    <p><strong>Authors:</strong> Shuyuan Tu, Yueming Pan, Yinming Huang, Xintong Han, Zhen Xing, Qi Dai, Chong Luo, Zuxuan Wu, Yu-Gang Jiang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Current diffusion models for audio-driven avatar video generation struggle to synthesize long videos with natural audio synchronization and identity consistency. This paper presents StableAvatar, the first end-to-end video diffusion transformer that synthesizes infinite-length high-quality videos without post-processing. Conditioned on a reference image and audio, StableAvatar integrates tailored training and inference modules to enable infinite-length video generation. We observe that the main reason preventing existing models from generating long videos lies in their audio modeling. They typically rely on third-party off-the-shelf extractors to obtain audio embeddings, which are then directly injected into the diffusion model via cross-attention. Since current diffusion backbones lack any audio-related priors, this approach causes severe latent distribution error accumulation across video clips, leading the latent distribution of subsequent segments to drift away from the optimal distribution gradually. To address this, StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents error accumulation via time-step-aware modulation. During inference, we propose a novel Audio Native Guidance Mechanism to further enhance the audio synchronization by leveraging the diffusions own evolving joint audio-latent prediction as a dynamic guidance signal. To enhance the smoothness of the infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy that fuses latent over time. Experiments on benchmarks show the effectiveness of StableAvatar both qualitatively and quantitatively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08246v1" target="_blank">Composable Quantum Fault-Tolerance</a></h3>
                    <p><strong>Authors:</strong> Zhiyang He, Quynh T. Nguyen, Christopher A. Pattison</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> Proving threshold theorems for fault-tolerant quantum computation is a burdensome endeavor with many moving parts that come together in relatively formulaic but lengthy ways. It is difficult and rare to combine elements from multiple papers into a single formal threshold proof, due to the use of different measures of fault-tolerance. In this work, we introduce composable fault-tolerance, a framework that decouples the probabilistic analysis of the noise distribution from the combinatorial analysis of circuit correctness, and enables threshold proofs to compose independently analyzed gadgets easily and rigorously. Within this framework, we provide a library of standard and commonly used gadgets such as memory and logic implemented by constant-depth circuits for quantum low-density parity check codes and distillation. As sample applications, we explicitly write down a threshold proof for computation with surface code and re-derive the constant space-overhead fault-tolerant scheme of Gottesman using gadgets from this library. We expect that future fault-tolerance proofs may focus on the analysis of novel techniques while leaving the standard components to the composable fault-tolerance framework, with the formal proof following the intuitive ``napkin math exactly.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08245v1" target="_blank">Symmetry-Enriched Topological Phases and Their Gauging: A String-Net Model Realization</a></h3>
                    <p><strong>Authors:</strong> Nianrui Fu, Yu Zhao, Yidun Wan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.stat-mech, hep-th, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We present a systematic framework for constructing exactly-solvable lattice models of symmetry-enriched topological (SET) phases based on an enlarged version of the string-net model. We also gauge the global symmetries of our SET models to obtain string-net models of pure topological phases. Without invoking externally imposed onsite symmetry actions, our approach promotes the string-net model of a pure topological order, specified by an input unitary fusion category $\mathscr{F}$, to an SET model, specified by a multifusion category together with a set of isomorphisms. Two complementary construction strategies are developed in the main text: (i) promotion via outer automorphisms of $\mathscr{F}$ and (ii) promotion via the Frobenius algebras of $\mathscr{F}$. The global symmetries derived via these two strategies are intrinsic to topological phases and are thus termed blood symmetries, as opposed to adopted symmetries, which can be arbitrarily imposed on topological phases. We propose the concept of symmetry-gauging family of topological phases, which are related by gauging their blood symmetries. With our approach, we construct the first explicit lattice realization of a nonabelian-symmetry-enriched topological phase -- the $S_3$ symmetry-enriched $\mathbb{Z}_2 \times \mathbb{Z}_2$ quantum-double phase. The approach further reveals the role of local excitations in SET phases and establishes their symmetry constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08244v1" target="_blank">Cut2Next: Generating Next Shot via In-Context Tuning</a></h3>
                    <p><strong>Authors:</strong> Jingwen He, Hongbo Liu, Jiajun Li, Ziqi Huang, Yu Qiao, Wanli Ouyang, Ziwei Liu</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Effective multi-shot generation demands purposeful, film-like transitions and strict cinematic continuity. Current methods, however, often prioritize basic visual consistency, neglecting crucial editing patterns (e.g., shot/reverse shot, cutaways) that drive narrative flow for compelling storytelling. This yields outputs that may be visually coherent but lack narrative sophistication and true cinematic integrity. To bridge this, we introduce Next Shot Generation (NSG): synthesizing a subsequent, high-quality shot that critically conforms to professional editing patterns while upholding rigorous cinematic continuity. Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This strategy uses Relational Prompts to define overall context and inter-shot editing styles. Individual Prompts then specify per-shot content and cinematographic attributes. Together, these guide Cut2Next to generate cinematically appropriate next shots. Architectural innovations, Context-Aware Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further integrate these diverse signals without introducing new parameters. We construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with hierarchical prompts, and introduce CutBench for evaluation. Experiments show Cut2Next excels in visual consistency and text fidelity. Crucially, user studies reveal a strong preference for Cut2Next, particularly for its adherence to intended editing patterns and overall cinematic continuity, validating its ability to generate high-quality, narratively expressive, and cinematically coherent subsequent shots.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08243v1" target="_blank">Jinx: Unlimited LLMs for Probing Alignment Failures</a></h3>
                    <p><strong>Authors:</strong> Jiahao Zhao, Liwei Dong</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Unlimited, or so-called helpful-only language models are trained without safety alignment constraints and never refuse user queries. They are widely used by leading AI companies as internal tools for red teaming and alignment evaluation. For example, if a safety-aligned model produces harmful outputs similar to an unlimited model, this indicates alignment failures that require further attention. Despite their essential role in assessing alignment, such models are not available to the research community. We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx responds to all queries without refusals or safety filtering, while preserving the base models capabilities in reasoning and instruction following. It provides researchers with an accessible tool for probing alignment failures, evaluating safety boundaries, and systematically studying failure modes in language model safety.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08240v1" target="_blank">ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks</a></h3>
                    <p><strong>Authors:</strong> Kaijun Wang, Liqin Lu, Mingyu Liu, Jianuo Jiang, Zeju Li, Bolin Zhang, Wancai Zheng, Xinyi Yu, Hao Chen, Chunhua Shen</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Language-guided long-horizon mobile manipulation has long been a grand challenge in embodied semantic reasoning, generalizable manipulation, and adaptive locomotion. Three fundamental limitations hinder progress: First, although large language models have improved spatial reasoning and task planning through semantic priors, existing implementations remain confined to tabletop scenarios, failing to address the constrained perception and limited actuation ranges of mobile platforms. Second, current manipulation strategies exhibit insufficient generalization when confronted with the diverse object configurations encountered in open-world environments. Third, while crucial for practical deployment, the dual requirement of maintaining high platform maneuverability alongside precise end-effector control in unstructured settings remains understudied. In this work, we present ODYSSEY, a unified mobile manipulation framework for agile quadruped robots equipped with manipulators, which seamlessly integrates high-level task planning with low-level whole-body control. To address the challenge of egocentric perception in language-conditioned tasks, we introduce a hierarchical planner powered by a vision-language model, enabling long-horizon instruction decomposition and precise action execution. At the control level, our novel whole-body policy achieves robust coordination across challenging terrains. We further present the first benchmark for long-horizon mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through successful sim-to-real transfer, we demonstrate the systems generalization and robustness in real-world deployments, underscoring the practicality of legged manipulators in unstructured environments. Our work advances the feasibility of generalized robotic assistants capable of complex, dynamic tasks. Our project page: https://kaijwang.github.io/odyssey.github.io/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08239v1" target="_blank">Readout of multi-level quantum geometry from electronic transport</a></h3>
                    <p><strong>Authors:</strong> Raffael L. Klees, MÃ³nica Benito</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> The quantum geometric tensor (QGT) of a quantum system in a given parameter space captures both the geometry of the state manifold and the topology of the system. While the local QGT elements have been successfully measured in various platforms, the challenge of detecting them in electronic transport systems - such as tunnel or molecular junctions - has yet to be resolved. To fill this gap, we propose a measurement protocol based on weak and resonant parameter modulations, and theoretically demonstrate how the local QGT in such systems can be directly probed from changes of the tunnel conductance. This approach enables the measurement of both geometrical and topological features of quantum states in a broad class of transport-based quantum systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08238v1" target="_blank">Closing the Mass Window for Stupendously Large Black Holes</a></h3>
                    <p><strong>Authors:</strong> Christopher Gerlach, Yann Gouttenoire, Antonio J. Iovino, Nicholas Leister</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc, hep-ph</p>
                    <p><strong>Summary:</strong> We show that primordial black holes (PBHs) in the $\textit{Stupendously Large Black Hole}$ mass range ($M \gtrsim 10^{11}\,M_\odot$) produce isocurvature perturbations exceeding current $\textit{Planck}$ Cosmic Microwave Background limits, thereby excluding them as a significant dark matter component.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08237v1" target="_blank">VGGSounder: Audio-Visual Evaluations for Foundation Models</a></h3>
                    <p><strong>Authors:</strong> Daniil Zverev, ThaddÃ¤us Wiedemer, Ameya Prabhu, Matthias Bethge, Wieland Brendel, A. Sophia Koepke</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.MM, cs.AI, cs.SD</p>
                    <p><strong>Summary:</strong> The emergence of audio-visual foundation models underscores the importance of reliably assessing their multi-modal understanding. The VGGSounder dataset is commonly used as a benchmark for evaluation audio-visual classification. However, our analysis identifies several limitations of VGGSounder, including incomplete labelling, partially overlapping classes, and misaligned modalities. These lead to distorted evaluations of auditory and visual capabilities. To address these limitations, we introduce VGGSounder, a comprehensively re-annotated, multi-label test set that extends VGGSound and is specifically designed to evaluate audio-visual foundation models. VGGSounder features detailed modality annotations, enabling precise analyses of modality-specific performance. Furthermore, we reveal model limitations by analysing performance degradation when adding another input modality with our new modality confusion metric.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08236v1" target="_blank">Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge</a></h3>
                    <p><strong>Authors:</strong> Yunna Cai, Fan Wang, Haowei Wang, Kun Wang, Kailai Yang, Sophia Ananiadou, Moyan Li, Mingming Fan</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Evaluating the safety alignment of LLM responses in high-risk mental health dialogues is particularly difficult due to missing gold-standard answers and the ethically sensitive nature of these interactions. To address this challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark based on real-world Chinese mental health dialogues. It evaluates whether the model responses align with the safety principles defined by experts. Specifically designed for settings without standard references, our method adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation using expert-defined reasoning chains grounded in psychological intervention principles. We employ binary point-wise scoring across multiple safety dimensions to enhance the explainability and traceability of the evaluation. Additionally, we present a manually curated, high-quality Chinese-language dataset covering self-harm, suicidal ideation, and existential distress, derived from real-world online discourse. Experiments on 3600 judgments show that our method achieves the highest agreement with expert assessments and produces more interpretable evaluation rationales compared to existing approaches. Our dataset and evaluation tool are publicly available to facilitate further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08234v1" target="_blank">Gravitational Waves from Strongly Magnetized Eccentric Neutron Star Binaries</a></h3>
                    <p><strong>Authors:</strong> R. Prasad, Anushka Doke, Prayush Kumar</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, gr-qc</p>
                    <p><strong>Summary:</strong> We study the imprint of magnetic fields on gravitational waves emitted during the inspiral phase of eccentric binary neutron star systems. While observations indicate that neutron stars typically exhibit strong magnetic fields in the range of $10^{14}$-$10^{15}\,\mathrm{G}$, theoretical models allow for fields as high as $ \sim 10^{17-18}\,\mathrm{G}$. In binaries, the fate of these fields depends on the formation pathway: in systems formed through isolated evolution, magnetic fields may decay over long inspiral timescales. In contrast, binaries formed via dynamical capture can retain substantial eccentricity and strong fields until merger, potentially altering the gravitational waveform. We consider two magnetic effects: magnetic interaction between the neutron stars and electromagnetic radiation from the systems effective dipole, and identify regimes where each dominates. Using a perturbative framework, we compute the associated energy loss and gravitational wave phase evolution. We find that for binaries with strong and comparable magnetic fields, $10^{14}\,\mathrm{G}$ fields may be detectable up to $\sim 10 \, \mathrm{Mpc}$ with DECIGO and the Einstein Telescope, while $10^{15}\,\mathrm{G}$ fields extend the reach to several hundred Mpc. For extreme fields of $10^{16}\,\mathrm{G}$, third-generation detectors could be sensitive out to Gpc scales. In contrast, LIGO is limited to galactic distances: $10^{15}\,\mathrm{G}$ fields are detectable only within $\sim 100\,\mathrm{kpc}$, and only ultrastrong fields ($\sim 10^{16}$-$10^{17}\,\mathrm{G}$) are potentially observable at Gpc distances. In highly asymmetric systems, where dipole radiation dominates, the gravitational wave dephasing is significantly suppressed, reducing the detection horizon. These findings suggest that current and future gravitational wave observatories may be capable of identifying magnetized binary systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08232v1" target="_blank">Mamba-FCS: Joint Spatio- Frequency Feature Fusion, Change-Guided Attention, and SeK Loss for Enhanced Semantic Change Detection in Remote Sensing</a></h3>
                    <p><strong>Authors:</strong> Buddhi Wijenayake, Athulya Ratnayake, Praveen Sumanasekara, Roshan Godaliyadda, Parakrama Ekanayake, Vijitha Herath, Nichula Wasalathilaka</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> eess.IV, eess.SP</p>
                    <p><strong>Summary:</strong> Semantic Change Detection (SCD) from remote sensing imagery requires models balancing extensive spatial context, computational efficiency, and sensitivity to class-imbalanced land-cover transitions. While Convolutional Neural Networks excel at local feature extraction but lack global context, Transformers provide global modeling at high computational costs. Recent Mamba architectures based on state-space models offer compelling solutions through linear complexity and efficient long-range modeling. In this study, we introduce Mamba-FCS, a SCD framework built upon Visual State Space Model backbone incorporating, a Joint Spatio-Frequency Fusion block incorporating log-amplitude frequency domain features to enhance edge clarity and suppress illumination artifacts, a Change-Guided Attention (CGA) module that explicitly links the naturally intertwined BCD and SCD tasks, and a Separated Kappa (SeK) loss tailored for class-imbalanced performance optimization. Extensive evaluation on SECOND and Landsat-SCD datasets shows that Mamba-FCS achieves state-of-the-art metrics, 88.62% Overall Accuracy, 65.78% F_scd, and 25.50% SeK on SECOND, 96.25% Overall Accuracy, 89.27% F_scd, and 60.26% SeK on Landsat-SCD. Ablation analyses confirm distinct contributions of each novel component, with qualitative assessments highlighting significant improvements in SCD. Our results underline the substantial potential of Mamba architectures, enhanced by proposed techniques, setting a new benchmark for effective and scalable semantic change detection in remote sensing applications. The complete source code, configuration files, and pre-trained models will be publicly available upon publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08231v1" target="_blank">A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies</a></h3>
                    <p><strong>Authors:</strong> Chris Schmitz, Joanna Bryson</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> Public-sector bureaucracies seek to reap the benefits of artificial intelligence (AI), but face important concerns about accountability and transparency when using AI systems. These concerns center on threats to the twin aims of bureaucracy: legitimate and faithful implementation of legislation, and the provision of stable, long-term governance. Both aims are threatened when AI systems are misattributed as either mere tools or moral subjects - a framing error that creates ethics sinks, constructs that facilitate dissipation of responsibility by obscuring clear lines of human moral agency. Here, we reject the notion that such outcomes are inevitable. Rather, where they appear, they are the product of structural design decisions across both the technology and the institution deploying it. We support this claim via a systematic application of conceptions of moral agency in AI ethics to Weberian bureaucracy. We establish that it is both desirable and feasible to render AI systems as tools for the generation of organizational transparency and legibility, which continue the processes of Weberian rationalization initiated by previous waves of digitalization. We present a three-point Moral Agency Framework for legitimate integration of AI in bureaucratic structures: (a) maintain clear and just human lines of accountability, (b) ensure humans whose work is augmented by AI systems can verify the systems are functioning correctly, and (c) introduce AI only where it doesnt inhibit the capacity of bureaucracies towards either of their twin aims of legitimacy and stewardship. We suggest that AI introduced within this framework can not only improve efficiency and productivity while avoiding ethics sinks, but also improve the transparency and even the legitimacy of a bureaucracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08229v1" target="_blank">Quantum-centric simulation of hydrogen abstraction by sample-based quantum diagonalization and entanglement forging</a></h3>
                    <p><strong>Authors:</strong> Tyler Smith, Tanvi P. Gujarati, Mario Motta, Ben Link, Ieva Liepuoniute, Triet Friedhoff, Hiromichi Nishimura, Nam Nguyen, Kristen S. Williams, Javier Robledo Moreno, Caleb Johnson, Kevin J. Sung, Abdullah Ash Saki, Marna Kagele</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> The simulation of electronic systems is an anticipated application for quantum-centric computers, i.e. heterogeneous architectures where classical and quantum processing units operate in concert. An important application is the computation of radical chain reactions, including those responsible for the photodegradation of composite materials used in aerospace engineering. Here, we compute the activation energy and reaction energy for hydrogen abstraction from 2,2-diphenyldipropane, used as a minimal model for a step in a radical chain reaction. Calculations are performed using a superconducting quantum processor of the IBM Heron family and classical computing resources. To this end, we combine a qubit-reduction technique called entanglement forging (EF) with sample based quantum diagonalization (SQD), a method that projects the Schr\{o}dinger equation into a subspace of configurations sampled from a quantum device. In conventional quantum simulations, a qubit represents a spin-orbital. In contrast, EF maps a qubit to a spatial orbital, reducing the required number of qubits by half. We provide a complete derivation and a detailed description of the combined EF and SQD approach, and we assess its accuracy across active spaces of varying sizes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08227v1" target="_blank">OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution</a></h3>
                    <p><strong>Authors:</strong> Zhiqiang Wu, Zhaomang Sun, Tong Zhou, Bingtao Fu, Ji Cong, Yitong Dong, Huaqi Zhang, Xuan Tang, Mingsong Chen, Xian Wei</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM) generative models show promising potential for one-step Real-World Image Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a Low-Quality (LQ) image latent distribution at the initial timestep. However, a fundamental gap exists between the LQ image latent distribution and the Gaussian noisy latent distribution, limiting the effective utilization of generative priors. We observe that the noisy latent distribution at DDPM/FM mid-timesteps aligns more closely with the LQ image latent distribution. Based on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a universal framework applicable to DDPM/FM-based generative models. OMGSR injects the LQ image latent distribution at a pre-computed mid-timestep, incorporating the proposed Latent Distribution Refinement loss to alleviate the latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to eliminate checkerboard artifacts in image generation. Within this framework, we instantiate OMGSR for DDPM/FM-based generative models with two variants: OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate that OMGSR-S/F achieves balanced/excellent performance across quantitative and qualitative metrics at 512-resolution. Notably, OMGSR-F establishes overwhelming dominance in all reference metrics. We further train a 1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which yields excellent results, especially in the details of the image generation. We also generate 2k-resolution images by the 1k-resolution OMGSR-F using our two-stage Tiled VAE  Diffusion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08224v1" target="_blank">Capabilities of GPT-5 on Multimodal Medical Reasoning</a></h3>
                    <p><strong>Authors:</strong> Shansong Wang, Mingzhe Hu, Qiang Li, Mojtaba Safari, Xiaofeng Yang</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in large language models (LLMs) have enabled general-purpose systems to perform increasingly complex domain-specific reasoning without extensive fine-tuning. In the medical domain, decision-making often requires integrating heterogeneous information sources, including patient narratives, structured data, and medical images. This study positions GPT-5 as a generalist multimodal reasoner for medical decision support and systematically evaluates its zero-shot chain-of-thought reasoning performance on both text-based question answering and visual question answering tasks under a unified protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20 against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that GPT-5 consistently outperforms all baselines, achieving state-of-the-art accuracy across all QA benchmarks and delivering substantial gains in multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in understanding. In contrast, GPT-4o remains below human expert performance in most dimensions. A representative case study demonstrates GPT-5s ability to integrate visual and textual cues into a coherent diagnostic reasoning chain, recommending appropriate high-stakes interventions. Our results show that, on these controlled multimodal reasoning benchmarks, GPT-5 moves from human-comparable to above human-expert performance. This improvement may substantially inform the design of future clinical decision-support systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08223v1" target="_blank">Photon Statistics for Fock and Coherent States Interfering in a Beamsplitter</a></h3>
                    <p><strong>Authors:</strong> Jhordan A. T. Santiago</p>
                    <p><strong>Published:</strong> 8/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We present a straightforward yet comprehensive theoretical study of different quantum states emerging from a bi-modal beamsplitter when various input states interfere. Specifically, we analyze the output states for different combinations of input fields, including Fock states $|n\rangle|m\rangle$, hybrid states $|n\rangle|\alpha\rangle$, and coherent states $|\alpha\rangle|\beta\rangle$. We derive explicit expressions for the output state vectors, calculate the mean photon number, photon number variance, Mandel Q parameter, and secondorder coherence function to characterize the statistical properties of the output fields. Our results are intended as a pedagogical resource, serving as an introductory reference for students and researchers aiming to understand basic photon statistics using beamsplitters.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

