
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-13<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 110
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

AI safety research is a critical area, focusing on ensuring that AI systems operate reliably and ethically, especially as they become increasingly integrated into everyday life. Several papers from the provided list contribute to this domain by addressing various challenges and proposing innovative solutions.

One significant trend is the focus on reinforcing the safety and reliability of AI systems through improved methodologies. A notable example is the paper A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions, which explores methods to ensure system stability and constraint satisfaction in reinforcement learning, crucial for maintaining control in dynamic environments. Similarly, Deep Neural Network Calibration by Reducing Classifier Shift with Stochastic Masking aims to improve the reliability of AI predictions by enhancing the calibration of neural networks, especially important in safety-critical areas like healthcare and autonomous driving.

Another important aspect of AI safety is bias mitigation, as highlighted in Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs. This work introduces a method to identify and mitigate biases directly within a models internal processes, thus reducing harmful outcomes in AI-generated content. Additionally, the survey A Survey on Training-free Alignment of Large Language Models discusses alignment techniques that ensure AI models adhere to human values and ethical standards without extensive retraining, offering practical alternatives for deploying safer AI systems.

These efforts are complemented by research on the robustness and ethical challenges of AI systems. Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams evaluates AI systems capabilities in regulatory compliance and governance, a step towards ensuring AIs role in high-stakes environments. Meanwhile, Beyond Predictions: A Study of AI Strength and Weakness Transparency Communication on Human-AI Collaboration underscores the importance of transparent AI communication, enhancing user trust and collaboration.

Overall, these papers collectively represent a robust effort towards making AI systems safer and more reliable, emphasizing stability, bias mitigation, alignment with human values, and transparent communication. These advancements are crucial as AI continues to influence various sectors, requiring rigorous standards to safeguard against potential risks.

*Based on 50 research papers*

---

## ai alignment research

AI alignment research focuses on ensuring that AI systems behave in ways that are consistent with human values and ethical standards. Among the papers you listed, several touch on themes relevant to this domain, particularly around safety, robustness, and the practical deployment of AI models.

One notable trend is the exploration of methods to enhance the safety and reliability of AI systems. For instance, the review on safe reinforcement learning highlights the use of Lyapunov and barrier functions to ensure system stability and constraint satisfaction, echoing a broader movement towards integrating classical control theory with modern AI techniques to improve safety. Similarly, the paper on deep neural network calibration (MaC-Cal) addresses the critical challenge of confidence estimation in AI, which is essential for the deployment of AI systems in high-stakes environments like autonomous vehicles and healthcare. This aligns with the overall goal of AI alignment by focusing on improving the trustworthiness and reliability of AI outputs.

Another significant contribution to AI alignment comes from the investigation of training-free alignment techniques for large language models. This approach offers a promising path to align AI outputs with human values without the computational overhead of retraining, making AI systems more adaptable and potentially safer in diverse environments. The survey on training-free alignment methods emphasizes the use of in-context learning and post-generation corrections to achieve alignment, which could democratize access to AI systems by reducing the resources needed for alignment processes.

Overall, these papers reflect critical advancements in the AI alignment field, emphasizing safety, reliability, and efficient adaptation of AI systems to align with human expectations and ethical standards. These efforts are crucial for the responsible integration of AI into society, particularly as AI systems become more autonomous and influential in decision-making processes.

*Based on 50 research papers*

---

## quantum computing

The research paper Quantum Sensing Radiative Decays of Neutrinos and Dark Matter Particles introduces an innovative approach to utilizing quantum computing technologies, such as superconducting transmon qubits and trapped ion systems, for detecting faint electromagnetic signals from weakly interacting particles. This study highlights the potential of quantum sensors to probe the radiative decays of dark matter candidates with existing technology, marking a significant advancement in the field of quantum sensing and its application in particle physics. While current quantum architectures can already explore dark matter scenarios, further advancements in scalability and coherence are needed to investigate neutrino properties beyond current limits. This underscores an emerging trend where quantum computing and sensing are increasingly intersecting with fundamental physics to explore phenomena that are otherwise challenging to detect with classical methods.

In Instrument-based quantum resources: quantification, hierarchies and towards constructing resource theories, the authors delve into the relatively unexplored domain of instrument-based quantum resource theories. They propose frameworks to study various resources such as information preservability and entanglement preservability, which are critical for multi-party quantum operations. This research highlights an important trend in quantum computing: the development of sophisticated resource theories that extend beyond state-based and measurement-based approaches. By providing measures to quantify these resources, the study lays the groundwork for understanding and optimizing the use of quantum instruments, which are essential for advancing quantum information processing and communication. This represents a crucial step towards harnessing quantum resources more effectively, thereby broadening the scope and impact of quantum computing in diverse operational tasks.

*Based on 10 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.09137v1" target="_blank">HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis</a></h3>
                    <p><strong>Authors:</strong> Timo Teufel, Pulkit Gera, Xilong Zhou, Umar Iqbal, Pramod Rao, Jan Kautz, Vladislav Golyanik, Christian Theobalt</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Simultaneous relighting and novel-view rendering of digital human representations is an important yet challenging task with numerous applications. Progress in this area has been significantly limited due to the lack of publicly available, high-quality datasets, especially for full-body human captures. To address this critical gap, we introduce the HumanOLAT dataset, the first publicly accessible large-scale dataset of multi-view One-Light-at-a-Time (OLAT) captures of full-body humans. The dataset includes HDR RGB frames under various illuminations, such as white light, environment maps, color gradients and fine-grained OLAT illuminations. Our evaluations of state-of-the-art relighting and novel-view synthesis methods underscore both the datasets value and the significant challenges still present in modeling complex human-centric appearance and lighting interactions. We believe HumanOLAT will significantly facilitate future research, enabling rigorous benchmarking and advancements in both general and human-specific relighting and rendering techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09136v1" target="_blank">Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices</a></h3>
                    <p><strong>Authors:</strong> Ya Zou, Jingfeng Yao, Siyuan Yu, Shuai Zhang, Wenyu Liu, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> There is a growing demand for deploying large generative AI models on mobile devices. For recent popular video generative models, however, the Variational AutoEncoder (VAE) represents one of the major computational bottlenecks. Both large parameter sizes and mismatched kernels cause out-of-memory errors or extremely slow inference on mobile devices. To address this, we propose a low-cost solution that efficiently transfers widely used video VAEs to mobile devices. (1) We analyze redundancy in existing VAE architectures and get empirical design insights. By integrating 3D depthwise separable convolutions into our model, we significantly reduce the number of parameters. (2) We observe that the upsampling techniques in mainstream video VAEs are poorly suited to mobile hardware and form the main bottleneck. In response, we propose a decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building upon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3) We propose an efficient VAE decoder training method. Since only the decoder is used during deployment, we distill it to Turbo-VAED instead of retraining the full VAE, enabling fast mobile adaptation with minimal performance loss. To our knowledge, our method enables real-time 720p video VAE decoding on mobile devices for the first time. This approach is widely applicable to most video VAEs. When integrated into four representative models, with training cost as low as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on GPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of the original reconstruction quality. Compared to mobile-optimized VAEs, Turbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on the iPhone 16 Pro. The code and models will soon be available at https://github.com/hustvl/Turbo-VAED.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09130v1" target="_blank">An Open-Source Simulation and Data Management Tool for EnergyPlus Building Models</a></h3>
                    <p><strong>Authors:</strong> Ninad Gaikwad, Kasey Dettlaff, Athul Jose P, Anamika Dubey</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> We present a new open-source, GUI-based application created using Plotly-Dash, along with an integrated PostgreSQL-based relational database, developed to streamline EnergyPlus building model simulation workflows. The application facilitates data generation, aggregation (across thermal zones), and visualization based on customizable user preferences, while the database efficiently stores and retrieves complex simulation data generated by EnergyPlus. We demonstrate the need for this application and database, emphasizing how existing approaches for generating, managing, and analyzing EnergyPlus simulation data can be cumbersome, particularly when handling a large number of building models with varying simulation setups. This integrated framework enables building energy engineers and researchers to simplify their EnergyPlus simulations, manage generated simulation data, perform data analyses, and support data-driven modeling tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09128v1" target="_blank">A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions</a></h3>
                    <p><strong>Authors:</strong> Dhruv S. Kushwaha, Zoleikha A. Biron</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, 93E99, A.1; I.2</p>
                    <p><strong>Summary:</strong> Reinforcement learning (RL) has proven to be particularly effective in solving complex decision-making problems for a wide range of applications. From a control theory perspective, RL can be considered as an adaptive optimal control scheme. Lyapunov and barrier functions are the most commonly used certificates to guarantee system stability for a proposed/derived controller and constraint satisfaction guarantees, respectively, in control theoretic approaches. However, compared to theoretical guarantees available in control theoretic methods, RL lacks closed-loop stability of a computed policy and constraint satisfaction guarantees. Safe reinforcement learning refers to a class of constrained problems where the constraint violations lead to partial or complete system failure. The goal of this review is to provide an overview of safe RL techniques using Lyapunov and barrier functions to guarantee this notion of safety discussed (stability of the system in terms of a computed policy and constraint satisfaction during training and deployment). The different approaches employed are discussed in detail along with their shortcomings and benefits to provide critique and possible future research directions. Key motivation for this review is to discuss current theoretical approaches for safety and stability guarantees in RL similar to control theoretic approaches using Lyapunov and barrier functions. The review provides proven potential and promising scope of providing safety guarantees for complex dynamical systems with operational constraints using model-based and model-free RL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09126v1" target="_blank">Neutone SDK: An Open Source Framework for Neural Audio Processing</a></h3>
                    <p><strong>Authors:</strong> Christopher Mitcheltree, Bogdan Teleaga, Andrew Fyfe, Naotake Masuda, Matthias SchÃ¤fer, Alfie Bradic, Nao Tokui</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.SE, eess.AS</p>
                    <p><strong>Summary:</strong> Neural audio processing has unlocked novel methods of sound transformation and synthesis, yet integrating deep learning models into digital audio workstations (DAWs) remains challenging due to real-time / neural network inference constraints and the complexities of plugin development. In this paper, we introduce the Neutone SDK: an open source framework that streamlines the deployment of PyTorch-based neural audio models for both real-time and offline applications. By encapsulating common challenges such as variable buffer sizes, sample rate conversion, delay compensation, and control parameter handling within a unified, model-agnostic interface, our framework enables seamless interoperability between neural models and host plugins while allowing users to work entirely in Python. We provide a technical overview of the interfaces needed to accomplish this, as well as the corresponding SDK implementations. We also demonstrate the SDKs versatility across applications such as audio effect emulation, timbre transfer, and sample generation, as well as its adoption by researchers, educators, companies, and artists alike. The Neutone SDK is available at https://github.com/Neutone/neutone_sdk</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09124v1" target="_blank">OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows</a></h3>
                    <p><strong>Authors:</strong> Weixuan Wang, Dongge Han, Daniel Madrigal Diaz, Jin Xu, Victor RÃ¼hle, Saravan Rajmohan</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows. However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios. To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar. Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks. Each task requires agent to identify essential information from long-horizon interaction histories and perform multi-step reasoning across various applications. To enable scalable benchmark creation, we propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis. Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. We believe that OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios. In addition, we release OdysseyBench and HomerAgents to foster research along this line.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09123v1" target="_blank">OpenCUA: Open Foundations for Computer-Use Agents</a></h3>
                    <p><strong>Authors:</strong> Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo, Yiheng Xu, Chen Henry Wu, Zhennan Shen, Zhuokai Li, Ryan Li, Xiaochuan Li, Junda Chen, Boyuan Zheng, Peihang Li, Fangyu Lei, Ruisheng Cao, Yeqiao Fu, Dongchan Shin, Martin Shin, Jiarui Hu, Yuyan Wang, Jixuan Chen, Yuxiao Ye, Danyang Zhang, Dikang Du, Hao Hu, Huarong Chen, Zaida Zhou, Yipu Wang, Heng Wang, Diyi Yang, Victor Zhong, Flood Sung, Y. Charles, Zhilin Yang, Tao Yu</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09117v1" target="_blank">Spectral Efficiency Considerations for 6G</a></h3>
                    <p><strong>Authors:</strong> Joseph Boccuzzi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> As wireless connectivity continues to evolve towards 6G, there is an ever-increasing demand to not only deliver higher throughput, lower latency, and improved reliability, but also do so as efficiently as possible. To this point, the term efficiency has been quantified through applications to Spectral Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new system metric called Radio Resource Utilization Efficiency (RUE). This metric quantifies the efficiency of the available radio resources (Spectrum, Access Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We compare the system performance of Typical Cellular and Cell-Free Massive MIMO deployments as a vehicle to demonstrate the need for this new metric. We begin by providing a concise treatment of items impacting SE by introducing three categories: 5G Radio Resources, Practical Limitations (such as channel matrix rank deficiency) and Implementation Losses (SINR degradation). For the example Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47% (revealing significant room for improvement when defining 6G). Practical limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO) measurements conducted in a commercialized deployment. SE losses are characterized to offer guidance to advanced algorithms employing Machine Learning (ML) based techniques. We present the benefits of increasing the transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next Generation RAN architecture that can support 6G and AI-RAN.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09116v1" target="_blank">Deep Neural Network Calibration by Reducing Classifier Shift with Stochastic Masking</a></h3>
                    <p><strong>Authors:</strong> Jiani Ni, He Zhao, Yibo Yang, Dandan Guo</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In recent years, deep neural networks (DNNs) have shown competitive results in many fields. Despite this success, they often suffer from poor calibration, especially in safety-critical scenarios such as autonomous driving and healthcare, where unreliable confidence estimates can lead to serious consequences. Recent studies have focused on improving calibration by modifying the classifier, yet such efforts remain limited. Moreover, most existing approaches overlook calibration errors caused by underconfidence, which can be equally detrimental. To address these challenges, we propose MaC-Cal, a novel mask-based classifier calibration method that leverages stochastic sparsity to enhance the alignment between confidence and accuracy. MaC-Cal adopts a two-stage training scheme with adaptive sparsity, dynamically adjusting mask retention rates based on the deviation between confidence and accuracy. Extensive experiments show that MaC-Cal achieves superior calibration performance and robustness under data corruption, offering a practical and effective solution for reliable confidence estimation in DNNs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09115v1" target="_blank">SinLlama -- A Large Language Model for Sinhala</a></h3>
                    <p><strong>Authors:</strong> H. W. K. Aravinda, Rashad Sirajudeen, Samith Karunathilake, Nisansa de Silva, Surangika Ranathunga, Rishemjit Kaur</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Low-resource languages such as Sinhala are often overlooked by open-source Large Language Models (LLMs). In this research, we extend an existing multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM tokenizer with Sinhala specific vocabulary and perform continual pre-training on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This is the very first decoder-based open-source LLM with explicit Sinhala support. When SinLlama was instruction fine-tuned for three text classification tasks, it outperformed base and instruct variants of Llama-3-8B by a significant margin.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09099v1" target="_blank">Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving</a></h3>
                    <p><strong>Authors:</strong> Tianyun Yang, Yunwen Li, Ziniu Li, Zhihang Lin, Ruoyu Sun, Tian Ding</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Large vision language models exhibit notable limitations on Geometry Problem Solving (GPS) because of their unreliable diagram interpretation and pure natural-language reasoning. A recent line of work mitigates this by using symbolic solvers: the model directly generates a formal program that a geometry solver can execute. However, this direct program generation lacks intermediate reasoning, making the decision process opaque and prone to errors. In this work, we explore a new approach that integrates Chain-of-Thought (CoT) with formal language. The model interleaves natural language reasoning with incremental emission of solver-executable code, producing a hybrid reasoning trace in which critical derivations are expressed in formal language. To teach this behavior at scale, we combine (1) supervised fine-tuning on an 11K newly developed synthetic dataset with interleaved natural language reasoning and automatic formalization, and (2) solver-in-the-loop reinforcement learning that jointly optimizes both the CoT narrative and the resulting program through outcome-based rewards. Built on Qwen2.5-VL-7B, our new model, named GF-Reasoner, achieves up to 15% accuracy improvements on standard GPS benchmarks, surpassing both 7B-scale peers and the much larger model Qwen2.5-VL-72B. By exploiting high-order geometric knowledge and offloading symbolic computation to the solver, the generated reasoning traces are noticeably shorter and cleaner. Furthermore, we present a comprehensive analysis of method design choices (e.g., reasoning paradigms, data synthesis, training epochs, etc.), providing actionable insights for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09096v1" target="_blank">Link Prediction for Event Logs in the Process Industry</a></h3>
                    <p><strong>Authors:</strong> Anastasia Zhukova, Thomas Walton, Christian E. Matt, Bela Gipp</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> Knowledge management (KM) is vital in the process industry for optimizing operations, ensuring safety, and enabling continuous improvement through effective use of operational data and past insights. A key challenge in this domain is the fragmented nature of event logs in shift books, where related records, e.g., entries documenting issues related to equipment or processes and the corresponding solutions, may remain disconnected. This fragmentation hinders the recommendation of previous solutions to the users. To address this problem, we investigate record linking (RL) as link prediction, commonly studied in graph-based machine learning, by framing it as a cross-document coreference resolution (CDCR) task enhanced with natural language inference (NLI) and semantic text similarity (STS) by shifting it into the causal inference (CI). We adapt CDCR, traditionally applied in the news domain, into an RL model to operate at the passage level, similar to NLI and STS, while accommodating the process industrys specific text formats, which contain unstructured text and structured record attributes. Our RL model outperformed the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and 27% (11.21 points), respectively. Our work demonstrates how domain adaptation of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can be effectively tailored to the process industry, improving data quality and connectivity in shift logs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09094v1" target="_blank">Deep Learning Models for Robust Facial Liveness Detection</a></h3>
                    <p><strong>Authors:</strong> Oleksandr Kuznetsov, Emanuele Frontoni, Luca Romeo, Riccardo Rosati, Andrea Maranesi, Alessandro Muscatello</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In the rapidly evolving landscape of digital security, biometric authentication systems, particularly facial recognition, have emerged as integral components of various security protocols. However, the reliability of these systems is compromised by sophisticated spoofing attacks, where imposters gain unauthorized access by falsifying biometric traits. Current literature reveals a concerning gap: existing liveness detection methodologies - designed to counteract these breaches - fall short against advanced spoofing tactics employing deepfakes and other artificial intelligence-driven manipulations. This study introduces a robust solution through novel deep learning models addressing the deficiencies in contemporary anti-spoofing techniques. By innovatively integrating texture analysis and reflective properties associated with genuine human traits, our models distinguish authentic presence from replicas with remarkable precision. Extensive evaluations were conducted across five diverse datasets, encompassing a wide range of attack vectors and environmental conditions. Results demonstrate substantial advancement over existing systems, with our best model (AttackNet V2.2) achieving 99.9% average accuracy when trained on combined data. Moreover, our research unveils critical insights into the behavioral patterns of impostor attacks, contributing to a more nuanced understanding of their evolving nature. The implications are profound: our models do not merely fortify the authentication processes but also instill confidence in biometric systems across various sectors reliant on secure access.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09085v1" target="_blank">Dynamic Uncertainty-aware Multimodal Fusion for Outdoor Health Monitoring</a></h3>
                    <p><strong>Authors:</strong> Zihan Fang, Zheng Lin, Senkang Hu, Yihang Tao, Yiqin Deng, Xianhao Chen, Yuguang Fang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Outdoor health monitoring is essential to detect early abnormal health status for safeguarding human health and safety. Conventional outdoor monitoring relies on static multimodal deep learning frameworks, which requires extensive data training from scratch and fails to capture subtle health status changes. Multimodal large language models (MLLMs) emerge as a promising alternative, utilizing only small datasets to fine-tune pre-trained information-rich models for enabling powerful health status monitoring. Unfortunately, MLLM-based outdoor health monitoring also faces significant challenges: I) sensor data contains input noise stemming from sensor data acquisition and fluctuation noise caused by sudden changes in physiological signals due to dynamic outdoor environments, thus degrading the training performance; ii) current transformer based MLLMs struggle to achieve robust multimodal fusion, as they lack a design for fusing the noisy modality; iii) modalities with varying noise levels hinder accurate recovery of missing data from fluctuating distributions. To combat these challenges, we propose an uncertainty-aware multimodal fusion framework, named DUAL-Health, for outdoor health monitoring in dynamic and noisy environments. First, to assess the impact of noise, we accurately quantify modality uncertainty caused by input and fluctuation noise with current and temporal features. Second, to empower efficient muitimodal fusion with low-quality modalities,we customize the fusion weight for each modality based on quantified and calibrated uncertainty. Third, to enhance data recovery from fluctuating noisy modalities, we align modality distributions within a common semantic space. Extensive experiments demonstrate that our DUAL-Health outperforms state-of-the-art baselines in detection accuracy and robustness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09079v1" target="_blank">The shape of economics before and after the financial crisis</a></h3>
                    <p><strong>Authors:</strong> Alberto Baccini, Lucio Barabesi, Carlo Debernardi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> econ.GN, cs.DL, q-fin.EC, stat.OT</p>
                    <p><strong>Summary:</strong> This paper investigates the impact of the global financial crisis on the shape of economics as a discipline by analyzing EconLit-indexed journals from 2006 to 2020 using a multilayer network approach. We consider two types of social relationships among journals, based on shared editors (interlocking editorship) and shared authors (interlocking authorship), as well as two forms of intellectual proximity, derived from bibliographic coupling and textual similarity. These four dimensions are integrated using Similarity Network Fusion to produce a unified similarity network from which journal communities are identified. Comparing the field in 2006, 2012, and 2019 reveals a high degree of structural continuity. Our findings suggest that, despite changes in research topics after the crisis, fundamental social and intellectual relationships among journals have remained remarkably stable. Editorial networks, in particular, continue to shape hierarchies and legitimize knowledge production.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09078v1" target="_blank">Efficient motion-based metrics for video frame interpolation</a></h3>
                    <p><strong>Authors:</strong> Conall Daly, Darren Ramsook, Anil Kokaram</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Video frame interpolation (VFI) offers a way to generate intermediate frames between consecutive frames of a video sequence. Although the development of advanced frame interpolation algorithms has received increased attention in recent years, assessing the perceptual quality of interpolated content remains an ongoing area of research. In this paper, we investigate simple ways to process motion fields, with the purposes of using them as video quality metric for evaluating frame interpolation algorithms. We evaluate these quality metrics using the BVI-VFI dataset which contains perceptual scores measured for interpolated sequences. From our investigation we propose a motion metric based on measuring the divergence of motion fields. This metric correlates reasonably with these perceptual scores (PLCC=0.51) and is more computationally efficient (x2.7 speedup) compared to FloLPIPS (a well known motion-based metric). We then use our new proposed metrics to evaluate a range of state of the art frame interpolation metrics and find our metrics tend to favour more perceptual pleasing interpolated frames that may not score highly in terms of PSNR or SSIM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09061v1" target="_blank">VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception</a></h3>
                    <p><strong>Authors:</strong> Fuhao Chang, Shuxin Li, Yabei Li, Lei He</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Open-set perception in complex traffic environments poses a critical challenge for autonomous driving systems, particularly in identifying previously unseen object categories, which is vital for ensuring safety. Visual Language Models (VLMs), with their rich world knowledge and strong semantic reasoning capabilities, offer new possibilities for addressing this task. However, existing approaches typically leverage VLMs to extract visual features and couple them with traditional object detectors, resulting in multi-stage error propagation that hinders perception accuracy. To overcome this limitation, we propose VLM-3D, the first end-to-end framework that enables VLMs to perform 3D geometric perception in autonomous driving scenarios. VLM-3D incorporates Low-Rank Adaptation (LoRA) to efficiently adapt VLMs to driving tasks with minimal computational overhead, and introduces a joint semantic-geometric loss design: token-level semantic loss is applied during early training to ensure stable convergence, while 3D IoU loss is introduced in later stages to refine the accuracy of 3D bounding box predictions. Evaluations on the nuScenes dataset demonstrate that the proposed joint semantic-geometric loss in VLM-3D leads to a 12.8% improvement in perception accuracy, fully validating the effectiveness and advancement of our method.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09058v1" target="_blank">ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds</a></h3>
                    <p><strong>Authors:</strong> Shanle Yao, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video Anomaly Detection (VAD) can play a key role in spotting unusual activities in video footage. VAD is difficult to use in real-world settings due to the dynamic nature of human actions, environmental variations, and domain shifts. Traditional evaluation metrics often prove inadequate for such scenarios, as they rely on static assumptions and fall short of identifying a threshold that distinguishes normal from anomalous behavior in dynamic settings. To address this, we introduce an active learning framework tailored for VAD, designed for adapting to the ever-changing real-world conditions. Our approach leverages active learning to continuously select the most informative data points for labeling, thereby enhancing model adaptability. A critical innovation is the incorporation of a human-in-the-loop mechanism, which enables the identification of actual normal and anomalous instances from pseudo-labeling results generated by AI. This collected data allows the framework to define an adaptive threshold tailored to different environments, ensuring that the system remains effective as the definition of normal shifts across various settings. Implemented within a lab-based framework that simulates real-world conditions, our approach allows rigorous testing and refinement of VAD algorithms with a new metric. Experimental results show that our method achieves an EBI (Error Balance Index) of 68.91 for Q3 in real-world simulated scenarios, demonstrating its practical effectiveness and significantly enhancing the applicability of VAD in dynamic environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09054v1" target="_blank">CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks</a></h3>
                    <p><strong>Authors:</strong> Debdeep Mukherjee, Eduardo Di Santi, ClÃ©ment Lefebvre, Nenad Mijatovic, Victor Martin, Thierry Josse, Jonathan Brown, Kenza Saiah</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG, 68T07, 68T05, I.2.6; I.5.1; I.5.4</p>
                    <p><strong>Summary:</strong> Track circuits are critical for railway operations, acting as the main signalling sub-system to locate trains. Continuous Variable Current Modulation (CVCM) is one such technology. Like any field-deployed, safety-critical asset, it can fail, triggering cascading disruptions. Many failures originate as subtle anomalies that evolve over time, often not visually apparent in monitored signals. Conventional approaches, which rely on clear signal changes, struggle to detect them early. Early identification of failure types is essential to improve maintenance planning, minimising downtime and revenue loss. Leveraging deep neural networks, we propose a predictive maintenance framework that classifies anomalies well before they escalate into failures. Validated on 10 CVCM failure cases across different installations, the method is ISO-17359 compliant and outperforms conventional techniques, achieving 99.31% overall accuracy with detection within 1% of anomaly onset. Through conformal prediction, we provide uncertainty estimates, reaching 99% confidence with consistent coverage across classes. Given CVCMs global deployment, the approach is scalable and adaptable to other track circuits and railway systems, enhancing operational reliability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09043v1" target="_blank">Where are GIScience Faculty Hired from? Analyzing Faculty Mobility and Research Themes Through Hiring Networks</a></h3>
                    <p><strong>Authors:</strong> Yanbing Chen, Jonathan Nelson, Bing Zhou, Ryan Zhenqi Zhou, Shan Ye, Haokun Liu, Zhining Gu, Armita Kar, Hoeyun Kwon, Pengyu Chen, Maoran Sun, Yuhao Kang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY, cs.SI</p>
                    <p><strong>Summary:</strong> Academia is profoundly influenced by faculty hiring networks, which serve as critical conduits for knowledge dissemination and the formation of collaborative research initiatives. While extensive research in various disciplines has revealed the institutional hierarchies inherent in these networks, their impacts within GIScience remain underexplored. To fill this gap, this study analyzes the placement patterns of 946 GIScience faculty worldwide by mapping the connections between PhD-granting institutions and current faculty affiliations. Our dataset, which is compiled from volunteer-contributed information, is the most comprehensive collection available in this field. While there may be some limitations in its representativeness, its scope and depth provide a unique and valuable perspective on the global placement patterns of GIScience faculty. Our analysis reveals several influential programs in placing GIScience faculty, with hiring concentrated in the western countries. We examined the diversity index to assess the representation of regions and institutions within the global GIScience faculty network. We observe significant internal retention at both the continental and country levels, and a high level of non-self-hired ratio at the institutional level. Over time, research themes have also evolved, with growing research clusters emphasis on spatial data analytics, cartography and geovisualization, geocomputation, and environmental sciences, etc. These results illuminate the influence of hiring practices on global knowledge dissemination and contribute to promoting academic equity within GIScience and Geography.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09042v1" target="_blank">LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback</a></h3>
                    <p><strong>Authors:</strong> Chen Xu, Zhenyu Lv, Tian Lan, Xianyang Wang, Luyao Ji, Leyang Cui, Minqiang Yang, Jian Shen, Qunxi Dong, Xiuling Liu, Juan Wang, Bin Hu</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Although large language models (LLMs) hold significant promise in psychotherapy, their direct application in patient-facing scenarios raises ethical and safety concerns. Therefore, this work shifts towards developing an LLM as a supervisor to train real therapists. In addition to the privacy of clinical therapist training data, a fundamental contradiction complicates the training of therapeutic behaviors: clear feedback standards are necessary to ensure a controlled training system, yet there is no absolute gold standard for appropriate therapeutic behaviors in practice. In contrast, many common therapeutic mistakes are universal and identifiable, making them effective triggers for targeted feedback that can serve as clearer evidence. Motivated by this, we create a novel therapist-training paradigm: (1) guidelines for mistaken behaviors and targeted correction strategies are first established as standards; (2) a human-in-the-loop dialogue-feedback dataset is then constructed, where a mistake-prone agent intentionally makes standard mistakes during interviews naturally, and a supervisor agent locates and identifies mistakes and provides targeted feedback; (3) after fine-tuning on this dataset, the final supervisor model is provided for real therapist training. The detailed experimental results of automated, human and downstream assessments demonstrate that models fine-tuned on our dataset MATE, can provide high-quality feedback according to the clinical guideline, showing significant potential for the therapist training scenario.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09039v1" target="_blank">Polar Express: Rapid Functionalization of Single-Walled Carbon Nanotubes in High Dipole Moment Media</a></h3>
                    <p><strong>Authors:</strong> Dominik Just, Ryszard Siedlecki, Maciej Krzywiecki, Oussama Er-Riyahi, Yann Pouillon, Javier Junquera, Karolina Z. Milowska, Dawid Janas</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Fluorescent semiconducting single-walled carbon nanotubes (SWCNTs) hold considerable promise for photonics. Furthermore, the optical characteristics of the material can be significantly improved by covalent modification, which generates new spectral features in the near-infrared region and enhances its photoluminescence quantum yield. However, despite the dynamic development of this research domain, the importance of the solvent environment in which the SWCNT functionalization is conducted remains relatively unexplored. In this work, the complex relationships between solvent, dispersant, and SWCNTs were untangled to unravel the underlying phenomena. Through a systematic investigation of SWCNT reactivity in a broad spectrum of solvents, supported by multi-scale modeling enabled by our new implementation of a hybrid functional within SIESTA, we discovered that both the solvent medium and the dispersant enabling SWCNT solubilization affect not only the kinetics but also the course of the covalent modification of SWCNTs. Polar solvents proved to induce significant structural reorganization of polymer molecules on the SWCNT surface and enhance charge redistribution at the polymer-SWCNT interface. Consequently, we achieved a high degree of control over the optical properties of SWCNTs, and the tailored SWCNTs enabled facile optical detection of cholesterol, a significant risk factor for cardiovascular diseases.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09036v1" target="_blank">Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams</a></h3>
                    <p><strong>Authors:</strong> Zane Witherspoon, Thet Mon Aye, YingYing Hao</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technologys strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPPs passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAIs GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09033v1" target="_blank">Beyond Predictions: A Study of AI Strength and Weakness Transparency Communication on Human-AI Collaboration</a></h3>
                    <p><strong>Authors:</strong> Tina Behzad, Nikolos Gurney, Ning Wang, David V. Pynadath</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> The promise of human-AI teaming lies in humans and AI working together to achieve performance levels neither could accomplish alone. Effective communication between AI and humans is crucial for teamwork, enabling users to efficiently benefit from AI assistance. This paper investigates how AI communication impacts human-AI team performance. We examine AI explanations that convey an awareness of its strengths and limitations. To achieve this, we train a decision tree on the models mistakes, allowing it to recognize and explain where and why it might err. Through a user study on an income prediction task, we assess the impact of varying levels of information and explanations about AI predictions. Our results show that AI performance insights enhance task performance, and conveying AI awareness of its strengths and weaknesses improves trust calibration. These findings highlight the importance of considering how information delivery influences user trust and reliance in AI-assisted decision-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09032v1" target="_blank">Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding</a></h3>
                    <p><strong>Authors:</strong> Maxim A. Patratskiy, Alexey K. Kovalev, Aleksandr I. Panov</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.RO</p>
                    <p><strong>Summary:</strong> Vision-Language-Action models have demonstrated remarkable capabilities in predicting agent movements within virtual environments and real-world scenarios based on visual observations and textual instructions. Although recent research has focused on enhancing spatial and temporal understanding independently, this paper presents a novel approach that integrates both aspects through visual prompting. We introduce a method that projects visual traces of key points from observations onto depth maps, enabling models to capture both spatial and temporal information simultaneously. The experiments in SimplerEnv show that the mean number of tasks successfully solved increased for 4% compared to SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this enhancement can be achieved with minimal training data, making it particularly valuable for real-world applications where data collection is challenging. The project page is available at https://ampiromax.github.io/ST-VLA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09028v1" target="_blank">Envisioning Generative Artificial Intelligence in Cartography and Mapmaking</a></h3>
                    <p><strong>Authors:</strong> Yuhao Kang, Chenglong Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Generative artificial intelligence (GenAI), including large language models, diffusion-based image generation models, and GenAI agents, has provided new opportunities for advancements in mapping and cartography. Due to their characteristics including world knowledge and generalizability, artistic style and creativity, and multimodal integration, we envision that GenAI may benefit a variety of cartographic design decisions, from mapmaking (e.g., conceptualization, data preparation, map design, and map evaluation) to map use (such as map reading, interpretation, and analysis). This paper discusses several important topics regarding why and how GenAI benefits cartography with case studies including symbolization, map evaluation, and map reading. Despite its unprecedented potential, we identify key scenarios where GenAI may not be suitable, such as tasks that require a deep understanding of cartographic knowledge or prioritize precision and reliability. We also emphasize the need to consider ethical and social implications, such as concerns related to hallucination, reproducibility, bias, copyright, and explainability. This work lays the foundation for further exploration and provides a roadmap for future research at the intersection of GenAI and cartography.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09027v1" target="_blank">A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems</a></h3>
                    <p><strong>Authors:</strong> Jie Wang, Guang Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Passenger waiting time prediction plays a critical role in enhancing both ridesharing user experience and platform efficiency. While most existing research focuses on post-request waiting time prediction with knowing the matched driver information, pre-request waiting time prediction (i.e., before submitting a ride request and without matching a driver) is also important, as it enables passengers to plan their trips more effectively and enhance the experience of both passengers and drivers. However, it has not been fully studied by existing works. In this paper, we take the first step toward understanding the predictability and explainability of pre-request passenger waiting time in ridesharing systems. Particularly, we conduct an in-depth data-driven study to investigate the impact of demandsupply dynamics on passenger waiting time. Based on this analysis and feature engineering, we propose FiXGBoost, a novel feature interaction-based XGBoost model designed to predict waiting time without knowing the assigned driver information. We further perform an importance analysis to quantify the contribution of each factor. Experiments on a large-scale real-world ridesharing dataset including over 30 million trip records show that our FiXGBoost can achieve a good performance for pre-request passenger waiting time prediction with high explainability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09022v1" target="_blank">When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges</a></h3>
                    <p><strong>Authors:</strong> Zhiqiang Yang, Renshuai Tao, Xiaolong Zheng, Guodong Yang, Chunjie Zhang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Existing deepfake detection methods heavily depend on labeled training data. However, as AI-generated content becomes increasingly realistic, even \textbf{human annotators struggle to distinguish} between deepfakes and authentic images. This makes the labeling process both time-consuming and less reliable. Specifically, there is a growing demand for approaches that can effectively utilize large-scale unlabeled data from online social networks. Unlike typical unsupervised learning tasks, where categories are distinct, AI-generated faces closely mimic real image distributions and share strong similarities, causing performance drop in conventional strategies. In this paper, we introduce the Dual-Path Guidance Network (DPGNet), to tackle two key challenges: (1) bridging the domain gap between faces from different generation models, and (2) utilizing unlabeled image samples. The method features two core modules: text-guided cross-domain alignment, which uses learnable prompts to unify visual and textual embeddings into a domain-invariant feature space, and curriculum-driven pseudo label generation, which dynamically exploit more informative unlabeled samples. To prevent catastrophic forgetting, we also facilitate bridging between domains via cross-domain knowledge distillation. Extensive experiments on \textbf{11 popular datasets}, show that DPGNet outperforms SoTA approaches by \textbf{6.3\%}, highlighting its effectiveness in leveraging unlabeled data to address the annotation challenges posed by the increasing realism of deepfakes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09019v1" target="_blank">Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs</a></h3>
                    <p><strong>Authors:</strong> Shivam Dubey</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) become more integrated into societal systems, the risk of them perpetuating and amplifying harmful biases becomes a critical safety concern. Traditional methods for mitigating bias often rely on data filtering or post-hoc output moderation, which treat the model as an opaque black box. In this work, we introduce a complete, end-to-end system that uses techniques from mechanistic interpretability to both identify and actively mitigate bias directly within a models internal workings. Our method involves two primary stages. First, we train linear probes on the internal activations of a model to detect the latent representations of various biases (e.g., gender, race, age). Our experiments on \texttt{gpt2-large} demonstrate that these probes can identify biased content with near-perfect accuracy, revealing that bias representations become most salient in the models later layers. Second, we leverage these findings to compute steering vectors by contrasting the models activation patterns for biased and neutral statements. By adding these vectors during inference, we can actively steer the models generative process away from producing harmful, stereotypical, or biased content in real-time. We demonstrate the efficacy of this activation steering technique, showing that it successfully alters biased completions toward more neutral alternatives. We present our work as a robust and reproducible system that offers a more direct and interpretable approach to building safer and more accountable LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09016v1" target="_blank">A Survey on Training-free Alignment of Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Birong Pan, Yongqi Li, Weiyu Zhang, Wenpeng Lu, Mayi Xu, Shen Zhou, Yuanyuan Zhu, Ming Zhong, Tieyun Qian</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> The alignment of large language models (LLMs) aims to ensure their outputs adhere to human values, ethical standards, and legal norms. Traditional alignment methods often rely on resource-intensive fine-tuning (FT), which may suffer from knowledge degradation and face challenges in scenarios where the model accessibility or computational resources are constrained. In contrast, training-free (TF) alignment techniques--leveraging in-context learning, decoding-time adjustments, and post-generation corrections--offer a promising alternative by enabling alignment without heavily retraining LLMs, making them adaptable to both open-source and closed-source environments. This paper presents the first systematic review of TF alignment methods, categorizing them by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we provide a detailed examination from the viewpoint of LLMs and multimodal LLMs (MLLMs), highlighting their mechanisms and limitations. Furthermore, we identify key challenges and future directions, paving the way for more inclusive and effective TF alignment techniques. By synthesizing and organizing the rapidly growing body of research, this survey offers a guidance for practitioners and advances the development of safer and more reliable LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09003v1" target="_blank">Large Scale Robotic Material Handling: Learning, Planning, and Control</a></h3>
                    <p><strong>Authors:</strong> Filippo A. Spinelli, Yifan Zhai, Fang Nan, Pascal Egli, Julian Nubert, Thilo Bleumer, Lukas Miller, Ferdinand Hofmann, Marco Hutter</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> Bulk material handling involves the efficient and precise moving of large quantities of materials, a core operation in many industries, including cargo ship unloading, waste sorting, construction, and demolition. These repetitive, labor-intensive, and safety-critical operations are typically performed using large hydraulic material handlers equipped with underactuated grippers. In this work, we present a comprehensive framework for the autonomous execution of large-scale material handling tasks. The system integrates specialized modules for environment perception, pile attack point selection, path planning, and motion control. The main contributions of this work are two reinforcement learning-based modules: an attack point planner that selects optimal grasping locations on the material pile to maximize removal efficiency and minimize the number of scoops, and a robust trajectory following controller that addresses the precision and safety challenges associated with underactuated grippers in movement, while utilizing their free-swinging nature to release material through dynamic throwing. We validate our framework through real-world experiments on a 40 t material handler in a representative worksite, focusing on two key tasks: high-throughput bulk pile management and high-precision truck loading. Comparative evaluations against human operators demonstrate the systems effectiveness in terms of precision, repeatability, and operational safety. To the best of our knowledge, this is the first complete automation of material handling tasks on a full scale.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09000v1" target="_blank">UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale</a></h3>
                    <p><strong>Authors:</strong> Yuhao Wang, Wei Xi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Convolutional neural networks (ConvNets) with large effective receptive field (ERF), still in their early stages, have demonstrated promising effectiveness while constrained by high parameters and FLOPs costs and disrupted asymptotically Gaussian distribution (AGD) of ERF. This paper proposes an alternative paradigm: rather than merely employing extremely large ERF, it is more effective and efficient to expand the ERF while maintaining AGD of ERF by proper combination of smaller kernels, such as $7\times{7}$, $9\times{9}$, $11\times{11}$. This paper introduces a Three-layer Receptive Field Aggregator and designs a Layer Operator as the fundamental operator from the perspective of receptive field. The ERF can be expanded to the level of existing large-kernel ConvNets through the stack of proposed modules while maintaining AGD of ERF. Using these designs, we propose a universal model for ConvNet of any scale, termed UniConvNet. Extensive experiments on ImageNet-1K, COCO2017, and ADE20K demonstrate that UniConvNet outperforms state-of-the-art CNNs and ViTs across various vision recognition tasks for both lightweight and large-scale models with comparable throughput. Surprisingly, UniConvNet-T achieves $84.2\%$ ImageNet top-1 accuracy with $30M$ parameters and $5.1G$ FLOPs. UniConvNet-XL also shows competitive scalability to big data and large models, acquiring $88.4\%$ top-1 accuracy on ImageNet. Code and models are publicly available at https://github.com/ai-paperwithcode/UniConvNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08992v1" target="_blank">Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty</a></h3>
                    <p><strong>Authors:</strong> Rui Wang, Qihan Lin, Jiayu Liu, Qing Zong, Tianshi Zheng, Weiqi Wang, Yangqiu Song</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Prospect Theory (PT) models human decision-making under uncertainty, while epistemic markers (e.g., maybe) serve to express uncertainty in language. However, it remains largely unexplored whether Prospect Theory applies to contemporary Large Language Models and whether epistemic markers, which express human uncertainty, affect their decision-making behaviour. To address these research gaps, we design a three-stage experiment based on economic questionnaires. We propose a more general and precise evaluation framework to model LLMs decision-making behaviour under PT, introducing uncertainty through the empirical probability values associated with commonly used epistemic markers in comparable contexts. We then incorporate epistemic markers into the evaluation framework based on their corresponding probability values to examine their influence on LLM decision-making behaviours. Our findings suggest that modelling LLMs decision-making with PT is not consistently reliable, particularly when uncertainty is expressed in diverse linguistic forms. Our code is released in https://github.com/HKUST-KnowComp/MarPT.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08976v1" target="_blank">Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change</a></h3>
                    <p><strong>Authors:</strong> Ziyi Guo, Yan Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> Natural disasters such as hurricanes and wildfires increasingly introduce unusual disturbance on economic activities, which are especially likely to reshape commercial land use pattern given their sensitive to customer visitation. However, current modeling approaches are limited in capturing such complex interplay between human activities and commercial land use change under and following disturbances. Such interactions have been more effectively captured in current resilient urban planning theories. This study designs and calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict both the yearly decline and expansion of commercial land use at census block level under cumulative impact of disasters on human activities over two years. Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal attention mechanisms with three theory-informed modules. Resilience theory guides a disaster-aware temporal attention module that captures visitation dynamics. Spatial economic theory informs a multi-relational spatial attention module for inter-block representation. Diffusion theory contributes a regularization term that constrains land use transitions. The model performs significantly better than non-theoretical baselines in predicting commercial land use change under the scenario of recurrent hurricanes, with around 19% improvement in F1 score (0.8763). The effectiveness of the theory-guided modules was further validated through ablation studies. The research demonstrates that embedding urban theory into commercial land use modeling models may substantially enhance the capacity to capture its gains and losses. These advances in commercial land use modeling contribute to land use research that accounts for cumulative impacts of recurrent disasters and shifts in economic activity patterns.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08974v1" target="_blank">Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering</a></h3>
                    <p><strong>Authors:</strong> Elman Ghazaei, Erchan Aptoula</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The Earths surface is constantly changing, and detecting these changes provides valuable insights that benefit various aspects of human society. While traditional change detection methods have been employed to detect changes from bi-temporal images, these approaches typically require expert knowledge for accurate interpretation. To enable broader and more flexible access to change information by non-expert users, the task of Change Detection Visual Question Answering (CDVQA) has been introduced. However, existing CDVQA methods have been developed under the assumption that training and testing datasets share similar distributions. This assumption does not hold in real-world applications, where domain shifts often occur. In this paper, the CDVQA task is revisited with a focus on addressing domain shift. To this end, a new multi-modal and multi-domain dataset, BrightVQA, is introduced to facilitate domain generalization research in CDVQA. Furthermore, a novel state space model, termed Text-Conditioned State Space Model (TCSSM), is proposed. The TCSSM framework is designed to leverage both bi-temporal imagery and geo-disaster-related textual information in an unified manner to extract domain-invariant features across domains. Input-dependent parameters existing in TCSSM are dynamically predicted by using both bi-temporal images and geo-disaster-related description, thereby facilitating the alignment between bi-temporal visual data and the associated textual descriptions. Extensive experiments are conducted to evaluate the proposed method against state-of-the-art models, and superior performance is consistently demonstrated. The code and dataset will be made publicly available upon acceptance at https://github.com/Elman295/TCSSM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08973v1" target="_blank">Millisecond-scale Volatile Memory in HZO Ferroelectric Capacitors for Bio-inspired Temporal Computing</a></h3>
                    <p><strong>Authors:</strong> Luca Fehlings, Thomas Mikolajick, Beatriz Noheda, Erika Covi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.ET, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> With the broad recent research on ferroelectric hafnium oxide for non-volatile memory technology, depolarization effects in HfO2-based ferroelectric devices gained a lot of interest. Understanding the physical mechanisms regulating the retention of these devices provides an excellent opportunity for device optimization both towards non-volatile memory applications and towards real-time signal processing applications in which controlled time constants are of paramount importance. Indeed, we argue that ferroelectric devices, particularly HfO2-based, are an elegant solution to realize possibly arbitrary time constants in a single scaled memory device, which paves the way for temporal and brain-inspired computing in hardware. Here we present a ferroelectric capacitor stack realizing volatile memory due to its unique interface configuration. We provide electrical characterization of the device to motivate its use for realizing time constants in hardware, followed by an investigation of the electronic mechanisms and their possible relation to the observed retention times to facilitate further modeling of the retention process in HfO2-based ferroelectric capacitors. In the presented device, internal electric fields stabilize one polarization of the ferroelectric film, opening the possibility for unipolar operation with millisecond retention for the unstable polarization state. We show a dependence of the retention on both the polarization as well as the electrical stimuli, allowing us to exploit a range of time scales in a single device. Further, the intentionally defective interface in the presented material stack allows an insight into the interplay between retention loss in HfO2-based ferroelectric devices and the internal bias field, which we relate to the interface composition and the role of oxygen vacancies as a possible source of the internal bias fields.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08966v1" target="_blank">Integrating attention into explanation frameworks for language and vision transformers</a></h3>
                    <p><strong>Authors:</strong> Marte Eggen, Jacob LysnÃ¦s-Larsen, Inga StrÃ¼mke</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG, stat.ML</p>
                    <p><strong>Summary:</strong> The attention mechanism lies at the core of the transformer architecture, providing an interpretable model-internal signal that has motivated a growing interest in attention-based model explanations. Although attention weights do not directly determine model outputs, they reflect patterns of token influence that can inform and complement established explainability techniques. This work studies the potential of utilising the information encoded in attention weights to provide meaningful model explanations by integrating them into explainable AI (XAI) frameworks that target fundamentally different aspects of model behaviour. To this end, we develop two novel explanation methods applicable to both natural language processing and computer vision tasks. The first integrates attention weights into the Shapley value decomposition by redefining the characteristic function in terms of pairwise token interactions via attention weights, thus adapting this widely used game-theoretic solution concept to provide attention-driven attributions for local explanations. The second incorporates attention weights into token-level directional derivatives defined through concept activation vectors to measure concept sensitivity for global explanations. Our empirical evaluations on standard benchmarks and in a comparison study with widely used explanation methods show that attention weights can be meaningfully incorporated into the studied XAI frameworks, highlighting their value in enriching transformer explainability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08959v1" target="_blank">A Framework for FAIR and CLEAR Ecological Data and Knowledge: Semantic Units for Synthesis and Causal Modelling</a></h3>
                    <p><strong>Authors:</strong> Lars Vogt, Birgitta KÃ¶nig-Ries, Tim Alamenciak, Joshua I. Brian, Carlos Alberto Arnillas, Lotte Korell, Robert FrÃ¼hstÃ¼ckl, Tina Heger</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.DB</p>
                    <p><strong>Summary:</strong> Ecological research increasingly relies on integrating heterogeneous datasets and knowledge to explain and predict complex phenomena. Yet, differences in data types, terminology, and documentation often hinder interoperability, reuse, and causal understanding. We present the Semantic Units Framework, a novel, domain-agnostic semantic modelling approach applied here to ecological data and knowledge in compliance with the FAIR (Findable, Accessible, Interoperable, Reusable) and CLEAR (Cognitively interoperable, semantically Linked, contextually Explorable, easily Accessible, human-Readable and -interpretable) Principles. The framework models data and knowledge as modular, logic-aware semantic units: single propositions (statement units) or coherent groups of propositions (compound units). Statement units can model measurements, observations, or universal relationships, including causal ones, and link to methods and evidence. Compound units group related statement units into reusable, semantically coherent knowledge objects. Implemented using RDF, OWL, and knowledge graphs, semantic units can be serialized as FAIR Digital Objects with persistent identifiers, provenance, and semantic interoperability. We show how universal statement units build ecological causal networks, which can be composed into causal maps and perspective-specific subnetworks. These support causal reasoning, confounder detection (back-door), effect identification with unobserved confounders (front-door), application of do-calculus, and alignment with Bayesian networks, structural equation models, and structural causal models. By linking fine-grained empirical data to high-level causal reasoning, the Semantic Units Framework provides a foundation for ecological knowledge synthesis, evidence annotation, cross-domain integration, reproducible workflows, and AI-ready ecological research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08958v1" target="_blank">Addressing the Heterogeneity of Visualization in an Introductory PhD Course in the Swedish Context</a></h3>
                    <p><strong>Authors:</strong> Kostiantyn Kucher, Niklas RÃ¶nnberg, Jonas LÃ¶wgren</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC, K.3.2; H.5; I.3</p>
                    <p><strong>Summary:</strong> Visualization is a heterogeneous field, and this aspect is often reflected by the organizational structures at higher education institutions that academic researchers in visualization and related fields including computer graphics, human-computer interaction, and media design are typically affiliated with. It may thus be a challenge for new PhD students to grasp the fragmented structure of their new workplace, form collegial relations across the institution, and to build a coherent picture of the discipline as a whole. We report an attempt to address this challenge, in the form of an introductory course on the subject of Visualization Technology and Methodology for PhD students at the Division for Media and Information Technology, Link\oping University, Sweden. We discuss the course design, including interactions with other doctoral education activities and field trips to multiple research groups and units within the division (ranging from scientific visualization and computer graphics to media design and visual communication). Lessons learned from the course preparation work as well as the first instance of the course offered during autumn term 2023 can be helpful to researchers and educators aiming to establish or improve similar doctoral courses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08955v1" target="_blank">Fre-CW: Targeted Attack on Time Series Forecasting using Frequency Domain Loss</a></h3>
                    <p><strong>Authors:</strong> Naifu Feng, Lixing Chen, Junhua Tang, Hua Ding, Jianhua Li, Yang Bai</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Transformer-based models have made significant progress in time series forecasting. However, a key limitation of deep learning models is their susceptibility to adversarial attacks, which has not been studied enough in the context of time series prediction. In contrast to areas such as computer vision, where adversarial robustness has been extensively studied, frequency domain features of time series data play an important role in the prediction task but have not been sufficiently explored in terms of adversarial attacks. This paper proposes a time series prediction attack algorithm based on frequency domain loss. Specifically, we adapt an attack method originally designed for classification tasks to the prediction field and optimize the adversarial samples using both time-domain and frequency-domain losses. To the best of our knowledge, there is no relevant research on using frequency information for time-series adversarial attacks. Our experimental results show that these current time series prediction models are vulnerable to adversarial attacks, and our approach achieves excellent performance on major time series forecasting datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08945v1" target="_blank">Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset</a></h3>
                    <p><strong>Authors:</strong> Syed Irtiza Maksud, Subhash Lakshminarayana</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> The growing digitalization and the rapid adoption of high-powered Internet-of-Things (IoT)-enabled devices (e.g., EV charging stations) have increased the vulnerability of power grids to cyber threats. In particular, the so-called Load Altering Attacks (LAAs) can trigger rapid frequency fluctuations and potentially destabilize the power grid. This paper aims to bridge the gap between academic research and practical application by using open-source datasets released by grid operators. It investigates various LAA scenarios on a real-world transmission network, namely the Great Britain (GB)-36 Zone model released by the UKs National Electricity System Operator (NESO). It evaluates the threshold of LAA severity that the grid can tolerate before triggering cascading effects. Additionally, it explores how Battery Energy Storage Systems (BESS) based fast frequency response services can mitigate or prevent such impacts. Simulations are conducted using DIgSILENT PowerFactory to ensure realistic system representation. The analysis provides several useful insights to grid operators on the LAA impact, such as the influence of the relative locations of BESS and LAA, as well as how delays in attack execution can influence the overall system response.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08930v1" target="_blank">How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation</a></h3>
                    <p><strong>Authors:</strong> Juyeong Hwang, Seong-Eun Hon, JaeYoung Seon, Hyeongyeop Kang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.GR</p>
                    <p><strong>Summary:</strong> Natural head rotation is critical for believable embodied virtual agents, yet this micro-level behavior remains largely underexplored. While head-rotation prediction algorithms could, in principle, reproduce this behavior, they typically focus on visually salient stimuli and overlook the cognitive motives that guide head rotation. This yields agents that look at conspicuous objects while overlooking obstacles or task-relevant cues, diminishing realism in a virtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning framework for Embodied Head Rotation, a data-agnostic framework that produces context-aware head movements without task-specific training or hand-tuned heuristics. A controlled VR study (N=20) identifies five motivational drivers of human head movements: Interest, Information Seeking, Safety, Social Schema, and Habit. SCORE encodes these drivers as symbolic predicates, perceives the scene with a Vision-Language Model (VLM), and plans head poses with a Large Language Model (LLM). The framework employs a hybrid workflow: the VLM-LLM reasoning is executed offline, after which a lightweight FastVLM performs online validation to suppress hallucinations while maintaining responsiveness to scene dynamics. The result is an agent that predicts not only where to look but also why, generalizing to unseen scenes and multi-agent crowds while retaining behavioral plausibility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08928v1" target="_blank">DASC: Depth-of-Field Aware Scene Complexity Metric for 3D Visualization on Light Field Display</a></h3>
                    <p><strong>Authors:</strong> Kamran Akbar, Robert Bregovic, Federica Battisti</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.MM, cs.GR</p>
                    <p><strong>Summary:</strong> Light field display is one of the technologies providing 3D immersive visualization. However, a light field display generates only a limited number of light rays which results in finite angular and spatial resolutions. Therefore, 3D content can be shown with high quality only within a narrow depth range notated as Depth of Field (DoF) around the display screen. Outside this range, due to the appearance of aliasing artifacts, the quality degrades proportionally to the distance from the screen. One solution to mitigate the artifacts is depth of field rendering which blurs the content in the distorted regions, but can result in the removal of scene details. This research focuses on proposing a DoF Aware Scene Complexity (DASC) metric that characterizes 3D content based on geometrical and positional factors considering the light field displays DoF. In this research, we also evaluate the observers preference across different level of blurriness caused by DoF rendering ranging from sharp, aliased scenes to overly smoothed alias-free scenes. We have conducted this study over multiple scenes that we created to account for different types of content. Based on the outcome of subjective studies, we propose a model that takes the value of DASC metric as input and predicts the preferred level of blurring for the given scene as output.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08926v1" target="_blank">Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models</a></h3>
                    <p><strong>Authors:</strong> Wei Cai, Jian Zhao, Yuchu Jiang, Tianle Zhang, Xuelong Li</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large Vision-Language Models face growing safety challenges with multimodal inputs. This paper introduces the concept of Implicit Reasoning Safety, a vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due to flawed or hidden reasoning. To showcase this, we developed Safe Semantics, Unsafe Interpretations, the first dataset for this critical issue. Our demonstrations show that even simple In-Context Learning with SSUI significantly mitigates these implicit multimodal threats, underscoring the urgent need to improve cross-modal implicit reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08917v1" target="_blank">A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition</a></h3>
                    <p><strong>Authors:</strong> Jintao Cheng, Jiehao Luo, Xieyuanli Chen, Jin Wu, Rui Fan, Xiaoyu Tang, Wei Zhang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> LiDAR-based Place Recognition (LPR) remains a critical task in Embodied Artificial Intelligence (AI) and Autonomous Driving, primarily addressing localization challenges in GPS-denied environments and supporting loop closure detection. Existing approaches reduce place recognition to a Euclidean distance-based metric learning task, neglecting the feature spaces intrinsic structures and intra-class variances. Such Euclidean-centric formulation inherently limits the models capacity to capture nonlinear data distributions, leading to suboptimal performance in complex environments and temporal-varying scenarios. To address these challenges, we propose a novel cross-view network based on an innovative fusion paradigm. Our framework introduces a pseudo-global information guidance mechanism that coordinates multi-modal branches to perform feature learning within a unified semantic space. Concurrently, we propose a Manifold Adaptation and Pairwise Variance-Locality Learning Metric that constructs a Symmetric Positive Definite (SPD) matrix to compute Mahalanobis distance, superseding traditional Euclidean distance metrics. This geometric formulation enables the model to accurately characterize intrinsic data distributions and capture complex inter-class dependencies within the feature space. Experimental results demonstrate that the proposed algorithm achieves competitive performance, particularly excelling in complex environmental conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08909v1" target="_blank">Compass-Thinker-7B Technical Report</a></h3>
                    <p><strong>Authors:</strong> Anxiang Zeng, Haibo Zhang, Kaixiang Mo, Long Zhang, Shuman Liu, Yanhui Huang, Yawen Liu, Yuepeng Sheng, Yuwei Huang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Recent R1-Zero-like research further demonstrates that reasoning extension has given large language models (LLMs) unprecedented reasoning capabilities, and Reinforcement Learning is the core technology to elicit its complex reasoning. However, conducting RL experiments directly on hyperscale models involves high computational costs and resource demands, posing significant risks. We propose the Compass-Thinker-7B model, which aims to explore the potential of Reinforcement Learning with less computational resources and costs, and provides insights for further research into RL recipes for larger models. Compass-Thinker-7B is trained from an open source model through a specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k verifiable mathematics problems for the Reinforcement Learning Pipeline. By configuring data and training settings with different difficulty distributions for different stages, the potential of the model is gradually released and the training efficiency is improved. Extensive evaluations show that Compass-Thinker-7B possesses exceptional reasoning potential, and achieves superior performance on mathematics compared to the same-sized RL model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B achieves 40% accuracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08906v1" target="_blank">Ultra Ethernets Design Principles and Architectural Innovations</a></h3>
                    <p><strong>Authors:</strong> Torsten Hoefler, Karen Schramm, Eric Spada, Keith Underwood, Cedell Alexander, Bob Alverson, Paul Bottorff, Adrian Caulfield, Mark Handley, Cathy Huang, Costin Raiciu, Abdul Kabbani, Eugene Opsasnick, Rong Pan, Adee Ran, Rip Sohan</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.AR, cs.DC, cs.OS, cs.PF</p>
                    <p><strong>Summary:</strong> The recently released Ultra Ethernet (UE) 1.0 specification defines a transformative High-Performance Ethernet standard for future Artificial Intelligence (AI) and High-Performance Computing (HPC) systems. This paper, written by the specifications authors, provides a high-level overview of UEs design, offering crucial motivations and scientific context to understand its innovations. While UE introduces advancements across the entire Ethernet stack, its standout contribution is the novel Ultra Ethernet Transport (UET), a potentially fully hardware-accelerated protocol engineered for reliable, fast, and efficient communication in extreme-scale systems. Unlike InfiniBand, the last major standardization effort in high-performance networking over two decades ago, UE leverages the expansive Ethernet ecosystem and the 1,000x gains in computational efficiency per moved bit to deliver a new era of high-performance networking.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08896v1" target="_blank">Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors</a></h3>
                    <p><strong>Authors:</strong> Haoyu Zhao, Linghao Zhuang, Xingyue Zhao, Cheng Zeng, Haoran Xu, Yuming Jiang, Jun Cen, Kexiang Wang, Jiayan Guo, Siteng Huang, Xin Li, Deli Zhao, Hua Zou</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> A dexterous hand capable of generalizable grasping objects is fundamental for the development of general-purpose embodied AI. However, previous methods focus narrowly on low-level grasp stability metrics, neglecting affordance-aware positioning and human-like poses which are crucial for downstream manipulation. To address these limitations, we propose AffordDex, a novel framework with two-stage training that learns a universal grasping policy with an inherent understanding of both motion priors and object affordances. In the first stage, a trajectory imitator is pre-trained on a large corpus of human hand motions to instill a strong prior for natural movement. In the second stage, a residual module is trained to adapt these general human-like motions to specific object instances. This refinement is critically guided by two components: our Negative Affordance-aware Segmentation (NAA) module, which identifies functionally inappropriate contact regions, and a privileged teacher-student distillation process that ensures the final vision-based policy is highly successful. Extensive experiments demonstrate that AffordDex not only achieves universal dexterous grasping but also remains remarkably human-like in posture and functionally appropriate in contact location. As a result, AffordDex significantly outperforms state-of-the-art baselines across seen objects, unseen instances, and even entirely novel categories.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08895v1" target="_blank">ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs</a></h3>
                    <p><strong>Authors:</strong> Keyu Chen, Zhifeng Shen, Daohai Yu, Haoqian Wu, Wei Wen, Jianfeng He, Ruizhi Qiao, Xing Sun</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The increasing scale and complexity of large language models (LLMs) pose significant inference latency challenges, primarily due to their autoregressive decoding paradigm characterized by the sequential nature of next-token prediction. By re-examining the outputs of autoregressive models, we observed that some segments exhibit parallelizable structures, which we term intrinsic parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel decoding) can significantly improve the overall inference speed of LLMs. In this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which addresses two core challenges: automated construction of parallelizable data and efficient parallel decoding mechanism. More specifically, we introduce a non-invasive pipeline that automatically extracts and validates parallelizable structures from the responses of autoregressive models. To empower efficient adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which enables seamless transitions between serial and parallel decoding modes while maintaining a reusable KV cache, maximizing computational efficiency. Extensive evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical Reasoning, demonstrate that ASPD achieves unprecedented performance in both effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up to 3.19x speedup (1.85x on average) while maintaining response quality within 1% difference compared to autoregressive models, realizing significant acceleration without compromising generation quality. Our framework sets a groundbreaking benchmark for efficient LLM parallel inference, paving the way for its deployment in latency-sensitive applications such as AI-powered customer service bots and answer retrieval engines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08892v1" target="_blank">Sound Signal Synthesis with Auxiliary Classifier GAN, COVID-19 cough as an example</a></h3>
                    <p><strong>Authors:</strong> Yahya Sherif Solayman Mohamed Saleh, Ahmed Mohammed Dabbous, Lama Alkhaled, Hum Yan Chai, Muhammad Ehsan Rana, Hamam Mokayed</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.LG</p>
                    <p><strong>Summary:</strong> One of the fastest-growing domains in AI is healthcare. Given its importance, it has been the interest of many researchers to deploy ML models into the ever-demanding healthcare domain to aid doctors and increase accessibility. Delivering reliable models, however, demands a sizable amount of data, and the recent COVID-19 pandemic served as a reminder of the rampant and scary nature of healthcare that makes training models difficult. To alleviate such scarcity, many published works attempted to synthesize radiological cough data to train better COVID-19 detection models on the respective radiological data. To accommodate the time sensitivity expected during a pandemic, this work focuses on detecting COVID-19 through coughs using synthetic data to improve the accuracy of the classifier. The work begins by training a CNN on a balanced subset of the Coughvid dataset, establishing a baseline classification test accuracy of 72%. The paper demonstrates how an Auxiliary Classification GAN (ACGAN) may be trained to conditionally generate novel synthetic Mel Spectrograms of both healthy and COVID-19 coughs. These coughs are used to augment the training dataset of the CNN classifier, allowing it to reach a new test accuracy of 75%. The work highlights the expected messiness and inconsistency in training and offers insights into detecting and handling such shortcomings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09137v1" target="_blank">HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis</a></h3>
                    <p><strong>Authors:</strong> Timo Teufel, Pulkit Gera, Xilong Zhou, Umar Iqbal, Pramod Rao, Jan Kautz, Vladislav Golyanik, Christian Theobalt</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Simultaneous relighting and novel-view rendering of digital human representations is an important yet challenging task with numerous applications. Progress in this area has been significantly limited due to the lack of publicly available, high-quality datasets, especially for full-body human captures. To address this critical gap, we introduce the HumanOLAT dataset, the first publicly accessible large-scale dataset of multi-view One-Light-at-a-Time (OLAT) captures of full-body humans. The dataset includes HDR RGB frames under various illuminations, such as white light, environment maps, color gradients and fine-grained OLAT illuminations. Our evaluations of state-of-the-art relighting and novel-view synthesis methods underscore both the datasets value and the significant challenges still present in modeling complex human-centric appearance and lighting interactions. We believe HumanOLAT will significantly facilitate future research, enabling rigorous benchmarking and advancements in both general and human-specific relighting and rendering techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09136v1" target="_blank">Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices</a></h3>
                    <p><strong>Authors:</strong> Ya Zou, Jingfeng Yao, Siyuan Yu, Shuai Zhang, Wenyu Liu, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> There is a growing demand for deploying large generative AI models on mobile devices. For recent popular video generative models, however, the Variational AutoEncoder (VAE) represents one of the major computational bottlenecks. Both large parameter sizes and mismatched kernels cause out-of-memory errors or extremely slow inference on mobile devices. To address this, we propose a low-cost solution that efficiently transfers widely used video VAEs to mobile devices. (1) We analyze redundancy in existing VAE architectures and get empirical design insights. By integrating 3D depthwise separable convolutions into our model, we significantly reduce the number of parameters. (2) We observe that the upsampling techniques in mainstream video VAEs are poorly suited to mobile hardware and form the main bottleneck. In response, we propose a decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building upon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3) We propose an efficient VAE decoder training method. Since only the decoder is used during deployment, we distill it to Turbo-VAED instead of retraining the full VAE, enabling fast mobile adaptation with minimal performance loss. To our knowledge, our method enables real-time 720p video VAE decoding on mobile devices for the first time. This approach is widely applicable to most video VAEs. When integrated into four representative models, with training cost as low as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on GPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of the original reconstruction quality. Compared to mobile-optimized VAEs, Turbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on the iPhone 16 Pro. The code and models will soon be available at https://github.com/hustvl/Turbo-VAED.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09130v1" target="_blank">An Open-Source Simulation and Data Management Tool for EnergyPlus Building Models</a></h3>
                    <p><strong>Authors:</strong> Ninad Gaikwad, Kasey Dettlaff, Athul Jose P, Anamika Dubey</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> We present a new open-source, GUI-based application created using Plotly-Dash, along with an integrated PostgreSQL-based relational database, developed to streamline EnergyPlus building model simulation workflows. The application facilitates data generation, aggregation (across thermal zones), and visualization based on customizable user preferences, while the database efficiently stores and retrieves complex simulation data generated by EnergyPlus. We demonstrate the need for this application and database, emphasizing how existing approaches for generating, managing, and analyzing EnergyPlus simulation data can be cumbersome, particularly when handling a large number of building models with varying simulation setups. This integrated framework enables building energy engineers and researchers to simplify their EnergyPlus simulations, manage generated simulation data, perform data analyses, and support data-driven modeling tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09128v1" target="_blank">A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions</a></h3>
                    <p><strong>Authors:</strong> Dhruv S. Kushwaha, Zoleikha A. Biron</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, 93E99, A.1; I.2</p>
                    <p><strong>Summary:</strong> Reinforcement learning (RL) has proven to be particularly effective in solving complex decision-making problems for a wide range of applications. From a control theory perspective, RL can be considered as an adaptive optimal control scheme. Lyapunov and barrier functions are the most commonly used certificates to guarantee system stability for a proposed/derived controller and constraint satisfaction guarantees, respectively, in control theoretic approaches. However, compared to theoretical guarantees available in control theoretic methods, RL lacks closed-loop stability of a computed policy and constraint satisfaction guarantees. Safe reinforcement learning refers to a class of constrained problems where the constraint violations lead to partial or complete system failure. The goal of this review is to provide an overview of safe RL techniques using Lyapunov and barrier functions to guarantee this notion of safety discussed (stability of the system in terms of a computed policy and constraint satisfaction during training and deployment). The different approaches employed are discussed in detail along with their shortcomings and benefits to provide critique and possible future research directions. Key motivation for this review is to discuss current theoretical approaches for safety and stability guarantees in RL similar to control theoretic approaches using Lyapunov and barrier functions. The review provides proven potential and promising scope of providing safety guarantees for complex dynamical systems with operational constraints using model-based and model-free RL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09126v1" target="_blank">Neutone SDK: An Open Source Framework for Neural Audio Processing</a></h3>
                    <p><strong>Authors:</strong> Christopher Mitcheltree, Bogdan Teleaga, Andrew Fyfe, Naotake Masuda, Matthias SchÃ¤fer, Alfie Bradic, Nao Tokui</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.SE, eess.AS</p>
                    <p><strong>Summary:</strong> Neural audio processing has unlocked novel methods of sound transformation and synthesis, yet integrating deep learning models into digital audio workstations (DAWs) remains challenging due to real-time / neural network inference constraints and the complexities of plugin development. In this paper, we introduce the Neutone SDK: an open source framework that streamlines the deployment of PyTorch-based neural audio models for both real-time and offline applications. By encapsulating common challenges such as variable buffer sizes, sample rate conversion, delay compensation, and control parameter handling within a unified, model-agnostic interface, our framework enables seamless interoperability between neural models and host plugins while allowing users to work entirely in Python. We provide a technical overview of the interfaces needed to accomplish this, as well as the corresponding SDK implementations. We also demonstrate the SDKs versatility across applications such as audio effect emulation, timbre transfer, and sample generation, as well as its adoption by researchers, educators, companies, and artists alike. The Neutone SDK is available at https://github.com/Neutone/neutone_sdk</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09124v1" target="_blank">OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows</a></h3>
                    <p><strong>Authors:</strong> Weixuan Wang, Dongge Han, Daniel Madrigal Diaz, Jin Xu, Victor RÃ¼hle, Saravan Rajmohan</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows. However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios. To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar. Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks. Each task requires agent to identify essential information from long-horizon interaction histories and perform multi-step reasoning across various applications. To enable scalable benchmark creation, we propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis. Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. We believe that OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios. In addition, we release OdysseyBench and HomerAgents to foster research along this line.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09123v1" target="_blank">OpenCUA: Open Foundations for Computer-Use Agents</a></h3>
                    <p><strong>Authors:</strong> Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo, Yiheng Xu, Chen Henry Wu, Zhennan Shen, Zhuokai Li, Ryan Li, Xiaochuan Li, Junda Chen, Boyuan Zheng, Peihang Li, Fangyu Lei, Ruisheng Cao, Yeqiao Fu, Dongchan Shin, Martin Shin, Jiarui Hu, Yuyan Wang, Jixuan Chen, Yuxiao Ye, Danyang Zhang, Dikang Du, Hao Hu, Huarong Chen, Zaida Zhou, Yipu Wang, Heng Wang, Diyi Yang, Victor Zhong, Flood Sung, Y. Charles, Zhilin Yang, Tao Yu</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09117v1" target="_blank">Spectral Efficiency Considerations for 6G</a></h3>
                    <p><strong>Authors:</strong> Joseph Boccuzzi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> As wireless connectivity continues to evolve towards 6G, there is an ever-increasing demand to not only deliver higher throughput, lower latency, and improved reliability, but also do so as efficiently as possible. To this point, the term efficiency has been quantified through applications to Spectral Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new system metric called Radio Resource Utilization Efficiency (RUE). This metric quantifies the efficiency of the available radio resources (Spectrum, Access Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We compare the system performance of Typical Cellular and Cell-Free Massive MIMO deployments as a vehicle to demonstrate the need for this new metric. We begin by providing a concise treatment of items impacting SE by introducing three categories: 5G Radio Resources, Practical Limitations (such as channel matrix rank deficiency) and Implementation Losses (SINR degradation). For the example Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47% (revealing significant room for improvement when defining 6G). Practical limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO) measurements conducted in a commercialized deployment. SE losses are characterized to offer guidance to advanced algorithms employing Machine Learning (ML) based techniques. We present the benefits of increasing the transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next Generation RAN architecture that can support 6G and AI-RAN.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09116v1" target="_blank">Deep Neural Network Calibration by Reducing Classifier Shift with Stochastic Masking</a></h3>
                    <p><strong>Authors:</strong> Jiani Ni, He Zhao, Yibo Yang, Dandan Guo</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In recent years, deep neural networks (DNNs) have shown competitive results in many fields. Despite this success, they often suffer from poor calibration, especially in safety-critical scenarios such as autonomous driving and healthcare, where unreliable confidence estimates can lead to serious consequences. Recent studies have focused on improving calibration by modifying the classifier, yet such efforts remain limited. Moreover, most existing approaches overlook calibration errors caused by underconfidence, which can be equally detrimental. To address these challenges, we propose MaC-Cal, a novel mask-based classifier calibration method that leverages stochastic sparsity to enhance the alignment between confidence and accuracy. MaC-Cal adopts a two-stage training scheme with adaptive sparsity, dynamically adjusting mask retention rates based on the deviation between confidence and accuracy. Extensive experiments show that MaC-Cal achieves superior calibration performance and robustness under data corruption, offering a practical and effective solution for reliable confidence estimation in DNNs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09115v1" target="_blank">SinLlama -- A Large Language Model for Sinhala</a></h3>
                    <p><strong>Authors:</strong> H. W. K. Aravinda, Rashad Sirajudeen, Samith Karunathilake, Nisansa de Silva, Surangika Ranathunga, Rishemjit Kaur</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Low-resource languages such as Sinhala are often overlooked by open-source Large Language Models (LLMs). In this research, we extend an existing multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM tokenizer with Sinhala specific vocabulary and perform continual pre-training on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This is the very first decoder-based open-source LLM with explicit Sinhala support. When SinLlama was instruction fine-tuned for three text classification tasks, it outperformed base and instruct variants of Llama-3-8B by a significant margin.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09100v1" target="_blank">Towards Universal Neural Inference</a></h3>
                    <p><strong>Authors:</strong> Shreyas Bhat Brahmavar, Yang Li, Junier Oliva</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Real-world data often appears in diverse, disjoint forms -- with varying schemas, inconsistent semantics, and no fixed feature ordering -- making it challenging to build general-purpose models that can leverage information across datasets. We introduce ASPIRE, Arbitrary Set-based Permutation-Invariant Reasoning Engine, a Universal Neural Inference model for semantic reasoning and prediction over heterogeneous structured data. ASPIRE combines a permutation-invariant, set-based Transformer with a semantic grounding module that incorporates natural language descriptions, dataset metadata, and in-context examples to learn cross-dataset feature dependencies. This architecture allows ASPIRE to ingest arbitrary sets of feature--value pairs and support examples, align semantics across disjoint tables, and make predictions for any specified target. Once trained, ASPIRE generalizes to new inference tasks without additional tuning. In addition to delivering strong results across diverse benchmarks, ASPIRE naturally supports cost-aware active feature acquisition in an open-world setting, selecting informative features under test-time budget constraints for an arbitrary unseen dataset. These capabilities position ASPIRE as a step toward truly universal, semantics-aware inference over structured data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09099v1" target="_blank">Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving</a></h3>
                    <p><strong>Authors:</strong> Tianyun Yang, Yunwen Li, Ziniu Li, Zhihang Lin, Ruoyu Sun, Tian Ding</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Large vision language models exhibit notable limitations on Geometry Problem Solving (GPS) because of their unreliable diagram interpretation and pure natural-language reasoning. A recent line of work mitigates this by using symbolic solvers: the model directly generates a formal program that a geometry solver can execute. However, this direct program generation lacks intermediate reasoning, making the decision process opaque and prone to errors. In this work, we explore a new approach that integrates Chain-of-Thought (CoT) with formal language. The model interleaves natural language reasoning with incremental emission of solver-executable code, producing a hybrid reasoning trace in which critical derivations are expressed in formal language. To teach this behavior at scale, we combine (1) supervised fine-tuning on an 11K newly developed synthetic dataset with interleaved natural language reasoning and automatic formalization, and (2) solver-in-the-loop reinforcement learning that jointly optimizes both the CoT narrative and the resulting program through outcome-based rewards. Built on Qwen2.5-VL-7B, our new model, named GF-Reasoner, achieves up to 15% accuracy improvements on standard GPS benchmarks, surpassing both 7B-scale peers and the much larger model Qwen2.5-VL-72B. By exploiting high-order geometric knowledge and offloading symbolic computation to the solver, the generated reasoning traces are noticeably shorter and cleaner. Furthermore, we present a comprehensive analysis of method design choices (e.g., reasoning paradigms, data synthesis, training epochs, etc.), providing actionable insights for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09094v1" target="_blank">Deep Learning Models for Robust Facial Liveness Detection</a></h3>
                    <p><strong>Authors:</strong> Oleksandr Kuznetsov, Emanuele Frontoni, Luca Romeo, Riccardo Rosati, Andrea Maranesi, Alessandro Muscatello</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In the rapidly evolving landscape of digital security, biometric authentication systems, particularly facial recognition, have emerged as integral components of various security protocols. However, the reliability of these systems is compromised by sophisticated spoofing attacks, where imposters gain unauthorized access by falsifying biometric traits. Current literature reveals a concerning gap: existing liveness detection methodologies - designed to counteract these breaches - fall short against advanced spoofing tactics employing deepfakes and other artificial intelligence-driven manipulations. This study introduces a robust solution through novel deep learning models addressing the deficiencies in contemporary anti-spoofing techniques. By innovatively integrating texture analysis and reflective properties associated with genuine human traits, our models distinguish authentic presence from replicas with remarkable precision. Extensive evaluations were conducted across five diverse datasets, encompassing a wide range of attack vectors and environmental conditions. Results demonstrate substantial advancement over existing systems, with our best model (AttackNet V2.2) achieving 99.9% average accuracy when trained on combined data. Moreover, our research unveils critical insights into the behavioral patterns of impostor attacks, contributing to a more nuanced understanding of their evolving nature. The implications are profound: our models do not merely fortify the authentication processes but also instill confidence in biometric systems across various sectors reliant on secure access.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09091v1" target="_blank">Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages</a></h3>
                    <p><strong>Authors:</strong> Imalsha Puranegedara, Themira Chathumina, Nisal Ranathunga, Nisansa de Silva, Surangika Ranathunga, Mokanarangan Thayaparan</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) excel in English, but their performance degrades significantly on low-resource languages (LRLs) due to English-centric training. While methods like LangBridge align LLMs with multilingual encoders such as the Massively Multilingual Text-to-Text Transfer Transformer (mT5), they typically use only the final encoder layer. We propose a novel architecture that fuses all intermediate layers, enriching the linguistic information passed to the LLM. Our approach features two strategies: (1) a Global Softmax weighting for overall layer importance, and (2) a Transformer Softmax model that learns token-specific weights. The fused representations are mapped into the LLMs embedding space, enabling it to process multilingual inputs. The model is trained only on English data, without using any parallel or multilingual data. Evaluated on XNLI, IndicXNLI, Sinhala News Classification, and Amazon Reviews, our Transformer Softmax model significantly outperforms the LangBridge baseline. We observe strong performance gains in LRLs, improving Sinhala classification accuracy from 71.66% to 75.86% and achieving clear improvements across Indic languages such as Tamil, Bengali, and Malayalam. These specific gains contribute to an overall boost in average XNLI accuracy from 70.36% to 71.50%. This approach offers a scalable, data-efficient path toward more capable and equitable multilingual LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09085v1" target="_blank">Dynamic Uncertainty-aware Multimodal Fusion for Outdoor Health Monitoring</a></h3>
                    <p><strong>Authors:</strong> Zihan Fang, Zheng Lin, Senkang Hu, Yihang Tao, Yiqin Deng, Xianhao Chen, Yuguang Fang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Outdoor health monitoring is essential to detect early abnormal health status for safeguarding human health and safety. Conventional outdoor monitoring relies on static multimodal deep learning frameworks, which requires extensive data training from scratch and fails to capture subtle health status changes. Multimodal large language models (MLLMs) emerge as a promising alternative, utilizing only small datasets to fine-tune pre-trained information-rich models for enabling powerful health status monitoring. Unfortunately, MLLM-based outdoor health monitoring also faces significant challenges: I) sensor data contains input noise stemming from sensor data acquisition and fluctuation noise caused by sudden changes in physiological signals due to dynamic outdoor environments, thus degrading the training performance; ii) current transformer based MLLMs struggle to achieve robust multimodal fusion, as they lack a design for fusing the noisy modality; iii) modalities with varying noise levels hinder accurate recovery of missing data from fluctuating distributions. To combat these challenges, we propose an uncertainty-aware multimodal fusion framework, named DUAL-Health, for outdoor health monitoring in dynamic and noisy environments. First, to assess the impact of noise, we accurately quantify modality uncertainty caused by input and fluctuation noise with current and temporal features. Second, to empower efficient muitimodal fusion with low-quality modalities,we customize the fusion weight for each modality based on quantified and calibrated uncertainty. Third, to enhance data recovery from fluctuating noisy modalities, we align modality distributions within a common semantic space. Extensive experiments demonstrate that our DUAL-Health outperforms state-of-the-art baselines in detection accuracy and robustness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09079v1" target="_blank">The shape of economics before and after the financial crisis</a></h3>
                    <p><strong>Authors:</strong> Alberto Baccini, Lucio Barabesi, Carlo Debernardi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> econ.GN, cs.DL, q-fin.EC, stat.OT</p>
                    <p><strong>Summary:</strong> This paper investigates the impact of the global financial crisis on the shape of economics as a discipline by analyzing EconLit-indexed journals from 2006 to 2020 using a multilayer network approach. We consider two types of social relationships among journals, based on shared editors (interlocking editorship) and shared authors (interlocking authorship), as well as two forms of intellectual proximity, derived from bibliographic coupling and textual similarity. These four dimensions are integrated using Similarity Network Fusion to produce a unified similarity network from which journal communities are identified. Comparing the field in 2006, 2012, and 2019 reveals a high degree of structural continuity. Our findings suggest that, despite changes in research topics after the crisis, fundamental social and intellectual relationships among journals have remained remarkably stable. Editorial networks, in particular, continue to shape hierarchies and legitimize knowledge production.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09078v1" target="_blank">Efficient motion-based metrics for video frame interpolation</a></h3>
                    <p><strong>Authors:</strong> Conall Daly, Darren Ramsook, Anil Kokaram</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Video frame interpolation (VFI) offers a way to generate intermediate frames between consecutive frames of a video sequence. Although the development of advanced frame interpolation algorithms has received increased attention in recent years, assessing the perceptual quality of interpolated content remains an ongoing area of research. In this paper, we investigate simple ways to process motion fields, with the purposes of using them as video quality metric for evaluating frame interpolation algorithms. We evaluate these quality metrics using the BVI-VFI dataset which contains perceptual scores measured for interpolated sequences. From our investigation we propose a motion metric based on measuring the divergence of motion fields. This metric correlates reasonably with these perceptual scores (PLCC=0.51) and is more computationally efficient (x2.7 speedup) compared to FloLPIPS (a well known motion-based metric). We then use our new proposed metrics to evaluate a range of state of the art frame interpolation metrics and find our metrics tend to favour more perceptual pleasing interpolated frames that may not score highly in terms of PSNR or SSIM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09063v1" target="_blank">Enhanced superconductivity in ultrathin FeSe films on SrTiO3 via resonant anti-shielding: Superconductivity meets superfluidity</a></h3>
                    <p><strong>Authors:</strong> Krzysztof Kempa, Michael J. Naughton, Hanno H. Weitering</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> A vanishingly small dielectric function reflects a singular polarization response in a medium, leading to collective plasmonic or polaronic excitations that can enhance Cooper pairing in superconductors via a resonant anti-shielding (RAS) effect. Here, we show that RAS can explain the dramatic enhancement of superconductivity-relative to bulk FeSe, observed in single-unit-cell FeSe films on SrTiO$_3$ (STO) and related substrates. Moreover, we present evidence that RAS may play a central role in driving the Cooper pair condensate into a bipolaronic superfluid state. This interpretation aligns with a recent quantum Monte Carlo simulation by Zhang, et al. [Phys. Rev. X 13, 011010 (2023)], which indicated enhanced bipolaronic superconductivity in two-dimensional systems with moderately strong electron-phonon coupling. RAS may therefore represent a promising strategy for engineering high-T$_c$ superconducting heterostructures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09058v1" target="_blank">ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds</a></h3>
                    <p><strong>Authors:</strong> Shanle Yao, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video Anomaly Detection (VAD) can play a key role in spotting unusual activities in video footage. VAD is difficult to use in real-world settings due to the dynamic nature of human actions, environmental variations, and domain shifts. Traditional evaluation metrics often prove inadequate for such scenarios, as they rely on static assumptions and fall short of identifying a threshold that distinguishes normal from anomalous behavior in dynamic settings. To address this, we introduce an active learning framework tailored for VAD, designed for adapting to the ever-changing real-world conditions. Our approach leverages active learning to continuously select the most informative data points for labeling, thereby enhancing model adaptability. A critical innovation is the incorporation of a human-in-the-loop mechanism, which enables the identification of actual normal and anomalous instances from pseudo-labeling results generated by AI. This collected data allows the framework to define an adaptive threshold tailored to different environments, ensuring that the system remains effective as the definition of normal shifts across various settings. Implemented within a lab-based framework that simulates real-world conditions, our approach allows rigorous testing and refinement of VAD algorithms with a new metric. Experimental results show that our method achieves an EBI (Error Balance Index) of 68.91 for Q3 in real-world simulated scenarios, demonstrating its practical effectiveness and significantly enhancing the applicability of VAD in dynamic environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09043v1" target="_blank">Where are GIScience Faculty Hired from? Analyzing Faculty Mobility and Research Themes Through Hiring Networks</a></h3>
                    <p><strong>Authors:</strong> Yanbing Chen, Jonathan Nelson, Bing Zhou, Ryan Zhenqi Zhou, Shan Ye, Haokun Liu, Zhining Gu, Armita Kar, Hoeyun Kwon, Pengyu Chen, Maoran Sun, Yuhao Kang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY, cs.SI</p>
                    <p><strong>Summary:</strong> Academia is profoundly influenced by faculty hiring networks, which serve as critical conduits for knowledge dissemination and the formation of collaborative research initiatives. While extensive research in various disciplines has revealed the institutional hierarchies inherent in these networks, their impacts within GIScience remain underexplored. To fill this gap, this study analyzes the placement patterns of 946 GIScience faculty worldwide by mapping the connections between PhD-granting institutions and current faculty affiliations. Our dataset, which is compiled from volunteer-contributed information, is the most comprehensive collection available in this field. While there may be some limitations in its representativeness, its scope and depth provide a unique and valuable perspective on the global placement patterns of GIScience faculty. Our analysis reveals several influential programs in placing GIScience faculty, with hiring concentrated in the western countries. We examined the diversity index to assess the representation of regions and institutions within the global GIScience faculty network. We observe significant internal retention at both the continental and country levels, and a high level of non-self-hired ratio at the institutional level. Over time, research themes have also evolved, with growing research clusters emphasis on spatial data analytics, cartography and geovisualization, geocomputation, and environmental sciences, etc. These results illuminate the influence of hiring practices on global knowledge dissemination and contribute to promoting academic equity within GIScience and Geography.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09039v1" target="_blank">Polar Express: Rapid Functionalization of Single-Walled Carbon Nanotubes in High Dipole Moment Media</a></h3>
                    <p><strong>Authors:</strong> Dominik Just, Ryszard Siedlecki, Maciej Krzywiecki, Oussama Er-Riyahi, Yann Pouillon, Javier Junquera, Karolina Z. Milowska, Dawid Janas</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Fluorescent semiconducting single-walled carbon nanotubes (SWCNTs) hold considerable promise for photonics. Furthermore, the optical characteristics of the material can be significantly improved by covalent modification, which generates new spectral features in the near-infrared region and enhances its photoluminescence quantum yield. However, despite the dynamic development of this research domain, the importance of the solvent environment in which the SWCNT functionalization is conducted remains relatively unexplored. In this work, the complex relationships between solvent, dispersant, and SWCNTs were untangled to unravel the underlying phenomena. Through a systematic investigation of SWCNT reactivity in a broad spectrum of solvents, supported by multi-scale modeling enabled by our new implementation of a hybrid functional within SIESTA, we discovered that both the solvent medium and the dispersant enabling SWCNT solubilization affect not only the kinetics but also the course of the covalent modification of SWCNTs. Polar solvents proved to induce significant structural reorganization of polymer molecules on the SWCNT surface and enhance charge redistribution at the polymer-SWCNT interface. Consequently, we achieved a high degree of control over the optical properties of SWCNTs, and the tailored SWCNTs enabled facile optical detection of cholesterol, a significant risk factor for cardiovascular diseases.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09036v1" target="_blank">Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams</a></h3>
                    <p><strong>Authors:</strong> Zane Witherspoon, Thet Mon Aye, YingYing Hao</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technologys strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPPs passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAIs GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09033v1" target="_blank">Beyond Predictions: A Study of AI Strength and Weakness Transparency Communication on Human-AI Collaboration</a></h3>
                    <p><strong>Authors:</strong> Tina Behzad, Nikolos Gurney, Ning Wang, David V. Pynadath</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> The promise of human-AI teaming lies in humans and AI working together to achieve performance levels neither could accomplish alone. Effective communication between AI and humans is crucial for teamwork, enabling users to efficiently benefit from AI assistance. This paper investigates how AI communication impacts human-AI team performance. We examine AI explanations that convey an awareness of its strengths and limitations. To achieve this, we train a decision tree on the models mistakes, allowing it to recognize and explain where and why it might err. Through a user study on an income prediction task, we assess the impact of varying levels of information and explanations about AI predictions. Our results show that AI performance insights enhance task performance, and conveying AI awareness of its strengths and weaknesses improves trust calibration. These findings highlight the importance of considering how information delivery influences user trust and reliance in AI-assisted decision-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09032v1" target="_blank">Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding</a></h3>
                    <p><strong>Authors:</strong> Maxim A. Patratskiy, Alexey K. Kovalev, Aleksandr I. Panov</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.RO</p>
                    <p><strong>Summary:</strong> Vision-Language-Action models have demonstrated remarkable capabilities in predicting agent movements within virtual environments and real-world scenarios based on visual observations and textual instructions. Although recent research has focused on enhancing spatial and temporal understanding independently, this paper presents a novel approach that integrates both aspects through visual prompting. We introduce a method that projects visual traces of key points from observations onto depth maps, enabling models to capture both spatial and temporal information simultaneously. The experiments in SimplerEnv show that the mean number of tasks successfully solved increased for 4% compared to SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this enhancement can be achieved with minimal training data, making it particularly valuable for real-world applications where data collection is challenging. The project page is available at https://ampiromax.github.io/ST-VLA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09028v1" target="_blank">Envisioning Generative Artificial Intelligence in Cartography and Mapmaking</a></h3>
                    <p><strong>Authors:</strong> Yuhao Kang, Chenglong Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Generative artificial intelligence (GenAI), including large language models, diffusion-based image generation models, and GenAI agents, has provided new opportunities for advancements in mapping and cartography. Due to their characteristics including world knowledge and generalizability, artistic style and creativity, and multimodal integration, we envision that GenAI may benefit a variety of cartographic design decisions, from mapmaking (e.g., conceptualization, data preparation, map design, and map evaluation) to map use (such as map reading, interpretation, and analysis). This paper discusses several important topics regarding why and how GenAI benefits cartography with case studies including symbolization, map evaluation, and map reading. Despite its unprecedented potential, we identify key scenarios where GenAI may not be suitable, such as tasks that require a deep understanding of cartographic knowledge or prioritize precision and reliability. We also emphasize the need to consider ethical and social implications, such as concerns related to hallucination, reproducibility, bias, copyright, and explainability. This work lays the foundation for further exploration and provides a roadmap for future research at the intersection of GenAI and cartography.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09027v1" target="_blank">A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems</a></h3>
                    <p><strong>Authors:</strong> Jie Wang, Guang Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Passenger waiting time prediction plays a critical role in enhancing both ridesharing user experience and platform efficiency. While most existing research focuses on post-request waiting time prediction with knowing the matched driver information, pre-request waiting time prediction (i.e., before submitting a ride request and without matching a driver) is also important, as it enables passengers to plan their trips more effectively and enhance the experience of both passengers and drivers. However, it has not been fully studied by existing works. In this paper, we take the first step toward understanding the predictability and explainability of pre-request passenger waiting time in ridesharing systems. Particularly, we conduct an in-depth data-driven study to investigate the impact of demandsupply dynamics on passenger waiting time. Based on this analysis and feature engineering, we propose FiXGBoost, a novel feature interaction-based XGBoost model designed to predict waiting time without knowing the assigned driver information. We further perform an importance analysis to quantify the contribution of each factor. Experiments on a large-scale real-world ridesharing dataset including over 30 million trip records show that our FiXGBoost can achieve a good performance for pre-request passenger waiting time prediction with high explainability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09022v1" target="_blank">When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges</a></h3>
                    <p><strong>Authors:</strong> Zhiqiang Yang, Renshuai Tao, Xiaolong Zheng, Guodong Yang, Chunjie Zhang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Existing deepfake detection methods heavily depend on labeled training data. However, as AI-generated content becomes increasingly realistic, even \textbf{human annotators struggle to distinguish} between deepfakes and authentic images. This makes the labeling process both time-consuming and less reliable. Specifically, there is a growing demand for approaches that can effectively utilize large-scale unlabeled data from online social networks. Unlike typical unsupervised learning tasks, where categories are distinct, AI-generated faces closely mimic real image distributions and share strong similarities, causing performance drop in conventional strategies. In this paper, we introduce the Dual-Path Guidance Network (DPGNet), to tackle two key challenges: (1) bridging the domain gap between faces from different generation models, and (2) utilizing unlabeled image samples. The method features two core modules: text-guided cross-domain alignment, which uses learnable prompts to unify visual and textual embeddings into a domain-invariant feature space, and curriculum-driven pseudo label generation, which dynamically exploit more informative unlabeled samples. To prevent catastrophic forgetting, we also facilitate bridging between domains via cross-domain knowledge distillation. Extensive experiments on \textbf{11 popular datasets}, show that DPGNet outperforms SoTA approaches by \textbf{6.3\%}, highlighting its effectiveness in leveraging unlabeled data to address the annotation challenges posed by the increasing realism of deepfakes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09016v1" target="_blank">A Survey on Training-free Alignment of Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Birong Pan, Yongqi Li, Weiyu Zhang, Wenpeng Lu, Mayi Xu, Shen Zhou, Yuanyuan Zhu, Ming Zhong, Tieyun Qian</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> The alignment of large language models (LLMs) aims to ensure their outputs adhere to human values, ethical standards, and legal norms. Traditional alignment methods often rely on resource-intensive fine-tuning (FT), which may suffer from knowledge degradation and face challenges in scenarios where the model accessibility or computational resources are constrained. In contrast, training-free (TF) alignment techniques--leveraging in-context learning, decoding-time adjustments, and post-generation corrections--offer a promising alternative by enabling alignment without heavily retraining LLMs, making them adaptable to both open-source and closed-source environments. This paper presents the first systematic review of TF alignment methods, categorizing them by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we provide a detailed examination from the viewpoint of LLMs and multimodal LLMs (MLLMs), highlighting their mechanisms and limitations. Furthermore, we identify key challenges and future directions, paving the way for more inclusive and effective TF alignment techniques. By synthesizing and organizing the rapidly growing body of research, this survey offers a guidance for practitioners and advances the development of safer and more reliable LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09000v1" target="_blank">UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale</a></h3>
                    <p><strong>Authors:</strong> Yuhao Wang, Wei Xi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Convolutional neural networks (ConvNets) with large effective receptive field (ERF), still in their early stages, have demonstrated promising effectiveness while constrained by high parameters and FLOPs costs and disrupted asymptotically Gaussian distribution (AGD) of ERF. This paper proposes an alternative paradigm: rather than merely employing extremely large ERF, it is more effective and efficient to expand the ERF while maintaining AGD of ERF by proper combination of smaller kernels, such as $7\times{7}$, $9\times{9}$, $11\times{11}$. This paper introduces a Three-layer Receptive Field Aggregator and designs a Layer Operator as the fundamental operator from the perspective of receptive field. The ERF can be expanded to the level of existing large-kernel ConvNets through the stack of proposed modules while maintaining AGD of ERF. Using these designs, we propose a universal model for ConvNet of any scale, termed UniConvNet. Extensive experiments on ImageNet-1K, COCO2017, and ADE20K demonstrate that UniConvNet outperforms state-of-the-art CNNs and ViTs across various vision recognition tasks for both lightweight and large-scale models with comparable throughput. Surprisingly, UniConvNet-T achieves $84.2\%$ ImageNet top-1 accuracy with $30M$ parameters and $5.1G$ FLOPs. UniConvNet-XL also shows competitive scalability to big data and large models, acquiring $88.4\%$ top-1 accuracy on ImageNet. Code and models are publicly available at https://github.com/ai-paperwithcode/UniConvNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08997v1" target="_blank">Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory</a></h3>
                    <p><strong>Authors:</strong> Sizhe Yuen, Francisco Gomez Medina, Ting Su, Yali Du, Adam J. Sobey</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through structured agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory templates that preserve specialized perspectives while focusing on task-relevant information. We benchmark our approach on the PDDL dataset, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing an improvement of 38.6\% with the highest token efficiency. An additional evaluation is performed on a complex data pipeline design task, we demonstrate that our approach produces higher quality designs when comparing 5 metrics: scalability, reliability, usability, cost-effectiveness and documentation with additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through structured, intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08995v1" target="_blank">GRB minimum variability timescales with Fermi/GBM</a></h3>
                    <p><strong>Authors:</strong> R. Maccary, C. Guidorzi, A. E. Camisasca, M. Maistrello, S. Kobayashi, L. Amati, L. Bazzanini, M. Bulla, L. Ferro, F. Frontera, A. Tsvetkova</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE</p>
                    <p><strong>Summary:</strong> Context. Gamma-ray bursts (GRBs) have traditionally been classified by duration into long (LGRBs) and short (SGRBs), with the former believed to originate from massive star collapses and the latter from compact binary mergers. However, events such as the SGRB 200826A (coming from a collapsar) and the LGRBs 211211A and 230307A (associated with a merger) suggest that duration-based classification could be sometimes misleading. Recently, the minimum variability timescale (MVT) has emerged as a key metric for classifying GRBs. Aims. We calculate the MVT, defined as the full width at half maximum (FWHM) of the narrowest pulse in the light curve, using an independent dataset from Fermi/GBM and we compare our results with other MVT definitions. We update the MVT-T90 plane and analyse peculiar events like long-duration merger candidates 211211A, 230307A, and other short GRBs with extended emission (SEE-GRBs). We also examine extragalactic magnetar giant flares (MGFs) and explore possible new correlations with peak energy. Methods. We used the MEPSA algorithm to identify the shortest pulse in each GRB light curve and measure its FWHM. We calculated the MVT for around 3700 GRBs, 177 of which with spectroscopically known redshift. Results. SEE-GRBs and SGRBs share similar MVTs (from few tens to a few hundreds of ms), indicating a common progenitor, while extragalactic MGFs exhibit even shorter values (from few ms to few tens of ms). Our MVT estimation method consistently yields higher values than another existing technique, the latter aligning with the pulse rise time. For LGRBs, we confirmed the correlations of MVT with peak luminosity and Lorentz factor. Conclusions. We confirmed that, although MVT alone cannot determine the GRB progenitor, it is a valuable tool when combined with other indicators, helping to flag long-duration mergers and distinguish MGFs from typical SGRBs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08992v1" target="_blank">Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty</a></h3>
                    <p><strong>Authors:</strong> Rui Wang, Qihan Lin, Jiayu Liu, Qing Zong, Tianshi Zheng, Weiqi Wang, Yangqiu Song</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Prospect Theory (PT) models human decision-making under uncertainty, while epistemic markers (e.g., maybe) serve to express uncertainty in language. However, it remains largely unexplored whether Prospect Theory applies to contemporary Large Language Models and whether epistemic markers, which express human uncertainty, affect their decision-making behaviour. To address these research gaps, we design a three-stage experiment based on economic questionnaires. We propose a more general and precise evaluation framework to model LLMs decision-making behaviour under PT, introducing uncertainty through the empirical probability values associated with commonly used epistemic markers in comparable contexts. We then incorporate epistemic markers into the evaluation framework based on their corresponding probability values to examine their influence on LLM decision-making behaviours. Our findings suggest that modelling LLMs decision-making with PT is not consistently reliable, particularly when uncertainty is expressed in diverse linguistic forms. Our code is released in https://github.com/HKUST-KnowComp/MarPT.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08976v1" target="_blank">Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change</a></h3>
                    <p><strong>Authors:</strong> Ziyi Guo, Yan Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> Natural disasters such as hurricanes and wildfires increasingly introduce unusual disturbance on economic activities, which are especially likely to reshape commercial land use pattern given their sensitive to customer visitation. However, current modeling approaches are limited in capturing such complex interplay between human activities and commercial land use change under and following disturbances. Such interactions have been more effectively captured in current resilient urban planning theories. This study designs and calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict both the yearly decline and expansion of commercial land use at census block level under cumulative impact of disasters on human activities over two years. Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal attention mechanisms with three theory-informed modules. Resilience theory guides a disaster-aware temporal attention module that captures visitation dynamics. Spatial economic theory informs a multi-relational spatial attention module for inter-block representation. Diffusion theory contributes a regularization term that constrains land use transitions. The model performs significantly better than non-theoretical baselines in predicting commercial land use change under the scenario of recurrent hurricanes, with around 19% improvement in F1 score (0.8763). The effectiveness of the theory-guided modules was further validated through ablation studies. The research demonstrates that embedding urban theory into commercial land use modeling models may substantially enhance the capacity to capture its gains and losses. These advances in commercial land use modeling contribute to land use research that accounts for cumulative impacts of recurrent disasters and shifts in economic activity patterns.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08974v1" target="_blank">Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering</a></h3>
                    <p><strong>Authors:</strong> Elman Ghazaei, Erchan Aptoula</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The Earths surface is constantly changing, and detecting these changes provides valuable insights that benefit various aspects of human society. While traditional change detection methods have been employed to detect changes from bi-temporal images, these approaches typically require expert knowledge for accurate interpretation. To enable broader and more flexible access to change information by non-expert users, the task of Change Detection Visual Question Answering (CDVQA) has been introduced. However, existing CDVQA methods have been developed under the assumption that training and testing datasets share similar distributions. This assumption does not hold in real-world applications, where domain shifts often occur. In this paper, the CDVQA task is revisited with a focus on addressing domain shift. To this end, a new multi-modal and multi-domain dataset, BrightVQA, is introduced to facilitate domain generalization research in CDVQA. Furthermore, a novel state space model, termed Text-Conditioned State Space Model (TCSSM), is proposed. The TCSSM framework is designed to leverage both bi-temporal imagery and geo-disaster-related textual information in an unified manner to extract domain-invariant features across domains. Input-dependent parameters existing in TCSSM are dynamically predicted by using both bi-temporal images and geo-disaster-related description, thereby facilitating the alignment between bi-temporal visual data and the associated textual descriptions. Extensive experiments are conducted to evaluate the proposed method against state-of-the-art models, and superior performance is consistently demonstrated. The code and dataset will be made publicly available upon acceptance at https://github.com/Elman295/TCSSM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08973v1" target="_blank">Millisecond-scale Volatile Memory in HZO Ferroelectric Capacitors for Bio-inspired Temporal Computing</a></h3>
                    <p><strong>Authors:</strong> Luca Fehlings, Thomas Mikolajick, Beatriz Noheda, Erika Covi</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.ET, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> With the broad recent research on ferroelectric hafnium oxide for non-volatile memory technology, depolarization effects in HfO2-based ferroelectric devices gained a lot of interest. Understanding the physical mechanisms regulating the retention of these devices provides an excellent opportunity for device optimization both towards non-volatile memory applications and towards real-time signal processing applications in which controlled time constants are of paramount importance. Indeed, we argue that ferroelectric devices, particularly HfO2-based, are an elegant solution to realize possibly arbitrary time constants in a single scaled memory device, which paves the way for temporal and brain-inspired computing in hardware. Here we present a ferroelectric capacitor stack realizing volatile memory due to its unique interface configuration. We provide electrical characterization of the device to motivate its use for realizing time constants in hardware, followed by an investigation of the electronic mechanisms and their possible relation to the observed retention times to facilitate further modeling of the retention process in HfO2-based ferroelectric capacitors. In the presented device, internal electric fields stabilize one polarization of the ferroelectric film, opening the possibility for unipolar operation with millisecond retention for the unstable polarization state. We show a dependence of the retention on both the polarization as well as the electrical stimuli, allowing us to exploit a range of time scales in a single device. Further, the intentionally defective interface in the presented material stack allows an insight into the interplay between retention loss in HfO2-based ferroelectric devices and the internal bias field, which we relate to the interface composition and the role of oxygen vacancies as a possible source of the internal bias fields.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08967v1" target="_blank">Revealing the Role of Audio Channels in ASR Performance Degradation</a></h3>
                    <p><strong>Authors:</strong> Kuan-Tang Huang, Li-Wei Chen, Hung-Shin Lee, Berlin Chen, Hsin-Min Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Pre-trained automatic speech recognition (ASR) models have demonstrated strong performance on a variety of tasks. However, their performance can degrade substantially when the input audio comes from different recording channels. While previous studies have demonstrated this phenomenon, it is often attributed to the mismatch between training and testing corpora. This study argues that variations in speech characteristics caused by different recording channels can fundamentally harm ASR performance. To address this limitation, we propose a normalization technique designed to mitigate the impact of channel variation by aligning internal feature representations in the ASR model with those derived from a clean reference channel. This approach significantly improves ASR performance on previously unseen channels and languages, highlighting its ability to generalize across channel and language differences.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08966v1" target="_blank">Integrating attention into explanation frameworks for language and vision transformers</a></h3>
                    <p><strong>Authors:</strong> Marte Eggen, Jacob LysnÃ¦s-Larsen, Inga StrÃ¼mke</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG, stat.ML</p>
                    <p><strong>Summary:</strong> The attention mechanism lies at the core of the transformer architecture, providing an interpretable model-internal signal that has motivated a growing interest in attention-based model explanations. Although attention weights do not directly determine model outputs, they reflect patterns of token influence that can inform and complement established explainability techniques. This work studies the potential of utilising the information encoded in attention weights to provide meaningful model explanations by integrating them into explainable AI (XAI) frameworks that target fundamentally different aspects of model behaviour. To this end, we develop two novel explanation methods applicable to both natural language processing and computer vision tasks. The first integrates attention weights into the Shapley value decomposition by redefining the characteristic function in terms of pairwise token interactions via attention weights, thus adapting this widely used game-theoretic solution concept to provide attention-driven attributions for local explanations. The second incorporates attention weights into token-level directional derivatives defined through concept activation vectors to measure concept sensitivity for global explanations. Our empirical evaluations on standard benchmarks and in a comparison study with widely used explanation methods show that attention weights can be meaningfully incorporated into the studied XAI frameworks, highlighting their value in enriching transformer explainability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08961v1" target="_blank">DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Yuanyuan Wang, Dongchao Yang, Yiwen Shao, Hangting Chen, Jiankun Zhao, Zhiyong Wu, Helen Meng, Xixin Wu</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> Extending pre-trained Large Language Models (LLMs)s speech understanding or generation abilities by introducing various effective speech tokens has attracted great attention in the speech community. However, building a unified speech understanding and generation model still faces the following challenges: (1) Due to the huge modality gap between speech tokens and text tokens, extending text LLMs to unified speech LLMs relies on large-scale paired data for fine-tuning, and (2) Generation and understanding tasks prefer information at different levels, e.g., generation benefits from detailed acoustic features, while understanding favors high-level semantics. This divergence leads to difficult performance optimization in one unified model. To solve these challenges, in this paper, we present two key insights in speech tokenization and speech language modeling. Specifically, we first propose an Understanding-driven Speech Tokenizer (USTokenizer), which extracts high-level semantic information essential for accomplishing understanding tasks using text LLMs. In this way, USToken enjoys better modality commonality with text, which reduces the difficulty of modality alignment in adapting text LLMs to speech LLMs. Secondly, we present DualSpeechLM, a dual-token modeling framework that concurrently models USToken as input and acoustic token as output within a unified, end-to-end framework, seamlessly integrating speech understanding and generation capabilities. Furthermore, we propose a novel semantic supervision loss and a Chain-of-Condition (CoC) strategy to stabilize model training and enhance speech generation performance. Experimental results demonstrate that our proposed approach effectively fosters a complementary relationship between understanding and generation tasks, highlighting the promising strategy of mutually enhancing both tasks in one unified model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08959v1" target="_blank">A Framework for FAIR and CLEAR Ecological Data and Knowledge: Semantic Units for Synthesis and Causal Modelling</a></h3>
                    <p><strong>Authors:</strong> Lars Vogt, Birgitta KÃ¶nig-Ries, Tim Alamenciak, Joshua I. Brian, Carlos Alberto Arnillas, Lotte Korell, Robert FrÃ¼hstÃ¼ckl, Tina Heger</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.DB</p>
                    <p><strong>Summary:</strong> Ecological research increasingly relies on integrating heterogeneous datasets and knowledge to explain and predict complex phenomena. Yet, differences in data types, terminology, and documentation often hinder interoperability, reuse, and causal understanding. We present the Semantic Units Framework, a novel, domain-agnostic semantic modelling approach applied here to ecological data and knowledge in compliance with the FAIR (Findable, Accessible, Interoperable, Reusable) and CLEAR (Cognitively interoperable, semantically Linked, contextually Explorable, easily Accessible, human-Readable and -interpretable) Principles. The framework models data and knowledge as modular, logic-aware semantic units: single propositions (statement units) or coherent groups of propositions (compound units). Statement units can model measurements, observations, or universal relationships, including causal ones, and link to methods and evidence. Compound units group related statement units into reusable, semantically coherent knowledge objects. Implemented using RDF, OWL, and knowledge graphs, semantic units can be serialized as FAIR Digital Objects with persistent identifiers, provenance, and semantic interoperability. We show how universal statement units build ecological causal networks, which can be composed into causal maps and perspective-specific subnetworks. These support causal reasoning, confounder detection (back-door), effect identification with unobserved confounders (front-door), application of do-calculus, and alignment with Bayesian networks, structural equation models, and structural causal models. By linking fine-grained empirical data to high-level causal reasoning, the Semantic Units Framework provides a foundation for ecological knowledge synthesis, evidence annotation, cross-domain integration, reproducible workflows, and AI-ready ecological research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08958v1" target="_blank">Addressing the Heterogeneity of Visualization in an Introductory PhD Course in the Swedish Context</a></h3>
                    <p><strong>Authors:</strong> Kostiantyn Kucher, Niklas RÃ¶nnberg, Jonas LÃ¶wgren</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.HC, K.3.2; H.5; I.3</p>
                    <p><strong>Summary:</strong> Visualization is a heterogeneous field, and this aspect is often reflected by the organizational structures at higher education institutions that academic researchers in visualization and related fields including computer graphics, human-computer interaction, and media design are typically affiliated with. It may thus be a challenge for new PhD students to grasp the fragmented structure of their new workplace, form collegial relations across the institution, and to build a coherent picture of the discipline as a whole. We report an attempt to address this challenge, in the form of an introductory course on the subject of Visualization Technology and Methodology for PhD students at the Division for Media and Information Technology, Link\oping University, Sweden. We discuss the course design, including interactions with other doctoral education activities and field trips to multiple research groups and units within the division (ranging from scientific visualization and computer graphics to media design and visual communication). Lessons learned from the course preparation work as well as the first instance of the course offered during autumn term 2023 can be helpful to researchers and educators aiming to establish or improve similar doctoral courses.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08957v1" target="_blank">QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems</a></h3>
                    <p><strong>Authors:</strong> Chien-Chun Wang, Kuan-Tang Huang, Cheng-Yeh Yang, Hung-Shin Lee, Hsin-Min Wang, Berlin Chen</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Evaluating audio generation systems, including text-to-music (TTM), text-to-speech (TTS), and text-to-audio (TTA), remains challenging due to the subjective and multi-dimensional nature of human perception. Existing methods treat mean opinion score (MOS) prediction as a regression problem, but standard regression losses overlook the relativity of perceptual judgments. To address this limitation, we introduce QAMRO, a novel Quality-aware Adaptive Margin Ranking Optimization framework that seamlessly integrates regression objectives from different perspectives, aiming to highlight perceptual differences and prioritize accurate ratings. Our framework leverages pre-trained audio-text models such as CLAP and Audiobox-Aesthetics, and is trained exclusively on the official AudioMOS Challenge 2025 dataset. It demonstrates superior alignment with human evaluations across all dimensions, significantly outperforming robust baseline models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08955v1" target="_blank">Fre-CW: Targeted Attack on Time Series Forecasting using Frequency Domain Loss</a></h3>
                    <p><strong>Authors:</strong> Naifu Feng, Lixing Chen, Junhua Tang, Hua Ding, Jianhua Li, Yang Bai</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Transformer-based models have made significant progress in time series forecasting. However, a key limitation of deep learning models is their susceptibility to adversarial attacks, which has not been studied enough in the context of time series prediction. In contrast to areas such as computer vision, where adversarial robustness has been extensively studied, frequency domain features of time series data play an important role in the prediction task but have not been sufficiently explored in terms of adversarial attacks. This paper proposes a time series prediction attack algorithm based on frequency domain loss. Specifically, we adapt an attack method originally designed for classification tasks to the prediction field and optimize the adversarial samples using both time-domain and frequency-domain losses. To the best of our knowledge, there is no relevant research on using frequency information for time-series adversarial attacks. Our experimental results show that these current time series prediction models are vulnerable to adversarial attacks, and our approach achieves excellent performance on major time series forecasting datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08946v1" target="_blank">Mitigating Popularity Bias in Counterfactual Explanations using Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Arjan Hasami, Masoud Mansoury</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Counterfactual explanations (CFEs) offer a tangible and actionable way to explain recommendations by showing users a what-if scenario that demonstrates how small changes in their history would alter the systems output. However, existing CFE methods are susceptible to bias, generating explanations that might misalign with the users actual preferences. In this paper, we propose a pre-processing step that leverages large language models to filter out-of-character history items before generating an explanation. In experiments on two public datasets, we focus on popularity bias and apply our approach to ACCENT, a neural CFE framework. We find that it creates counterfactuals that are more closely aligned with each users popularity preferences than ACCENT alone.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08945v1" target="_blank">Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset</a></h3>
                    <p><strong>Authors:</strong> Syed Irtiza Maksud, Subhash Lakshminarayana</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> The growing digitalization and the rapid adoption of high-powered Internet-of-Things (IoT)-enabled devices (e.g., EV charging stations) have increased the vulnerability of power grids to cyber threats. In particular, the so-called Load Altering Attacks (LAAs) can trigger rapid frequency fluctuations and potentially destabilize the power grid. This paper aims to bridge the gap between academic research and practical application by using open-source datasets released by grid operators. It investigates various LAA scenarios on a real-world transmission network, namely the Great Britain (GB)-36 Zone model released by the UKs National Electricity System Operator (NESO). It evaluates the threshold of LAA severity that the grid can tolerate before triggering cascading effects. Additionally, it explores how Battery Energy Storage Systems (BESS) based fast frequency response services can mitigate or prevent such impacts. Simulations are conducted using DIgSILENT PowerFactory to ensure realistic system representation. The analysis provides several useful insights to grid operators on the LAA impact, such as the influence of the relative locations of BESS and LAA, as well as how delays in attack execution can influence the overall system response.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08942v1" target="_blank">Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens</a></h3>
                    <p><strong>Authors:</strong> Lucas Albarede, Jose Moreno, Lynda Tamine, Luce Lefeuvre</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> Despite their impressive performances, Large Language Models (LLMs) remain prone to hallucination, which critically undermines their trustworthiness. While most of the previous work focused on tackling answer and attribution correctness, a recent line of work investigated faithfulness, with a focus on leveraging internal model signals to reflect a models actual decision-making process while generating the answer. Nevertheless, these methods induce additional latency and have shown limitations in directly aligning token generation with attribution generation. In this paper, we introduce LoDIT, a method that jointly generates and faithfully attributes answers in RAG by leveraging specific token logits during generation. It consists of two steps: (1) marking the documents with specific token identifiers and then leveraging the logits of these tokens to estimate the contribution of each document to the answer during generation, and (2) aggregating these contributions into document attributions. Experiments on a trustworthiness-focused attributed text-generation benchmark, Trust-Align, show that LoDIT significantly outperforms state-of-the-art models on several metrics. Finally, an in-depth analysis of LoDIT shows both its efficiency in terms of latency and its robustness in different settings.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3728425.3759909" target="_blank">MADPromptS: Unlocking Zero-Shot Morphing Attack Detection with Multiple Prompt Aggregation</a></h3>
                    <p><strong>Authors:</strong> Eduarda Caldeira, Fadi Boutros, Naser Damer</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Face Morphing Attack Detection (MAD) is a critical challenge in face recognition security, where attackers can fool systems by interpolating the identity information of two or more individuals into a single face image, resulting in samples that can be verified as belonging to multiple identities by face recognition systems. While multimodal foundation models (FMs) like CLIP offer strong zero-shot capabilities by jointly modeling images and text, most prior works on FMs for biometric recognition have relied on fine-tuning for specific downstream tasks, neglecting their potential for direct, generalizable deployment. This work explores a pure zero-shot approach to MAD by leveraging CLIP without any additional training or fine-tuning, focusing instead on the design and aggregation of multiple textual prompts per class. By aggregating the embeddings of diverse prompts, we better align the models internal representations with the MAD task, capturing richer and more varied cues indicative of bona-fide or attack samples. Our results show that prompt aggregation substantially improves zero-shot detection performance, demonstrating the effectiveness of exploiting foundation models built-in multimodal knowledge through efficient prompt engineering.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08928v1" target="_blank">DASC: Depth-of-Field Aware Scene Complexity Metric for 3D Visualization on Light Field Display</a></h3>
                    <p><strong>Authors:</strong> Kamran Akbar, Robert Bregovic, Federica Battisti</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.MM, cs.GR</p>
                    <p><strong>Summary:</strong> Light field display is one of the technologies providing 3D immersive visualization. However, a light field display generates only a limited number of light rays which results in finite angular and spatial resolutions. Therefore, 3D content can be shown with high quality only within a narrow depth range notated as Depth of Field (DoF) around the display screen. Outside this range, due to the appearance of aliasing artifacts, the quality degrades proportionally to the distance from the screen. One solution to mitigate the artifacts is depth of field rendering which blurs the content in the distorted regions, but can result in the removal of scene details. This research focuses on proposing a DoF Aware Scene Complexity (DASC) metric that characterizes 3D content based on geometrical and positional factors considering the light field displays DoF. In this research, we also evaluate the observers preference across different level of blurriness caused by DoF rendering ranging from sharp, aliased scenes to overly smoothed alias-free scenes. We have conducted this study over multiple scenes that we created to account for different types of content. Based on the outcome of subjective studies, we propose a model that takes the value of DASC metric as input and predicts the preferred level of blurring for the given scene as output.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08917v1" target="_blank">A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition</a></h3>
                    <p><strong>Authors:</strong> Jintao Cheng, Jiehao Luo, Xieyuanli Chen, Jin Wu, Rui Fan, Xiaoyu Tang, Wei Zhang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> LiDAR-based Place Recognition (LPR) remains a critical task in Embodied Artificial Intelligence (AI) and Autonomous Driving, primarily addressing localization challenges in GPS-denied environments and supporting loop closure detection. Existing approaches reduce place recognition to a Euclidean distance-based metric learning task, neglecting the feature spaces intrinsic structures and intra-class variances. Such Euclidean-centric formulation inherently limits the models capacity to capture nonlinear data distributions, leading to suboptimal performance in complex environments and temporal-varying scenarios. To address these challenges, we propose a novel cross-view network based on an innovative fusion paradigm. Our framework introduces a pseudo-global information guidance mechanism that coordinates multi-modal branches to perform feature learning within a unified semantic space. Concurrently, we propose a Manifold Adaptation and Pairwise Variance-Locality Learning Metric that constructs a Symmetric Positive Definite (SPD) matrix to compute Mahalanobis distance, superseding traditional Euclidean distance metrics. This geometric formulation enables the model to accurately characterize intrinsic data distributions and capture complex inter-class dependencies within the feature space. Experimental results demonstrate that the proposed algorithm achieves competitive performance, particularly excelling in complex environmental conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08916v1" target="_blank">Automatic and standardized surgical reporting for central nervous system tumors</a></h3>
                    <p><strong>Authors:</strong> David Bouget, Mathilde Gajda Faanes, Asgeir Store Jakola, Frederik Barkhof, Hilko Ardon, Lorenzo Bello, Mitchel S. Berger, Shawn L. Hervey-Jumper, Julia Furtner, Albert J. S. Idema, Barbara Kiesel, Georg Widhalm, Rishi Nandoe Tewarie, Emmanuel Mandonnet, Pierre A. Robe, Michiel Wagemakers, Timothy R. Smith, Philip C. De Witt Hamer, Ole solheim, Ingerid Reinertsen</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG, I.4.6; J.3</p>
                    <p><strong>Summary:</strong> Magnetic resonance (MR) imaging is essential for evaluating central nervous system (CNS) tumors, guiding surgical planning, treatment decisions, and assessing postoperative outcomes and complication risks. While recent work has advanced automated tumor segmentation and report generation, most efforts have focused on preoperative data, with limited attention to postoperative imaging analysis. This study introduces a comprehensive pipeline for standardized postsurtical reporting in CNS tumors. Using the Attention U-Net architecture, segmentation models were trained for the preoperative (non-enhancing) tumor core, postoperative contrast-enhancing residual tumor, and resection cavity. Additionally, MR sequence classification and tumor type identification for contrast-enhancing lesions were explored using the DenseNet architecture. The models were integrated into a reporting pipeline, following the RANO 2.0 guidelines. Training was conducted on multicentric datasets comprising 2000 to 7000 patients, using a 5-fold cross-validation. Evaluation included patient-, voxel-, and object-wise metrics, with benchmarking against the latest BraTS challenge results. The segmentation models achieved average voxel-wise Dice scores of 87%, 66%, 70%, and 77% for the tumor core, non-enhancing tumor core, contrast-enhancing residual tumor, and resection cavity, respectively. Classification models reached 99.5% balanced accuracy in MR sequence classification and 80% in tumor type classification. The pipeline presented in this study enables robust, automated segmentation, MR sequence classification, and standardized report generation aligned with RANO 2.0 guidelines, enhancing postoperative evaluation and clinical decision-making. The proposed models and methods were integrated into Raidionics, open-source software platform for CNS tumor analysis, now including a dedicated module for postsurgical analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.08909v1" target="_blank">Compass-Thinker-7B Technical Report</a></h3>
                    <p><strong>Authors:</strong> Anxiang Zeng, Haibo Zhang, Kaixiang Mo, Long Zhang, Shuman Liu, Yanhui Huang, Yawen Liu, Yuepeng Sheng, Yuwei Huang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Recent R1-Zero-like research further demonstrates that reasoning extension has given large language models (LLMs) unprecedented reasoning capabilities, and Reinforcement Learning is the core technology to elicit its complex reasoning. However, conducting RL experiments directly on hyperscale models involves high computational costs and resource demands, posing significant risks. We propose the Compass-Thinker-7B model, which aims to explore the potential of Reinforcement Learning with less computational resources and costs, and provides insights for further research into RL recipes for larger models. Compass-Thinker-7B is trained from an open source model through a specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k verifiable mathematics problems for the Reinforcement Learning Pipeline. By configuring data and training settings with different difficulty distributions for different stages, the potential of the model is gradually released and the training efficiency is improved. Extensive evaluations show that Compass-Thinker-7B possesses exceptional reasoning potential, and achieves superior performance on mathematics compared to the same-sized RL model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B achieves 40% accuracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09139v1" target="_blank">Quantum Sensing Radiative Decays of Neutrinos and Dark Matter Particles</a></h3>
                    <p><strong>Authors:</strong> Zhongtian Dong, Doojin Kim, Kyoungchul Kong, Myeonghun Park, Miguel A. Soto Alcaraz</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> hep-ph, hep-ex</p>
                    <p><strong>Summary:</strong> We explore a novel strategy for detecting the radiative decay of very weakly interacting particles by leveraging the extreme sensitivity of quantum devices, such as superconducting transmon qubits and trapped ion systems, to faint electromagnetic signals. By modeling the effective electric field induced by the decay photons, we evaluate the response of quantum sensors across two particle physics scenarios: the cosmic neutrino background and two-component dark matter. We assess the discovery potential of these devices and outline the parameter space accessible under current experimental capabilities. Our analysis demonstrates that quantum sensors can probe radiative decays of dark matter candidates using existing technology, while probing neutrino magnetic moments beyond current limits will require scalable quantum architectures with enhanced coherence.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09138v1" target="_blank">Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models</a></h3>
                    <p><strong>Authors:</strong> Wen Wang, Bozhen Fang, Chenchen Jing, Yongliang Shen, Yangyi Shen, Qiuyu Wang, Hao Ouyang, Hao Chen, Chunhua Shen</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Diffusion large language models (dLLMs) generate text through iterative denoising, yet current decoding strategies discard rich intermediate predictions in favor of the final output. Our work here reveals a critical phenomenon, temporal oscillation, where correct answers often emerge in the middle process, but are overwritten in later denoising steps. To address this issue, we introduce two complementary methods that exploit temporal consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time decoding strategy that aggregates predictions across denoising steps to select the most consistent output; and 2) a post-training method termed Temporal Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a measure of semantic stability across intermediate predictions, as a reward signal to encourage stable generations. Empirical results across multiple benchmarks demonstrate the effectiveness of our approach. Using the negative TSE reward alone, we observe a remarkable average improvement of 24.7% on the Countdown dataset over an existing dLLM. Combined with the accuracy reward, we achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and 25.3% on Countdown, respectively. Our findings underscore the untapped potential of temporal dynamics in dLLMs and offer two simple yet effective tools to harness them.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09137v1" target="_blank">HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis</a></h3>
                    <p><strong>Authors:</strong> Timo Teufel, Pulkit Gera, Xilong Zhou, Umar Iqbal, Pramod Rao, Jan Kautz, Vladislav Golyanik, Christian Theobalt</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Simultaneous relighting and novel-view rendering of digital human representations is an important yet challenging task with numerous applications. Progress in this area has been significantly limited due to the lack of publicly available, high-quality datasets, especially for full-body human captures. To address this critical gap, we introduce the HumanOLAT dataset, the first publicly accessible large-scale dataset of multi-view One-Light-at-a-Time (OLAT) captures of full-body humans. The dataset includes HDR RGB frames under various illuminations, such as white light, environment maps, color gradients and fine-grained OLAT illuminations. Our evaluations of state-of-the-art relighting and novel-view synthesis methods underscore both the datasets value and the significant challenges still present in modeling complex human-centric appearance and lighting interactions. We believe HumanOLAT will significantly facilitate future research, enabling rigorous benchmarking and advancements in both general and human-specific relighting and rendering techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09136v1" target="_blank">Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices</a></h3>
                    <p><strong>Authors:</strong> Ya Zou, Jingfeng Yao, Siyuan Yu, Shuai Zhang, Wenyu Liu, Xinggang Wang</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> There is a growing demand for deploying large generative AI models on mobile devices. For recent popular video generative models, however, the Variational AutoEncoder (VAE) represents one of the major computational bottlenecks. Both large parameter sizes and mismatched kernels cause out-of-memory errors or extremely slow inference on mobile devices. To address this, we propose a low-cost solution that efficiently transfers widely used video VAEs to mobile devices. (1) We analyze redundancy in existing VAE architectures and get empirical design insights. By integrating 3D depthwise separable convolutions into our model, we significantly reduce the number of parameters. (2) We observe that the upsampling techniques in mainstream video VAEs are poorly suited to mobile hardware and form the main bottleneck. In response, we propose a decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building upon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3) We propose an efficient VAE decoder training method. Since only the decoder is used during deployment, we distill it to Turbo-VAED instead of retraining the full VAE, enabling fast mobile adaptation with minimal performance loss. To our knowledge, our method enables real-time 720p video VAE decoding on mobile devices for the first time. This approach is widely applicable to most video VAEs. When integrated into four representative models, with training cost as low as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on GPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of the original reconstruction quality. Compared to mobile-optimized VAEs, Turbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on the iPhone 16 Pro. The code and models will soon be available at https://github.com/hustvl/Turbo-VAED.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09134v1" target="_blank">Instrument-based quantum resources: quantification, hierarchies and towards constructing resource theories</a></h3>
                    <p><strong>Authors:</strong> Jatin Ghai, Arindam Mitra</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Quantum resources are certain features of the quantum world that provide advantages in certain information-theoretic, thermodynamic, or any other useful operational tasks that are outside the realm of what classical theories can achieve. Quantum resource theories provide us with an elegant framework for studying these resources quantitatively and rigorously. While numerous state-based quantum resource theories have already been investigated, and to some extent, measurement-based resource theories have also been explored, instrument-based resource theories remain largely unexplored, with only a few notable exceptions. As quantum instruments are devices that provide both the classical outcomes of induced measurements and the post-measurement quantum states, they are quite important, especially for scenarios where multiple parties sequentially act on a quantum system. In this work, we study several instrument-based resource theories, namely (1) the resource theory of information preservability, (2) the resource theory of (strong) entanglement preservability, (3) the resource theory of (strong) incompatibility preservability, (4) the resource theory of traditional incompatibility, and (5) the resource theory of parallel incompatibility. Furthermore, we outline the hierarchies of these instrument-based resources and provide measures to quantify them. In short, we provide a detailed framework for several instrument-based quantum resource theories.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09131v1" target="_blank">Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer</a></h3>
                    <p><strong>Authors:</strong> Zixin Yin, Xili Dai, Ling-Hao Chen, Deyu Zhou, Jianan Wang, Duomin Wang, Gang Yu, Lionel M. Ni, Heung-Yeung Shum</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Text-guided color editing in images and videos is a fundamental yet unsolved problem, requiring fine-grained manipulation of color attributes, including albedo, light source color, and ambient lighting, while preserving physical consistency in geometry, material properties, and light-matter interactions. Existing training-free methods offer broad applicability across editing tasks but struggle with precise color control and often introduce visual inconsistency in both edited and non-edited regions. In this work, we present ColorCtrl, a training-free color editing method that leverages the attention mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By disentangling structure and color through targeted manipulation of attention maps and value tokens, our method enables accurate and consistent color editing, along with word-level control of attribute intensity. Our method modifies only the intended regions specified by the prompt, leaving unrelated areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate that ColorCtrl outperforms existing training-free approaches and achieves state-of-the-art performances in both edit quality and consistency. Furthermore, our method surpasses strong commercial models such as FLUX.1 Kontext Max and GPT-4o Image Generation in terms of consistency. When extended to video models like CogVideoX, our approach exhibits greater advantages, particularly in maintaining temporal coherence and editing stability. Finally, our method also generalizes to instruction-based editing diffusion models such as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09128v1" target="_blank">A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions</a></h3>
                    <p><strong>Authors:</strong> Dhruv S. Kushwaha, Zoleikha A. Biron</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, 93E99, A.1; I.2</p>
                    <p><strong>Summary:</strong> Reinforcement learning (RL) has proven to be particularly effective in solving complex decision-making problems for a wide range of applications. From a control theory perspective, RL can be considered as an adaptive optimal control scheme. Lyapunov and barrier functions are the most commonly used certificates to guarantee system stability for a proposed/derived controller and constraint satisfaction guarantees, respectively, in control theoretic approaches. However, compared to theoretical guarantees available in control theoretic methods, RL lacks closed-loop stability of a computed policy and constraint satisfaction guarantees. Safe reinforcement learning refers to a class of constrained problems where the constraint violations lead to partial or complete system failure. The goal of this review is to provide an overview of safe RL techniques using Lyapunov and barrier functions to guarantee this notion of safety discussed (stability of the system in terms of a computed policy and constraint satisfaction during training and deployment). The different approaches employed are discussed in detail along with their shortcomings and benefits to provide critique and possible future research directions. Key motivation for this review is to discuss current theoretical approaches for safety and stability guarantees in RL similar to control theoretic approaches using Lyapunov and barrier functions. The review provides proven potential and promising scope of providing safety guarantees for complex dynamical systems with operational constraints using model-based and model-free RL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09125v1" target="_blank">Complex Logical Instruction Generation</a></h3>
                    <p><strong>Authors:</strong> Mian Zhang, Shujian Liu, Sixun Dong, Ming Yin, Yebowen Hu, Xun Wang, Steven Ma, Song Wang, Sathish Reddy Indurthi, Haoyun Deng, Zhiyu Zoey Chen, Kaiqiang Song</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Instruction following has catalyzed the recent era of Large Language Models (LLMs) and is the foundational skill underpinning more advanced capabilities such as reasoning and agentic behaviors. As tasks grow more challenging, the logic structures embedded in natural language instructions becomes increasingly intricate. However, how well LLMs perform on such logic-rich instructions remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a scalable, automated framework for generating verifiable instructions from code functions, which can naturally express rich logic such as conditionals, nesting, recursion, and function calls. We further curate a collection of complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark comprising 426 verifiable logic-rich instructions. Our experiments demonstrate that current state-of-the-art LLMs still struggle to correctly follow the instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the instructions, revealing significant deficiencies in the instruction-following ability. Code and Benchmark: https://github.com/mianzhang/LogicIF</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09124v1" target="_blank">OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows</a></h3>
                    <p><strong>Authors:</strong> Weixuan Wang, Dongge Han, Daniel Madrigal Diaz, Jin Xu, Victor RÃ¼hle, Saravan Rajmohan</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows. However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios. To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar. Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks. Each task requires agent to identify essential information from long-horizon interaction histories and perform multi-step reasoning across various applications. To enable scalable benchmark creation, we propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis. Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. We believe that OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios. In addition, we release OdysseyBench and HomerAgents to foster research along this line.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.09123v1" target="_blank">OpenCUA: Open Foundations for Computer-Use Agents</a></h3>
                    <p><strong>Authors:</strong> Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo, Yiheng Xu, Chen Henry Wu, Zhennan Shen, Zhuokai Li, Ryan Li, Xiaochuan Li, Junda Chen, Boyuan Zheng, Peihang Li, Fangyu Lei, Ruisheng Cao, Yeqiao Fu, Dongchan Shin, Martin Shin, Jiarui Hu, Yuyan Wang, Jixuan Chen, Yuxiao Ye, Danyang Zhang, Dikang Du, Hao Hu, Huarong Chen, Zaida Zhou, Yipu Wang, Heng Wang, Diyi Yang, Victor Zhong, Flood Sung, Y. Charles, Zhilin Yang, Tao Yu</p>
                    <p><strong>Published:</strong> 8/12/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

