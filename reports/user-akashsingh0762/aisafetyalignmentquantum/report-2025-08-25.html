
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-25<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The collection of research papers on AI safety research presents a wide array of advancements and challenges, emphasizing the importance of developing secure, reliable, and interpretable AI systems across various domains. A central theme is the need for robust benchmarks and frameworks to evaluate and ensure the safety of AI technologies. For instance, the paper on benchmarking robustness of agentic systems to adversarial harms highlights vulnerabilities in agentic systems and proposes a framework (BAD-ACTS) to systematically evaluate these threats and develop more resilient systems. Similarly, the introduction of Retrieval-Augmented Defense (RAD) aims to bolster the defense mechanisms against jailbreak attacks in large language models (LLMs), emphasizing adaptation without retraining.

Another significant trend is the focus on explainability and interpretability of AI models, as seen in the development of explainable AI for solar storm prediction and the introduction of LLMSymGuard, which uses interpretable concepts to build symbolic safety guardrails for LLMs. These efforts underscore the necessity of transparent AI systems that users can trust and understand. Additionally, the paper on data gluttony discusses the epistemic risks associated with data reuse and proposes strategies like data temperance to manage inferential errors, further emphasizing the need for careful data governance to ensure AI safety. Collectively, these research efforts reflect a growing recognition of AIs potential risks and the critical need for comprehensive safety measures to mitigate these challenges, thereby ensuring the responsible deployment of AI technologies in various applications.

*Based on 50 research papers*

---

## quantum computing

The selected research papers cover diverse advancements in quantum computing and related fields, emphasizing key trends, breakthroughs, and implications. Notably, the paper on **Optimal Hamiltonian for a quantum state with finite entropy** by M. E. Shirokov introduces a novel approach to determining the optimal Hamiltonian for a given quantum state with finite entropy, providing explicit expressions and proposing potential applications in quantum thermodynamics and resource management. This work contributes to a deeper understanding of energy efficiency in quantum systems, which is crucial for developing more sustainable quantum technologies.

Another significant contribution is presented in **Emergent statistical mechanics in holographic random tensor networks** by Shozab Qasim et al., which explores the dynamics of random tensor networks (RTNs) on hyperbolic geometries. This research demonstrates how RTNs can model critical boundary states and exhibit equilibration under generic Hamiltonians, offering a new perspective on holographic dualities and quantum many-body phases. These insights could lead to novel approaches in simulating complex quantum systems, enhancing our ability to probe the fundamental nature of quantum entanglement and holography.

Lastly, the study **Automated discovery of heralded ballistic graph state generators for fusion-based photonic quantum computation** by Gavin S. Hartnett et al. highlights advancements in designing photonic circuits for high-fidelity graph state preparation. Utilizing a polynomial-based simulation approach, the research achieves significant improvements in success probabilities for photonic quantum circuits, which is vital for scalable quantum computing. This paper underscores the importance of automation and optimization in the development of efficient quantum photonic systems, paving the way for practical quantum information processing and communication technologies. Together, these papers illustrate significant strides in understanding and enhancing quantum resources, computation, and simulation, all of which are critical for the continued evolution of quantum technologies.

*Based on 50 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.16576v1" target="_blank">Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet</a></h3>
                    <p><strong>Authors:</strong> Anyu Ying, Natarajan Balaji Shankar, Chyi-Jiunn Lin, Mohan Shi, Pu Wang, Hye-jin Shim, Siddhant Arora, Hugo Van hamme, Abeer Alwan, Shinji Watanabe</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite advancements in ASR, child speech recognition remains challenging due to acoustic variability and limited annotated data. While fine-tuning adult ASR models on child speech is common, comparisons with flat-start training remain underexplored. We compare flat-start training across multiple datasets, SSL representations (WavLM, XEUS), and decoder architectures. Our results show that SSL representations are biased toward adult speech, with flat-start training on child speech mitigating these biases. We also analyze model scaling, finding consistent improvements up to 1B parameters, beyond which performance plateaus. Additionally, age-related ASR and speaker verification analysis highlights the limitations of proprietary models like Whisper, emphasizing the need for open-data models for reliable child speech research. All investigations are conducted using ESPnet, and our publicly available benchmark provides insights into training strategies for robust child speech processing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16571v1" target="_blank">LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence</a></h3>
                    <p><strong>Authors:</strong> Alisa Vinogradova, Vlad Vinogradov, Dmitrii Radkevich, Ilya Yasny, Dmitry Kobyzev, Ivan Izmailov, Katsiaryna Yanchanka, Andrey Doronichev</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.IR, cs.MA</p>
                    <p><strong>Summary:</strong> In this paper, we describe and benchmark a competitor-discovery component used within an agentic AI system for fast drug asset due diligence. A competitor-discovery AI agent, given an indication, retrieves all drugs comprising the competitive landscape of that indication and extracts canonical attributes for these drugs. The competitor definition is investor-specific, and data is paywalled/licensed, fragmented across registries, ontology-mismatched by indication, alias-heavy for drug names, multimodal, and rapidly changing. Although considered the best tool for this problem, the current LLM-based AI systems arent capable of reliably retrieving all competing drug names, and there is no accepted public benchmark for this task. To address the lack of evaluation, we use LLM-based agents to transform five years of multi-modal, unstructured diligence memos from a private biotech VC fund into a structured evaluation corpus mapping indications to competitor drugs with normalized attributes. We also introduce a competitor validating LLM-as-a-judge agent that filters out false positives from the list of predicted competitors to maximize precision and suppress hallucinations. On this benchmark, our competitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research (65%) and Perplexity Labs (60%). The system is deployed in production with enterprise users; in a case study with a biotech VC investment fund, analyst turnaround time dropped from 2.5 days to $\sim$3 hours ($\sim$20x) for the competitive analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16552v1" target="_blank">Data Gluttony: Epistemic Risks, Dependent Testing and Data Reuse in Large Datasets</a></h3>
                    <p><strong>Authors:</strong> Reid Dale, Jordan Rodu, Maria E. Currie, Mike Baiocchi</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> math.ST, stat.ME, stat.TH</p>
                    <p><strong>Summary:</strong> Large-scale registries have collected vast amounts of data which has enabled investigators to efficiently conduct studies of observational data. Common practice is for investigators to use all data meeting the inclusion criteria of their study to perform their analysis. We term this common practice data gluttony. It has apparent formal justification insofar as this approach maximizes per-study power. But this comes at a cost: data reuse affects the shape of the tail distribution of inferential errors. Using the theory of risk orderings we demonstrate how positively dependent testing procedures result in strictly riskier distributions of inferential error. We identify two remedies to this state of affairs: research portfolio optimization and what we term data temperance. Research portfolio optimization requires that we formulate the enterprise of inference in a utility theoretic framework: associated to each hypothesis to be evaluated is some utility dependent on its truth as well as the impact of the statistical decision rendered on the basis of the data. Under certain models of data governance, this approach can be used to optimally allocate data usage across multiple inferential tasks. On the other hand, data temperance is a more flexible strategy for managing the distribution of inferential errors. Data temperance is the principle that an investigator use only as much data as is necessary to perform the task at hand. This is possible due to the diminishing marginal returns in power and precision in sample size. We analyze the effectiveness of data temperance at reducing the dependence across testing and develop a theory of the capacity of a static database to sustain large numbers of inferential tasks with low probability of inducing pairwise dependent testing procedures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16543v1" target="_blank">Explainable AI in Deep Learning-Based Prediction of Solar Storms</a></h3>
                    <p><strong>Authors:</strong> Adam O. Rawashdeh, Jason T. L. Wang, Katherine G. Herbert</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> A deep learning model is often considered a black-box model, as its internal workings tend to be opaque to the user. Because of the lack of transparency, it is challenging to understand the reasoning behind the models predictions. Here, we present an approach to making a deep learning-based solar storm prediction model interpretable, where solar storms include solar flares and coronal mass ejections (CMEs). This deep learning model, built based on a long short-term memory (LSTM) network with an attention mechanism, aims to predict whether an active region (AR) on the Suns surface that produces a flare within 24 hours will also produce a CME associated with the flare. The crux of our approach is to model data samples in an AR as time series and use the LSTM network to capture the temporal dynamics of the data samples. To make the models predictions accountable and reliable, we leverage post hoc model-agnostic techniques, which help elucidate the factors contributing to the predicted output for an input sequence and provide insights into the models behavior across multiple sequences within an AR. To our knowledge, this is the first time that interpretability has been added to an LSTM-based solar storm prediction model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16527v1" target="_blank">Towards Open World Detection: A Survey</a></h3>
                    <p><strong>Authors:</strong> Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, 68T45, A.1; I.2; I.4</p>
                    <p><strong>Summary:</strong> For decades, Computer Vision has aimed at enabling machines to perceive the external world. Initial limitations led to the development of highly specialized niches. As success in each task accrued and research progressed, increasingly complex perception tasks emerged. This survey charts the convergence of these tasks and, in doing so, introduces Open World Detection (OWD), an umbrella term we propose to unify class-agnostic and generally applicable detection models in the vision domain. We start from the history of foundational vision subdomains and cover key concepts, methodologies and datasets making up todays state-of-the-art landscape. This traverses topics starting from early saliency detection, foreground/background separation, out of distribution detection and leading up to open world object detection, zero-shot detection and Vision Large Language Models (VLLMs). We explore the overlap between these subdomains, their increasing convergence, and their potential to unify into a singular domain in the future, perception.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.telpol.2020.101960" target="_blank">Innovation ecosystems theory revisited: The case of artificial intelligence in China</a></h3>
                    <p><strong>Authors:</strong> Arenal Alberto, Armuna Cristina, Feijoo Claudio, Ramos Sergio, Xu Zimu, Moreno Ana Maria</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> econ.TH</p>
                    <p><strong>Summary:</strong> Beyond the mainstream discussion on the key role of China in the global AI landscape, the knowledge about the real performance and future perspectives of the AI ecosystem in China is still limited. This paper evaluates the status and prospects of Chinas AI innovation ecosystem by developing a Triple Helix framework particularized for this case. Based on an in-depth qualitative study and on interviews with experts, the analysis section summarizes the way in which the AI innovation ecosystem in China is being built, which are the key features of the three spheres of the Triple Helix -governments, industry and academic/research institutions-as well as the dynamic context of the ecosystem through the identification of main aspects related to the flows of skills, knowledge and funding and the interactions among them. Using this approach, the discussion section illustrates the specificities of the AI innovation ecosystem in China, its strengths and its gaps, and which are its prospects. Overall, this revisited ecosystem approach permits the authors to address the complexity of emerging environments of innovation to draw meaningful conclusions which are not possible with mere observation. The results show how a favourable context, the broad adoption rate and the competition for talent and capital among regional-specialized clusters are boosting the advance of AI in China, mainly in the business to customer arena. Finally, the paper highlights the challenges ahead in the current implementation of the ecosystem that will largely determine the potential global leadership of China in this domain.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16519v1" target="_blank">The Community Index: A More Comprehensive Approach to Assessing Scholarly Impact</a></h3>
                    <p><strong>Authors:</strong> Arav Kumar, Cameron Sabet, Alessandro Hammond, Amelia Fiske, Bhav Jain, Deirdre Goode, Dharaa Suresha, Leo Anthony Celi, Lisa Soleymani Lehmann, Ned Mccague, Rawan Abulibdeh, Sameer Pradhan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.DL, stat.CO</p>
                    <p><strong>Summary:</strong> The h index is a widely recognized metric for assessing the research impact of scholars, defined as the maximum value h such that the scholar has published h papers each cited at least h times. While it has proven useful measuring individual scholarly productivity and citation impact, the h index has limitations, such as an inability to account for interdisciplinary collaboration or demographic differences in citation patterns. Moreover, it is sometimes mistakenly treated as a measure of research quality, even though it only reflects how often work has been cited. While metric based evaluations of research have grown in importance in some areas of academia, such as medicine, these evaluations fail to consider other important aspects of intellectual work, such as representational and epistemic diversity in research. In this article, we propose a new metric called the c index, or the community index, which combines multiple dimensions of scholarly impact. This is important because a plurality of perspectives and lived experiences within author teams can promote epistemological reflection and humility as part of the creation and validation of scientific knowledge. The c index is a means of accounting for the often global, and increasingly interdisciplinary nature of contemporary research, in particular, the data that is collected, curated and analyzed in the process of scientific inquiry. While the c index provides a means of quantifying diversity within research teams, diversity is integral to the advancement of scientific excellence and should be actively fostered through formal recognition and valuation. We herein describe the mathematical foundation of the c index and demonstrate its potential to provide a more comprehensive representation and more multidimensional assessment of scientific contributions of research impact as compared to the h index.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16508v1" target="_blank">Abmax: A JAX-based Agent-based Modeling Framework</a></h3>
                    <p><strong>Authors:</strong> Siddharth Chaturvedi, Ahmed El-Gazzar, Marcel van Gerven</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MA, cs.SE</p>
                    <p><strong>Summary:</strong> Agent-based modeling (ABM) is a principal approach for studying complex systems. By decomposing a system into simpler, interacting agents, agent-based modeling (ABM) allows researchers to observe the emergence of complex phenomena. High-performance array computing libraries like JAX can help scale such computational models to a large number of agents by using automatic vectorization and just-in-time (JIT) compilation. One of the caveats of using JAX to achieve such scaling is that the shapes of arrays used in the computational model should remain immutable throughout the simulation. In the context of agent-based modeling (ABM), this can pose constraints on certain agent manipulation operations that require flexible data structures. A subset of which is represented by the ability to update a dynamically selected number of agents by applying distinct changes to them during a simulation. To this effect, we introduce Abmax, an ABM framework based on JAX that implements multiple just-in-time (JIT) compilable algorithms to provide this functionality. On the canonical predation model benchmark, Abmax achieves runtime performance comparable to state-of-the-art implementations. Further, we show that this functionality can also be vectorized, making it possible to run many similar agent-based models in parallel. We also present two examples in the form of a traffic-flow model and a financial market model to show the use case of Abmax.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16488v1" target="_blank">SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being</a></h3>
                    <p><strong>Authors:</strong> Kayenat Fatmi, Mohammad Abbas</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> In the digital era, individuals are increasingly exposed to online harms such as toxicity, manipulation, and grooming, which often pose emotional and safety risks. Existing systems for detecting abusive content or issuing safety alerts operate in isolation and rarely combine digital safety with emotional well-being. In this paper, we present SafeSpace, a unified web application that integrates three modules: (1) toxicity detection in chats and screenshots using NLP models and Googles Perspective API, (2) a configurable safety ping system that issues emergency alerts with the users live location (longitude and latitude) via SMTP-based emails when check-ins are missed or SOS alerts are manually triggered, and (3) a reflective questionnaire that evaluates relationship health and emotional resilience. The system employs Firebase for alert management and a modular architecture designed for usability, privacy, and scalability. The experimental evaluation shows 93% precision in toxicity detection, 100% reliability in safety alerts under emulator tests, and 92% alignment between automated and manual questionnaire scoring. SafeSpace, implemented as a web application, demonstrates the feasibility of integrating detection, protection, and reflection within a single platform, with future deployment envisioned as a mobile application for broader accessibility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16481v1" target="_blank">Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms</a></h3>
                    <p><strong>Authors:</strong> Jonathan NÃ¶ther, Adish Singla, Goran Radanovic</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Ensuring the safe use of agentic systems requires a thorough understanding of the range of malicious behaviors these systems may exhibit when under attack. In this paper, we evaluate the robustness of LLM-based agentic systems against attacks that aim to elicit harmful actions from agents. To this end, we propose a novel taxonomy of harms for agentic systems and a novel benchmark, BAD-ACTS, for studying the security of agentic systems with respect to a wide range of harmful actions. BAD-ACTS consists of 4 implementations of agentic systems in distinct application environments, as well as a dataset of 188 high-quality examples of harmful actions. This enables a comprehensive study of the robustness of agentic systems across a wide range of categories of harmful behaviors, available tools, and inter-agent communication structures. Using this benchmark, we analyze the robustness of agentic systems against an attacker that controls one of the agents in the system and aims to manipulate other agents to execute a harmful target action. Our results show that the attack has a high success rate, demonstrating that even a single adversarial agent within the system can have a significant impact on the security. This attack remains effective even when agents use a simple prompting-based defense strategy. However, we additionally propose a more effective defense based on message monitoring. We believe that this benchmark provides a diverse testbed for the security research of agentic systems. The benchmark can be found at github.com/JNoether/BAD-ACTS</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16474v1" target="_blank">Reinforcement Learning-based Control via Y-wise Affine Neural Networks (YANNs)</a></h3>
                    <p><strong>Authors:</strong> Austin Braniff, Yuhe Tian</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.LG, cs.SY, math.OC</p>
                    <p><strong>Summary:</strong> This work presents a novel reinforcement learning (RL) algorithm based on Y-wise Affine Neural Networks (YANNs). YANNs provide an interpretable neural network which can exactly represent known piecewise affine functions of arbitrary input and output dimensions defined on any amount of polytopic subdomains. One representative application of YANNs is to reformulate explicit solutions of multi-parametric linear model predictive control. Built on this, we propose the use of YANNs to initialize RL actor and critic networks, which enables the resulting YANN-RL control algorithm to start with the confidence of linear optimal control. The YANN-actor is initialized by representing the multi-parametric control solutions obtained via offline computation using an approximated linear system model. The YANN-critic represents the explicit form of the state-action value function for the linear system and the reward function as the objective in an optimal control problem (OCP). Additional network layers are injected to extend YANNs for nonlinear expressions, which can be trained online by directly interacting with the true complex nonlinear system. In this way, both the policy and state-value functions exactly represent a linear OCP initially and are able to eventually learn the solution of a general nonlinear OCP. Continuous policy improvement is also implemented to provide heuristic confidence that the linear OCP solution serves as an effective lower bound to the performance of RL policy. The YANN-RL algorithm is demonstrated on a clipped pendulum and a safety-critical chemical-reactive system. Our results show that YANN-RL significantly outperforms the modern RL algorithm using deep deterministic policy gradient, especially when considering safety constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16457v1" target="_blank">Wide-Area Power System Oscillations from Large-Scale AI Workloads</a></h3>
                    <p><strong>Authors:</strong> Min-Seung Ko, Hao Zhu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> This paper develops a new dynamic power profiling approach for modeling AI-centric datacenter loads and analyzing their impact on grid operations, particularly their potential to induce wide-area grid oscillations. We characterize the periodic stochastic power fluctuations inherent to large-scale AI workloads during both the training and fine-tuning stages, driven by the state-of-the-art GPU computing architecture designs. These sustained, large power fluctuations, unlike conventional load ramping, act as persistent forcing inputs capable of interacting with and amplifying local and inter-area oscillation modes. Using the WECC 179-bus system as a test case, we examine the amplitude and variability of oscillatory responses under different factors, ranging from system strength, penetration level, fluctuation frequency range, individual datacenter size, to geographical deployment. Simulation results show that, notably, narrower fluctuation bands, larger single-site capacities, or dispersed siting can intensify oscillations across multiple modes. Our models and numerical studies provide a quantitative basis for integrating AI-dominant electricity demands into grid oscillation studies, and further support the development of new planning and operational measures to power the continuous AI load growth.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746027.3755257" target="_blank">Beyond Interpretability: Exploring the Comprehensibility of Adaptive Video Streaming through Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Lianchen Jia, Chaoyang Li, Ziqi Yuan, Jiahui Chen, Tianchi Huang, Jiangchuan Liu, Lifeng Sun</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MM, cs.LG, eess.IV</p>
                    <p><strong>Summary:</strong> Over the past decade, adaptive video streaming technology has witnessed significant advancements, particularly driven by the rapid evolution of deep learning techniques. However, the black-box nature of deep learning algorithms presents challenges for developers in understanding decision-making processes and optimizing for specific application scenarios. Although existing research has enhanced algorithm interpretability through decision tree conversion, interpretability does not directly equate to developers subjective comprehensibility. To address this challenge, we introduce \texttt{ComTree}, the first bitrate adaptation algorithm generation framework that considers comprehensibility. The framework initially generates the complete set of decision trees that meet performance requirements, then leverages large language models to evaluate these trees for developer comprehensibility, ultimately selecting solutions that best facilitate human understanding and enhancement. Experimental results demonstrate that \texttt{ComTree} significantly improves comprehensibility while maintaining competitive performance, showing potential for further advancement. The source code is available at https://github.com/thu-media/ComTree.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16445v1" target="_blank">Using LLMs and Essence to Support Software Practice Adoption</a></h3>
                    <p><strong>Authors:</strong> Sonia Nicoletti, Paolo Ciancarini</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Recent advancements in natural language processing (NLP) have enabled the development of automated tools that support various domains, including software engineering. However, while NLP and artificial intelligence (AI) research has extensively focused on tasks such as code generation, less attention has been given to automating support for the adoption of best practices, the evolution of ways of working, and the monitoring of process health. This study addresses this gap by exploring the integration of Essence, a standard and thinking framework for managing software engineering practices, with large language models (LLMs). To this end, a specialised chatbot was developed to assist students and professionals in understanding and applying Essence. The chatbot employs a retrieval-augmented generation (RAG) system to retrieve relevant contextual information from a curated knowledge base. Four different LLMs were used to create multiple chatbot configurations, each evaluated both as a base model and augmented with the RAG system. The system performance was evaluated through both the relevance of retrieved context and the quality of generated responses. Comparative analysis against the general-purpose LLMs demonstrated that the proposed system consistently outperforms its baseline counterpart in domain-specific tasks. By facilitating access to structured software engineering knowledge, this work contributes to bridging the gap between theoretical frameworks and practical application, potentially improving process management and the adoption of software development practices. While further validation through user studies is required, these findings highlight the potential of LLM-based automation to enhance learning and decision-making in software engineering.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16440v1" target="_blank">Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework</a></h3>
                    <p><strong>Authors:</strong> Surya Murthy, Zhenyu Gao, John-Paul Clarke, Ufuk Topcu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MA, cs.LG</p>
                    <p><strong>Summary:</strong> Urban Air Mobility (UAM) envisions the widespread use of small aerial vehicles to transform transportation in dense urban environments. However, UAM faces critical operational challenges, particularly the balance between minimizing noise exposure and maintaining safe separation in low-altitude urban airspace, two objectives that are often addressed separately. We propose a reinforcement learning (RL)-based air traffic management system that integrates both noise and safety considerations within a unified, decentralized framework. Under this scalable air traffic coordination solution, agents operate in a structured, multi-layered airspace and learn altitude adjustment policies to jointly manage noise impact and separation constraints. The system demonstrates strong performance across both objectives and reveals tradeoffs among separation, noise exposure, and energy efficiency under high traffic density. The findings highlight the potential of RL and multi-objective coordination strategies in enhancing the safety, quietness, and efficiency of UAM operations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16439v1" target="_blank">PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark</a></h3>
                    <p><strong>Authors:</strong> Adil Bahaj, Mounir Ghogho</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.CL, cs.GR, cs.MM</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) and vision-augmented LLMs (VLMs) have significantly advanced medical informatics, diagnostics, and decision support. However, these models exhibit systematic biases, particularly age bias, compromising their reliability and equity. This is evident in their poorer performance on pediatric-focused text and visual question-answering tasks. This bias reflects a broader imbalance in medical research, where pediatric studies receive less funding and representation despite the significant disease burden in children. To address these issues, a new comprehensive multi-modal pediatric question-answering benchmark, PediatricsMQA, has been introduced. It consists of 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatric topics across seven developmental stages (prenatal to adolescent) and 2,067 vision-based MCQs using 634 pediatric images from 67 imaging modalities and 256 anatomical regions. The dataset was developed using a hybrid manual-automatic pipeline, incorporating peer-reviewed pediatric literature, validated question banks, existing benchmarks, and existing QA resources. Evaluating state-of-the-art open models, we find dramatic performance drops in younger cohorts, highlighting the need for age-aware methods to ensure equitable AI support in pediatric care.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16406v1" target="_blank">Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Guangyu Yang, Jinghong Chen, Jingbiao Mei, Weizhe Lin, Bill Byrne</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) remain vulnerable to jailbreak attacks, which attempt to elicit harmful responses from LLMs. The evolving nature and diversity of these attacks pose many challenges for defense systems, including (1) adaptation to counter emerging attack strategies without costly retraining, and (2) control of the trade-off between safety and utility. To address these challenges, we propose Retrieval-Augmented Defense (RAD), a novel framework for jailbreak detection that incorporates a database of known attack examples into Retrieval-Augmented Generation, which is used to infer the underlying, malicious user query and jailbreak strategy used to attack the system. RAD enables training-free updates for newly discovered jailbreak strategies and provides a mechanism to balance safety and utility. Experiments on StrongREJECT show that RAD substantially reduces the effectiveness of strong jailbreak attacks such as PAP and PAIR while maintaining low rejection rates for benign queries. We propose a novel evaluation scheme and show that RAD achieves a robust safety-utility trade-off across a range of operating points in a controllable manner.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16402v1" target="_blank">AetherCode: Evaluating LLMs Ability to Win In Premier Programming Competitions</a></h3>
                    <p><strong>Authors:</strong> Zihan Wang, Jiaze Chen, Zhicheng Liu, Markus Mak, Yidi Du, Geonsik Moon, Luoqi Xu, Aaron Tua, Kunshuo Peng, Jiayi Lu, Mingfei Xia, Boqian Zou, Chenyang Ran, Guang Tian, Shoutai Zhu, Yeheng Duan, Zhenghui Kang, Zhenxing Lin, Shangshu Li, Qiang Luo, Qingshen Long, Zhiyong Chen, Yihan Xiao, Yurong Wu, Daoguang Zan, Yuyi Fu, Mingxuan Wang, Ming Ding</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.CL</p>
                    <p><strong>Summary:</strong> Competitive programming has emerged as a critical benchmark for evaluating the reasoning and coding capabilities of Large Language Models (LLMs). Despite impressive progress on existing benchmarks, we argue that current evaluations overstate model proficiency, masking a substantial gap between LLMs and elite human programmers. This gap arises from two key limitations: insufficient difficulty and scope of benchmark problems, and evaluation bias from low-quality test cases. To address these shortcomings, we present AetherCode, a new benchmark that draws problems from premier programming competitions such as IOI and ICPC, offering broader coverage and higher difficulty. AetherCode further incorporates comprehensive, expert-validated test suites built through a hybrid of automated generation and human curation, ensuring rigorous and reliable assessment. By combining challenging problem design with robust evaluation, AetherCode provides a more faithful measure of LLM capabilities and sets a new standard for future research in code reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16390v1" target="_blank">RoMedQA: The First Benchmark for Romanian Medical Question Answering</a></h3>
                    <p><strong>Authors:</strong> Ana-Cristina Rogoz, Radu Tudor Ionescu, Alexandra-Valentina Anghel, Ionut-Lucian Antone-Iordache, Simona Coniac, Andreea Iuliana Ionescu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Question answering (QA) is an actively studied topic, being a core natural language processing (NLP) task that needs to be addressed before achieving Artificial General Intelligence (AGI). However, the lack of QA datasets in specific domains and languages hinders the development of robust AI models able to generalize across various domains and languages. To this end, we introduce RoMedQA, the first Romanian QA benchmark for the medical domain, alongside a comprehensive evaluation of state-of-the-art large language models (LLMs). We construct a high-quality and large-scale dataset comprising 102,646 QA pairs related to cancer patients. The questions regard medical case summaries of 1,011 patients, requiring either keyword extraction or reasoning to be answered correctly. RoMedQA is the result of a time-consuming manual annotation process carried out by seven physicians specialized in oncology or radiotherapy, who spent a total of about 2,100 work hours to generate the QA pairs. We experiment with four LLMs from distinct families of models on RoMedQA. Each model is employed in two scenarios, namely one based on zero-shot prompting and one based on supervised fine-tuning. Our results show that fine-tuned models significantly outperform their zero-shot counterparts, clearly indicating that pretrained models fail to generalize on RoMedQA. Our findings demonstrate the importance of both domain-specific and language-specific fine-tuning for reliable clinical QA in Romanian. We publicly release our dataset and code at https://github.com/ana-rogoz/RoMedQA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16379v1" target="_blank">Agentic AI Empowered Multi-UAV Trajectory Optimization in Low-Altitude Economy Networks</a></h3>
                    <p><strong>Authors:</strong> Feibo Jiang, Li Dong, Xitao Pan, Kezhi Wang, Cunhua Pan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> This paper proposes a novel Agentic Retrieval-augmented generation with Mamba-Attention Integrated Transformer (ARMAIT) framework for multi-Unmanned Aerial Vehicle (UAV) trajectory optimization. The framework is built upon Large Language Models (LLMs), incorporating Retrieval-Augmented Generation (RAG) empowered by Agentic AI and integrated with a UAV-specific knowledge base. Through the Agentic RAG, the LLM autonomously interprets high-level task requirements and identifies the key components necessary for trajectory optimization, including model inputs and outputs, network architecture, reward functions, and task constraints. To support efficient modeling across different system scales, we introduce the Mamba-Attention Integrated Transformer (MAIT), a hybrid neural architecture that combines the long-range dependency modeling capability of attention mechanisms with the efficient temporal dynamic representation of Mamba. Furthermore, a Trajectory-Group Relative Policy Optimization (T-GRPO) method is proposed to achieve unified policy gradient optimization in both discrete and continuous trajectory spaces for MAIT training. Extensive experimental results validate the feasibility and effectiveness of the proposed ARMAIT framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16377v1" target="_blank">Applications and Challenges of Fairness APIs in Machine Learning Software</a></h3>
                    <p><strong>Authors:</strong> Ajoy Das, Gias Uddin, Shaiful Chowdhury, Mostafijur Rahman Akhond, Hadi Hemmati</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.SE</p>
                    <p><strong>Summary:</strong> Machine Learning software systems are frequently used in our day-to-day lives. Some of these systems are used in various sensitive environments to make life-changing decisions. Therefore, it is crucial to ensure that these AI/ML systems do not make any discriminatory decisions for any specific groups or populations. In that vein, different bias detection and mitigation open-source software libraries (aka API libraries) are being developed and used. In this paper, we conduct a qualitative study to understand in what scenarios these open-source fairness APIs are used in the wild, how they are used, and what challenges the developers of these APIs face while developing and adopting these libraries. We have analyzed 204 GitHub repositories (from a list of 1885 candidate repositories) which used 13 APIs that are developed to address bias in ML software. We found that these APIs are used for two primary purposes (i.e., learning and solving real-world problems), targeting 17 unique use-cases. Our study suggests that developers are not well-versed in bias detection and mitigation; they face lots of troubleshooting issues, and frequently ask for opinions and resources. Our findings can be instrumental for future bias-related software engineering research, and for guiding educators in developing more state-of-the-art curricula.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16376v1" target="_blank">RIROS: A Parallel RTL Fault SImulation FRamework with TwO-Dimensional Parallelism and Unified Schedule</a></h3>
                    <p><strong>Authors:</strong> Jiaping Tang, Jianan Mu, Zizhen Liu, Ge Yu, Tenghui Hua, Bin Sun, Silin Liu, Jing Ye, Huawei Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> With the rapid development of safety-critical applications such as autonomous driving and embodied intelligence, the functional safety of the corresponding electronic chips becomes more critical. Ensuring chip functional safety requires performing a large number of time-consuming RTL fault simulations during the design phase, significantly increasing the verification cycle. To meet time-to-market demands while ensuring thorough chip verification, parallel acceleration of RTL fault simulation is necessary. Due to the dynamic nature of fault propagation paths and varying fault propagation capabilities, task loads in RTL fault simulation are highly imbalanced, making traditional singledimension parallel methods, such as structural-level parallelism, ineffective. Through an analysis of fault propagation paths and task loads, we identify two types of tasks in RTL fault simulation: tasks that are few in number but high in load, and tasks that are numerous but low in load. Based on this insight, we propose a two-dimensional parallel approach that combines structurallevel and fault-level parallelism to minimize bubbles in RTL fault simulation. Structural-level parallelism combining with workstealing mechanism is used to handle the numerous low-load tasks, while fault-level parallelism is applied to split the high-load tasks. Besides, we deviate from the traditional serial execution model of computation and global synchronization in RTL simulation by proposing a unified computation/global synchronization scheduling approach, which further eliminates bubbles. Finally, we implemented a parallel RTL fault simulation framework, RIROS. Experimental results show a performance improvement of 7.0 times and 11.0 times compared to the state-of-the-art RTL fault simulation and a commercial tool.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16352v1" target="_blank">Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management</a></h3>
                    <p><strong>Authors:</strong> Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AI, eess.SP</p>
                    <p><strong>Summary:</strong> Efficient and reliable beam alignment is a critical requirement for mmWave multiple-input multiple-output (MIMO) systems, especially in 6G and beyond, where communication must be fast, adaptive, and resilient to real-world uncertainties. Existing deep learning (DL)-based beam alignment methods often neglect the underlying causal relationships between inputs and outputs, leading to limited interpretability, poor generalization, and unnecessary beam sweeping overhead. In this work, we propose a causally-aware DL framework that integrates causal discovery into beam management pipeline. Particularly, we propose a novel two-stage causal beam selection algorithm to identify a minimal set of relevant inputs for beam prediction. First, causal discovery learns a Bayesian graph capturing dependencies between received power inputs and the optimal beam. Then, this graph guides causal feature selection for the DL-based classifier. Simulation results reveal that the proposed causal beam selection matches the performance of conventional methods while drastically reducing input selection time by 94.4% and beam sweeping overhead by 59.4% by focusing only on causally relevant features.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16347v1" target="_blank">Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs</a></h3>
                    <p><strong>Authors:</strong> Yu Yan, Sheng Sun, Zhe Wang, Yijun Lin, Zenghao Duan, zhifei zheng, Min Liu, Zhiyi yin, Jianping Zhang</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> With the development of Large Language Models (LLMs), numerous efforts have revealed their vulnerabilities to jailbreak attacks. Although these studies have driven the progress in LLMs safety alignment, it remains unclear whether LLMs have internalized authentic knowledge to deal with real-world crimes, or are merely forced to simulate toxic language patterns. This ambiguity raises concerns that jailbreak success is often attributable to a hallucination loop between jailbroken LLM and judger LLM. By decoupling the use of jailbreak techniques, we construct knowledge-intensive Q\A to investigate the misuse threats of LLMs in terms of dangerous knowledge possession, harmful task planning utility, and harmfulness judgment robustness. Experiments reveal a mismatch between jailbreak success rates and harmful knowledge possession in LLMs, and existing LLM-as-a-judge frameworks tend to anchor harmfulness judgments on toxic language patterns. Our study reveals a gap between existing LLM safety assessments and real-world threat potential.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16345v1" target="_blank">Uppaal Coshy: Automatic Synthesis of Compact Shields for Hybrid Systems</a></h3>
                    <p><strong>Authors:</strong> Asger Horn Brorholt, Andreas Holck HÃ¸eg-Petersen, Peter GjÃ¸l Jensen, Kim Guldstrand Larsen, Marius MikuÄionis, Christian Schilling, Andrzej WÄ…sowski</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> We present Uppaal Coshy, a tool for automatic synthesis of a safety strategy -- or shield -- for Markov decision processes over continuous state spaces and complex hybrid dynamics. The general methodology is to partition the state space and then solve a two-player safety game, which entails a number of algorithmically hard problems such as reachability for hybrid systems. The general philosophy of Uppaal Coshy is to approximate hard-to-obtain solutions using simulations. Our implementation is fully automatic and supports the expressive formalism of Uppaal models, which encompass stochastic hybrid automata. The precision of our partition-based approach benefits from using finer grids, which however are not efficient to store. We include an algorithm called Caap to efficiently compute a compact representation of a shield in the form of a decision tree, which yields significant reductions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16339v1" target="_blank">Observation of negative orbital torque from Vanadium</a></h3>
                    <p><strong>Authors:</strong> Nikhil Vijayan, Durgesh Kumar, Ao Du, Lei Gao, Zijie Xiao, Hai I. Wang, Rahul Gupta, Gerhard Jakob, Sachin Krishnia, Yuriy Mokrousov, Mathias KlÃ¤ui</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> We present systematic investigations of orbital torques generated from the light metal $V$, revealing a negative orbital torque. We observe that the damping-like torque (DLT) per unit electric field depends on the choice of the ferromagnetic layer, with approximately seven times higher torque efficiency in $Ni/V$ as compared to $Fe_{60}Co_{20}B_{20}/V$. We find the sign of DLT per unit electric field from $V$ is opposite to that from $Pt$. These results collectively confirm the existence of negative orbital Hall effect (OHE) in $V$. Furthermore, the DLT per unit electric field increases with the $V$ layer thickness, maintaining the negative sign at all thicknesses. We also note that the DLT per unit electric field exceeds that of the $Pt$ reference samples at higher $V$ thicknesses. Through fitting using the drift-diffusion equation, we extract a high effective orbital Hall conductivity of $-(1.46 \pm 0.09)\,\frac{\hbar}{2e}\,\times 10^{5}\,\Omega^{-1}\,\mathrm{m}^{-1}$ and a long orbital diffusion length of $(13.7 \pm 0.9)\,\mathrm{nm}$ in $V$. .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16325v1" target="_blank">LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts</a></h3>
                    <p><strong>Authors:</strong> Darpan Aswal, CÃ©line Hudelot</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.SC</p>
                    <p><strong>Summary:</strong> Large Language Models have found success in a variety of applications; however, their safety remains a matter of concern due to the existence of various types of jailbreaking methods. Despite significant efforts, alignment and safety fine-tuning only provide a certain degree of robustness against jailbreak attacks that covertly mislead LLMs towards the generation of harmful content. This leaves them prone to a number of vulnerabilities, ranging from targeted misuse to accidental profiling of users. This work introduces \textbf{LLMSymGuard}, a novel framework that leverages Sparse Autoencoders (SAEs) to identify interpretable concepts within LLM internals associated with different jailbreak themes. By extracting semantically meaningful internal representations, LLMSymGuard enables building symbolic, logical safety guardrails -- offering transparent and robust defenses without sacrificing model capabilities or requiring further fine-tuning. Leveraging advances in mechanistic interpretability of LLMs, our approach demonstrates that LLMs learn human-interpretable concepts from jailbreaks, and provides a foundation for designing more interpretable and logical safeguard measures against attackers. Code will be released upon publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16320v1" target="_blank">AI-Supported Mini-Labs: Combining Smartphone-Based Experiments and Multimodal AI</a></h3>
                    <p><strong>Authors:</strong> Jochen Kuhn, David J. Rakestraw, Stefan KÃ¼chemann, Patrik Vogt</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> This paper presents the concept of AI-supported Mini-Labs, combining smartphone-based experiments with multimodal large language models (MLLMs). Smartphones, with their integrated sensors and computational power, function as versatile mobile laboratories for physics education. While they enable the collection of rich experimental data, the analysis of complex everyday phenomena has often been limited in the classroom. Advances in MLLMs now allow learners to process multimodal data, text, images, audio, and video, and receive support in experiment design, data analysis, and scientific interpretation. Three case studies highlight the approach: determining a vehicle drag coefficient from accelerometer data, measuring the ionospheric reflection height from lightning-generated signals analyzed as audio spectrograms, and real-time spectroscopy of blood volume dynamics using smartphone video. The results show clear advantages over conventional methods, including time savings, high-quality visualizations, and individualized guidance. Beyond simplifying data analysis, AI-augmented pocket labs foster representational competence, critical thinking, and 21st-century skills. This hybrid approach offers a promising pathway for individualized and inquiry-based science education, though further studies are needed to assess long-term learning effects and potential risks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16316v1" target="_blank">QUEENS: An Open-Source Python Framework for Solver-Independent Analyses of Large-Scale Computational Models</a></h3>
                    <p><strong>Authors:</strong> Jonas Biehler, Jonas Nitzler, Sebastian BrandstÃ¤ter, Maximilian Dinkel, Volker Gravemeier, Lea J. HÃ¤usel, Gil Robalo Rei, Harald Willmann, Barbara Wirthl, Wolfgang A. Wall</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> A growing challenge in research and industrial engineering applications is the need for repeated, systematic analysis of large-scale computational models, for example, patient-specific digital twins of diseased human organs: The analysis requires efficient implementation, data, resource management, and parallelization, possibly on distributed systems. To tackle these challenges and save many researchers from annoying, time-consuming tasks, we present QUEENS (Quantification of Uncertain Effects in Engineering Systems), an open-source Python framework for composing and managing simulation analyses with arbitrary (physics-based) solvers on distributed computing infrastructures. Besides simulation management capabilities, QUEENS offers a comprehensive collection of efficiently implemented state-of-the-art algorithms ranging from routines for convergence studies and common optimization algorithms to more advanced sampling algorithms for uncertainty quantification and Bayesian inverse analysis. Additionally, we provide our latest cutting-edge research in multi-fidelity uncertainty quantification, efficient multi-fidelity Bayesian inverse analysis, and probabilistic machine learning. QUEENS adopts a Bayesian, probabilistic mindset but equally supports standard deterministic analysis without requiring prior knowledge of probability theory. The modular architecture allows rapid switching between common types of analyses and facilitates building sophisticated hierarchical algorithms. Encouraging natural incremental steps and scaling towards complexity allows researchers to consider the big picture while building towards it through smaller, manageable steps. The open-source repository is available at https://github.com/queens-py/queens.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16315v1" target="_blank">OwkinZero: Accelerating Biological Discovery with AI</a></h3>
                    <p><strong>Authors:</strong> Nathan Bigaud, Vincent Cabeli, Meltem Gurel, Arthur Pignet, John Klein, Gilles Wainrib, Eric Durand</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> While large language models (LLMs) are rapidly advancing scientific research, they continue to struggle with core biological reasoning tasks essential for translational and biomedical discovery. To address this limitation, we created and curated eight comprehensive benchmark datasets comprising over 300,000 verifiable question-and-answer pairs, each targeting critical challenges in drug discovery including target druggability, modality suitability, and drug perturbation effects. Using this resource, we developed the OwkinZero models by post-training open-source LLMs through a Reinforcement Learning from Verifiable Rewards strategy. Our results demonstrate that specialized 8-32B OwkinZero models substantially outperform larger, state-of-the-art commercial LLMs on these biological benchmarks. Remarkably, we uncover evidence of a key aspect of generalization: specialist models trained on a single task consistently outperform their base models on previously unseen tasks. This generalization effect is further amplified in our comprehensive OwkinZero models, which were trained on a mixture of datasets and achieve even broader cross-task improvements. This study represents a significant step toward addressing the biological reasoning blind spot in current LLMs, demonstrating that targeted reinforcement learning on carefully curated data can unlock generalizable performance in specialized models, thereby accelerating AI-driven biological discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16313v1" target="_blank">Retrieval Enhanced Feedback via In-context Neural Error-book</a></h3>
                    <p><strong>Authors:</strong> Jongyeop Hyun, Bumsoo Kim</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models (LLMs) have significantly improved reasoning capabilities, with in-context learning (ICL) emerging as a key technique for adaptation without retraining. While previous works have focused on leveraging correct examples, recent research highlights the importance of learning from errors to enhance performance. However, existing methods lack a structured framework for analyzing and mitigating errors, particularly in Multimodal Large Language Models (MLLMs), where integrating visual and textual inputs adds complexity. To address this issue, we propose REFINE: Retrieval-Enhanced Feedback via In-context Neural Error-book, a teacher-student framework that systematically structures errors and provides targeted feedback. REFINE introduces three systematic queries to construct structured feedback -- Feed-Target, Feed-Check, and Feed-Path -- to enhance multimodal reasoning by prioritizing relevant visual information, diagnosing critical failure points, and formulating corrective actions. Unlike prior approaches that rely on redundant retrievals, REFINE optimizes structured feedback retrieval, improving inference efficiency, token usage, and scalability. Our results demonstrate substantial speedup, reduced computational costs, and successful generalization, highlighting REFINEs potential for enhancing multimodal reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16297v1" target="_blank">Hybrid Classical-Quantum Supercomputing: A demonstration of a multi-user, multi-QPU and multi-GPU environment</a></h3>
                    <p><strong>Authors:</strong> Mateusz Slysz, Piotr Rydlichowski, Krzysztof Kurowski, Omar Bacarezza, Esperanza Cuenca Gomez, Zohim Chandani, Bettina Heim, Pradnya Khalate, William R. Clements, James Fletcher</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.DC, cs.ET</p>
                    <p><strong>Summary:</strong> Achieving a practical quantum advantage for near-term applications is widely expected to rely on hybrid classical-quantum algorithms. To deliver this practical advantage to users, high performance computing (HPC) centers need to provide a suitable software and hardware stack that supports algorithms of this type. In this paper, we describe the worlds first implementation of a classical-quantum environment in an HPC center that allows multiple users to execute hybrid algorithms on multiple quantum processing units (QPUs) and GPUs. Our setup at the Poznan Supercomputing and Networking Center (PCSS) aligns with current HPC norms: the computing hardware including QPUs is installed in an active data center room with standard facilities; there are no special considerations for networking, power, and cooling; we use Slurm for workload management as well as the NVIDIA CUDA-Q extension API for classical-quantum interactions. We demonstrate applications of this environment for hybrid classical-quantum machine learning and optimisation. The aim of this work is to provide the community with an experimental example for further research and development on how quantum computing can practically enhance and extend HPC capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16295v1" target="_blank">Enhanced Hybrid Technique for Efficient Digitization of Handwritten Marksheets</a></h3>
                    <p><strong>Authors:</strong> Junaid Ahmed Sifat, Abir Chowdhury, Hasnat Md. Imtiaz, Md. Irtiza Hossain, Md. Imran Bin Azad</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The digitization of handwritten marksheets presents huge challenges due to the different styles of handwriting and complex table structures in such documents like marksheets. This work introduces a hybrid method that integrates OpenCV for table detection and PaddleOCR for recognizing sequential handwritten text. The image processing capabilities of OpenCV efficiently detects rows and columns which enable computationally lightweight and accurate table detection. Additionally, YOLOv8 and Modified YOLOv8 are implemented for handwritten text recognition within the detected table structures alongside PaddleOCR which further enhance the systems versatility. The proposed model achieves high accuracy on our custom dataset which is designed to represent different and diverse handwriting styles and complex table layouts. Experimental results demonstrate that YOLOv8 Modified achieves an accuracy of 92.72 percent, outperforming PaddleOCR 91.37 percent and the YOLOv8 model 88.91 percent. This efficiency reduces the necessity for manual work which makes this a practical and fast solution for digitizing academic as well as administrative documents. This research serves the field of document automation, particularly handwritten document understanding, by providing operational and reliable methods to scale, enhance, and integrate the technologies involved.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16284v1" target="_blank">EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents</a></h3>
                    <p><strong>Authors:</strong> Anjith George, Sebastien Marcel</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The widespread availability of tools for manipulating images and documents has made it increasingly easy to forge digital documents, posing a serious threat to Know Your Customer (KYC) processes and remote onboarding systems. Detecting such forgeries is essential to preserving the integrity and security of these services. In this work, we present EdgeDoc, a novel approach for the detection and localization of document forgeries. Our architecture combines a lightweight convolutional transformer with auxiliary noiseprint features extracted from the images, enhancing its ability to detect subtle manipulations. EdgeDoc achieved third place in the ICCV 2025 DeepID Challenge, demonstrating its competitiveness. Experimental results on the FantasyID dataset show that our method outperforms baseline approaches, highlighting its effectiveness in realworld scenarios. Project page : https://www.idiap. ch/paper/edgedoc/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16277v1" target="_blank">The next question after Turings question: Introducing the Grow-AI test</a></h3>
                    <p><strong>Authors:</strong> Alexandru Tugui</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, 68T01, 68T05, 68T42, 91A80, I.2; K.4</p>
                    <p><strong>Summary:</strong> This study aims to extend the framework for assessing artificial intelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom), designed to answer the question Can machines grow up? -- a natural successor to the Turing Test. The methodology applied is based on a system of six primary criteria (C1-C6), each assessed through a specific game, divided into four arenas that explore both the human dimension and its transposition into AI. All decisions and actions of the entity are recorded in a standardized AI Journal, the primary source for calculating composite scores. The assessment uses the prior expert method to establish initial weights, and the global score -- Grow Up Index -- is calculated as the arithmetic mean of the six scores, with interpretation on maturity thresholds. The results show that the methodology allows for a coherent and comparable assessment of the level of growth of AI entities, regardless of their type (robots, software agents, LLMs). The multi-game structure highlights strengths and vulnerable areas, and the use of a unified journal guarantees traceability and replicability in the evaluation. The originality of the work lies in the conceptual transposition of the process of growing from the human world to that of artificial intelligence, in an integrated testing format that combines perspectives from psychology, robotics, computer science, and ethics. Through this approach, GROW-AI not only measures performance but also captures the evolutionary path of an AI entity towards maturity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16276v1" target="_blank">Implicit reporting standards in bibliometric research: what can reviewers comments tell us about reporting completeness?</a></h3>
                    <p><strong>Authors:</strong> Dimity Stephen, Alexander Schniedermann, Andrey Lovakov, Marion Schmidt, Matteo Ottaviani, Nikita Sorgatz, Roberto Cruz Romero, Torger MÃ¶ller, Valeria Aman, Stephan Stahlschmidt</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.DL</p>
                    <p><strong>Summary:</strong> The recent surge in bibliometric studies published has been accompanied by increasing diversity in the completeness of reporting these studies details, affecting reliability, reproducibility, and robustness. Our study systematises the reporting of bibliometric research using open peer reviews. We examined 182 peer reviews of 85 bibliometric studies published in library and information science (LIS) journals and conference proceedings, and non-LIS journals. We extracted 968 reviewer comments and inductively classified them into 11 broad thematic categories and 68 sub-categories, determining that reviewers largely focus on the completeness and clarity of reporting data, methods, and results. We subsequently derived 49 recommendations for the details authors should report and compared them with the GLOBAL, PRIBA, and BIBLIO reporting guidelines to identify (dis)similarities in content. Our recommendations addressed 60-80% of the guidelines items, while the guidelines covered 45-65% of our recommendations. Our recommendations provided greater range and specificity, but did not incorporate the functions of guidelines beyond addressing academic content. We argue that peer reviews provide valuable information for the development of future guidelines. Further, our recommendations can be read as the implicit community standards for reporting bibliometric studies and could be used by authors to aid complete and accurate reporting of their manuscripts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16273v1" target="_blank">A Systematic Mapping Study on Smart Cities Modeling Approaches</a></h3>
                    <p><strong>Authors:</strong> Maria Teresa Rossi, Martina De Sanctis, Ludovico Iovino, Manuel Wimmer</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> The Smart City concept was introduced to define an idealized city characterized by automation and connection. It then evolved rapidly by including further aspects, such as economy, environment. Since then, many publications have explored various aspects of Smart Cities across different application domains and research communities, acknowledging the interdisciplinary nature of this subject. In particular, our interest focuses on how smart cities are designed and modeled, as a whole or as regards with their subsystems, when dealing with the accomplishment of the research goals in this complex and heterogeneous domain. To this aim, we performed a systematic mapping study on smart cities modeling approaches identifying the relevant contributions (i) to get an overview of existing research approaches, (ii) to identify whether there are any publication trends, and (iii) to identify possible future research directions. We followed the guidelines for conducting systematic mapping studies by Petersen et al. to analyze smart cities modeling publications. Our analysis revealed the following main findings: (i) smart governance is the most investigated and modeled smart city dimension; (ii) the most used modeling approaches are business, architectural, and ontological modeling approaches, spanning multiple application fields; (iii) the great majority of existing technologies for modeling smart cities are not yet proven in operational environments; (iv) diverse research communities publish their results in a multitude of different venues which further motivates the presented literature study. Researchers can use our results for better understanding the state-of-the-art in modeling smart cities, and as a foundation for further analysis of specific approaches about smart cities modeling. Lastly, we also discuss the impact of our analysis for the Model-Driven Engineering community.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/TGRS.2025.3600249" target="_blank">IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization</a></h3>
                    <p><strong>Authors:</strong> Yu Meng, Ligao Deng, Zhihao Xi, Jiansheng Chen, Jingbo Chen, Anzhi Yue, Diyou Liu, Kai Li, Chenhao Wang, Kaiyu Li, Yupeng Deng, Xian Sun</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the enhancement of remote sensing image resolution and the rapid advancement of deep learning, land cover mapping is transitioning from pixel-level segmentation to object-based vector modeling. This shift demands more from deep learning models, requiring precise object boundaries and topological consistency. However, existing datasets face three main challenges: limited class annotations, small data scale, and lack of spatial structural information. To overcome these issues, we introduce IRSAMap, the first global remote sensing dataset for large-scale, high-resolution, multi-feature land cover vector mapping. IRSAMap offers four key advantages: 1) a comprehensive vector annotation system with over 1.8 million instances of 10 typical objects (e.g., buildings, roads, rivers), ensuring semantic and spatial accuracy; 2) an intelligent annotation workflow combining manual and AI-based methods to improve efficiency and consistency; 3) global coverage across 79 regions in six continents, totaling over 1,000 km; and 4) multi-task adaptability for tasks like pixel-level classification, building outline extraction, road centerline extraction, and panoramic segmentation. IRSAMap provides a standardized benchmark for the shift from pixel-based to object-based approaches, advancing geographic feature automation and collaborative modeling. It is valuable for global geographic information updates and digital twin construction. The dataset is publicly available at https://github.com/ucas-dlg/IRSAMap</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16268v1" target="_blank">Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication</a></h3>
                    <p><strong>Authors:</strong> Rob Carson, Mohamed Chahine Ghanem, Feriel Bouakkaz</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.DC</p>
                    <p><strong>Summary:</strong> This Paper proposes a self-healing, automated network of Raspberry Pi devices designed for deployment in scenarios where traditional networking is unavailable. Leveraging the low-power, long-range capabilities of the LoRa (Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the research addresses challenges such as limited bandwidth, data collisions, and node failures. Given that LoRas packet-based system is incompatible with conventional IaC tools like Ansible and Terraform, which rely on TCP/IP networking, the research adapts IaC principles within a containerised architecture deployed across a Raspberry Pi cluster. Evaluation experiments indicate that fragmenting data packets and retransmitting any missed fragments can mitigate LoRas inherent throughput and packet size limitations, although issues such as collisions and line-of-sight interference persist. An automated failover mechanism was integrated into the architecture, enabling unresponsive services to be redeployed to alternative nodes within one second, demonstrating the systems resilience in maintaining operational continuity despite node or service failures. The paper also identifies practical challenges, including the necessity for time-slotting transmissions to prevent data packet overlap and collisions. Future research should explore the integration of mesh networking to enhance range, develop more advanced scheduling algorithms, and adopt cutting-edge low-power wide-area network (LPWAN) techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16265v1" target="_blank">M3TQA: Massively Multilingual Multitask Table Question Answering</a></h3>
                    <p><strong>Authors:</strong> Daixin Shu, Jian Yang, Zhenhe Wu, Xianjie Wu, Xianfu Cheng, Xiangyuan Guan, Yanghai Wang, Pengfei Wu, Tingyang Yang, Hualei Zhu, Wei Zhang, Ge Zhang, Jiaheng Liu, Zhoujun Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Tabular data is a fundamental component of real-world information systems, yet most research in table understanding remains confined to English, leaving multilingual comprehension significantly underexplored. Existing multilingual table benchmarks suffer from geolinguistic imbalance - overrepresenting certain languages and lacking sufficient scale for rigorous cross-lingual analysis. To address these limitations, we introduce a comprehensive framework for massively multilingual multitask table question answering, featuring m3TQA-Instruct, a large-scale benchmark spanning 97 languages across diverse language families, including underrepresented and low-resource languages. We construct m3TQA by curating 50 real-world tables in Chinese and English, then applying a robust six-step LLM-based translation pipeline powered by DeepSeek and GPT-4o, achieving high translation fidelity with a median BLEU score of 60.19 as validated through back-translation. The benchmark includes 2,916 professionally annotated question-answering pairs across four tasks designed to evaluate nuanced table reasoning capabilities. Experiments on state-of-the-art LLMs reveal critical insights into cross-lingual generalization, demonstrating that synthetically generated, unannotated QA data can significantly boost performance, particularly for low-resource languages. M3T-Bench establishes a new standard for multilingual table understanding, providing both a challenging evaluation platform and a scalable methodology for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16263v1" target="_blank">Attribute Filtering in Approximate Nearest Neighbor Search: An In-depth Experimental Study</a></h3>
                    <p><strong>Authors:</strong> Mocheng Li, Xiao Yan, Baotong Lu, Yue Zhang, James Cheng, Chenhao Ma</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.DB, cs.IR</p>
                    <p><strong>Summary:</strong> With the growing integration of structured and unstructured data, new methods have emerged for performing similarity searches on vectors while honoring structured attribute constraints, i.e., a process known as Filtering Approximate Nearest Neighbor (Filtering ANN) search. Since many of these algorithms have only appeared in recent years and are designed to work with a variety of base indexing methods and filtering strategies, there is a pressing need for a unified analysis that identifies their core techniques and enables meaningful comparisons. In this work, we present a unified Filtering ANN search interface that encompasses the latest algorithms and evaluate them extensively from multiple perspectives. First, we propose a comprehensive taxonomy of existing Filtering ANN algorithms based on attribute types and filtering strategies. Next, we analyze their key components, i.e., index structures, pruning strategies, and entry point selection, to elucidate design differences and tradeoffs. We then conduct a broad experimental evaluation on 10 algorithms and 12 methods across 4 datasets (each with up to 10 million items), incorporating both synthetic and real attributes and covering selectivity levels from 0.1% to 100%. Finally, an in-depth component analysis reveals the influence of pruning, entry point selection, and edge filtering costs on overall performance. Based on our findings, we summarize the strengths and limitations of each approach, provide practical guidelines for selecting appropriate methods, and suggest promising directions for future research. Our code is available at: https://github.com/lmccccc/FANNBench.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16261v1" target="_blank">On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View</a></h3>
                    <p><strong>Authors:</strong> Tao Guo, Junxiao Wang, Fushuo Huo, Laizhong Cui, Song Guo, Jie Gui, Dacheng Tao</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Federated Learning (FL) enables training models across decentralized data silos while preserving client data privacy. Recent research has explored efficient methods for post-training large language models (LLMs) within FL to address computational and communication challenges. While existing approaches often rely on access to LLMs internal information, which is frequently restricted in real-world scenarios, an inference-only paradigm (black-box FedLLM) has emerged to address these limitations. This paper presents a comprehensive survey on federated tuning for LLMs. We propose a taxonomy categorizing existing studies along two axes: model access-based and parameter efficiency-based optimization. We classify FedLLM approaches into white-box, gray-box, and black-box techniques, highlighting representative methods within each category. We review emerging research treating LLMs as black-box inference APIs and discuss promising directions and open challenges for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16254v1" target="_blank">FEST: A Unified Framework for Evaluating Synthetic Tabular Data</a></h3>
                    <p><strong>Authors:</strong> Weijie Niu, Alberto Huertas Celdran, Karoline Siarsky, Burkhard Stiller</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Synthetic data generation, leveraging generative machine learning techniques, offers a promising approach to mitigating privacy concerns associated with real-world data usage. Synthetic data closely resembles real-world data while maintaining strong privacy guarantees. However, a comprehensive assessment framework is still missing in the evaluation of synthetic data generation, especially when considering the balance between privacy preservation and data utility in synthetic data. This research bridges this gap by proposing FEST, a systematic framework for evaluating synthetic tabular data. FEST integrates diverse privacy metrics (attack-based and distance-based), along with similarity and machine learning utility metrics, to provide a holistic assessment. We develop FEST as an open-source Python-based library and validate it on multiple datasets, demonstrating its effectiveness in analyzing the privacy-utility trade-off of different synthetic data generation models. The source code of FEST is available on Github.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16251v1" target="_blank">A QoE-Driven Personalized Incentive Mechanism Design for AIGC Services in Resource-Constrained Edge Networks</a></h3>
                    <p><strong>Authors:</strong> Hongjia Wu, Minrui Xu, Zehui Xiong, Lin Gao, Haoyuan Pan, Dusit Niyato, Tse-Tin Chan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.GT</p>
                    <p><strong>Summary:</strong> With rapid advancements in large language models (LLMs), AI-generated content (AIGC) has emerged as a key driver of technological innovation and economic transformation. Personalizing AIGC services to meet individual user demands is essential but challenging for AIGC service providers (ASPs) due to the subjective and complex demands of mobile users (MUs), as well as the computational and communication resource constraints faced by ASPs. To tackle these challenges, we first develop a novel multi-dimensional quality-of-experience (QoE) metric. This metric comprehensively evaluates AIGC services by integrating accuracy, token count, and timeliness. We focus on a mobile edge computing (MEC)-enabled AIGC network, consisting of multiple ASPs deploying differentiated AIGC models on edge servers and multiple MUs with heterogeneous QoE requirements requesting AIGC services from ASPs. To incentivize ASPs to provide personalized AIGC services under MEC resource constraints, we propose a QoE-driven incentive mechanism. We formulate the problem as an equilibrium problem with equilibrium constraints (EPEC), where MUs as leaders determine rewards, while ASPs as followers optimize resource allocation. To solve this, we develop a dual-perturbation reward optimization algorithm, reducing the implementation complexity of adaptive pricing. Experimental results demonstrate that our proposed mechanism achieves a reduction of approximately $64.9\%$ in average computational and communication overhead, while the average service cost for MUs and the resource consumption of ASPs decrease by $66.5\%$ and $76.8\%$, respectively, compared to state-of-the-art benchmarks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16227v1" target="_blank">UMATO: Bridging Local and Global Structures for Reliable Visual Analytics with Dimensionality Reduction</a></h3>
                    <p><strong>Authors:</strong> Hyeon Jeon, Kwon Ko, Soohyun Lee, Jake Hyun, Taehyun Yang, Gyehun Go, Jaemin Jo, Jinwook Seo</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Due to the intrinsic complexity of high-dimensional (HD) data, dimensionality reduction (DR) techniques cannot preserve all the structural characteristics of the original data. Therefore, DR techniques focus on preserving either local neighborhood structures (local techniques) or global structures such as pairwise distances between points (global techniques). However, both approaches can mislead analysts to erroneous conclusions about the overall arrangement of manifolds in HD data. For example, local techniques may exaggerate the compactness of individual manifolds, while global techniques may fail to separate clusters that are well-separated in the original space. In this research, we provide a deeper insight into Uniform Manifold Approximation with Two-phase Optimization (UMATO), a DR technique that addresses this problem by effectively capturing local and global structures. UMATO achieves this by dividing the optimization process of UMAP into two phases. In the first phase, it constructs a skeletal layout using representative points, and in the second phase, it projects the remaining points while preserving the regional characteristics. Quantitative experiments validate that UMATO outperforms widely used DR techniques, including UMAP, in terms of global structure preservation, with a slight loss in local structure. We also confirm that UMATO outperforms baseline techniques in terms of scalability and stability against initialization and subsampling, making it more effective for reliable HD data analysis. Finally, we present a case study and a qualitative demonstration that highlight UMATOs effectiveness in generating faithful projections, enhancing the overall reliability of visual analytics using DR.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16220v1" target="_blank">Generating Cylindrical Vector Î³ Rays via Beam-Target Interactions: Towards Structured Light at High Energies</a></h3>
                    <p><strong>Authors:</strong> Yue Cao, Kun Xue, Si-Man Liu, Zhong-Peng Li, Li-Xiang Hu, Xin-Yu Liu, Zhen-Ke Dou, Feng Wan, Qian Zhao, Tong-Pu Yu, Jian-Xing Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.optics, physics.plasm-ph</p>
                    <p><strong>Summary:</strong> Structured {\gamma} rays, particularly cylindrical vector {\gamma} rays, offer promising tools for sub-nuclear imaging and polarization-sensitive probes in fundamental research and applications, but conventional optical methods face great challenges at such photon energy. Here, we put forward a novel method generating such {\gamma} rays through relativistic beam-target interactions. For instance, radially polarized {\gamma} rays can be generated by using a dense electron beam striking a multifoil target. We find that the radial polarization is transferred from the generated coherent transition radiation (CTR) fields to $\gamma$ photons through nonlinear Compton scattering, with the high polarization preserved by phase matching. Three-dimensional spin-resolved simulations demonstrate radial polarization degrees approaching 60\%. Furthermore, these {\gamma} rays can decay into azimuthally spin-polarized positrons via the nonlinear Breit-Wheeler process, with their spins aligning along the CTR magnetic field. Our work extends the concept of structured light into the {\gamma}-ray regime, offering new prospects for broad fields such as nuclear structure probing, fundamental symmetries tests, polarization-sensitive studies in extreme conditions, and laboratory astrophysical observations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16213v1" target="_blank">MedOmni-45Â°: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine</a></h3>
                    <p><strong>Authors:</strong> Kaiyuan Ji, Yijin Guo, Zicheng Zhang, Xiangyang Zhu, Yuan Tian, Ning Liu, Guangtao Zhai</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the increasing use of large language models (LLMs) in medical decision-support, it is essential to evaluate not only their final answers but also the reliability of their reasoning. Two key risks are Chain-of-Thought (CoT) faithfulness -- whether reasoning aligns with responses and medical facts -- and sycophancy, where models follow misleading cues over correctness. Existing benchmarks often collapse such vulnerabilities into single accuracy scores. To address this, we introduce MedOmni-45 Degrees, a benchmark and workflow designed to quantify safety-performance trade-offs under manipulative hint conditions. It contains 1,804 reasoning-focused medical questions across six specialties and three task types, including 500 from MedMCQA. Each question is paired with seven manipulative hint types and a no-hint baseline, producing about 27K inputs. We evaluate seven LLMs spanning open- vs. closed-source, general-purpose vs. medical, and base vs. reasoning-enhanced models, totaling over 189K inferences. Three metrics -- Accuracy, CoT-Faithfulness, and Anti-Sycophancy -- are combined into a composite score visualized with a 45 Degrees plot. Results show a consistent safety-performance trade-off, with no model surpassing the diagonal. The open-source QwQ-32B performs closest (43.81 Degrees), balancing safety and accuracy but not leading in both. MedOmni-45 Degrees thus provides a focused benchmark for exposing reasoning vulnerabilities in medical LLMs and guiding safer model development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16207v1" target="_blank">\textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring</a></h3>
                    <p><strong>Authors:</strong> Thinesh Thiyakesan Ponbagavathi, Kunyu Peng, Alina Roitberg</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Changes of camera perspective are a common obstacle in driver monitoring. While deep learning and pretrained foundation models show strong potential for improved generalization via lightweight adaptation of the final layers (probing), their robustness to unseen viewpoints remains underexplored. We study this challenge by adapting image foundation models to driver monitoring using a single training view, and evaluating them directly on unseen perspectives without further adaptation. We benchmark simple linear probes, advanced probing strategies, and compare two foundation models (DINOv2 and CLIP) against parameter-efficient fine-tuning (PEFT) and full fine-tuning. Building on these insights, we introduce \textsc{T-Mask} -- a new image-to-video probing method that leverages temporal token masking and emphasizes more dynamic video regions. Benchmarked on the public Drive\Act dataset, \textsc{T-Mask} improves cross-view top-1 accuracy by $+1.23\%$ over strong probing baselines and $+8.0\%$ over PEFT methods, without adding any parameters. It proves particularly effective for underrepresented secondary activities, boosting recognition by $+5.42\%$ under the trained view and $+1.36\%$ under cross-view settings. This work provides encouraging evidence that adapting foundation models with lightweight probing methods like \textsc{T-Mask} has strong potential in fine-grained driver observation, especially in cross-view and low-data settings. These results highlight the importance of temporal token selection when leveraging foundation models to build robust driver monitoring systems. Code and models will be made available at https://github.com/th-nesh/T-MASK to support ongoing research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16202v1" target="_blank">How to Beat Nakamoto in the Race</a></h3>
                    <p><strong>Authors:</strong> Shu-Jie Cao, Dongning Guo</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> This paper studies proof-of-work Nakamoto consensus under bounded network delays, settling two long-standing questions in blockchain security: How can an adversary most effectively attack block safety under a given block confirmation latency? And what is the resulting probability of safety violation? A Markov decision process (MDP) framework is introduced to precise characterize the system state (including the tree and timings of all blocks mined), the adversarys potential actions, and the state transitions due to the adversarial action and the random block arrival processes. An optimal attack, called bait-and-switch, is proposed and proved to maximize the adversarys chance of violating block safety by beating Nakamoto in the race. The exact probability of this violation is calculated for any confirmation depth using Markov chain analysis, offering fresh insights into the interplay of network delay, confirmation rules, and blockchain security.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16198v1" target="_blank">CMR-SPB: Cross-Modal Multi-Hop Reasoning over Text, Image, and Speech with Path Balance</a></h3>
                    <p><strong>Authors:</strong> Seunghee Kim, Ingyu Bang, Seokgyu Jang, Changhyeon Kim, Sanghwan Bae, Jihun Choi, Richeng Xuan, Taeuk Kim</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Cross-modal multi-hop reasoning (CMR) is a valuable yet underexplored capability of multimodal large language models (MLLMs), entailing the integration of information from multiple modalities to produce a coherent output for a given context. We argue that existing benchmarks for evaluating this ability have critical shortcomings: (1) they largely overlook the speech modality, and (2) they exhibit heavily biased reasoning path distributions, which can severely undermine fair evaluation. To address these limitations, we introduce a novel benchmark -- Cross-Modal Multi-Hop Reasoning over Text, Image and Speech with Path Balance (CMR-SPB) -- designed to assess tri-modal multi-hop reasoning while ensuring both unbiased and diverse reasoning paths. Our experiments with the new dataset reveal consistent model failures in specific reasoning sequences and show that biased benchmarks risk misrepresenting model performance. Finally, based on our extensive analysis, we propose a new ECV (Extract, Connect, Verify) prompting technique that effectively mitigates the performance gap across different reasoning paths. Overall, we call for more careful evaluation in CMR to advance the development of robust multimodal AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16576v1" target="_blank">Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet</a></h3>
                    <p><strong>Authors:</strong> Anyu Ying, Natarajan Balaji Shankar, Chyi-Jiunn Lin, Mohan Shi, Pu Wang, Hye-jin Shim, Siddhant Arora, Hugo Van hamme, Abeer Alwan, Shinji Watanabe</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite advancements in ASR, child speech recognition remains challenging due to acoustic variability and limited annotated data. While fine-tuning adult ASR models on child speech is common, comparisons with flat-start training remain underexplored. We compare flat-start training across multiple datasets, SSL representations (WavLM, XEUS), and decoder architectures. Our results show that SSL representations are biased toward adult speech, with flat-start training on child speech mitigating these biases. We also analyze model scaling, finding consistent improvements up to 1B parameters, beyond which performance plateaus. Additionally, age-related ASR and speaker verification analysis highlights the limitations of proprietary models like Whisper, emphasizing the need for open-data models for reliable child speech research. All investigations are conducted using ESPnet, and our publicly available benchmark provides insights into training strategies for robust child speech processing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16571v1" target="_blank">LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence</a></h3>
                    <p><strong>Authors:</strong> Alisa Vinogradova, Vlad Vinogradov, Dmitrii Radkevich, Ilya Yasny, Dmitry Kobyzev, Ivan Izmailov, Katsiaryna Yanchanka, Andrey Doronichev</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.IR, cs.MA</p>
                    <p><strong>Summary:</strong> In this paper, we describe and benchmark a competitor-discovery component used within an agentic AI system for fast drug asset due diligence. A competitor-discovery AI agent, given an indication, retrieves all drugs comprising the competitive landscape of that indication and extracts canonical attributes for these drugs. The competitor definition is investor-specific, and data is paywalled/licensed, fragmented across registries, ontology-mismatched by indication, alias-heavy for drug names, multimodal, and rapidly changing. Although considered the best tool for this problem, the current LLM-based AI systems arent capable of reliably retrieving all competing drug names, and there is no accepted public benchmark for this task. To address the lack of evaluation, we use LLM-based agents to transform five years of multi-modal, unstructured diligence memos from a private biotech VC fund into a structured evaluation corpus mapping indications to competitor drugs with normalized attributes. We also introduce a competitor validating LLM-as-a-judge agent that filters out false positives from the list of predicted competitors to maximize precision and suppress hallucinations. On this benchmark, our competitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research (65%) and Perplexity Labs (60%). The system is deployed in production with enterprise users; in a case study with a biotech VC investment fund, analyst turnaround time dropped from 2.5 days to $\sim$3 hours ($\sim$20x) for the competitive analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16569v1" target="_blank">A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer</a></h3>
                    <p><strong>Authors:</strong> Yuhui Tao, Zhongwei Zhao, Zilong Wang, Xufang Luo, Feng Chen, Kang Wang, Chuanfu Wu, Xue Zhang, Shaoting Zhang, Jiaxi Yao, Xingwei Jin, Xinyang Jiang, Yifan Yang, Dongsheng Li, Lili Qiu, Zhiqiang Shao, Jianming Guo, Nengwang Yu, Shuo Wang, Ying Xiong</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The non-invasive assessment of increasingly incidentally discovered renal masses is a critical challenge in urologic oncology, where diagnostic uncertainty frequently leads to the overtreatment of benign or indolent tumors. In this study, we developed and validated RenalCLIP using a dataset of 27,866 CT scans from 8,809 patients across nine Chinese medical centers and the public TCIA cohort, a visual-language foundation model for characterization, diagnosis and prognosis of renal mass. The model was developed via a two-stage pre-training strategy that first enhances the image and text encoders with domain-specific knowledge before aligning them through a contrastive learning objective, to create robust representations for superior generalization and diagnostic precision. RenalCLIP achieved better performance and superior generalizability across 10 core tasks spanning the full clinical workflow of kidney cancer, including anatomical assessment, diagnostic classification, and survival prediction, compared with other state-of-the-art general-purpose CT foundation models. Especially, for complicated task like recurrence-free survival prediction in the TCIA cohort, RenalCLIP achieved a C-index of 0.726, representing a substantial improvement of approximately 20% over the leading baselines. Furthermore, RenalCLIPs pre-training imparted remarkable data efficiency; in the diagnostic classification task, it only needs 20% training data to achieve the peak performance of all baseline models even after they were fully fine-tuned on 100% of the data. Additionally, it achieved superior performance in report generation, image-text retrieval and zero-shot diagnosis tasks. Our findings establish that RenalCLIP provides a robust tool with the potential to enhance diagnostic accuracy, refine prognostic stratification, and personalize the management of patients with kidney cancer.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16568v1" target="_blank">Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation</a></h3>
                    <p><strong>Authors:</strong> Guangyu Sun, Jingtao Li, Weiming Zhuang, Chen Chen, Chen Chen, Lingjuan Lyu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> Foundation models (FMs) exhibit remarkable generalization but require adaptation to downstream tasks, particularly in privacy-sensitive applications. Due to data privacy regulations, cloud-based FMs cannot directly access private edge data, limiting their adaptation. Federated learning (FL) provides a privacy-aware alternative, but existing FL approaches overlook the constraints imposed by edge devices -- namely, limited computational resources and the scarcity of labeled data. To address these challenges, we introduce Practical Semi-Supervised Federated Learning (PSSFL), where edge devices hold only unlabeled, low-resolution data, while the server has limited labeled, high-resolution data. In this setting, we propose the Federated Mixture of Experts (FedMox), a novel framework that enhances FM adaptation in FL. FedMox tackles computational and resolution mismatch challenges via a sparse Mixture-of-Experts architecture, employing a spatial router to align features across resolutions and a Soft-Mixture strategy to stabilize semi-supervised learning. We take object detection as a case study, and experiments on real-world autonomous driving datasets demonstrate that FedMox effectively adapts FMs under PSSFL, significantly improving performance with constrained memory costs on edge devices. Our work paves the way for scalable and privacy-preserving FM adaptation in federated scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16557v1" target="_blank">Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution</a></h3>
                    <p><strong>Authors:</strong> Tainyi Zhang, Zheng-Peng Duan, Peng-Tao Jiang, Bo Li, Ming-Ming Cheng, Chun-Le Guo, Chongyi Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Diffusion-based real-world image super-resolution (Real-ISR) methods have demonstrated impressive performance. To achieve efficient Real-ISR, many works employ Variational Score Distillation (VSD) to distill pre-trained stable-diffusion (SD) model for one-step SR with a fixed timestep. However, due to the different noise injection timesteps, the SD will perform different generative priors. Therefore, a fixed timestep is difficult for these methods to fully leverage the generative priors in SD, leading to suboptimal performance. To address this, we propose a Time-Aware one-step Diffusion Network for Real-ISR (TADSR). We first introduce a Time-Aware VAE Encoder, which projects the same image into different latent features based on timesteps. Through joint dynamic variation of timesteps and latent features, the student model can better align with the input pattern distribution of the pre-trained SD, thereby enabling more effective utilization of SDs generative capabilities. To better activate the generative prior of SD at different timesteps, we propose a Time-Aware VSD loss that bridges the timesteps of the student model and those of the teacher model, thereby producing more consistent generative prior guidance conditioned on timesteps. Additionally, though utilizing the generative prior in SD at different timesteps, our method can naturally achieve controllable trade-offs between fidelity and realism by changing the timestep condition. Experimental results demonstrate that our method achieves both state-of-the-art performance and controllable SR results with only a single step.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16552v1" target="_blank">Data Gluttony: Epistemic Risks, Dependent Testing and Data Reuse in Large Datasets</a></h3>
                    <p><strong>Authors:</strong> Reid Dale, Jordan Rodu, Maria E. Currie, Mike Baiocchi</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> math.ST, stat.ME, stat.TH</p>
                    <p><strong>Summary:</strong> Large-scale registries have collected vast amounts of data which has enabled investigators to efficiently conduct studies of observational data. Common practice is for investigators to use all data meeting the inclusion criteria of their study to perform their analysis. We term this common practice data gluttony. It has apparent formal justification insofar as this approach maximizes per-study power. But this comes at a cost: data reuse affects the shape of the tail distribution of inferential errors. Using the theory of risk orderings we demonstrate how positively dependent testing procedures result in strictly riskier distributions of inferential error. We identify two remedies to this state of affairs: research portfolio optimization and what we term data temperance. Research portfolio optimization requires that we formulate the enterprise of inference in a utility theoretic framework: associated to each hypothesis to be evaluated is some utility dependent on its truth as well as the impact of the statistical decision rendered on the basis of the data. Under certain models of data governance, this approach can be used to optimally allocate data usage across multiple inferential tasks. On the other hand, data temperance is a more flexible strategy for managing the distribution of inferential errors. Data temperance is the principle that an investigator use only as much data as is necessary to perform the task at hand. This is possible due to the diminishing marginal returns in power and precision in sample size. We analyze the effectiveness of data temperance at reducing the dependence across testing and develop a theory of the capacity of a static database to sustain large numbers of inferential tasks with low probability of inducing pairwise dependent testing procedures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16543v1" target="_blank">Explainable AI in Deep Learning-Based Prediction of Solar Storms</a></h3>
                    <p><strong>Authors:</strong> Adam O. Rawashdeh, Jason T. L. Wang, Katherine G. Herbert</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> A deep learning model is often considered a black-box model, as its internal workings tend to be opaque to the user. Because of the lack of transparency, it is challenging to understand the reasoning behind the models predictions. Here, we present an approach to making a deep learning-based solar storm prediction model interpretable, where solar storms include solar flares and coronal mass ejections (CMEs). This deep learning model, built based on a long short-term memory (LSTM) network with an attention mechanism, aims to predict whether an active region (AR) on the Suns surface that produces a flare within 24 hours will also produce a CME associated with the flare. The crux of our approach is to model data samples in an AR as time series and use the LSTM network to capture the temporal dynamics of the data samples. To make the models predictions accountable and reliable, we leverage post hoc model-agnostic techniques, which help elucidate the factors contributing to the predicted output for an input sequence and provide insights into the models behavior across multiple sequences within an AR. To our knowledge, this is the first time that interpretability has been added to an LSTM-based solar storm prediction model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16527v1" target="_blank">Towards Open World Detection: A Survey</a></h3>
                    <p><strong>Authors:</strong> Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, 68T45, A.1; I.2; I.4</p>
                    <p><strong>Summary:</strong> For decades, Computer Vision has aimed at enabling machines to perceive the external world. Initial limitations led to the development of highly specialized niches. As success in each task accrued and research progressed, increasingly complex perception tasks emerged. This survey charts the convergence of these tasks and, in doing so, introduces Open World Detection (OWD), an umbrella term we propose to unify class-agnostic and generally applicable detection models in the vision domain. We start from the history of foundational vision subdomains and cover key concepts, methodologies and datasets making up todays state-of-the-art landscape. This traverses topics starting from early saliency detection, foreground/background separation, out of distribution detection and leading up to open world object detection, zero-shot detection and Vision Large Language Models (VLLMs). We explore the overlap between these subdomains, their increasing convergence, and their potential to unify into a singular domain in the future, perception.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.telpol.2020.101960" target="_blank">Innovation ecosystems theory revisited: The case of artificial intelligence in China</a></h3>
                    <p><strong>Authors:</strong> Arenal Alberto, Armuna Cristina, Feijoo Claudio, Ramos Sergio, Xu Zimu, Moreno Ana Maria</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> econ.TH</p>
                    <p><strong>Summary:</strong> Beyond the mainstream discussion on the key role of China in the global AI landscape, the knowledge about the real performance and future perspectives of the AI ecosystem in China is still limited. This paper evaluates the status and prospects of Chinas AI innovation ecosystem by developing a Triple Helix framework particularized for this case. Based on an in-depth qualitative study and on interviews with experts, the analysis section summarizes the way in which the AI innovation ecosystem in China is being built, which are the key features of the three spheres of the Triple Helix -governments, industry and academic/research institutions-as well as the dynamic context of the ecosystem through the identification of main aspects related to the flows of skills, knowledge and funding and the interactions among them. Using this approach, the discussion section illustrates the specificities of the AI innovation ecosystem in China, its strengths and its gaps, and which are its prospects. Overall, this revisited ecosystem approach permits the authors to address the complexity of emerging environments of innovation to draw meaningful conclusions which are not possible with mere observation. The results show how a favourable context, the broad adoption rate and the competition for talent and capital among regional-specialized clusters are boosting the advance of AI in China, mainly in the business to customer arena. Finally, the paper highlights the challenges ahead in the current implementation of the ecosystem that will largely determine the potential global leadership of China in this domain.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16519v1" target="_blank">The Community Index: A More Comprehensive Approach to Assessing Scholarly Impact</a></h3>
                    <p><strong>Authors:</strong> Arav Kumar, Cameron Sabet, Alessandro Hammond, Amelia Fiske, Bhav Jain, Deirdre Goode, Dharaa Suresha, Leo Anthony Celi, Lisa Soleymani Lehmann, Ned Mccague, Rawan Abulibdeh, Sameer Pradhan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.DL, stat.CO</p>
                    <p><strong>Summary:</strong> The h index is a widely recognized metric for assessing the research impact of scholars, defined as the maximum value h such that the scholar has published h papers each cited at least h times. While it has proven useful measuring individual scholarly productivity and citation impact, the h index has limitations, such as an inability to account for interdisciplinary collaboration or demographic differences in citation patterns. Moreover, it is sometimes mistakenly treated as a measure of research quality, even though it only reflects how often work has been cited. While metric based evaluations of research have grown in importance in some areas of academia, such as medicine, these evaluations fail to consider other important aspects of intellectual work, such as representational and epistemic diversity in research. In this article, we propose a new metric called the c index, or the community index, which combines multiple dimensions of scholarly impact. This is important because a plurality of perspectives and lived experiences within author teams can promote epistemological reflection and humility as part of the creation and validation of scientific knowledge. The c index is a means of accounting for the often global, and increasingly interdisciplinary nature of contemporary research, in particular, the data that is collected, curated and analyzed in the process of scientific inquiry. While the c index provides a means of quantifying diversity within research teams, diversity is integral to the advancement of scientific excellence and should be actively fostered through formal recognition and valuation. We herein describe the mathematical foundation of the c index and demonstrate its potential to provide a more comprehensive representation and more multidimensional assessment of scientific contributions of research impact as compared to the h index.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16512v1" target="_blank">Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation</a></h3>
                    <p><strong>Authors:</strong> Chun-Peng Chang, Chen-Yu Wang, Julian Schmidt, Holger Caesar, Alain Pagani</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advancements in video generation have substantially improved visual quality and temporal coherence, making these models increasingly appealing for applications such as autonomous driving, particularly in the context of driving simulation and so-called world models. In this work, we investigate the effects of existing fine-tuning video generation approaches on structured driving datasets and uncover a potential trade-off: although visual fidelity improves, spatial accuracy in modeling dynamic elements may degrade. We attribute this degradation to a shift in the alignment between visual quality and dynamic understanding objectives. In datasets with diverse scene structures within temporal space, where objects or perspective shift in varied ways, these objectives tend to highly correlated. However, the very regular and repetitive nature of driving scenes allows visual quality to improve by modeling dominant scene motion patterns, without necessarily preserving fine-grained dynamic behavior. As a result, fine-tuning encourages the model to prioritize surface-level realism over dynamic accuracy. To further examine this phenomenon, we show that simple continual learning strategies, such as replay from diverse domains, can offer a balanced alternative by preserving spatial accuracy while maintaining strong visual quality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16508v1" target="_blank">Abmax: A JAX-based Agent-based Modeling Framework</a></h3>
                    <p><strong>Authors:</strong> Siddharth Chaturvedi, Ahmed El-Gazzar, Marcel van Gerven</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MA, cs.SE</p>
                    <p><strong>Summary:</strong> Agent-based modeling (ABM) is a principal approach for studying complex systems. By decomposing a system into simpler, interacting agents, agent-based modeling (ABM) allows researchers to observe the emergence of complex phenomena. High-performance array computing libraries like JAX can help scale such computational models to a large number of agents by using automatic vectorization and just-in-time (JIT) compilation. One of the caveats of using JAX to achieve such scaling is that the shapes of arrays used in the computational model should remain immutable throughout the simulation. In the context of agent-based modeling (ABM), this can pose constraints on certain agent manipulation operations that require flexible data structures. A subset of which is represented by the ability to update a dynamically selected number of agents by applying distinct changes to them during a simulation. To this effect, we introduce Abmax, an ABM framework based on JAX that implements multiple just-in-time (JIT) compilable algorithms to provide this functionality. On the canonical predation model benchmark, Abmax achieves runtime performance comparable to state-of-the-art implementations. Further, we show that this functionality can also be vectorized, making it possible to run many similar agent-based models in parallel. We also present two examples in the form of a traffic-flow model and a financial market model to show the use case of Abmax.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16488v1" target="_blank">SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being</a></h3>
                    <p><strong>Authors:</strong> Kayenat Fatmi, Mohammad Abbas</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> In the digital era, individuals are increasingly exposed to online harms such as toxicity, manipulation, and grooming, which often pose emotional and safety risks. Existing systems for detecting abusive content or issuing safety alerts operate in isolation and rarely combine digital safety with emotional well-being. In this paper, we present SafeSpace, a unified web application that integrates three modules: (1) toxicity detection in chats and screenshots using NLP models and Googles Perspective API, (2) a configurable safety ping system that issues emergency alerts with the users live location (longitude and latitude) via SMTP-based emails when check-ins are missed or SOS alerts are manually triggered, and (3) a reflective questionnaire that evaluates relationship health and emotional resilience. The system employs Firebase for alert management and a modular architecture designed for usability, privacy, and scalability. The experimental evaluation shows 93% precision in toxicity detection, 100% reliability in safety alerts under emulator tests, and 92% alignment between automated and manual questionnaire scoring. SafeSpace, implemented as a web application, demonstrates the feasibility of integrating detection, protection, and reflection within a single platform, with future deployment envisioned as a mobile application for broader accessibility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16484v1" target="_blank">HAMSA: Hijacking Aligned Compact Models via Stealthy Automation</a></h3>
                    <p><strong>Authors:</strong> Alexey Krylov, Iskander Vagizov, Dmitrii Korzh, Maryam Douiba, Azidine Guezzaz, Vladimir Kokh, Sergey D. Erokhin, Elena V. Tutubalina, Oleg Y. Rogov</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs), especially their compact efficiency-oriented variants, remain susceptible to jailbreak attacks that can elicit harmful outputs despite extensive alignment efforts. Existing adversarial prompt generation techniques often rely on manual engineering or rudimentary obfuscation, producing low-quality or incoherent text that is easily flagged by perplexity-based filters. We present an automated red-teaming framework that evolves semantically meaningful and stealthy jailbreak prompts for aligned compact LLMs. The approach employs a multi-stage evolutionary search, where candidate prompts are iteratively refined using a population-based strategy augmented with temperature-controlled variability to balance exploration and coherence preservation. This enables the systematic discovery of prompts capable of bypassing alignment safeguards while maintaining natural language fluency. We evaluate our method on benchmarks in English (In-The-Wild Jailbreak Prompts on LLMs), and a newly curated Arabic one derived from In-The-Wild Jailbreak Prompts on LLMs and annotated by native Arabic linguists, enabling multilingual assessment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16481v1" target="_blank">Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms</a></h3>
                    <p><strong>Authors:</strong> Jonathan NÃ¶ther, Adish Singla, Goran Radanovic</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Ensuring the safe use of agentic systems requires a thorough understanding of the range of malicious behaviors these systems may exhibit when under attack. In this paper, we evaluate the robustness of LLM-based agentic systems against attacks that aim to elicit harmful actions from agents. To this end, we propose a novel taxonomy of harms for agentic systems and a novel benchmark, BAD-ACTS, for studying the security of agentic systems with respect to a wide range of harmful actions. BAD-ACTS consists of 4 implementations of agentic systems in distinct application environments, as well as a dataset of 188 high-quality examples of harmful actions. This enables a comprehensive study of the robustness of agentic systems across a wide range of categories of harmful behaviors, available tools, and inter-agent communication structures. Using this benchmark, we analyze the robustness of agentic systems against an attacker that controls one of the agents in the system and aims to manipulate other agents to execute a harmful target action. Our results show that the attack has a high success rate, demonstrating that even a single adversarial agent within the system can have a significant impact on the security. This attack remains effective even when agents use a simple prompting-based defense strategy. However, we additionally propose a more effective defense based on message monitoring. We believe that this benchmark provides a diverse testbed for the security research of agentic systems. The benchmark can be found at github.com/JNoether/BAD-ACTS</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16479v1" target="_blank">Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization</a></h3>
                    <p><strong>Authors:</strong> Yupei Zhang, Xiaofei Wang, Anran Liu, Lequan Yu, Chao Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Histopathology remains the gold standard for cancer diagnosis and prognosis. With the advent of transcriptome profiling, multi-modal learning combining transcriptomics with histology offers more comprehensive information. However, existing multi-modal approaches are challenged by intrinsic multi-modal heterogeneity, insufficient multi-scale integration, and reliance on paired data, restricting clinical applicability. To address these challenges, we propose a disentangled multi-modal framework with four contributions: 1) To mitigate multi-modal heterogeneity, we decompose WSIs and transcriptomes into tumor and microenvironment subspaces using a disentangled multi-modal fusion module, and introduce a confidence-guided gradient coordination strategy to balance subspace optimization. 2) To enhance multi-scale integration, we propose an inter-magnification gene-expression consistency strategy that aligns transcriptomic signals across WSI magnifications. 3) To reduce dependency on paired data, we propose a subspace knowledge distillation strategy enabling transcriptome-agnostic inference through a WSI-only student model. 4) To improve inference efficiency, we propose an informative token aggregation module that suppresses WSI redundancy while preserving subspace semantics. Extensive experiments on cancer diagnosis, prognosis, and survival prediction demonstrate our superiority over state-of-the-art methods across multiple settings. Code is available at https://github.com/helenypzhang/Disentangled-Multimodal-Learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16457v1" target="_blank">Wide-Area Power System Oscillations from Large-Scale AI Workloads</a></h3>
                    <p><strong>Authors:</strong> Min-Seung Ko, Hao Zhu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> This paper develops a new dynamic power profiling approach for modeling AI-centric datacenter loads and analyzing their impact on grid operations, particularly their potential to induce wide-area grid oscillations. We characterize the periodic stochastic power fluctuations inherent to large-scale AI workloads during both the training and fine-tuning stages, driven by the state-of-the-art GPU computing architecture designs. These sustained, large power fluctuations, unlike conventional load ramping, act as persistent forcing inputs capable of interacting with and amplifying local and inter-area oscillation modes. Using the WECC 179-bus system as a test case, we examine the amplitude and variability of oscillatory responses under different factors, ranging from system strength, penetration level, fluctuation frequency range, individual datacenter size, to geographical deployment. Simulation results show that, notably, narrower fluctuation bands, larger single-site capacities, or dispersed siting can intensify oscillations across multiple modes. Our models and numerical studies provide a quantitative basis for integrating AI-dominant electricity demands into grid oscillation studies, and further support the development of new planning and operational measures to power the continuous AI load growth.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16456v1" target="_blank">A Probabilistic Inference Scaling Theory for LLM Self-Correction</a></h3>
                    <p><strong>Authors:</strong> Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have demonstrated the capability to refine their generated answers through self-correction, enabling continuous performance improvement over multiple rounds. However, the mechanisms underlying how and why accuracy evolves during this iterative process remain unexplored. To fill this gap, we propose a probabilistic theory to model the dynamics of accuracy change and explain the performance improvements observed in multi-round self-correction. Through mathematical derivation, we establish that the accuracy after the $t^{th}$ round of self-correction is given by: $Acc_t = Upp - \alpha^t(Upp - Acc_0),$ where $Acc_0$ denotes the initial accuracy, $Upp$ represents the upper bound of accuracy convergence, and $\alpha$ determines the rate of convergence. Based on our theory, these parameters can be calculated and the predicted accuracy curve then can be obtained through only a single round of self-correction. Extensive experiments across diverse models and datasets demonstrate that our theoretical predictions align closely with empirical accuracy curves, validating the effectiveness of the theory. Our work provides a theoretical foundation for understanding LLM self-correction, thus paving the way for further explorations.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3718958.3750526" target="_blank">Towards User-level QoE: Large-scale Practice in Personalized Optimization of Adaptive Video Streaming</a></h3>
                    <p><strong>Authors:</strong> Lianchen Jia, Chao Zhou, Chaoyang Li, Jiangchuan Liu, Lifeng Sun</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MM, eess.IV</p>
                    <p><strong>Summary:</strong> Traditional optimization methods based on system-wide Quality of Service (QoS) metrics have approached their performance limitations in modern large-scale streaming systems. However, aligning user-level Quality of Experience~(QoE) with algorithmic optimization objectives remains an unresolved challenge. Therefore, we propose \texttt{LingXi}, the first large-scale deployed system for personalized adaptive video streaming based on user-level experience. \texttt{LingXi} dynamically optimizes the objectives of adaptive video streaming algorithms by analyzing user engagement. Utilizing exit rate as a key metric, we investigate the correlation between QoS indicators and exit rates based on production environment logs, subsequently developing a personalized exit rate predictor. Through Monte Carlo sampling and online Bayesian optimization, we iteratively determine optimal parameters. Large-scale A/B testing utilizing 8\% of traffic on Kuaishou, one of the largest short video platforms, demonstrates \texttt{LingXi}s superior performance. \texttt{LingXi} achieves a 0.15\% increase in total viewing time, a 0.1\% improvement in bitrate, and a 1.3\% reduction in stall time across all users, with particularly significant improvements for low-bandwidth users who experience a 15\% reduction in stall time.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746027.3755257" target="_blank">Beyond Interpretability: Exploring the Comprehensibility of Adaptive Video Streaming through Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Lianchen Jia, Chaoyang Li, Ziqi Yuan, Jiahui Chen, Tianchi Huang, Jiangchuan Liu, Lifeng Sun</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MM, cs.LG, eess.IV</p>
                    <p><strong>Summary:</strong> Over the past decade, adaptive video streaming technology has witnessed significant advancements, particularly driven by the rapid evolution of deep learning techniques. However, the black-box nature of deep learning algorithms presents challenges for developers in understanding decision-making processes and optimizing for specific application scenarios. Although existing research has enhanced algorithm interpretability through decision tree conversion, interpretability does not directly equate to developers subjective comprehensibility. To address this challenge, we introduce \texttt{ComTree}, the first bitrate adaptation algorithm generation framework that considers comprehensibility. The framework initially generates the complete set of decision trees that meet performance requirements, then leverages large language models to evaluate these trees for developer comprehensibility, ultimately selecting solutions that best facilitate human understanding and enhancement. Experimental results demonstrate that \texttt{ComTree} significantly improves comprehensibility while maintaining competitive performance, showing potential for further advancement. The source code is available at https://github.com/thu-media/ComTree.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16445v1" target="_blank">Using LLMs and Essence to Support Software Practice Adoption</a></h3>
                    <p><strong>Authors:</strong> Sonia Nicoletti, Paolo Ciancarini</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Recent advancements in natural language processing (NLP) have enabled the development of automated tools that support various domains, including software engineering. However, while NLP and artificial intelligence (AI) research has extensively focused on tasks such as code generation, less attention has been given to automating support for the adoption of best practices, the evolution of ways of working, and the monitoring of process health. This study addresses this gap by exploring the integration of Essence, a standard and thinking framework for managing software engineering practices, with large language models (LLMs). To this end, a specialised chatbot was developed to assist students and professionals in understanding and applying Essence. The chatbot employs a retrieval-augmented generation (RAG) system to retrieve relevant contextual information from a curated knowledge base. Four different LLMs were used to create multiple chatbot configurations, each evaluated both as a base model and augmented with the RAG system. The system performance was evaluated through both the relevance of retrieved context and the quality of generated responses. Comparative analysis against the general-purpose LLMs demonstrated that the proposed system consistently outperforms its baseline counterpart in domain-specific tasks. By facilitating access to structured software engineering knowledge, this work contributes to bridging the gap between theoretical frameworks and practical application, potentially improving process management and the adoption of software development practices. While further validation through user studies is required, these findings highlight the potential of LLM-based automation to enhance learning and decision-making in software engineering.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16439v1" target="_blank">PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark</a></h3>
                    <p><strong>Authors:</strong> Adil Bahaj, Mounir Ghogho</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.CL, cs.GR, cs.MM</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) and vision-augmented LLMs (VLMs) have significantly advanced medical informatics, diagnostics, and decision support. However, these models exhibit systematic biases, particularly age bias, compromising their reliability and equity. This is evident in their poorer performance on pediatric-focused text and visual question-answering tasks. This bias reflects a broader imbalance in medical research, where pediatric studies receive less funding and representation despite the significant disease burden in children. To address these issues, a new comprehensive multi-modal pediatric question-answering benchmark, PediatricsMQA, has been introduced. It consists of 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatric topics across seven developmental stages (prenatal to adolescent) and 2,067 vision-based MCQs using 634 pediatric images from 67 imaging modalities and 256 anatomical regions. The dataset was developed using a hybrid manual-automatic pipeline, incorporating peer-reviewed pediatric literature, validated question banks, existing benchmarks, and existing QA resources. Evaluating state-of-the-art open models, we find dramatic performance drops in younger cohorts, highlighting the need for age-aware methods to ensure equitable AI support in pediatric care.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16420v1" target="_blank">Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Yue Pei, Hongming Zhang, Chao Gao, Martin MÃ¼ller, Mengxiao Zhu, Hao Sheng, Haogang Zhu, Liang Lin</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Offline reinforcement learning (RL) has achieved significant advances in domains such as robotic control, autonomous driving, and medical decision-making. Most existing methods primarily focus on training policies that maximize cumulative returns from a given dataset. However, many real-world applications require precise control over policy performance levels, rather than simply pursuing the best possible return. Reinforcement learning via supervised learning (RvS) frames offline RL as a sequence modeling task, enabling the extraction of diverse policies by conditioning on different desired returns. Yet, existing RvS-based transformers, such as Decision Transformer (DT), struggle to reliably align the actual achieved returns with specified target returns, especially when interpolating within underrepresented returns or extrapolating beyond the dataset. To address this limitation, we propose Doctor, a novel approach that Double Checks the Transformer with target alignment for Offline RL. Doctor achieves superior target alignment both within and beyond the dataset, while enabling accurate and flexible control over policy performance. Notably, on the dynamic treatment regime benchmark, EpiCare, our approach effectively modulates treatment policy aggressiveness, balancing therapeutic returns against adverse event risk.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16402v1" target="_blank">AetherCode: Evaluating LLMs Ability to Win In Premier Programming Competitions</a></h3>
                    <p><strong>Authors:</strong> Zihan Wang, Jiaze Chen, Zhicheng Liu, Markus Mak, Yidi Du, Geonsik Moon, Luoqi Xu, Aaron Tua, Kunshuo Peng, Jiayi Lu, Mingfei Xia, Boqian Zou, Chenyang Ran, Guang Tian, Shoutai Zhu, Yeheng Duan, Zhenghui Kang, Zhenxing Lin, Shangshu Li, Qiang Luo, Qingshen Long, Zhiyong Chen, Yihan Xiao, Yurong Wu, Daoguang Zan, Yuyi Fu, Mingxuan Wang, Ming Ding</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.CL</p>
                    <p><strong>Summary:</strong> Competitive programming has emerged as a critical benchmark for evaluating the reasoning and coding capabilities of Large Language Models (LLMs). Despite impressive progress on existing benchmarks, we argue that current evaluations overstate model proficiency, masking a substantial gap between LLMs and elite human programmers. This gap arises from two key limitations: insufficient difficulty and scope of benchmark problems, and evaluation bias from low-quality test cases. To address these shortcomings, we present AetherCode, a new benchmark that draws problems from premier programming competitions such as IOI and ICPC, offering broader coverage and higher difficulty. AetherCode further incorporates comprehensive, expert-validated test suites built through a hybrid of automated generation and human curation, ensuring rigorous and reliable assessment. By combining challenging problem design with robust evaluation, AetherCode provides a more faithful measure of LLM capabilities and sets a new standard for future research in code reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16396v1" target="_blank">Domain-aligned generative downscaling enhances projections of extreme climate events</a></h3>
                    <p><strong>Authors:</strong> Ruian Tie, Xiaohui Zhong, Zhengyu Shi, Hao Li, Jun Liu, Wu Libo</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.ao-ph, cs.AI</p>
                    <p><strong>Summary:</strong> Climate change is exacerbating extreme weather events globally, including high temperatures, extreme precipitation, strong winds, and tropical cyclones, posing severe threats to human health, infrastructure, food security, and socio-economic systems. Although existing global climate models (GCMs) provide essential tools for climate prediction, they face limitations such as insufficient resolution and high computational costs when simulating extreme events. To address these issues, this study proposes a spatiotemporal downscaling model based on generative machine learning-the Domain Aligned Climate Downscaling model (DACD), designed to enhance the simulation capabilities for extreme weather events. The proposed model employs domain adaptation tricks and a Flow Matching training framework to transform global low-resolution climate data into high-resolution local-scale climate information while achieving precise simulation of multivariable and temporal scales. The results show that during the historical period (2005-2014), our model outperformed existing methods in simulating high temperatures, extreme precipitation, strong wind, and tropical cyclone tracks, significantly reducing errors and improving the ability to capture extreme events. Under different future scenarios (2015-2100), the model reveals a significant increasing trend in the frequency and intensity of extreme events, particularly under the high-emission scenario (SSP585). Compared to traditional methods, our model more accurately simulates the spatial distribution and dynamic changes of extreme events, providing an essential tool for understanding the impacts of climate change. This study offers a new technological pathway for high-resolution climate analysis and extreme event prediction, providing scientific support for addressing future climate change and formulating adaptation strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16390v1" target="_blank">RoMedQA: The First Benchmark for Romanian Medical Question Answering</a></h3>
                    <p><strong>Authors:</strong> Ana-Cristina Rogoz, Radu Tudor Ionescu, Alexandra-Valentina Anghel, Ionut-Lucian Antone-Iordache, Simona Coniac, Andreea Iuliana Ionescu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Question answering (QA) is an actively studied topic, being a core natural language processing (NLP) task that needs to be addressed before achieving Artificial General Intelligence (AGI). However, the lack of QA datasets in specific domains and languages hinders the development of robust AI models able to generalize across various domains and languages. To this end, we introduce RoMedQA, the first Romanian QA benchmark for the medical domain, alongside a comprehensive evaluation of state-of-the-art large language models (LLMs). We construct a high-quality and large-scale dataset comprising 102,646 QA pairs related to cancer patients. The questions regard medical case summaries of 1,011 patients, requiring either keyword extraction or reasoning to be answered correctly. RoMedQA is the result of a time-consuming manual annotation process carried out by seven physicians specialized in oncology or radiotherapy, who spent a total of about 2,100 work hours to generate the QA pairs. We experiment with four LLMs from distinct families of models on RoMedQA. Each model is employed in two scenarios, namely one based on zero-shot prompting and one based on supervised fine-tuning. Our results show that fine-tuned models significantly outperform their zero-shot counterparts, clearly indicating that pretrained models fail to generalize on RoMedQA. Our findings demonstrate the importance of both domain-specific and language-specific fine-tuning for reliable clinical QA in Romanian. We publicly release our dataset and code at https://github.com/ana-rogoz/RoMedQA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16379v1" target="_blank">Agentic AI Empowered Multi-UAV Trajectory Optimization in Low-Altitude Economy Networks</a></h3>
                    <p><strong>Authors:</strong> Feibo Jiang, Li Dong, Xitao Pan, Kezhi Wang, Cunhua Pan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> This paper proposes a novel Agentic Retrieval-augmented generation with Mamba-Attention Integrated Transformer (ARMAIT) framework for multi-Unmanned Aerial Vehicle (UAV) trajectory optimization. The framework is built upon Large Language Models (LLMs), incorporating Retrieval-Augmented Generation (RAG) empowered by Agentic AI and integrated with a UAV-specific knowledge base. Through the Agentic RAG, the LLM autonomously interprets high-level task requirements and identifies the key components necessary for trajectory optimization, including model inputs and outputs, network architecture, reward functions, and task constraints. To support efficient modeling across different system scales, we introduce the Mamba-Attention Integrated Transformer (MAIT), a hybrid neural architecture that combines the long-range dependency modeling capability of attention mechanisms with the efficient temporal dynamic representation of Mamba. Furthermore, a Trajectory-Group Relative Policy Optimization (T-GRPO) method is proposed to achieve unified policy gradient optimization in both discrete and continuous trajectory spaces for MAIT training. Extensive experimental results validate the feasibility and effectiveness of the proposed ARMAIT framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16377v1" target="_blank">Applications and Challenges of Fairness APIs in Machine Learning Software</a></h3>
                    <p><strong>Authors:</strong> Ajoy Das, Gias Uddin, Shaiful Chowdhury, Mostafijur Rahman Akhond, Hadi Hemmati</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.SE</p>
                    <p><strong>Summary:</strong> Machine Learning software systems are frequently used in our day-to-day lives. Some of these systems are used in various sensitive environments to make life-changing decisions. Therefore, it is crucial to ensure that these AI/ML systems do not make any discriminatory decisions for any specific groups or populations. In that vein, different bias detection and mitigation open-source software libraries (aka API libraries) are being developed and used. In this paper, we conduct a qualitative study to understand in what scenarios these open-source fairness APIs are used in the wild, how they are used, and what challenges the developers of these APIs face while developing and adopting these libraries. We have analyzed 204 GitHub repositories (from a list of 1885 candidate repositories) which used 13 APIs that are developed to address bias in ML software. We found that these APIs are used for two primary purposes (i.e., learning and solving real-world problems), targeting 17 unique use-cases. Our study suggests that developers are not well-versed in bias detection and mitigation; they face lots of troubleshooting issues, and frequently ask for opinions and resources. Our findings can be instrumental for future bias-related software engineering research, and for guiding educators in developing more state-of-the-art curricula.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16371v1" target="_blank">The Mediomatix Corpus: Parallel Data for Romansh Idioms via Comparable Schoolbooks</a></h3>
                    <p><strong>Authors:</strong> Zachary Hopton, Jannis Vamvas, Andrin BÃ¼chler, Anna Rutkiewicz, Rico Cathomas, Rico Sennrich</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The five idioms (i.e., varieties) of the Romansh language are largely standardized and are taught in the schools of the respective communities in Switzerland. In this paper, we present the first parallel corpus of Romansh idioms. The corpus is based on 291 schoolbook volumes, which are comparable in content for the five idioms. We use automatic alignment methods to extract 207k multi-parallel segments from the books, with more than 2M tokens in total. A small-scale human evaluation confirms that the segments are highly parallel, making the dataset suitable for NLP applications such as machine translation between Romansh idioms. We release the parallel and unaligned versions of the dataset under a CC-BY-NC-SA license and demonstrate its utility for machine translation by training and evaluating an LLM on a sample of the dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16352v1" target="_blank">Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management</a></h3>
                    <p><strong>Authors:</strong> Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AI, eess.SP</p>
                    <p><strong>Summary:</strong> Efficient and reliable beam alignment is a critical requirement for mmWave multiple-input multiple-output (MIMO) systems, especially in 6G and beyond, where communication must be fast, adaptive, and resilient to real-world uncertainties. Existing deep learning (DL)-based beam alignment methods often neglect the underlying causal relationships between inputs and outputs, leading to limited interpretability, poor generalization, and unnecessary beam sweeping overhead. In this work, we propose a causally-aware DL framework that integrates causal discovery into beam management pipeline. Particularly, we propose a novel two-stage causal beam selection algorithm to identify a minimal set of relevant inputs for beam prediction. First, causal discovery learns a Bayesian graph capturing dependencies between received power inputs and the optimal beam. Then, this graph guides causal feature selection for the DL-based classifier. Simulation results reveal that the proposed causal beam selection matches the performance of conventional methods while drastically reducing input selection time by 94.4% and beam sweeping overhead by 59.4% by focusing only on causally relevant features.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16347v1" target="_blank">Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs</a></h3>
                    <p><strong>Authors:</strong> Yu Yan, Sheng Sun, Zhe Wang, Yijun Lin, Zenghao Duan, zhifei zheng, Min Liu, Zhiyi yin, Jianping Zhang</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> With the development of Large Language Models (LLMs), numerous efforts have revealed their vulnerabilities to jailbreak attacks. Although these studies have driven the progress in LLMs safety alignment, it remains unclear whether LLMs have internalized authentic knowledge to deal with real-world crimes, or are merely forced to simulate toxic language patterns. This ambiguity raises concerns that jailbreak success is often attributable to a hallucination loop between jailbroken LLM and judger LLM. By decoupling the use of jailbreak techniques, we construct knowledge-intensive Q\A to investigate the misuse threats of LLMs in terms of dangerous knowledge possession, harmful task planning utility, and harmfulness judgment robustness. Experiments reveal a mismatch between jailbreak success rates and harmful knowledge possession in LLMs, and existing LLM-as-a-judge frameworks tend to anchor harmfulness judgments on toxic language patterns. Our study reveals a gap between existing LLM safety assessments and real-world threat potential.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16339v1" target="_blank">Observation of negative orbital torque from Vanadium</a></h3>
                    <p><strong>Authors:</strong> Nikhil Vijayan, Durgesh Kumar, Ao Du, Lei Gao, Zijie Xiao, Hai I. Wang, Rahul Gupta, Gerhard Jakob, Sachin Krishnia, Yuriy Mokrousov, Mathias KlÃ¤ui</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> We present systematic investigations of orbital torques generated from the light metal $V$, revealing a negative orbital torque. We observe that the damping-like torque (DLT) per unit electric field depends on the choice of the ferromagnetic layer, with approximately seven times higher torque efficiency in $Ni/V$ as compared to $Fe_{60}Co_{20}B_{20}/V$. We find the sign of DLT per unit electric field from $V$ is opposite to that from $Pt$. These results collectively confirm the existence of negative orbital Hall effect (OHE) in $V$. Furthermore, the DLT per unit electric field increases with the $V$ layer thickness, maintaining the negative sign at all thicknesses. We also note that the DLT per unit electric field exceeds that of the $Pt$ reference samples at higher $V$ thicknesses. Through fitting using the drift-diffusion equation, we extract a high effective orbital Hall conductivity of $-(1.46 \pm 0.09)\,\frac{\hbar}{2e}\,\times 10^{5}\,\Omega^{-1}\,\mathrm{m}^{-1}$ and a long orbital diffusion length of $(13.7 \pm 0.9)\,\mathrm{nm}$ in $V$. .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16332v1" target="_blank">Vevo2: Bridging Controllable Speech and Singing Voice Generation via Unified Prosody Learning</a></h3>
                    <p><strong>Authors:</strong> Xueyao Zhang, Junan Zhang, Yuancheng Wang, Chaoren Wang, Yuanzhe Chen, Dongya Jia, Zhuo Chen, Zhizheng Wu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Controllable human voice generation, particularly for expressive domains like singing, remains a significant challenge. This paper introduces Vevo2, a unified framework for controllable speech and singing voice generation. To tackle issues like the scarcity of annotated singing data and to enable flexible controllability, Vevo2 introduces two audio tokenizers: (1) a music-notation-free prosody tokenizer that captures prosody and melody from speech, singing, and even instrumental sounds, and (2) a low-frame-rate (12.5 Hz) content-style tokenizer that encodes linguistic content, prosody, and style for both speech and singing, while enabling timbre disentanglement. Vevo2 consists of an auto-regressive (AR) content-style modeling stage, which aims to enable controllability over text, prosody, and style, as well as a flow-matching acoustic modeling stage that allows for timbre control. Particularly, during pre-training of the AR model, we propose both explicit and implicit prosody learning strategies to bridge speech and singing voice. Moreover, to further enhance the AR models ability to follow text and prosody, we design a multi-objective post-training task that integrates both intelligibility and prosody similarity alignment. Experimental results show that the unified modeling in Vevo2 brings mutual benefits to both speech and singing voice generation. Additionally, Vevo2s effectiveness across a wide range of synthesis, conversion, and editing tasks for both speech and singing further demonstrates its strong generalization ability and versatility. Audio samples are are available at https://versasinger.github.io/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16325v1" target="_blank">LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts</a></h3>
                    <p><strong>Authors:</strong> Darpan Aswal, CÃ©line Hudelot</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.SC</p>
                    <p><strong>Summary:</strong> Large Language Models have found success in a variety of applications; however, their safety remains a matter of concern due to the existence of various types of jailbreaking methods. Despite significant efforts, alignment and safety fine-tuning only provide a certain degree of robustness against jailbreak attacks that covertly mislead LLMs towards the generation of harmful content. This leaves them prone to a number of vulnerabilities, ranging from targeted misuse to accidental profiling of users. This work introduces \textbf{LLMSymGuard}, a novel framework that leverages Sparse Autoencoders (SAEs) to identify interpretable concepts within LLM internals associated with different jailbreak themes. By extracting semantically meaningful internal representations, LLMSymGuard enables building symbolic, logical safety guardrails -- offering transparent and robust defenses without sacrificing model capabilities or requiring further fine-tuning. Leveraging advances in mechanistic interpretability of LLMs, our approach demonstrates that LLMs learn human-interpretable concepts from jailbreaks, and provides a foundation for designing more interpretable and logical safeguard measures against attackers. Code will be released upon publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16320v1" target="_blank">AI-Supported Mini-Labs: Combining Smartphone-Based Experiments and Multimodal AI</a></h3>
                    <p><strong>Authors:</strong> Jochen Kuhn, David J. Rakestraw, Stefan KÃ¼chemann, Patrik Vogt</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph</p>
                    <p><strong>Summary:</strong> This paper presents the concept of AI-supported Mini-Labs, combining smartphone-based experiments with multimodal large language models (MLLMs). Smartphones, with their integrated sensors and computational power, function as versatile mobile laboratories for physics education. While they enable the collection of rich experimental data, the analysis of complex everyday phenomena has often been limited in the classroom. Advances in MLLMs now allow learners to process multimodal data, text, images, audio, and video, and receive support in experiment design, data analysis, and scientific interpretation. Three case studies highlight the approach: determining a vehicle drag coefficient from accelerometer data, measuring the ionospheric reflection height from lightning-generated signals analyzed as audio spectrograms, and real-time spectroscopy of blood volume dynamics using smartphone video. The results show clear advantages over conventional methods, including time savings, high-quality visualizations, and individualized guidance. Beyond simplifying data analysis, AI-augmented pocket labs foster representational competence, critical thinking, and 21st-century skills. This hybrid approach offers a promising pathway for individualized and inquiry-based science education, though further studies are needed to assess long-term learning effects and potential risks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16316v1" target="_blank">QUEENS: An Open-Source Python Framework for Solver-Independent Analyses of Large-Scale Computational Models</a></h3>
                    <p><strong>Authors:</strong> Jonas Biehler, Jonas Nitzler, Sebastian BrandstÃ¤ter, Maximilian Dinkel, Volker Gravemeier, Lea J. HÃ¤usel, Gil Robalo Rei, Harald Willmann, Barbara Wirthl, Wolfgang A. Wall</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> A growing challenge in research and industrial engineering applications is the need for repeated, systematic analysis of large-scale computational models, for example, patient-specific digital twins of diseased human organs: The analysis requires efficient implementation, data, resource management, and parallelization, possibly on distributed systems. To tackle these challenges and save many researchers from annoying, time-consuming tasks, we present QUEENS (Quantification of Uncertain Effects in Engineering Systems), an open-source Python framework for composing and managing simulation analyses with arbitrary (physics-based) solvers on distributed computing infrastructures. Besides simulation management capabilities, QUEENS offers a comprehensive collection of efficiently implemented state-of-the-art algorithms ranging from routines for convergence studies and common optimization algorithms to more advanced sampling algorithms for uncertainty quantification and Bayesian inverse analysis. Additionally, we provide our latest cutting-edge research in multi-fidelity uncertainty quantification, efficient multi-fidelity Bayesian inverse analysis, and probabilistic machine learning. QUEENS adopts a Bayesian, probabilistic mindset but equally supports standard deterministic analysis without requiring prior knowledge of probability theory. The modular architecture allows rapid switching between common types of analyses and facilitates building sophisticated hierarchical algorithms. Encouraging natural incremental steps and scaling towards complexity allows researchers to consider the big picture while building towards it through smaller, manageable steps. The open-source repository is available at https://github.com/queens-py/queens.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16315v1" target="_blank">OwkinZero: Accelerating Biological Discovery with AI</a></h3>
                    <p><strong>Authors:</strong> Nathan Bigaud, Vincent Cabeli, Meltem Gurel, Arthur Pignet, John Klein, Gilles Wainrib, Eric Durand</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> While large language models (LLMs) are rapidly advancing scientific research, they continue to struggle with core biological reasoning tasks essential for translational and biomedical discovery. To address this limitation, we created and curated eight comprehensive benchmark datasets comprising over 300,000 verifiable question-and-answer pairs, each targeting critical challenges in drug discovery including target druggability, modality suitability, and drug perturbation effects. Using this resource, we developed the OwkinZero models by post-training open-source LLMs through a Reinforcement Learning from Verifiable Rewards strategy. Our results demonstrate that specialized 8-32B OwkinZero models substantially outperform larger, state-of-the-art commercial LLMs on these biological benchmarks. Remarkably, we uncover evidence of a key aspect of generalization: specialist models trained on a single task consistently outperform their base models on previously unseen tasks. This generalization effect is further amplified in our comprehensive OwkinZero models, which were trained on a mixture of datasets and achieve even broader cross-task improvements. This study represents a significant step toward addressing the biological reasoning blind spot in current LLMs, demonstrating that targeted reinforcement learning on carefully curated data can unlock generalizable performance in specialized models, thereby accelerating AI-driven biological discovery.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/LWC.2025.3593066" target="_blank">Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links</a></h3>
                    <p><strong>Authors:</strong> Selen Gecgel Cetin, Tolga Ovatman, Gunes Karabulut Kurt</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.ET</p>
                    <p><strong>Summary:</strong> This letter addresses essential aspects of threat assessment by proposing intent-driven threat models that incorporate both capabilities and intents. We propose a holistic framework for cyber physical awareness (CPA) in space networks, pointing out that analyzing reliability and security separately can lead to overfitting on system-specific criteria. We structure our proposed framework in three main steps. First, we suggest an algorithm that extracts characteristic properties of the received signal to facilitate an intuitive understanding of potential threats. Second, we develop a multitask learning architecture where one task evaluates reliability-related capabilities while the other deciphers the underlying intentions of the signal. Finally, we propose an adaptable threat assessment that aligns with varying security and reliability requirements. The proposed framework enhances the robustness of threat detection and assessment, outperforming conventional sequential methods, and enables space networks with emerging intershell links to effectively address complex threat scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16313v1" target="_blank">Retrieval Enhanced Feedback via In-context Neural Error-book</a></h3>
                    <p><strong>Authors:</strong> Jongyeop Hyun, Bumsoo Kim</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models (LLMs) have significantly improved reasoning capabilities, with in-context learning (ICL) emerging as a key technique for adaptation without retraining. While previous works have focused on leveraging correct examples, recent research highlights the importance of learning from errors to enhance performance. However, existing methods lack a structured framework for analyzing and mitigating errors, particularly in Multimodal Large Language Models (MLLMs), where integrating visual and textual inputs adds complexity. To address this issue, we propose REFINE: Retrieval-Enhanced Feedback via In-context Neural Error-book, a teacher-student framework that systematically structures errors and provides targeted feedback. REFINE introduces three systematic queries to construct structured feedback -- Feed-Target, Feed-Check, and Feed-Path -- to enhance multimodal reasoning by prioritizing relevant visual information, diagnosing critical failure points, and formulating corrective actions. Unlike prior approaches that rely on redundant retrievals, REFINE optimizes structured feedback retrieval, improving inference efficiency, token usage, and scalability. Our results demonstrate substantial speedup, reduced computational costs, and successful generalization, highlighting REFINEs potential for enhancing multimodal reasoning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16303v1" target="_blank">JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus</a></h3>
                    <p><strong>Authors:</strong> Masaaki Nagata, Katsuki Chousa, Norihito Yasuda</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We constructed JaParaPat (Japanese-English Parallel Patent Application Corpus), a bilingual corpus of more than 300 million Japanese-English sentence pairs from patent applications published in Japan and the United States from 2000 to 2021. We obtained the publication of unexamined patent applications from the Japan Patent Office (JPO) and the United States Patent and Trademark Office (USPTO). We also obtained patent family information from the DOCDB, that is a bibliographic database maintained by the European Patent Office (EPO). We extracted approximately 1.4M Japanese-English document pairs, which are translations of each other based on the patent families, and extracted about 350M sentence pairs from the document pairs using a translation-based sentence alignment method whose initial translation model is bootstrapped from a dictionary-based sentence alignment method. We experimentally improved the accuracy of the patent translations by 20 bleu points by adding more than 300M sentence pairs obtained from patent applications to 22M sentence pairs obtained from the web.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16297v1" target="_blank">Hybrid Classical-Quantum Supercomputing: A demonstration of a multi-user, multi-QPU and multi-GPU environment</a></h3>
                    <p><strong>Authors:</strong> Mateusz Slysz, Piotr Rydlichowski, Krzysztof Kurowski, Omar Bacarezza, Esperanza Cuenca Gomez, Zohim Chandani, Bettina Heim, Pradnya Khalate, William R. Clements, James Fletcher</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.DC, cs.ET</p>
                    <p><strong>Summary:</strong> Achieving a practical quantum advantage for near-term applications is widely expected to rely on hybrid classical-quantum algorithms. To deliver this practical advantage to users, high performance computing (HPC) centers need to provide a suitable software and hardware stack that supports algorithms of this type. In this paper, we describe the worlds first implementation of a classical-quantum environment in an HPC center that allows multiple users to execute hybrid algorithms on multiple quantum processing units (QPUs) and GPUs. Our setup at the Poznan Supercomputing and Networking Center (PCSS) aligns with current HPC norms: the computing hardware including QPUs is installed in an active data center room with standard facilities; there are no special considerations for networking, power, and cooling; we use Slurm for workload management as well as the NVIDIA CUDA-Q extension API for classical-quantum interactions. We demonstrate applications of this environment for hybrid classical-quantum machine learning and optimisation. The aim of this work is to provide the community with an experimental example for further research and development on how quantum computing can practically enhance and extend HPC capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16295v1" target="_blank">Enhanced Hybrid Technique for Efficient Digitization of Handwritten Marksheets</a></h3>
                    <p><strong>Authors:</strong> Junaid Ahmed Sifat, Abir Chowdhury, Hasnat Md. Imtiaz, Md. Irtiza Hossain, Md. Imran Bin Azad</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The digitization of handwritten marksheets presents huge challenges due to the different styles of handwriting and complex table structures in such documents like marksheets. This work introduces a hybrid method that integrates OpenCV for table detection and PaddleOCR for recognizing sequential handwritten text. The image processing capabilities of OpenCV efficiently detects rows and columns which enable computationally lightweight and accurate table detection. Additionally, YOLOv8 and Modified YOLOv8 are implemented for handwritten text recognition within the detected table structures alongside PaddleOCR which further enhance the systems versatility. The proposed model achieves high accuracy on our custom dataset which is designed to represent different and diverse handwriting styles and complex table layouts. Experimental results demonstrate that YOLOv8 Modified achieves an accuracy of 92.72 percent, outperforming PaddleOCR 91.37 percent and the YOLOv8 model 88.91 percent. This efficiency reduces the necessity for manual work which makes this a practical and fast solution for digitizing academic as well as administrative documents. This research serves the field of document automation, particularly handwritten document understanding, by providing operational and reliable methods to scale, enhance, and integrate the technologies involved.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16291v1" target="_blank">Learning Long-Range Action Representation by Two-Stream Mamba Pyramid Network for Figure Skating Assessment</a></h3>
                    <p><strong>Authors:</strong> Fengshun Wang, Qiurui Wang, Peilin Zhao</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.MM</p>
                    <p><strong>Summary:</strong> Technical Element Score (TES) and Program Component Score (PCS) evaluations in figure skating demand precise assessment of athletic actions and artistic interpretation, respectively. Existing methods face three major challenges. Firstly, video and audio cues are regarded as common features for both TES and PCS predictions in previous works without considering the prior evaluation criterion of figure skating. Secondly, action elements in competitions are separated in time, TES should be derived from each elements score, but existing methods try to give an overall TES prediction without evaluating each action element. Thirdly, lengthy competition videos make it difficult and inefficient to handle long-range contexts. To address these challenges, we propose a two-stream Mamba pyramid network that aligns with actual judging criteria to predict TES and PCS by separating visual-feature based TES evaluation stream from audio-visual-feature based PCS evaluation stream. In the PCS evaluation stream, we introduce a multi-level fusion mechanism to guarantee that video-based features remain unaffected when assessing TES, and enhance PCS estimation by fusing visual and auditory cues across each contextual level of the pyramid. In the TES evaluation stream, the multi-scale Mamba pyramid and TES head we proposed effectively address the challenges of localizing and evaluating action elements with various temporal scales and give score predictions. With Mambas superior ability to capture long-range dependencies and its linear computational complexity, our method is ideal for handling lengthy figure skating videos. Comprehensive experimentation demonstrates that our framework attains state-of-the-art performance on the FineFS benchmark. Our source code is available at https://github.com/ycwfs/Figure-Skating-Action-Quality-Assessment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16285v1" target="_blank">A Social Choice Analysis of Optimisms Retroactive Project Funding</a></h3>
                    <p><strong>Authors:</strong> Eyal Briman, Nimrod Talmon, Angela Kreitenweis, Muhammad Idrees</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.GT</p>
                    <p><strong>Summary:</strong> The Optimism Retroactive Project Funding (RetroPGF) is a key initiative within the blockchain ecosystem that retroactively rewards projects deemed valuable to the Ethereum and Optimism communities. Managed by the Optimism Collective, a decentralized autonomous organization (DAO), RetroPGF represents a large-scale experiment in decentralized governance. Funding rewards are distributed in OP tokens, the native digital currency of the ecosystem. As of this writing, four funding rounds have been completed, collectively allocating over 100M dollars, with an additional 1.3B dollars reserved for future rounds. However, we identify significant shortcomings in the current allocation system, underscoring the need for improved governance mechanisms given the scale of funds involved. Leveraging computational social choice techniques and insights from multiagent systems, we propose improvements to the voting process by recommending the adoption of a utilitarian moving phantoms mechanism. This mechanism, originally introduced by Freeman et al. in 2019, is designed to enhance social welfare (using the L1 norm) while satisfying strategyproofness -- two key properties aligned with the applications governance requirements. Our analysis provides a formal framework for designing improved funding mechanisms for DAOs, contributing to the broader discourse on decentralized governance and public goods allocation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16284v1" target="_blank">EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents</a></h3>
                    <p><strong>Authors:</strong> Anjith George, Sebastien Marcel</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The widespread availability of tools for manipulating images and documents has made it increasingly easy to forge digital documents, posing a serious threat to Know Your Customer (KYC) processes and remote onboarding systems. Detecting such forgeries is essential to preserving the integrity and security of these services. In this work, we present EdgeDoc, a novel approach for the detection and localization of document forgeries. Our architecture combines a lightweight convolutional transformer with auxiliary noiseprint features extracted from the images, enhancing its ability to detect subtle manipulations. EdgeDoc achieved third place in the ICCV 2025 DeepID Challenge, demonstrating its competitiveness. Experimental results on the FantasyID dataset show that our method outperforms baseline approaches, highlighting its effectiveness in realworld scenarios. Project page : https://www.idiap. ch/paper/edgedoc/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16277v1" target="_blank">The next question after Turings question: Introducing the Grow-AI test</a></h3>
                    <p><strong>Authors:</strong> Alexandru Tugui</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, 68T01, 68T05, 68T42, 91A80, I.2; K.4</p>
                    <p><strong>Summary:</strong> This study aims to extend the framework for assessing artificial intelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom), designed to answer the question Can machines grow up? -- a natural successor to the Turing Test. The methodology applied is based on a system of six primary criteria (C1-C6), each assessed through a specific game, divided into four arenas that explore both the human dimension and its transposition into AI. All decisions and actions of the entity are recorded in a standardized AI Journal, the primary source for calculating composite scores. The assessment uses the prior expert method to establish initial weights, and the global score -- Grow Up Index -- is calculated as the arithmetic mean of the six scores, with interpretation on maturity thresholds. The results show that the methodology allows for a coherent and comparable assessment of the level of growth of AI entities, regardless of their type (robots, software agents, LLMs). The multi-game structure highlights strengths and vulnerable areas, and the use of a unified journal guarantees traceability and replicability in the evaluation. The originality of the work lies in the conceptual transposition of the process of growing from the human world to that of artificial intelligence, in an integrated testing format that combines perspectives from psychology, robotics, computer science, and ethics. Through this approach, GROW-AI not only measures performance but also captures the evolutionary path of an AI entity towards maturity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16276v1" target="_blank">Implicit reporting standards in bibliometric research: what can reviewers comments tell us about reporting completeness?</a></h3>
                    <p><strong>Authors:</strong> Dimity Stephen, Alexander Schniedermann, Andrey Lovakov, Marion Schmidt, Matteo Ottaviani, Nikita Sorgatz, Roberto Cruz Romero, Torger MÃ¶ller, Valeria Aman, Stephan Stahlschmidt</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.DL</p>
                    <p><strong>Summary:</strong> The recent surge in bibliometric studies published has been accompanied by increasing diversity in the completeness of reporting these studies details, affecting reliability, reproducibility, and robustness. Our study systematises the reporting of bibliometric research using open peer reviews. We examined 182 peer reviews of 85 bibliometric studies published in library and information science (LIS) journals and conference proceedings, and non-LIS journals. We extracted 968 reviewer comments and inductively classified them into 11 broad thematic categories and 68 sub-categories, determining that reviewers largely focus on the completeness and clarity of reporting data, methods, and results. We subsequently derived 49 recommendations for the details authors should report and compared them with the GLOBAL, PRIBA, and BIBLIO reporting guidelines to identify (dis)similarities in content. Our recommendations addressed 60-80% of the guidelines items, while the guidelines covered 45-65% of our recommendations. Our recommendations provided greater range and specificity, but did not incorporate the functions of guidelines beyond addressing academic content. We argue that peer reviews provide valuable information for the development of future guidelines. Further, our recommendations can be read as the implicit community standards for reporting bibliometric studies and could be used by authors to aid complete and accurate reporting of their manuscripts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16273v1" target="_blank">A Systematic Mapping Study on Smart Cities Modeling Approaches</a></h3>
                    <p><strong>Authors:</strong> Maria Teresa Rossi, Martina De Sanctis, Ludovico Iovino, Manuel Wimmer</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> The Smart City concept was introduced to define an idealized city characterized by automation and connection. It then evolved rapidly by including further aspects, such as economy, environment. Since then, many publications have explored various aspects of Smart Cities across different application domains and research communities, acknowledging the interdisciplinary nature of this subject. In particular, our interest focuses on how smart cities are designed and modeled, as a whole or as regards with their subsystems, when dealing with the accomplishment of the research goals in this complex and heterogeneous domain. To this aim, we performed a systematic mapping study on smart cities modeling approaches identifying the relevant contributions (i) to get an overview of existing research approaches, (ii) to identify whether there are any publication trends, and (iii) to identify possible future research directions. We followed the guidelines for conducting systematic mapping studies by Petersen et al. to analyze smart cities modeling publications. Our analysis revealed the following main findings: (i) smart governance is the most investigated and modeled smart city dimension; (ii) the most used modeling approaches are business, architectural, and ontological modeling approaches, spanning multiple application fields; (iii) the great majority of existing technologies for modeling smart cities are not yet proven in operational environments; (iv) diverse research communities publish their results in a multitude of different venues which further motivates the presented literature study. Researchers can use our results for better understanding the state-of-the-art in modeling smart cities, and as a foundation for further analysis of specific approaches about smart cities modeling. Lastly, we also discuss the impact of our analysis for the Model-Driven Engineering community.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/TGRS.2025.3600249" target="_blank">IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization</a></h3>
                    <p><strong>Authors:</strong> Yu Meng, Ligao Deng, Zhihao Xi, Jiansheng Chen, Jingbo Chen, Anzhi Yue, Diyou Liu, Kai Li, Chenhao Wang, Kaiyu Li, Yupeng Deng, Xian Sun</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the enhancement of remote sensing image resolution and the rapid advancement of deep learning, land cover mapping is transitioning from pixel-level segmentation to object-based vector modeling. This shift demands more from deep learning models, requiring precise object boundaries and topological consistency. However, existing datasets face three main challenges: limited class annotations, small data scale, and lack of spatial structural information. To overcome these issues, we introduce IRSAMap, the first global remote sensing dataset for large-scale, high-resolution, multi-feature land cover vector mapping. IRSAMap offers four key advantages: 1) a comprehensive vector annotation system with over 1.8 million instances of 10 typical objects (e.g., buildings, roads, rivers), ensuring semantic and spatial accuracy; 2) an intelligent annotation workflow combining manual and AI-based methods to improve efficiency and consistency; 3) global coverage across 79 regions in six continents, totaling over 1,000 km; and 4) multi-task adaptability for tasks like pixel-level classification, building outline extraction, road centerline extraction, and panoramic segmentation. IRSAMap provides a standardized benchmark for the shift from pixel-based to object-based approaches, advancing geographic feature automation and collaborative modeling. It is valuable for global geographic information updates and digital twin construction. The dataset is publicly available at https://github.com/ucas-dlg/IRSAMap</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16268v1" target="_blank">Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication</a></h3>
                    <p><strong>Authors:</strong> Rob Carson, Mohamed Chahine Ghanem, Feriel Bouakkaz</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.DC</p>
                    <p><strong>Summary:</strong> This Paper proposes a self-healing, automated network of Raspberry Pi devices designed for deployment in scenarios where traditional networking is unavailable. Leveraging the low-power, long-range capabilities of the LoRa (Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the research addresses challenges such as limited bandwidth, data collisions, and node failures. Given that LoRas packet-based system is incompatible with conventional IaC tools like Ansible and Terraform, which rely on TCP/IP networking, the research adapts IaC principles within a containerised architecture deployed across a Raspberry Pi cluster. Evaluation experiments indicate that fragmenting data packets and retransmitting any missed fragments can mitigate LoRas inherent throughput and packet size limitations, although issues such as collisions and line-of-sight interference persist. An automated failover mechanism was integrated into the architecture, enabling unresponsive services to be redeployed to alternative nodes within one second, demonstrating the systems resilience in maintaining operational continuity despite node or service failures. The paper also identifies practical challenges, including the necessity for time-slotting transmissions to prevent data packet overlap and collisions. Future research should explore the integration of mesh networking to enhance range, develop more advanced scheduling algorithms, and adopt cutting-edge low-power wide-area network (LPWAN) techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16577v1" target="_blank">MV-RAG: Retrieval Augmented Multiview Diffusion</a></h3>
                    <p><strong>Authors:</strong> Yosef Dayani, Omer Benishu, Sagie Benaim</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Text-to-3D generation approaches have advanced significantly by leveraging pretrained 2D diffusion priors, producing high-quality and 3D-consistent outputs. However, they often fail to produce out-of-domain (OOD) or rare concepts, yielding inconsistent or inaccurate results. To this end, we propose MV-RAG, a novel text-to-3D pipeline that first retrieves relevant 2D images from a large in-the-wild 2D database and then conditions a multiview diffusion model on these images to synthesize consistent and accurate multiview outputs. Training such a retrieval-conditioned model is achieved via a novel hybrid strategy bridging structured multiview data and diverse 2D image collections. This involves training on multiview data using augmented conditioning views that simulate retrieval variance for view-specific reconstruction, alongside training on sets of retrieved real-world 2D images using a distinctive held-out view prediction objective: the model predicts the held-out view from the other views to infer 3D consistency from 2D data. To facilitate a rigorous OOD evaluation, we introduce a new collection of challenging OOD prompts. Experiments against state-of-the-art text-to-3D, image-to-3D, and personalization baselines show that our approach significantly improves 3D consistency, photorealism, and text adherence for OOD/rare concepts, while maintaining competitive performance on standard benchmarks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16576v1" target="_blank">Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet</a></h3>
                    <p><strong>Authors:</strong> Anyu Ying, Natarajan Balaji Shankar, Chyi-Jiunn Lin, Mohan Shi, Pu Wang, Hye-jin Shim, Siddhant Arora, Hugo Van hamme, Abeer Alwan, Shinji Watanabe</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite advancements in ASR, child speech recognition remains challenging due to acoustic variability and limited annotated data. While fine-tuning adult ASR models on child speech is common, comparisons with flat-start training remain underexplored. We compare flat-start training across multiple datasets, SSL representations (WavLM, XEUS), and decoder architectures. Our results show that SSL representations are biased toward adult speech, with flat-start training on child speech mitigating these biases. We also analyze model scaling, finding consistent improvements up to 1B parameters, beyond which performance plateaus. Additionally, age-related ASR and speaker verification analysis highlights the limitations of proprietary models like Whisper, emphasizing the need for open-data models for reliable child speech research. All investigations are conducted using ESPnet, and our publicly available benchmark provides insights into training strategies for robust child speech processing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16575v1" target="_blank">Optimal Hamiltonian for a quantum state with finite entropy</a></h3>
                    <p><strong>Authors:</strong> M. E. Shirokov</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.IT, math-ph, math.IT, math.MP</p>
                    <p><strong>Summary:</strong> We consider the following task: how for a given quantum state $\rho$ to find a grounded Hamiltonian $H$ such that $\mathrm{Tr}H\rho\leq E_00$ be as small as possible. We show that for any mixed state $\rho$ with finite entropy and any $E0$ there is a unique solution $H(\rho,E_0,E)$ of the above problem which we call optimal Hamiltonian for this state. Explicit expressions for $H(\rho,E_0,E)$ and $S(\gamma_H(E))$ with $H=H(\rho,E_0,E)$ are obtained. Several examples are considered. A brief overview of possible applications is given (with the intention to give a detailed description in a separate article).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16570v1" target="_blank">Emergent statistical mechanics in holographic random tensor networks</a></h3>
                    <p><strong>Authors:</strong> Shozab Qasim, Jens Eisert, Alexander Jahn</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech, hep-th</p>
                    <p><strong>Summary:</strong> Recent years have enjoyed substantial progress in capturing properties of complex quantum systems by means of random tensor networks (RTNs), which form ensembles of quantum states that depend only on the tensor network geometry and bond dimensions. Of particular interest are RTNs on hyperbolic geometries, with local tensors typically chosen from the unitary Haar measure, that model critical boundary states of holographic bulk-boundary dualities. In this work, we elevate static pictures of ensemble averages to a dynamical one, to show that RTN states exhibit equilibration of time-averaged operator expectation values under a highly generic class of Hamiltonians with non-degenerate spectra. We prove that RTN states generally equilibrate at large bond dimension and also in the scaling limit for three classes of geometries: Those of matrix product states, regular hyperbolic tilings, and single black hole tensors. Furthermore, we prove a hierarchy of equilibration between finite-dimensional instances of these classes for bulk and boundary states with small entanglement. This suggests an equivalent hierarchy between corresponding many-body phases, and reproduces a holographic degree-of-freedom counting for the effective dimension of each system. These results demonstrate that RTN techniques can probe aspects of late-time dynamics of quantum many-body phases and suggest a new approach to describing aspects of holographic dualities using techniques from statistical mechanics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16569v1" target="_blank">A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer</a></h3>
                    <p><strong>Authors:</strong> Yuhui Tao, Zhongwei Zhao, Zilong Wang, Xufang Luo, Feng Chen, Kang Wang, Chuanfu Wu, Xue Zhang, Shaoting Zhang, Jiaxi Yao, Xingwei Jin, Xinyang Jiang, Yifan Yang, Dongsheng Li, Lili Qiu, Zhiqiang Shao, Jianming Guo, Nengwang Yu, Shuo Wang, Ying Xiong</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The non-invasive assessment of increasingly incidentally discovered renal masses is a critical challenge in urologic oncology, where diagnostic uncertainty frequently leads to the overtreatment of benign or indolent tumors. In this study, we developed and validated RenalCLIP using a dataset of 27,866 CT scans from 8,809 patients across nine Chinese medical centers and the public TCIA cohort, a visual-language foundation model for characterization, diagnosis and prognosis of renal mass. The model was developed via a two-stage pre-training strategy that first enhances the image and text encoders with domain-specific knowledge before aligning them through a contrastive learning objective, to create robust representations for superior generalization and diagnostic precision. RenalCLIP achieved better performance and superior generalizability across 10 core tasks spanning the full clinical workflow of kidney cancer, including anatomical assessment, diagnostic classification, and survival prediction, compared with other state-of-the-art general-purpose CT foundation models. Especially, for complicated task like recurrence-free survival prediction in the TCIA cohort, RenalCLIP achieved a C-index of 0.726, representing a substantial improvement of approximately 20% over the leading baselines. Furthermore, RenalCLIPs pre-training imparted remarkable data efficiency; in the diagnostic classification task, it only needs 20% training data to achieve the peak performance of all baseline models even after they were fully fine-tuned on 100% of the data. Additionally, it achieved superior performance in report generation, image-text retrieval and zero-shot diagnosis tasks. Our findings establish that RenalCLIP provides a robust tool with the potential to enhance diagnostic accuracy, refine prognostic stratification, and personalize the management of patients with kidney cancer.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16568v1" target="_blank">Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation</a></h3>
                    <p><strong>Authors:</strong> Guangyu Sun, Jingtao Li, Weiming Zhuang, Chen Chen, Chen Chen, Lingjuan Lyu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> Foundation models (FMs) exhibit remarkable generalization but require adaptation to downstream tasks, particularly in privacy-sensitive applications. Due to data privacy regulations, cloud-based FMs cannot directly access private edge data, limiting their adaptation. Federated learning (FL) provides a privacy-aware alternative, but existing FL approaches overlook the constraints imposed by edge devices -- namely, limited computational resources and the scarcity of labeled data. To address these challenges, we introduce Practical Semi-Supervised Federated Learning (PSSFL), where edge devices hold only unlabeled, low-resolution data, while the server has limited labeled, high-resolution data. In this setting, we propose the Federated Mixture of Experts (FedMox), a novel framework that enhances FM adaptation in FL. FedMox tackles computational and resolution mismatch challenges via a sparse Mixture-of-Experts architecture, employing a spatial router to align features across resolutions and a Soft-Mixture strategy to stabilize semi-supervised learning. We take object detection as a case study, and experiments on real-world autonomous driving datasets demonstrate that FedMox effectively adapts FMs under PSSFL, significantly improving performance with constrained memory costs on edge devices. Our work paves the way for scalable and privacy-preserving FM adaptation in federated scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16565v1" target="_blank">Webification of symmetry classes of plane partitions</a></h3>
                    <p><strong>Authors:</strong> Ashleigh Adams, Jessica Striker</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> math.CO, 05E10, 05A19, 13A50</p>
                    <p><strong>Summary:</strong> Webs are graphical objects that give a tangible, combinatorial way to compute and classify tensor invariants. Recently, [Gaetz, Pechenik, Pfannerer, Striker, Swanson 2023+] found a rotation-invariant web basis for $\mathrm{SL}_4$, as well as its quantum deformation $U_q(\mathfrak{sl}_4)$, and a bijection between move equivalence classes of $U_q(\mathfrak{sl}_4)$-webs and fluctuating tableaux such that web rotation corresponds to tableau promotion. They also found a bijection between the set of plane partitions in an $a\times b\times c$ box and a benzene move equivalence class of $U_q(\mathfrak{sl}_4)$-webs by determining the corresponding oscillating tableau. In this paper, we similarly find the oscillating tableaux corresponding to plane partitions in certain symmetry classes. We furthermore show that there is a projection from $U_q(\mathfrak{sl}_4)$ invariants to $U_q(\mathfrak{sl}_r)$ for $r=2,3$ for webs arising from certain symmetry classes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16564v1" target="_blank">A Nodal Discontinuous Galerkin Method with Low-Rank Velocity Space Representation for the Multi-Scale BGK Model</a></h3>
                    <p><strong>Authors:</strong> Andres Galindo-Olarte, Joseph Nakao, Mirjeta Pasha, Jing-Mei Qiu, William Taitano</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> A novel hybrid algorithm is presented for the Boltzmann-BGK equation, in which a low-rank decomposition is applied solely in the velocity subspace, while a full-rank representation is maintained in the physical (position) space. This approach establishes a foundation for extending modern low-rank techniques to solve the Boltzmann equation in realistic settings, particularly where structured representations -- such as conformal geometries -- may not be feasible in practical engineering applications. A nodal discontinuous Galerkin method is employed for spatial discretization, coupled with a low-rank decomposition over the velocity grid, as well as implicit-explicit Runge-Kutta methods for time integration. To handle the limit of vanishing collision time, a multiscale implicit integrator based on an auxiliary moment equation is utilized. The algorithms order of accuracy, reduced computational complexity, and robustness are demonstrated on a suite of canonical gas kinetics problems with increasing complexity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16562v1" target="_blank">Energy-momentum response to metric perturbations in the fluid dynamic regime</a></h3>
                    <p><strong>Authors:</strong> Tim Stoetzel, Rebekka Fechtner, Stefan Floerchinger</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-ph</p>
                    <p><strong>Summary:</strong> The interplay of relativistic fluid dynamics and spacetime geometry is discussed in the regime of small wave numbers and frequencies. A combination of gravitational Ward identities and fluid dynamic equations of motion in the Mueller-Israel-Stewart formulation is used to explicitly determine the retarded linear response of the energy-momentum tensor to metric perturbations. We also discuss applications to gravitational wave production and the damping of gravitational waves in a relativistic fluid.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16560v1" target="_blank">Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders</a></h3>
                    <p><strong>Authors:</strong> David Chanin, AdriÃ  Garriga-Alonso</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Sparse Autoencoders (SAEs) extract features from LLM internal activations, meant to correspond to single concepts. A core SAE training hyperparameter is L0: how many features should fire per token on average. Existing work compares SAE algorithms using sparsity--reconstruction tradeoff plots, implying L0 is a free parameter with no single correct value. In this work we study the effect of L0 on BatchTopK SAEs, and show that if L0 is not set precisely, the SAE fails to learn the underlying features of the LLM. If L0 is too low, the SAE will mix correlated features to improve reconstruction. If L0 is too high, the SAE finds degenerate solutions that also mix features. Further, we demonstrate a method to determine the correct L0 value for an SAE on a given training distribution, which finds the true L0 in toy models and coincides with peak sparse probing performance in LLMs. We find that most commonly used SAEs have an L0 that is too low. Our work shows that, to train SAEs with correct features, practitioners must set L0 correctly.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16557v1" target="_blank">Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution</a></h3>
                    <p><strong>Authors:</strong> Tainyi Zhang, Zheng-Peng Duan, Peng-Tao Jiang, Bo Li, Ming-Ming Cheng, Chun-Le Guo, Chongyi Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Diffusion-based real-world image super-resolution (Real-ISR) methods have demonstrated impressive performance. To achieve efficient Real-ISR, many works employ Variational Score Distillation (VSD) to distill pre-trained stable-diffusion (SD) model for one-step SR with a fixed timestep. However, due to the different noise injection timesteps, the SD will perform different generative priors. Therefore, a fixed timestep is difficult for these methods to fully leverage the generative priors in SD, leading to suboptimal performance. To address this, we propose a Time-Aware one-step Diffusion Network for Real-ISR (TADSR). We first introduce a Time-Aware VAE Encoder, which projects the same image into different latent features based on timesteps. Through joint dynamic variation of timesteps and latent features, the student model can better align with the input pattern distribution of the pre-trained SD, thereby enabling more effective utilization of SDs generative capabilities. To better activate the generative prior of SD at different timesteps, we propose a Time-Aware VSD loss that bridges the timesteps of the student model and those of the teacher model, thereby producing more consistent generative prior guidance conditioned on timesteps. Additionally, though utilizing the generative prior in SD at different timesteps, our method can naturally achieve controllable trade-offs between fidelity and realism by changing the timestep condition. Experimental results demonstrate that our method achieves both state-of-the-art performance and controllable SR results with only a single step.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16556v1" target="_blank">Spherical latent space models for social network analysis</a></h3>
                    <p><strong>Authors:</strong> Juan Sosa, Carlos Nosa</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.CO</p>
                    <p><strong>Summary:</strong> This article introduces a spherical latent space model for social network analysis, embedding actors on a hypersphere rather than in Euclidean space as in standard latent space models. The spherical geometry facilitates the representation of transitive relationships and community structure, naturally captures cyclical patterns, and ensures bounded distances, thereby mitigating degeneracy issues common in traditional approaches. Bayesian inference is performed via Markov chain Monte Carlo methods to estimate both latent positions and other model parameters. The approach is demonstrated using two benchmark social network datasets, yielding improved model fit and interpretability relative to conventional latent space models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16555v1" target="_blank">Transfer Learning via Lexical Relatedness: A Sarcasm and Hate Speech Case Study</a></h3>
                    <p><strong>Authors:</strong> Angelly Cabrera, Linus Lei, Antonio Ortega</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Detecting hate speech in non-direct forms, such as irony, sarcasm, and innuendos, remains a persistent challenge for social networks. Although sarcasm and hate speech are regarded as distinct expressions, our work explores whether integrating sarcasm as a pre-training step improves implicit hate speech detection and, by extension, explicit hate speech detection. Incorporating samples from ETHOS, Sarcasm on Reddit, and Implicit Hate Corpus, we devised two training strategies to compare the effectiveness of sarcasm pre-training on a CNN+LSTM and BERT+BiLSTM model. The first strategy is a single-step training approach, where a model trained only on sarcasm is then tested on hate speech. The second strategy uses sequential transfer learning to fine-tune models for sarcasm, implicit hate, and explicit hate. Our results show that sarcasm pre-training improved the BERT+BiLSTMs recall by 9.7%, AUC by 7.8%, and F1-score by 6% on ETHOS. On the Implicit Hate Corpus, precision increased by 7.8% when tested only on implicit samples. By incorporating sarcasm into the training process, we show that models can more effectively detect both implicit and explicit hate.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16554v1" target="_blank">Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations</a></h3>
                    <p><strong>Authors:</strong> Karan Shah, Attila Cangi</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, cs.LG, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Time-dependent density functional theory (TDDFT) is a widely used method to investigate electron dynamics under external time-dependent perturbations such as laser fields. In this work, we present a novel approach to accelerate electron dynamics simulations based on real time TDDFT using autoregressive neural operators as time-propagators for the electron density. By leveraging physics-informed constraints and featurization, and high-resolution training data, our model achieves superior accuracy and computational speed compared to traditional numerical solvers. We demonstrate the effectiveness of our model on a class of one-dimensional diatomic molecules under the influence of a range of laser parameters. This method has potential in enabling real-time, on-the-fly modeling of laser-irradiated molecules and materials with varying experimental parameters.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16553v1" target="_blank">TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine</a></h3>
                    <p><strong>Authors:</strong> Tim Langer, Matthias Widra, Volkhard Beyer</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV, cs.ET, cs.SY, eess.SP, eess.SY, I.2.1; I.5.4; C.5.3; C.3</p>
                    <p><strong>Summary:</strong> In the context of industry 4.0, long-serving industrial machines can be retrofitted with process monitoring capabilities for future use in a smart factory. One possible approach is the deployment of wireless monitoring systems, which can benefit substantially from the TinyML paradigm. This work presents a complete TinyML flow from dataset generation, to machine learning model development, up to implementation and evaluation of a full preprocessing and classification pipeline on a microcontroller. After a short review on TinyML in industrial process monitoring, the creation of the novel MillingVibes dataset is described. The feasibility of a TinyML system for structure-integrated process quality monitoring could be shown by the development of an 8-bit-quantized convolutional neural network (CNN) model with 12.59kiB parameter storage. A test accuracy of 100.0% could be reached at 15.4ms inference time and 1.462mJ per quantized CNN inference on an ARM Cortex M4F microcontroller, serving as a reference for future TinyML process monitoring solutions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16547v1" target="_blank">Microscopic field theories of the quantum skyrmion Hall effect</a></h3>
                    <p><strong>Authors:</strong> Vinay Patil, Archi Banerjee, Ashley M. Cook</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> hep-th, cond-mat.str-el, math-ph, math.MP, quant-ph</p>
                    <p><strong>Summary:</strong> We construct effective field theories of the quantum skyrmion Hall effect from matrix Chern-Simons theory for $N$ electrons, corresponding to matrix dimension $N$. We first consider a quantum Hall droplet within finite $N$ matrix Chern-Simons theory. Taking into account the differential geometry of the matrix Chern-Simons droplet for a partially-filled fuzzy two-sphere, we first generalize the quantization procedure by replacing the Poisson bracket, a classical Lie derivative, with a quantum counterpart, the Lie derivative for a deformed fuzzy sphere. This yields the topological invariant introduced in earlier works on the quantum skyrmion Hall effect and previously unidentified fusion rules. This is consistent with treatment of a spin $S$ of multiplicity $2S+1$ as a quantum Hall droplet within matrix Chern-Simons theory for $N=2S+1$ spinless electrons and a generalization of a Jain composite particle for a Laughlin state. We then construct $D$-dimensional arrays of coupled small $N$ matrix Chern-Simons droplets as effective field theories of the quantum skyrmion Hall effect. In higher-symmetry constructions, this yields what appears to be a D+1 dimensional $U(N)$ Yang-Mills theory, but actually contains $\delta$ extra fuzzy dimensions from the finite $N$ MCS theory as well as deformations from $U(N)$ due to partial filling of the fuzzy spheres. In this construction, the Chern-Simons level is $k+1$ for each small $N$ droplet, while the entire array can be interpreted as an unbounded matrix Chern-Simons theory at level $k$. Such constructions at $k=2$ are consistent with earlier results for the multiplicative Chern insulator. We also formulate the quantum skyrmion Hall effect in terms of a Lagrangian for an array of potentially distinct, small $N$ droplets within anisotropic fuzzification. We discuss the relevance of these results to spin lattice models and lattice gauge theories.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16539v1" target="_blank">A Bayesian framework for opinion dynamics models</a></h3>
                    <p><strong>Authors:</strong> Yen-Shao Chen, Tauhid Zaman</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> econ.TH, cs.GT, cs.SI, physics.soc-ph</p>
                    <p><strong>Summary:</strong> This work introduces a Bayesian framework that unifies a wide class of opinion dynamics models. In this framework, an individuals opinion on a topic is the expected value of their belief, represented as a random variable with a prior distribution. Upon receiving a signal, modeled as the prior belief plus a bias term and subject to zero-mean noise with a known distribution, the individual updates their belief distribution via Bayes rule. By systematically varying the prior, bias, and noise distributions, this approach recovers a broad array of opinion dynamics models, including DeGroot, bounded confidence, bounded shift, and models exhibiting overreaction or backfire effects. Our analysis shows that the signal score is the key determinant of each models mathematical structure, governing both small- and large-signal behavior. All models converge to DeGroots linear update rule for small signals, but diverge in their tail behavior for large signals. This unification not only reveals theoretical linkages among previously disconnected models but also provides a systematic method for generating new ones, offering insights into the rational foundations of opinion formation under cognitive constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16538v1" target="_blank">Probing Reheating in a Decaying Oscillatory Inflationary Model with Latest ACT Constraints</a></h3>
                    <p><strong>Authors:</strong> Li-Yang Chen, Rongrong Zha, Feng-Yi Zhang</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc</p>
                    <p><strong>Summary:</strong> Recent observations from the Atacama Cosmology Telescope (ACT) indicate a moderate upward shift in the scalar spectral index $n_s$ compared to Planck $2018$, thereby placing tighter constraints on inflationary scenarios. Motivated by these results, we investigate a decaying oscillatory Inflationary model inspired by minimal no-scale supergravity, characterized by the potential $V(\phi) = \lambda \phi^{2n} \sin^2(l/\phi^n)$. We perform a numerical analysis of the background dynamics and reheating process across a range of model parameters. The model yields robust predictions for $n_s$ and the tensor-to-scalar ratio $r$, in excellent agreement with current ACT data. Successful reheating in this model requires a large effective equation-of-state parameter approaching unity, consistent with both cosmic microwave background (CMB) and big bang nucleosynthesis (BBN) constraints. The corresponding number of inflationary $e$-folds increases with $n$ and is weakly sensitive to $l$. Overall, the model offers a simple yet predictive framework that captures both inflationary dynamics and post-inflationary reheating, and remains viable under the latest high-precision observations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16534v1" target="_blank">The NANOGrav 15 yr Data Set: Targeted Searches for Supermassive Black Hole Binaries</a></h3>
                    <p><strong>Authors:</strong> Nikita Agarwal, Gabriella Agazie, Akash Anumarlapudi, Anne M. Archibald, Zaven Arzoumanian, Jeremy G. Baier, Paul T. Baker, Bence Becsy, Laura Blecha, Adam Brazier, Paul R. Brook, Sarah Burke-Spolaor, Rand Burnette, Robin Case, J. Andrew Casey-Clyde, Yu-Ting Chang, Maria Charisi, Shami Chatterjee, Tyler Cohen, Paolo Coppi, James M. Cordes, Neil J. Cornish, Fronefield Crawford, H. Thankful Cromartie, Kathryn Crowter, Megan E. DeCesar, Paul B. Demorest, Heling Deng, Lankeswar Dey, Timothy Dolch, Daniel J. DOrazio, Ellis Eisenberg, Elizabeth C. Ferrara, William Fiore, Emmanuel Fonseca, Gabriel E. Freedman, Emiko C. Gardiner, Nate Garver-Daniels, Peter A. Gentile, Kyle A. Gersbach, Joseph Glaser, Matthew J. Graham, Deborah C. Good, Kayhan Gultekin, C. J. Harris, Jeffrey S. Hazboun, Forrest Hutchison, Ross J. Jennings, Aaron D. Johnson, Megan L. Jones, David L. Kaplan, Luke Zoltan Kelley, Matthew Kerr, Joey S. Key, Nima Laal, Michael T. Lam, William G. Lamb, Bjorn Larsen, T. Joseph W. Lazio, Natalia Lewandowska, Tingting Liu, Duncan R. Lorimer, Jing Luo, Ryan S. Lynch, Chung-Pei Ma, Dustin R. Madison, Cayenne Matt, Alexander McEwen, James W. McKee, Maura A. McLaughlin, Natasha McMann, Bradley W. Meyers, Patrick M. Meyers, Chiara M. F. Mingarelli, Andrea Mitridate, Priyamvada Natarajan, Cherry Ng, David J. Nice, Stella Koch Ocker, Ken D. Olum, Timothy T. Pennucci, Benetge B. P. Perera, Polina Petrov, Nihan S. Pol, Henri A. Radovan, Scott M. Ransom, Paul S. Ray, Joseph D. Romano, Jessie C. Runnoe, Alexander Saffer, Shashwat C. Sardesai, Ann Schmiedekamp, Carl Schmiedekamp, Kai Schmitz, Federico Semenzato, Brent J. Shapiro-Albert, Rohan Shivakumar, Xavier Siemens, Joseph Simon, Sophia V. Sosa Fiscella, Ingrid H. Stairs, Daniel R. Stinebring, Kevin Stovall, Abhimanyu Susobhanan, Joseph K. Swiggum, Jacob A. Taylor, Stephen R. Taylor, Mercedes S. Thompson, Jacob E. Turner, Michele Vallisneri, Rutger van Haasteren, Sarah J. Vigeland, Haley M. Wahl, London Willson, Kevin P. Wilson, Caitlin A. Witt, David Wright, Olivia Young, Qinyuan Zheng</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, astro-ph.CO, gr-qc</p>
                    <p><strong>Summary:</strong> We present the first catalog of targeted searches for continuous gravitational waves (CWs) from 114 active galactic nuclei (AGN) that may host supermassive black hole binaries (SMBHBs), using the NANOGrav 15 yr data set. By incorporating electromagnetic priors on sky location, distance, redshift, and CW frequency, our strain and chirp mass upper limits are on average 2.6$\times$ more constraining than sky-averaged limits. Bayesian model comparisons against a common uncorrelated red noise for the gravitational wave background (GWB) disfavor a CW signal for almost all targets, yielding a mean Bayes factor of $0.87 \pm 0.31$. There are two notable exceptions: SDSS J153636.22+044127.0, ``Rohan with $\mathrm{BF} = 3.37(5)$, and SDSS J072908.71+400836.6, ``Gondor with $\mathrm{BF} = 2.44(3)$. These Bayes factors correspond to p-values of $0.01$--$0.03$ ($1.9\sigma$--$2.3\sigma$) and $0.05$--$0.08$ ($1.4\sigma$--$1.6\sigma$), respectively, depending on the empirical null distribution. We outline the beginnings of a detection protocol by identifying and carrying out a battery of tests on Rohan and Gondor to verify their binary nature. Notably, when replacing the common uncorrelated red noise model with a Hellings--Downs correlated GWB, Rohans Bayes factor drops to $1.25(7)$, while Gondors increases to $3.2(1)$. Both have rich electromagnetic datasets, including optical and infrared variability and spectroscopic features that support their classification as SMBHB candidates, though this was discovered after the targeted searches were complete. Our results suggest more simulations are needed to confirm or refute the nature of these and future SMBHB candidates, while creating a roadmap for targeted CW detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16530v1" target="_blank">ACT-Era Constraints on Single-Field Inflation in $f(T)$ Teleparallel Gravity</a></h3>
                    <p><strong>Authors:</strong> Feng-Yi Zhang, Rongrong Zhai, Li-Yang Chen</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We reassess single-field slow-roll inflation in teleparallel gravity with $f(T)=C\,T^{2\delta+1}$, motivated by recent measurements from the Atacama Cosmology Telescope (ACT) that indicate a modest upward shift in the scalar spectral index $n_s$. Using analytic approximations together with high-precision numerical calculations, we compute primordial predictions for representative potentials: power-law monomials, hilltop models, and $E$-type plateaus. We find that torsional corrections controlled by $\delta$ generically suppress $r$ while keeping $n_s$ near its slow-roll value. As a result, modest positive $\delta$ can restore viability to sub-quadratic monomials and hilltop models that are disfavored in general relativity (GR), whereas $E$-type plateaus remain compatible only in a limited range of $\delta$: small $\delta$ may improve the fit but moderate $\delta$ drives the dynamics toward quadratic-like behaviour and increases $r$. These signatures are observationally testable: improved cosmic microwave background (CMB) B-mode measurements will further discriminate among potential classes and place quantitative bounds on torsional deviations from GR.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16528v1" target="_blank">Exploring null-entropy events: What do we learn when nothing happens?</a></h3>
                    <p><strong>Authors:</strong> Abhaya S. Hegde, AndrÃ© M. Timpanaro, Gabriel T. Landi</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cond-mat.stat-mech, quant-ph</p>
                    <p><strong>Summary:</strong> Fluctuation theorems establish that thermodynamic processes at the microscale can occasionally result in negative entropy production. At the microscale, another distinct possibility becomes more likely: processes where no entropy is produced overall. In this work, we explore the constraints imposed by such null-entropy events on the fluctuations of thermodynamic currents. By incorporating the probability of null-entropy events, we obtain tighter bounds on finite-time thermodynamic uncertainty relations derived from fluctuation theorems. We validate this framework using an example of a qudit SWAP engine.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16527v1" target="_blank">Towards Open World Detection: A Survey</a></h3>
                    <p><strong>Authors:</strong> Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, 68T45, A.1; I.2; I.4</p>
                    <p><strong>Summary:</strong> For decades, Computer Vision has aimed at enabling machines to perceive the external world. Initial limitations led to the development of highly specialized niches. As success in each task accrued and research progressed, increasingly complex perception tasks emerged. This survey charts the convergence of these tasks and, in doing so, introduces Open World Detection (OWD), an umbrella term we propose to unify class-agnostic and generally applicable detection models in the vision domain. We start from the history of foundational vision subdomains and cover key concepts, methodologies and datasets making up todays state-of-the-art landscape. This traverses topics starting from early saliency detection, foreground/background separation, out of distribution detection and leading up to open world object detection, zero-shot detection and Vision Large Language Models (VLLMs). We explore the overlap between these subdomains, their increasing convergence, and their potential to unify into a singular domain in the future, perception.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16522v1" target="_blank">On the Duality of Task and Actor Programming Models</a></h3>
                    <p><strong>Authors:</strong> Rohan Yadav, Joseph Guman, Sean Treichler, Michael Garland, Alex Aiken, Fredrik Kjolstad, Michael Bauer</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.PL, cs.DC</p>
                    <p><strong>Summary:</strong> Programming models for distributed and heterogeneous machines are rapidly growing in popularity to meet the demands of modern workloads. Task and actor models are common choices that offer different trade-offs between development productivity and achieved performance. Task-based models offer better productivity and composition of software, whereas actor-based models routinely deliver better peak performance due to lower overheads. While task-based and actor-based models appear to be different superficially, we demonstrate these programming models are duals of each other. Importantly, we show that this duality extends beyond functionality to performance, and elucidate techniques that let task-based systems deliver performance competitive with actor-based systems without compromising productivity. We apply these techniques to both Realm, an explicitly parallel task-based runtime, as well as Legion, an implicitly parallel task-based runtime. We show these techniques reduce Realms overheads by between 1.7-5.3x, coming within a factor of two of the overheads imposed by heavily optimized actor-based systems like Charm++ and MPI. We further show that our techniques enable between 1.3-5.0x improved strong scaling of unmodified Legion applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16519v1" target="_blank">The Community Index: A More Comprehensive Approach to Assessing Scholarly Impact</a></h3>
                    <p><strong>Authors:</strong> Arav Kumar, Cameron Sabet, Alessandro Hammond, Amelia Fiske, Bhav Jain, Deirdre Goode, Dharaa Suresha, Leo Anthony Celi, Lisa Soleymani Lehmann, Ned Mccague, Rawan Abulibdeh, Sameer Pradhan</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.DL, stat.CO</p>
                    <p><strong>Summary:</strong> The h index is a widely recognized metric for assessing the research impact of scholars, defined as the maximum value h such that the scholar has published h papers each cited at least h times. While it has proven useful measuring individual scholarly productivity and citation impact, the h index has limitations, such as an inability to account for interdisciplinary collaboration or demographic differences in citation patterns. Moreover, it is sometimes mistakenly treated as a measure of research quality, even though it only reflects how often work has been cited. While metric based evaluations of research have grown in importance in some areas of academia, such as medicine, these evaluations fail to consider other important aspects of intellectual work, such as representational and epistemic diversity in research. In this article, we propose a new metric called the c index, or the community index, which combines multiple dimensions of scholarly impact. This is important because a plurality of perspectives and lived experiences within author teams can promote epistemological reflection and humility as part of the creation and validation of scientific knowledge. The c index is a means of accounting for the often global, and increasingly interdisciplinary nature of contemporary research, in particular, the data that is collected, curated and analyzed in the process of scientific inquiry. While the c index provides a means of quantifying diversity within research teams, diversity is integral to the advancement of scientific excellence and should be actively fostered through formal recognition and valuation. We herein describe the mathematical foundation of the c index and demonstrate its potential to provide a more comprehensive representation and more multidimensional assessment of scientific contributions of research impact as compared to the h index.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16516v1" target="_blank">A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering</a></h3>
                    <p><strong>Authors:</strong> Lin Li, Chunyang Li, Yu Yin, Xiaohui Tao, Jianwei Zhang</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> In the realm of collaborative filtering recommendation systems, Graph Neural Networks (GNNs) have demonstrated remarkable performance but face significant challenges in deployment on resource-constrained edge devices due to their high embedding parameter requirements and computational costs. Using common quantization method directly on node embeddings may overlooks their graph based structure, causing error accumulation during message passing and degrading the quality of quantized embeddings.To address this, we propose Graph based Node-Aware Dynamic Quantization training for collaborative filtering (GNAQ), a novel quantization approach that leverages graph structural information to enhance the balance between efficiency and accuracy of GNNs for Top-K recommendation. GNAQ introduces a node-aware dynamic quantization strategy that adapts quantization scales to individual node embeddings by incorporating graph interaction relationships. Specifically, it initializes quantization intervals based on node-wise feature distributions and dynamically refines them through message passing in GNN layers. This approach mitigates information loss caused by fixed quantization scales and captures hierarchical semantic features in user-item interaction graphs. Additionally, GNAQ employs graph relation-aware gradient estimation to replace traditional straight-through estimators, ensuring more accurate gradient propagation during training. Extensive experiments on four real-world datasets demonstrate that GNAQ outperforms state-of-the-art quantization methods, including BiGeaR and N2UQ, by achieving average improvement in 27.8\% Recall@10 and 17.6\% NDCG@10 under 2-bit quantization. In particular, GNAQ is capable of maintaining the performance of full-precision models while reducing their model sizes by 8 to 12 times; in addition, the training time is twice as fast compared to quantization baseline methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16515v1" target="_blank">Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments</a></h3>
                    <p><strong>Authors:</strong> Hichem Cheriet, Khellat Kihel Badra, Chouraqui Samira</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI</p>
                    <p><strong>Summary:</strong> The most crucial challenges for UAVs are planning paths and avoiding obstacles in their way. In recent years, a wide variety of path-planning algorithms have been developed. These algorithms have successfully solved path-planning problems; however, they suffer from multiple challenges and limitations. To test the effectiveness and efficiency of three widely used algorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper conducts extensive experiments in 3D urban city environments cluttered with obstacles. Three experiments were designed with two scenarios each to test the aforementioned algorithms. These experiments consider different city map sizes, different altitudes, and varying obstacle densities and sizes in the environment. According to the experimental results, the A* algorithm outperforms the others in both computation efficiency and path quality. PSO is especially suitable for tight turns and dense environments, and RRT* offers a balance and works well across all experiments due to its randomized approach to finding solutions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16514v1" target="_blank">FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline</a></h3>
                    <p><strong>Authors:</strong> Parker Seegmiller, Kartik Mehta, Soumya Saha, Chenyang Tao, Shereen Oraby, Arpit Gupta, Tagyoung Chung, Mohit Bansal, Nanyun Peng</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Recent works improving LLM math reasoning with synthetic data have used unique setups, making comparison of data synthesis strategies impractical. This leaves many unanswered questions about the roles of different factors in the synthetic data pipeline, such as the impact of filtering low-quality problems. To address this gap, we introduce FLAMES, a Framework for LLM Assessment of Math rEasoning Data Synthesis, and perform a systematic study of 10 existing data synthesis strategies and multiple other factors impacting the performance of synthetic math reasoning data. Our FLAMES experiments provide several valuable insights about the optimal balance of difficulty and diversity of synthetic data. First, data agents designed to increase problem complexity lead to best improvements on most math metrics. Second, with a fixed data generation budget, keeping higher problem coverage is more important than keeping only problems with reliable solutions. Third, GSM8K- and MATH-based synthetic data can lead to improvements on competition-level benchmarks, showcasing easy-to-hard generalization. Leveraging insights from our FLAMES experiments, we design two novel data synthesis strategies for improving out-of-domain generalization and robustness. Further, we develop the FLAMES dataset, an effective blend of our novel and existing data synthesis strategies, outperforming public datasets on OlympiadBench (+15.7), CollegeMath (+4.5), GSMPlus (+6.5), and MATH (+3.1). Fine-tuning Qwen2.5-Math-7B on the FLAMES dataset achieves 81.4% on MATH, surpassing larger Llama3 405B, GPT-4o and Claude 3.5 Sonnet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16512v1" target="_blank">Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation</a></h3>
                    <p><strong>Authors:</strong> Chun-Peng Chang, Chen-Yu Wang, Julian Schmidt, Holger Caesar, Alain Pagani</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advancements in video generation have substantially improved visual quality and temporal coherence, making these models increasingly appealing for applications such as autonomous driving, particularly in the context of driving simulation and so-called world models. In this work, we investigate the effects of existing fine-tuning video generation approaches on structured driving datasets and uncover a potential trade-off: although visual fidelity improves, spatial accuracy in modeling dynamic elements may degrade. We attribute this degradation to a shift in the alignment between visual quality and dynamic understanding objectives. In datasets with diverse scene structures within temporal space, where objects or perspective shift in varied ways, these objectives tend to highly correlated. However, the very regular and repetitive nature of driving scenes allows visual quality to improve by modeling dominant scene motion patterns, without necessarily preserving fine-grained dynamic behavior. As a result, fine-tuning encourages the model to prioritize surface-level realism over dynamic accuracy. To further examine this phenomenon, we show that simple continual learning strategies, such as replay from diverse domains, can offer a balanced alternative by preserving spatial accuracy while maintaining strong visual quality.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.mechmachtheory.2025.106172" target="_blank">On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach</a></h3>
                    <p><strong>Authors:</strong> Otobong Jerome, Alexandr Klimchik, Alexander Maloletov, Geesara Kulathunga</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.RO, math.OC</p>
                    <p><strong>Summary:</strong> This work casts the kinodynamic planning problem for car-like vehicles as an optimization task to compute a minimum-time trajectory and its associated velocity profile, subject to boundary conditions on velocity, acceleration, and steering. The approach simultaneously optimizes both the spatial path and the sequence of acceleration and steering controls, ensuring continuous motion from a specified initial position and velocity to a target end position and velocity.The method analyzes the admissible control space and terrain to avoid local minima. The proposed method operates efficiently in simplicial complex environments, a preferred terrain representation for capturing intricate 3D landscapes. The problem is initially posed as a mixed-integer fractional program with quadratic constraints, which is then reformulated into a mixed-integer bilinear objective through a variable transformation and subsequently relaxed to a mixed-integer linear program using McCormick envelopes. Comparative simulations against planners such as MPPI and log-MPPI demonstrate that the proposed approach generates solutions 104 times faster while strictly adhering to the specified constraints</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16509v1" target="_blank">ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks</a></h3>
                    <p><strong>Authors:</strong> Manuel Reinhardt, GaÅ¡per TkaÄik, Pieter Rein ten Wolde</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.bio-ph, cond-mat.stat-mech, cs.IT, cs.LG, math.IT, q-bio.NC</p>
                    <p><strong>Summary:</strong> The ability to quantify information transmission is crucial for the analysis and design of natural and engineered systems. The information transmission rate is the fundamental measure for systems with time-varying signals, yet computing it is extremely challenging. In particular, the rate cannot be obtained directly from experimental time-series data without approximations, because of the high dimensionality of the signal trajectory space. Path Weight Sampling (PWS) is a computational technique that makes it possible to obtain the information rate exactly for any stochastic system. However, it requires a mathematical model of the system of interest, be it described by a master equation or a set of differential equations. Here, we present a technique that employs Machine Learning (ML) to develop a generative model from experimental time-series data, which is then combined with PWS to obtain the information rate. We demonstrate the accuracy of this technique, called ML-PWS, by comparing its results on synthetic time-series data generated from a non-linear model against ground-truth results obtained by applying PWS directly to the same model. We illustrate the utility of ML-PWS by applying it to neuronal time-series data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16508v1" target="_blank">Abmax: A JAX-based Agent-based Modeling Framework</a></h3>
                    <p><strong>Authors:</strong> Siddharth Chaturvedi, Ahmed El-Gazzar, Marcel van Gerven</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.MA, cs.SE</p>
                    <p><strong>Summary:</strong> Agent-based modeling (ABM) is a principal approach for studying complex systems. By decomposing a system into simpler, interacting agents, agent-based modeling (ABM) allows researchers to observe the emergence of complex phenomena. High-performance array computing libraries like JAX can help scale such computational models to a large number of agents by using automatic vectorization and just-in-time (JIT) compilation. One of the caveats of using JAX to achieve such scaling is that the shapes of arrays used in the computational model should remain immutable throughout the simulation. In the context of agent-based modeling (ABM), this can pose constraints on certain agent manipulation operations that require flexible data structures. A subset of which is represented by the ability to update a dynamically selected number of agents by applying distinct changes to them during a simulation. To this effect, we introduce Abmax, an ABM framework based on JAX that implements multiple just-in-time (JIT) compilable algorithms to provide this functionality. On the canonical predation model benchmark, Abmax achieves runtime performance comparable to state-of-the-art implementations. Further, we show that this functionality can also be vectorized, making it possible to run many similar agent-based models in parallel. We also present two examples in the form of a traffic-flow model and a financial market model to show the use case of Abmax.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16505v1" target="_blank">Automated discovery of heralded ballistic graph state generators for fusion-based photonic quantum computation</a></h3>
                    <p><strong>Authors:</strong> Gavin S. Hartnett, Dave Kielpinski, Smarak Maity, Pranav S. Mundada, Yuval Baum, Michael R. Hush</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Designing photonic circuits that prepare graph states with high fidelity and success probability is a central challenge in linear optical quantum computing. Existing approaches rely on hand-crafted designs or fusion-based assemblies. In the absence of multiplexing/boosting, both post-selected ballistic circuits and sequential fusion builds exhibit exponentially decreasing single-shot yields, motivating automated discovery of higher-success circuits. We present a general-purpose optimization framework for automated photonic circuit discovery using a novel polynomial-based simulation approach, enabling efficient strong simulation and gradient-based optimization. Our framework employs a two-pass optimization procedure: the first pass identifies a unitary transformation that prepares the desired state with perfect fidelity and maximal success probability, while the second pass implements a novel sparsification algorithm that reduces this solution to a compact photonic circuit with minimal beamsplitter count while preserving performance. This sparsification procedure often reveals underlying mathematical structure, producing highly simplified circuits with rational reflection coefficients. We demonstrate our approach by discovering optimized circuits for $3$-, $4$-, and $5$-qubit graph states across multiple equivalence classes. For 4-qubit states, our circuits achieve success probabilities of $2.053 \times 10^{-3}$ to $7.813 \times 10^{-3}$, outperforming the fusion baseline by up to $4.7 \times$. For 5-qubit states, we achieve $5.926 \times 10^{-5}$ to $1.157 \times 10^{-3}$, demonstrating up to $7.5 \times$ improvement. These results include the first known state preparation circuits for certain 5-qubit graph states.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16499v1" target="_blank">How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair</a></h3>
                    <p><strong>Authors:</strong> Kazuki Kusama, Honglin Shu, Masanari Kondo, Yasutaka Kamei</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Background: Large language models (LLMs) have greatly improved the accuracy of automated program repair (APR) methods. However, LLMs are constrained by high computational resource requirements. Aims: We focus on small language models (SLMs), which perform well even with limited computational resources compared to LLMs. We aim to evaluate whether SLMs can achieve competitive performance in APR tasks. Method: We conducted experiments on the QuixBugs benchmark to compare the bug-fixing accuracy of SLMs and LLMs. We also analyzed the impact of int8 quantization on APR performance. Results: The latest SLMs can fix bugs as accurately as--or even more accurately than--LLMs. Also, int8 quantization had minimal effect on APR accuracy while significantly reducing memory requirements. Conclusions: SLMs present a viable alternative to LLMs for APR, offering competitive accuracy with lower computational costs, and quantization can further enhance their efficiency without compromising effectiveness.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16498v1" target="_blank">Enhanced Successive Cancellation List Decoder for Long Polar Codes Targeting 6G Air Interface</a></h3>
                    <p><strong>Authors:</strong> Jiajie Li, Sihui Shen, Warren J. Gross</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> The 6th generation communication standards air interface requires innovation in channel coding to fulfill anticipated energy and area cost reduction requirements. In this paper, we propose algorithmic techniques to enable the implementation of long polar codes (e.g., length 8K bits) in next-generation communications standards by addressing key challenges in memory usage and computational complexity presented by successive decoding list (SCL) polar decoding. Perturbation-enhanced (PE) successive cancelation list (SCL) decoders with a list size of $L$ reach the decoding performance of the SCL decoder with a list size of $2L$. The proposed bias-enhanced (BE) SCL decoders, which simplifies the PE SCL decoder based on insights gained by an ablation study, returns similar decoding performance to PE SCL decoders. Also, proposed BE generalized partitioned SCL (GPSCL) decoders with a list size of $8$ have a $67\%$ reduction in the memory usage and similar decoding performance compared to SCL decoders with a list size of $16$. Furthermore, input-distribution-aware (IDA) decoding is applied to BE GPSCL decoders. Up to $5.4\times$ reduction in the computational complexity is achieved compared to SCL decoders with a list size of $16$. The degraded decoding performance is at most $0.05\text{ dB}$ compared to BE GPSCL decoders without IDA decoding.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1103/3xs5-km1v" target="_blank">Nonlinear Optical Spectroscopy of Nodal-Line Semimetals</a></h3>
                    <p><strong>Authors:</strong> Navdeep Rana, M. S. Mrudul, Amar Bharti, Sucharita Giri, Gopal Dixit</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.optics, cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.other</p>
                    <p><strong>Summary:</strong> Intense laser-driven nonlinear optical phenomena in two-dimensional (2D) nodal-line semimetals (NLS) exhibit complex mechanisms, particularly in the NbSi$_{x}$Te$_{2}$ material systems characterized by nonsymmorphic symmetry-protected band degeneracy. Our findings reveal how nonsymmorphic symmetry-protected band degeneracy fundamentally influences the materials nonlienar optical responses. Notably, the nonsymmorphic glide-mirror symmetry leads to the exclusive generation of odd-order harmonics from inversion-symmetry-broken NLS. Moreover, harmonics are emitted parallel and perpendicular to the driving lasers polarization. We demonstrate distinct generation mechanisms arise from intrachain and interchain processes, with their relative contributions varying significantly with the polarization of the driving laser pulse. The polarization-dependence exhibits two-fold anisotropy, with each harmonic order showing characteristic angular distributions of maximum yield. Additionally, our analysis of the ellipticity-dependence reveals an intricate interplay between interband and intraband mechanisms. These insights open new possibilities for controlling harmonic generation through precise tuning parameters of the driving laser and highlight the potentials of NLS materials to fabricate lightwave-based photonics, optoelectronic and quantum devices operating on ultrafast timescales.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16493v1" target="_blank">Higher G-theory of simplicial toric varieties and vanishing of Chow groups</a></h3>
                    <p><strong>Authors:</strong> Zeyu Shen</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> math.AG, math.KT, 19E08 (primary) 14C35 19A99 (secondary)</p>
                    <p><strong>Summary:</strong> This paper gives computations of all the $G$-theory groups of several classes of simplicial toric varieties, including all affine toric surfaces when the base field is algebraically closed and has characteristic zero, all weighted projective spaces over any field and resolution of singularities of all affine toric surfaces $\operatorname{Spec}(k[x,xy,xy^2,...,xy^d])$ over any field $k$. The $G$-theory groups $G_0,G_1,G_2$ are computed for the product of any two weighted projective spaces over any field. The dimension of the rational vector space $G_0(X)\otimes\mathbb{Q}$ for any complete, simplicial toric variety $X$ over an algebraically closed field of characteristic zero is shown to be equal to the sum of the Betti numbers of even degrees. We also prove that the Chow group $A^2(X)$ of codimension 2 cycles vanishes for any affine, smooth toric variety, thereby proving a special case of my conjecture that the order of this Chow group $A^2(X)$ divides the determinant of the matrix whose columns are the minimal generators of the fan for any affine, simplicial toric variety $X$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16491v1" target="_blank">Tracking flat bands via phonon-mediated interband scattering</a></h3>
                    <p><strong>Authors:</strong> Fabian Garmroudi, Xinlin Yan, Silke Paschen, Sean M. Thomas, Eric D. Bauer, Andrej Pustogow, Priscila F. S. Rosa</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Flat-band (FB) materials have emerged as promising platforms for exploring exotic quantum phases. While numerous candidates have recently been identified through spectroscopic techniques such as angle-resolved photoemission spectroscopy, central challenges remain on how to tune FBs towards the Fermi level $E_F$ and to understand their impact on low-energy excitations probed in electronic transport experiments. Here, we show that, by attributing the temperature dependence of the electrical resistivity at elevated temperatures to electron-phonon interband scattering, one can infer the position of FBs near $E_F$ across diverse material classes. As charge carriers scatter off phonons, interband transitions into FB states lead to distinctive sub- or superlinear resistivity at elevated temperatures, governed by the proximity of the FB to $E_F$. Our phenomenological model captures these universal transport behaviors observed across several recently studied FB compounds and offers a simple, broadly applicable method for detecting flat bands.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16489v1" target="_blank">Ensembles of Neural Surrogates for Parametric Sensitivity in Ocean Modeling</a></h3>
                    <p><strong>Authors:</strong> Yixuan Sun, Romain Egele, Sri Hari Krishna Narayana, Luke Van Roekel, Carmelo Gonzales, Steven Brus, Balu Nadiga, Sandeep Madireddy, Prasanna Balaprakash</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> physics.ao-ph, cs.LG</p>
                    <p><strong>Summary:</strong> Accurate simulations of the oceans are crucial in understanding the Earth system. Despite their efficiency, simulations at lower resolutions must rely on various uncertain parameterizations to account for unresolved processes. However, model sensitivity to parameterizations is difficult to quantify, making it challenging to tune these parameterizations to reproduce observations. Deep learning surrogates have shown promise for efficient computation of the parametric sensitivities in the form of partial derivatives, but their reliability is difficult to evaluate without ground truth derivatives. In this work, we leverage large-scale hyperparameter search and ensemble learning to improve both forward predictions, autoregressive rollout, and backward adjoint sensitivity estimation. Particularly, the ensemble method provides epistemic uncertainty of function value predictions and their derivatives, providing improved reliability of the neural surrogates in decision making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16488v1" target="_blank">SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being</a></h3>
                    <p><strong>Authors:</strong> Kayenat Fatmi, Mohammad Abbas</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> In the digital era, individuals are increasingly exposed to online harms such as toxicity, manipulation, and grooming, which often pose emotional and safety risks. Existing systems for detecting abusive content or issuing safety alerts operate in isolation and rarely combine digital safety with emotional well-being. In this paper, we present SafeSpace, a unified web application that integrates three modules: (1) toxicity detection in chats and screenshots using NLP models and Googles Perspective API, (2) a configurable safety ping system that issues emergency alerts with the users live location (longitude and latitude) via SMTP-based emails when check-ins are missed or SOS alerts are manually triggered, and (3) a reflective questionnaire that evaluates relationship health and emotional resilience. The system employs Firebase for alert management and a modular architecture designed for usability, privacy, and scalability. The experimental evaluation shows 93% precision in toxicity detection, 100% reliability in safety alerts under emulator tests, and 92% alignment between automated and manual questionnaire scoring. SafeSpace, implemented as a web application, demonstrates the feasibility of integrating detection, protection, and reflection within a single platform, with future deployment envisioned as a mobile application for broader accessibility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16486v1" target="_blank">Manifestations of flow topology in a quantum driven-dissipative system</a></h3>
                    <p><strong>Authors:</strong> Kilian Seibold, Greta Villa, Javier del Pino, Oded Zilberberg</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> In driven-dissipative bosonic systems, the interplay between coherent driving, inter-particle interactions and dissipation leads to a rich variety of non-equilibrium stationary states (NESS). In the semiclassical limit, the flow topology of phase-space dynamics governs the stability and structure of these dynamical phases. Consequently, topological transitions occur when the number of NESS, their chirality, or their connectivity changes, reflecting global reorganization in the systems dynamical phase-space landscape. Here, we study the corresponding topological signatures in a driven-dissipative quantum Kerr oscillator. Employing a Lindblad master equation and quantum trajectory methods, we reveal that quantum dynamics retain key topological features of the underlying classical flows, with clear signatures accessible via quantum state tomography and linear response. In this manner, we predict new phases that are not signaled by Liouvillian gap closing, thereby generalizing the conventional criteria for diagnosing phase transitions. Our findings position phase-space flow topology as a powerful tool to identify and control robust quantum phases, enabling advances in error correction and sensing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16484v1" target="_blank">HAMSA: Hijacking Aligned Compact Models via Stealthy Automation</a></h3>
                    <p><strong>Authors:</strong> Alexey Krylov, Iskander Vagizov, Dmitrii Korzh, Maryam Douiba, Azidine Guezzaz, Vladimir Kokh, Sergey D. Erokhin, Elena V. Tutubalina, Oleg Y. Rogov</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs), especially their compact efficiency-oriented variants, remain susceptible to jailbreak attacks that can elicit harmful outputs despite extensive alignment efforts. Existing adversarial prompt generation techniques often rely on manual engineering or rudimentary obfuscation, producing low-quality or incoherent text that is easily flagged by perplexity-based filters. We present an automated red-teaming framework that evolves semantically meaningful and stealthy jailbreak prompts for aligned compact LLMs. The approach employs a multi-stage evolutionary search, where candidate prompts are iteratively refined using a population-based strategy augmented with temperature-controlled variability to balance exploration and coherence preservation. This enables the systematic discovery of prompts capable of bypassing alignment safeguards while maintaining natural language fluency. We evaluate our method on benchmarks in English (In-The-Wild Jailbreak Prompts on LLMs), and a newly curated Arabic one derived from In-The-Wild Jailbreak Prompts on LLMs and annotated by native Arabic linguists, enabling multilingual assessment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16482v1" target="_blank">Decoherent histories with(out) objectivity in a (broken) apparatus</a></h3>
                    <p><strong>Authors:</strong> BenoÃ®t FertÃ©, Davide Farci, Xiangyu Cao</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> We characterize monitored quantum dynamics in a solvable model exhibiting a phase transition between a measurement apparatus and a scrambler. We show that approximate decoherent histories emerge in both phases with respect to a coarse-grained extensive observable. However, the apparatus phase, where quantum Darwinism emerges, is distinguished by the non-ergodicity of the histories and their correlation with the measured qubit, which selects an ensemble of preferred pointer states. Our results demonstrate a clear distinction between two notion of classicality, decoherent histories and environment-induced decoherence.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3744736.3749360" target="_blank">Designing Doable and Locally-adapted Action Cards for an Interactive Tabletop Game To Support Bottom-Up Flood Resilience</a></h3>
                    <p><strong>Authors:</strong> Linda Hirsch, James Fey, Katherine Isbister</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Serious games can support communities in becoming more flood resilient. However, the process of identifying and integrating locally relevant and doable actions into gameplay is complex and underresearched. We approached the challenge by collaborating with a community-led education center and applying an iterative and participatory design process of identifying and defining actions that may increase local applicability and relevance. The process comprised a field observation, two expert focus groups (n=4), and an online survey (n=13). Our findings identified 27 actions related to increasing or maintaining individuals and communities flood resilience, which we turned into 20 playing cards. These action cards are a part of a larger interactive tabletop game, which we are currently developing. Our work discusses the potential of card games to educate non-experts to increase flood resilience, and contributes to our process of identifying local needs and conditions, and turning them into engaging game artifacts for bottom-up empowerment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16479v1" target="_blank">Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization</a></h3>
                    <p><strong>Authors:</strong> Yupei Zhang, Xiaofei Wang, Anran Liu, Lequan Yu, Chao Li</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Histopathology remains the gold standard for cancer diagnosis and prognosis. With the advent of transcriptome profiling, multi-modal learning combining transcriptomics with histology offers more comprehensive information. However, existing multi-modal approaches are challenged by intrinsic multi-modal heterogeneity, insufficient multi-scale integration, and reliance on paired data, restricting clinical applicability. To address these challenges, we propose a disentangled multi-modal framework with four contributions: 1) To mitigate multi-modal heterogeneity, we decompose WSIs and transcriptomes into tumor and microenvironment subspaces using a disentangled multi-modal fusion module, and introduce a confidence-guided gradient coordination strategy to balance subspace optimization. 2) To enhance multi-scale integration, we propose an inter-magnification gene-expression consistency strategy that aligns transcriptomic signals across WSI magnifications. 3) To reduce dependency on paired data, we propose a subspace knowledge distillation strategy enabling transcriptome-agnostic inference through a WSI-only student model. 4) To improve inference efficiency, we propose an informative token aggregation module that suppresses WSI redundancy while preserving subspace semantics. Extensive experiments on cancer diagnosis, prognosis, and survival prediction demonstrate our superiority over state-of-the-art methods across multiple settings. Code is available at https://github.com/helenypzhang/Disentangled-Multimodal-Learning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16478v1" target="_blank">LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Doohee You, Andy Parisi, Zach Vander Velden, Lara Dantas Inojosa</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> The advent of Large Language Models (LLMs) has provided unprecedented capabilities for analyzing unstructured text data. However, deploying these models as reliable, robust, and scalable classifiers in production environments presents significant methodological challenges. Standard fine-tuning approaches can be resource-intensive and often struggle with the dynamic nature of real-world data distributions, which is common in the industry. In this paper, we propose a comprehensive, semi-supervised framework that leverages the zero- and few-shot capabilities of LLMs for building hierarchical text classifiers as a framework for a solution to these industry-wide challenges. Our methodology emphasizes an iterative, human-in-the-loop process that begins with domain knowledge elicitation and progresses through prompt refinement, hierarchical expansion, and multi-faceted validation. We introduce techniques for assessing and mitigating sequence-based biases and outline a protocol for continuous monitoring and adaptation. This framework is designed to bridge the gap between the raw power of LLMs and the practical need for accurate, interpretable, and maintainable classification systems in industry applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16474v1" target="_blank">Reinforcement Learning-based Control via Y-wise Affine Neural Networks (YANNs)</a></h3>
                    <p><strong>Authors:</strong> Austin Braniff, Yuhe Tian</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.LG, cs.SY, math.OC</p>
                    <p><strong>Summary:</strong> This work presents a novel reinforcement learning (RL) algorithm based on Y-wise Affine Neural Networks (YANNs). YANNs provide an interpretable neural network which can exactly represent known piecewise affine functions of arbitrary input and output dimensions defined on any amount of polytopic subdomains. One representative application of YANNs is to reformulate explicit solutions of multi-parametric linear model predictive control. Built on this, we propose the use of YANNs to initialize RL actor and critic networks, which enables the resulting YANN-RL control algorithm to start with the confidence of linear optimal control. The YANN-actor is initialized by representing the multi-parametric control solutions obtained via offline computation using an approximated linear system model. The YANN-critic represents the explicit form of the state-action value function for the linear system and the reward function as the objective in an optimal control problem (OCP). Additional network layers are injected to extend YANNs for nonlinear expressions, which can be trained online by directly interacting with the true complex nonlinear system. In this way, both the policy and state-value functions exactly represent a linear OCP initially and are able to eventually learn the solution of a general nonlinear OCP. Continuous policy improvement is also implemented to provide heuristic confidence that the linear OCP solution serves as an effective lower bound to the performance of RL policy. The YANN-RL algorithm is demonstrated on a clipped pendulum and a safety-critical chemical-reactive system. Our results show that YANN-RL significantly outperforms the modern RL algorithm using deep deterministic policy gradient, especially when considering safety constraints.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16471v1" target="_blank">Modeling of Far-Field Quantum Coherence by Dielectric Bodies Based on the Volume Integral Equation Method</a></h3>
                    <p><strong>Authors:</strong> Chengnian Huang, Hangyu Ge, Yijia Cheng, Zi He, Feng Liu, Wei E. I. Sha</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, physics.optics</p>
                    <p><strong>Summary:</strong> The Hong-Ou-Mandel (HOM) effect is a hallmark of nonclassical photon interference. Accurate modeling of angle-resolved two-photon correlations in complex dielectric structures remains challenging because no efficient numerical framework directly links classical electromagnetic quantities to quantum correlation functions. We present a unified theoretical and computational framework for evaluating far-field HOM interference from arbitrary dielectric bodies. By quantizing plane-wave scattering modes and computing their far-field responses with a volume integral equation (VIE) solver, we determine the second-order normalized correlation function without near-to-far-field transformations or perfectly matched layers. This enables efficient evaluation of frequency-domain correlations and time-domain coincidence counts for photon wave packets. The approach is validated against analytical results for dielectric spheres and applied to a polarization-converting Pancharatnam-Berry-phase metasurface, revealing strong angular dependence of quantum interference that correlates with the characteristics of the HOM dip. The framework offers a computationally efficient and physically transparent tool for exploring structure-dependent quantum correlations, with applications to quantum antennas, metasurface-based quantum state engineering, and quantum inverse design.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16469v1" target="_blank">A New Approach to Stability of Delay Differential Equations with Time-Varying Delays via Isospectral Reduction</a></h3>
                    <p><strong>Authors:</strong> Quinlan Leishman, Benjamin Webb</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> math.DS, 34D23 (Primary) 34D06, 93D23 (Secondary)</p>
                    <p><strong>Summary:</strong> Understanding how time delays impact the stability of a delay differential equation is important for modeling many natural and technological systems that experience time delays. Here we introduce a new stability criterion for delay-independent stability of these equations, called intrinsic stability, showing global exponential stability for a large class of nonautonomous nonlinear systems. Our approach is able to incorporate bounded time-varying delays, including those with certain types of discontinuities. The approach we take to prove this result is novel, associating the delay differential equation with a sequence of finite-dimensional matrices of increasing size and using the graph-theoretic technique of isospectral reduction to analyze this sequence. We give an application of these results to the problem of determining consistency for delayed reservoir computers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16467v1" target="_blank">Arbitrary-Scale 3D Gaussian Super-Resolution</a></h3>
                    <p><strong>Authors:</strong> Huimin Zeng, Yue Bai, Yun Fu</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Existing 3D Gaussian Splatting (3DGS) super-resolution methods typically perform high-resolution (HR) rendering of fixed scale factors, making them impractical for resource-limited scenarios. Directly rendering arbitrary-scale HR views with vanilla 3DGS introduces aliasing artifacts due to the lack of scale-aware rendering ability, while adding a post-processing upsampler for 3DGS complicates the framework and reduces rendering efficiency. To tackle these issues, we build an integrated framework that incorporates scale-aware rendering, generative prior-guided optimization, and progressive super-resolving to enable 3D Gaussian super-resolution of arbitrary scale factors with a single 3D model. Notably, our approach supports both integer and non-integer scale rendering to provide more flexibility. Extensive experiments demonstrate the effectiveness of our model in rendering high-quality arbitrary-scale HR views (6.59 dB PSNR gain over 3DGS) with a single model. It preserves structural consistency with LR views and across different scales, while maintaining real-time rendering speed (85 FPS at 1080p).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.16466v1" target="_blank">Analytic Tools for Harvesting Magic Resource in Curved Spacetime</a></h3>
                    <p><strong>Authors:</strong> Jiayue Yang, Dyuman Bhattacharya, Ming Zhang, Robert B. Mann</p>
                    <p><strong>Published:</strong> 8/22/2025</p>
                    <p><strong>Categories:</strong> quant-ph, gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> The quantum vacuum is not really empty; it is a reservoir of operationally accessible non-classical resources. Understanding how to extract these resources to fuel information processing is a core objective in quantum technologies and lies at the heart of relativistic quantum information (RQI). While earlier studies of quantum resource harvesting protocols relied primarily on numerical methods, we present, for the first time, exact analytic results for the transition probability and coherence of a qutrit Unruh-DeWitt detector interacting with a scalar field in anti-de Sitter spacetime of arbitrary dimension. Leveraging these results, we analytically investigate the harvesting of non-stabilizerness and demonstrate that stronger spacetime curvature and higher dimensionality significantly suppress the amount of extractable magic resource from the vacuum. Our analytic framework is readily applicable to other scenarios, laying the groundwork for further analytic studies in RQI.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

