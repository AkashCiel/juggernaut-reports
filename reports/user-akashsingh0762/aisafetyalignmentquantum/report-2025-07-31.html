
    
        <h1>ü§ñ AI Research Report</h1>
        
            <strong>Date:</strong> 2025-07-31<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ü§ñ AI Summary</h2>
                <p>## ai safety research

The collection of papers on AI safety research presents a diverse set of advancements and challenges, reflecting the multifaceted nature of this field. Among the prominent trends is the focus on improving AI model robustness and interpretability, as seen in the work on consistency of feature attribution in deep learning architectures and the safe deployment of offline reinforcement learning via action correction. These studies emphasize the importance of understanding and controlling AI behavior to ensure safety and reliability in real-world applications, especially in mission-critical domains like healthcare and autonomous systems.

Another significant trend is the development of methodologies to detect and mitigate AI vulnerabilities, particularly those related to adversarial attacks and hallucinations. For instance, the DISTIL framework for Trojan input inversion and the reinforcement learning approach to reduce hallucinations in summarization highlight ongoing efforts to enhance AI security and trustworthiness. Additionally, the exploration of AI-generated content detection and the ethical implications of AI biases, as discussed in papers on AI-generated face detection and political biases in language models, underscore the broader societal impacts of AI safety research. These studies collectively contribute to building safer AI systems by addressing both technical challenges and ethical considerations, paving the way for more secure and transparent AI technologies.

*Based on 50 research papers*

---

## quantum computing

The recent research landscape in quantum computing showcases significant advancements, particularly in quantum error correction, quantum simulations, and resource optimization, which are crucial for the development of scalable quantum technologies. A notable breakthrough is presented by Bittel and Leone, who provide an operational interpretation of the stabilizer entropy, a key component in magic-state resource theory. This work elucidates how quantum states transition from stabilizer states to universal quantum states, enhancing our understanding of quantum error correction and the simulation of quantum systems. This progress is essential for developing fault-tolerant quantum computers, which are necessary for practical quantum computing applications.

In the realm of quantum simulations, Spagnoli et al. explore the simulation of nuclear dynamics using quantum computers, demonstrating that time evolution of nuclear systems can be efficiently simulated with polynomial resources. This work offers exponential improvements over previous methods and hints at the feasibility of simulating nuclear reactions on early fault-tolerant quantum platforms. Additionally, Lee et al. demonstrate the potential of digital quantum simulation for studying transport phenomena in quantum spin systems using a superconducting-qubit-based device. These advancements indicate a growing trend towards leveraging quantum computers for complex simulations in physics, which could significantly impact fields like quantum chemistry, materials science, and fundamental physics. Overall, these developments underscore the critical role of quantum computing in advancing both theoretical understanding and practical applications across various scientific domains.

*Based on 50 research papers*</p>
            
        
        
        <h2>üìö Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2507.22886v1" target="_blank">Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation</a></h3>
                    <p><strong>Authors:</strong> Kaining Ying, Henghui Ding, Guanquan Jie, Yu-Gang Jiang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Referring audio-visual segmentation (RAVS) has recently seen significant advancements, yet challenges remain in integrating multimodal information and deeply understanding and reasoning about audiovisual content. To extend the boundaries of RAVS and facilitate future research in this field, we propose Omnimodal Referring Audio-Visual Segmentation (OmniAVS), a new dataset containing 2,098 videos and 59,458 multimodal referring expressions. OmniAVS stands out with three key innovations: (1) 8 types of multimodal expressions that flexibly combine text, speech, sound, and visual cues; (2) an emphasis on understanding audio content beyond just detecting their presence; and (3) the inclusion of complex reasoning and world knowledge in expressions. Furthermore, we introduce Omnimodal Instructed Segmentation Assistant (OISA), to address the challenges of multimodal reasoning and fine-grained understanding of audiovisual content in OmniAVS. OISA uses MLLM to comprehend complex cues and perform reasoning-based segmentation. Extensive experiments show that OISA outperforms existing methods on OmniAVS and achieves competitive results on other related tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22877v1" target="_blank">Consistency of Feature Attribution in Deep Learning Architectures for Multi-Omics</a></h3>
                    <p><strong>Authors:</strong> Daniel Claborne, Javier Flores, Samantha Erwin, Luke Durell, Rachel Richardson, Ruby Fore, Lisa Bramer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Machine and deep learning have grown in popularity and use in biological research over the last decade but still present challenges in interpretability of the fitted model. The development and use of metrics to determine features driving predictions and increase model interpretability continues to be an open area of research. We investigate the use of Shapley Additive Explanations (SHAP) on a multi-view deep learning model applied to multi-omics data for the purposes of identifying biomolecules of interest. Rankings of features via these attribution methods are compared across various architectures to evaluate consistency of the method. We perform multiple computational experiments to assess the robustness of SHAP and investigate modeling approaches and diagnostics to increase and measure the reliability of the identification of important features. Accuracy of a random-forest model fit on subsets of features selected as being most influential as well as clustering quality using only these features are used as a measure of effectiveness of the attribution method. Our findings indicate that the rankings of features resulting from SHAP are sensitive to the choice of architecture as well as different random initializations of weights, suggesting caution when using attribution methods on multi-view deep learning models applied to multi-omics data. We present an alternative, simple method to assess the robustness of identification of important biomolecules.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22876v1" target="_blank">Automatically discovering heuristics in a complex SAT solver with large language models</a></h3>
                    <p><strong>Authors:</strong> Yiwen Sun, Furong Ye, Zhihan Chen, Ke Wei, Shaowei Cai</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LO</p>
                    <p><strong>Summary:</strong> Satisfiability problem (SAT) is a cornerstone of computational complexity with broad industrial applications, and it remains challenging to optimize modern SAT solvers in real-world settings due to their intricate architectures. While automatic configuration frameworks have been developed, they rely on manually constrained search spaces and yield limited performance gains. This work introduces a novel paradigm which effectively optimizes complex SAT solvers via Large Language Models (LLMs), and a tool called AutoModSAT is developed. Three fundamental challenges are addressed in order to achieve superior performance: (1) LLM-friendly solver: Systematic guidelines are proposed for developing a modularized solver to meet LLMs compatibility, emphasizing code simplification, information share and bug reduction; (2) Automatic prompt optimization: An unsupervised automatic prompt optimization method is introduced to advance the diversity of LLMs output; (3) Efficient search strategy: We design a presearch strategy and an EA evolutionary algorithm for the final efficient and effective discovery of heuristics. Extensive experiments across a wide range of datasets demonstrate that AutoModSAT achieves 50% performance improvement over the baseline solver and achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover, AutoModSAT attains a 20% speedup on average compared to parameter-tuned alternatives of the SOTA solvers, showcasing the enhanced capability in handling complex problem instances. This work bridges the gap between AI-driven heuristics discovery and mission-critical system optimization, and provides both methodological advancements and empirically validated results for next-generation complex solver development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22873v1" target="_blank">LCS: An AI-based Low-Complexity Scaler for Power-Efficient Super-Resolution of Game Content</a></h3>
                    <p><strong>Authors:</strong> Simon Pochinda, Momen K. Tageldeen, Mark Thompson, Tony Rinaldi, Troy Giorshev, Keith Lee, Jie Zhou, Frederick Walls</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> The increasing complexity of content rendering in modern games has led to a problematic growth in the workload of the GPU. In this paper, we propose an AI-based low-complexity scaler (LCS) inspired by state-of-the-art efficient super-resolution (ESR) models which could offload the workload on the GPU to a low-power device such as a neural processing unit (NPU). The LCS is trained on GameIR image pairs natively rendered at low and high resolution. We utilize adversarial training to encourage reconstruction of perceptually important details, and apply reparameterization and quantization techniques to reduce model complexity and size. In our comparative analysis we evaluate the LCS alongside the publicly available AMD hardware-based Edge Adaptive Scaling Function (EASF) and AMD FidelityFX Super Resolution 1 (FSR1) on five different metrics, and find that the LCS achieves better perceptual quality, demonstrating the potential of ESR models for upscaling on resource-constrained devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22871v1" target="_blank">Tracking research software outputs in the UK</a></h3>
                    <p><strong>Authors:</strong> Domhnall Carlin, Austen Rainer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.DL, D.2.13</p>
                    <p><strong>Summary:</strong> Research software is crucial in the research process and the growth of Open Science underscores the importance of accessing research artifacts, like data and code, raising traceability challenges among outputs. While it is a clear principle that research code, along with other essential outputs, should be recognised as artifacts of the research process, the how of this principle remains variable. This study examines where UK academic institutions store and register software as a unique research output, searching the UKRIs Gateway to Research (GtR) metadata for publicly funded research software in the UK. The quantity of software reported as research outcomes remains low in proportion to other categories. Artifact sharing appears low, with one-quarter of the reported software having no links and 45% having either a missing or erroneous URL. Of the valid URLs, we find the single largest category is Public Commercial Code Repository, with GitHub being the host of 18% of all publicly funded research software listed. These observations are contrasted with past findings from 2023 and finally, we discuss the lack of artifact sharing in UK research, with resulting implications for the maintenance and evolution of research software. Without dissemination, research software risks demotion to a transient artifact, useful only to meet short term research demands but ultimately lost to the broader enterprise of science.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22865v1" target="_blank">Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue</a></h3>
                    <p><strong>Authors:</strong> Sahan Liyanaarachchi, Sennur Ulukus</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.SY, eess.SY, math.IT</p>
                    <p><strong>Summary:</strong> With the dawn of AI factories ushering a new era of computing supremacy, development of strategies to effectively track and utilize the available computing resources is garnering utmost importance. These computing resources are often modeled as Markov sources, which oscillate between free and busy states, depending on their internal load and external utilization, and are commonly referred to as Markov machines (MMs). Most of the prior work solely focuses on the problem of tracking these MMs, while often assuming a rudimentary decision process that governs their utilization. Our key observation is that the ultimate goal of tracking a MM is to properly utilize it. In this work, we consider the problem of maximizing the utility of a MM, where the utility is defined as the average revenue generated by the MM. Assuming a Poisson job arrival process and a query-based sampling procedure to sample the state of the MM, we find the optimal times to submit the available jobs to the MM so as to maximize the average revenue generated per unit job. We show that, depending on the parameters of the MM, the optimal policy is in the form of either a \emph{threshold policy} or a \emph{switching policy} based on the \emph{age of our estimate} of the state of the MM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22861v1" target="_blank">Conditions for building generalized action graphs from sequences</a></h3>
                    <p><strong>Authors:</strong> Sarah Klanderman, Katy McDicken, Amelia Tebbe</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.CO, 05A19, 05C05 (Primary)</p>
                    <p><strong>Summary:</strong> This paper explores the properties of directed graphs, termed generalized action graphs, which exhibit a strong connection to certain number sequences. Focusing on the structural and combinatorial aspects, we investigate the conditions under which specific sequences can generate generalized action graphs. Building upon prior research in this field, we analyze specific features of these graphs and how they correspond to patterns and properties in their sequences. These findings support a broader conclusion that establishes framework for identifying which sequences can produce generalized action graphs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22847v1" target="_blank">The Incomplete Bridge: How AI Research (Mis)Engages with Psychology</a></h3>
                    <p><strong>Authors:</strong> Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, Ziang Xiao</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Social sciences have accumulated a rich body of theories and methodologies for investigating the human mind and behaviors, while offering valuable insights into the design and understanding of Artificial Intelligence (AI) systems. Focusing on psychology as a prominent case, this study explores the interdisciplinary synergy between AI and the field by analyzing 1,006 LLM-related papers published in premier AI venues between 2023 and 2025, along with the 2,544 psychology publications they cite. Through our analysis, we identify key patterns of interdisciplinary integration, locate the psychology domains most frequently referenced, and highlight areas that remain underexplored. We further examine how psychology theories/frameworks are operationalized and interpreted, identify common types of misapplication, and offer guidance for more effective incorporation. Our work provides a comprehensive map of interdisciplinary engagement between AI and psychology, thereby facilitating deeper collaboration and advancing AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22844v1" target="_blank">RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents</a></h3>
                    <p><strong>Authors:</strong> Zijing Zhang, Ziyang Chen, Mingxiao Li, Zhaopeng Tu, Xiaolong Li</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> The development of autonomous agents for complex, long-horizon tasks is a central goal in AI. However, dominant training paradigms face a critical limitation: reinforcement learning (RL) methods that optimize solely for final task success often reinforce flawed or inefficient reasoning paths, a problem we term inefficient exploration. This leads to agents that are brittle and fail to generalize, as they learn to find solutions without learning how to reason coherently. To address this, we introduce RLVMR, a novel framework that integrates dense, process-level supervision into end-to-end RL by rewarding verifiable, meta-reasoning behaviors. RLVMR equips an agent to explicitly tag its cognitive steps, such as planning, exploration, and reflection, and provides programmatic, rule-based rewards for actions that contribute to effective problem-solving. These process-centric rewards are combined with the final outcome signal and optimized using a critic-free policy gradient method. On the challenging ALFWorld and ScienceWorld benchmarks, RLVMR achieves new state-of-the-art results, with our 7B model reaching an 83.6% success rate on the most difficult unseen task split. Our analysis confirms these gains stem from improved reasoning quality, including significant reductions in redundant actions and enhanced error recovery, leading to more robust, efficient, and interpretable agents.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22824v1" target="_blank">Bi-Level Optimization for Self-Supervised AI-Generated Face Detection</a></h3>
                    <p><strong>Authors:</strong> Mian Zou, Nan Zhong, Baosheng Yu, Yibing Zhan, Kede Ma</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> AI-generated face detectors trained via supervised learning typically rely on synthesized images from specific generators, limiting their generalization to emerging generative techniques. To overcome this limitation, we introduce a self-supervised method based on bi-level optimization. In the inner loop, we pretrain a vision encoder only on photographic face images using a set of linearly weighted pretext tasks: classification of categorical exchangeable image file format (EXIF) tags, ranking of ordinal EXIF tags, and detection of artificial face manipulations. The outer loop then optimizes the relative weights of these pretext tasks to enhance the coarse-grained detection of manipulated faces, serving as a proxy task for identifying AI-generated faces. In doing so, it aligns self-supervised learning more closely with the ultimate goal of AI-generated face detection. Once pretrained, the encoder remains fixed, and AI-generated faces are detected either as anomalies under a Gaussian mixture model fitted to photographic face features or by a lightweight two-layer perceptron serving as a binary classifier. Extensive experiments demonstrate that our detectors significantly outperform existing approaches in both one-class and binary classification settings, exhibiting strong generalization to unseen generators.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22814v1" target="_blank">Quantum Simulation of Nuclear Dynamics in First Quantization</a></h3>
                    <p><strong>Authors:</strong> Luca Spagnoli, Chiara Lissoni, Alessandro Roggero</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph, nucl-th</p>
                    <p><strong>Summary:</strong> The study of real time dynamics of nuclear systems is of great importance to provide theoretical predictions of cross sections relevant for both terrestrial experiments as well as applications in astrophysics. First principles simulations of these dynamical processes is however hindered by an exponential cost in classical resources and the possibility of performing scalable simulations using quantum computers is currently an active field of research. In this work we provide the first complete characterization of the resource requirements for studying nuclear dynamics with the full Leading Order (LO) pionless EFT Hamiltonian in first quantization employing simulation strategies using both product formulas as well as Quantum Signal Processing. In particular, we show that time evolution of such an Hamiltonian can be performed with polynomial resources in the number of particles, and logarithmic resources in the number of single-particle basis states. This result provides an exponential improvement compared with previous work on the same Hamiltonian model in second quantization. We find that interesting simulations for low energy nuclear scattering could be achievable with tens of millions of T gates and few hundred logical qubits suggesting that the study of simple nuclear reactions could be amenable for early fault tolerant quantum platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22813v1" target="_blank">DISTIL: Data-Free Inversion of Suspicious Trojan Inputs via Latent Diffusion</a></h3>
                    <p><strong>Authors:</strong> Hossein Mirzaei, Zeinab Taghavi, Sepehr Rezaee, Masoud Hadi, Moein Madadi, Mackenzie W. Mathis</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep neural networks have demonstrated remarkable success across numerous tasks, yet they remain vulnerable to Trojan (backdoor) attacks, raising serious concerns about their safety in real-world mission-critical applications. A common countermeasure is trigger inversion -- reconstructing malicious shortcut patterns (triggers) inserted by an adversary during training. Current trigger-inversion methods typically search the full pixel space under specific assumptions but offer no assurances that the estimated trigger is more than an adversarial perturbation that flips the model output. Here, we propose a data-free, zero-shot trigger-inversion strategy that restricts the search space while avoiding strong assumptions on trigger appearance. Specifically, we incorporate a diffusion-based generator guided by the target classifier; through iterative generation, we produce candidate triggers that align with the internal representations the model relies on for malicious behavior. Empirical evaluations, both quantitative and qualitative, show that our approach reconstructs triggers that effectively distinguish clean versus Trojaned models. DISTIL surpasses alternative methods by high margins, achieving up to 7.1% higher accuracy on the BackdoorBench dataset and a 9.4% improvement on trojaned object detection model scanning, offering a promising new direction for reliable backdoor defense without reliance on extensive data or strong prior assumptions about triggers. The code is available at https://github.com/AdaptiveMotorControlLab/DISTIL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22802v1" target="_blank">Advancing Fetal Ultrasound Image Quality Assessment in Low-Resource Settings</a></h3>
                    <p><strong>Authors:</strong> Dongli He, Hu Wang, Mohammad Yaqub</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Accurate fetal biometric measurements, such as abdominal circumference, play a vital role in prenatal care. However, obtaining high-quality ultrasound images for these measurements heavily depends on the expertise of sonographers, posing a significant challenge in low-income countries due to the scarcity of trained personnel. To address this issue, we leverage FetalCLIP, a vision-language model pretrained on a curated dataset of over 210,000 fetal ultrasound image-caption pairs, to perform automated fetal ultrasound image quality assessment (IQA) on blind-sweep ultrasound data. We introduce FetalCLIP$_{CLS}$, an IQA model adapted from FetalCLIP using Low-Rank Adaptation (LoRA), and evaluate it on the ACOUSLIC-AI dataset against six CNN and Transformer baselines. FetalCLIP$_{CLS}$ achieves the highest F1 score of 0.757. Moreover, we show that an adapted segmentation model, when repurposed for classification, further improves performance, achieving an F1 score of 0.771. Our work demonstrates how parameter-efficient fine-tuning of fetal ultrasound foundation models can enable task-specific adaptations, advancing prenatal care in resource-limited settings. The experimental code is available at: https://github.com/donglihe-hub/FetalCLIP-IQA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22799v1" target="_blank">Human Mobility in Epidemic Modeling</a></h3>
                    <p><strong>Authors:</strong> Xin Lu, Jiawei Feng, Shengjie Lai, Petter Holme, Shuo Liu, Zhanwei Du, Xiaoqian Yuan, Siqing Wang, Yunxuan Li, Xiaoyu Zhang, Yuan Bai, Xiaojun Duan, Wenjun Mei, Hongjie Yu, Suoyi Tan, Fredrik Liljeros</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SI, physics.data-an, physics.soc-ph, 91Cxx, 37M05, 91F99, J.3; J.4; K.4.1</p>
                    <p><strong>Summary:</strong> Human mobility forms the backbone of contact patterns through which infectious diseases propagate, fundamentally shaping the spatio-temporal dynamics of epidemics and pandemics. While traditional models are often based on the assumption that all individuals have the same probability of infecting every other individual in the population, a so-called random homogeneous mixing, they struggle to capture the complex and heterogeneous nature of real-world human interactions. Recent advancements in data-driven methodologies and computational capabilities have unlocked the potential of integrating high-resolution human mobility data into epidemic modeling, significantly improving the accuracy, timeliness, and applicability of epidemic risk assessment, contact tracing, and intervention strategies. This review provides a comprehensive synthesis of the current landscape in human mobility-informed epidemic modeling. We explore diverse sources and representations of human mobility data, and then examine the behavioral and structural roles of mobility and contact in shaping disease transmission dynamics. Furthermore, the review spans a wide range of epidemic modeling approaches, ranging from classical compartmental models to network-based, agent-based, and machine learning models. And we also discuss how mobility integration enhances risk management and response strategies during epidemics. By synthesizing these insights, the review can serve as a foundational resource for researchers and practitioners, bridging the gap between epidemiological theory and the dynamic complexities of human interaction while charting clear directions for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22792v1" target="_blank">Segment Anything for Video: A Comprehensive Review of Video Object Segmentation and Tracking from Past to Future</a></h3>
                    <p><strong>Authors:</strong> Guoping Xu, Jayaram K. Udupa, Yajun Yu, Hua-Chieh Shao, Songlin Zhao, Wei Liu, You Zhang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video Object Segmentation and Tracking (VOST) presents a complex yet critical challenge in computer vision, requiring robust integration of segmentation and tracking across temporally dynamic frames. Traditional methods have struggled with domain generalization, temporal consistency, and computational efficiency. The emergence of foundation models like the Segment Anything Model (SAM) and its successor, SAM2, has introduced a paradigm shift, enabling prompt-driven segmentation with strong generalization capabilities. Building upon these advances, this survey provides a comprehensive review of SAM/SAM2-based methods for VOST, structured along three temporal dimensions: past, present, and future. We examine strategies for retaining and updating historical information (past), approaches for extracting and optimizing discriminative features from the current frame (present), and motion prediction and trajectory estimation mechanisms for anticipating object dynamics in subsequent frames (future). In doing so, we highlight the evolution from early memory-based architectures to the streaming memory and real-time segmentation capabilities of SAM2. We also discuss recent innovations such as motion-aware memory selection and trajectory-guided prompting, which aim to enhance both accuracy and efficiency. Finally, we identify remaining challenges including memory redundancy, error accumulation, and prompt inefficiency, and suggest promising directions for future research. This survey offers a timely and structured overview of the field, aiming to guide researchers and practitioners in advancing the state of VOST through the lens of foundation models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22789v1" target="_blank">G-Core: A Simple, Scalable and Balanced RLHF Trainer</a></h3>
                    <p><strong>Authors:</strong> Junyu Wu, Weiming Chang, Xiaotao Liu, Guanyou He, Haoqiang Hong, Boqi Liu, Hongtao Tian, Tao Yang, Yunsheng Shi, Feng Lin, Ting Yao</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Reinforcement Learning from Human Feedback (RLHF) has become an increasingly popular paradigm for training large language models (LLMs) and diffusion models. While existing RLHF training systems have enabled significant progress, they often face challenges in scaling to multi-modal and diffusion workflows and adapting to dynamic workloads. In particular, current approaches may encounter limitations in controller scalability, flexible resource placement, and efficient orchestration when handling complex RLHF pipelines, especially in scenarios involving dynamic sampling or generative reward modeling. In this paper, we present \textbf{G-Core}, a simple, scalable, and balanced RLHF training framework designed to address these challenges. G-Core introduces a parallel controller programming model, enabling flexible and efficient orchestration of complex RLHF workflows without the bottlenecks of a single centralized controller. Furthermore, we propose a dynamic placement schema that adaptively partitions resources and schedules workloads, significantly reducing hardware idle time and improving utilization, even under highly variable training conditions. G-Core has successfully trained models that support WeChat product features serving a large-scale user base, demonstrating its effectiveness and robustness in real-world scenarios. Our results show that G-Core advances the state of the art in RLHF training, providing a solid foundation for future research and deployment of large-scale, human-aligned models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22781v1" target="_blank">HOLA: Enhancing Audio-visual Deepfake Detection via Hierarchical Contextual Aggregations and Efficient Pre-training</a></h3>
                    <p><strong>Authors:</strong> Xuecheng Wu, Danlei Huang, Heli Sun, Xinyi Yin, Yifan Wang, Hao Wang, Jia Zhang, Fei Wang, Peihao Guo, Suyu Xing, Junxiao Xue, Liang He</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Advances in Generative AI have made video-level deepfake detection increasingly challenging, exposing the limitations of current detection techniques. In this paper, we present HOLA, our solution to the Video-Level Deepfake Detection track of 2025 1M-Deepfakes Detection Challenge. Inspired by the success of large-scale pre-training in the general domain, we first scale audio-visual self-supervised pre-training in the multimodal video-level deepfake detection, which leverages our self-built dataset of 1.81M samples, thereby leading to a unified two-stage framework. To be specific, HOLA features an iterative-aware cross-modal learning module for selective audio-visual interactions, hierarchical contextual modeling with gated aggregations under the local-global perspective, and a pyramid-like refiner for scale-aware cross-grained semantic enhancements. Moreover, we propose the pseudo supervised singal injection strategy to further boost model performance. Extensive experiments across expert models and MLLMs impressivly demonstrate the effectiveness of our proposed HOLA. We also conduct a series of ablation studies to explore the crucial design factors of our introduced components. Remarkably, our HOLA ranks 1st, outperforming the second by 0.0476 AUC on the TestA set.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22780v1" target="_blank">Euclid: Forecasts on $Œõ$CDM consistency tests with growth rate data</a></h3>
                    <p><strong>Authors:</strong> I. Ocampo, D. Sapone, S. Nesseris, G. Alestas, J. Garc√≠a-Bellido, Z. Sakr, C. J. A. P. Martins, J. P. Mimoso, A. Carvalho, A. Da Silva, A. Blanchard, S. Casas, S. Camera, M. Martinelli, V. Pettorino, A. Amara, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, A. Balestra, S. Bardelli, P. Battaglia, F. Bernardeau, A. Biviano, E. Branchini, M. Brescia, G. Ca√±as-Herrera, V. Capobianco, C. Carbone, V. F. Cardone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, H. Degaudenzi, S. de la Torre, G. De Lucia, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Farrens, F. Faustini, S. Ferriol, F. Finelli, P. Fosalba, N. Fourmanoit, M. Frailis, E. Franceschi, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keih√§nen, S. Kermiche, B. Kubik, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, O. Marggraf, K. Markovic, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, S. Pires, G. Polenta, M. Poncet, L. A. Popa, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, B. Sartoris, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-Cresp√≠, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, G. Zamorani, F. M. Zerbi, E. Zucca, M. Ballardini, C. Burigana, L. Gabarra, A. Pezzotta, V. Scottez, M. Viel</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> The large-scale structure (LSS) of the Universe is an important probe for deviations from the canonical cosmological constant $\Lambda$ and cold dark matter ($\Lambda$CDM) model. A statistically significant detection of any deviations would signify the presence of new physics or the breakdown of any number of the underlying assumptions of the standard cosmological model or possible systematic errors in the data. In this paper, we quantify the ability of the LSS data products of the spectroscopic survey of the Euclid mission, together with other contemporary surveys, to improve the constraints on deviations from $\Lambda$CDM in the redshift range $0z1.75$. We consider both currently available growth rate data and simulated data with specifications from Euclid and external surveys, based on $\Lambda$CDM and a modified gravity (MoG) model with an evolving Newtons constant (denoted $\mu$CDM), and carry out a binning method and a machine learning reconstruction, based on genetic algorithms (GAs), of several LSS null tests. Using the forecast Euclid growth data from the spectroscopic survey in the range $0.95z1.75$, we find that in combination with external data products (covering the range $0z0.95$), Euclid will be able to improve on current constraints of null tests of the LSS on average by a factor of eight when using a binning method and a factor of six when using the GAs. Our work highlights the need for synergies between Euclid and other surveys, but also the usefulness of statistical analyses, such as GAs, in order to disentangle any degeneracies in the cosmological parameters. Both are necessary to provide tight constraints over an extended redshift range and to probe for deviations from the $\Lambda$CDM model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22776v1" target="_blank">Label-free estimation of clinically relevant performance metrics under distribution shifts</a></h3>
                    <p><strong>Authors:</strong> Tim Fl√ºhmann, Alceu Bissoto, Trung-Dung Hoang, Lisa M. Koch</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Performance monitoring is essential for safe clinical deployment of image classification models. However, because ground-truth labels are typically unavailable in the target dataset, direct assessment of real-world model performance is infeasible. State-of-the-art performance estimation methods address this by leveraging confidence scores to estimate the target accuracy. Despite being a promising direction, the established methods mainly estimate the models accuracy and are rarely evaluated in a clinical domain, where strong class imbalances and dataset shifts are common. Our contributions are twofold: First, we introduce generalisations of existing performance prediction methods that directly estimate the full confusion matrix. Then, we benchmark their performance on chest x-ray data in real-world distribution shifts as well as simulated covariate and prevalence shifts. The proposed confusion matrix estimation methods reliably predicted clinically relevant counting metrics on medical images under distribution shifts. However, our simulated shift scenarios exposed important failure modes of current performance estimation techniques, calling for a better understanding of real-world deployment contexts when implementing these performance monitoring techniques for postmarket surveillance of medical AI models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22769v1" target="_blank">Bayesian Optimization applied for accelerated Virtual Validation of the Autonomous Driving Function</a></h3>
                    <p><strong>Authors:</strong> Satyesh Shanker Awasthi, Mohammed Irshadh Ismaaeel Sathyamangalam Imran, Stefano Arrigoni, Francesco Braghin</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.SY, eess.SY</p>
                    <p><strong>Summary:</strong> Rigorous Verification and Validation (VV) of Autonomous Driving Functions (ADFs) is paramount for ensuring the safety and public acceptance of Autonomous Vehicles (AVs). Current validation relies heavily on simulation to achieve sufficient test coverage within the Operational Design Domain (ODD) of a vehicle, but exhaustively exploring the vast parameter space of possible scenarios is computationally expensive and time-consuming. This work introduces a framework based on Bayesian Optimization (BO) to accelerate the discovery of critical scenarios. We demonstrate the effectiveness of the framework on an Model Predictive Controller (MPC)-based motion planner, showing that it identifies hazardous situations, such as off-road events, using orders of magnitude fewer simulations than brute-force Design of Experiments (DoE) methods. Furthermore, this study investigates the scalability of the framework in higher-dimensional parameter spaces and its ability to identify multiple, distinct critical regions within the ODD of the motion planner used as the case study .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22767v1" target="_blank">Teaching the Teacher: Improving Neural Network Distillability for Symbolic Regression via Jacobian Regularization</a></h3>
                    <p><strong>Authors:</strong> Soumyadeep Dhar, Kei Sen Fong, Mehul Motani</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Distilling large neural networks into simple, human-readable symbolic formulas is a promising path toward trustworthy and interpretable AI. However, this process is often brittle, as the complex functions learned by standard networks are poor targets for symbolic discovery, resulting in low-fidelity student models. In this work, we propose a novel training paradigm to address this challenge. Instead of passively distilling a pre-trained network, we introduce a \textbf{Jacobian-based regularizer} that actively encourages the ``teacher network to learn functions that are not only accurate but also inherently smoother and more amenable to distillation. We demonstrate through extensive experiments on a suite of real-world regression benchmarks that our method is highly effective. By optimizing the regularization strength for each problem, we improve the $R^2$ score of the final distilled symbolic model by an average of \textbf{120\% (relative)} compared to the standard distillation pipeline, all while maintaining the teachers predictive accuracy. Our work presents a practical and principled method for significantly improving the fidelity of interpretable models extracted from complex neural networks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22760v1" target="_blank">Of Good Demons and Bad Angels: Guaranteeing Safe Control under Finite Precision</a></h3>
                    <p><strong>Authors:</strong> Samuel Teuber, Debasmita Lohar, Bernhard Beckert</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.AI, cs.LG, cs.LO, cs.SY</p>
                    <p><strong>Summary:</strong> As neural networks (NNs) become increasingly prevalent in safety-critical neural network-controlled cyber-physical systems (NNCSs), formally guaranteeing their safety becomes crucial. For these systems, safety must be ensured throughout their entire operation, necessitating infinite-time horizon verification. To verify the infinite-time horizon safety of NNCSs, recent approaches leverage Differential Dynamic Logic (dL). However, these dL-based guarantees rely on idealized, real-valued NN semantics and fail to account for roundoff errors introduced by finite-precision implementations. This paper bridges the gap between theoretical guarantees and real-world implementations by incorporating robustness under finite-precision perturbations -- in sensing, actuation, and computation -- into the safety verification. We model the problem as a hybrid game between a good Demon, responsible for control actions, and a bad Angel, introducing perturbations. This formulation enables formal proofs of robustness w.r.t. a given (bounded) perturbation. Leveraging this bound, we employ state-of-the-art mixed-precision fixed-point tuners to synthesize sound and efficient implementations, thus providing a complete end-to-end solution. We evaluate our approach on case studies from the automotive and aeronautics domains, producing efficient NN implementations with rigorous infinite-time horizon safety guarantees.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22753v1" target="_blank">Opportunities and Challenges of LLMs in Education: An NLP Perspective</a></h3>
                    <p><strong>Authors:</strong> Sowmya Vajjala, Bashar Alhafni, Stefano Bann√≤, Kaushal Kumar Maurya, Ekaterina Kochmar</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Interest in the role of large language models (LLMs) in education is increasing, considering the new opportunities they offer for teaching, learning, and assessment. In this paper, we examine the impact of LLMs on educational NLP in the context of two main application scenarios: {\em assistance} and {\em assessment}, grounding them along the four dimensions -- reading, writing, speaking, and tutoring. We then present the new directions enabled by LLMs, and the key challenges to address. We envision that this holistic overview would be useful for NLP researchers and practitioners interested in exploring the role of LLMs in developing language-focused and NLP-enabled educational applications of the future.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22751v1" target="_blank">Characterization of mini-CryoCube detectors from the Ricochet experiment commissioning at the Institut Laue-Langevin</a></h3>
                    <p><strong>Authors:</strong> Antoine Armatol, Corinne Augier, Louis Bailly-Salins, Guillaume Baulieu, Laurent Berg√©, Julien Billard, Juliette Bl√©, Guillaume Bres, Jean-Louis Bret, Alexandre Broniatowski, Martino Calvo, Antonella Cavanna, Antoine Cazes, Emanuela Celi, David Chaize, Mohammed Chala, Maurice Chappellier, Luke Chaplinsky, Guillaume Chemin, Ran Chen, Jules Colas, Laurent Couraud, Elspeth Cudmore, Maryvonne De Jesus, Nicole Dombrowski, Louis Dumoulin, Alan Durnez, Olivier Exshaw, Sylvain Ferriol, Enectali Figueroa-Feliciano, Joseph A. Formaggio, Stephane Fuard, Jules Gascon, Andrea Giuliani, Corinne Goy, Cyrille Guerin, Elsa Guy, Le√Øla Haegel, Scott A. Hertel, Christophe Hoarau, Ziqing Hong, Jean-Christophe Ianigro, Yong Jin, Alexandre Juillard, Temirlan Khussainov, Andrew Kubik, Jacob Lamblin, Hugues Lattaud, Tatiana Le-Bellec, Laetitia Leroy, Mingyu Li, Alexey Lubashevskiy, Stefanos Marnieros, Nicolas Martini, Julien Minet, Alessandro Monfardini, Franck Mounier, Valentina Novati, Emiliano Olivieri, Pratyush K. Patel, Eric Perbet, Harold Douglas Pinckney, Denys V. Poda, Dmitrii Ponomarev, Wouter Van De Pontseele, Jean-S√©bastien Real, Faith C. Reyes, Alejandro Rodriguez, Murielle Rousseau, Sergey Rozov, Irina Rozova, Brianna Ryan, Deeksha Sabhari, Silvia Scorza, Renaud Serra, Yegor Shevchik, Torsten Soldner, Anne Stutz, Christian Ulysse, Lionel Vagneron, Sergey Vasilyev, Francis Vezzu, Paul Vittaz, Evgeny Yakushev, Jiatong Yang, Daniya Zinatulina</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM, hep-ex, physics.ins-det</p>
                    <p><strong>Summary:</strong> The Ricochet experiment aims to measure the coherent elastic neutrino-nucleus scattering process from antineutrinos emitted by a research nuclear reactor operated by the Institut Laue-Langevin (Grenoble, France). This article presents a description of the Ricochet experimental installation and the detector performance achieved during its commissioning with a mini-CryoCube module consisting of three 42-gram germanium cryogenic calorimeters. The baseline resolutions and background levels are reported both during reactor-on and reactor-off periods, and as noise mitigation techniques were improved. A baseline resolution of 40 eV electron equivalent was achieved for the ionization channel after setup improvements, and the phonon channel resolutions ranged from 50 to 80 eV of total phonon energy. In the energy region from 2 to 7 keV, a nuclear recoil rate of 15(2) events/(kg day keV) is measured during the reactor-off period selecting events in coincidence with muon veto signals. This rate is in agreement with the cosmogenic neutron rate calculated from GEANT4 simulations. After the rejection of events in coincidence with signals in the muon veto detectors, a combined 90% C.L. limit on the nuclear recoil background of  9 events/(kg day keV) is obtained in that energy region during the reactor-on period, which is compatible with our GEANT4 model calculation corresponding to a total rate of 5 events/(kg day keV). The sensitivity of this analysis was however found to be limited by a surface event contamination which is currently being addressed by the Ricochet Collaboration with upgraded detectors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22748v1" target="_blank">How Exposed Are UK Jobs to Generative AI? Developing and Applying a Novel Task-Based Index</a></h3>
                    <p><strong>Authors:</strong> Golo Henseke, Rhys Davies, Alan Felstead, Duncan Gallie, Francis Green, Ying Zhou</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> We introduce the Generative AI Susceptibility Index (GAISI), a task-based measure of UK job exposure to large language models (LLMs), such as ChatGPT. GAISI is derived from probabilistic task ratings by LLMs and linked to worker-reported task data from the Skills and Employment Surveys. It reflects the share of job activities where an LLM or LLM-powered system can reduce task completion time by at least 25 per cent beyond existing productivity tools. The index demonstrates high reliability, strong alignment with AI capabilities, and superior predictive power compared to existing exposure measures. By 2023-24, nearly all UK jobs exhibited some exposure, yet only a minority were heavily affected. Aggregate exposure has risen since 2017, primarily due to occupational shifts rather than changes in task profiles. The price premium for AI-exposed tasks declined relative to 2017, measuring approximately 11 per cent lower in 2023-24. Job postings in high-exposure roles also fell by 6.5 per cent following the release of ChatGPT. GAISI offers a robust framework for assessing generative AIs impact on work, providing early evidence that displacement effects may already outweigh productivity gains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22744v1" target="_blank">Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index</a></h3>
                    <p><strong>Authors:</strong> Praveenkumar Katwe, Rakesh Chandra, Balabantaray Kali, Prasad Vittala</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, 68T50, I.2.7</p>
                    <p><strong>Summary:</strong> Reducing hallucinations in abstractive summarization remains a critical challenge for deploying language models (LMs) in real-world settings. In this work, we introduce a rewarddriven fine-tuning framework that explicitly optimizes for Entity Hallucination Index (EHI), a metric designed to quantify the presence, correctness, and grounding of named entities in generated summaries. Given a corpus of meeting transcripts, we first generate baseline summaries using a pre-trained LM and compute EHI scores via automatic entity extraction and matching. We then apply reinforcement learning to fine-tune the model parameters, using EHI as a reward signal to bias generation toward entity-faithful outputs. Our approach does not rely on human-written factuality annotations, enabling scalable fine-tuning. Experiments demonstrate consistent improvements in EHI across datasets, with qualitative analysis revealing a significant reduction in entity-level hallucinations without degradation in fluency or informativeness. We release a reproducible Colab pipeline, facilitating further research on hallucination-aware model fine-tuning using lightweight, hallucintion metrics like EHI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22742v1" target="_blank">Social-Pose: Enhancing Trajectory Prediction with Human Body Pose</a></h3>
                    <p><strong>Authors:</strong> Yang Gao, Saeed Saadatnejad, Alexandre Alahi</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Accurate human trajectory prediction is one of the most crucial tasks for autonomous driving, ensuring its safety. Yet, existing models often fail to fully leverage the visual cues that humans subconsciously communicate when navigating the space. In this work, we study the benefits of predicting human trajectories using human body poses instead of solely their Cartesian space locations in time. We propose `Social-pose, an attention-based pose encoder that effectively captures the poses of all humans in a scene and their social relations. Our method can be integrated into various trajectory prediction architectures. We have conducted extensive experiments on state-of-the-art models (based on LSTM, GAN, MLP, and Transformer), and showed improvements over all of them on synthetic (Joint Track Auto) and real (Human3.6M, Pedestrians and Cyclists in Road Traffic, and JRDB) datasets. We also explored the advantages of using 2D versus 3D poses, as well as the effect of noisy poses and the application of our pose-based predictor in robot navigation scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22740v1" target="_blank">Foundations for Energy-Aware Zero-Energy Devices: From Energy Sensing to Adaptive Protocols</a></h3>
                    <p><strong>Authors:</strong> Onel L. A. L√≥pez, Mateen Ashraf, Samer Nasser, Gabriel M. de Jesus, Ritesh Kumar Singh, Miltiadis C. Filippou, Jeroen Famaey</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, 94Cxx, C.2.2; C.2.3; B.4.1; B.4.2; B.4.3; H.1.2</p>
                    <p><strong>Summary:</strong> Zero-energy devices (ZEDs) are key enablers of sustainable Internet of Things networks by operating solely on harvested ambient energy. Their limited and dynamic energy budget calls for protocols that are energy-aware and intelligently adaptive. However, designing effective energy-aware protocols for ZEDs requires theoretical models that realistically reflect device constraints. Indeed, existing approaches often oversimplify key aspects such as energy information (EI) acquisition, task-level variability, and energy storage dynamics, limiting their practical relevance and transferability. This article addresses this gap by offering a structured overview of the key modeling components, trade-offs, and limitations involved in energy-aware ZED protocol design. For this, we dissect EI acquisition methods and costs, characterize core operational tasks, analyze energy usage models and storage constraints, and review representative protocol strategies. Moreover, we offer design insights and guidelines on how ZED operation protocols can leverage EI, often illustrated through selected in-house examples. Finally, we outline key research directions to inspire more efficient and scalable protocol solutions for future ZEDs.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.bcra.2025.100274" target="_blank">Dynamic Exponent Market Maker: Personalized Portfolio Manager and One Pool to Trade Them All</a></h3>
                    <p><strong>Authors:</strong> Wittawat Kositwattanarerk</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> Decentralized exchange platforms such as Uniswap and Balancer operate on several pools where each pool contains two or more cryptocurrencies and constitutes direct trading pairs. The drawbacks here are that liquidity providing requires contribution of tokens in a specific proportion, and trading may require hopping between pools, hence increasing transaction fee and gas fee. We propose an automated market maker (AMM) protocol where liquidity providers can deposit any amount of tokens into the pool. The protocol will preserve the proportion of tokens by total value at the time of deposit and can be seen as a personalized self-balancing portfolio manager. In addition, since the invariant function is dynamic, all exchange pairs are executed from a single composite pool. Nevertheless, the scheme is vulnerable to flash loan attacks and must be used in conjunction with preventive measures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22720v1" target="_blank">Investigating Hallucination in Conversations for Low Resource Languages</a></h3>
                    <p><strong>Authors:</strong> Amit Das, Md. Najib Hasan, Souvika Sarkar, Zheng Zhang, Fatemeh Jamshidi, Tathagata Bhattacharya, Nilanjana Raychawdhury, Dongji Feng, Vinija Jain, Aman Chadha</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have demonstrated remarkable proficiency in generating text that closely resemble human writing. However, they often generate factually incorrect statements, a problem typically referred to as hallucination. Addressing hallucination is crucial for enhancing the reliability and effectiveness of LLMs. While much research has focused on hallucinations in English, our study extends this investigation to conversational data in three languages: Hindi, Farsi, and Mandarin. We offer a comprehensive analysis of a dataset to examine both factual and linguistic errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0, DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated responses in Mandarin but generate a significantly higher number of hallucinations in Hindi and Farsi.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22711v1" target="_blank">OFCnetLLM: Large Language Model for Network Monitoring and Alertness</a></h3>
                    <p><strong>Authors:</strong> Hong-Jun Yoon, Mariam Kiran, Danial Ebling, Joe Breen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.AI</p>
                    <p><strong>Summary:</strong> The rapid evolution of network infrastructure is bringing new challenges and opportunities for efficient network management, optimization, and security. With very large monitoring databases becoming expensive to explore, the use of AI and Generative AI can help reduce costs of managing these datasets. This paper explores the use of Large Language Models (LLMs) to revolutionize network monitoring management by addressing the limitations of query finding and pattern analysis. We leverage LLMs to enhance anomaly detection, automate root-cause analysis, and automate incident analysis to build a well-monitored network management team using AI. Through a real-world example of developing our own OFCNetLLM, based on the open-source LLM model, we demonstrate practical applications of OFCnetLLM in the OFC conference network. Our model is developed as a multi-agent approach and is still evolving, and we present early results here.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22692v1" target="_blank">Zero-Shot Image Anomaly Detection Using Generative Foundation Models</a></h3>
                    <p><strong>Authors:</strong> Lemar Abdi, Amaan Valiuddin, Francisco Caetano, Christiaan Viviers, Fons van der Sommen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Detecting out-of-distribution (OOD) inputs is pivotal for deploying safe vision systems in open-world environments. We revisit diffusion models, not as generators, but as universal perceptual templates for OOD detection. This research explores the use of score-based generative models as foundational tools for semantic anomaly detection across unseen datasets. Specifically, we leverage the denoising trajectories of Denoising Diffusion Models (DDMs) as a rich source of texture and semantic information. By analyzing Stein score errors, amplified through the Structural Similarity Index Metric (SSIM), we introduce a novel method for identifying anomalous samples without requiring re-training on each target dataset. Our approach improves over state-of-the-art and relies on training a single model on one dataset -- CelebA -- which we find to be an effective base distribution, even outperforming more commonly used datasets like ImageNet in several settings. Experimental results show near-perfect performance on some benchmarks, with notable headroom on others, highlighting both the strength and future potential of generative foundation models in anomaly detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22691v1" target="_blank">A Dual-Feature Extractor Framework for Accurate Back Depth and Spine Morphology Estimation from Monocular RGB Images</a></h3>
                    <p><strong>Authors:</strong> Yuxin Wei, Yue Zhang, Moxin Zhao, Chang Shi, Jason P. Y. Cheung, Teng Zhang, Nan Meng</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Scoliosis is a prevalent condition that impacts both physical health and appearance, with adolescent idiopathic scoliosis (AIS) being the most common form. Currently, the main AIS assessment tool, X-rays, poses significant limitations, including radiation exposure and limited accessibility in poor and remote areas. To address this problem, the current solutions are using RGB images to analyze spine morphology. However, RGB images are highly susceptible to environmental factors, such as lighting conditions, compromising model stability and generalizability. Therefore, in this study, we propose a novel pipeline to accurately estimate the depth information of the unclothed back, compensating for the limitations of 2D information, and then estimate spine morphology by integrating both depth and surface information. To capture the subtle depth variations of the back surface with precision, we design an adaptive multiscale feature learning network named Grid-Aware Multiscale Adaptive Network (GAMA-Net). This model uses dual encoders to extract both patch-level and global features, which are then interacted by the Patch-Based Hybrid Attention (PBHA) module. The Adaptive Multiscale Feature Fusion (AMFF) module is used to dynamically fuse information in the decoder. As a result, our depth estimation model achieves remarkable accuracy across three different evaluation metrics, with scores of nearly 78.2%, 93.6%, and 97.5%, respectively. To further validate the effectiveness of the predicted depth, we integrate both surface and depth information for spine morphology estimation. This integrated approach enhances the accuracy of spine curve generation, achieving an impressive performance of up to 97%.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22679v1" target="_blank">An alternative method of adjusting for multiple comparison in medical research</a></h3>
                    <p><strong>Authors:</strong> Jiale Li, Zimu Wei</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> stat.AP, stat.OT</p>
                    <p><strong>Summary:</strong> Background Most methods of adjusting for multiplicity focus primarily on controlling type I errors and rarely consider type II errors. We propose a new method that considers controlling for false-positive findings while ensuring sufficient statistical power. Methods We proposed a new method for multiple corrections called (Beta-exponential Adjustment, BEA) that considered the statistical power to control for type I errors while also considering the probability of type II errors. We conducted simulation studies to evaluate the performance characteristic of multiple testing correction procedures. We calculated sensitivity, specificity, and power separately for different sample sizes and number of biomarkers and compared them with the Bonferroni, Holm, and Benjamini-Hochberg (BH) correction methods. Results The results demonstrated that our proposed BEA correction method exhibited the highest sensitivity at different sample sizes and biomarkers (e.g., sensitivity: BEA 0.8 versus BH 0.62 at sample size at 1000, tested biomarkers at 1000 and positive rate at 30%). With different sample sizes and number of biomarkers, the BEA correction method demonstrated comparable specificity compared with traditional methods. Moreover, we observed that the BEA-corrected had the highest statistical power than other methods, when the outcome was relatively rare. Conclusion We proposed the BEA multiple correction method to adjust for multiple comparisons while considering statistical power. The BEA method demonstrated a higher sensitivity, comparable specificity, and higher statistical power, compared with traditional correction methods in different conditions. The BEA correction method can be an alternative of traditional methods of adjusting for multiplicity, especially in studies with small sample size, rare outcomes, or substantial number of biomarkers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22671v1" target="_blank">Designing for Self-Regulation in Informal Programming Learning: Insights from a Storytelling-Centric Approach</a></h3>
                    <p><strong>Authors:</strong> Sami Saeed Alghamdi, Christopher Bull, Ahmed Kharrufa</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CY, cs.SE, H.5.2; H.5.4</p>
                    <p><strong>Summary:</strong> Many people learn programming independently from online resources and often report struggles in achieving their personal learning goals. Learners frequently describe their experiences as isolating and frustrating, challenged by abundant uncertainties, information overload, and distraction, compounded by limited guidance. At the same time, social media serves as a personal space where many engage in diverse self-regulation practices, including help-seeking, using external memory aids (e.g., self-notes), self-reflection, emotion regulation, and self-motivation. For instance, learners often mark achievements and set milestones through their posts. In response, we developed a system consisting of a web platform and browser extensions to support self-regulation online. The design aims to add learner-defined structure to otherwise unstructured experiences and bring meaning to curation and reflection activities by translating them into learning stories with AI-generated feedback. We position storytelling as an integrative approach to design that connects resource curation, reflective and sensemaking practice, and narrative practices learners already use across social platforms. We recruited 15 informal programming learners who are regular social media users to engage with the system in a self-paced manner; participation concluded upon submitting a learning story and survey. We used three quantitative scales and a qualitative survey to examine users characteristics and perceptions of the systems support for their self-regulation. User feedback suggests the systems viability as a self-regulation aid. Learners particularly valued in-situ reflection, automated story feedback, and video annotation, while other features received mixed views. We highlight perceived benefits, friction points, and design opportunities for future AI-augmented self-regulation tools.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22666v1" target="_blank">Unconventional hybrid-order topological insulators</a></h3>
                    <p><strong>Authors:</strong> Wei Jia, Yuping Tian, Huanhuan Yang, Xiangru Kong, Zhi-Hao Huang, Wei-Jiang Gong, Jun-Hong An</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.str-el, quant-ph</p>
                    <p><strong>Summary:</strong> Exploring topological matters with exotic quantum states can update the understanding of topological phases and broaden the classification of topological materials. Here, we report a class of unconventional hybrid-order topological insulators (HyOTIs), which simultaneously host various different higher-order topological states in a single $d$-dimensional ($d$D) system. Such topological states exhibit a unique bulk-boundary correspondence that is different from first-order topological states, higher-order topological states, and the coexistence of both. Remarkably, we develop a generic surface theory to precisely capture them and firstly discover a $3$D unconventional HyOTI protected by inversion symmetry, which renders both second-order (helical) and third-order (corner) topological states in one band gap and exhibits a novel bulk-edge-corner correspondence. By adjusting the parameters of the system, we also observe the nontrivial phase transitions between the inversion-symmetric HyOTI and other conventional phases. We further propose a circuit-based experimental scheme to detect these interesting results. Particularly, we demonstrate that a modified tight-binding model of bismuth can support the unconventional HyOTI, suggesting a possible route for its material realization. This work shall significantly advance the research of hybrid topological states in both theory and experiment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22659v1" target="_blank">A Systematic Literature Review on Detecting Software Vulnerabilities with Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Sabrina Kaniewski, Fabian Schmidt, Markus Enzweiler, Michael Menth, Tobias Heer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> The increasing adoption of Large Language Models (LLMs) in software engineering has sparked interest in their use for software vulnerability detection. However, the rapid development of this field has resulted in a fragmented research landscape, with diverse studies that are difficult to compare due to differences in, e.g., system designs and dataset usage. This fragmentation makes it difficult to obtain a clear overview of the state-of-the-art or compare and categorize studies meaningfully. In this work, we present a comprehensive systematic literature review (SLR) of LLM-based software vulnerability detection. We analyze 227 studies published between January 2020 and June 2025, categorizing them by task formulation, input representation, system architecture, and adaptation techniques. Further, we analyze the datasets used, including their characteristics, vulnerability coverage, and diversity. We present a fine-grained taxonomy of vulnerability detection approaches, identify key limitations, and outline actionable future research opportunities. By providing a structured overview of the field, this review improves transparency and serves as a practical guide for researchers and practitioners aiming to conduct more comparable and reproducible research. We publicly release all artifacts and maintain a living repository of LLM-based software vulnerability detection studies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22640v1" target="_blank">Safe Deployment of Offline Reinforcement Learning via Input Convex Action Correction</a></h3>
                    <p><strong>Authors:</strong> Alex Durkin, Jasper Stolte, Matthew Jones, Raghuraman Pitchumani, Bei Li, Christian Michler, Mehmet Mercang√∂z</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.AI, cs.LG, cs.SY, stat.ML</p>
                    <p><strong>Summary:</strong> Offline reinforcement learning (offline RL) offers a promising framework for developing control strategies in chemical process systems using historical data, without the risks or costs of online experimentation. This work investigates the application of offline RL to the safe and efficient control of an exothermic polymerisation continuous stirred-tank reactor. We introduce a Gymnasium-compatible simulation environment that captures the reactors nonlinear dynamics, including reaction kinetics, energy balances, and operational constraints. The environment supports three industrially relevant scenarios: startup, grade change down, and grade change up. It also includes reproducible offline datasets generated from proportional-integral controllers with randomised tunings, providing a benchmark for evaluating offline RL algorithms in realistic process control tasks. We assess behaviour cloning and implicit Q-learning as baseline algorithms, highlighting the challenges offline agents face, including steady-state offsets and degraded performance near setpoints. To address these issues, we propose a novel deployment-time safety layer that performs gradient-based action correction using input convex neural networks (PICNNs) as learned cost models. The PICNN enables real-time, differentiable correction of policy actions by descending a convex, state-conditioned cost surface, without requiring retraining or environment interaction. Experimental results show that offline RL, particularly when combined with convex action correction, can outperform traditional control approaches and maintain stability across all scenarios. These findings demonstrate the feasibility of integrating offline RL with interpretable and safety-aware corrections for high-stakes chemical process control, and lay the groundwork for more reliable data-driven automation in industrial systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22635v1" target="_blank">trAIce3D: A Prompt-Driven Transformer Based U-Net for Semantic Segmentation of Microglial Cells from Large-Scale 3D Microscopy Images</a></h3>
                    <p><strong>Authors:</strong> MohammadAmin Alamalhoda, Arsalan Firoozi, Alessandro Venturino, Sandra Siegert</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> The shape of a cell contains essential information about its function within the biological system. Segmenting these structures from large-scale 3D microscopy images is challenging, limiting clinical insights especially for microglia, immune-associated cells involved in neurodegenerative diseases. Existing segmentation methods mainly focus on cell bodies, struggle with overlapping structures, perform poorly on noisy images, require hyperparameter tuning for each new dataset, or rely on tedious semi-automated approaches. We introduce trAIce3D, a deep-learning architecture designed for precise microglia segmentation, capturing both somas and branches. It employs a two-stage approach: first, a 3D U-Net with vision transformers in the encoder detects somas using a sliding-window technique to cover the entire image. Then, the same architecture, enhanced with cross-attention blocks in skip connections, refines each soma and its branches by using soma coordinates as a prompt and a 3D window around the target cell as input. Training occurs in two phases: self-supervised Soma Segmentation, followed by prompt-based Branch Segmentation, leveraging pre-trained weights from the first phase. Trained and evaluated on a dataset of 41,230 microglial cells, trAIce3D significantly improves segmentation accuracy and generalization, enabling scalable analysis of complex cellular morphologies. While optimized for microglia, its architecture can extend to other intricate cell types, such as neurons and astrocytes, broadening its impact on neurobiological research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22630v1" target="_blank">Parametric Amplification in Kerr Nonlinear Resonators: A theoretical review of Josephson Parametric Amplifiers</a></h3>
                    <p><strong>Authors:</strong> Rajlaxmi Bhoite, Shraddhanjali Choudhury</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> This paper presents a detailed theoretical review of the amplification process in Josephson Parametric Amplifiers (JPAs), which are crucial for quantum-limited signal amplification in superconducting circuits. The paper begins by outlining the principles of parametric amplification, focusing on how a strong classical pump interacts with the nonlinear Josephson medium in reflection geometry. The key dynamical equations are derived under intense pumping, leading to a nonlinear steady-state solution. Linearization around this solution allows to analyze the system response to weak signals and extract expressions for parametric gain and intermodulation gain using the input-output formalism. Numerically, the equations are solved to explore how the gain depends on frequency detuning and pump strength, which is visualized with a gain response curve. By enhancing our understanding of JPAs, this work aims to inspire continued research in the field of quantum-limited amplification.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22623v1" target="_blank">Multilingual Political Views of Large Language Models: Identification and Steering</a></h3>
                    <p><strong>Authors:</strong> Daniil Gurgurov, Katharina Trinley, Ivan Vykopal, Josef van Genabith, Simon Ostermann, Roberto Zamparelli</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are increasingly used in everyday tools and applications, raising concerns about their potential influence on political views. While prior research has shown that LLMs often exhibit measurable political biases--frequently skewing toward liberal or progressive positions--key gaps remain. Most existing studies evaluate only a narrow set of models and languages, leaving open questions about the generalizability of political biases across architectures, scales, and multilingual settings. Moreover, few works examine whether these biases can be actively controlled. In this work, we address these gaps through a large-scale study of political orientation in modern open-source instruction-tuned LLMs. We evaluate seven models, including LLaMA-3.1, Qwen-3, and Aya-Expanse, across 14 languages using the Political Compass Test with 11 semantically equivalent paraphrases per statement to ensure robust measurement. Our results reveal that larger models consistently shift toward libertarian-left positions, with significant variations across languages and model families. To test the manipulability of political stances, we utilize a simple center-of-mass activation intervention technique and show that it reliably steers model responses toward alternative ideological positions across multiple languages. Our code is publicly available at https://github.com/d-gurgurov/Political-Ideologies-LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22617v1" target="_blank">Hate in Plain Sight: On the Risks of Moderating AI-Generated Hateful Illusions</a></h3>
                    <p><strong>Authors:</strong> Yiting Qu, Ziqing Yang, Yihan Ma, Michael Backes, Savvas Zannettou, Yang Zhang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.CV</p>
                    <p><strong>Summary:</strong> Recent advances in text-to-image diffusion models have enabled the creation of a new form of digital art: optical illusions--visual tricks that create different perceptions of reality. However, adversaries may misuse such techniques to generate hateful illusions, which embed specific hate messages into harmless scenes and disseminate them across web communities. In this work, we take the first step toward investigating the risks of scalable hateful illusion generation and the potential for bypassing current content moderation models. Specifically, we generate 1,860 optical illusions using Stable Diffusion and ControlNet, conditioned on 62 hate messages. Of these, 1,571 are hateful illusions that successfully embed hate messages, either overtly or subtly, forming the Hateful Illusion dataset. Using this dataset, we evaluate the performance of six moderation classifiers and nine vision language models (VLMs) in identifying hateful illusions. Experimental results reveal significant vulnerabilities in existing moderation models: the detection accuracy falls below 0.245 for moderation classifiers and below 0.102 for VLMs. We further identify a critical limitation in their vision encoders, which mainly focus on surface-level image details while overlooking the secondary layer of information, i.e., hidden messages. To address this risk, we explore preliminary mitigation measures and identify the most effective approaches from the perspectives of image transformations and training-level strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22614v1" target="_blank">Exploring Student-AI Interactions in Vibe Coding</a></h3>
                    <p><strong>Authors:</strong> Francis Geng, Anshul Shah, Haolin Li, Nawab Mulla, Steven Swanson, Gerald Soosai Raj, Daniel Zingaro, Leo Porter</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY</p>
                    <p><strong>Summary:</strong> Background and Context. Chat-based and inline-coding-based GenAI has already had substantial impact on the CS Education community. The recent introduction of ``vibe coding may further transform how students program, as it introduces a new way for students to create software projects with minimal oversight. Objectives. The purpose of this study is to understand how students in introductory programming and advanced software engineering classes interact with a vibe coding platform (Replit) when creating software and how the interactions differ by programming background. Methods. Interview participants were asked to think-aloud while building a web application using Replit. Thematic analysis was then used to analyze the video recordings with an emphasis on the interactions between the student and Replit. Findings. For both groups, the majority of student interactions with Replit were to test or debug the prototype and only rarely did students visit code. Prompts by advanced software engineering students were much more likely to include relevant app feature and codebase contexts than those by introductory programming students.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22610v1" target="_blank">Metamorphic Testing of Deep Code Models: A Systematic Literature Review</a></h3>
                    <p><strong>Authors:</strong> Ali Asgari, Milan de Koning, Pouria Derakhshanfar, Annibale Panichella</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Large language models and deep learning models designed for code intelligence have revolutionized the software engineering field due to their ability to perform various code-related tasks. These models can process source code and software artifacts with high accuracy in tasks such as code completion, defect detection, and code summarization; therefore, they can potentially become an integral part of modern software engineering practices. Despite these capabilities, robustness remains a critical quality attribute for deep-code models as they may produce different results under varied and adversarial conditions (e.g., variable renaming). Metamorphic testing has become a widely used approach to evaluate models robustness by applying semantic-preserving transformations to input programs and analyzing the stability of model outputs. While prior research has explored testing deep learning models, this systematic literature review focuses specifically on metamorphic testing for deep code models. By studying 45 primary papers, we analyze the transformations, techniques, and evaluation methods used to assess robustness. Our review summarizes the current landscape, identifying frequently evaluated models, programming tasks, datasets, target languages, and evaluation metrics, and highlights key challenges and future directions for advancing the field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22607v1" target="_blank">VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning</a></h3>
                    <p><strong>Authors:</strong> Ruifeng Yuan, Chenghao Xiao, Sicong Leng, Jianyu Wang, Long Li, Weiwen Xu, Hou Pong Chan, Deli Zhao, Tingyang Xu, Zhongyu Wei, Hao Zhang, Yu Rong</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement learning has proven its effectiveness in enhancing the reasoning capabilities of large language models. Recent research efforts have progressively extended this paradigm to multimodal reasoning tasks. Due to the inherent complexity and diversity of multimodal tasks, especially in semantic content and problem formulations, existing models often exhibit unstable performance across various domains and difficulty levels. To address these limitations, we propose VL-Cogito, an advanced multimodal reasoning model trained via a novel multi-stage Progressive Curriculum Reinforcement Learning (PCuRL) framework. PCuRL systematically guides the model through tasks of gradually increasing difficulty, substantially improving its reasoning abilities across diverse multimodal contexts. The framework introduces two key innovations: (1) an online difficulty soft weighting mechanism, dynamically adjusting training difficulty across successive RL training stages; and (2) a dynamic length reward mechanism, which encourages the model to adaptively regulate its reasoning path length according to task complexity, thus balancing reasoning efficiency with correctness. Experimental evaluations demonstrate that VL-Cogito consistently matches or surpasses existing reasoning-oriented models across mainstream multimodal benchmarks spanning mathematics, science, logic, and general understanding, validating the effectiveness of our approach.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22604v1" target="_blank">ShortFT: Diffusion Model Alignment via Shortcut-based Fine-Tuning</a></h3>
                    <p><strong>Authors:</strong> Xiefan Guo, Miaomiao Cui, Liefeng Bo, Di Huang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Backpropagation-based approaches aim to align diffusion models with reward functions through end-to-end backpropagation of the reward gradient within the denoising chain, offering a promising perspective. However, due to the computational costs and the risk of gradient explosion associated with the lengthy denoising chain, existing approaches struggle to achieve complete gradient backpropagation, leading to suboptimal results. In this paper, we introduce Shortcut-based Fine-Tuning (ShortFT), an efficient fine-tuning strategy that utilizes the shorter denoising chain. More specifically, we employ the recently researched trajectory-preserving few-step diffusion model, which enables a shortcut over the original denoising chain, and construct a shortcut-based denoising chain of shorter length. The optimization on this chain notably enhances the efficiency and effectiveness of fine-tuning the foundational model. Our method has been rigorously tested and can be effectively applied to various reward functions, significantly improving alignment performance and surpassing state-of-the-art alternatives.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22603v1" target="_blank">BALSAM: A Platform for Benchmarking Arabic Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Rawan Al-Matham, Kareem Darwish, Raghad Al-Rasheed, Waad Alshammari, Muneera Alhoshan, Amal Almazrua, Asma Al Wazrah, Mais Alheraki, Firoj Alam, Preslav Nakov, Norah Alzahrani, Eman alBilali, Nizar Habash, Abdelrahman El-Sheikh, Muhammad Elmallah, Haonan Li, Hamdy Mubarak, Mohamed Anwar, Zaid Alyafeai, Ahmed Abdelali, Nora Altwairesh, Maram Hasanain, Abdulmohsen Al Thubaity, Shady Shehata, Bashar Alhafni, Injy Hamed, Go Inoue, Khalid Elmadani, Ossama Obeid, Fatima Haouari, Tamer Elsayed, Emad Alghamdi, Khalid Almubarak, Saied Alshahrani, Ola Aljarrah, Safa Alajlan, Areej Alshaqarawi, Maryam Alshihri, Sultana Alghurabi, Atikah Alzeghayer, Afrah Altamimi, Abdullah Alfaifi, Abdulrahman AlOsaimy</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The impressive advancement of Large Language Models (LLMs) in English has not been matched across all languages. In particular, LLM performance in Arabic lags behind, due to data scarcity, linguistic diversity of Arabic and its dialects, morphological complexity, etc. Progress is further hindered by the quality of Arabic benchmarks, which typically rely on static, publicly available data, lack comprehensive task coverage, or do not provide dedicated platforms with blind test sets. This makes it challenging to measure actual progress and to mitigate data contamination. Here, we aim to bridge these gaps. In particular, we introduce BALSAM, a comprehensive, community-driven benchmark aimed at advancing Arabic LLM development and evaluation. It includes 78 NLP tasks from 14 broad categories, with 52K examples divided into 37K test and 15K development, and a centralized, transparent platform for blind evaluation. We envision BALSAM as a unifying platform that sets standards and promotes collaborative research to advance Arabic LLM capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22589v1" target="_blank">Diffusion Models for Influence Maximization on Temporal Networks: A Guide to Make the Best Choice</a></h3>
                    <p><strong>Authors:</strong> Aaqib Zahoor, Iqra Altaf Gillani, Janibul Bashir</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SI</p>
                    <p><strong>Summary:</strong> The increasing prominence of temporal networks in online social platforms and dynamic communication systems has made influence maximization a critical research area. Various diffusion models have been proposed to capture the spread of information, yet selecting the most suitable model for a given scenario remains challenging. This article provides a structured guide to making the best choice among diffusion models for influence maximization on temporal networks. We categorize existing models based on their underlying mechanisms and assess their effectiveness in different network settings. We analyze seed selection strategies, highlighting how the inherent properties of influence spread enable the development of efficient algorithms that can find near-optimal sets of influential nodes. By comparing key advancements, challenges, and practical applications, we offer a comprehensive roadmap for researchers and practitioners to navigate the landscape of temporal influence maximization effectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22576v1" target="_blank">COOkeD: Ensemble-based OOD detection in the era of zero-shot CLIP</a></h3>
                    <p><strong>Authors:</strong> Galadrielle Humblot-Renaux, Gianni Franchi, Sergio Escalera, Thomas B. Moeslund</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Out-of-distribution (OOD) detection is an important building block in trustworthy image recognition systems as unknown classes may arise at test-time. OOD detection methods typically revolve around a single classifier, leading to a split in the research field between the classical supervised setting (e.g. ResNet18 classifier trained on CIFAR100) vs. the zero-shot setting (class names fed as prompts to CLIP). In both cases, an overarching challenge is that the OOD detection performance is implicitly constrained by the classifiers capabilities on in-distribution (ID) data. In this work, we show that given a little open-mindedness from both ends, remarkable OOD detection can be achieved by instead creating a heterogeneous ensemble - COOkeD combines the predictions of a closed-world classifier trained end-to-end on a specific dataset, a zero-shot CLIP classifier, and a linear probe classifier trained on CLIP image features. While bulky at first sight, this approach is modular, post-hoc and leverages the availability of pre-trained VLMs, thus introduces little overhead compared to training a single standard classifier. We evaluate COOkeD on popular CIFAR100 and ImageNet benchmarks, but also consider more challenging, realistic settings ranging from training-time label noise, to test-time covariate shift, to zero-shot shift which has been previously overlooked. Despite its simplicity, COOkeD achieves state-of-the-art performance and greater robustness compared to both classical and CLIP-based OOD detection methods. Code is available at https://github.com/glhr/COOkeD</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22570v1" target="_blank">Explaining Deep Network Classification of Matrices: A Case Study on Monotonicity</a></h3>
                    <p><strong>Authors:</strong> Leandro Farina, Sergey Korotov</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.NA, math.NA, 15B48, 68T07, 15A18, 62G32, I.2.6; I.5.2; G.1.3</p>
                    <p><strong>Summary:</strong> This work demonstrates a methodology for using deep learning to discover simple, practical criteria for classifying matrices based on abstract algebraic properties. By combining a high-performance neural network with explainable AI (XAI) techniques, we can distill a models learned strategy into human-interpretable rules. We apply this approach to the challenging case of monotone matrices, defined by the condition that their inverses are entrywise nonnegative. Despite their simple definition, an easy characterization in terms of the matrix elements or the derived parameters is not known. Here, we present, to the best of our knowledge, the first systematic machine-learning approach for deriving a practical criterion that distinguishes monotone from non-monotone matrices. After establishing a labelled dataset by randomly generated monotone and non-monotone matrices uniformly on $(-1,1)$, we employ deep neural network algorithms for classifying the matrices as monotone or non-monotone, using both their entries and a comprehensive set of matrix features. By saliency methods, such as integrated gradients, we identify among all features, two matrix parameters which alone provide sufficient information for the matrix classification, with $95\%$ accuracy, namely the absolute values of the two lowest-order coefficients, $c_0$ and $c_1$ of the matrixs characteristic polynomial. A data-driven study of 18,000 random $7\times7$ matrices shows that the monotone class obeys $\lvert c_{0}/c_{1}\rvert\le0.18$ with probability $99.98\%$; because $\lvert c_{0}/c_{1}\rvert = 1/\mathrm{tr}(A^{-1})$ for monotone $A$, this is equivalent to the simple bound $\mathrm{tr}(A^{-1})\ge5.7$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22886v1" target="_blank">Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation</a></h3>
                    <p><strong>Authors:</strong> Kaining Ying, Henghui Ding, Guanquan Jie, Yu-Gang Jiang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Referring audio-visual segmentation (RAVS) has recently seen significant advancements, yet challenges remain in integrating multimodal information and deeply understanding and reasoning about audiovisual content. To extend the boundaries of RAVS and facilitate future research in this field, we propose Omnimodal Referring Audio-Visual Segmentation (OmniAVS), a new dataset containing 2,098 videos and 59,458 multimodal referring expressions. OmniAVS stands out with three key innovations: (1) 8 types of multimodal expressions that flexibly combine text, speech, sound, and visual cues; (2) an emphasis on understanding audio content beyond just detecting their presence; and (3) the inclusion of complex reasoning and world knowledge in expressions. Furthermore, we introduce Omnimodal Instructed Segmentation Assistant (OISA), to address the challenges of multimodal reasoning and fine-grained understanding of audiovisual content in OmniAVS. OISA uses MLLM to comprehend complex cues and perform reasoning-based segmentation. Extensive experiments show that OISA outperforms existing methods on OmniAVS and achieves competitive results on other related tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22880v1" target="_blank">AUV-Fusion: Cross-Modal Adversarial Fusion of User Interactions and Visual Perturbations Against VARS</a></h3>
                    <p><strong>Authors:</strong> Hai Ling, Tianchi Wang, Xiaohao Liu, Zhulin Tao, Lifang Yang, Xianglin Huang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Modern Visual-Aware Recommender Systems (VARS) exploit the integration of user interaction data and visual features to deliver personalized recommendations with high precision. However, their robustness against adversarial attacks remains largely underexplored, posing significant risks to system reliability and security. Existing attack strategies suffer from notable limitations: shilling attacks are costly and detectable, and visual-only perturbations often fail to align with user preferences. To address these challenges, we propose AUV-Fusion, a cross-modal adversarial attack framework that adopts high-order user preference modeling and cross-modal adversary generation. Specifically, we obtain robust user embeddings through multi-hop user-item interactions and transform them via an MLP into semantically aligned perturbations. These perturbations are injected onto the latent space of a pre-trained VAE within the diffusion model. By synergistically integrating genuine user interaction data with visually plausible perturbations, AUV-Fusion eliminates the need for injecting fake user profiles and effectively mitigates the challenge of insufficient user preference extraction inherent in traditional visual-only attacks. Comprehensive evaluations on diverse VARS architectures and real-world datasets demonstrate that AUV-Fusion significantly enhances the exposure of target (cold-start) items compared to conventional baseline methods. Moreover, AUV-Fusion maintains exceptional stealth under rigorous scrutiny.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22879v1" target="_blank">RecGPT Technical Report</a></h3>
                    <p><strong>Authors:</strong> Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Mao Zhang, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL</p>
                    <p><strong>Summary:</strong> Recommender systems are among the most impactful applications of artificial intelligence, serving as critical infrastructure connecting users, merchants, and platforms. However, most current industrial systems remain heavily reliant on historical co-occurrence patterns and log-fitting objectives, i.e., optimizing for past user interactions without explicitly modeling user intent. This log-fitting approach often leads to overfitting to narrow historical preferences, failing to capture users evolving and latent interests. As a result, it reinforces filter bubbles and long-tail phenomena, ultimately harming user experience and threatening the sustainability of the whole recommendation ecosystem. To address these challenges, we rethink the overall design paradigm of recommender systems and propose RecGPT, a next-generation framework that places user intent at the center of the recommendation pipeline. By integrating large language models (LLMs) into key stages of user interest mining, item retrieval, and explanation generation, RecGPT transforms log-fitting recommendation into an intent-centric process. To effectively align general-purpose LLMs to the above domain-specific recommendation tasks at scale, RecGPT incorporates a multi-stage training paradigm, which integrates reasoning-enhanced pre-alignment and self-training evolution, guided by a Human-LLM cooperative judge system. Currently, RecGPT has been fully deployed on the Taobao App. Online experiments demonstrate that RecGPT achieves consistent performance gains across stakeholders: users benefit from increased content diversity and satisfaction, merchants and the platform gain greater exposure and conversions. These comprehensive improvement results across all stakeholders validates that LLM-driven, intent-centric design can foster a more sustainable and mutually beneficial recommendation ecosystem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22878v1" target="_blank">GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for Multiresolution Power Outage Analysis</a></h3>
                    <p><strong>Authors:</strong> Ethan Frakes, Yinghui Wu, Roger H. French, Mengjie Li</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Detecting, analyzing, and predicting power outages is crucial for grid risk assessment and disaster mitigation. Numerous outages occur each year, exacerbated by extreme weather events such as hurricanes. Existing outage data are typically reported at the county level, limiting their spatial resolution and making it difficult to capture localized patterns. However, it offers excellent temporal granularity. In contrast, nighttime light satellite image data provides significantly higher spatial resolution and enables a more comprehensive spatial depiction of outages, enhancing the accuracy of assessing the geographic extent and severity of power loss after disaster events. However, these satellite data are only available on a daily basis. Integrating spatiotemporal visual and time-series data sources into a unified knowledge representation can substantially improve power outage detection, analysis, and predictive reasoning. In this paper, we propose GeoOutageKG, a multimodal knowledge graph that integrates diverse data sources, including nighttime light satellite image data, high-resolution spatiotemporal power outage maps, and county-level timeseries outage reports in the U.S. We describe our method for constructing GeoOutageKG by aligning source data with a developed ontology, GeoOutageOnto. Currently, GeoOutageKG includes over 10.6 million individual outage records spanning from 2014 to 2024, 300,000 NTL images spanning from 2012 to 2024, and 15,000 outage maps. GeoOutageKG is a novel, modular and reusable semantic resource that enables robust multimodal data integration. We demonstrate its use through multiresolution analysis of geospatiotemporal power outages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22877v1" target="_blank">Consistency of Feature Attribution in Deep Learning Architectures for Multi-Omics</a></h3>
                    <p><strong>Authors:</strong> Daniel Claborne, Javier Flores, Samantha Erwin, Luke Durell, Rachel Richardson, Ruby Fore, Lisa Bramer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Machine and deep learning have grown in popularity and use in biological research over the last decade but still present challenges in interpretability of the fitted model. The development and use of metrics to determine features driving predictions and increase model interpretability continues to be an open area of research. We investigate the use of Shapley Additive Explanations (SHAP) on a multi-view deep learning model applied to multi-omics data for the purposes of identifying biomolecules of interest. Rankings of features via these attribution methods are compared across various architectures to evaluate consistency of the method. We perform multiple computational experiments to assess the robustness of SHAP and investigate modeling approaches and diagnostics to increase and measure the reliability of the identification of important features. Accuracy of a random-forest model fit on subsets of features selected as being most influential as well as clustering quality using only these features are used as a measure of effectiveness of the attribution method. Our findings indicate that the rankings of features resulting from SHAP are sensitive to the choice of architecture as well as different random initializations of weights, suggesting caution when using attribution methods on multi-view deep learning models applied to multi-omics data. We present an alternative, simple method to assess the robustness of identification of important biomolecules.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22876v1" target="_blank">Automatically discovering heuristics in a complex SAT solver with large language models</a></h3>
                    <p><strong>Authors:</strong> Yiwen Sun, Furong Ye, Zhihan Chen, Ke Wei, Shaowei Cai</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LO</p>
                    <p><strong>Summary:</strong> Satisfiability problem (SAT) is a cornerstone of computational complexity with broad industrial applications, and it remains challenging to optimize modern SAT solvers in real-world settings due to their intricate architectures. While automatic configuration frameworks have been developed, they rely on manually constrained search spaces and yield limited performance gains. This work introduces a novel paradigm which effectively optimizes complex SAT solvers via Large Language Models (LLMs), and a tool called AutoModSAT is developed. Three fundamental challenges are addressed in order to achieve superior performance: (1) LLM-friendly solver: Systematic guidelines are proposed for developing a modularized solver to meet LLMs compatibility, emphasizing code simplification, information share and bug reduction; (2) Automatic prompt optimization: An unsupervised automatic prompt optimization method is introduced to advance the diversity of LLMs output; (3) Efficient search strategy: We design a presearch strategy and an EA evolutionary algorithm for the final efficient and effective discovery of heuristics. Extensive experiments across a wide range of datasets demonstrate that AutoModSAT achieves 50% performance improvement over the baseline solver and achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover, AutoModSAT attains a 20% speedup on average compared to parameter-tuned alternatives of the SOTA solvers, showcasing the enhanced capability in handling complex problem instances. This work bridges the gap between AI-driven heuristics discovery and mission-critical system optimization, and provides both methodological advancements and empirically validated results for next-generation complex solver development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22873v1" target="_blank">LCS: An AI-based Low-Complexity Scaler for Power-Efficient Super-Resolution of Game Content</a></h3>
                    <p><strong>Authors:</strong> Simon Pochinda, Momen K. Tageldeen, Mark Thompson, Tony Rinaldi, Troy Giorshev, Keith Lee, Jie Zhou, Frederick Walls</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> The increasing complexity of content rendering in modern games has led to a problematic growth in the workload of the GPU. In this paper, we propose an AI-based low-complexity scaler (LCS) inspired by state-of-the-art efficient super-resolution (ESR) models which could offload the workload on the GPU to a low-power device such as a neural processing unit (NPU). The LCS is trained on GameIR image pairs natively rendered at low and high resolution. We utilize adversarial training to encourage reconstruction of perceptually important details, and apply reparameterization and quantization techniques to reduce model complexity and size. In our comparative analysis we evaluate the LCS alongside the publicly available AMD hardware-based Edge Adaptive Scaling Function (EASF) and AMD FidelityFX Super Resolution 1 (FSR1) on five different metrics, and find that the LCS achieves better perceptual quality, demonstrating the potential of ESR models for upscaling on resource-constrained devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22871v1" target="_blank">Tracking research software outputs in the UK</a></h3>
                    <p><strong>Authors:</strong> Domhnall Carlin, Austen Rainer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.DL, D.2.13</p>
                    <p><strong>Summary:</strong> Research software is crucial in the research process and the growth of Open Science underscores the importance of accessing research artifacts, like data and code, raising traceability challenges among outputs. While it is a clear principle that research code, along with other essential outputs, should be recognised as artifacts of the research process, the how of this principle remains variable. This study examines where UK academic institutions store and register software as a unique research output, searching the UKRIs Gateway to Research (GtR) metadata for publicly funded research software in the UK. The quantity of software reported as research outcomes remains low in proportion to other categories. Artifact sharing appears low, with one-quarter of the reported software having no links and 45% having either a missing or erroneous URL. Of the valid URLs, we find the single largest category is Public Commercial Code Repository, with GitHub being the host of 18% of all publicly funded research software listed. These observations are contrasted with past findings from 2023 and finally, we discuss the lack of artifact sharing in UK research, with resulting implications for the maintenance and evolution of research software. Without dissemination, research software risks demotion to a transient artifact, useful only to meet short term research demands but ultimately lost to the broader enterprise of science.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22865v1" target="_blank">Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue</a></h3>
                    <p><strong>Authors:</strong> Sahan Liyanaarachchi, Sennur Ulukus</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.SY, eess.SY, math.IT</p>
                    <p><strong>Summary:</strong> With the dawn of AI factories ushering a new era of computing supremacy, development of strategies to effectively track and utilize the available computing resources is garnering utmost importance. These computing resources are often modeled as Markov sources, which oscillate between free and busy states, depending on their internal load and external utilization, and are commonly referred to as Markov machines (MMs). Most of the prior work solely focuses on the problem of tracking these MMs, while often assuming a rudimentary decision process that governs their utilization. Our key observation is that the ultimate goal of tracking a MM is to properly utilize it. In this work, we consider the problem of maximizing the utility of a MM, where the utility is defined as the average revenue generated by the MM. Assuming a Poisson job arrival process and a query-based sampling procedure to sample the state of the MM, we find the optimal times to submit the available jobs to the MM so as to maximize the average revenue generated per unit job. We show that, depending on the parameters of the MM, the optimal policy is in the form of either a \emph{threshold policy} or a \emph{switching policy} based on the \emph{age of our estimate} of the state of the MM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22861v1" target="_blank">Conditions for building generalized action graphs from sequences</a></h3>
                    <p><strong>Authors:</strong> Sarah Klanderman, Katy McDicken, Amelia Tebbe</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.CO, 05A19, 05C05 (Primary)</p>
                    <p><strong>Summary:</strong> This paper explores the properties of directed graphs, termed generalized action graphs, which exhibit a strong connection to certain number sequences. Focusing on the structural and combinatorial aspects, we investigate the conditions under which specific sequences can generate generalized action graphs. Building upon prior research in this field, we analyze specific features of these graphs and how they correspond to patterns and properties in their sequences. These findings support a broader conclusion that establishes framework for identifying which sequences can produce generalized action graphs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22847v1" target="_blank">The Incomplete Bridge: How AI Research (Mis)Engages with Psychology</a></h3>
                    <p><strong>Authors:</strong> Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, Ziang Xiao</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Social sciences have accumulated a rich body of theories and methodologies for investigating the human mind and behaviors, while offering valuable insights into the design and understanding of Artificial Intelligence (AI) systems. Focusing on psychology as a prominent case, this study explores the interdisciplinary synergy between AI and the field by analyzing 1,006 LLM-related papers published in premier AI venues between 2023 and 2025, along with the 2,544 psychology publications they cite. Through our analysis, we identify key patterns of interdisciplinary integration, locate the psychology domains most frequently referenced, and highlight areas that remain underexplored. We further examine how psychology theories/frameworks are operationalized and interpreted, identify common types of misapplication, and offer guidance for more effective incorporation. Our work provides a comprehensive map of interdisciplinary engagement between AI and psychology, thereby facilitating deeper collaboration and advancing AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22844v1" target="_blank">RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents</a></h3>
                    <p><strong>Authors:</strong> Zijing Zhang, Ziyang Chen, Mingxiao Li, Zhaopeng Tu, Xiaolong Li</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> The development of autonomous agents for complex, long-horizon tasks is a central goal in AI. However, dominant training paradigms face a critical limitation: reinforcement learning (RL) methods that optimize solely for final task success often reinforce flawed or inefficient reasoning paths, a problem we term inefficient exploration. This leads to agents that are brittle and fail to generalize, as they learn to find solutions without learning how to reason coherently. To address this, we introduce RLVMR, a novel framework that integrates dense, process-level supervision into end-to-end RL by rewarding verifiable, meta-reasoning behaviors. RLVMR equips an agent to explicitly tag its cognitive steps, such as planning, exploration, and reflection, and provides programmatic, rule-based rewards for actions that contribute to effective problem-solving. These process-centric rewards are combined with the final outcome signal and optimized using a critic-free policy gradient method. On the challenging ALFWorld and ScienceWorld benchmarks, RLVMR achieves new state-of-the-art results, with our 7B model reaching an 83.6% success rate on the most difficult unseen task split. Our analysis confirms these gains stem from improved reasoning quality, including significant reductions in redundant actions and enhanced error recovery, leading to more robust, efficient, and interpretable agents.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22840v1" target="_blank">PAF-Net: Phase-Aligned Frequency Decoupling Network for Multi-Process Manufacturing Quality Prediction</a></h3>
                    <p><strong>Authors:</strong> Yang Luo, Haoyang Luan, Haoyun Pan, Yongquan Jia, Xiaofeng Gao, Guihai Chen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Accurate quality prediction in multi-process manufacturing is critical for industrial efficiency but hindered by three core challenges: time-lagged process interactions, overlapping operations with mixed periodicity, and inter-process dependencies in shared frequency bands. To address these, we propose PAF-Net, a frequency decoupled time series prediction framework with three key innovations: (1) A phase-correlation alignment method guided by frequency domain energy to synchronize time-lagged quality series, resolving temporal misalignment. (2) A frequency independent patch attention mechanism paired with Discrete Cosine Transform (DCT) decomposition to capture heterogeneous operational features within individual series. (3) A frequency decoupled cross attention module that suppresses noise from irrelevant frequencies, focusing exclusively on meaningful dependencies within shared bands. Experiments on 4 real-world datasets demonstrate PAF-Nets superiority. It outperforms 10 well-acknowledged baselines by 7.06% lower MSE and 3.88% lower MAE. Our code is available at https://github.com/StevenLuan904/PAF-Net-Official.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22832v1" target="_blank">Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks</a></h3>
                    <p><strong>Authors:</strong> Maciej Satkiewicz</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV, cs.NE, I.2.6; I.4.10</p>
                    <p><strong>Summary:</strong> In this paper we argue that ReLU networks learn an implicit linear model we can actually tap into. We describe that alleged model formally and show that we can approximately pull its decision boundary back to the input space with certain simple modification to the backward pass. The resulting gradients (called excitation pullbacks) reveal high-resolution input- and target-specific features of remarkable perceptual alignment on a number of popular ImageNet-pretrained deep architectures. This strongly suggests that neural networks do, in fact, rely on learned interpretable patterns that can be recovered after training. Thus, our findings may have profound implications for knowledge discovery and the development of dependable artificial systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22825v1" target="_blank">DepR: Depth Guided Single-view Scene Reconstruction with Instance-level Diffusion</a></h3>
                    <p><strong>Authors:</strong> Qingcheng Zhao, Xiang Zhang, Haiyang Xu, Zeyuan Chen, Jianwen Xie, Yuan Gao, Zhuowen Tu</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We propose DepR, a depth-guided single-view scene reconstruction framework that integrates instance-level diffusion within a compositional paradigm. Instead of reconstructing the entire scene holistically, DepR generates individual objects and subsequently composes them into a coherent 3D layout. Unlike previous methods that use depth solely for object layout estimation during inference and therefore fail to fully exploit its rich geometric information, DepR leverages depth throughout both training and inference. Specifically, we introduce depth-guided conditioning to effectively encode shape priors into diffusion models. During inference, depth further guides DDIM sampling and layout optimization, enhancing alignment between the reconstruction and the input image. Despite being trained on limited synthetic data, DepR achieves state-of-the-art performance and demonstrates strong generalization in single-view scene reconstruction, as shown through evaluations on both synthetic and real-world datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22824v1" target="_blank">Bi-Level Optimization for Self-Supervised AI-Generated Face Detection</a></h3>
                    <p><strong>Authors:</strong> Mian Zou, Nan Zhong, Baosheng Yu, Yibing Zhan, Kede Ma</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> AI-generated face detectors trained via supervised learning typically rely on synthesized images from specific generators, limiting their generalization to emerging generative techniques. To overcome this limitation, we introduce a self-supervised method based on bi-level optimization. In the inner loop, we pretrain a vision encoder only on photographic face images using a set of linearly weighted pretext tasks: classification of categorical exchangeable image file format (EXIF) tags, ranking of ordinal EXIF tags, and detection of artificial face manipulations. The outer loop then optimizes the relative weights of these pretext tasks to enhance the coarse-grained detection of manipulated faces, serving as a proxy task for identifying AI-generated faces. In doing so, it aligns self-supervised learning more closely with the ultimate goal of AI-generated face detection. Once pretrained, the encoder remains fixed, and AI-generated faces are detected either as anomalies under a Gaussian mixture model fitted to photographic face features or by a lightweight two-layer perceptron serving as a binary classifier. Extensive experiments demonstrate that our detectors significantly outperform existing approaches in both one-class and binary classification settings, exhibiting strong generalization to unseen generators.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22814v1" target="_blank">Quantum Simulation of Nuclear Dynamics in First Quantization</a></h3>
                    <p><strong>Authors:</strong> Luca Spagnoli, Chiara Lissoni, Alessandro Roggero</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph, nucl-th</p>
                    <p><strong>Summary:</strong> The study of real time dynamics of nuclear systems is of great importance to provide theoretical predictions of cross sections relevant for both terrestrial experiments as well as applications in astrophysics. First principles simulations of these dynamical processes is however hindered by an exponential cost in classical resources and the possibility of performing scalable simulations using quantum computers is currently an active field of research. In this work we provide the first complete characterization of the resource requirements for studying nuclear dynamics with the full Leading Order (LO) pionless EFT Hamiltonian in first quantization employing simulation strategies using both product formulas as well as Quantum Signal Processing. In particular, we show that time evolution of such an Hamiltonian can be performed with polynomial resources in the number of particles, and logarithmic resources in the number of single-particle basis states. This result provides an exponential improvement compared with previous work on the same Hamiltonian model in second quantization. We find that interesting simulations for low energy nuclear scattering could be achievable with tens of millions of T gates and few hundred logical qubits suggesting that the study of simple nuclear reactions could be amenable for early fault tolerant quantum platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22813v1" target="_blank">DISTIL: Data-Free Inversion of Suspicious Trojan Inputs via Latent Diffusion</a></h3>
                    <p><strong>Authors:</strong> Hossein Mirzaei, Zeinab Taghavi, Sepehr Rezaee, Masoud Hadi, Moein Madadi, Mackenzie W. Mathis</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep neural networks have demonstrated remarkable success across numerous tasks, yet they remain vulnerable to Trojan (backdoor) attacks, raising serious concerns about their safety in real-world mission-critical applications. A common countermeasure is trigger inversion -- reconstructing malicious shortcut patterns (triggers) inserted by an adversary during training. Current trigger-inversion methods typically search the full pixel space under specific assumptions but offer no assurances that the estimated trigger is more than an adversarial perturbation that flips the model output. Here, we propose a data-free, zero-shot trigger-inversion strategy that restricts the search space while avoiding strong assumptions on trigger appearance. Specifically, we incorporate a diffusion-based generator guided by the target classifier; through iterative generation, we produce candidate triggers that align with the internal representations the model relies on for malicious behavior. Empirical evaluations, both quantitative and qualitative, show that our approach reconstructs triggers that effectively distinguish clean versus Trojaned models. DISTIL surpasses alternative methods by high margins, achieving up to 7.1% higher accuracy on the BackdoorBench dataset and a 9.4% improvement on trojaned object detection model scanning, offering a promising new direction for reliable backdoor defense without reliance on extensive data or strong prior assumptions about triggers. The code is available at https://github.com/AdaptiveMotorControlLab/DISTIL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22804v1" target="_blank">Deep reinforcement learning for efficient exploration of combinatorial structural design spaces</a></h3>
                    <p><strong>Authors:</strong> Chloe S. H. Hong, Keith J. Lee, Caitlin T. Mueller</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> This paper proposes a reinforcement learning framework for performance-driven structural design that combines bottom-up design generation with learned strategies to efficiently search large combinatorial design spaces. Motivated by the limitations of conventional top-down approaches such as optimization, the framework instead models structures as compositions of predefined elements, aligning form finding with practical constraints like constructability and component reuse. With the formulation of the design task as a sequential decision-making problem and a human learning inspired training algorithm, the method adapts reinforcement learning for structural design. The framework is demonstrated by designing steel braced truss frame cantilever structures, where trained policies consistently generate distinct, high-performing designs that display structural performance and material efficiency with the use of structural strategies that align with known engineering principles. Further analysis shows that the agent efficiently narrows its search to promising regions of the design space, revealing transferable structural knowledge.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22802v1" target="_blank">Advancing Fetal Ultrasound Image Quality Assessment in Low-Resource Settings</a></h3>
                    <p><strong>Authors:</strong> Dongli He, Hu Wang, Mohammad Yaqub</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Accurate fetal biometric measurements, such as abdominal circumference, play a vital role in prenatal care. However, obtaining high-quality ultrasound images for these measurements heavily depends on the expertise of sonographers, posing a significant challenge in low-income countries due to the scarcity of trained personnel. To address this issue, we leverage FetalCLIP, a vision-language model pretrained on a curated dataset of over 210,000 fetal ultrasound image-caption pairs, to perform automated fetal ultrasound image quality assessment (IQA) on blind-sweep ultrasound data. We introduce FetalCLIP$_{CLS}$, an IQA model adapted from FetalCLIP using Low-Rank Adaptation (LoRA), and evaluate it on the ACOUSLIC-AI dataset against six CNN and Transformer baselines. FetalCLIP$_{CLS}$ achieves the highest F1 score of 0.757. Moreover, we show that an adapted segmentation model, when repurposed for classification, further improves performance, achieving an F1 score of 0.771. Our work demonstrates how parameter-efficient fine-tuning of fetal ultrasound foundation models can enable task-specific adaptations, advancing prenatal care in resource-limited settings. The experimental code is available at: https://github.com/donglihe-hub/FetalCLIP-IQA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22799v1" target="_blank">Human Mobility in Epidemic Modeling</a></h3>
                    <p><strong>Authors:</strong> Xin Lu, Jiawei Feng, Shengjie Lai, Petter Holme, Shuo Liu, Zhanwei Du, Xiaoqian Yuan, Siqing Wang, Yunxuan Li, Xiaoyu Zhang, Yuan Bai, Xiaojun Duan, Wenjun Mei, Hongjie Yu, Suoyi Tan, Fredrik Liljeros</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SI, physics.data-an, physics.soc-ph, 91Cxx, 37M05, 91F99, J.3; J.4; K.4.1</p>
                    <p><strong>Summary:</strong> Human mobility forms the backbone of contact patterns through which infectious diseases propagate, fundamentally shaping the spatio-temporal dynamics of epidemics and pandemics. While traditional models are often based on the assumption that all individuals have the same probability of infecting every other individual in the population, a so-called random homogeneous mixing, they struggle to capture the complex and heterogeneous nature of real-world human interactions. Recent advancements in data-driven methodologies and computational capabilities have unlocked the potential of integrating high-resolution human mobility data into epidemic modeling, significantly improving the accuracy, timeliness, and applicability of epidemic risk assessment, contact tracing, and intervention strategies. This review provides a comprehensive synthesis of the current landscape in human mobility-informed epidemic modeling. We explore diverse sources and representations of human mobility data, and then examine the behavioral and structural roles of mobility and contact in shaping disease transmission dynamics. Furthermore, the review spans a wide range of epidemic modeling approaches, ranging from classical compartmental models to network-based, agent-based, and machine learning models. And we also discuss how mobility integration enhances risk management and response strategies during epidemics. By synthesizing these insights, the review can serve as a foundational resource for researchers and practitioners, bridging the gap between epidemiological theory and the dynamic complexities of human interaction while charting clear directions for future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22795v1" target="_blank">Genuine multipartite entanglement as a probe of many-body localization in disordered spin chains with Dzyaloshinskii-Moriya interactions</a></h3>
                    <p><strong>Authors:</strong> Triyas Sapui, Keshav Das Agarwal, Tanoy Kanti Konar, Leela Ganesh Chandra Lakkaraju, Aditi Sen De</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.dis-nn, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> We demonstrate that the quenched average genuine multipartite entanglement (GME) can approach its maximum value in the ergodic phase of a disordered quantum spin model. In contrast, GME vanishes in the many-body localized (MBL) phase, both in equilibrium and in the long-time dynamical steady state, indicating a lack of useful entanglement in the localized regime. To establish this, we analyze the disordered Heisenberg spin chain subjected to a random magnetic field and incorporating two- and three-body Dzyaloshinskii-Moriya (DM) interactions. We exhibit that the behavior of GME, in both static eigenstates and in dynamically evolved states from an initial Neel configuration, serves as a reliable indicator of the critical disorder strength required for the ergodic-to-MBL transition. The identified transition point aligns well with standard indicators such as the gap ratio and correlation length. Moreover, we find that the presence of DM interactions, particularly the three-body one, significantly stabilizes the thermal phase and delays the onset of localization. This shift in the transition point is consistently reflected in both static and dynamical analyses, reinforcing GME as a robust probe for MBL transitions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22792v1" target="_blank">Segment Anything for Video: A Comprehensive Review of Video Object Segmentation and Tracking from Past to Future</a></h3>
                    <p><strong>Authors:</strong> Guoping Xu, Jayaram K. Udupa, Yajun Yu, Hua-Chieh Shao, Songlin Zhao, Wei Liu, You Zhang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video Object Segmentation and Tracking (VOST) presents a complex yet critical challenge in computer vision, requiring robust integration of segmentation and tracking across temporally dynamic frames. Traditional methods have struggled with domain generalization, temporal consistency, and computational efficiency. The emergence of foundation models like the Segment Anything Model (SAM) and its successor, SAM2, has introduced a paradigm shift, enabling prompt-driven segmentation with strong generalization capabilities. Building upon these advances, this survey provides a comprehensive review of SAM/SAM2-based methods for VOST, structured along three temporal dimensions: past, present, and future. We examine strategies for retaining and updating historical information (past), approaches for extracting and optimizing discriminative features from the current frame (present), and motion prediction and trajectory estimation mechanisms for anticipating object dynamics in subsequent frames (future). In doing so, we highlight the evolution from early memory-based architectures to the streaming memory and real-time segmentation capabilities of SAM2. We also discuss recent innovations such as motion-aware memory selection and trajectory-guided prompting, which aim to enhance both accuracy and efficiency. Finally, we identify remaining challenges including memory redundancy, error accumulation, and prompt inefficiency, and suggest promising directions for future research. This survey offers a timely and structured overview of the field, aiming to guide researchers and practitioners in advancing the state of VOST through the lens of foundation models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22789v1" target="_blank">G-Core: A Simple, Scalable and Balanced RLHF Trainer</a></h3>
                    <p><strong>Authors:</strong> Junyu Wu, Weiming Chang, Xiaotao Liu, Guanyou He, Haoqiang Hong, Boqi Liu, Hongtao Tian, Tao Yang, Yunsheng Shi, Feng Lin, Ting Yao</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Reinforcement Learning from Human Feedback (RLHF) has become an increasingly popular paradigm for training large language models (LLMs) and diffusion models. While existing RLHF training systems have enabled significant progress, they often face challenges in scaling to multi-modal and diffusion workflows and adapting to dynamic workloads. In particular, current approaches may encounter limitations in controller scalability, flexible resource placement, and efficient orchestration when handling complex RLHF pipelines, especially in scenarios involving dynamic sampling or generative reward modeling. In this paper, we present \textbf{G-Core}, a simple, scalable, and balanced RLHF training framework designed to address these challenges. G-Core introduces a parallel controller programming model, enabling flexible and efficient orchestration of complex RLHF workflows without the bottlenecks of a single centralized controller. Furthermore, we propose a dynamic placement schema that adaptively partitions resources and schedules workloads, significantly reducing hardware idle time and improving utilization, even under highly variable training conditions. G-Core has successfully trained models that support WeChat product features serving a large-scale user base, demonstrating its effectiveness and robustness in real-world scenarios. Our results show that G-Core advances the state of the art in RLHF training, providing a solid foundation for future research and deployment of large-scale, human-aligned models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22784v1" target="_blank">Geometrical entanglement and alignment regulate self-organization in active ring polymer suspensions</a></h3>
                    <p><strong>Authors:</strong> Juan Pablo Miranda, Emanuele Locatelli, Cristian Micheletti, Demian Levis, Chantal Valeriani</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cond-mat.soft</p>
                    <p><strong>Summary:</strong> We study the emerging self-organization in active ring suspensions, focusing on how the rings orientational order and geometric entanglement vary with density and spatial confinement. To quantify entanglement, we introduce the wrapping number, a pairwise measure of ring interpenetration, while orientational order is characterized by the alignment of the normal vectors to the rings osculating planes. Both wrapping number and alignment distinguish active from passive systems, and their combination aptly identifies the self-organized states that emerge with the onset of activity. Mutual-information analysis reveals a significant correlation between alignment and wrapping number across all considered active conditions. However, self-organization displays a non-monotonic dependence on the activity-induced entanglement. Specifically, moderate wrapping stabilizes contacts of neighboring aligned rings, while excessive entanglement disrupts alignment. We show that this competition arises because increasing entanglement interferes with the planar conformations required to form aligned stacks. Given the simplicity of this microscopic mechanism, analogous effects may occur more generally in polymer systems where the degree of entanglement is regulated by out-of-equilibrium effects.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22781v1" target="_blank">HOLA: Enhancing Audio-visual Deepfake Detection via Hierarchical Contextual Aggregations and Efficient Pre-training</a></h3>
                    <p><strong>Authors:</strong> Xuecheng Wu, Danlei Huang, Heli Sun, Xinyi Yin, Yifan Wang, Hao Wang, Jia Zhang, Fei Wang, Peihao Guo, Suyu Xing, Junxiao Xue, Liang He</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Advances in Generative AI have made video-level deepfake detection increasingly challenging, exposing the limitations of current detection techniques. In this paper, we present HOLA, our solution to the Video-Level Deepfake Detection track of 2025 1M-Deepfakes Detection Challenge. Inspired by the success of large-scale pre-training in the general domain, we first scale audio-visual self-supervised pre-training in the multimodal video-level deepfake detection, which leverages our self-built dataset of 1.81M samples, thereby leading to a unified two-stage framework. To be specific, HOLA features an iterative-aware cross-modal learning module for selective audio-visual interactions, hierarchical contextual modeling with gated aggregations under the local-global perspective, and a pyramid-like refiner for scale-aware cross-grained semantic enhancements. Moreover, we propose the pseudo supervised singal injection strategy to further boost model performance. Extensive experiments across expert models and MLLMs impressivly demonstrate the effectiveness of our proposed HOLA. We also conduct a series of ablation studies to explore the crucial design factors of our introduced components. Remarkably, our HOLA ranks 1st, outperforming the second by 0.0476 AUC on the TestA set.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22780v1" target="_blank">Euclid: Forecasts on $Œõ$CDM consistency tests with growth rate data</a></h3>
                    <p><strong>Authors:</strong> I. Ocampo, D. Sapone, S. Nesseris, G. Alestas, J. Garc√≠a-Bellido, Z. Sakr, C. J. A. P. Martins, J. P. Mimoso, A. Carvalho, A. Da Silva, A. Blanchard, S. Casas, S. Camera, M. Martinelli, V. Pettorino, A. Amara, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, A. Balestra, S. Bardelli, P. Battaglia, F. Bernardeau, A. Biviano, E. Branchini, M. Brescia, G. Ca√±as-Herrera, V. Capobianco, C. Carbone, V. F. Cardone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, H. Degaudenzi, S. de la Torre, G. De Lucia, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Farrens, F. Faustini, S. Ferriol, F. Finelli, P. Fosalba, N. Fourmanoit, M. Frailis, E. Franceschi, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keih√§nen, S. Kermiche, B. Kubik, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, O. Marggraf, K. Markovic, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, S. Pires, G. Polenta, M. Poncet, L. A. Popa, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, B. Sartoris, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-Cresp√≠, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, G. Zamorani, F. M. Zerbi, E. Zucca, M. Ballardini, C. Burigana, L. Gabarra, A. Pezzotta, V. Scottez, M. Viel</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> The large-scale structure (LSS) of the Universe is an important probe for deviations from the canonical cosmological constant $\Lambda$ and cold dark matter ($\Lambda$CDM) model. A statistically significant detection of any deviations would signify the presence of new physics or the breakdown of any number of the underlying assumptions of the standard cosmological model or possible systematic errors in the data. In this paper, we quantify the ability of the LSS data products of the spectroscopic survey of the Euclid mission, together with other contemporary surveys, to improve the constraints on deviations from $\Lambda$CDM in the redshift range $0z1.75$. We consider both currently available growth rate data and simulated data with specifications from Euclid and external surveys, based on $\Lambda$CDM and a modified gravity (MoG) model with an evolving Newtons constant (denoted $\mu$CDM), and carry out a binning method and a machine learning reconstruction, based on genetic algorithms (GAs), of several LSS null tests. Using the forecast Euclid growth data from the spectroscopic survey in the range $0.95z1.75$, we find that in combination with external data products (covering the range $0z0.95$), Euclid will be able to improve on current constraints of null tests of the LSS on average by a factor of eight when using a binning method and a factor of six when using the GAs. Our work highlights the need for synergies between Euclid and other surveys, but also the usefulness of statistical analyses, such as GAs, in order to disentangle any degeneracies in the cosmological parameters. Both are necessary to provide tight constraints over an extended redshift range and to probe for deviations from the $\Lambda$CDM model.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22776v1" target="_blank">Label-free estimation of clinically relevant performance metrics under distribution shifts</a></h3>
                    <p><strong>Authors:</strong> Tim Fl√ºhmann, Alceu Bissoto, Trung-Dung Hoang, Lisa M. Koch</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Performance monitoring is essential for safe clinical deployment of image classification models. However, because ground-truth labels are typically unavailable in the target dataset, direct assessment of real-world model performance is infeasible. State-of-the-art performance estimation methods address this by leveraging confidence scores to estimate the target accuracy. Despite being a promising direction, the established methods mainly estimate the models accuracy and are rarely evaluated in a clinical domain, where strong class imbalances and dataset shifts are common. Our contributions are twofold: First, we introduce generalisations of existing performance prediction methods that directly estimate the full confusion matrix. Then, we benchmark their performance on chest x-ray data in real-world distribution shifts as well as simulated covariate and prevalence shifts. The proposed confusion matrix estimation methods reliably predicted clinically relevant counting metrics on medical images under distribution shifts. However, our simulated shift scenarios exposed important failure modes of current performance estimation techniques, calling for a better understanding of real-world deployment contexts when implementing these performance monitoring techniques for postmarket surveillance of medical AI models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22767v1" target="_blank">Teaching the Teacher: Improving Neural Network Distillability for Symbolic Regression via Jacobian Regularization</a></h3>
                    <p><strong>Authors:</strong> Soumyadeep Dhar, Kei Sen Fong, Mehul Motani</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Distilling large neural networks into simple, human-readable symbolic formulas is a promising path toward trustworthy and interpretable AI. However, this process is often brittle, as the complex functions learned by standard networks are poor targets for symbolic discovery, resulting in low-fidelity student models. In this work, we propose a novel training paradigm to address this challenge. Instead of passively distilling a pre-trained network, we introduce a \textbf{Jacobian-based regularizer} that actively encourages the ``teacher network to learn functions that are not only accurate but also inherently smoother and more amenable to distillation. We demonstrate through extensive experiments on a suite of real-world regression benchmarks that our method is highly effective. By optimizing the regularization strength for each problem, we improve the $R^2$ score of the final distilled symbolic model by an average of \textbf{120\% (relative)} compared to the standard distillation pipeline, all while maintaining the teachers predictive accuracy. Our work presents a practical and principled method for significantly improving the fidelity of interpretable models extracted from complex neural networks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22753v1" target="_blank">Opportunities and Challenges of LLMs in Education: An NLP Perspective</a></h3>
                    <p><strong>Authors:</strong> Sowmya Vajjala, Bashar Alhafni, Stefano Bann√≤, Kaushal Kumar Maurya, Ekaterina Kochmar</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Interest in the role of large language models (LLMs) in education is increasing, considering the new opportunities they offer for teaching, learning, and assessment. In this paper, we examine the impact of LLMs on educational NLP in the context of two main application scenarios: {\em assistance} and {\em assessment}, grounding them along the four dimensions -- reading, writing, speaking, and tutoring. We then present the new directions enabled by LLMs, and the key challenges to address. We envision that this holistic overview would be useful for NLP researchers and practitioners interested in exploring the role of LLMs in developing language-focused and NLP-enabled educational applications of the future.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22751v1" target="_blank">Characterization of mini-CryoCube detectors from the Ricochet experiment commissioning at the Institut Laue-Langevin</a></h3>
                    <p><strong>Authors:</strong> Antoine Armatol, Corinne Augier, Louis Bailly-Salins, Guillaume Baulieu, Laurent Berg√©, Julien Billard, Juliette Bl√©, Guillaume Bres, Jean-Louis Bret, Alexandre Broniatowski, Martino Calvo, Antonella Cavanna, Antoine Cazes, Emanuela Celi, David Chaize, Mohammed Chala, Maurice Chappellier, Luke Chaplinsky, Guillaume Chemin, Ran Chen, Jules Colas, Laurent Couraud, Elspeth Cudmore, Maryvonne De Jesus, Nicole Dombrowski, Louis Dumoulin, Alan Durnez, Olivier Exshaw, Sylvain Ferriol, Enectali Figueroa-Feliciano, Joseph A. Formaggio, Stephane Fuard, Jules Gascon, Andrea Giuliani, Corinne Goy, Cyrille Guerin, Elsa Guy, Le√Øla Haegel, Scott A. Hertel, Christophe Hoarau, Ziqing Hong, Jean-Christophe Ianigro, Yong Jin, Alexandre Juillard, Temirlan Khussainov, Andrew Kubik, Jacob Lamblin, Hugues Lattaud, Tatiana Le-Bellec, Laetitia Leroy, Mingyu Li, Alexey Lubashevskiy, Stefanos Marnieros, Nicolas Martini, Julien Minet, Alessandro Monfardini, Franck Mounier, Valentina Novati, Emiliano Olivieri, Pratyush K. Patel, Eric Perbet, Harold Douglas Pinckney, Denys V. Poda, Dmitrii Ponomarev, Wouter Van De Pontseele, Jean-S√©bastien Real, Faith C. Reyes, Alejandro Rodriguez, Murielle Rousseau, Sergey Rozov, Irina Rozova, Brianna Ryan, Deeksha Sabhari, Silvia Scorza, Renaud Serra, Yegor Shevchik, Torsten Soldner, Anne Stutz, Christian Ulysse, Lionel Vagneron, Sergey Vasilyev, Francis Vezzu, Paul Vittaz, Evgeny Yakushev, Jiatong Yang, Daniya Zinatulina</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM, hep-ex, physics.ins-det</p>
                    <p><strong>Summary:</strong> The Ricochet experiment aims to measure the coherent elastic neutrino-nucleus scattering process from antineutrinos emitted by a research nuclear reactor operated by the Institut Laue-Langevin (Grenoble, France). This article presents a description of the Ricochet experimental installation and the detector performance achieved during its commissioning with a mini-CryoCube module consisting of three 42-gram germanium cryogenic calorimeters. The baseline resolutions and background levels are reported both during reactor-on and reactor-off periods, and as noise mitigation techniques were improved. A baseline resolution of 40 eV electron equivalent was achieved for the ionization channel after setup improvements, and the phonon channel resolutions ranged from 50 to 80 eV of total phonon energy. In the energy region from 2 to 7 keV, a nuclear recoil rate of 15(2) events/(kg day keV) is measured during the reactor-off period selecting events in coincidence with muon veto signals. This rate is in agreement with the cosmogenic neutron rate calculated from GEANT4 simulations. After the rejection of events in coincidence with signals in the muon veto detectors, a combined 90% C.L. limit on the nuclear recoil background of  9 events/(kg day keV) is obtained in that energy region during the reactor-on period, which is compatible with our GEANT4 model calculation corresponding to a total rate of 5 events/(kg day keV). The sensitivity of this analysis was however found to be limited by a surface event contamination which is currently being addressed by the Ricochet Collaboration with upgraded detectors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22748v1" target="_blank">How Exposed Are UK Jobs to Generative AI? Developing and Applying a Novel Task-Based Index</a></h3>
                    <p><strong>Authors:</strong> Golo Henseke, Rhys Davies, Alan Felstead, Duncan Gallie, Francis Green, Ying Zhou</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> We introduce the Generative AI Susceptibility Index (GAISI), a task-based measure of UK job exposure to large language models (LLMs), such as ChatGPT. GAISI is derived from probabilistic task ratings by LLMs and linked to worker-reported task data from the Skills and Employment Surveys. It reflects the share of job activities where an LLM or LLM-powered system can reduce task completion time by at least 25 per cent beyond existing productivity tools. The index demonstrates high reliability, strong alignment with AI capabilities, and superior predictive power compared to existing exposure measures. By 2023-24, nearly all UK jobs exhibited some exposure, yet only a minority were heavily affected. Aggregate exposure has risen since 2017, primarily due to occupational shifts rather than changes in task profiles. The price premium for AI-exposed tasks declined relative to 2017, measuring approximately 11 per cent lower in 2023-24. Job postings in high-exposure roles also fell by 6.5 per cent following the release of ChatGPT. GAISI offers a robust framework for assessing generative AIs impact on work, providing early evidence that displacement effects may already outweigh productivity gains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22744v1" target="_blank">Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index</a></h3>
                    <p><strong>Authors:</strong> Praveenkumar Katwe, Rakesh Chandra, Balabantaray Kali, Prasad Vittala</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, 68T50, I.2.7</p>
                    <p><strong>Summary:</strong> Reducing hallucinations in abstractive summarization remains a critical challenge for deploying language models (LMs) in real-world settings. In this work, we introduce a rewarddriven fine-tuning framework that explicitly optimizes for Entity Hallucination Index (EHI), a metric designed to quantify the presence, correctness, and grounding of named entities in generated summaries. Given a corpus of meeting transcripts, we first generate baseline summaries using a pre-trained LM and compute EHI scores via automatic entity extraction and matching. We then apply reinforcement learning to fine-tune the model parameters, using EHI as a reward signal to bias generation toward entity-faithful outputs. Our approach does not rely on human-written factuality annotations, enabling scalable fine-tuning. Experiments demonstrate consistent improvements in EHI across datasets, with qualitative analysis revealing a significant reduction in entity-level hallucinations without degradation in fluency or informativeness. We release a reproducible Colab pipeline, facilitating further research on hallucination-aware model fine-tuning using lightweight, hallucintion metrics like EHI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22740v1" target="_blank">Foundations for Energy-Aware Zero-Energy Devices: From Energy Sensing to Adaptive Protocols</a></h3>
                    <p><strong>Authors:</strong> Onel L. A. L√≥pez, Mateen Ashraf, Samer Nasser, Gabriel M. de Jesus, Ritesh Kumar Singh, Miltiadis C. Filippou, Jeroen Famaey</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY, 94Cxx, C.2.2; C.2.3; B.4.1; B.4.2; B.4.3; H.1.2</p>
                    <p><strong>Summary:</strong> Zero-energy devices (ZEDs) are key enablers of sustainable Internet of Things networks by operating solely on harvested ambient energy. Their limited and dynamic energy budget calls for protocols that are energy-aware and intelligently adaptive. However, designing effective energy-aware protocols for ZEDs requires theoretical models that realistically reflect device constraints. Indeed, existing approaches often oversimplify key aspects such as energy information (EI) acquisition, task-level variability, and energy storage dynamics, limiting their practical relevance and transferability. This article addresses this gap by offering a structured overview of the key modeling components, trade-offs, and limitations involved in energy-aware ZED protocol design. For this, we dissect EI acquisition methods and costs, characterize core operational tasks, analyze energy usage models and storage constraints, and review representative protocol strategies. Moreover, we offer design insights and guidelines on how ZED operation protocols can leverage EI, often illustrated through selected in-house examples. Finally, we outline key research directions to inspire more efficient and scalable protocol solutions for future ZEDs.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.bcra.2025.100274" target="_blank">Dynamic Exponent Market Maker: Personalized Portfolio Manager and One Pool to Trade Them All</a></h3>
                    <p><strong>Authors:</strong> Wittawat Kositwattanarerk</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> Decentralized exchange platforms such as Uniswap and Balancer operate on several pools where each pool contains two or more cryptocurrencies and constitutes direct trading pairs. The drawbacks here are that liquidity providing requires contribution of tokens in a specific proportion, and trading may require hopping between pools, hence increasing transaction fee and gas fee. We propose an automated market maker (AMM) protocol where liquidity providers can deposit any amount of tokens into the pool. The protocol will preserve the proportion of tokens by total value at the time of deposit and can be seen as a personalized self-balancing portfolio manager. In addition, since the invariant function is dynamic, all exchange pairs are executed from a single composite pool. Nevertheless, the scheme is vulnerable to flash loan attacks and must be used in conjunction with preventive measures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22729v1" target="_blank">Resource-Efficient Adaptation of Large Language Models for Text Embeddings via Prompt Engineering and Contrastive Fine-tuning</a></h3>
                    <p><strong>Authors:</strong> Benedikt Roth, Stephan Rappensperger, Tianming Qiu, Hamza Imamoviƒá, Julian W√∂rmann, Hao Shen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have become a cornerstone in Natural Language Processing (NLP), achieving impressive performance in text generation. Their token-level representations capture rich, human-aligned semantics. However, pooling these vectors into a text embedding discards crucial information. Nevertheless, many non-generative downstream tasks, such as clustering, classification, or retrieval, still depend on accurate and controllable sentence- or document-level embeddings. We explore several adaptation strategies for pre-trained, decoder-only LLMs: (i) various aggregation techniques for token embeddings, (ii) task-specific prompt engineering, and (iii) text-level augmentation via contrastive fine-tuning. Combining these components yields state-of-the-art performance on the English clustering track of the Massive Text Embedding Benchmark (MTEB). An analysis of the attention map further shows that fine-tuning shifts focus from prompt tokens to semantically relevant words, indicating more effective compression of meaning into the final hidden state. Our experiments demonstrate that LLMs can be effectively adapted as text embedding models through a combination of prompt engineering and resource-efficient contrastive fine-tuning on synthetically generated positive pairs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22720v1" target="_blank">Investigating Hallucination in Conversations for Low Resource Languages</a></h3>
                    <p><strong>Authors:</strong> Amit Das, Md. Najib Hasan, Souvika Sarkar, Zheng Zhang, Fatemeh Jamshidi, Tathagata Bhattacharya, Nilanjana Raychawdhury, Dongji Feng, Vinija Jain, Aman Chadha</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have demonstrated remarkable proficiency in generating text that closely resemble human writing. However, they often generate factually incorrect statements, a problem typically referred to as hallucination. Addressing hallucination is crucial for enhancing the reliability and effectiveness of LLMs. While much research has focused on hallucinations in English, our study extends this investigation to conversational data in three languages: Hindi, Farsi, and Mandarin. We offer a comprehensive analysis of a dataset to examine both factual and linguistic errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0, DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated responses in Mandarin but generate a significantly higher number of hallucinations in Hindi and Farsi.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22714v1" target="_blank">On the impact of the turbulent grazing flow development on the acoustic response of an acoustic liner</a></h3>
                    <p><strong>Authors:</strong> Angelo Paduano, Francesco Scarano, Julio Cordioli, Damiano Casalino, Francesco Avallone</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn</p>
                    <p><strong>Summary:</strong> The interaction between acoustic waves and turbulent grazing flow over an acoustic liner is investigated using Lattice-Boltzmann Very-Large-Eddy simulations. A single-degree-of-freedom liner with 11 streamwise-aligned cavities is studied in a grazing flow impedance tube. The conditions replicate reference experiments from the Federal University of Santa Catarina. The influence of grazing flow (with a centerline Mach of 0.32), acoustic wave amplitude, frequency, and propagation direction relative to the mean flow is analysed. Impedance is computed using both the in-situ and the mode-matching methods. The in-situ method reveals strong spatial variations; however, averaged values throughout the sample show minimal differences between upstream and downstream propagating waves, in contrast to the mode-matching method. Flow analyses reveal that the orifices displace the flow away from the face sheet, with this effect amplified by acoustic waves and dependent on the wave propagation direction. Consequently, the boundary layer displacement thickness (${\delta}$*) increases along the streamwise direction compared to a smooth wall and exhibits localised humps downstream of each orifice. The growth of ${\delta}$* alters the flow dynamics within the orifices by weakening the shear layer at downstream positions. This influences the acoustic-induced mass flow rate through the orifices, suggesting that acoustic energy is dissipated differently along the liner. The role of near-wall flow features highlights the need to consider a spatially evolving turbulent flow when studying the acoustic-flow interaction and measuring impedance. The spatial development of the turbulent flow may also partly explain the upstream-downstream impedance differences, as current eduction methods do not account for it.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22712v1" target="_blank">Order Book Filtration and Directional Signal Extraction at High Frequency</a></h3>
                    <p><strong>Authors:</strong> Aditya Nittur Anantha, Shashi Jain, Prithwish Maiti</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> q-fin.TR, q-fin.CP, q-fin.GN, q-fin.ST, stat.ME</p>
                    <p><strong>Summary:</strong> With the advent of electronic capital markets and algorithmic trading agents, the number of events in tick-by-tick market data has exploded. A large fraction of these orders is transient. Their ephemeral character degrades the informativeness of directional alphas derived from the limit order book (LOB) state. We investigate whether directional signals such as order book imbalance (OBI) can be improved by structurally filtering high-frequency LOB data. Three real-time, observable filtration schemes: based on order lifetime, update count, and inter-update delay. These are used to recompute OBI on structurally filtered event streams. To assess the effect of filtration, we implement a three-layer diagnostic framework: contemporaneous correlation with returns, explanatory power under discretized regime counts, and causal coherence via Hawkes excitation norms. Empirical results show that structural filtration improves directional signal clarity in correlation and regime-based metrics, but leads to only limited gains in causal excitation strength. In contrast, OBI computed using trade events exhibits stronger causal alignment with future price movements. These findings highlight the importance of differentiating between associative and causal diagnostics when designing high-frequency directional signals.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22711v1" target="_blank">OFCnetLLM: Large Language Model for Network Monitoring and Alertness</a></h3>
                    <p><strong>Authors:</strong> Hong-Jun Yoon, Mariam Kiran, Danial Ebling, Joe Breen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.NI, cs.AI</p>
                    <p><strong>Summary:</strong> The rapid evolution of network infrastructure is bringing new challenges and opportunities for efficient network management, optimization, and security. With very large monitoring databases becoming expensive to explore, the use of AI and Generative AI can help reduce costs of managing these datasets. This paper explores the use of Large Language Models (LLMs) to revolutionize network monitoring management by addressing the limitations of query finding and pattern analysis. We leverage LLMs to enhance anomaly detection, automate root-cause analysis, and automate incident analysis to build a well-monitored network management team using AI. Through a real-world example of developing our own OFCNetLLM, based on the open-source LLM model, we demonstrate practical applications of OFCnetLLM in the OFC conference network. Our model is developed as a multi-agent approach and is still evolving, and we present early results here.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22692v1" target="_blank">Zero-Shot Image Anomaly Detection Using Generative Foundation Models</a></h3>
                    <p><strong>Authors:</strong> Lemar Abdi, Amaan Valiuddin, Francisco Caetano, Christiaan Viviers, Fons van der Sommen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Detecting out-of-distribution (OOD) inputs is pivotal for deploying safe vision systems in open-world environments. We revisit diffusion models, not as generators, but as universal perceptual templates for OOD detection. This research explores the use of score-based generative models as foundational tools for semantic anomaly detection across unseen datasets. Specifically, we leverage the denoising trajectories of Denoising Diffusion Models (DDMs) as a rich source of texture and semantic information. By analyzing Stein score errors, amplified through the Structural Similarity Index Metric (SSIM), we introduce a novel method for identifying anomalous samples without requiring re-training on each target dataset. Our approach improves over state-of-the-art and relies on training a single model on one dataset -- CelebA -- which we find to be an effective base distribution, even outperforming more commonly used datasets like ImageNet in several settings. Experimental results show near-perfect performance on some benchmarks, with notable headroom on others, highlighting both the strength and future potential of generative foundation models in anomaly detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22691v1" target="_blank">A Dual-Feature Extractor Framework for Accurate Back Depth and Spine Morphology Estimation from Monocular RGB Images</a></h3>
                    <p><strong>Authors:</strong> Yuxin Wei, Yue Zhang, Moxin Zhao, Chang Shi, Jason P. Y. Cheung, Teng Zhang, Nan Meng</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Scoliosis is a prevalent condition that impacts both physical health and appearance, with adolescent idiopathic scoliosis (AIS) being the most common form. Currently, the main AIS assessment tool, X-rays, poses significant limitations, including radiation exposure and limited accessibility in poor and remote areas. To address this problem, the current solutions are using RGB images to analyze spine morphology. However, RGB images are highly susceptible to environmental factors, such as lighting conditions, compromising model stability and generalizability. Therefore, in this study, we propose a novel pipeline to accurately estimate the depth information of the unclothed back, compensating for the limitations of 2D information, and then estimate spine morphology by integrating both depth and surface information. To capture the subtle depth variations of the back surface with precision, we design an adaptive multiscale feature learning network named Grid-Aware Multiscale Adaptive Network (GAMA-Net). This model uses dual encoders to extract both patch-level and global features, which are then interacted by the Patch-Based Hybrid Attention (PBHA) module. The Adaptive Multiscale Feature Fusion (AMFF) module is used to dynamically fuse information in the decoder. As a result, our depth estimation model achieves remarkable accuracy across three different evaluation metrics, with scores of nearly 78.2%, 93.6%, and 97.5%, respectively. To further validate the effectiveness of the predicted depth, we integrate both surface and depth information for spine morphology estimation. This integrated approach enhances the accuracy of spine curve generation, achieving an impressive performance of up to 97%.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22684v1" target="_blank">Distorted quarkonia and spin alignment</a></h3>
                    <p><strong>Authors:</strong> Guowei Yan, Shu Lin</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> hep-ph, nucl-ex, nucl-th</p>
                    <p><strong>Summary:</strong> We study both orbital and spin contributions to quarkonia spin alignment induced by magnetic field in heavy ion collisions. The orbital contribution arises from distortion of quarkonium spatial wave function, and the spin contribution is due to spin states mixing in the magnetic field. We find the spin contribution dominates in heavy ion phenomenology. The subleading orbital contribution offers the possibility of studying structure change of quarkonium in magnetic field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22679v1" target="_blank">An alternative method of adjusting for multiple comparison in medical research</a></h3>
                    <p><strong>Authors:</strong> Jiale Li, Zimu Wei</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> stat.AP, stat.OT</p>
                    <p><strong>Summary:</strong> Background Most methods of adjusting for multiplicity focus primarily on controlling type I errors and rarely consider type II errors. We propose a new method that considers controlling for false-positive findings while ensuring sufficient statistical power. Methods We proposed a new method for multiple corrections called (Beta-exponential Adjustment, BEA) that considered the statistical power to control for type I errors while also considering the probability of type II errors. We conducted simulation studies to evaluate the performance characteristic of multiple testing correction procedures. We calculated sensitivity, specificity, and power separately for different sample sizes and number of biomarkers and compared them with the Bonferroni, Holm, and Benjamini-Hochberg (BH) correction methods. Results The results demonstrated that our proposed BEA correction method exhibited the highest sensitivity at different sample sizes and biomarkers (e.g., sensitivity: BEA 0.8 versus BH 0.62 at sample size at 1000, tested biomarkers at 1000 and positive rate at 30%). With different sample sizes and number of biomarkers, the BEA correction method demonstrated comparable specificity compared with traditional methods. Moreover, we observed that the BEA-corrected had the highest statistical power than other methods, when the outcome was relatively rare. Conclusion We proposed the BEA multiple correction method to adjust for multiple comparisons while considering statistical power. The BEA method demonstrated a higher sensitivity, comparable specificity, and higher statistical power, compared with traditional correction methods in different conditions. The BEA correction method can be an alternative of traditional methods of adjusting for multiplicity, especially in studies with small sample size, rare outcomes, or substantial number of biomarkers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22671v1" target="_blank">Designing for Self-Regulation in Informal Programming Learning: Insights from a Storytelling-Centric Approach</a></h3>
                    <p><strong>Authors:</strong> Sami Saeed Alghamdi, Christopher Bull, Ahmed Kharrufa</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CY, cs.SE, H.5.2; H.5.4</p>
                    <p><strong>Summary:</strong> Many people learn programming independently from online resources and often report struggles in achieving their personal learning goals. Learners frequently describe their experiences as isolating and frustrating, challenged by abundant uncertainties, information overload, and distraction, compounded by limited guidance. At the same time, social media serves as a personal space where many engage in diverse self-regulation practices, including help-seeking, using external memory aids (e.g., self-notes), self-reflection, emotion regulation, and self-motivation. For instance, learners often mark achievements and set milestones through their posts. In response, we developed a system consisting of a web platform and browser extensions to support self-regulation online. The design aims to add learner-defined structure to otherwise unstructured experiences and bring meaning to curation and reflection activities by translating them into learning stories with AI-generated feedback. We position storytelling as an integrative approach to design that connects resource curation, reflective and sensemaking practice, and narrative practices learners already use across social platforms. We recruited 15 informal programming learners who are regular social media users to engage with the system in a self-paced manner; participation concluded upon submitting a learning story and survey. We used three quantitative scales and a qualitative survey to examine users characteristics and perceptions of the systems support for their self-regulation. User feedback suggests the systems viability as a self-regulation aid. Learners particularly valued in-situ reflection, automated story feedback, and video annotation, while other features received mixed views. We highlight perceived benefits, friction points, and design opportunities for future AI-augmented self-regulation tools.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746027.3755547" target="_blank">Graph-Guided Dual-Level Augmentation for 3D Scene Segmentation</a></h3>
                    <p><strong>Authors:</strong> Hongbin Lin, Yifan Jiang, Juangui Xu, Jesse Jiaxi Xu, Yi Lu, Zhengyu Hu, Ying-Cong Chen, Hao Wang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D point cloud segmentation aims to assign semantic labels to individual points in a scene for fine-grained spatial understanding. Existing methods typically adopt data augmentation to alleviate the burden of large-scale annotation. However, most augmentation strategies only focus on local transformations or semantic recomposition, lacking the consideration of global structural dependencies within scenes. To address this limitation, we propose a graph-guided data augmentation framework with dual-level constraints for realistic 3D scene synthesis. Our method learns object relationship statistics from real-world data to construct guiding graphs for scene generation. Local-level constraints enforce geometric plausibility and semantic consistency between objects, while global-level constraints maintain the topological structure of the scene by aligning the generated layout with the guiding graph. Extensive experiments on indoor and outdoor datasets demonstrate that our framework generates diverse and high-quality augmented scenes, leading to consistent improvements in point cloud segmentation performance across various models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22666v1" target="_blank">Unconventional hybrid-order topological insulators</a></h3>
                    <p><strong>Authors:</strong> Wei Jia, Yuping Tian, Huanhuan Yang, Xiangru Kong, Zhi-Hao Huang, Wei-Jiang Gong, Jun-Hong An</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.str-el, quant-ph</p>
                    <p><strong>Summary:</strong> Exploring topological matters with exotic quantum states can update the understanding of topological phases and broaden the classification of topological materials. Here, we report a class of unconventional hybrid-order topological insulators (HyOTIs), which simultaneously host various different higher-order topological states in a single $d$-dimensional ($d$D) system. Such topological states exhibit a unique bulk-boundary correspondence that is different from first-order topological states, higher-order topological states, and the coexistence of both. Remarkably, we develop a generic surface theory to precisely capture them and firstly discover a $3$D unconventional HyOTI protected by inversion symmetry, which renders both second-order (helical) and third-order (corner) topological states in one band gap and exhibits a novel bulk-edge-corner correspondence. By adjusting the parameters of the system, we also observe the nontrivial phase transitions between the inversion-symmetric HyOTI and other conventional phases. We further propose a circuit-based experimental scheme to detect these interesting results. Particularly, we demonstrate that a modified tight-binding model of bismuth can support the unconventional HyOTI, suggesting a possible route for its material realization. This work shall significantly advance the research of hybrid topological states in both theory and experiment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22659v1" target="_blank">A Systematic Literature Review on Detecting Software Vulnerabilities with Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Sabrina Kaniewski, Fabian Schmidt, Markus Enzweiler, Michael Menth, Tobias Heer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> The increasing adoption of Large Language Models (LLMs) in software engineering has sparked interest in their use for software vulnerability detection. However, the rapid development of this field has resulted in a fragmented research landscape, with diverse studies that are difficult to compare due to differences in, e.g., system designs and dataset usage. This fragmentation makes it difficult to obtain a clear overview of the state-of-the-art or compare and categorize studies meaningfully. In this work, we present a comprehensive systematic literature review (SLR) of LLM-based software vulnerability detection. We analyze 227 studies published between January 2020 and June 2025, categorizing them by task formulation, input representation, system architecture, and adaptation techniques. Further, we analyze the datasets used, including their characteristics, vulnerability coverage, and diversity. We present a fine-grained taxonomy of vulnerability detection approaches, identify key limitations, and outline actionable future research opportunities. By providing a structured overview of the field, this review improves transparency and serves as a practical guide for researchers and practitioners aiming to conduct more comparable and reproducible research. We publicly release all artifacts and maintain a living repository of LLM-based software vulnerability detection studies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22635v1" target="_blank">trAIce3D: A Prompt-Driven Transformer Based U-Net for Semantic Segmentation of Microglial Cells from Large-Scale 3D Microscopy Images</a></h3>
                    <p><strong>Authors:</strong> MohammadAmin Alamalhoda, Arsalan Firoozi, Alessandro Venturino, Sandra Siegert</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> The shape of a cell contains essential information about its function within the biological system. Segmenting these structures from large-scale 3D microscopy images is challenging, limiting clinical insights especially for microglia, immune-associated cells involved in neurodegenerative diseases. Existing segmentation methods mainly focus on cell bodies, struggle with overlapping structures, perform poorly on noisy images, require hyperparameter tuning for each new dataset, or rely on tedious semi-automated approaches. We introduce trAIce3D, a deep-learning architecture designed for precise microglia segmentation, capturing both somas and branches. It employs a two-stage approach: first, a 3D U-Net with vision transformers in the encoder detects somas using a sliding-window technique to cover the entire image. Then, the same architecture, enhanced with cross-attention blocks in skip connections, refines each soma and its branches by using soma coordinates as a prompt and a 3D window around the target cell as input. Training occurs in two phases: self-supervised Soma Segmentation, followed by prompt-based Branch Segmentation, leveraging pre-trained weights from the first phase. Trained and evaluated on a dataset of 41,230 microglial cells, trAIce3D significantly improves segmentation accuracy and generalization, enabling scalable analysis of complex cellular morphologies. While optimized for microglia, its architecture can extend to other intricate cell types, such as neurons and astrocytes, broadening its impact on neurobiological research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22633v1" target="_blank">H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity</a></h3>
                    <p><strong>Authors:</strong> Wei Guo, Siyuan Lu, Yiqi Tong, Zhaojun Hu, Fuzhen Zhuang, Xiao Zhang, Tao Fan, Jin Dong</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Different from existing federated fine-tuning (FFT) methods for foundation models, hybrid heterogeneous federated fine-tuning (HHFFT) is an under-explored scenario where clients exhibit double heterogeneity in model architectures and downstream tasks. This hybrid heterogeneity introduces two significant challenges: 1) heterogeneous matrix aggregation, where clients adopt different large-scale foundation models based on their task requirements and resource limitations, leading to dimensional mismatches during LoRA parameter aggregation; and 2) multi-task knowledge interference, where local shared parameters, trained with both task-shared and task-specific knowledge, cannot ensure only task-shared knowledge is transferred between clients. To address these challenges, we propose H2Tune, a federated foundation model fine-tuning with hybrid heterogeneity. Our framework H2Tune consists of three key components: (i) sparsified triple matrix decomposition to align hidden dimensions across clients through constructing rank-consistent middle matrices, with adaptive sparsification based on client resources; (ii) relation-guided matrix layer alignment to handle heterogeneous layer structures and representation capabilities; and (iii) alternating task-knowledge disentanglement mechanism to decouple shared and specific knowledge of local model parameters through alternating optimization. Theoretical analysis proves a convergence rate of O(1/\sqrt{T}). Extensive experiments show our method achieves up to 15.4% accuracy improvement compared to state-of-the-art baselines. Our code is available at https://anonymous.4open.science/r/H2Tune-1407.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22887v1" target="_blank">Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning</a></h3>
                    <p><strong>Authors:</strong> Kwesi Cobbina, Tianyi Zhou</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> In-context learning (ICL) is a critical emerging capability of large language models (LLMs), enabling few-shot learning during inference by including a few demonstrations (demos) in the prompt. However, it has been found that ICLs performance can be sensitive to the choices of demos and their order. This paper investigates an unexplored new positional bias of ICL for the first time: we observe that the predictions and accuracy can drift drastically when the positions of demos, the system prompt, and the user message in LLM input are varied. We refer to this bias as DEMOS POSITION IN PROMPT (DPP) bias. We design a systematic evaluation pipeline to study this type of positional bias across classification, question answering, summarization, and reasoning tasks. We introduce two metrics, ACCURACY-CHANGE and PREDICTION-CHANGE, to quantify net gains and output volatility induced by changes in the demos position. Extensive experiments on ten LLMs from four open-source model families (QWEN, LLAMA3, MISTRAL, COHERE) verify that the bias significantly affects their accuracy and predictions: placing demos at the start of the prompt yields the most stable and accurate outputs with gains of up to +6 points. In contrast, placing demos at the end of the user message flips over 30\% of predictions without improving correctness on QA tasks. Smaller models are most affected by this sensitivity, though even large models remain marginally affected on complex tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22885v1" target="_blank">Viser: Imperative, Web-based 3D Visualization in Python</a></h3>
                    <p><strong>Authors:</strong> Brent Yi, Chung Min Kim, Justin Kerr, Gina Wu, Rebecca Feng, Anthony Zhang, Jonas Kulhanek, Hongsuk Choi, Yi Ma, Matthew Tancik, Angjoo Kanazawa</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> We present Viser, a 3D visualization library for computer vision and robotics. Viser aims to bring easy and extensible 3D visualization to Python: we provide a comprehensive set of 3D scene and 2D GUI primitives, which can be used independently with minimal setup or composed to build specialized interfaces. This technical report describes Visers features, interface, and implementation. Key design choices include an imperative-style API and a web-based viewer, which improve compatibility with modern programming patterns and workflows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22886v1" target="_blank">Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation</a></h3>
                    <p><strong>Authors:</strong> Kaining Ying, Henghui Ding, Guanquan Jie, Yu-Gang Jiang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Referring audio-visual segmentation (RAVS) has recently seen significant advancements, yet challenges remain in integrating multimodal information and deeply understanding and reasoning about audiovisual content. To extend the boundaries of RAVS and facilitate future research in this field, we propose Omnimodal Referring Audio-Visual Segmentation (OmniAVS), a new dataset containing 2,098 videos and 59,458 multimodal referring expressions. OmniAVS stands out with three key innovations: (1) 8 types of multimodal expressions that flexibly combine text, speech, sound, and visual cues; (2) an emphasis on understanding audio content beyond just detecting their presence; and (3) the inclusion of complex reasoning and world knowledge in expressions. Furthermore, we introduce Omnimodal Instructed Segmentation Assistant (OISA), to address the challenges of multimodal reasoning and fine-grained understanding of audiovisual content in OmniAVS. OISA uses MLLM to comprehend complex cues and perform reasoning-based segmentation. Extensive experiments show that OISA outperforms existing methods on OmniAVS and achieves competitive results on other related tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22883v1" target="_blank">Operational interpretation of the Stabilizer Entropy</a></h3>
                    <p><strong>Authors:</strong> Lennart Bittel, Lorenzo Leone</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Magic-state resource theory is a fundamental framework with far-reaching applications in quantum error correction and the classical simulation of quantum systems. Recent advances have significantly deepened our understanding of magic as a resource across diverse domains, including many-body physics, nuclear and particle physics, and quantum chemistry. Central to this progress is the stabilizer R\enyi entropy, a computable and experimentally accessible magic monotone. Despite its widespread adoption, a rigorous operational interpretation of the stabilizer entropy has remained an open problem. In this work, we provide such an interpretation in the context of quantum property testing. By showing that the stabilizer entropy is the most robust measurable magic monotone, we demonstrate that the Clifford orbit of a quantum state becomes exponentially indistinguishable from Haar-random states, at a rate governed by the stabilizer entropy $M(\psi)$ and the number of available copies. This implies that the Clifford orbit forms an approximate state $k$-design, with an approximation error $\Theta(\exp(-M(\psi))$. Conversely, we establish that the optimal probability of distinguishing a given quantum state from the set of stabilizer states is also governed by its stabilizer entropy. These results reveal that the stabilizer entropy quantitatively characterizes the transition from stabilizer states to universal quantum states, thereby offering a comprehensive operational perspective of the stabilizer entropy as a quantum resource.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22882v1" target="_blank">Non-classicality at equilibrium and efficient predictions under non-commuting charges</a></h3>
                    <p><strong>Authors:</strong> Lodovico Scarpa, Nishan Ranabhat, Amit Teeni, Abdulla Alhajri, Vlatko Vedral, Fabio Anza, Luis Pedro Garc√≠a-Pintos</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.stat-mech</p>
                    <p><strong>Summary:</strong> A quantum thermodynamic system can conserve non-commuting observables, but the consequences of this phenomenon on relaxation are still not fully understood. We investigate this problem by leveraging an observable-dependent approach to equilibration and thermalization in isolated quantum systems. We extend such approach to scenarios with non-commuting charges, and show that it can accurately estimate the equilibrium distribution of coarse observables without access to the energy eigenvalues and eigenvectors. Our predictions do not require weak coupling and are not restricted to local observables, thus providing an advantage over the non-Abelian thermal state. Within this approach, weak values and quasiprobability distributions emerge naturally and play a crucial role in characterizing the equilibrium distributions of observables. We show and numerically confirm that, due to charges non-commutativity, these weak values can be anomalous even at equilibrium, which has been proven to be a proxy for non-classicality. Our work thus uncovers a novel connection between the relaxation of observables under non-commuting charges, weak values, and Kirkwood-Dirac quasiprobability distributions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22879v1" target="_blank">RecGPT Technical Report</a></h3>
                    <p><strong>Authors:</strong> Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Mao Zhang, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL</p>
                    <p><strong>Summary:</strong> Recommender systems are among the most impactful applications of artificial intelligence, serving as critical infrastructure connecting users, merchants, and platforms. However, most current industrial systems remain heavily reliant on historical co-occurrence patterns and log-fitting objectives, i.e., optimizing for past user interactions without explicitly modeling user intent. This log-fitting approach often leads to overfitting to narrow historical preferences, failing to capture users evolving and latent interests. As a result, it reinforces filter bubbles and long-tail phenomena, ultimately harming user experience and threatening the sustainability of the whole recommendation ecosystem. To address these challenges, we rethink the overall design paradigm of recommender systems and propose RecGPT, a next-generation framework that places user intent at the center of the recommendation pipeline. By integrating large language models (LLMs) into key stages of user interest mining, item retrieval, and explanation generation, RecGPT transforms log-fitting recommendation into an intent-centric process. To effectively align general-purpose LLMs to the above domain-specific recommendation tasks at scale, RecGPT incorporates a multi-stage training paradigm, which integrates reasoning-enhanced pre-alignment and self-training evolution, guided by a Human-LLM cooperative judge system. Currently, RecGPT has been fully deployed on the Taobao App. Online experiments demonstrate that RecGPT achieves consistent performance gains across stakeholders: users benefit from increased content diversity and satisfaction, merchants and the platform gain greater exposure and conversions. These comprehensive improvement results across all stakeholders validates that LLM-driven, intent-centric design can foster a more sustainable and mutually beneficial recommendation ecosystem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22878v1" target="_blank">GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for Multiresolution Power Outage Analysis</a></h3>
                    <p><strong>Authors:</strong> Ethan Frakes, Yinghui Wu, Roger H. French, Mengjie Li</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Detecting, analyzing, and predicting power outages is crucial for grid risk assessment and disaster mitigation. Numerous outages occur each year, exacerbated by extreme weather events such as hurricanes. Existing outage data are typically reported at the county level, limiting their spatial resolution and making it difficult to capture localized patterns. However, it offers excellent temporal granularity. In contrast, nighttime light satellite image data provides significantly higher spatial resolution and enables a more comprehensive spatial depiction of outages, enhancing the accuracy of assessing the geographic extent and severity of power loss after disaster events. However, these satellite data are only available on a daily basis. Integrating spatiotemporal visual and time-series data sources into a unified knowledge representation can substantially improve power outage detection, analysis, and predictive reasoning. In this paper, we propose GeoOutageKG, a multimodal knowledge graph that integrates diverse data sources, including nighttime light satellite image data, high-resolution spatiotemporal power outage maps, and county-level timeseries outage reports in the U.S. We describe our method for constructing GeoOutageKG by aligning source data with a developed ontology, GeoOutageOnto. Currently, GeoOutageKG includes over 10.6 million individual outage records spanning from 2014 to 2024, 300,000 NTL images spanning from 2012 to 2024, and 15,000 outage maps. GeoOutageKG is a novel, modular and reusable semantic resource that enables robust multimodal data integration. We demonstrate its use through multiresolution analysis of geospatiotemporal power outages.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22877v1" target="_blank">Consistency of Feature Attribution in Deep Learning Architectures for Multi-Omics</a></h3>
                    <p><strong>Authors:</strong> Daniel Claborne, Javier Flores, Samantha Erwin, Luke Durell, Rachel Richardson, Ruby Fore, Lisa Bramer</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Machine and deep learning have grown in popularity and use in biological research over the last decade but still present challenges in interpretability of the fitted model. The development and use of metrics to determine features driving predictions and increase model interpretability continues to be an open area of research. We investigate the use of Shapley Additive Explanations (SHAP) on a multi-view deep learning model applied to multi-omics data for the purposes of identifying biomolecules of interest. Rankings of features via these attribution methods are compared across various architectures to evaluate consistency of the method. We perform multiple computational experiments to assess the robustness of SHAP and investigate modeling approaches and diagnostics to increase and measure the reliability of the identification of important features. Accuracy of a random-forest model fit on subsets of features selected as being most influential as well as clustering quality using only these features are used as a measure of effectiveness of the attribution method. Our findings indicate that the rankings of features resulting from SHAP are sensitive to the choice of architecture as well as different random initializations of weights, suggesting caution when using attribution methods on multi-view deep learning models applied to multi-omics data. We present an alternative, simple method to assess the robustness of identification of important biomolecules.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22876v1" target="_blank">Automatically discovering heuristics in a complex SAT solver with large language models</a></h3>
                    <p><strong>Authors:</strong> Yiwen Sun, Furong Ye, Zhihan Chen, Ke Wei, Shaowei Cai</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LO</p>
                    <p><strong>Summary:</strong> Satisfiability problem (SAT) is a cornerstone of computational complexity with broad industrial applications, and it remains challenging to optimize modern SAT solvers in real-world settings due to their intricate architectures. While automatic configuration frameworks have been developed, they rely on manually constrained search spaces and yield limited performance gains. This work introduces a novel paradigm which effectively optimizes complex SAT solvers via Large Language Models (LLMs), and a tool called AutoModSAT is developed. Three fundamental challenges are addressed in order to achieve superior performance: (1) LLM-friendly solver: Systematic guidelines are proposed for developing a modularized solver to meet LLMs compatibility, emphasizing code simplification, information share and bug reduction; (2) Automatic prompt optimization: An unsupervised automatic prompt optimization method is introduced to advance the diversity of LLMs output; (3) Efficient search strategy: We design a presearch strategy and an EA evolutionary algorithm for the final efficient and effective discovery of heuristics. Extensive experiments across a wide range of datasets demonstrate that AutoModSAT achieves 50% performance improvement over the baseline solver and achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover, AutoModSAT attains a 20% speedup on average compared to parameter-tuned alternatives of the SOTA solvers, showcasing the enhanced capability in handling complex problem instances. This work bridges the gap between AI-driven heuristics discovery and mission-critical system optimization, and provides both methodological advancements and empirically validated results for next-generation complex solver development.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22875v1" target="_blank">Numerical Fredholm determinants for matrix-valued kernels on the real line</a></h3>
                    <p><strong>Authors:</strong> Erika Gallo, John Zweck, Yuri Latushkin</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, math.FA, math.SP, 65R20, 65F40 (Primary) 47G10 (Secondary)</p>
                    <p><strong>Summary:</strong> We analyze a numerical method for computing Fredholm determinants of trace class and Hilbert Schmidt integral operators defined in terms of matrix-valued kernels on the entire real line. With this method, the Fredholm determinant is approximated by the determinant of a matrix constructed by truncating the kernel of the operator to a finite interval and then applying a quadrature rule. Under the assumption that the kernel decays exponentially, we derive an estimate relating the Fredholm determinant of the operator on the real line to that of its truncation to a finite interval. Then we derive a quadrature error estimate relating the Fredholm determinant of a matrix-valued kernel on a finite interval to its numerical approximation obtained via an adaptive composite Simpsons quadrature rule. These results extend the analysis of Bornemann which focused on Fredholm determinants of trace class operators defined by scalar-valued kernels on a finite interval. Numerical results are provided for a Birman-Schwinger operator that characterizes the stability of stationary solutions of nonlinear wave equations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22874v1" target="_blank">Non-periodic Boundary Conditions for Euler Class and Dynamical Signatures of Obstruction</a></h3>
                    <p><strong>Authors:</strong> Osama A. Alsaiari, Adrien Bouhon, Robert-Jan Slager, F. Nur √únal</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas, cond-mat.mes-hall, physics.atom-ph, quant-ph</p>
                    <p><strong>Summary:</strong> While the landscape of free-fermion phases has drastically been expanded in the last decades, recently novel multi-gap topological phases were proposed where groups of bands can acquire new invariants such as Euler class. As in conventional single-gap topologies, obstruction plays an inherent role that so far has only been incidentally addressed. We here systematically investigate the nuances of the relation between the non-Bravais lattice configurations and the Brillouin zone boundary conditions (BZBCs) for any number of dimensions. Clarifying the nomenclature, we provide a general periodictization recipe to obtain a gauge with an almost Brillouin-zone-periodic Bloch Hamiltonian both generally and upon imposing a reality condition on Hamiltonians for Euler class. Focusing on three-band $\mathcal{C}_2$ symmetric Euler systems in two dimensions as a guiding example, we present a procedure to enumerate the possible lattice configurations, and thus the unique BZBCs possibilities. We establish a comprehensive classification for the identified BZBC patterns according to the parity constraints they impose on the Euler invariant, highlighting how it extends to more bands and higher dimensions. Moreover, by building upon previous work utilizing Hopf maps, we illustrate physical consequences of non-trivial BZBCs in the quench dynamics of non-Bravais lattice Euler systems, reflecting the parity of the Euler invariant. We numerically confirm our results and corresponding observable signatures, and discuss possible experimental implementations. Our work presents a general framework to study the role of non-trivial boundary conditions and obstructions on multi-gap topology that can be employed for arbitrary number bands or in higher dimensions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22873v1" target="_blank">LCS: An AI-based Low-Complexity Scaler for Power-Efficient Super-Resolution of Game Content</a></h3>
                    <p><strong>Authors:</strong> Simon Pochinda, Momen K. Tageldeen, Mark Thompson, Tony Rinaldi, Troy Giorshev, Keith Lee, Jie Zhou, Frederick Walls</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> The increasing complexity of content rendering in modern games has led to a problematic growth in the workload of the GPU. In this paper, we propose an AI-based low-complexity scaler (LCS) inspired by state-of-the-art efficient super-resolution (ESR) models which could offload the workload on the GPU to a low-power device such as a neural processing unit (NPU). The LCS is trained on GameIR image pairs natively rendered at low and high resolution. We utilize adversarial training to encourage reconstruction of perceptually important details, and apply reparameterization and quantization techniques to reduce model complexity and size. In our comparative analysis we evaluate the LCS alongside the publicly available AMD hardware-based Edge Adaptive Scaling Function (EASF) and AMD FidelityFX Super Resolution 1 (FSR1) on five different metrics, and find that the LCS achieves better perceptual quality, demonstrating the potential of ESR models for upscaling on resource-constrained devices.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22872v1" target="_blank">TR-PTS: Task-Relevant Parameter and Token Selection for Efficient Tuning</a></h3>
                    <p><strong>Authors:</strong> Siqi Luo, Haoran Yang, Yi Xin, Mingyang Yi, Guangyang Wu, Guangtao Zhai, Xiaohong Liu</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Large pre-trained models achieve remarkable performance in vision tasks but are impractical for fine-tuning due to high computational and storage costs. Parameter-Efficient Fine-Tuning (PEFT) methods mitigate this issue by updating only a subset of parameters; however, most existing approaches are task-agnostic, failing to fully exploit task-specific adaptations, which leads to suboptimal efficiency and performance. To address this limitation, we propose Task-Relevant Parameter and Token Selection (TR-PTS), a task-driven framework that enhances both computational efficiency and accuracy. Specifically, we introduce Task-Relevant Parameter Selection, which utilizes the Fisher Information Matrix (FIM) to identify and fine-tune only the most informative parameters in a layer-wise manner, while keeping the remaining parameters frozen. Simultaneously, Task-Relevant Token Selection dynamically preserves the most informative tokens and merges redundant ones, reducing computational overhead. By jointly optimizing parameters and tokens, TR-PTS enables the model to concentrate on task-discriminative information. We evaluate TR-PTS on benchmark, including FGVC and VTAB-1k, where it achieves state-of-the-art performance, surpassing full fine-tuning by 3.40% and 10.35%, respectively. The code are available at https://github.com/synbol/TR-PTS.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1103/l3xp-yrrv" target="_blank">Solitons, chaos, and quantum phenomena: a deterministic approach to the Schr√∂dinger equation</a></h3>
                    <p><strong>Authors:</strong> Dami√† Gomila</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph, nlin.PS</p>
                    <p><strong>Summary:</strong> We show that the Schr\odinger equation describes the ensemble mean dynamics of solitons in a Galilean invariant field theory where we interpret solitons as particles. On a zero background, solitons move classically, following Newton`s second law, however, on a non-zero amplitude chaotic background, their momentum and position fluctuate fulfilling an exact uncertainty relation, which give rise to the emergence of quantum phenomena. The Schrodinger equation for the ensemble of solitons is obtained from this exact uncertainty relation, and the amplitude of the background fluctuations is what corresponds to the value of $\hbar$. We confirm our analytical results running simulations of solitons moving against a potential barrier and comparing the ensemble probabilities with the predictions of the time dependent Schr\odinger equation, providing a deterministic version of the quantum tunneling effect. We conclude with a discussion of how our theory does not present statistical independence between measurement and experiment outcome.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22865v1" target="_blank">Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue</a></h3>
                    <p><strong>Authors:</strong> Sahan Liyanaarachchi, Sennur Ulukus</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.SY, eess.SY, math.IT</p>
                    <p><strong>Summary:</strong> With the dawn of AI factories ushering a new era of computing supremacy, development of strategies to effectively track and utilize the available computing resources is garnering utmost importance. These computing resources are often modeled as Markov sources, which oscillate between free and busy states, depending on their internal load and external utilization, and are commonly referred to as Markov machines (MMs). Most of the prior work solely focuses on the problem of tracking these MMs, while often assuming a rudimentary decision process that governs their utilization. Our key observation is that the ultimate goal of tracking a MM is to properly utilize it. In this work, we consider the problem of maximizing the utility of a MM, where the utility is defined as the average revenue generated by the MM. Assuming a Poisson job arrival process and a query-based sampling procedure to sample the state of the MM, we find the optimal times to submit the available jobs to the MM so as to maximize the average revenue generated per unit job. We show that, depending on the parameters of the MM, the optimal policy is in the form of either a \emph{threshold policy} or a \emph{switching policy} based on the \emph{age of our estimate} of the state of the MM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22862v1" target="_blank">Parameter Estimation for GW200208\_22 with Targeted Eccentric Numerical-relativity Simulations</a></h3>
                    <p><strong>Authors:</strong> Patricia McMillin, Katelyn J. Wagner, Giuseppe Ficarra, Carlos O. Lousto, Richard OShaughnessy</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.HE</p>
                    <p><strong>Summary:</strong> We have analyzed LVK gravitational wave events that show some evidence of eccentricity from TEOBResumS modeling parameter estimations and have confronted them independently with full numerical generated waveforms from our bank of nearly two thousand simulations of binary black holes. We have used RIFT for Bayesian parameter estimation and found that GW200208\_{22} KDE estimates favor eccentricities $e_{20} = 0.217_{-0.184}^{+0.076}$ upon entering the LVK band at $\sim20$Hz within a 90\% confidence limit. Within this event analysis we employed 39 new targeted full numerical relativity simulations and we have thus found a top improved likelihood $\ln \mathcal{L}$ matching waveform, compared to model-based analysis, with an estimated eccentricity at 20Hz, $e_{20}=0.200$, thus reinforcing the eccentric hypothesis of the binary. We have also used our full bank of numerical waveforms on GW190620 finding that it favors eccentricities in the range of {$0\leq e_{10}\leq0.3$}. New specifically targeted simulations will be required to narrow this eccentricity range.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22859v1" target="_blank">Mesh based segmentation for automated margin line generation on incisors receiving crown treatment</a></h3>
                    <p><strong>Authors:</strong> Ammar Alsheghri, Ying Zhang, Farnoosh Ghadiri, Julia Keren, Farida Cheriet, Francois Guibault</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CE, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Dental crowns are essential dental treatments for restoring damaged or missing teeth of patients. Recent design approaches of dental crowns are carried out using commercial dental design software. Once a scan of a preparation is uploaded to the software, a dental technician needs to manually define a precise margin line on the preparation surface, which constitutes a non-repeatable and inconsistent procedure. This work proposes a new framework to determine margin lines automatically and accurately using deep learning. A dataset of incisor teeth was provided by a collaborating dental laboratory to train a deep learning segmentation model. A mesh-based neural network was modified by changing its input channels and used to segment the prepared tooth into two regions such that the margin line is contained within the boundary faces separating the two regions. Next, k-fold cross-validation was used to train 5 models, and a voting classifier technique was used to combine their results to enhance the segmentation. After that, boundary smoothing and optimization using the graph cut method were applied to refine the segmentation results. Then, boundary faces separating the two regions were selected to represent the margin line faces. A spline was approximated to best fit the centers of the boundary faces to predict the margin line. Our results show that an ensemble model combined with maximum probability predicted the highest number of successful test cases (7 out of 13) based on a maximum distance threshold of 200 m (representing human error) between the predicted and ground truth point clouds. It was also demonstrated that the better the quality of the preparation, the smaller the divergence between the predicted and ground truth margin lines (Spearmans rank correlation coefficient of -0.683). We provide the train and test datasets for the community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22855v1" target="_blank">Federated Learning on Riemannian Manifolds: A Gradient-Free Projection-Based Approach</a></h3>
                    <p><strong>Authors:</strong> Hongye Wang, Zhaoye Pan, Chang He, Jiaxiang Li, Bo Jiang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.OC, cs.LG</p>
                    <p><strong>Summary:</strong> Federated learning (FL) has emerged as a powerful paradigm for collaborative model training across distributed clients while preserving data privacy. However, existing FL algorithms predominantly focus on unconstrained optimization problems with exact gradient information, limiting its applicability in scenarios where only noisy function evaluations are accessible or where model parameters are constrained. To address these challenges, we propose a novel zeroth-order projection-based algorithm on Riemannian manifolds for FL. By leveraging the projection operator, we introduce a computationally efficient zeroth-order Riemannian gradient estimator. Unlike existing estimators, ours requires only a simple Euclidean random perturbation, eliminating the need to sample random vectors in the tangent space, thus reducing computational cost. Theoretically, we first prove the approximation properties of the estimator and then establish the sublinear convergence of the proposed algorithm, matching the rate of its first-order counterpart. Numerically, we first assess the efficiency of our estimator using kernel principal component analysis. Furthermore, we apply the proposed algorithm to two real-world scenarios: zeroth-order attacks on deep neural networks and low-rank neural network training to validate the theoretical findings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22854v1" target="_blank">A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model</a></h3>
                    <p><strong>Authors:</strong> Andris Ambainis, Joao F. Doriguello, Debbie Lim</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, math.OC, quant-ph, stat.ML</p>
                    <p><strong>Summary:</strong> We propose novel classical and quantum online algorithms for learning finite-horizon and infinite-horizon average-reward Markov Decision Processes (MDPs). Our algorithms are based on a hybrid exploration-generative reinforcement learning (RL) model wherein the agent can, from time to time, freely interact with the environment in a generative sampling fashion, i.e., by having access to a simulator. By employing known classical and new quantum algorithms for approximating optimal policies under a generative model within our learning algorithms, we show that it is possible to avoid several paradigms from RL like optimism in the face of uncertainty and posterior sampling and instead compute and use optimal policies directly, which yields better regret bounds compared to previous works. For finite-horizon MDPs, our quantum algorithms obtain regret bounds which only depend logarithmically on the number of time steps $T$, thus breaking the $O(\sqrt{T})$ classical barrier. This matches the time dependence of the prior quantum works of Ganguly et al. (arXiv23) and Zhong et al. (ICML24), but with improved dependence on other parameters like state space size $S$ and action space size $A$. For infinite-horizon MDPs, our classical and quantum bounds still maintain the $O(\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we propose a novel measure of regret for infinite-horizon MDPs with respect to which our quantum algorithms have $\operatorname{poly}\log{T}$ regret, exponentially better compared to classical algorithms. Finally, we generalise all of our results to compact state spaces.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22851v1" target="_blank">Morph: ChirpTransformer-based Encoder-decoder Co-design for Reliable LoRa Communication</a></h3>
                    <p><strong>Authors:</strong> Yidong Ren, Maolin Gan, Chenning Li, Shakhrul Iman Siam, Mi Zhang, Shigang Chen, Zhichao Cao</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.NI, eess.SP</p>
                    <p><strong>Summary:</strong> In this paper, we propose Morph, a LoRa encoder-decoder co-design to enhance communication reliability while improving its computation efficiency in extremely-low signal-to-noise ratio (SNR) situations. The standard LoRa encoder controls 6 Spreading Factors (SFs) to tradeoff SNR tolerance with data rate. SF-12 is the maximum SF providing the lowest SNR tolerance on commercial off-the-shelf (COTS) LoRa nodes. In Morph, we develop an SF-configuration based encoder to mimic the larger SFs beyond SF-12 while it is compatible with COTS LoRa nodes. Specifically, we manipulate four SF configurations of a Morph symbol to encode 2-bit data. Accordingly, we recognize the used SF configuration of the symbol for data decoding. We leverage a Deep Neural Network (DNN) decoder to fully capture multi-dimensional features among diverse SF configurations to maximize the SNR gain. Moreover, we customize the input size, neural network structure, and training method of the DNN decoder to improve its efficiency, reliability, and generalizability. We implement Morph with COTS LoRa nodes and a USRP N210, then evaluate its performance on indoor and campus-scale testbeds. Results show that we can reliably decode data at -28.8~dB SNR, which is 6.4~dB lower than the standard LoRa with SF-12 chirps. In addition, the computation efficiency of our DNN decoder is about 3x higher than state-of-the-art.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22847v1" target="_blank">The Incomplete Bridge: How AI Research (Mis)Engages with Psychology</a></h3>
                    <p><strong>Authors:</strong> Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, Ziang Xiao</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> Social sciences have accumulated a rich body of theories and methodologies for investigating the human mind and behaviors, while offering valuable insights into the design and understanding of Artificial Intelligence (AI) systems. Focusing on psychology as a prominent case, this study explores the interdisciplinary synergy between AI and the field by analyzing 1,006 LLM-related papers published in premier AI venues between 2023 and 2025, along with the 2,544 psychology publications they cite. Through our analysis, we identify key patterns of interdisciplinary integration, locate the psychology domains most frequently referenced, and highlight areas that remain underexplored. We further examine how psychology theories/frameworks are operationalized and interpreted, identify common types of misapplication, and offer guidance for more effective incorporation. Our work provides a comprehensive map of interdisciplinary engagement between AI and psychology, thereby facilitating deeper collaboration and advancing AI systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22846v1" target="_blank">Digital Quantum Simulation of Spin Transport</a></h3>
                    <p><strong>Authors:</strong> Yi-Ting Lee, Bibek Pokharel, Jeffrey Cohn, Andre Schleife, Arnab Banerjee</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Understanding transport phenomena in quantum spin systems has long intrigued physicists due to their potential applications in spintronic devices and spin qubits. Here, using a superconducting-qubit-based transmon device, we show that pre-fault-tolerant digital quantum simulation is reliable for studying transport phenomena via spin-current autocorrelation function (ACF). While quantum simulations of the spin-spin ACF have been used to probe spin transport, methods based on the spin-current ACF have yet to be demonstrated due to their high gate cost, despite offering more direct information relevant to the transport properties. Overcoming the resource constraints set by indirect measurement schemes like the Hadamard test, we showcase a direct measurement scheme that utilizes non-unitary operations, in particular mid-circuit measurements, to investigate spin transport for the 40-site 1D XXZ Heisenberg model in the near-ballistic, superdiffusive, and diffusive regimes. We successfully reproduce the expected power-law behavior in the superdiffusive regime and vanishing of the Drude weight in the diffusive regime.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22845v1" target="_blank">Connection Between Classical and Quantum Descriptions of Spin Waves Using Quantum Circuits</a></h3>
                    <p><strong>Authors:</strong> Daniel D. Stancil, Bojko N. Bakalov, Gregory T. Byrd</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> A quantum computing circuit is presented that approximates a single spin wave quantum on a linear chain of spin 1/2 particles described by a Heisenberg Hamiltonian. The circuit is a product state where each qubit represents a spin. The spin wave motion is represented by opening the cone angle using Y rotations and then adding progressive Z rotations along the chain to represent wave propagation. We show analytically that this product state yields the correct dispersion relation in the limit of an unbounded chain. This surprising observation is confirmed using both a simulator and various quantum processors. The quantum circuit calculation leads to insight into the connection between classical and quantum descriptions of spin waves, and may also be useful for characterizing the error in quantum processors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22843v1" target="_blank">DEQSE Quantum IDE Extension: Integrated Tool for Quantum Software Engineering</a></h3>
                    <p><strong>Authors:</strong> Majid Haghparast, Ronja Heikkinen, Samuel Ovaskainen, Julian Fuchs, Jussi P P Jokinen, Tommi Mikkonen</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> This paper presents a tool that simplifies quantum software development by unifying circuit design, code generation, and execution within a single cross-platform environment that supports iterative development. Implemented as open source, the DEQSE Quantum IDE Extension has been developed to provide quantum functionalities within the Visual Studio Code environment, including project creator, code runner, code converter, and embedded quantum circuit simulator. Furthermore, the system provides capabilities that facilitate iterative development and support learning, distinguishing it from other available Visual Studio Code Extensions for quantum computing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22841v1" target="_blank">The Construction of Correlators in Finite Rigid Logarithmic Conformal Field Theory</a></h3>
                    <p><strong>Authors:</strong> Lukas Woike</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.QA, math-ph, math.AT, math.MP, math.RT</p>
                    <p><strong>Summary:</strong> For logarithmic conformal field theories whose monodromy data is given by a not necessarily semisimple modular category, we solve the problem of constructing and classifying the consistent systems of correlators. The correlator construction given in this article generalizes the well-known one for rational conformal field theories given by Fuchs-Runkel-Schweigert roughly twenty years ago and solves conjectures of Fuchs, Gannon, Schaumann and Schweigert. The strategy is, even in the rational special case, entirely different. The correlators are constructed using the extension procedures that can be devised by means of the modular microcosm principle. It is shown that, as in the rational case, the correlators admit a holographic description, with the main difference that the holographic principle is phrased in terms of factorization homology. The latter description is used to prove that the coefficients of the torus partition function are non-negative integers. Moreover, we show that the derived algebra of local operators associated to a consistent system of correlators carries a Batalin-Vilkovisky structure. We prove that it is equivalent to the Batalin-Vilkovisky structure on the Hochschild cohomology of the pivotal module category of boundary conditions, for the notion of pivotality due to Schaumann and Shimizu. This proves several expectations formulated by Kapustin-Rozansky and Fuchs-Schweigert for general conformal field theories.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22838v1" target="_blank">Modelling and simulation of electro-mechanically coupled dielectric elastomers and myocardial tissue using smoothed finite element methods</a></h3>
                    <p><strong>Authors:</strong> Tan Tran, Denisa Martonova, Sigrid Leyendecker</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> Computational modelling offers a cost-effective and time-efficient alternative to experimental studies in biomedical engineering. In cardiac electro-mechanics, finite element method (FEM)-based simulations provide valuable insights into diseased tissue behaviour and the development of assistive systems such as di-electric elastomer actuators. However, the use of automatically generated tetrahedral meshes, commonly applied due to geometric complexity, often leads to numerical issues including overly stiff responses and volume locking, particularly in incompressible materials. Smoothed finite element methods (S-FEMs) offer a promising alternative by softening the stiffness matrix through gradient smoothing over defined smoothing domains. This work extends S-FEM formulations to electro-mechanically coupled problems and compares their performance against standard linear FEM. We implement and evaluate four approaches in the Abaqus environment via custom user elements: standard linear FEM, face-based S-FEM (FS-FEM), node-based S-FEM (NS-FEM), and the hybrid face/node-based S-FEM (FSNS-FEM). Two benchmark problems are studied: the electrically induced contraction of a compressible dielectric elastomer and an incompressible, orthotropic myocardial tissue sample. Reference solutions are obtained using a mesh consisting of higher-order elements. Our results demonstrate that FSNS-FEM provides the best balance between accuracy and computational efficiency, closely matching reference data. NS-FEM produces softer results, which leads to an overestimation of the true deformation. FS-FEM and standard FEM consistently exhibit overly stiff behaviour, with pronounced volume locking in the myocardial case. These findings support the potential of S-FEMs, in particular FSNS-FEM, for accurate simulation of coupled electro-mechanical behaviour in complex biomedical applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22837v1" target="_blank">Recoil-Safe Subtraction, Matching and Merging in e+e- to hadrons</a></h3>
                    <p><strong>Authors:</strong> Stefan H√∂che, Frank Krauss, Peter Meinzinger, Daniel Reichelt</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> hep-ph</p>
                    <p><strong>Summary:</strong> We present the first next-to-leading order matched and multi-jet merged predictions based on the Alaric parton shower. The components needed for infrared subtraction in the S-MC@NLO algorithm are computed analytically for the case of color singlet decays to hadronic final states and validated against existing approaches for up to e+e- to 5 jets. Phenomenological results for e+e- to hadrons at the Z pole are obtained with up to five jets at next-to-leading order precision, for the first time using an evolution algorithm with NLL-preserving kinematics mapping.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22835v1" target="_blank">Gravitons and Temperature Fluctuation Correlations from Inflation</a></h3>
                    <p><strong>Authors:</strong> L. H. Ford, I-Tai Ho, Chun-Hsien Wu</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.CO, hep-th</p>
                    <p><strong>Summary:</strong> Inflationary tensor perturbations are treated as arising from a bath of gravitons produced by quantum particle creation at the end of inflation. We calculate the correlation function of the CMB temperature fluctuations produced by these gravitons in a model with an infrared cut off. The CMB photons are emitted from within a last scattering shell of finite thickness in redshift. We find the correlation function in terms of the separation of a pair of spacetime points of emission in both angle and redshift. In both variables, there is a significant amount of anti-correlation. The anti-correlation minimum has a relative magnitude compared to the central correlation maximum of about 20% in angle and 50% in redshift.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22832v1" target="_blank">Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks</a></h3>
                    <p><strong>Authors:</strong> Maciej Satkiewicz</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV, cs.NE, I.2.6; I.4.10</p>
                    <p><strong>Summary:</strong> In this paper we argue that ReLU networks learn an implicit linear model we can actually tap into. We describe that alleged model formally and show that we can approximately pull its decision boundary back to the input space with certain simple modification to the backward pass. The resulting gradients (called excitation pullbacks) reveal high-resolution input- and target-specific features of remarkable perceptual alignment on a number of popular ImageNet-pretrained deep architectures. This strongly suggests that neural networks do, in fact, rely on learned interpretable patterns that can be recovered after training. Thus, our findings may have profound implications for knowledge discovery and the development of dependable artificial systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22829v1" target="_blank">Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused Table Summarization</a></h3>
                    <p><strong>Authors:</strong> Weijia Zhang, Songgaojun Deng, Evangelos Kanoulas</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Query-focused table summarization requires complex reasoning, often approached through step-by-step natural language (NL) plans. However, NL plans are inherently ambiguous and lack structure, limiting their conversion into executable programs like SQL and hindering scalability, especially for multi-table tasks. To address this, we propose a paradigm shift to structured representations. We introduce a new structured plan, TaSoF, inspired by formalism in traditional multi-agent systems, and a framework, SPaGe, that formalizes the reasoning process in three phases: 1) Structured Planning to generate TaSoF from a query, 2) Graph-based Execution to convert plan steps into SQL and model dependencies via a directed cyclic graph for parallel execution, and 3) Summary Generation to produce query-focused summaries. Our method explicitly captures complex dependencies and improves reliability. Experiments on three public benchmarks show that SPaGe consistently outperforms prior models in both single- and multi-table settings, demonstrating the advantages of structured representations for robust and scalable summarization.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746027.3755203" target="_blank">CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models</a></h3>
                    <p><strong>Authors:</strong> Kedong Xiu, Saiqian Zhang</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> As Vision-Language Models (VLMs) are increasingly deployed in split-DNN configurations--with visual encoders (e.g., ResNet, ViT) operating on user devices and sending intermediate features to the cloud--there is a growing privacy risk from semantic information leakage. Existing approaches to reconstructing images from these intermediate features often result in blurry, semantically ambiguous images. To directly address semantic leakage, we propose CapRecover, a cross-modality inversion framework that recovers high-level semantic content, such as labels or captions, directly from intermediate features without image reconstruction. We evaluate CapRecover on multiple datasets and victim models, demonstrating strong performance in semantic recovery. Specifically, CapRecover achieves up to 92.71% Top-1 label accuracy on CIFAR-10 and generates fluent captions from ResNet50 features on COCO2017 with ROUGE-L scores up to 0.52. Our analysis further reveals that deeper convolutional layers encode significantly more semantic information compared to shallow layers. To mitigate semantic leakage, we introduce a simple yet effective protection method: adding random noise to intermediate features at each layer and removing the noise in the next layer. Experimental results show that this approach prevents semantic leakage without additional training costs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22827v1" target="_blank">ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents</a></h3>
                    <p><strong>Authors:</strong> Yilei Jiang, Yaozhi Zheng, Yuxuan Wan, Jiaming Han, Qunzhong Wang, Michael R. Lyu, Xiangyu Yue</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Automating the transformation of user interface (UI) designs into front-end code holds significant promise for accelerating software development and democratizing design workflows. While recent large language models (LLMs) have demonstrated progress in text-to-code generation, many existing approaches rely solely on natural language prompts, limiting their effectiveness in capturing spatial layout and visual design intent. In contrast, UI development in practice is inherently multimodal, often starting from visual sketches or mockups. To address this gap, we introduce a modular multi-agent framework that performs UI-to-code generation in three interpretable stages: grounding, planning, and generation. The grounding agent uses a vision-language model to detect and label UI components, the planning agent constructs a hierarchical layout using front-end engineering priors, and the generation agent produces HTML/CSS code via adaptive prompt-based synthesis. This design improves robustness, interpretability, and fidelity over end-to-end black-box methods. Furthermore, we extend the framework into a scalable data engine that automatically produces large-scale image-code pairs. Using these synthetic examples, we fine-tune and reinforce an open-source VLM, yielding notable gains in UI understanding and code quality. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in layout accuracy, structural coherence, and code correctness. Our code is made publicly available at https://github.com/leigest519/ScreenCoder.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22825v1" target="_blank">DepR: Depth Guided Single-view Scene Reconstruction with Instance-level Diffusion</a></h3>
                    <p><strong>Authors:</strong> Qingcheng Zhao, Xiang Zhang, Haiyang Xu, Zeyuan Chen, Jianwen Xie, Yuan Gao, Zhuowen Tu</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We propose DepR, a depth-guided single-view scene reconstruction framework that integrates instance-level diffusion within a compositional paradigm. Instead of reconstructing the entire scene holistically, DepR generates individual objects and subsequently composes them into a coherent 3D layout. Unlike previous methods that use depth solely for object layout estimation during inference and therefore fail to fully exploit its rich geometric information, DepR leverages depth throughout both training and inference. Specifically, we introduce depth-guided conditioning to effectively encode shape priors into diffusion models. During inference, depth further guides DDIM sampling and layout optimization, enhancing alignment between the reconstruction and the input image. Despite being trained on limited synthetic data, DepR achieves state-of-the-art performance and demonstrates strong generalization in single-view scene reconstruction, as shown through evaluations on both synthetic and real-world datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22824v1" target="_blank">Bi-Level Optimization for Self-Supervised AI-Generated Face Detection</a></h3>
                    <p><strong>Authors:</strong> Mian Zou, Nan Zhong, Baosheng Yu, Yibing Zhan, Kede Ma</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> AI-generated face detectors trained via supervised learning typically rely on synthesized images from specific generators, limiting their generalization to emerging generative techniques. To overcome this limitation, we introduce a self-supervised method based on bi-level optimization. In the inner loop, we pretrain a vision encoder only on photographic face images using a set of linearly weighted pretext tasks: classification of categorical exchangeable image file format (EXIF) tags, ranking of ordinal EXIF tags, and detection of artificial face manipulations. The outer loop then optimizes the relative weights of these pretext tasks to enhance the coarse-grained detection of manipulated faces, serving as a proxy task for identifying AI-generated faces. In doing so, it aligns self-supervised learning more closely with the ultimate goal of AI-generated face detection. Once pretrained, the encoder remains fixed, and AI-generated faces are detected either as anomalies under a Gaussian mixture model fitted to photographic face features or by a lightweight two-layer perceptron serving as a binary classifier. Extensive experiments demonstrate that our detectors significantly outperform existing approaches in both one-class and binary classification settings, exhibiting strong generalization to unseen generators.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22823v1" target="_blank">Programmable Microwave Cluster States via Josephson Metamaterials</a></h3>
                    <p><strong>Authors:</strong> A. Alocco, A. Celotto, E. Palumbo, B. Galvano, P. Livreri, L. Fasolo, L. Callegaro, E. Enrico</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Cluster states are a fundamental resource for continuous-variable quantum computing, enabling measurement-based protocols that can scale beyond the limitations of qubit-based architectures. Here, we demonstrate on-demand generation of multimode entangled microwave cluster states using a programmable Josephson Traveling-Wave Parametric Amplifier (JTWPA) operated in the three-wave mixing regime. By injecting a tailored, non-equidistant set of pump tones via an arbitrary waveform generator, we engineer frequency-specific nonlinear couplings between multiple frequency modes. The entanglement structure is verified via frequency-resolved heterodyne detection of quadrature nullifiers, confirming the target graph topology of the cluster state. Our approach allows reconfigurability through the pumps spectrum and supports scalability by leveraging the wide bandwidth and spatial homogeneity of the JTWPA. This platform opens new avenues for scalable measurement-based quantum information processing in the microwave domain, compatible with superconducting circuit architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22822v1" target="_blank">Dipolar optimal control of quantum states</a></h3>
                    <p><strong>Authors:</strong> H√©ctor Briongos-Merino, Felipe Isaule, Bruno Juli√°-D√≠az, Montserrat Guilleumas</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cond-mat.quant-gas</p>
                    <p><strong>Summary:</strong> Quantum state control is a fundamental tool for quantum technologies. In this work, we propose and analyze the use of quantum optimal control that exploits the dipolar interaction of ultracold atoms on a lattice ring, focusing on the generation of selected states with entangled circulation. This scheme requires time-dependent control over the orientation of the magnetic field, a technique that is feasible in ultracold atom laboratories. The systems evolution is driven by just two independent control functions. We describe the symmetry constraints and other requirements of this approach, and numerically test them using the extended Bose-Hubbard model. We find that the proposed control can engineer entangled current states with perfect fidelity across a wide range of systems, and that in the remaining cases, the theoretical upper bounds for fidelity are reached.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22821v1" target="_blank">Axisymmetric Gyrokinetic Simulation of ASDEX-Upgrade Scrape-off Layer Using a Conservative Implicit BGK Collision Operator</a></h3>
                    <p><strong>Authors:</strong> D. Liu, J. Juno, G. W. Hammett, A. Hakim, A. Shukla, M. Francisquez</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> physics.plasm-ph</p>
                    <p><strong>Summary:</strong> Collisions play an important role in turbulence and transport of fusion plasmas. For kinetic simulations, as the collisionality increases in the domain of interest, the size of the time step to resolve the collisional physics can become overly restrictive in an explicit time integration scheme, leading to high computational cost. With the aim of overcoming such restriction, we have implemented an implicit Bhatnagar-Gross-Krook (BGK) collision operator for use in the discontinuous Galerkin (DG) full-f gyrokinetic solver within the Gkeyll framework, which, when combined with Gkeylls traditional explicit time integrator for collisionless advection, can significantly increase the time step in gyrokinetic simulations of highly collisional regimes. To ensure conservation of density, momentum, and energy, we utilize an iterative scheme to correct the discretized approximation to the equilibrium Maxwellian distribution to which the BGK collision operator relaxes. We have further generalized the BGK infrastructure, both the implicit scheme and the correction routine, to handle cross species collisions. This improved implicit and conservative BGK operator is benchmarked against the more accurate but more computationally expensive Lenard-Bernstein-Dougherty (LBD) operator which has been utilized in prior studies with Gkeyll. The implicit BGK operator enables 2D axisymmetric simulations of the ASDEX-Upgrade scrape-off layer to run 56 times faster to completion than the simulations with the LBD operator, because the BGK operator is more robust and converges at a lower resolution than is required by the LBD operator. Additionally, in this more collisional limit, we demonstrate that the results of our simulations utilizing the implicit BGK operator agreed well with simulations utilizing the more computationally expensive LBD operator.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22820v1" target="_blank">Reflection Equivariance and the Heisenberg Picture for Spaces of Conformal Blocks</a></h3>
                    <p><strong>Authors:</strong> Lukas Woike</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.QA, math-ph, math.AT, math.MP</p>
                    <p><strong>Summary:</strong> Monoidal product, braiding, balancing and weak duality are pieces of algebraic information that are well-known to have their origin in oriented genus zero surfaces and their mapping classes. More precisely, each of them correspond to operations of the cyclic framed $E_2$-operad. We extend this correspondence to include another algebraic piece of data, namely the modified trace, by showing that it amounts to a homotopy fixed point structure with respect to the homotopy involution that reverses the orientation of surfaces and dualizes the state spaces. We call such a homotopy fixed point structure reflection equivariance. As an application, we describe the effect of orientation reversal on spaces of conformal blocks and skein modules in the non-semisimple setting, throughout relying on their factorization homology description. This has important consequences: For a modular functor that is reflection equivariant relative to a rigid duality, i) the circle category is modular, and the resulting mapping class group representations are automatically the ones built by Lyubashenko, and ii) the resulting internal skein algebras have one simple representation, carrying a unique projective mapping class group representation making the action equivariant. While i) is a new topological characterization of not necessarily semisimple modular categories, ii) generalizes the implicit description of spaces of conformal blocks purely through the representation theory of moduli algebras given by Alekseev-Grosse-Schomerus from rational conformal field theories admitting a Hopf algebra description to finite rigid logarithmic conformal field theories. This also generalizes several results of Faitg from ribbon factorizable Hopf algebras to arbitrary modular categories.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22819v1" target="_blank">Reducing the complexity of computing the values of a Nash equilibrium</a></h3>
                    <p><strong>Authors:</strong> Debtoru Chatterjee, Girish Tiwari, Niladri Chatterjee</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.GT, cs.CC</p>
                    <p><strong>Summary:</strong> The Colonel Blotto game, formulated by Emile Borel, involves players allocating limited resources to multiple battlefields simultaneously, with the winner being the one who allocates more resources to each battlefield. Computation of the Nash equilibrium, including of two person, zero sum, mixed strategy Colonel Blotto games have encountered issues of scalability and complexity owing to their PPAD completeness. This paper proposes an algorithm that computes the same value as the Nash equilibrium but cannot be characterized by the Fixed point Theorems of Tarski, Kakutani and Brouwer. The reduced complexity of the proposed algorithm is based on dispensing with the need for computing both players Nash strategies in Colonel Blotto games. The same algorithm can, therefore, be extended to all two person, zero sum games to compute the value of the Nash equilibrium. The theoretical superiority of the proposed algorithm over both LP solvers and another method that computes the same value of the game as its Nash equilibrium by a random assignment of probabilities to the active strategy set of the defending player, is also proposed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22818v1" target="_blank">Numerical Methods for Solving Nonlinearly Coupled Poisson Equations in Dual-Continuum Modeled Porous Electrodes</a></h3>
                    <p><strong>Authors:</strong> Yuhe Wang, Min Wang, Zhihang Xu</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> Porous electrodes are widely used in electrochemical systems, where accurately determining electric potentials, particularly overpotentials, is essential for understanding electrode behavior. At the macroscopic scale, porous electrodes are typically modeled using a dual-continuum approach, treating the porous solid phase and the liquid electrolyte as spatially superimposed domains. Determining potential distributions requires solving two Poisson equations that are nonlinearly coupled through Butler-Volmer kinetics under galvanostatic and potentiostatic operating modes. Under galvanostatic operation, these equations form an underconstrained singular system due to all-Neumann boundary conditions, posing numerical challenges. This paper systematically presents numerical methods for solving nonlinearly coupled Poisson equations in dual-continuum porous electrodes, with a particular focus on galvanostatic solutions. We mathematically establish solution uniqueness in terms of the potential difference between the electrode and electrolyte (or overpotential), as well as the individual potentials up to a shared constant shift. To resolve the nonuniqueness of the solution, we introduce three numerical approaches: (1) Lagrange Constrained Method (LCM), (2) Dirichlet Substitution Method (DSM), and (3) Global Constraining Method (GCM), where GCM enables solving the overpotential without imposing an explicit system reference potential. Additionally, we develop both decoupled and fully coupled nonlinear solution strategies and evaluate their computational performance in both homogeneous and heterogeneous conductivity cases. The presented numerical methods are general for addressing similar underconstrained nonlinear systems. A Python implementation is provided at https://github.com/harrywang1129/porous_electrode_solver.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22817v1" target="_blank">Wall Shear Stress Estimation in Abdominal Aortic Aneurysms: Towards Generalisable Neural Surrogate Models</a></h3>
                    <p><strong>Authors:</strong> Patryk Rygiel, Julian Suk, Christoph Brune, Kak Khee Yeung, Jelmer M. Wolterink</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Abdominal aortic aneurysms (AAAs) are pathologic dilatations of the abdominal aorta posing a high fatality risk upon rupture. Studying AAA progression and rupture risk often involves in-silico blood flow modelling with computational fluid dynamics (CFD) and extraction of hemodynamic factors like time-averaged wall shear stress (TAWSS) or oscillatory shear index (OSI). However, CFD simulations are known to be computationally demanding. Hence, in recent years, geometric deep learning methods, operating directly on 3D shapes, have been proposed as compelling surrogates, estimating hemodynamic parameters in just a few seconds. In this work, we propose a geometric deep learning approach to estimating hemodynamics in AAA patients, and study its generalisability to common factors of real-world variation. We propose an E(3)-equivariant deep learning model utilising novel robust geometrical descriptors and projective geometric algebra. Our model is trained to estimate transient WSS using a dataset of CT scans of 100 AAA patients, from which lumen geometries are extracted and reference CFD simulations with varying boundary conditions are obtained. Results show that the model generalizes well within the distribution, as well as to the external test set. Moreover, the model can accurately estimate hemodynamics across geometry remodelling and changes in boundary conditions. Furthermore, we find that a trained model can be applied to different artery tree topologies, where new and unseen branches are added during inference. Finally, we find that the model is to a large extent agnostic to mesh resolution. These results show the accuracy and generalisation of the proposed model, and highlight its potential to contribute to hemodynamic parameter estimation in clinical practice.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22816v1" target="_blank">Kan Approximations of the Persistent Homology Transform</a></h3>
                    <p><strong>Authors:</strong> Shreya Arya, Justin Curry</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> math.AT, cs.CG, math.CT</p>
                    <p><strong>Summary:</strong> The persistent homology transform (PHT) of a subset $M \subset \mathbb{R}^d$ is a map $\text{PHT}(M):\mathbb{S}^{d-1} \to \mathbf{Dgm}$ from the unit sphere to the space of persistence diagrams. This map assigns to each direction $v\in \mathbb{S}^{d-1}$ the persistent homology of the filtration of $M$ in direction $v$. In practice, one can only sample the map $\text{PHT}(M)$ at a finite set of directions $A \subset \mathbb{S}^{d-1}$. This suggests two natural questions: (1) Can we interpolate the PHT from this finite sample of directions to the entire sphere? If so, (2) can we prove that the resulting interpolation is close to the true PHT? In this paper we show that if we can sample the PHT at the module level, where we have information about how homology from each direction interacts, a ready-made interpolation theory due to Bubenik, de Silva, and Nanda using Kan extensions can answer both of these questions in the affirmative. A close inspection of those techniques shows that we can infer the PHT from a finite sample of heights from each direction as well. Our paper presents the first known results for approximating the PHT from finite directional and scalar data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22815v1" target="_blank">Dual-wavelength quantum skyrmions from liquid crystal topological defect</a></h3>
                    <p><strong>Authors:</strong> Mwezi Koni, Fazilah Nothlawala, Vagharshak Hakobyan, Isaac Nape, Etienne Brasselet, Andrew Forbes</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We propose a spin-orbit strategy for generating dual-wavelength quantum skyrmions, realized either as entangled photon pairs at distinct wavelengths or as heralded single-photon states at a given wavelength -- regimes neither previously conceptualized nor demonstrated. By coupling a two-photon entangled state to an electrically tunable liquid crystal topological defect, we engineer both nonlocal and local skyrmionic topologies in a reconfigurable platform. These results open new directions for topological quantum state engineering and the topological richness of liquid crystals.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22814v1" target="_blank">Quantum Simulation of Nuclear Dynamics in First Quantization</a></h3>
                    <p><strong>Authors:</strong> Luca Spagnoli, Chiara Lissoni, Alessandro Roggero</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> quant-ph, nucl-th</p>
                    <p><strong>Summary:</strong> The study of real time dynamics of nuclear systems is of great importance to provide theoretical predictions of cross sections relevant for both terrestrial experiments as well as applications in astrophysics. First principles simulations of these dynamical processes is however hindered by an exponential cost in classical resources and the possibility of performing scalable simulations using quantum computers is currently an active field of research. In this work we provide the first complete characterization of the resource requirements for studying nuclear dynamics with the full Leading Order (LO) pionless EFT Hamiltonian in first quantization employing simulation strategies using both product formulas as well as Quantum Signal Processing. In particular, we show that time evolution of such an Hamiltonian can be performed with polynomial resources in the number of particles, and logarithmic resources in the number of single-particle basis states. This result provides an exponential improvement compared with previous work on the same Hamiltonian model in second quantization. We find that interesting simulations for low energy nuclear scattering could be achievable with tens of millions of T gates and few hundred logical qubits suggesting that the study of simple nuclear reactions could be amenable for early fault tolerant quantum platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22813v1" target="_blank">DISTIL: Data-Free Inversion of Suspicious Trojan Inputs via Latent Diffusion</a></h3>
                    <p><strong>Authors:</strong> Hossein Mirzaei, Zeinab Taghavi, Sepehr Rezaee, Masoud Hadi, Moein Madadi, Mackenzie W. Mathis</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Deep neural networks have demonstrated remarkable success across numerous tasks, yet they remain vulnerable to Trojan (backdoor) attacks, raising serious concerns about their safety in real-world mission-critical applications. A common countermeasure is trigger inversion -- reconstructing malicious shortcut patterns (triggers) inserted by an adversary during training. Current trigger-inversion methods typically search the full pixel space under specific assumptions but offer no assurances that the estimated trigger is more than an adversarial perturbation that flips the model output. Here, we propose a data-free, zero-shot trigger-inversion strategy that restricts the search space while avoiding strong assumptions on trigger appearance. Specifically, we incorporate a diffusion-based generator guided by the target classifier; through iterative generation, we produce candidate triggers that align with the internal representations the model relies on for malicious behavior. Empirical evaluations, both quantitative and qualitative, show that our approach reconstructs triggers that effectively distinguish clean versus Trojaned models. DISTIL surpasses alternative methods by high margins, achieving up to 7.1% higher accuracy on the BackdoorBench dataset and a 9.4% improvement on trojaned object detection model scanning, offering a promising new direction for reliable backdoor defense without reliance on extensive data or strong prior assumptions about triggers. The code is available at https://github.com/AdaptiveMotorControlLab/DISTIL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22811v1" target="_blank">DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph</a></h3>
                    <p><strong>Authors:</strong> Debayan Banerjee, Tilahun Abedissa Taffa, Ricardo Usbeck</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In this work we present an entity linker for DBLPs 2025 version of RDF-based Knowledge Graph. Compared to the 2022 version, DBLP now considers publication venues as a new entity type called dblp:Stream. In the earlier version of DBLPLink, we trained KG-embeddings and re-rankers on a dataset to produce entity linkings. In contrast, in this work, we develop a zero-shot entity linker using LLMs using a novel method, where we re-rank candidate entities based on the log-probabilities of the yes token output at the penultimate layer of the LLM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22806v1" target="_blank">Enhanced Biaxial Compressive Strain Tuning of 2D semiconductors via Hot Dry Transfer on Polymer Substrates</a></h3>
                    <p><strong>Authors:</strong> Alvaro Cortes-Flores, Eudomar Henr√≠quez-Guerra, Lisa Almonte, Hao Li, Andres Castellanos-Gomez, M. Reyes Calvo</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Strain engineering is an effective tool for tailoring the properties of two-dimensional (2D) materials, especially for tuning quantum phenomena. Among the limited methods available for strain engineering under cryogenic conditions, thermal mismatch with polymeric substrates provides a simple and affordable strategy to induce biaxial compressive strain upon cooling. In this work, we demonstrate the transfer of unprecedentedly large levels of uniform biaxial compressive strain to single-layer WS$_2$ by employing a pre-straining approach prior to cryogenic cooling. Using a hot-dry-transfer method, single-layer WS$_2$ samples were deposited onto thermally expanded polymeric substrates at 100 $^\circ$C. As the substrate cools to room temperature, it contracts, inducing biaxial compressive strain (up to ~0.5%) in the WS$_2$ layer. This pre-strain results in a measurable blueshift in excitonic energies compared to samples transferred at room temperature, which serve as control (not pre-strained) samples. Subsequent cooling of the pre-strained samples from room temperature down to 5 K leads to a remarkable total blueshift of ~200 meV in the exciton energies of single-layer WS$_2$. This energy shift surpasses previously reported values, indicating superior levels of biaxial compressive strain induced by the accumulated substrate contraction of ~1.7%. Moreover, our findings reveal a pronounced temperature dependence in strain transfer efficiency, with gauge factors approaching theoretical limits for ideal strain transfer at 5 K. We attribute this enhanced efficiency to the increased Youngs modulus of the polymeric substrate at cryogenic temperatures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22805v1" target="_blank">MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention</a></h3>
                    <p><strong>Authors:</strong> Yuqi Pang, Bowen Yang, Yun Cao, Fan Rong, Xiaoyu Li, Chen He</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Vision large language models (VLLMs) are focusing primarily on handling complex and fine-grained visual information by incorporating advanced vision encoders and scaling up visual models. However, these approaches face high training and inference costs, as well as challenges in extracting visual details, effectively bridging across modalities. In this work, we propose a novel visual framework, MoCHA, to address these issues. Our framework integrates four vision backbones (i.e., CLIP, SigLIP, DINOv2 and ConvNeXt) to extract complementary visual features and is equipped with a sparse Mixture of Experts Connectors (MoECs) module to dynamically select experts tailored to different visual dimensions. To mitigate redundant or insufficient use of the visual information encoded by the MoECs module, we further design a Hierarchical Group Attention (HGA) with intra- and inter-group operations and an adaptive gating strategy for encoded visual features. We train MoCHA on two mainstream LLMs (e.g., Phi2-2.7B and Vicuna-7B) and evaluate their performance across various benchmarks. Notably, MoCHA outperforms state-of-the-art open-weight models on various tasks. For example, compared to CuMo (Mistral-7B), our MoCHA (Phi2-2.7B) presents outstanding abilities to mitigate hallucination by showing improvements of 3.25% in POPE and to follow visual instructions by raising 153 points on MME. Finally, ablation studies further confirm the effectiveness and robustness of the proposed MoECs and HGA in improving the overall performance of MoCHA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22804v1" target="_blank">Deep reinforcement learning for efficient exploration of combinatorial structural design spaces</a></h3>
                    <p><strong>Authors:</strong> Chloe S. H. Hong, Keith J. Lee, Caitlin T. Mueller</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> This paper proposes a reinforcement learning framework for performance-driven structural design that combines bottom-up design generation with learned strategies to efficiently search large combinatorial design spaces. Motivated by the limitations of conventional top-down approaches such as optimization, the framework instead models structures as compositions of predefined elements, aligning form finding with practical constraints like constructability and component reuse. With the formulation of the design task as a sequential decision-making problem and a human learning inspired training algorithm, the method adapts reinforcement learning for structural design. The framework is demonstrated by designing steel braced truss frame cantilever structures, where trained policies consistently generate distinct, high-performing designs that display structural performance and material efficiency with the use of structural strategies that align with known engineering principles. Further analysis shows that the agent efficiently narrows its search to promising regions of the design space, revealing transferable structural knowledge.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.22802v1" target="_blank">Advancing Fetal Ultrasound Image Quality Assessment in Low-Resource Settings</a></h3>
                    <p><strong>Authors:</strong> Dongli He, Hu Wang, Mohammad Yaqub</p>
                    <p><strong>Published:</strong> 7/30/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Accurate fetal biometric measurements, such as abdominal circumference, play a vital role in prenatal care. However, obtaining high-quality ultrasound images for these measurements heavily depends on the expertise of sonographers, posing a significant challenge in low-income countries due to the scarcity of trained personnel. To address this issue, we leverage FetalCLIP, a vision-language model pretrained on a curated dataset of over 210,000 fetal ultrasound image-caption pairs, to perform automated fetal ultrasound image quality assessment (IQA) on blind-sweep ultrasound data. We introduce FetalCLIP$_{CLS}$, an IQA model adapted from FetalCLIP using Low-Rank Adaptation (LoRA), and evaluate it on the ACOUSLIC-AI dataset against six CNN and Transformer baselines. FetalCLIP$_{CLS}$ achieves the highest F1 score of 0.757. Moreover, we show that an adapted segmentation model, when repurposed for classification, further improves performance, achieving an F1 score of 0.771. Our work demonstrates how parameter-efficient fine-tuning of fetal ultrasound foundation models can enable task-specific adaptations, advancing prenatal care in resource-limited settings. The experimental code is available at: https://github.com/donglihe-hub/FetalCLIP-IQA.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

