
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-07-24<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

While the provided papers cover a broad range of topics, several contribute to the domain of AI safety research directly or indirectly by addressing aspects such as the reliability, security, and interpretability of AI systems. A prominent trend in AI safety is the growing focus on developing systems that can effectively identify and mitigate potential risks associated with artificial intelligence. For instance, the paper BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems discusses the use of vision language models (VLMs) in automotive systems, emphasizing the need for detecting and addressing model hallucinations to prevent potentially dangerous misinterpretations of traffic scenarios. This work underscores the importance of developing AI systems that are robust against errors that could lead to safety-critical failures, especially in autonomous vehicles.

Another significant aspect of AI safety involves ensuring compliance with ethical and legal standards, as evidenced by TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment. This paper highlights the importance of assessing AI systems against frameworks like the AI Act, ensuring they operate within prescribed risk levels. Moreover, the integration of human trust and interpretability into AI systems is explored through frameworks like An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models, which aims to enhance alignment with human intent and safety norms by quantifying and managing output uncertainty. These works collectively emphasize the necessity of developing AI systems that are not only technically proficient but also ethically aligned and comprehensible, thereby reinforcing safe and responsible deployment across various domains.

*Based on 50 research papers*

---

## quantum computing

While none of the listed papers directly focus on quantum computing breakthroughs, there are notable insights that indirectly relate to the field, particularly through advancements in computational methods and security considerations which are relevant to quantum computing environments.

1. **Quantum Software Security**: The paper on quantum software security challenges within shared quantum computing environments identifies key issues related to multi-programming in quantum cloud services. As quantum computing resources grow, sharing a single quantum processor among multiple users introduces security vulnerabilities that need addressing. This highlights an emerging trend of focusing on software and system-level security in quantum computing, crucial for future shared quantum environments.

2. **Block-Encoding in Quantum Algorithms**: The discussion of resource-efficient variational block-encoding in quantum algorithms highlights efforts to optimize computational resources within quantum systems. By reducing the gate complexity of block-encoding operators, the paper suggests pathways to more efficient quantum algorithms, critical for scaling quantum computing applications.

3. **Quantum Time Measurements**: The paper on quantum stroboscopy offers an innovative approach to time measurements in quantum mechanics, which could have implications for improving precision in quantum computing tasks that involve timing or synchronization, potentially enhancing quantum algorithms efficiency.

These insights reflect broader trends in quantum computing, focusing on enhancing security, optimizing resource use, and improving computational precision, which are vital for advancing the practical deployment of quantum technologies.

*Based on 50 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2507.17731v1" target="_blank">Flow Matching Meets Biology and Life Science: A Survey</a></h3>
                    <p><strong>Authors:</strong> Zihao Li, Zhichen Zeng, Xiao Lin, Feihao Fang, Yanru Qu, Zhe Xu, Zhining Liu, Xuying Ning, Tianxin Wei, Ge Liu, Hanghang Tong, Jingrui He</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Over the past decade, advances in generative modeling, such as generative adversarial networks, masked autoencoders, and diffusion models, have significantly transformed biological research and discovery, enabling breakthroughs in molecule design, protein generation, drug discovery, and beyond. At the same time, biological applications have served as valuable testbeds for evaluating the capabilities of generative models. Recently, flow matching has emerged as a powerful and efficient alternative to diffusion-based generative modeling, with growing interest in its application to problems in biology and life sciences. This paper presents the first comprehensive survey of recent developments in flow matching and its applications in biological domains. We begin by systematically reviewing the foundations and variants of flow matching, and then categorize its applications into three major areas: biological sequence modeling, molecule generation and design, and peptide and protein generation. For each, we provide an in-depth review of recent progress. We also summarize commonly used datasets and software tools, and conclude with a discussion of potential future directions. The corresponding curated resources are available at https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17730v1" target="_blank">Online Submission and Evaluation System Design for Competition Operations</a></h3>
                    <p><strong>Authors:</strong> Zhe Chen, Daniel Harabor, Ryan Hechnenberger, Nathan R. Sturtevant</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Research communities have developed benchmark datasets across domains to compare the performance of algorithms and techniques However, tracking the progress in these research areas is not easy, as publications appear in different venues at the same time, and many of them claim to represent the state-of-the-art. To address this, research communities often organise periodic competitions to evaluate the performance of various algorithms and techniques, thereby tracking advancements in the field. However, these competitions pose a significant operational burden. The organisers must manage and evaluate a large volume of submissions. Furthermore, participants typically develop their solutions in diverse environments, leading to compatibility issues during the evaluation of their submissions. This paper presents an online competition system that automates the submission and evaluation process for a competition. The competition system allows organisers to manage large numbers of submissions efficiently, utilising isolated environments to evaluate submissions. This system has already been used successfully for several competitions, including the Grid-Based Pathfinding Competition and the League of Robot Runners competition.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.3390/polym15030558" target="_blank">Application of new conformal cooling layouts to the green injection molding of complex slender polymeric parts with high dimensional specifications</a></h3>
                    <p><strong>Authors:</strong> Abelardo Torres Alba, Jorge Manuel Mercado Colmenero, Juan de Dios Caballero Garcia, Cristina Martin Donate</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> Eliminating warpage in injection molded polymeric parts is one of the most important problems in the injection molding industry today. This situation is critical in geometries that are particularly susceptible to warping due to their geometric features, and this occurs with topologies of great length and slenderness with high changes in thickness. These features are, in these special geometries, impossible to manufacture with traditional technologies to meet the dimensional and sustainable requirements of the industry. This paper presents an innovative green conformal cooling system that is specifically designed for parts with slender geometric shapes that are highly susceptible to warping. Additionally, the work presented by the authors investigates the importance of using highly conductive inserts made of steel alloys in combination with the use of additively manufactured conformal channels for reducing influential parameters, such as warpage, cooling time, and residual stresses in the complex manufacturing of long and slender parts. The results of this real industrial case study indicated that the use of conformal cooling layouts decreased the cycle time by 175.1 s 66% below the current cooling time; the temperature gradient by 78.5% specifically, 18.16 C; the residual stress by 39.78 MPa or 81.88%; and the warpage by 6.9 mm or 90.5%. In this way, it was possible to achieve a final warping in the complex geometry studied of 0.72 mm, which was under the maximum value required at the industrial level of 1 mm. The resulting values obtained by the researchers present a turning point from which the manufacturing and sustainability in the injection molding of said plastic geometries is possible, and they take into account that the geometric manufacturing features analyzed will present a great demand in the coming years in the auto parts manufacturing industry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17722v1" target="_blank">BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems</a></h3>
                    <p><strong>Authors:</strong> Malsha Ashani Mahawatta Dona, Beatriz Cabrero-Daniel, Yinan Yu, Christian Berger</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, I.4.m</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are growingly extended to process multimodal data such as text and video simultaneously. Their remarkable performance in understanding what is shown in images is surpassing specialized neural networks (NNs) such as Yolo that is supporting only a well-formed but very limited vocabulary, ie., objects that they are able to detect. When being non-restricted, LLMs and in particular state-of-the-art vision language models (VLMs) show impressive performance to describe even complex traffic situations. This is making them potentially suitable components for automotive perception systems to support the understanding of complex traffic situations or edge case situation. However, LLMs and VLMs are prone to hallucination, which mean to either potentially not seeing traffic agents such as vulnerable road users who are present in a situation, or to seeing traffic agents who are not there in reality. While the latter is unwanted making an ADAS or autonomous driving systems (ADS) to unnecessarily slow down, the former could lead to disastrous decisions from an ADS. In our work, we are systematically assessing the performance of 3 state-of-the-art VLMs on a diverse subset of traffic situations sampled from the Waymo Open Dataset to support safety guardrails for capturing such hallucinations in VLM-supported perception systems. We observe that both, proprietary and open VLMs exhibit remarkable image understanding capabilities even paying thorough attention to fine details sometimes difficult to spot for us humans. However, they are also still prone to making up elements in their descriptions to date requiring hallucination detection strategies such as BetterCheck that we propose in our work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17718v1" target="_blank">AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer</a></h3>
                    <p><strong>Authors:</strong> Danny D. Leybzon, Shreyas Tirumala, Nishant Jain, Summer Gillen, Michael Jackson, Cameron McPhee, Jennifer Schmidt</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> With the rise of voice-enabled artificial intelligence (AI) systems, quantitative survey researchers have access to a new data-collection mode: AI telephone surveying. By using AI to conduct phone interviews, researchers can scale quantitative studies while balancing the dual goals of human-like interactivity and methodological rigor. Unlike earlier efforts that used interactive voice response (IVR) technology to automate these surveys, voice AI enables a more natural and adaptive respondent experience as it is more robust to interruptions, corrections, and other idiosyncrasies of human speech. We built and tested an AI system to conduct quantitative surveys based on large language models (LLM), automatic speech recognition (ASR), and speech synthesis technologies. The system was specifically designed for quantitative research, and strictly adhered to research best practices like question order randomization, answer order randomization, and exact wording. To validate the systems effectiveness, we deployed it to conduct two pilot surveys with the SSRS Opinion Panel and followed-up with a separate human-administered survey to assess respondent experiences. We measured three key metrics: the survey completion rates, break-off rates, and respondent satisfaction scores. Our results suggest that shorter instruments and more responsive AI interviewers may contribute to improvements across all three metrics studied.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17717v1" target="_blank">From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes</a></h3>
                    <p><strong>Authors:</strong> Karen Zhou, John Giorgi, Pranav Mani, Peng Xu, Davis Liang, Chenhao Tan</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> AI-generated clinical notes are increasingly used in healthcare, but evaluating their quality remains a challenge due to high subjectivity and limited scalability of expert review. Existing automated metrics often fail to align with real-world physician preferences. To address this, we propose a pipeline that systematically distills real user feedback into structured checklists for note evaluation. These checklists are designed to be interpretable, grounded in human feedback, and enforceable by LLM-based evaluators. Using deidentified data from over 21,000 clinical encounters, prepared in accordance with the HIPAA safe harbor standard, from a deployed AI medical scribe system, we show that our feedback-derived checklist outperforms baseline approaches in our offline evaluations in coverage, diversity, and predictive power for human ratings. Extensive experiments confirm the checklists robustness to quality-degrading perturbations, significant alignment with clinician preferences, and practical value as an evaluation methodology. In offline research settings, the checklist can help identify notes likely to fall below our chosen quality thresholds.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17709v1" target="_blank">TyDi QA-WANA: A Benchmark for Information-Seeking Question Answering in Languages of West Asia and North Africa</a></h3>
                    <p><strong>Authors:</strong> Parker Riley, Siamak Shakeri, Waleed Ammar, Jonathan H. Clark</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We present TyDi QA-WANA, a question-answering dataset consisting of 28K examples divided among 10 language varieties of western Asia and northern Africa. The data collection process was designed to elicit information-seeking questions, where the asker is genuinely curious to know the answer. Each question in paired with an entire article that may or may not contain the answer; the relatively large size of the articles results in a task suitable for evaluating models abilities to utilize large text contexts in answering questions. Furthermore, the data was collected directly in each language variety, without the use of translation, in order to avoid issues of cultural relevance. We present performance of two baseline models, and release our code and data to facilitate further improvement by the research community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17703v1" target="_blank">Piecewise Control Barrier Functions for Stochastic Systems</a></h3>
                    <p><strong>Authors:</strong> Rayan Mazouz, Luca Laurenti, Morteza Lahijanian</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> This paper presents a method for the simultaneous synthesis of a barrier certificate and a safe controller for discrete-time nonlinear stochastic systems. Our approach, based on piecewise stochastic control barrier functions, reduces the synthesis problem to a minimax optimization, which we solve exactly using a dual linear program with zero gap. This enables the joint optimization of the barrier certificate and safe controller within a single formulation. The method accommodates stochastic dynamics with additive noise and a bounded continuous control set. The synthesized controllers and barrier certificates provide a formally guaranteed lower bound on probabilistic safety. Case studies on linear and nonlinear stochastic systems validate the effectiveness of our approach.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17699v1" target="_blank">Thinking Isnt an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations</a></h3>
                    <p><strong>Authors:</strong> Zhao Song, Song Yue, Jiahao Zhang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large Reasoning Models (LRMs) have become a central focus in todays large language model (LLM) research, where models are designed to output a step-by-step thinking process before arriving at a final answer to handle complex reasoning tasks. Despite their promise, recent empirical studies (e.g., [Shojaee et al., 2025] from Apple) suggest that this thinking process may not actually enhance reasoning ability, where LLMs without explicit reasoning actually outperform LRMs on tasks with low or high complexity. In this work, we revisit these findings and investigate whether the limitations of LRMs persist when tool augmentations are introduced. We incorporate two types of tools, Python interpreters and scratchpads, and evaluate three representative LLMs and their LRM counterparts on Apples benchmark reasoning puzzles. Our results show that, with proper tool use, LRMs consistently outperform their non-reasoning counterparts across all levels of task complexity. These findings challenge the recent narrative that reasoning is an illusion and highlight the potential of tool-augmented LRMs for solving complex problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17695v1" target="_blank">Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks</a></h3>
                    <p><strong>Authors:</strong> Ilias Chatzistefanidis, Navid Nikaein</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.NI</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLMs input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17682v1" target="_blank">Audio-Vision Contrastive Learning for Phonological Class Recognition</a></h3>
                    <p><strong>Authors:</strong> Daiqi Liu, TomÃ¡s Arias-Vergara, Jana Hutter, Andreas Maier, Paula Andrea PÃ©rez-Toro</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CV, cs.MM, eess.AS</p>
                    <p><strong>Summary:</strong> Accurate classification of articulatory-phonological features plays a vital role in understanding human speech production and developing robust speech technologies, particularly in clinical contexts where targeted phonemic analysis and therapy can improve disease diagnosis accuracy and personalized rehabilitation. In this work, we propose a multimodal deep learning framework that combines real-time magnetic resonance imaging (rtMRI) and speech signals to classify three key articulatory dimensions: manner of articulation, place of articulation, and voicing. We perform classification on 15 phonological classes derived from the aforementioned articulatory dimensions and evaluate the system with four audio/vision configurations: unimodal rtMRI, unimodal audio signals, multimodal middle fusion, and contrastive learning-based audio-vision fusion. Experimental results on the USC-TIMIT dataset show that our contrastive learning-based approach achieves state-of-the-art performance, with an average F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal baseline. The results confirm the effectiveness of contrastive representation learning for multimodal articulatory analysis. Our code and processed dataset will be made publicly available at https://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17680v1" target="_blank">Simulating multiple human perspectives in socio-ecological systems using large language models</a></h3>
                    <p><strong>Authors:</strong> Yongchao Zeng, Calum Brown, Ioannis Kyriakou, Ronja Hotz, Mark Rounsevell</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> Understanding socio-ecological systems requires insights from diverse stakeholder perspectives, which are often hard to access. To enable alternative, simulation-based exploration of different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) to represent various stakeholders; users can step into the agent roles to experience perspectival differences. A simulation protocol serves as a scaffold to streamline multiple perspective-taking simulations, supporting users in reflecting on, transitioning between, and integrating across perspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional dynamics and land use change, enabling both narrative-driven and numerical experiments. In an illustrative experiment, a user successively adopts the perspectives of a system observer and a researcher - a role that analyses data from the embedded land use model to inform evidence-based decision-making for other LLM agents representing various institutions. Despite the users effort to recommend technically sound policies, discrepancies persist between the policy recommendation and implementation due to stakeholders competing advocacies, mirroring real-world misalignment between researcher and policymaker perspectives. The users reflection highlights the subjective feelings of frustration and disappointment as a researcher, especially due to the challenge of maintaining political neutrality while attempting to gain political influence. Despite this, the user exhibits high motivation to experiment with alternative narrative framing strategies, suggesting the systems potential in exploring different perspectives. Further system and protocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-ecological simulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17679v1" target="_blank">Safety Assurance for Quadrotor Kinodynamic Motion Planning</a></h3>
                    <p><strong>Authors:</strong> Theodoros Tavoulareas, Marzia Cescon</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Autonomous drones have gained considerable attention for applications in real-world scenarios, such as search and rescue, inspection, and delivery. As their use becomes ever more pervasive in civilian applications, failure to ensure safe operation can lead to physical damage to the system, environmental pollution, and even loss of human life. Recent work has demonstrated that motion planning techniques effectively generate a collision-free trajectory during navigation. However, these methods, while creating the motion plans, do not inherently consider the safe operational region of the system, leading to potential safety constraints violation during deployment. In this paper, we propose a method that leverages run time safety assurance in a kinodynamic motion planning scheme to satisfy the systems operational constraints. First, we use a sampling-based geometric planner to determine a high-level collision-free path within a user-defined space. Second, we design a low-level safety assurance filter to provide safety guarantees to the control input of a Linear Quadratic Regulator (LQR) designed with the purpose of trajectory tracking. We demonstrate our proposed approach in a restricted 3D simulation environment using a model of the Crazyflie 2.0 drone.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.3847/1538-4357/adf05e" target="_blank">Mapping ground-based coronagraphic images to Helioprojective-Cartesian coordinate system by image registration</a></h3>
                    <p><strong>Authors:</strong> Feiyang Sha, Yu Liu, Lidong Xia, Yao Chen, Qing Zhou, Yangrui Chen, Chuyu Zhong, Xuefei Zhang, Tengfei Song, Mingzhe Sun, Haitang Li, Jacob Oloketuyi, Qiang Liu, Xinjian Wang, Qiwang Luo, Xiaobo Li</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR, astro-ph.GA, astro-ph.IM</p>
                    <p><strong>Summary:</strong> A few ground-based solar coronagraphs have been installed in western China for observing the low-layer corona in recent years. However, determining the Helioprojective Coordinates for the coronagraphic data with high precision is an important but challenging step for further research with other multi-wavelength data. In this paper, we propose an automatic coronal image registration method that combines local statistical correlation and feature point matching to achieve accurate registration between ground-based coronal green-line images and space-based 211 {\AA} images. Then, the accurate field of view information of the coronal green-line images can be derived, allowing the images to be mapped to the Helioprojective Cartesian Coordinates with an accuracy of no less than 0.1. This method has been extensively validated using 100 days of coronal data spanning an 11-year period, demonstrating its broad applicability to ground-based coronagraphs equipped with green-line observations. It significantly enhances the scientific value of ground-based coronal data, enabling comprehensive studies of coronal transient activities and facilitating the joint analysis of data from multiple instruments. Additionally, it holds potential for future applications in improving the pointing accuracy of coronagraphs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17665v1" target="_blank">Perspective-Invariant 3D Object Detection</a></h3>
                    <p><strong>Authors:</strong> Ao Liang, Lingdong Kong, Dongyue Lu, Youquan Liu, Jian Fang, Huaici Zhao, Wei Tsang Ooi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> With the rise of robotics, LiDAR-based 3D object detection has garnered significant attention in both academia and industry. However, existing datasets and methods predominantly focus on vehicle-mounted platforms, leaving other autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET, the first benchmark featuring LiDAR data and 3D bounding box annotations collected from multiple platforms: vehicle, quadruped, and drone, thereby facilitating research in 3D object detection for non-vehicle platforms as well as cross-platform 3D detection. Based on Pi3DET, we propose a novel cross-platform adaptation framework that transfers knowledge from the well-studied vehicle platform to other platforms. This framework achieves perspective-invariant 3D detection through robust alignment at both geometric and feature levels. Additionally, we establish a benchmark to evaluate the resilience and robustness of current 3D detectors in cross-platform scenarios, providing valuable insights for developing adaptive 3D perception systems. Extensive experiments validate the effectiveness of our approach on challenging cross-platform tasks, demonstrating substantial gains over existing adaptation methods. We hope this work paves the way for generalizable and unified 3D perception systems across diverse and complex environments. Our Pi3DET dataset, cross-platform benchmark suite, and annotation toolkit have been made publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17662v1" target="_blank">Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography</a></h3>
                    <p><strong>Authors:</strong> Farnoush Bayatmakou, Reza Taleei, Nicole Simone, Arash Mohammadi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Breast cancer (BC) remains one of the leading causes of cancer-related mortality among women, despite recent advances in Computer-Aided Diagnosis (CAD) systems. Accurate and efficient interpretation of multi-view mammograms is essential for early detection, driving a surge of interest in Artificial Intelligence (AI)-powered CAD models. While state-of-the-art multi-view mammogram classification models are largely based on Transformer architectures, their computational complexity scales quadratically with the number of image patches, highlighting the need for more efficient alternatives. To address this challenge, we propose Mammo-Mamba, a novel framework that integrates Selective State-Space Models (SSMs), transformer-based attention, and expert-driven feature refinement into a unified architecture. Mammo-Mamba extends the MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE) mechanism through its customized SecMamba block. The SecMamba is a modified MambaVision block that enhances representation learning in high-resolution mammographic images by enabling content-adaptive feature refinement. These blocks are integrated into the deeper stages of MambaVision, allowing the model to progressively adjust feature emphasis through dynamic expert gating, effectively mitigating the limitations of traditional Transformer models. Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior classification performance across all key metrics while maintaining computational efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17655v1" target="_blank">Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses</a></h3>
                    <p><strong>Authors:</strong> Shams Shaikh, Trima P. Fernandes e Fizardo</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.NI, cs.SE, C.2.4; D.4.6; E.3; E.5; K.6.5</p>
                    <p><strong>Summary:</strong> As organizations rapidly migrate to the cloud, the security of cryptographic key management has become a growing concern. Hardware Security Modules (HSMs) and Trusted Platform Modules (TPMs), traditionally seen as the gold standard for securing encryption keys and digital trust, are increasingly challenged by cloud-native threats. Real-world breaches have exposed weaknesses in cloud deployments, including misconfigurations, API abuse, and privilege escalations, allowing attackers to access sensitive key material and bypass protections. These incidents reveal that while the hardware remains secure, the surrounding cloud ecosystem introduces systemic vulnerabilities. This paper analyzes notable security failures involving HSMs and TPMs, identifies common attack vectors, and questions longstanding assumptions about their effectiveness in distributed environments. We explore alternative approaches such as confidential computing, post-quantum cryptography, and decentralized key management. Our findings highlight that while HSMs and TPMs still play a role, modern cloud security requires more adaptive, layered architectures. By evaluating both current weaknesses and emerging models, this research equips cloud architects and security engineers with strategies to reinforce cryptographic trust in the evolving threat landscape.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17636v1" target="_blank">Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries</a></h3>
                    <p><strong>Authors:</strong> Victor Hartman, Petter TÃ¶rnberg</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Negative campaigning is a central feature of political competition, yet empirical research has been limited by the high cost and limited scalability of existing classification methods. This study makes two key contributions. First, it introduces zero-shot Large Language Models (LLMs) as a novel approach for cross-lingual classification of negative campaigning. Using benchmark datasets in ten languages, we demonstrate that LLMs achieve performance on par with native-speaking human coders and outperform conventional supervised machine learning approaches. Second, we leverage this novel method to conduct the largest cross-national study of negative campaigning to date, analyzing 18 million tweets posted by parliamentarians in 19 European countries between 2017 and 2022. The results reveal consistent cross-national patterns: governing parties are less likely to use negative messaging, while ideologically extreme and populist parties -- particularly those on the radical right -- engage in significantly higher levels of negativity. These findings advance our understanding of how party-level characteristics shape strategic communication in multiparty systems. More broadly, the study demonstrates the potential of LLMs to enable scalable, transparent, and replicable research in political communication across linguistic and cultural contexts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17627v1" target="_blank">Insights into experimental evaluation of the non-fourier heat transfer model in biological tissues</a></h3>
                    <p><strong>Authors:</strong> Mohammad Azhdari, Ghader Rezazadeh, Raghav Pathak, Hans-Michael Tautenhahn, Franziska Tautenhahn, Tim Ricken, Seyed Morteza Seyedpour</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.bio-ph</p>
                    <p><strong>Summary:</strong> A comprehensive understanding of heat transfer mechanisms in biological tissues is essential for the advancement of thermal therapeutic techniques and the development of accurate bioheat transfer models. Conventional models often fail to capture the inherently complex thermal behavior of biological media, necessitating more sophisticated approaches for experimental validation and parameter extraction. In this study, the Two-Dimensional Three-Phase Lag (TPL) heat transfer model, implemented via the finite difference method (FDM), was employed to extract key phase lag parameters characterizing heat conduction in bovine skin tissue. Experimental measurements were obtained using a 450 nm laser source and two non-contact infrared sensors. The influence of four critical parameters was systematically investigated: heat flux phase lag ($\tau_{q}$), temperature gradient phase lag ($\tau_{\theta}$), thermal displacement coefficient ($k^*$), and thermal displacement phase lag ($\tau_{v}$). A carefully designed experimental protocol was used to assess each parameter independently. The results revealed that the extracted phase lag values were substantially lower than those previously reported in the literature. This highlights the importance of high-precision measurements and the need to isolate each parameter during analysis. These findings contribute to the refinement of bioheat transfer models and hold potential for improving the efficacy and safety of clinical thermal therapies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17618v1" target="_blank">A Hybrid Early-Exit Algorithm for Large Language Models Based on Space Alignment Decoding (SPADE)</a></h3>
                    <p><strong>Authors:</strong> Bowen Zheng, Ming Ma, Zhongqiao Lin, Tianming Yang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.PF</p>
                    <p><strong>Summary:</strong> Large language models are computationally expensive due to their deep structures. Prior research has shown that intermediate layers contain sufficient information to generate accurate answers, leading to the development of early-exit algorithms that reduce inference costs by terminating computation at earlier layers. However, these methods often suffer from poor performance due to misalignment between intermediate and output layer representations that lead to decoding inaccuracy. To address these challenges, we propose SPADE (SPace Alignment DEcoding), a novel decoding method that aligns intermediate layer representations with the output layer by propagating a minimally reduced sequence consisting of only the start token and the answer token. We further optimize the early-exit decision-making process by training a linear approximation of SPADE that computes entropy-based confidence metrics. Putting them together, we create a hybrid early-exit algorithm that monitors confidence levels and stops inference at intermediate layers while using SPADE to generate high-quality outputs. This approach significantly reduces inference costs without compromising accuracy, offering a scalable and efficient solution for deploying large language models in real-world applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17616v1" target="_blank">Vision Transformer attention alignment with human visual perception in aesthetic object evaluation</a></h3>
                    <p><strong>Authors:</strong> Miguel Carrasco, CÃ©sar GonzÃ¡lez-MartÃ­n, JosÃ© Aranda, Luis Oliveros</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Visual attention mechanisms play a crucial role in human perception and aesthetic evaluation. Recent advances in Vision Transformers (ViTs) have demonstrated remarkable capabilities in computer vision tasks, yet their alignment with human visual attention patterns remains underexplored, particularly in aesthetic contexts. This study investigates the correlation between human visual attention and ViT attention mechanisms when evaluating handcrafted objects. We conducted an eye-tracking experiment with 30 participants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal objects comprising basketry bags and ginger jars. Using a Pupil Labs eye-tracker, we recorded gaze patterns and generated heat maps representing human visual attention. Simultaneously, we analyzed the same objects using a pre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting attention maps from each of the 12 attention heads. We compared human and ViT attention distributions using Kullback-Leibler divergence across varying Gaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal correlation at sigma=2.4 +-0.03, with attention head #12 showing the strongest alignment with human visual patterns. Significant differences were found between attention heads, with heads #7 and #9 demonstrating the greatest divergence from human attention (p 0.05, Tukey HSD test). Results indicate that while ViTs exhibit more global attention patterns compared to human focal attention, certain attention heads can approximate human visual behavior, particularly for specific object features like buckles in basketry items. These findings suggest potential applications of ViT attention mechanisms in product design and aesthetic evaluation, while highlighting fundamental differences in attention strategies between human perception and current AI models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17614v1" target="_blank">Comparing performance of variational quantum algorithm simulations on HPC systems</a></h3>
                    <p><strong>Authors:</strong> Marco De Pascale, Tobias Valentin Bauer, Yaknan John Gambo, Mario HernÃ¡ndez Vera, Stefan Huber, Burak Mete, Amit Jamadagni, Amine Bentellis, Marita Oliv, Luigi Iapichino, Jeanette Miriam Lorenz</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.DC</p>
                    <p><strong>Summary:</strong> Variational quantum algorithms are of special importance in the research on quantum computing applications because of their applicability to current Noisy Intermediate-Scale Quantum (NISQ) devices. The main building blocks of these algorithms (among them, the definition of the Hamiltonian and of the ansatz, the optimizer) define a relatively large parameter space, making the comparison of results and performance between different approaches and software simulators cumbersome and prone to errors. In this paper, we employ a generic description of the problem, in terms of both Hamiltonian and ansatz, to port a problem definition consistently among different simulators. Three use cases of relevance for current quantum hardware (ground state calculation for the Hydrogen molecule, MaxCut, Travelling Salesman Problem) have been run on a set of HPC systems and software simulators to study the dependence of performance on the runtime environment, the scalability of the simulation codes and the mutual agreement of the physical results, respectively. The results show that our toolchain can successfully translate a problem definition between different simulators. On the other hand, variational algorithms are limited in their scaling by the long runtimes with respect to their memory footprint, so they expose limited parallelism to computation. This shortcoming is partially mitigated by using techniques like job arrays. The potential of the parser tool for exploring HPC performance and comparisons of results of variational algorithm simulations is highlighted.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17606v1" target="_blank">Time Deep Gradient Flow Method for pricing American options</a></h3>
                    <p><strong>Authors:</strong> Jasper Rou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> q-fin.CP, cs.LG, math.PR, q-fin.MF, 91G20, 91G60, 68T07</p>
                    <p><strong>Summary:</strong> In this research, we explore neural network-based methods for pricing multidimensional American put options under the BlackScholes and Heston model, extending up to five dimensions. We focus on two approaches: the Time Deep Gradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the TDGF method to handle the free-boundary partial differential equation inherent in American options. We carefully design the sampling strategy during training to enhance performance. Both TDGF and DGM achieve high accuracy while outperforming conventional Monte Carlo methods in terms of computational speed. In particular, TDGF tends to be faster during training than DGM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17597v1" target="_blank">Explainable AI for Collaborative Assessment of 2D/3D Registration Quality</a></h3>
                    <p><strong>Authors:</strong> Sue Min Cho, Alexander Do, Russell H. Taylor, Mathias Unberath</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CV</p>
                    <p><strong>Summary:</strong> As surgery embraces digital transformation--integrating sophisticated imaging, advanced algorithms, and robotics to support and automate complex sub-tasks--human judgment of system correctness remains a vital safeguard for patient safety. This shift introduces new operator-type roles tasked with verifying complex algorithmic outputs, particularly at critical junctures of the procedure, such as the intermediary check before drilling or implant placement. A prime example is 2D/3D registration, a key enabler of image-based surgical navigation that aligns intraoperative 2D images with preoperative 3D data. Although registration algorithms have advanced significantly, they occasionally yield inaccurate results. Because even small misalignments can lead to revision surgery or irreversible surgical errors, there is a critical need for robust quality assurance. Current visualization-based strategies alone have been found insufficient to enable humans to reliably detect 2D/3D registration misalignments. In response, we propose the first artificial intelligence (AI) framework trained specifically for 2D/3D registration quality verification, augmented by explainability features that clarify the models decision-making. Our explainable AI (XAI) approach aims to enhance informed decision-making for human operators by providing a second opinion together with a rationale behind it. Through algorithm-centric and human-centered evaluations, we systematically compare four conditions: AI-only, human-only, human-AI, and human-XAI. Our findings reveal that while explainability features modestly improve user trust and willingness to override AI errors, they do not exceed the standalone AI in aggregate performance. Nevertheless, future work extending both the algorithmic design and the human-XAI collaboration elements holds promise for more robust quality assurance of 2D/3D registration.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17580v1" target="_blank">Enhancing Quantum Federated Learning with Fisher Information-Based Optimization</a></h3>
                    <p><strong>Authors:</strong> Amandeep Singh Bhatia, Sabre Kais</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.DC, cs.ET, quant-ph</p>
                    <p><strong>Summary:</strong> Federated Learning (FL) has become increasingly popular across different sectors, offering a way for clients to work together to train a global model without sharing sensitive data. It involves multiple rounds of communication between the global model and participating clients, which introduces several challenges like high communication costs, heterogeneous client data, prolonged processing times, and increased vulnerability to privacy threats. In recent years, the convergence of federated learning and parameterized quantum circuits has sparked significant research interest, with promising implications for fields such as healthcare and finance. By enabling decentralized training of quantum models, it allows clients or institutions to collaboratively enhance model performance and outcomes while preserving data privacy. Recognizing that Fisher information can quantify the amount of information that a quantum state carries under parameter changes, thereby providing insight into its geometric and statistical properties. We intend to leverage this property to address the aforementioned challenges. In this work, we propose a Quantum Federated Learning (QFL) algorithm that makes use of the Fisher information computed on local client models, with data distributed across heterogeneous partitions. This approach identifies the critical parameters that significantly influence the quantum models performance, ensuring they are preserved during the aggregation process. Our research assessed the effectiveness and feasibility of QFL by comparing its performance against other variants, and exploring the benefits of incorporating Fisher information in QFL settings. Experimental results on ADNI and MNIST datasets demonstrate the effectiveness of our approach in achieving better performance and robustness against the quantum federated averaging method.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17563v1" target="_blank">BoSS: Beyond-Semantic Speech</a></h3>
                    <p><strong>Authors:</strong> Qing Wang, Zehan Li, Hang Lv, Hongjie Chen, Yaodong Song, Jian Kang, Jie Lian, Jie Li, Yongxiang Li, Zhongjiang He, Xuelong Li</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CL, eess.AS</p>
                    <p><strong>Summary:</strong> Human communication involves more than explicit semantics, with implicit signals and contextual cues playing a critical role in shaping meaning. However, modern speech technologies, such as Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) often fail to capture these beyond-semantic dimensions. To better characterize and benchmark the progression of speech intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5), a hierarchical framework illustrated the evolution of spoken dialogue systems from basic command recognition to human-like social interaction. To support these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which refers to the set of information in speech communication that encompasses but transcends explicit semantics. It conveys emotions, contexts, and modifies or extends meanings through multidimensional features such as affective cues, contextual dynamics, and implicit semantics, thereby enhancing the understanding of communicative intentions and scenarios. We present a formalized framework for BoSS, leveraging cognitive relevance theories and machine learning models to analyze temporal and contextual speech dynamics. We evaluate BoSS-related attributes across five different dimensions, reveals that current spoken language models (SLMs) are hard to fully interpret beyond-semantic signals. These findings highlight the need for advancing BoSS research to enable richer, more context-aware human-machine communication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17561v1" target="_blank">Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper</a></h3>
                    <p><strong>Authors:</strong> Lorenzo Vianello, Matthew Short, Julia Manczurowsky, Emek BarÄ±ÅŸ KÃ¼Ã§Ã¼ktabak, Francesco Di Tommaso, Alessia Noccaro, Laura Bandini, Shoshana Clark, Alaina Fiorenza, Francesca Lunardini, Alberto Canton, Marta Gandolla, Alessandra L. G. Pedrocchi, Emilia Ambrosini, Manuel Murie-Fernandez, Carmen B. Roman, Jesus Tornero, Natacha Leon, Andrew Sawers, Jim Patton, Domenico Formica, Nevio Luigi Tagliamonte, Georg Rauter, Kilian Baur, Fabian Just, Christopher J. Hasson, Vesna D. Novak, Jose L. Pons</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Neurorehabilitation conventionally relies on the interaction between a patient and a physical therapist. Robotic systems can improve and enrich the physical feedback provided to patients after neurological injury, but they under-utilize the adaptability and clinical expertise of trained therapists. In this position paper, we advocate for a novel approach that integrates the therapists clinical expertise and nuanced decision-making with the strength, accuracy, and repeatability of robotics: Robot-mediated physical Human-Human Interaction. This framework, which enables two individuals to physically interact through robotic devices, has been studied across diverse research groups and has recently emerged as a promising link between conventional manual therapy and rehabilitation robotics, harmonizing the strengths of both approaches. This paper presents the rationale of a multidisciplinary team-including engineers, doctors, and physical therapists-for conducting research that utilizes: a unified taxonomy to describe robot-mediated rehabilitation, a framework of interaction based on social psychology, and a technological approach that makes robotic systems seamless facilitators of natural human-human interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17543v1" target="_blank">Anticipate, Simulate, Reason (ASR): A Comprehensive Generative AI Framework for Combating Messaging Scams</a></h3>
                    <p><strong>Authors:</strong> Xue Wen Tan, Kenneth See, Stanley Kok</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> The rapid growth of messaging scams creates an escalating challenge for user security and financial safety. In this paper, we present the Anticipate, Simulate, Reason (ASR) framework, a generative AI method that enables users to proactively identify and comprehend scams within instant messaging platforms. Using large language models, ASR predicts scammer responses, creates realistic scam conversations, and delivers real-time, interpretable support to end-users. We develop ScamGPT-J, a domain-specific language model fine-tuned on a new, high-quality dataset of scam conversations covering multiple scam types. Thorough experimental evaluation shows that the ASR framework substantially enhances scam detection, particularly in challenging contexts such as job scams, and uncovers important demographic patterns in user vulnerability and perceptions of AI-generated assistance. Our findings reveal a contradiction where those most at risk are often least receptive to AI support, emphasizing the importance of user-centered design in AI-driven fraud prevention. This work advances both the practical and theoretical foundations for interpretable, human-centered AI systems in combating evolving digital threats.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17526v1" target="_blank">Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling</a></h3>
                    <p><strong>Authors:</strong> Leandro Von Krannichfeldt, Kristina Orehounig, Olga Fink</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.AI, cs.LG, cs.SY</p>
                    <p><strong>Summary:</strong> Building energy modeling is a key tool for optimizing the performance of building energy systems. Historically, a wide spectrum of methods has been explored -- ranging from conventional physics-based models to purely data-driven techniques. Recently, hybrid approaches that combine the strengths of both paradigms have gained attention. These include strategies such as learning surrogates for physics-based models, modeling residuals between simulated and observed data, fine-tuning surrogates with real-world measurements, using physics-based outputs as additional inputs for data-driven models, and integrating the physics-based output into the loss function the data-driven model. Despite this progress, two significant research gaps remain. First, most hybrid methods focus on deterministic modeling, often neglecting the inherent uncertainties caused by factors like weather fluctuations and occupant behavior. Second, there has been little systematic comparison within a probabilistic modeling framework. This study addresses these gaps by evaluating five representative hybrid approaches for probabilistic building energy modeling, focusing on quantile predictions of building thermodynamics in a real-world case study. Our results highlight two main findings. First, the performance of hybrid approaches varies across different building room types, but residual learning with a Feedforward Neural Network performs best on average. Notably, the residual approach is the only model that produces physically intuitive predictions when applied to out-of-distribution test data. Second, Quantile Conformal Prediction is an effective procedure for calibrating quantile predictions in case of indoor temperature modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17521v1" target="_blank">Single-photon loading of polar molecules into an optical trap</a></h3>
                    <p><strong>Authors:</strong> Bart J. Schellenberg, Eifion H. Prinsen, Janko Nauta, LukÃ¡Å¡ F. PaÅ¡teka, Anastasia Borschevsky, Steven Hoekstra</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph</p>
                    <p><strong>Summary:</strong> We propose a scheme to transfer molecules from a slow beam into an optical trap using only a single photon absorption and emission cycle. The efficiency of such a scheme is numerically explored for BaF using realistic experimental parameters. The technique makes use of the state-dependent potential in an external electric field to trap molecules from an initial velocity of order 10m/s. A rapid optical transition at the point where the molecules come to a standstill in the electric field potential irreversibly transfers them into a ~7mK optical dipole trap. For a pulsed Stark decelerated beam, we estimated the per-shot efficiency to be ~0.04% or up to ~103 molecules, with a potential factor 20 improvement when the fields are synchronously modulated with the arriving velocity components. The irreversibility of the scheme allows for larger numbers to be built up over time. Since this scheme does not rely on a closed cycling transition for laser cooling, it broadens the range of molecules that can be used for research on cold molecular chemistry, quantum information, and fundamental interactions in optical traps.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17519v1" target="_blank">Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners</a></h3>
                    <p><strong>Authors:</strong> Kostas Karakontis, Thanos Petsanis, Athanasios Ch. Kapoutsis, Pavlos Ch. Kapoutsis, Elias B. Kosmatopoulos</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial software typically treat a Region of Interest (RoI) only as a 2D plane, ignoring important3D structure characteristics. This leads to incomplete 3Dreconstructions, especially around occluded or vertical surfaces. In this paper, we propose a modular algorithm that can extend commercial two-dimensional path planners to facilitate terrain-aware planning by adjusting altitude and camera orientations. To demonstrate it, we extend the well-known DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm and produce DARP-3D. We present simulation results in multiple 3D environments and a real-world flight test using DJI hardware. Compared to baseline, our approach consistently captures improved 3D reconstructions, particularly in areas with significant vertical features. An open-source implementation of the algorithm is available here:https://github.com/konskara/TerraPlan</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17518v1" target="_blank">Enabling Cyber Security Education through Digital Twins and Generative AI</a></h3>
                    <p><strong>Authors:</strong> Vita Santa Barletta, Vito Bavaro, Miriana Calvano, Antonio Curci, Antonio Piccinno, Davide Pio Posa</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.CY, cs.HC, cs.SE</p>
                    <p><strong>Summary:</strong> Digital Twins (DTs) are gaining prominence in cybersecurity for their ability to replicate complex IT (Information Technology), OT (Operational Technology), and IoT (Internet of Things) infrastructures, allowing for real time monitoring, threat analysis, and system simulation. This study investigates how integrating DTs with penetration testing tools and Large Language Models (LLMs) can enhance cybersecurity education and operational readiness. By simulating realistic cyber environments, this approach offers a practical, interactive framework for exploring vulnerabilities and defensive strategies. At the core of this research is the Red Team Knife (RTK), a custom penetration testing toolkit aligned with the Cyber Kill Chain model. RTK is designed to guide learners through key phases of cyberattacks, including reconnaissance, exploitation, and response within a DT powered ecosystem. The incorporation of Large Language Models (LLMs) further enriches the experience by providing intelligent, real-time feedback, natural language threat explanations, and adaptive learning support during training exercises. This combined DT LLM framework is currently being piloted in academic settings to develop hands on skills in vulnerability assessment, threat detection, and security operations. Initial findings suggest that the integration significantly improves the effectiveness and relevance of cybersecurity training, bridging the gap between theoretical knowledge and real-world application. Ultimately, the research demonstrates how DTs and LLMs together can transform cybersecurity education to meet evolving industry demands.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17514v1" target="_blank">TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment</a></h3>
                    <p><strong>Authors:</strong> Athanasios Davvetas, Xenia Ziouvelou, Ypatia Dami, Alexis Kaponis, Konstantina Giouvanopoulou, Michael Papademas</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool with minimalistic input. The current version of the tool supports the legal TAI assessment, with a particular emphasis on facilitating compliance with the AI Act. It involves a two-step approach with a pre-screening and an assessment phase. The assessment output of the system includes insight regarding the risk-level of the AI system according to the AI Act, while at the same time retrieving relevant articles to aid with compliance and notify on their obligations. Our qualitative evaluation using use-case scenarios yields promising results, correctly predicting risk levels while retrieving relevant articles across three distinct semantic groups. Furthermore, interpretation of results shows that the tools reasoning relies on comparison with the setting of high-risk systems, a behaviour attributed to their deployment requiring careful consideration, and therefore frequently presented within the AI Act.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17512v1" target="_blank">Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Yu Li, Zhuoshi Pan, Honglin Lin, Mengyuan Sun, Conghui He, Lijun Wu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing research has predominantly concentrated on isolated reasoning domains such as mathematical problem-solving, coding tasks, or logical reasoning. However, real world reasoning scenarios inherently demand an integrated application of multiple cognitive skills. Despite this, the interplay among these reasoning skills under reinforcement learning remains poorly understood. To bridge this gap, we present a systematic investigation of multi-domain reasoning within the RLVR framework, explicitly focusing on three primary domains: mathematical reasoning, code generation, and logical puzzle solving. We conduct a comprehensive study comprising four key components: (1) Leveraging the GRPO algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the models in-domain improvements and cross-domain generalization capabilities when trained on single-domain datasets. (2) Additionally, we examine the intricate interactions including mutual enhancements and conflicts that emerge during combined cross-domain training. (3) To further understand the influence of SFT on RL, we also analyze and compare performance differences between base and instruct models under identical RL configurations. (4) Furthermore, we delve into critical RL training details, systematically exploring the impacts of curriculum learning strategies, variations in reward design, and language-specific factors. Through extensive experiments, our results offer significant insights into the dynamics governing domain interactions, revealing key factors influencing both specialized and generalizable reasoning performance. These findings provide valuable guidance for optimizing RL methodologies to foster comprehensive, multi-domain reasoning capabilities in LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17508v1" target="_blank">Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation</a></h3>
                    <p><strong>Authors:</strong> Jorgen Cani, Christos Diou, Spyridon Evangelatos, Vasileios Argyriou, Panagiotis Radoglou-Grammatikis, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Automated X-ray inspection is crucial for efficient and unobtrusive security screening in various public settings. However, challenges such as object occlusion, variations in the physical properties of items, diversity in X-ray scanning devices, and limited training data hinder accurate and reliable detection of illicit items. Despite the large body of research in the field, reported experimental evaluations are often incomplete, with frequently conflicting outcomes. To shed light on the research landscape and facilitate further research, a systematic, detailed, and thorough comparative evaluation of recent Deep Learning (DL)-based methods for X-ray object detection is conducted. For this, a comprehensive evaluation framework is developed, composed of: a) Six recent, large-scale, and widely used public datasets for X-ray illicit item detection (OPIXray, CLCXray, SIXray, EDS, HiXray, and PIDray), b) Ten different state-of-the-art object detection schemes covering all main categories in the literature, including generic Convolutional Neural Network (CNN), custom CNN, generic transformer, and hybrid CNN-transformer architectures, and c) Various detection (mAP50 and mAP50:95) and time/computational-complexity (inference time (ms), parameter size (M), and computational load (GFLOPS)) metrics. A thorough analysis of the results leads to critical observations and insights, emphasizing key aspects such as: a) Overall behavior of the object detection schemes, b) Object-level detection performance, c) Dataset-specific observations, and d) Time efficiency and computational complexity analysis. To support reproducibility of the reported experimental results, the evaluation code and model weights are made publicly available at https://github.com/jgenc/xray-comparative-evaluation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17507v1" target="_blank">Unfolding Data Quality Dimensions in Practice: A Survey</a></h3>
                    <p><strong>Authors:</strong> Vasileios Papastergios, Lisa Ehrlinger, Anastasios Gounaris</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.DB</p>
                    <p><strong>Summary:</strong> Data quality describes the degree to which data meet specific requirements and are fit for use by humans and/or downstream tasks (e.g., artificial intelligence). Data quality can be assessed across multiple high-level concepts called dimensions, such as accuracy, completeness, consistency, or timeliness. While extensive research and several attempts for standardization (e.g., ISO/IEC 25012) exist for data quality dimensions, their practical application often remains unclear. In parallel to research endeavors, a large number of tools have been developed that implement functionalities for the detection and mitigation of specific data quality issues, such as missing values or outliers. With this paper, we aim to bridge this gap between data quality theory and practice by systematically connecting low-level functionalities offered by data quality tools with high-level dimensions, revealing their many-to-many relationships. Through an examination of seven open-source data quality tools, we provide a comprehensive mapping between their functionalities and the data quality dimensions, demonstrating how individual functionalities and their variants partially contribute to the assessment of single dimensions. This systematic survey provides both practitioners and researchers with a unified view on the fragmented landscape of data quality checks, offering actionable insights for quality assessment across multiple dimensions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17482v1" target="_blank">LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning</a></h3>
                    <p><strong>Authors:</strong> Luca Salvatore Lorello, Nikolaos Manginas, Marco Lippi, Stefano Melacci</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Neuro-symbolic artificial intelligence aims to combine neural architectures with symbolic approaches that can represent knowledge in a human-interpretable formalism. Continual learning concerns with agents that expand their knowledge over time, improving their skills while avoiding to forget previously learned concepts. Most of the existing approaches for neuro-symbolic artificial intelligence are applied to static scenarios only, and the challenging setting where reasoning along the temporal dimension is necessary has been seldom explored. In this work we introduce LTLZinc, a benchmarking framework that can be used to generate datasets covering a variety of different problems, against which neuro-symbolic and continual learning methods can be evaluated along the temporal and constraint-driven dimensions. Our framework generates expressive temporal reasoning and continual learning tasks from a linear temporal logic specification over MiniZinc constraints, and arbitrary image classification datasets. Fine-grained annotations allow multiple neural and neuro-symbolic training settings on the same generated datasets. Experiments on six neuro-symbolic sequence classification and four class-continual learning tasks generated by LTLZinc, demonstrate the challenging nature of temporal learning and reasoning, and highlight limitations of current state-of-the-art methods. We release the LTLZinc generator and ten ready-to-use tasks to the neuro-symbolic and continual learning communities, in the hope of fostering research towards unified temporal learning and reasoning frameworks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17481v1" target="_blank">AI in Design Education at College Level-Educators Perspectives and Challenges</a></h3>
                    <p><strong>Authors:</strong> Lizhu Zhang, Cecilia X. Wang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.HC</p>
                    <p><strong>Summary:</strong> Artificial intelligence has deeply permeated numerous fields, especially the design area which relies on technology as a tool for innovation. This change naturally extends to the field of design education, which is closest to design practice. This has led to further exploration of the impact of AI on college-level education in the design discipline. This study aims to examine how current design educators perceive the role of AI in college-level design education, their perspectives on integrating AI into teaching and research, and their concerns regarding its potential challenges in design education and research. Through qualitative, semi-structured, in-depth interviews with seven faculties in U.S. design colleges, the findings reveal that AI, as a tool and source of information, has become an integral part of design education. AI- derived functionalities are increasingly utilized in design software, and educators are actively incorporating AI as a theoretical framework in their teaching. Educators can guide students in using AI tools, but only if they first acquire a strong foundation in basic design principles and skills. This study also indicates the importance of promoting a cooperative relationship between design educators and AI. At the same time, educators express anticipation for advancements in ethical standards, authenticity, and the resolution of copyright issues related to AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17477v1" target="_blank">An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Haoran Sun, Zekun Zhang, Shaoning Zeng</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have demonstrated remarkable progress in instruction following and general-purpose reasoning. However, achieving high-quality alignment with human intent and safety norms without human annotations remains a fundamental challenge. In this work, we propose an Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to improve LLM alignment in a fully automated manner. UDASA first generates multiple responses for each input and quantifies output uncertainty across three dimensions: semantics, factuality, and value alignment. Based on these uncertainty scores, the framework constructs preference pairs and categorizes training samples into three stages, conservative, moderate, and exploratory, according to their uncertainty difference. The model is then optimized progressively across these stages. In addition, we conduct a series of preliminary studies to validate the core design assumptions and provide strong empirical motivation for the proposed framework. Experimental results show that UDASA outperforms existing alignment methods across multiple tasks, including harmlessness, helpfulness, truthfulness, and controlled sentiment generation, significantly improving model performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17448v1" target="_blank">Reasoning-Driven Retrosynthesis Prediction with Large Language Models via Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Situo Zhang, Hanqi Li, Lu Chen, Zihan Zhao, Xuanze Lin, Zichen Zhu, Bo Chen, Xin Chen, Kai Yu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CE, cs.AI, physics.chem-ph</p>
                    <p><strong>Summary:</strong> Retrosynthesis planning, essential in organic synthesis and drug discovery, has greatly benefited from recent AI-driven advancements. Nevertheless, existing methods frequently face limitations in both applicability and explainability. Traditional graph-based and sequence-to-sequence models often lack generalized chemical knowledge, leading to predictions that are neither consistently accurate nor easily explainable. To address these challenges, we introduce RetroDFM-R, a reasoning-based large language model (LLM) designed specifically for chemical retrosynthesis. Leveraging large-scale reinforcement learning guided by chemically verifiable rewards, RetroDFM-R significantly enhances prediction accuracy and explainability. Comprehensive evaluations demonstrate that RetroDFM-R significantly outperforms state-of-the-art methods, achieving a top-1 accuracy of 65.0% on the USPTO-50K benchmark. Double-blind human assessments further validate the chemical plausibility and practical utility of RetroDFM-Rs predictions. RetroDFM-R also accurately predicts multistep retrosynthetic routes reported in the literature for both real-world drug molecules and perovskite materials. Crucially, the models explicit reasoning process provides human-interpretable insights, thereby enhancing trust and practical value in real-world retrosynthesis applications.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3706598.3713599" target="_blank">Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces</a></h3>
                    <p><strong>Authors:</strong> Yan Dong, Hanjie Yu, Yanran Chen, Zipeng Zhang, Qiong Wu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Integrating technology with the distinctive characteristics of craftsmanship has become a key issue in the field of digital craftsmanship. This paper introduces Layered Interactions, a design approach that seamlessly merges Human-Computer Interaction (HCI) technologies with traditional lacquerware craftsmanship. By leveraging the multi-layer structure and material properties of lacquerware, we embed interactive circuits and integrate programmable hardware within the layers, creating tangible interfaces that support diverse interactions. This method enhances the adaptability and practicality of traditional crafts in modern digital contexts. Through the development of a lacquerware toolkit, along with user experiments and semi-structured interviews, we demonstrate that this approach not only makes technology more accessible to traditional artisans but also enhances the materiality and emotional qualities of interactive interfaces. Additionally, it fosters mutual learning and collaboration between artisans and technologists. Our research introduces a cross-disciplinary perspective to the HCI community, broadening the material and design possibilities for interactive interfaces.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17417v1" target="_blank">A Comprehensive Evaluation on Quantization Techniques for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Yutong Liu, Cairong Zhao, Guosheng Hu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> For large language models (LLMs), post-training quantization (PTQ) can significantly reduce memory footprint and computational overhead. Model quantization is a rapidly evolving research field. Though many papers have reported breakthrough performance, they may not conduct experiments on the same ground since one quantization method usually contains multiple components. In addition, analyzing the theoretical connections among existing methods is crucial for in-depth understanding. To bridge these gaps, we conduct an extensive review of state-of-the-art methods and perform comprehensive evaluations on the same ground to ensure fair comparisons. To our knowledge, this fair and extensive investigation remains critically important yet underexplored. To better understand the theoretical connections, we decouple the published quantization methods into two steps: pre-quantization transformation and quantization error mitigation. We define the former as a preprocessing step applied before quantization to reduce the impact of outliers, making the data distribution flatter and more suitable for quantization. Quantization error mitigation involves techniques that offset the errors introduced during quantization, thereby enhancing model performance. We evaluate and analyze the impact of different components of quantization methods. Additionally, we analyze and evaluate the latest MXFP4 data format and its performance. Our experimental results demonstrate that optimized rotation and scaling yield the best performance for pre-quantization transformation, and combining low-rank compensation with GPTQ occasionally outperforms using GPTQ alone for quantization error mitigation. Furthermore, we explore the potential of the latest MXFP4 quantization and reveal that the optimal pre-quantization transformation strategy for INT4 does not generalize well to MXFP4, inspiring further investigation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17412v1" target="_blank">Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging</a></h3>
                    <p><strong>Authors:</strong> Farnaz Khun Jush, Steffen Vogler, Matthias Lenga</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> The increasing volume of medical images poses challenges for radiologists in retrieving relevant cases. Content-based image retrieval (CBIR) systems offer potential for efficient access to similar cases, yet lack standardized evaluation and comprehensive studies. Building on prior studies for tumor characterization via CBIR, this study advances CBIR research for volumetric medical images through three key contributions: (1) a framework eliminating reliance on pre-segmented data and organ-specific datasets, aligning with large and unstructured image archiving systems, i.e. PACS in clinical practice; (2) introduction of C-MIR, a novel volumetric re-ranking method adapting ColBERTs contextualized late interaction mechanism for 3D medical imaging; (3) comprehensive evaluation across four tumor sites using three feature extractors and three database configurations. Our evaluations highlight the significant advantages of C-MIR. We demonstrate the successful adaptation of the late interaction principle to volumetric medical images, enabling effective context-aware re-ranking. A key finding is C-MIRs ability to effectively localize the region of interest, eliminating the need for pre-segmentation of datasets and offering a computationally efficient alternative to systems relying on expensive data enrichment steps. C-MIR demonstrates promising improvements in tumor flagging, achieving improved performance, particularly for colon and lung tumors (p0.05). C-MIR also shows potential for improving tumor staging, warranting further exploration of its capabilities. Ultimately, our work seeks to bridge the gap between advanced retrieval techniques and their practical applications in healthcare, paving the way for improved diagnostic processes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17405v1" target="_blank">Automatic Blink-based Bad EEG channels Detection for BCI Applications</a></h3>
                    <p><strong>Authors:</strong> Eva Guttmann-Flury, Yanyan Wei, Shan Zhao</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC</p>
                    <p><strong>Summary:</strong> In Brain-Computer Interface (BCI) applications, noise presents a persistent challenge, often compromising the quality of EEG signals essential for accurate data interpretation. This paper focuses on optimizing the signal-to-noise ratio (SNR) to improve BCI performance, with channel selection being a key method for achieving this enhancement. The Eye-BCI multimodal dataset is used to address the issue of detecting and eliminating faulty EEG channels caused by non-biological artifacts, such as malfunctioning electrodes and power line interference. The core of this research is the automatic detection of problematic channels through the Adaptive Blink-Correction and De-Drifting (ABCD) algorithm. This method utilizes blink propagation patterns to identify channels affected by artifacts or malfunctions. Additionally, segmented SNR topographies and source localization plots are employed to illustrate the impact of channel removal by comparing Left and Right hand grasp Motor Imagery (MI). Classification accuracy further supports the value of the ABCD algorithm, reaching an average classification accuracy of 93.81% [74.81%; 98.76%] (confidence interval at 95% confidence level) across 31 subjects (63 sessions), significantly surpassing traditional methods such as Independent Component Analysis (ICA) (79.29% [57.41%; 92.89%]) and Artifact Subspace Reconstruction (ASR) (84.05% [62.88%; 95.31%]). These results underscore the critical role of channel selection and the potential of using blink patterns for detecting bad EEG channels, offering valuable insights for improving real-time or offline BCI systems by reducing noise and enhancing signal quality.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17395v1" target="_blank">Realizing non-Hermitian tunneling phenomena using non-reciprocal active acoustic metamaterials</a></h3>
                    <p><strong>Authors:</strong> Felix Langfeldt, Joe Tan, Sayan Jana, Lea Sirota</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> Non-reciprocal systems have been shown to exhibit various interesting wave phenomena, such as the non-Hermitian skin effect, which causes accumulation of modes at boundaries. Recent research on discrete systems showed that this effect can pose a barrier for waves hitting an interface between reciprocal and non-reciprocal systems. Under certain conditions, however, waves can tunnel through this barrier, similar to the tunneling of particles in quantum mechanics. This work proposes and investigates an active acoustic metamaterial design to realize this tunneling phenomenon in the acoustical wave domain. The metamaterial consists of an acoustic waveguide with microphones and loudspeakers embedded in its wall. Starting from a purely discrete non-Hermitian lattice model of the system, a hybrid continuous-discrete acoustic model is derived, resulting in distributed feedback control laws to realize the desired behavior for acoustic waves. The proposed control laws are validated using frequency and time domain finite element method simulations, which include lumped electro-acoustic loudspeaker models. Additionally, an experimental demonstration is performed using a waveguide with embedded active unit cells and a digital implementation of the control laws. In both the simulations and experiments the tunneling phenomenon is successfully observed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17389v1" target="_blank">Investigating Training Data Detection in AI Coders</a></h3>
                    <p><strong>Authors:</strong> Tianlin Li, Yunxiang Wei, Zhiming Li, Aishan Liu, Qing Guo, Xianglong Liu, Dongning Sun, Yang Liu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in code large language models (CodeLLMs) have made them indispensable tools in modern software engineering. However, these models occasionally produce outputs that contain proprietary or sensitive code snippets, raising concerns about potential non-compliant use of training data, and posing risks to privacy and intellectual property. To ensure responsible and compliant deployment of CodeLLMs, training data detection (TDD) has become a critical task. While recent TDD methods have shown promise in natural language settings, their effectiveness on code data remains largely underexplored. This gap is particularly important given codes structured syntax and distinct similarity criteria compared to natural language. To address this, we conduct a comprehensive empirical study of seven state-of-the-art TDD methods on source code data, evaluating their performance across eight CodeLLMs. To support this evaluation, we introduce CodeSnitch, a function-level benchmark dataset comprising 9,000 code samples in three programming languages, each explicitly labeled as either included or excluded from CodeLLM training. Beyond evaluation on the original CodeSnitch, we design targeted mutation strategies to test the robustness of TDD methods under three distinct settings. These mutation strategies are grounded in the well-established Type-1 to Type-4 code clone detection taxonomy. Our study provides a systematic assessment of current TDD techniques for code and offers insights to guide the development of more effective and robust detection methods in the future.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17385v1" target="_blank">A Zero-overhead Flow for Security Closure</a></h3>
                    <p><strong>Authors:</strong> Mohammad Eslami, Ashira Johara, Kyungbin Park, Samuel Pagliarini</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> In the traditional Application-Specific Integrated Circuit (ASIC) design flow, the concept of timing closure implies to reach convergence during physical synthesis such that, under a given area and power budget, the design works at the targeted frequency. However, security has been largely neglected when evaluating the Quality of Results (QoR) from physical synthesis. In general, commercial place  route tools do not understand security goals. In this work, we propose a modified ASIC design flow that is security-aware and, differently from prior research, does not degrade QoR for the sake of security improvement. Therefore, we propose a first-of-its-kind zero-overhead flow for security closure. Our flow is concerned with two distinct threat models: (i) insertion of Hardware Trojans (HTs) and (ii) physical probing/fault injection. Importantly, the flow is entirely executed within a commercial place  route engine and is scalable. In several metrics, our security-aware flow achieves the best-known results for the ISPD`22 set of benchmark circuits while incurring negligible design overheads due to security-related strategies. Finally, we open source the entire methodology (as a set of scripts) and also share the protected circuits (as design databases) for the benefit of the hardware security community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17384v1" target="_blank">Mass-Gap Neutron Stars from Vector \texorpdfstring{$f(R)$}{f(R)} Gravity Inflationary Deformations</a></h3>
                    <p><strong>Authors:</strong> V. K. Oikonomou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> The latest observations from the LIGO-Virgo indicated the existence of mass-gap region astrophysical objects. This is a rather sensational observation and there are two possibilities for the nature of these mass-gap region astrophysical objects, these are either small black holes that result from the mergers of ordinary mass neutron stars, or these are heavy neutron stars. In the line of research implied by the former possibility, in this work we shall examine the implied neutron star phenomenology from vector $f(R)$ gravity inflationary models. These theories are basically scalar-tensor deformations of the Starobinsky inflationary model. We shall present the essential features of cosmologically viable and non-viable deformations of the Starobinsky model, originating from vector $f(R)$ gravity inflationary theories, and we indicate which models and for which equations of state provide a viable neutron star phenomenology. We solve the Tolman-Oppenheimer-Volkov equations using a robust double shooting LSODA python based code, for the following piecewise polytropic equations of state the WFF1, the SLy, the APR, the MS1, the AP3, the AP4, the ENG, the MPA1 and the MS1b. We confront the resulting phenomenology with several well known neutron star constraints and we indicate which equation of state and model fits the phenomenological constraints. A remarkable feature, also known from other inflationary attractor models, is that the MPA1 is the equation of state which is most nicely fitted the constraints, for all the theoretical models used, and actually the maximum mass for this equation of state is well inside the mass-gap region. Another mentionable feature that stroked us with surprise is the fact that even cosmologically non-viable inflationary models produced a viable neutron star phenomenology, which most likely has to be a model-dependent feature.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17376v1" target="_blank">An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness</a></h3>
                    <p><strong>Authors:</strong> Tianshu Ruan, Aniketh Ramesh, Rustam Stolkin, Manolis Chiou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> In this paper, we investigate the impact of high-level semantics (evaluation of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction (HRI) in the context of mobile robot deployments. Although semantics has been widely researched in AI, how high-level semantics can benefit the HRT paradigm is underexplored, often fuzzy, and intractable. We applied a semantics-based framework that could reveal different indicators of the environment (i.e. how much semantic information exists) in a mock-up disaster response mission. In such missions, semantics are crucial as the HRT should handle complex situations and respond quickly with correct decisions, where humans might have a high workload and stress. Especially when human operators need to shift their attention between robots and other tasks, they will struggle to build Situational Awareness (SA) quickly. The experiment suggests that the presented semantics: 1) alleviate the perceived workload of human operators; 2) increase the operators trust in the SA; and 3) help to reduce the reaction time in switching the level of autonomy when needed. Additionally, we find that participants with higher trust in the system are encouraged by high-level semantics to use teleoperation mode more.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17372v1" target="_blank">Giant Damping-like Torque Efficiency via Synergistic Spin Hall and enhanced Orbital Hall Effects</a></h3>
                    <p><strong>Authors:</strong> Subhakanta Das, Sabpreet Bhatti, Ramu Maddu, Bilal Jamshed, Go Dong Wook, S. N. Piramanayagam</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Current-induced spin-orbit torque (SOT) has emerged as a promising method for achieving energy-efficient magnetisation switching in advanced spintronic devices. Over the past two decades, researchers have primarily focused on enhancing spin current generation through the spin Hall effect, relying predominantly on the spin degree of freedom (DoF) of the electron, while neglecting its orbital counterpart. Orbital Hall effect depends critically on the crystallinity and the interface between the orbital Hall layer and the orbital-to-spin conversion layer. However, most experimental works on orbital Hall effect relied on polycrystalline films with no special attention to improve the crystallographic texture. In this work, we have grown the Ru layer on a NiW seedlayer, which helped to improve the crystallographic texture, thereby enhancing the switching efficiency by over 44%. Such a huge increase in switching efficiency was achieved by (i) improving crystallographic texture and (ii) leveraging both spin and orbital DoFs. Our study underscores the potential for improving the spin-torque efficiency by combining interface engineering, orbital and spin Hall effects to drive next-generation spintronics.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3705328.3748082" target="_blank">Leave No One Behind: Fairness-Aware Cross-Domain Recommender Systems for Non-Overlapping Users</a></h3>
                    <p><strong>Authors:</strong> Weixin Chen, Yuhan Zhao, Li Chen, Weike Pan</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Cross-domain recommendation (CDR) methods predominantly leverage overlapping users to transfer knowledge from a source domain to a target domain. However, through empirical studies, we uncover a critical bias inherent in these approaches: while overlapping users experience significant enhancements in recommendation quality, non-overlapping users benefit minimally and even face performance degradation. This unfairness may erode user trust, and, consequently, negatively impact business engagement and revenue. To address this issue, we propose a novel solution that generates virtual source-domain users for non-overlapping target-domain users. Our method utilizes a dual attention mechanism to discern similarities between overlapping and non-overlapping users, thereby synthesizing realistic virtual user embeddings. We further introduce a limiter component that ensures the generated virtual users align with real-data distributions while preserving each users unique characteristics. Notably, our method is model-agnostic and can be seamlessly integrated into any CDR model. Comprehensive experiments conducted on three public datasets with five CDR baselines demonstrate that our method effectively mitigates the CDR non-overlapping user bias, without loss of overall accuracy. Our code is publicly available at https://github.com/WeixinChen98/VUG.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17746v1" target="_blank">Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains</a></h3>
                    <p><strong>Authors:</strong> Anisha Gunjal, Anthony Wang, Elaine Lau, Vaskar Nath, Bing Liu, Sean Hendryx</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world tasks often requires balancing objective and subjective evaluation criteria. However, many such tasks lack a single, unambiguous ground truth-making it difficult to define reliable reward signals for post-training language models. While traditional preference-based methods offer a workaround, they rely on opaque reward functions that are difficult to interpret and prone to spurious correlations. We introduce $\textbf{Rubrics as Rewards}$ (RaR), a framework that uses structured, checklist-style rubrics as interpretable reward signals for on-policy training with GRPO. Our best RaR method yields up to a $28\%$ relative improvement on HealthBench-1k compared to simple Likert-based approaches, while matching or surpassing the performance of reward signals derived from expert-written references. By treating rubrics as structured reward signals, we show that RaR enables smaller-scale judge models to better align with human preferences and sustain robust performance across model scales.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17731v1" target="_blank">Flow Matching Meets Biology and Life Science: A Survey</a></h3>
                    <p><strong>Authors:</strong> Zihao Li, Zhichen Zeng, Xiao Lin, Feihao Fang, Yanru Qu, Zhe Xu, Zhining Liu, Xuying Ning, Tianxin Wei, Ge Liu, Hanghang Tong, Jingrui He</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Over the past decade, advances in generative modeling, such as generative adversarial networks, masked autoencoders, and diffusion models, have significantly transformed biological research and discovery, enabling breakthroughs in molecule design, protein generation, drug discovery, and beyond. At the same time, biological applications have served as valuable testbeds for evaluating the capabilities of generative models. Recently, flow matching has emerged as a powerful and efficient alternative to diffusion-based generative modeling, with growing interest in its application to problems in biology and life sciences. This paper presents the first comprehensive survey of recent developments in flow matching and its applications in biological domains. We begin by systematically reviewing the foundations and variants of flow matching, and then categorize its applications into three major areas: biological sequence modeling, molecule generation and design, and peptide and protein generation. For each, we provide an in-depth review of recent progress. We also summarize commonly used datasets and software tools, and conclude with a discussion of potential future directions. The corresponding curated resources are available at https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17730v1" target="_blank">Online Submission and Evaluation System Design for Competition Operations</a></h3>
                    <p><strong>Authors:</strong> Zhe Chen, Daniel Harabor, Ryan Hechnenberger, Nathan R. Sturtevant</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Research communities have developed benchmark datasets across domains to compare the performance of algorithms and techniques However, tracking the progress in these research areas is not easy, as publications appear in different venues at the same time, and many of them claim to represent the state-of-the-art. To address this, research communities often organise periodic competitions to evaluate the performance of various algorithms and techniques, thereby tracking advancements in the field. However, these competitions pose a significant operational burden. The organisers must manage and evaluate a large volume of submissions. Furthermore, participants typically develop their solutions in diverse environments, leading to compatibility issues during the evaluation of their submissions. This paper presents an online competition system that automates the submission and evaluation process for a competition. The competition system allows organisers to manage large numbers of submissions efficiently, utilising isolated environments to evaluate submissions. This system has already been used successfully for several competitions, including the Grid-Based Pathfinding Competition and the League of Robot Runners competition.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17727v1" target="_blank">CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation</a></h3>
                    <p><strong>Authors:</strong> Robel Mamo, Taeyeong Choi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> State-of-the-art visual under-canopy navigation methods are designed with deep learning-based perception models to distinguish traversable space from crop rows. While these models have demonstrated successful performance, they require large amounts of training data to ensure reliability in real-world field deployment. However, data collection is costly, demanding significant human resources for in-field sampling and annotation. To address this challenge, various data augmentation techniques are commonly employed during model training, such as color jittering, Gaussian blur, and horizontal flip, to diversify training data and enhance model robustness. In this paper, we hypothesize that utilizing only these augmentation techniques may lead to suboptimal performance, particularly in complex under-canopy environments with frequent occlusions, debris, and non-uniform spacing of crops. Instead, we propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut) which masks random regions out in input images that are spatially distributed around crop rows on the sides to encourage trained models to capture high-level contextual features even when fine-grained information is obstructed. Our extensive experiments with a public cornfield dataset demonstrate that masking-based augmentations are effective for simulating occlusions and significantly improving robustness in semantic keypoint predictions for visual navigation. In particular, we show that biasing the mask distribution toward crop rows in CA-Cut is critical for enhancing both prediction accuracy and generalizability across diverse environments achieving up to a 36.9% reduction in prediction error. In addition, we conduct ablation studies to determine the number of masks, the size of each mask, and the spatial distribution of masks to maximize overall performance.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.3390/polym15030558" target="_blank">Application of new conformal cooling layouts to the green injection molding of complex slender polymeric parts with high dimensional specifications</a></h3>
                    <p><strong>Authors:</strong> Abelardo Torres Alba, Jorge Manuel Mercado Colmenero, Juan de Dios Caballero Garcia, Cristina Martin Donate</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> Eliminating warpage in injection molded polymeric parts is one of the most important problems in the injection molding industry today. This situation is critical in geometries that are particularly susceptible to warping due to their geometric features, and this occurs with topologies of great length and slenderness with high changes in thickness. These features are, in these special geometries, impossible to manufacture with traditional technologies to meet the dimensional and sustainable requirements of the industry. This paper presents an innovative green conformal cooling system that is specifically designed for parts with slender geometric shapes that are highly susceptible to warping. Additionally, the work presented by the authors investigates the importance of using highly conductive inserts made of steel alloys in combination with the use of additively manufactured conformal channels for reducing influential parameters, such as warpage, cooling time, and residual stresses in the complex manufacturing of long and slender parts. The results of this real industrial case study indicated that the use of conformal cooling layouts decreased the cycle time by 175.1 s 66% below the current cooling time; the temperature gradient by 78.5% specifically, 18.16 C; the residual stress by 39.78 MPa or 81.88%; and the warpage by 6.9 mm or 90.5%. In this way, it was possible to achieve a final warping in the complex geometry studied of 0.72 mm, which was under the maximum value required at the industrial level of 1 mm. The resulting values obtained by the researchers present a turning point from which the manufacturing and sustainability in the injection molding of said plastic geometries is possible, and they take into account that the geometric manufacturing features analyzed will present a great demand in the coming years in the auto parts manufacturing industry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17718v1" target="_blank">AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer</a></h3>
                    <p><strong>Authors:</strong> Danny D. Leybzon, Shreyas Tirumala, Nishant Jain, Summer Gillen, Michael Jackson, Cameron McPhee, Jennifer Schmidt</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> With the rise of voice-enabled artificial intelligence (AI) systems, quantitative survey researchers have access to a new data-collection mode: AI telephone surveying. By using AI to conduct phone interviews, researchers can scale quantitative studies while balancing the dual goals of human-like interactivity and methodological rigor. Unlike earlier efforts that used interactive voice response (IVR) technology to automate these surveys, voice AI enables a more natural and adaptive respondent experience as it is more robust to interruptions, corrections, and other idiosyncrasies of human speech. We built and tested an AI system to conduct quantitative surveys based on large language models (LLM), automatic speech recognition (ASR), and speech synthesis technologies. The system was specifically designed for quantitative research, and strictly adhered to research best practices like question order randomization, answer order randomization, and exact wording. To validate the systems effectiveness, we deployed it to conduct two pilot surveys with the SSRS Opinion Panel and followed-up with a separate human-administered survey to assess respondent experiences. We measured three key metrics: the survey completion rates, break-off rates, and respondent satisfaction scores. Our results suggest that shorter instruments and more responsive AI interviewers may contribute to improvements across all three metrics studied.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17717v1" target="_blank">From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes</a></h3>
                    <p><strong>Authors:</strong> Karen Zhou, John Giorgi, Pranav Mani, Peng Xu, Davis Liang, Chenhao Tan</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> AI-generated clinical notes are increasingly used in healthcare, but evaluating their quality remains a challenge due to high subjectivity and limited scalability of expert review. Existing automated metrics often fail to align with real-world physician preferences. To address this, we propose a pipeline that systematically distills real user feedback into structured checklists for note evaluation. These checklists are designed to be interpretable, grounded in human feedback, and enforceable by LLM-based evaluators. Using deidentified data from over 21,000 clinical encounters, prepared in accordance with the HIPAA safe harbor standard, from a deployed AI medical scribe system, we show that our feedback-derived checklist outperforms baseline approaches in our offline evaluations in coverage, diversity, and predictive power for human ratings. Extensive experiments confirm the checklists robustness to quality-degrading perturbations, significant alignment with clinician preferences, and practical value as an evaluation methodology. In offline research settings, the checklist can help identify notes likely to fall below our chosen quality thresholds.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17709v1" target="_blank">TyDi QA-WANA: A Benchmark for Information-Seeking Question Answering in Languages of West Asia and North Africa</a></h3>
                    <p><strong>Authors:</strong> Parker Riley, Siamak Shakeri, Waleed Ammar, Jonathan H. Clark</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We present TyDi QA-WANA, a question-answering dataset consisting of 28K examples divided among 10 language varieties of western Asia and northern Africa. The data collection process was designed to elicit information-seeking questions, where the asker is genuinely curious to know the answer. Each question in paired with an entire article that may or may not contain the answer; the relatively large size of the articles results in a task suitable for evaluating models abilities to utilize large text contexts in answering questions. Furthermore, the data was collected directly in each language variety, without the use of translation, in order to avoid issues of cultural relevance. We present performance of two baseline models, and release our code and data to facilitate further improvement by the research community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17699v1" target="_blank">Thinking Isnt an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations</a></h3>
                    <p><strong>Authors:</strong> Zhao Song, Song Yue, Jiahao Zhang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large Reasoning Models (LRMs) have become a central focus in todays large language model (LLM) research, where models are designed to output a step-by-step thinking process before arriving at a final answer to handle complex reasoning tasks. Despite their promise, recent empirical studies (e.g., [Shojaee et al., 2025] from Apple) suggest that this thinking process may not actually enhance reasoning ability, where LLMs without explicit reasoning actually outperform LRMs on tasks with low or high complexity. In this work, we revisit these findings and investigate whether the limitations of LRMs persist when tool augmentations are introduced. We incorporate two types of tools, Python interpreters and scratchpads, and evaluate three representative LLMs and their LRM counterparts on Apples benchmark reasoning puzzles. Our results show that, with proper tool use, LRMs consistently outperform their non-reasoning counterparts across all levels of task complexity. These findings challenge the recent narrative that reasoning is an illusion and highlight the potential of tool-augmented LRMs for solving complex problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17695v1" target="_blank">Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks</a></h3>
                    <p><strong>Authors:</strong> Ilias Chatzistefanidis, Navid Nikaein</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.NI</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLMs input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17688v1" target="_blank">Mindfulness Meditation and Respiration: Accelerometer-Based Respiration Rate and Mindfulness Progress Estimation to Enhance App Engagement and Mindfulness Skills</a></h3>
                    <p><strong>Authors:</strong> Mohammad Nur Hossain Khan, David creswell, Jordan Albert, Patrick OConnell, Shawn Fallon, Mathew Polowitz, Xuhai orson Xu, Bashima islam</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Mindfulness training is widely recognized for its benefits in reducing depression, anxiety, and loneliness. With the rise of smartphone-based mindfulness apps, digital meditation has become more accessible, but sustaining long-term user engagement remains a challenge. This paper explores whether respiration biosignal feedback and mindfulness skill estimation enhance system usability and skill development. We develop a smartphones accelerometer-based respiration tracking algorithm, eliminating the need for additional wearables. Unlike existing methods, our approach accurately captures slow breathing patterns typical of mindfulness meditation. Additionally, we introduce the first quantitative framework to estimate mindfulness skills-concentration, sensory clarity, and equanimity-based on accelerometer-derived respiration data. We develop and test our algorithms on 261 mindfulness sessions in both controlled and real-world settings. A user study comparing an experimental group receiving biosignal feedback with a control group using a standard app shows that respiration feedback enhances system usability. Our respiration tracking model achieves a mean absolute error (MAE) of 1.6 breaths per minute, closely aligning with ground truth data, while our mindfulness skill estimation attains F1 scores of 80-84% in tracking skill progression. By integrating respiration tracking and mindfulness estimation into a commercial app, we demonstrate the potential of smartphone sensors to enhance digital mindfulness training.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17682v1" target="_blank">Audio-Vision Contrastive Learning for Phonological Class Recognition</a></h3>
                    <p><strong>Authors:</strong> Daiqi Liu, TomÃ¡s Arias-Vergara, Jana Hutter, Andreas Maier, Paula Andrea PÃ©rez-Toro</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CV, cs.MM, eess.AS</p>
                    <p><strong>Summary:</strong> Accurate classification of articulatory-phonological features plays a vital role in understanding human speech production and developing robust speech technologies, particularly in clinical contexts where targeted phonemic analysis and therapy can improve disease diagnosis accuracy and personalized rehabilitation. In this work, we propose a multimodal deep learning framework that combines real-time magnetic resonance imaging (rtMRI) and speech signals to classify three key articulatory dimensions: manner of articulation, place of articulation, and voicing. We perform classification on 15 phonological classes derived from the aforementioned articulatory dimensions and evaluate the system with four audio/vision configurations: unimodal rtMRI, unimodal audio signals, multimodal middle fusion, and contrastive learning-based audio-vision fusion. Experimental results on the USC-TIMIT dataset show that our contrastive learning-based approach achieves state-of-the-art performance, with an average F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal baseline. The results confirm the effectiveness of contrastive representation learning for multimodal articulatory analysis. Our code and processed dataset will be made publicly available at https://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17680v1" target="_blank">Simulating multiple human perspectives in socio-ecological systems using large language models</a></h3>
                    <p><strong>Authors:</strong> Yongchao Zeng, Calum Brown, Ioannis Kyriakou, Ronja Hotz, Mark Rounsevell</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> Understanding socio-ecological systems requires insights from diverse stakeholder perspectives, which are often hard to access. To enable alternative, simulation-based exploration of different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) to represent various stakeholders; users can step into the agent roles to experience perspectival differences. A simulation protocol serves as a scaffold to streamline multiple perspective-taking simulations, supporting users in reflecting on, transitioning between, and integrating across perspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional dynamics and land use change, enabling both narrative-driven and numerical experiments. In an illustrative experiment, a user successively adopts the perspectives of a system observer and a researcher - a role that analyses data from the embedded land use model to inform evidence-based decision-making for other LLM agents representing various institutions. Despite the users effort to recommend technically sound policies, discrepancies persist between the policy recommendation and implementation due to stakeholders competing advocacies, mirroring real-world misalignment between researcher and policymaker perspectives. The users reflection highlights the subjective feelings of frustration and disappointment as a researcher, especially due to the challenge of maintaining political neutrality while attempting to gain political influence. Despite this, the user exhibits high motivation to experiment with alternative narrative framing strategies, suggesting the systems potential in exploring different perspectives. Further system and protocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-ecological simulations.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.3847/1538-4357/adf05e" target="_blank">Mapping ground-based coronagraphic images to Helioprojective-Cartesian coordinate system by image registration</a></h3>
                    <p><strong>Authors:</strong> Feiyang Sha, Yu Liu, Lidong Xia, Yao Chen, Qing Zhou, Yangrui Chen, Chuyu Zhong, Xuefei Zhang, Tengfei Song, Mingzhe Sun, Haitang Li, Jacob Oloketuyi, Qiang Liu, Xinjian Wang, Qiwang Luo, Xiaobo Li</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR, astro-ph.GA, astro-ph.IM</p>
                    <p><strong>Summary:</strong> A few ground-based solar coronagraphs have been installed in western China for observing the low-layer corona in recent years. However, determining the Helioprojective Coordinates for the coronagraphic data with high precision is an important but challenging step for further research with other multi-wavelength data. In this paper, we propose an automatic coronal image registration method that combines local statistical correlation and feature point matching to achieve accurate registration between ground-based coronal green-line images and space-based 211 {\AA} images. Then, the accurate field of view information of the coronal green-line images can be derived, allowing the images to be mapped to the Helioprojective Cartesian Coordinates with an accuracy of no less than 0.1. This method has been extensively validated using 100 days of coronal data spanning an 11-year period, demonstrating its broad applicability to ground-based coronagraphs equipped with green-line observations. It significantly enhances the scientific value of ground-based coronal data, enabling comprehensive studies of coronal transient activities and facilitating the joint analysis of data from multiple instruments. Additionally, it holds potential for future applications in improving the pointing accuracy of coronagraphs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17665v1" target="_blank">Perspective-Invariant 3D Object Detection</a></h3>
                    <p><strong>Authors:</strong> Ao Liang, Lingdong Kong, Dongyue Lu, Youquan Liu, Jian Fang, Huaici Zhao, Wei Tsang Ooi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> With the rise of robotics, LiDAR-based 3D object detection has garnered significant attention in both academia and industry. However, existing datasets and methods predominantly focus on vehicle-mounted platforms, leaving other autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET, the first benchmark featuring LiDAR data and 3D bounding box annotations collected from multiple platforms: vehicle, quadruped, and drone, thereby facilitating research in 3D object detection for non-vehicle platforms as well as cross-platform 3D detection. Based on Pi3DET, we propose a novel cross-platform adaptation framework that transfers knowledge from the well-studied vehicle platform to other platforms. This framework achieves perspective-invariant 3D detection through robust alignment at both geometric and feature levels. Additionally, we establish a benchmark to evaluate the resilience and robustness of current 3D detectors in cross-platform scenarios, providing valuable insights for developing adaptive 3D perception systems. Extensive experiments validate the effectiveness of our approach on challenging cross-platform tasks, demonstrating substantial gains over existing adaptation methods. We hope this work paves the way for generalizable and unified 3D perception systems across diverse and complex environments. Our Pi3DET dataset, cross-platform benchmark suite, and annotation toolkit have been made publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17662v1" target="_blank">Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography</a></h3>
                    <p><strong>Authors:</strong> Farnoush Bayatmakou, Reza Taleei, Nicole Simone, Arash Mohammadi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Breast cancer (BC) remains one of the leading causes of cancer-related mortality among women, despite recent advances in Computer-Aided Diagnosis (CAD) systems. Accurate and efficient interpretation of multi-view mammograms is essential for early detection, driving a surge of interest in Artificial Intelligence (AI)-powered CAD models. While state-of-the-art multi-view mammogram classification models are largely based on Transformer architectures, their computational complexity scales quadratically with the number of image patches, highlighting the need for more efficient alternatives. To address this challenge, we propose Mammo-Mamba, a novel framework that integrates Selective State-Space Models (SSMs), transformer-based attention, and expert-driven feature refinement into a unified architecture. Mammo-Mamba extends the MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE) mechanism through its customized SecMamba block. The SecMamba is a modified MambaVision block that enhances representation learning in high-resolution mammographic images by enabling content-adaptive feature refinement. These blocks are integrated into the deeper stages of MambaVision, allowing the model to progressively adjust feature emphasis through dynamic expert gating, effectively mitigating the limitations of traditional Transformer models. Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior classification performance across all key metrics while maintaining computational efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17655v1" target="_blank">Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses</a></h3>
                    <p><strong>Authors:</strong> Shams Shaikh, Trima P. Fernandes e Fizardo</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.NI, cs.SE, C.2.4; D.4.6; E.3; E.5; K.6.5</p>
                    <p><strong>Summary:</strong> As organizations rapidly migrate to the cloud, the security of cryptographic key management has become a growing concern. Hardware Security Modules (HSMs) and Trusted Platform Modules (TPMs), traditionally seen as the gold standard for securing encryption keys and digital trust, are increasingly challenged by cloud-native threats. Real-world breaches have exposed weaknesses in cloud deployments, including misconfigurations, API abuse, and privilege escalations, allowing attackers to access sensitive key material and bypass protections. These incidents reveal that while the hardware remains secure, the surrounding cloud ecosystem introduces systemic vulnerabilities. This paper analyzes notable security failures involving HSMs and TPMs, identifies common attack vectors, and questions longstanding assumptions about their effectiveness in distributed environments. We explore alternative approaches such as confidential computing, post-quantum cryptography, and decentralized key management. Our findings highlight that while HSMs and TPMs still play a role, modern cloud security requires more adaptive, layered architectures. By evaluating both current weaknesses and emerging models, this research equips cloud architects and security engineers with strategies to reinforce cryptographic trust in the evolving threat landscape.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17636v1" target="_blank">Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries</a></h3>
                    <p><strong>Authors:</strong> Victor Hartman, Petter TÃ¶rnberg</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Negative campaigning is a central feature of political competition, yet empirical research has been limited by the high cost and limited scalability of existing classification methods. This study makes two key contributions. First, it introduces zero-shot Large Language Models (LLMs) as a novel approach for cross-lingual classification of negative campaigning. Using benchmark datasets in ten languages, we demonstrate that LLMs achieve performance on par with native-speaking human coders and outperform conventional supervised machine learning approaches. Second, we leverage this novel method to conduct the largest cross-national study of negative campaigning to date, analyzing 18 million tweets posted by parliamentarians in 19 European countries between 2017 and 2022. The results reveal consistent cross-national patterns: governing parties are less likely to use negative messaging, while ideologically extreme and populist parties -- particularly those on the radical right -- engage in significantly higher levels of negativity. These findings advance our understanding of how party-level characteristics shape strategic communication in multiparty systems. More broadly, the study demonstrates the potential of LLMs to enable scalable, transparent, and replicable research in political communication across linguistic and cultural contexts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17618v1" target="_blank">A Hybrid Early-Exit Algorithm for Large Language Models Based on Space Alignment Decoding (SPADE)</a></h3>
                    <p><strong>Authors:</strong> Bowen Zheng, Ming Ma, Zhongqiao Lin, Tianming Yang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.PF</p>
                    <p><strong>Summary:</strong> Large language models are computationally expensive due to their deep structures. Prior research has shown that intermediate layers contain sufficient information to generate accurate answers, leading to the development of early-exit algorithms that reduce inference costs by terminating computation at earlier layers. However, these methods often suffer from poor performance due to misalignment between intermediate and output layer representations that lead to decoding inaccuracy. To address these challenges, we propose SPADE (SPace Alignment DEcoding), a novel decoding method that aligns intermediate layer representations with the output layer by propagating a minimally reduced sequence consisting of only the start token and the answer token. We further optimize the early-exit decision-making process by training a linear approximation of SPADE that computes entropy-based confidence metrics. Putting them together, we create a hybrid early-exit algorithm that monitors confidence levels and stops inference at intermediate layers while using SPADE to generate high-quality outputs. This approach significantly reduces inference costs without compromising accuracy, offering a scalable and efficient solution for deploying large language models in real-world applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17616v1" target="_blank">Vision Transformer attention alignment with human visual perception in aesthetic object evaluation</a></h3>
                    <p><strong>Authors:</strong> Miguel Carrasco, CÃ©sar GonzÃ¡lez-MartÃ­n, JosÃ© Aranda, Luis Oliveros</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Visual attention mechanisms play a crucial role in human perception and aesthetic evaluation. Recent advances in Vision Transformers (ViTs) have demonstrated remarkable capabilities in computer vision tasks, yet their alignment with human visual attention patterns remains underexplored, particularly in aesthetic contexts. This study investigates the correlation between human visual attention and ViT attention mechanisms when evaluating handcrafted objects. We conducted an eye-tracking experiment with 30 participants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal objects comprising basketry bags and ginger jars. Using a Pupil Labs eye-tracker, we recorded gaze patterns and generated heat maps representing human visual attention. Simultaneously, we analyzed the same objects using a pre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting attention maps from each of the 12 attention heads. We compared human and ViT attention distributions using Kullback-Leibler divergence across varying Gaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal correlation at sigma=2.4 +-0.03, with attention head #12 showing the strongest alignment with human visual patterns. Significant differences were found between attention heads, with heads #7 and #9 demonstrating the greatest divergence from human attention (p 0.05, Tukey HSD test). Results indicate that while ViTs exhibit more global attention patterns compared to human focal attention, certain attention heads can approximate human visual behavior, particularly for specific object features like buckles in basketry items. These findings suggest potential applications of ViT attention mechanisms in product design and aesthetic evaluation, while highlighting fundamental differences in attention strategies between human perception and current AI models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17614v1" target="_blank">Comparing performance of variational quantum algorithm simulations on HPC systems</a></h3>
                    <p><strong>Authors:</strong> Marco De Pascale, Tobias Valentin Bauer, Yaknan John Gambo, Mario HernÃ¡ndez Vera, Stefan Huber, Burak Mete, Amit Jamadagni, Amine Bentellis, Marita Oliv, Luigi Iapichino, Jeanette Miriam Lorenz</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.DC</p>
                    <p><strong>Summary:</strong> Variational quantum algorithms are of special importance in the research on quantum computing applications because of their applicability to current Noisy Intermediate-Scale Quantum (NISQ) devices. The main building blocks of these algorithms (among them, the definition of the Hamiltonian and of the ansatz, the optimizer) define a relatively large parameter space, making the comparison of results and performance between different approaches and software simulators cumbersome and prone to errors. In this paper, we employ a generic description of the problem, in terms of both Hamiltonian and ansatz, to port a problem definition consistently among different simulators. Three use cases of relevance for current quantum hardware (ground state calculation for the Hydrogen molecule, MaxCut, Travelling Salesman Problem) have been run on a set of HPC systems and software simulators to study the dependence of performance on the runtime environment, the scalability of the simulation codes and the mutual agreement of the physical results, respectively. The results show that our toolchain can successfully translate a problem definition between different simulators. On the other hand, variational algorithms are limited in their scaling by the long runtimes with respect to their memory footprint, so they expose limited parallelism to computation. This shortcoming is partially mitigated by using techniques like job arrays. The potential of the parser tool for exploring HPC performance and comparisons of results of variational algorithm simulations is highlighted.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17606v1" target="_blank">Time Deep Gradient Flow Method for pricing American options</a></h3>
                    <p><strong>Authors:</strong> Jasper Rou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> q-fin.CP, cs.LG, math.PR, q-fin.MF, 91G20, 91G60, 68T07</p>
                    <p><strong>Summary:</strong> In this research, we explore neural network-based methods for pricing multidimensional American put options under the BlackScholes and Heston model, extending up to five dimensions. We focus on two approaches: the Time Deep Gradient Flow (TDGF) method and the Deep Galerkin Method (DGM). We extend the TDGF method to handle the free-boundary partial differential equation inherent in American options. We carefully design the sampling strategy during training to enhance performance. Both TDGF and DGM achieve high accuracy while outperforming conventional Monte Carlo methods in terms of computational speed. In particular, TDGF tends to be faster during training than DGM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17597v1" target="_blank">Explainable AI for Collaborative Assessment of 2D/3D Registration Quality</a></h3>
                    <p><strong>Authors:</strong> Sue Min Cho, Alexander Do, Russell H. Taylor, Mathias Unberath</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CV</p>
                    <p><strong>Summary:</strong> As surgery embraces digital transformation--integrating sophisticated imaging, advanced algorithms, and robotics to support and automate complex sub-tasks--human judgment of system correctness remains a vital safeguard for patient safety. This shift introduces new operator-type roles tasked with verifying complex algorithmic outputs, particularly at critical junctures of the procedure, such as the intermediary check before drilling or implant placement. A prime example is 2D/3D registration, a key enabler of image-based surgical navigation that aligns intraoperative 2D images with preoperative 3D data. Although registration algorithms have advanced significantly, they occasionally yield inaccurate results. Because even small misalignments can lead to revision surgery or irreversible surgical errors, there is a critical need for robust quality assurance. Current visualization-based strategies alone have been found insufficient to enable humans to reliably detect 2D/3D registration misalignments. In response, we propose the first artificial intelligence (AI) framework trained specifically for 2D/3D registration quality verification, augmented by explainability features that clarify the models decision-making. Our explainable AI (XAI) approach aims to enhance informed decision-making for human operators by providing a second opinion together with a rationale behind it. Through algorithm-centric and human-centered evaluations, we systematically compare four conditions: AI-only, human-only, human-AI, and human-XAI. Our findings reveal that while explainability features modestly improve user trust and willingness to override AI errors, they do not exceed the standalone AI in aggregate performance. Nevertheless, future work extending both the algorithmic design and the human-XAI collaboration elements holds promise for more robust quality assurance of 2D/3D registration.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17588v1" target="_blank">Dual-branch Prompting for Multimodal Machine Translation</a></h3>
                    <p><strong>Authors:</strong> Jie Wang, Zhendong Yang, Liansong Zong, Xiaobo Zhang, Dexian Wang, Ji Zhang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL</p>
                    <p><strong>Summary:</strong> Multimodal Machine Translation (MMT) typically enhances text-only translation by incorporating aligned visual features. Despite the remarkable progress, state-of-the-art MMT approaches often rely on paired image-text inputs at inference and are sensitive to irrelevant visual noise, which limits their robustness and practical applicability. To address these issues, we propose D2P-MMT, a diffusion-based dual-branch prompting framework for robust vision-guided translation. Specifically, D2P-MMT requires only the source text and a reconstructed image generated by a pre-trained diffusion model, which naturally filters out distracting visual details while preserving semantic cues. During training, the model jointly learns from both authentic and reconstructed images using a dual-branch prompting strategy, encouraging rich cross-modal interactions. To bridge the modality gap and mitigate training-inference discrepancies, we introduce a distributional alignment loss that enforces consistency between the output distributions of the two branches. Extensive experiments on the Multi30K dataset demonstrate that D2P-MMT achieves superior translation performance compared to existing state-of-the-art approaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17580v1" target="_blank">Enhancing Quantum Federated Learning with Fisher Information-Based Optimization</a></h3>
                    <p><strong>Authors:</strong> Amandeep Singh Bhatia, Sabre Kais</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.DC, cs.ET, quant-ph</p>
                    <p><strong>Summary:</strong> Federated Learning (FL) has become increasingly popular across different sectors, offering a way for clients to work together to train a global model without sharing sensitive data. It involves multiple rounds of communication between the global model and participating clients, which introduces several challenges like high communication costs, heterogeneous client data, prolonged processing times, and increased vulnerability to privacy threats. In recent years, the convergence of federated learning and parameterized quantum circuits has sparked significant research interest, with promising implications for fields such as healthcare and finance. By enabling decentralized training of quantum models, it allows clients or institutions to collaboratively enhance model performance and outcomes while preserving data privacy. Recognizing that Fisher information can quantify the amount of information that a quantum state carries under parameter changes, thereby providing insight into its geometric and statistical properties. We intend to leverage this property to address the aforementioned challenges. In this work, we propose a Quantum Federated Learning (QFL) algorithm that makes use of the Fisher information computed on local client models, with data distributed across heterogeneous partitions. This approach identifies the critical parameters that significantly influence the quantum models performance, ensuring they are preserved during the aggregation process. Our research assessed the effectiveness and feasibility of QFL by comparing its performance against other variants, and exploring the benefits of incorporating Fisher information in QFL settings. Experimental results on ADNI and MNIST datasets demonstrate the effectiveness of our approach in achieving better performance and robustness against the quantum federated averaging method.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17576v1" target="_blank">Atomistic modeling of uranium monocarbide with a machine learning interatomic potential</a></h3>
                    <p><strong>Authors:</strong> Lorena Alzate-Vargas, Kashi N. Subedi, Roxanne M. Tutchton, Michael W. D. Cooper, Tammie Gibson, Richard A. Messerly</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> Uranium monocarbide (UC) is an advanced ceramic fuel candidate due to its superior uranium density and thermal conductivity compared to traditional fuels. To accurately model UC at reactor operating conditions, we developed a machine learning interatomic potential (MLIP) using an active learning procedure to generate a comprehensive training dataset capturing diverse atomic configurations. The resulting MLIP predicts structural, elastic, thermophysical properties, defect formation energies, and diffusion behaviors, aligning well with experimental and theoretical benchmarks. This work significantly advances computational methods to explore UC, enabling efficient large-scale and long-time molecular dynamics simulations essential for reactor fuel qualification.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17563v1" target="_blank">BoSS: Beyond-Semantic Speech</a></h3>
                    <p><strong>Authors:</strong> Qing Wang, Zehan Li, Hang Lv, Hongjie Chen, Yaodong Song, Jian Kang, Jie Lian, Jie Li, Yongxiang Li, Zhongjiang He, Xuelong Li</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CL, eess.AS</p>
                    <p><strong>Summary:</strong> Human communication involves more than explicit semantics, with implicit signals and contextual cues playing a critical role in shaping meaning. However, modern speech technologies, such as Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) often fail to capture these beyond-semantic dimensions. To better characterize and benchmark the progression of speech intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5), a hierarchical framework illustrated the evolution of spoken dialogue systems from basic command recognition to human-like social interaction. To support these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which refers to the set of information in speech communication that encompasses but transcends explicit semantics. It conveys emotions, contexts, and modifies or extends meanings through multidimensional features such as affective cues, contextual dynamics, and implicit semantics, thereby enhancing the understanding of communicative intentions and scenarios. We present a formalized framework for BoSS, leveraging cognitive relevance theories and machine learning models to analyze temporal and contextual speech dynamics. We evaluate BoSS-related attributes across five different dimensions, reveals that current spoken language models (SLMs) are hard to fully interpret beyond-semantic signals. These findings highlight the need for advancing BoSS research to enable richer, more context-aware human-machine communication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17562v1" target="_blank">Sliding multiferrocity in van der Waals layered CrI$_2$</a></h3>
                    <p><strong>Authors:</strong> Hui-Shi Yu, Xiao-Sheng Ni, Kun Cao</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mtrl-sci, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> Understanding magnetoelectric coupling in emerging van der Waals multiferroics is crucial for developing atomically thin spintronic devices. Here, we present a comprehensive first-principles investigation of magnetoelectric coupling in orthorhombic CrI$_2$. Monte Carlo simulations based on DFT-calculated magnetic exchange interactions suggest a proper-screw helimagnetic ground state with a N\{e}el temperature consistent with experimental observations. A ferroelectric switching pathway driven by interlayer sliding is predicted, featuring a low switching energy barrier and out-of-plane ferroelectric polarization. To quantitatively characterize the magnetoelectric effect in orthorhombic CrI$_2$ and its microscopic origin, we evaluate the spin-driven polarization using the paramagnetic phase as a reference alongside the magnetoelectric tensor method. The extracted spin-driven polarization aligns along the $z$-axis, with its origin dominated by the exchange-striction mechanism. Although in-plane components of the total polarization in the bulk vanish due to global symmetry constraints, each CrI$_2$ single layer exhibits local electric polarization along the $x$ direction, arising from the generalized spin-current mechanism, which couples spin chirality to the electric polarization. As a result, we further predict that a proper-screw helimagnetic state may persist in monolayer CrI$_2$, with its charity reversable by switching the in-plane electric polarization through applying external electric field, providing another promising candidate for electrical control of two-dimensional multiferroics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17561v1" target="_blank">Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper</a></h3>
                    <p><strong>Authors:</strong> Lorenzo Vianello, Matthew Short, Julia Manczurowsky, Emek BarÄ±ÅŸ KÃ¼Ã§Ã¼ktabak, Francesco Di Tommaso, Alessia Noccaro, Laura Bandini, Shoshana Clark, Alaina Fiorenza, Francesca Lunardini, Alberto Canton, Marta Gandolla, Alessandra L. G. Pedrocchi, Emilia Ambrosini, Manuel Murie-Fernandez, Carmen B. Roman, Jesus Tornero, Natacha Leon, Andrew Sawers, Jim Patton, Domenico Formica, Nevio Luigi Tagliamonte, Georg Rauter, Kilian Baur, Fabian Just, Christopher J. Hasson, Vesna D. Novak, Jose L. Pons</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Neurorehabilitation conventionally relies on the interaction between a patient and a physical therapist. Robotic systems can improve and enrich the physical feedback provided to patients after neurological injury, but they under-utilize the adaptability and clinical expertise of trained therapists. In this position paper, we advocate for a novel approach that integrates the therapists clinical expertise and nuanced decision-making with the strength, accuracy, and repeatability of robotics: Robot-mediated physical Human-Human Interaction. This framework, which enables two individuals to physically interact through robotic devices, has been studied across diverse research groups and has recently emerged as a promising link between conventional manual therapy and rehabilitation robotics, harmonizing the strengths of both approaches. This paper presents the rationale of a multidisciplinary team-including engineers, doctors, and physical therapists-for conducting research that utilizes: a unified taxonomy to describe robot-mediated rehabilitation, a framework of interaction based on social psychology, and a technological approach that makes robotic systems seamless facilitators of natural human-human interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17543v1" target="_blank">Anticipate, Simulate, Reason (ASR): A Comprehensive Generative AI Framework for Combating Messaging Scams</a></h3>
                    <p><strong>Authors:</strong> Xue Wen Tan, Kenneth See, Stanley Kok</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> The rapid growth of messaging scams creates an escalating challenge for user security and financial safety. In this paper, we present the Anticipate, Simulate, Reason (ASR) framework, a generative AI method that enables users to proactively identify and comprehend scams within instant messaging platforms. Using large language models, ASR predicts scammer responses, creates realistic scam conversations, and delivers real-time, interpretable support to end-users. We develop ScamGPT-J, a domain-specific language model fine-tuned on a new, high-quality dataset of scam conversations covering multiple scam types. Thorough experimental evaluation shows that the ASR framework substantially enhances scam detection, particularly in challenging contexts such as job scams, and uncovers important demographic patterns in user vulnerability and perceptions of AI-generated assistance. Our findings reveal a contradiction where those most at risk are often least receptive to AI support, emphasizing the importance of user-centered design in AI-driven fraud prevention. This work advances both the practical and theoretical foundations for interpretable, human-centered AI systems in combating evolving digital threats.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17539v1" target="_blank">Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning</a></h3>
                    <p><strong>Authors:</strong> Xinyao Liu, Diping Song</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> Multimodal large language models (MLLMs) demonstrate significant potential in the field of medical diagnosis. However, they face critical challenges in specialized domains such as ophthalmology, particularly the fragmentation of annotation granularity and inconsistencies in clinical reasoning logic, which hinder precise cross-modal understanding. This paper introduces FundusExpert, an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning capabilities, along with FundusGen, a dataset constructed through the intelligent Fundus-Engine system. Fundus-Engine automates localization and leverages MLLM-based semantic expansion to integrate global disease classification, local object detection, and fine-grained feature analysis within a single fundus image. Additionally, by constructing a clinically aligned cognitive chain, it guides the model to generate interpretable reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen, achieves the best performance in ophthalmic question-answering tasks, surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in zero-shot report generation tasks, achieving a clinical consistency of 77.0%, significantly outperforming GPT-4os 47.6%. Furthermore, we reveal a scaling law between data quality and model capability ($L \propto N^{0.068}$), demonstrating that the cognitive alignment annotations in FundusGen enhance data utilization efficiency. By integrating region-level localization with diagnostic reasoning chains, our work develops a scalable, clinically-aligned MLLM and explores a pathway toward bridging the visual-language gap in specific MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17533v1" target="_blank">Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding</a></h3>
                    <p><strong>Authors:</strong> Liwen Liu, Weidong Yang, Lipeng Ma, Ben Fei</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent advances in multi-modal pre-training methods have shown promising effectiveness in learning 3D representations by aligning multi-modal features between 3D shapes and their corresponding 2D counterparts. However, existing multi-modal pre-training frameworks primarily rely on a single pre-training task to gather multi-modal data in 3D applications. This limitation prevents the models from obtaining the abundant information provided by other relevant tasks, which can hinder their performance in downstream tasks, particularly in complex and diverse domains. In order to tackle this issue, we propose MMPT, a Multi-modal Multi-task Pre-training framework designed to enhance point cloud understanding. Specifically, three pre-training tasks are devised: (i) Token-level reconstruction (TLR) aims to recover masked point tokens, endowing the model with representative learning abilities. (ii) Point-level reconstruction (PLR) is integrated to predict the masked point positions directly, and the reconstructed point cloud can be considered as a transformed point cloud used in the subsequent task. (iii) Multi-modal contrastive learning (MCL) combines feature correspondences within and across modalities, thus assembling a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised manner. Moreover, this framework operates without requiring any 3D annotations, making it scalable for use with large datasets. The trained encoder can be effectively transferred to various downstream tasks. To demonstrate its effectiveness, we evaluated its performance compared to state-of-the-art methods in various discriminant and generative applications under widely-used benchmarks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17531v1" target="_blank">When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment</a></h3>
                    <p><strong>Authors:</strong> Abdel-Raouf Dannaoui, Johann Laconte, Christophe Debain, Francois Pomerleau, Paul Checchin</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Robust relocalization in dynamic outdoor environments remains a key challenge for autonomous systems relying on 3D lidar. While long-term localization has been widely studied, short-term environmental changes, occurring over days or weeks, remain underexplored despite their practical significance. To address this gap, we present a highresolution, short-term multi-temporal dataset collected weekly from February to April 2025 across natural and semi-urban settings. Each session includes high-density point cloud maps, 360 deg panoramic images, and trajectory data. Projected lidar scans, derived from the point cloud maps and modeled with sensor-accurate occlusions, are used to evaluate alignment accuracy against the ground truth using two Iterative Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show that Point-to-Plane offers significantly more stable and accurate registration, particularly in areas with sparse features or dense vegetation. This study provides a structured dataset for evaluating short-term localization robustness, a reproducible framework for analyzing scan-to-map alignment under noise, and a comparative evaluation of ICP performance in evolving outdoor environments. Our analysis underscores how local geometry and environmental variability affect localization success, offering insights for designing more resilient robotic systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17526v1" target="_blank">Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling</a></h3>
                    <p><strong>Authors:</strong> Leandro Von Krannichfeldt, Kristina Orehounig, Olga Fink</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.AI, cs.LG, cs.SY</p>
                    <p><strong>Summary:</strong> Building energy modeling is a key tool for optimizing the performance of building energy systems. Historically, a wide spectrum of methods has been explored -- ranging from conventional physics-based models to purely data-driven techniques. Recently, hybrid approaches that combine the strengths of both paradigms have gained attention. These include strategies such as learning surrogates for physics-based models, modeling residuals between simulated and observed data, fine-tuning surrogates with real-world measurements, using physics-based outputs as additional inputs for data-driven models, and integrating the physics-based output into the loss function the data-driven model. Despite this progress, two significant research gaps remain. First, most hybrid methods focus on deterministic modeling, often neglecting the inherent uncertainties caused by factors like weather fluctuations and occupant behavior. Second, there has been little systematic comparison within a probabilistic modeling framework. This study addresses these gaps by evaluating five representative hybrid approaches for probabilistic building energy modeling, focusing on quantile predictions of building thermodynamics in a real-world case study. Our results highlight two main findings. First, the performance of hybrid approaches varies across different building room types, but residual learning with a Feedforward Neural Network performs best on average. Notably, the residual approach is the only model that produces physically intuitive predictions when applied to out-of-distribution test data. Second, Quantile Conformal Prediction is an effective procedure for calibrating quantile predictions in case of indoor temperature modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17524v1" target="_blank">SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition</a></h3>
                    <p><strong>Authors:</strong> Jiahao Tang, Youjun Li, Xiangting Fan, Yangxuan Zheng, Siyuan Lu, Xueping Li, Peng Fang, Chenxi Li, Zi-Gang Huang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Electroencephalography(EEG) based emotion recognition holds great promise for affective brain-computer interfaces (aBCIs), yet practical deployment remains challenging due to substantial inter-subject variability and the lack of labeled data in target domains. To overcome these limitations, we present a novel unsupervised Semantic-Dynamic Consistency domain adaptation network for fully label-free cross-subject EEG emotion recognition. First, we introduce a Same-Subject Same-Trial Mixup strategy that generates augmented samples via intra-trial interpolation, enhancing data diversity while explicitly preserving individual identity to mitigate label ambiguity. Second, we construct a dynamic distribution alignment module in reproducing kernel Hilbert space (RKHS), jointly aligning marginal and conditional distributions through multi-objective kernel mean embedding, and leveraging a confidence-aware pseudo-labeling strategy to ensure stable adaptation. Third, we propose a dual-domain similarity consistency learning mechanism that enforces cross-domain structural constraints based on latent pairwise similarities, enabling semantic boundary learning without relying on temporal synchronization or label priors. To validate the effectiveness and robustness of the proposed SDC-Net, extensive experiments are conducted on three widely used EEG benchmark datasets: SEED, SEED-IV, and Faced. Comparative results against existing unsupervised domain adaptation methods demonstrate that SDC-Net achieves state-of-the-art performance in emotion recognition under both cross-subject and cross-session conditions. This advancement significantly improves the accuracy and generalization capability of emotion decoding, and lays a solid foundation for real-world applications of personalized affective brain-computer interfaces (aBCIs). The source code will be released at https://github.com/XuanSuTrum/SDC-Net.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17523v1" target="_blank">One year of ASPEX-SWIS operation -- Characteristic features, observations and science potential</a></h3>
                    <p><strong>Authors:</strong> Abhishek Kumar, Shivam Parashar, Prashant Kumar, Dibyendu Chakrabarty, Bhas Bapat, Aveek Sarkar, Manan S. Shah, Hiteshkumar L. Adalja, Arpit R. Patel, Pranav R. Adhyaru, M. Shanmugam, Swaroop B. Banerjee, K. P. Subramaniam, Tinkal Ladiya, Jacob Sebastian, Bijoy Dalal, Aakash Gupta, M. B. Dadhania, Santosh V. Vadawale, Shiv Kumar Goyal, Neeraj Kumar Tiwari, Aaditya Sarda, Sushil Kumar, Nishant Singh, Deepak Kumar Painkra, Piyush Sharma, Abhishek J. Verma, P. Janardhan, Anil Bhardwaj</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> astro-ph.SR, physics.space-ph</p>
                    <p><strong>Summary:</strong> The Aditya-L1 mission, Indias first dedicated solar observatory positioned at the first Lagrange point (L1) of the Sun-Earth system, carries the Solar Wind Ion Spectrometer (SWIS) as part of the ASPEX payload suite. Even before settling into its Halo orbit, SWIS has been providing nearly continuous in-situ measurements of solar wind ion spectra. Moments of the velocity distribution functions (VDFs) have been calculated to derive key solar wind parameters such as density, bulk speed, and temperature. In this study, we assess the performance of SWIS (hereafter referred to as AL1-ASPEX-SWIS) by comparing its measurements with contemporaneous data from the Wind and DSCOVR missions. In this study, we assess the performance of SWIS (hereafter referred to as AL1-ASPEX-SWIS) by comparing its measurements with contemporaneous data from the Wind and DSCOVR missions. A detailed case study of the interplanetary coronal mass ejection (ICME) event on August 7, 2024, is presented, where sharp changes in bulk speed, thermal speed, and number density were found to be well-aligned with independent observations-confirming the instruments ability to capture dynamic solar wind features. Spectral analysis of kinetic fluctuations revealed a well-defined inertial range with a spectral slope consistent with magnetohydrodynamic (MHD) turbulence. Furthermore, a 17-month statistical comparison (from January 2024 to May 2025) shows a strong correlation in bulk velocity (R2 = 0.94 with Wind), with expected variations in thermal speed and density arising from differences between instruments. These findings demonstrate the scientific value of AL1-ASPEX-SWIS for monitoring both transient solar events and long-term solar wind conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17522v1" target="_blank">STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds</a></h3>
                    <p><strong>Authors:</strong> Tian Guo, Hui Yuan, Xiaolong Mao, Shiqi Jiang, Raouf Hamzaoui, Sam Kwong</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> Very few studies have addressed quality enhancement for compressed dynamic point clouds. In particular, the effective exploitation of spatial-temporal correlations between point cloud frames remains largely unexplored. Addressing this gap, we propose a spatial-temporal attribute quality enhancement (STQE) network that exploits both spatial and temporal correlations to improve the visual quality of G-PCC compressed dynamic point clouds. Our contributions include a recoloring-based motion compensation module that remaps reference attribute information to the current frame geometry to achieve precise inter-frame geometric alignment, a channel-aware temporal attention module that dynamically highlights relevant regions across bidirectional reference frames, a Gaussian-guided neighborhood feature aggregation module that efficiently captures spatial dependencies between geometry and color attributes, and a joint loss function based on the Pearson correlation coefficient, designed to alleviate over-smoothing effects typical of point-wise mean squared error optimization. When applied to the latest G-PCC test model, STQE achieved improvements of 0.855 dB, 0.682 dB, and 0.828 dB in delta PSNR, with Bj{\o}ntegaard Delta rate (BD-rate) reductions of -25.2%, -31.6%, and -32.5% for the Luma, Cb, and Cr components, respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17521v1" target="_blank">Single-photon loading of polar molecules into an optical trap</a></h3>
                    <p><strong>Authors:</strong> Bart J. Schellenberg, Eifion H. Prinsen, Janko Nauta, LukÃ¡Å¡ F. PaÅ¡teka, Anastasia Borschevsky, Steven Hoekstra</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph</p>
                    <p><strong>Summary:</strong> We propose a scheme to transfer molecules from a slow beam into an optical trap using only a single photon absorption and emission cycle. The efficiency of such a scheme is numerically explored for BaF using realistic experimental parameters. The technique makes use of the state-dependent potential in an external electric field to trap molecules from an initial velocity of order 10m/s. A rapid optical transition at the point where the molecules come to a standstill in the electric field potential irreversibly transfers them into a ~7mK optical dipole trap. For a pulsed Stark decelerated beam, we estimated the per-shot efficiency to be ~0.04% or up to ~103 molecules, with a potential factor 20 improvement when the fields are synchronously modulated with the arriving velocity components. The irreversibility of the scheme allows for larger numbers to be built up over time. Since this scheme does not rely on a closed cycling transition for laser cooling, it broadens the range of molecules that can be used for research on cold molecular chemistry, quantum information, and fundamental interactions in optical traps.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17519v1" target="_blank">Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners</a></h3>
                    <p><strong>Authors:</strong> Kostas Karakontis, Thanos Petsanis, Athanasios Ch. Kapoutsis, Pavlos Ch. Kapoutsis, Elias B. Kosmatopoulos</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial software typically treat a Region of Interest (RoI) only as a 2D plane, ignoring important3D structure characteristics. This leads to incomplete 3Dreconstructions, especially around occluded or vertical surfaces. In this paper, we propose a modular algorithm that can extend commercial two-dimensional path planners to facilitate terrain-aware planning by adjusting altitude and camera orientations. To demonstrate it, we extend the well-known DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm and produce DARP-3D. We present simulation results in multiple 3D environments and a real-world flight test using DJI hardware. Compared to baseline, our approach consistently captures improved 3D reconstructions, particularly in areas with significant vertical features. An open-source implementation of the algorithm is available here:https://github.com/konskara/TerraPlan</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17518v1" target="_blank">Enabling Cyber Security Education through Digital Twins and Generative AI</a></h3>
                    <p><strong>Authors:</strong> Vita Santa Barletta, Vito Bavaro, Miriana Calvano, Antonio Curci, Antonio Piccinno, Davide Pio Posa</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, cs.CY, cs.HC, cs.SE</p>
                    <p><strong>Summary:</strong> Digital Twins (DTs) are gaining prominence in cybersecurity for their ability to replicate complex IT (Information Technology), OT (Operational Technology), and IoT (Internet of Things) infrastructures, allowing for real time monitoring, threat analysis, and system simulation. This study investigates how integrating DTs with penetration testing tools and Large Language Models (LLMs) can enhance cybersecurity education and operational readiness. By simulating realistic cyber environments, this approach offers a practical, interactive framework for exploring vulnerabilities and defensive strategies. At the core of this research is the Red Team Knife (RTK), a custom penetration testing toolkit aligned with the Cyber Kill Chain model. RTK is designed to guide learners through key phases of cyberattacks, including reconnaissance, exploitation, and response within a DT powered ecosystem. The incorporation of Large Language Models (LLMs) further enriches the experience by providing intelligent, real-time feedback, natural language threat explanations, and adaptive learning support during training exercises. This combined DT LLM framework is currently being piloted in academic settings to develop hands on skills in vulnerability assessment, threat detection, and security operations. Initial findings suggest that the integration significantly improves the effectiveness and relevance of cybersecurity training, bridging the gap between theoretical knowledge and real-world application. Ultimately, the research demonstrates how DTs and LLMs together can transform cybersecurity education to meet evolving industry demands.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17515v1" target="_blank">URPO: A Unified Reward  Policy Optimization Framework for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Songshuo Lu, Hua Wang, Zhi Chen, Yaohua Tang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL</p>
                    <p><strong>Summary:</strong> Large-scale alignment pipelines typically pair a policy model with a separately trained reward model whose parameters remain frozen during reinforcement learning (RL). This separation creates a complex, resource-intensive pipeline and suffers from a performance ceiling due to a static reward signal. We propose a novel framework, Unified Reward  Policy Optimization (URPO), that unifies instruction-following (player) and reward modeling (referee) within a single model and a single training phase. Our method recasts all alignment data-including preference pairs, verifiable reasoning, and open-ended instructions-into a unified generative format optimized by a single Group-Relative Policy Optimization (GRPO) loop. This enables the model to learn from ground-truth preferences and verifiable logic while simultaneously generating its own rewards for open-ended tasks. Experiments on the Qwen2.5-7B model demonstrate URPOs superiority. Our unified model significantly outperforms a strong baseline using a separate generative reward model, boosting the instruction-following score on AlpacaEval from 42.24 to 44.84 and the composite reasoning average from 32.66 to 35.66. Furthermore, URPO cultivates a superior internal evaluator as a byproduct of training, achieving a RewardBench score of 85.15 and surpassing the dedicated reward model it replaces (83.55). By eliminating the need for a separate reward model and fostering a co-evolutionary dynamic between generation and evaluation, URPO presents a simpler, more efficient, and more effective path towards robustly aligned language models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17514v1" target="_blank">TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment</a></h3>
                    <p><strong>Authors:</strong> Athanasios Davvetas, Xenia Ziouvelou, Ypatia Dami, Alexis Kaponis, Konstantina Giouvanopoulou, Michael Papademas</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool with minimalistic input. The current version of the tool supports the legal TAI assessment, with a particular emphasis on facilitating compliance with the AI Act. It involves a two-step approach with a pre-screening and an assessment phase. The assessment output of the system includes insight regarding the risk-level of the AI system according to the AI Act, while at the same time retrieving relevant articles to aid with compliance and notify on their obligations. Our qualitative evaluation using use-case scenarios yields promising results, correctly predicting risk levels while retrieving relevant articles across three distinct semantic groups. Furthermore, interpretation of results shows that the tools reasoning relies on comparison with the setting of high-risk systems, a behaviour attributed to their deployment requiring careful consideration, and therefore frequently presented within the AI Act.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17512v1" target="_blank">Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Yu Li, Zhuoshi Pan, Honglin Lin, Mengyuan Sun, Conghui He, Lijun Wu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing research has predominantly concentrated on isolated reasoning domains such as mathematical problem-solving, coding tasks, or logical reasoning. However, real world reasoning scenarios inherently demand an integrated application of multiple cognitive skills. Despite this, the interplay among these reasoning skills under reinforcement learning remains poorly understood. To bridge this gap, we present a systematic investigation of multi-domain reasoning within the RLVR framework, explicitly focusing on three primary domains: mathematical reasoning, code generation, and logical puzzle solving. We conduct a comprehensive study comprising four key components: (1) Leveraging the GRPO algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the models in-domain improvements and cross-domain generalization capabilities when trained on single-domain datasets. (2) Additionally, we examine the intricate interactions including mutual enhancements and conflicts that emerge during combined cross-domain training. (3) To further understand the influence of SFT on RL, we also analyze and compare performance differences between base and instruct models under identical RL configurations. (4) Furthermore, we delve into critical RL training details, systematically exploring the impacts of curriculum learning strategies, variations in reward design, and language-specific factors. Through extensive experiments, our results offer significant insights into the dynamics governing domain interactions, revealing key factors influencing both specialized and generalizable reasoning performance. These findings provide valuable guidance for optimizing RL methodologies to foster comprehensive, multi-domain reasoning capabilities in LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17508v1" target="_blank">Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation</a></h3>
                    <p><strong>Authors:</strong> Jorgen Cani, Christos Diou, Spyridon Evangelatos, Vasileios Argyriou, Panagiotis Radoglou-Grammatikis, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Automated X-ray inspection is crucial for efficient and unobtrusive security screening in various public settings. However, challenges such as object occlusion, variations in the physical properties of items, diversity in X-ray scanning devices, and limited training data hinder accurate and reliable detection of illicit items. Despite the large body of research in the field, reported experimental evaluations are often incomplete, with frequently conflicting outcomes. To shed light on the research landscape and facilitate further research, a systematic, detailed, and thorough comparative evaluation of recent Deep Learning (DL)-based methods for X-ray object detection is conducted. For this, a comprehensive evaluation framework is developed, composed of: a) Six recent, large-scale, and widely used public datasets for X-ray illicit item detection (OPIXray, CLCXray, SIXray, EDS, HiXray, and PIDray), b) Ten different state-of-the-art object detection schemes covering all main categories in the literature, including generic Convolutional Neural Network (CNN), custom CNN, generic transformer, and hybrid CNN-transformer architectures, and c) Various detection (mAP50 and mAP50:95) and time/computational-complexity (inference time (ms), parameter size (M), and computational load (GFLOPS)) metrics. A thorough analysis of the results leads to critical observations and insights, emphasizing key aspects such as: a) Overall behavior of the object detection schemes, b) Object-level detection performance, c) Dataset-specific observations, and d) Time efficiency and computational complexity analysis. To support reproducibility of the reported experimental results, the evaluation code and model weights are made publicly available at https://github.com/jgenc/xray-comparative-evaluation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17507v1" target="_blank">Unfolding Data Quality Dimensions in Practice: A Survey</a></h3>
                    <p><strong>Authors:</strong> Vasileios Papastergios, Lisa Ehrlinger, Anastasios Gounaris</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.DB</p>
                    <p><strong>Summary:</strong> Data quality describes the degree to which data meet specific requirements and are fit for use by humans and/or downstream tasks (e.g., artificial intelligence). Data quality can be assessed across multiple high-level concepts called dimensions, such as accuracy, completeness, consistency, or timeliness. While extensive research and several attempts for standardization (e.g., ISO/IEC 25012) exist for data quality dimensions, their practical application often remains unclear. In parallel to research endeavors, a large number of tools have been developed that implement functionalities for the detection and mitigation of specific data quality issues, such as missing values or outliers. With this paper, we aim to bridge this gap between data quality theory and practice by systematically connecting low-level functionalities offered by data quality tools with high-level dimensions, revealing their many-to-many relationships. Through an examination of seven open-source data quality tools, we provide a comprehensive mapping between their functionalities and the data quality dimensions, demonstrating how individual functionalities and their variants partially contribute to the assessment of single dimensions. This systematic survey provides both practitioners and researchers with a unified view on the fragmented landscape of data quality checks, offering actionable insights for quality assessment across multiple dimensions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17489v1" target="_blank">DFDNet: Dynamic Frequency-Guided De-Flare Network</a></h3>
                    <p><strong>Authors:</strong> Minglong Xue, Aoxiang Ning, Shivakumara Palaiahnakote, Mingliang Zhou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, eess.IV</p>
                    <p><strong>Summary:</strong> Strong light sources in nighttime photography frequently produce flares in images, significantly degrading visual quality and impacting the performance of downstream tasks. While some progress has been made, existing methods continue to struggle with removing large-scale flare artifacts and repairing structural damage in regions near the light source. We observe that these challenging flare artifacts exhibit more significant discrepancies from the reference images in the frequency domain compared to the spatial domain. Therefore, this paper presents a novel dynamic frequency-guided deflare network (DFDNet) that decouples content information from flare artifacts in the frequency domain, effectively removing large-scale flare artifacts. Specifically, DFDNet consists mainly of a global dynamic frequency-domain guidance (GDFG) module and a local detail guidance module (LDGM). The GDFG module guides the network to perceive the frequency characteristics of flare artifacts by dynamically optimizing global frequency domain features, effectively separating flare information from content information. Additionally, we design an LDGM via a contrastive learning strategy that aligns the local features of the light source with the reference image, reduces local detail damage from flare removal, and improves fine-grained image restoration. The experimental results demonstrate that the proposed method outperforms existing state-of-the-art methods in terms of performance. The code is available at \href{https://github.com/AXNing/DFDNet}{https://github.com/AXNing/DFDNet}.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17482v1" target="_blank">LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning</a></h3>
                    <p><strong>Authors:</strong> Luca Salvatore Lorello, Nikolaos Manginas, Marco Lippi, Stefano Melacci</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Neuro-symbolic artificial intelligence aims to combine neural architectures with symbolic approaches that can represent knowledge in a human-interpretable formalism. Continual learning concerns with agents that expand their knowledge over time, improving their skills while avoiding to forget previously learned concepts. Most of the existing approaches for neuro-symbolic artificial intelligence are applied to static scenarios only, and the challenging setting where reasoning along the temporal dimension is necessary has been seldom explored. In this work we introduce LTLZinc, a benchmarking framework that can be used to generate datasets covering a variety of different problems, against which neuro-symbolic and continual learning methods can be evaluated along the temporal and constraint-driven dimensions. Our framework generates expressive temporal reasoning and continual learning tasks from a linear temporal logic specification over MiniZinc constraints, and arbitrary image classification datasets. Fine-grained annotations allow multiple neural and neuro-symbolic training settings on the same generated datasets. Experiments on six neuro-symbolic sequence classification and four class-continual learning tasks generated by LTLZinc, demonstrate the challenging nature of temporal learning and reasoning, and highlight limitations of current state-of-the-art methods. We release the LTLZinc generator and ten ready-to-use tasks to the neuro-symbolic and continual learning communities, in the hope of fostering research towards unified temporal learning and reasoning frameworks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17481v1" target="_blank">AI in Design Education at College Level-Educators Perspectives and Challenges</a></h3>
                    <p><strong>Authors:</strong> Lizhu Zhang, Cecilia X. Wang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.HC</p>
                    <p><strong>Summary:</strong> Artificial intelligence has deeply permeated numerous fields, especially the design area which relies on technology as a tool for innovation. This change naturally extends to the field of design education, which is closest to design practice. This has led to further exploration of the impact of AI on college-level education in the design discipline. This study aims to examine how current design educators perceive the role of AI in college-level design education, their perspectives on integrating AI into teaching and research, and their concerns regarding its potential challenges in design education and research. Through qualitative, semi-structured, in-depth interviews with seven faculties in U.S. design colleges, the findings reveal that AI, as a tool and source of information, has become an integral part of design education. AI- derived functionalities are increasingly utilized in design software, and educators are actively incorporating AI as a theoretical framework in their teaching. Educators can guide students in using AI tools, but only if they first acquire a strong foundation in basic design principles and skills. This study also indicates the importance of promoting a cooperative relationship between design educators and AI. At the same time, educators express anticipation for advancements in ethical standards, authenticity, and the resolution of copyright issues related to AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17477v1" target="_blank">An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Haoran Sun, Zekun Zhang, Shaoning Zeng</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have demonstrated remarkable progress in instruction following and general-purpose reasoning. However, achieving high-quality alignment with human intent and safety norms without human annotations remains a fundamental challenge. In this work, we propose an Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to improve LLM alignment in a fully automated manner. UDASA first generates multiple responses for each input and quantifies output uncertainty across three dimensions: semantics, factuality, and value alignment. Based on these uncertainty scores, the framework constructs preference pairs and categorizes training samples into three stages, conservative, moderate, and exploratory, according to their uncertainty difference. The model is then optimized progressively across these stages. In addition, we conduct a series of preliminary studies to validate the core design assumptions and provide strong empirical motivation for the proposed framework. Experimental results show that UDASA outperforms existing alignment methods across multiple tasks, including harmlessness, helpfulness, truthfulness, and controlled sentiment generation, significantly improving model performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17752v1" target="_blank">Direct correlation of line intensity mapping and CMB lensing from lightcone evolution</a></h3>
                    <p><strong>Authors:</strong> Delon Shen, Nickolas Kokron, Emmanuel Schaan</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, astro-ph.GA</p>
                    <p><strong>Summary:</strong> Line intensity mapping (LIM) promises to probe previously inaccessible corners of the faint and high-redshift universe. However, confusion with bright foregrounds is a major challenge for current-era pathfinder LIM experiments. Cross-correlation with cosmic microwave background (CMB) lensing is a promising avenue to enable the first LIM detections at high redshifts, a pristine probe of fundamental physics but sparsely populated by faint galaxies, and to further probe the connection between matter and spectral line emission, expanding our understanding of galaxies and the IGM. Previous works have suggested that this direct correlation between LIM and CMB lensing is effectively impossible because smoothly varying modes in the intensity map are lost to bright foregrounds. In this work, we analytically revisit the direct correlation of foreground-filtered line intensity mapping with CMB lensing, highlighting lightcone evolutions previously neglected yet unavoidable and crucial effects. Indeed, the growth of structure and evolution of line emission along the lightcone breaks statistical translational invariance and thus induces mode coupling, even in linear theory, which enables the recovery of the smoothly varying modes lost to bright foregrounds. We compute the effects of these lightcone evolution-induced mode couplings on the LIMxCMB lensing cross-spectrum detectability, predicting that future wider-sky versions of COMAP, CCAT, and HETDEX will be able to precisely measure this cross-correlation. Although we focus on the direct correlation of LIM with CMB lensing in this paper, our arguments generalize to the direct correlation of LIM with any projected field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17748v1" target="_blank">Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility</a></h3>
                    <p><strong>Authors:</strong> Melih Barsbey, Lucas Prieto, Stefanos Zafeiriou, Tolga Birdal</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV, stat.ML</p>
                    <p><strong>Summary:</strong> Robustness and resource-efficiency are two highly desirable properties for modern machine learning models. However, achieving them jointly remains a challenge. In this paper, we position high learning rates as a facilitator for simultaneously achieving robustness to spurious correlations and network compressibility. We demonstrate that large learning rates also produce desirable representation properties such as invariant feature utilization, class separation, and activation sparsity. Importantly, our findings indicate that large learning rates compare favorably to other hyperparameters and regularization methods, in consistently satisfying these properties in tandem. In addition to demonstrating the positive effect of large learning rates across diverse spurious correlation datasets, models, and optimizers, we also present strong evidence that the previously documented success of large learning rates in standard classification tasks is likely due to its effect on addressing hidden/rare spurious correlations in the training dataset.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17747v1" target="_blank">Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks</a></h3>
                    <p><strong>Authors:</strong> Linbo Cao, Jinman Zhao</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> As frontier language models increasingly saturate standard QA benchmarks, concerns about data contamination, memorization, and escalating dataset creation costs persist. We propose a debate-driven evaluation paradigm that transforms any existing QA dataset into structured adversarial debates--where one model is given the official answer to defend, and another constructs and defends an alternative answer--adjudicated by a judge model blind to the correct solution. By forcing multi-round argumentation, this approach substantially increases difficulty while penalizing shallow memorization, yet reuses QA items to reduce curation overhead. We make two main contributions: (1) an evaluation pipeline to systematically convert QA tasks into debate-based assessments, and (2) a public benchmark that demonstrates our paradigms effectiveness on a subset of MMLU-Pro questions, complete with standardized protocols and reference models. Empirical results validate the robustness of the method and its effectiveness against data contamination--a Llama 3.1 model fine-tuned on test questions showed dramatic accuracy improvements (50% - 82%) but performed worse in debates. Results also show that even weaker judges can reliably differentiate stronger debaters, highlighting how debate-based evaluation can scale to future, more capable systems while maintaining a fraction of the cost of creating new benchmarks. Overall, our framework underscores that pretraining on the test set is no longer all you need, offering a sustainable path for measuring the genuine reasoning ability of advanced language models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17746v1" target="_blank">Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains</a></h3>
                    <p><strong>Authors:</strong> Anisha Gunjal, Anthony Wang, Elaine Lau, Vaskar Nath, Bing Liu, Sean Hendryx</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world tasks often requires balancing objective and subjective evaluation criteria. However, many such tasks lack a single, unambiguous ground truth-making it difficult to define reliable reward signals for post-training language models. While traditional preference-based methods offer a workaround, they rely on opaque reward functions that are difficult to interpret and prone to spurious correlations. We introduce $\textbf{Rubrics as Rewards}$ (RaR), a framework that uses structured, checklist-style rubrics as interpretable reward signals for on-policy training with GRPO. Our best RaR method yields up to a $28\%$ relative improvement on HealthBench-1k compared to simple Likert-based approaches, while matching or surpassing the performance of reward signals derived from expert-written references. By treating rubrics as structured reward signals, we show that RaR enables smaller-scale judge models to better align with human preferences and sustain robust performance across model scales.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17745v1" target="_blank">Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention</a></h3>
                    <p><strong>Authors:</strong> Yiwen Chen, Zhihao Li, Yikai Wang, Hu Zhang, Qin Li, Chi Zhang, Guosheng Lin</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in sparse voxel representations have significantly improved the quality of 3D content generation, enabling high-resolution modeling with fine-grained geometry. However, existing frameworks suffer from severe computational inefficiencies due to the quadratic complexity of attention mechanisms in their two-stage diffusion pipelines. In this work, we propose Ultra3D, an efficient 3D generation framework that significantly accelerates sparse voxel modeling without compromising quality. Our method leverages the compact VecSet representation to efficiently generate a coarse object layout in the first stage, reducing token count and accelerating voxel coordinate prediction. To refine per-voxel latent features in the second stage, we introduce Part Attention, a geometry-aware localized attention mechanism that restricts attention computation within semantically consistent part regions. This design preserves structural continuity while avoiding unnecessary global attention, achieving up to 6.7x speed-up in latent generation. To support this mechanism, we construct a scalable part annotation pipeline that converts raw meshes into part-labeled sparse voxels. Extensive experiments demonstrate that Ultra3D supports high-resolution 3D generation at 1024 resolution and achieves state-of-the-art performance in both visual fidelity and user preference.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17744v1" target="_blank">Yume: An Interactive World Generation Model</a></h3>
                    <p><strong>Authors:</strong> Xiaofeng Mao, Shaoheng Lin, Zhen Li, Chuanhao Li, Wenshuo Peng, Tong He, Jiangmiao Pang, Mingmin Chi, Yu Qiao, Kaipeng Zhang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Yume aims to use images, text, or videos to create an interactive, realistic, and dynamic world, which allows exploration and control using peripheral devices or neural signals. In this report, we present a preview version of \method, which creates a dynamic world from an input image and allows exploration of the world using keyboard actions. To achieve this high-fidelity and interactive video world generation, we introduce a well-designed framework, which consists of four main components, including camera motion quantization, video generation architecture, advanced sampler, and model acceleration. First, we quantize camera motions for stable training and user-friendly interaction using keyboard inputs. Then, we introduce the Masked Video Diffusion Transformer~(MVDT) with a memory module for infinite video generation in an autoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM) and Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE) are introduced to the sampler for better visual quality and more precise control. Moreover, we investigate model acceleration by synergistic optimization of adversarial distillation and caching mechanisms. We use the high-quality world exploration dataset \sekai to train \method, and it achieves remarkable results in diverse scenes and applications. All data, codebase, and model weights are available on https://github.com/stdstu12/YUME. Yume will update monthly to achieve its original goal. Project page: https://stdstu12.github.io/YUME-Project/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17743v1" target="_blank">Educational Insights from Code: Mapping Learning Challenges in Object-Oriented Programming through Code-Based Evidence</a></h3>
                    <p><strong>Authors:</strong> Andre Menolli, Bruno Strik</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Object-Oriented programming is frequently challenging for undergraduate Computer Science students, particularly in understanding abstract concepts such as encapsulation, inheritance, and polymorphism. Although the literature outlines various methods to identify potential design and coding issues in object-oriented programming through source code analysis, such as code smells and SOLID principles, few studies explore how these code-level issues relate to learning difficulties in Object-Oriented Programming. In this study, we explore the relationship of the code issue indicators with common challenges encountered during the learning of object-oriented programming. Using qualitative analysis, we identified the main categories of learning difficulties and, through a literature review, established connections between these difficulties, code smells, and violations of the SOLID principles. As a result, we developed a conceptual map that links code-related issues to specific learning challenges in Object-Oriented Programming. The model was then evaluated by an expert who applied it in the analysis of the student code to assess its relevance and applicability in educational contexts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17740v1" target="_blank">Quantum stroboscopy for time measurements</a></h3>
                    <p><strong>Authors:</strong> Seth Lloyd, Lorenzo Maccone, Lionel Martellini, Simone Roncallo</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Mielniks cannonball argument uses the Zeno effect to argue that projective measurements for time of arrival are impossible. If one repeatedly measures the position of a particle (or a cannonball!) that has yet to arrive at a detector, the Zeno effect will repeatedly collapse its wavefunction away from it: the particle never arrives. Here we introduce quantum stroboscopic measurements where we accumulate statistics of projective position measurements, performed on different copies of the system at different times, to obtain a time-of-arrival distribution. We show that, under appropriate limits, this gives the same statistics as time measurements of conventional ``always on particle detectors, that bypass Mielniks argument using non-projective, weak continuous measurements. In addition to time of arrival, quantum stroboscopy can describe distributions of general time measurements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17732v1" target="_blank">The Nonlinear Tails in Black Hole Ringdown: the Scattering Perspective</a></h3>
                    <p><strong>Authors:</strong> A. Ianniccari, L. Lo Bianco, A. Riotto</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> Black holes regain their static configuration by emitting ringdown gravitational waves, whose amplitude decays in time following a power law at fixed spatial positions. We show that the nonlinear decay power law may be obtained by simple scattering calculations using the in-in formalism and argue that the nonperturbative law should be $t^{-2\ell-1}$, where $\ell$ is the multipole of the propagating spherical gravitational wave.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17729v1" target="_blank">A Comprehensive Evaluation Framework for the Study of the Effects of Facial Filters on Face Recognition Accuracy</a></h3>
                    <p><strong>Authors:</strong> Kagan Ozturk, Louisa Conwill, Jacob Gutierrez, Kevin Bowyer, Walter J. Scheirer</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Facial filters are now commonplace for social media users around the world. Previous work has demonstrated that facial filters can negatively impact automated face recognition performance. However, these studies focus on small numbers of hand-picked filters in particular styles. In order to more effectively incorporate the wide ranges of filters present on various social media applications, we introduce a framework that allows for larger-scale study of the impact of facial filters on automated recognition. This framework includes a controlled dataset of face images, a principled filter selection process that selects a representative range of filters for experimentation, and a set of experiments to evaluate the filters impact on recognition. We demonstrate our framework with a case study of filters from the American applications Instagram and Snapchat and the Chinese applications Meitu and Pitu to uncover cross-cultural differences. Finally, we show how the filtering effect in a face embedding space can easily be detected and restored to improve face recognition performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17728v1" target="_blank">Megrez2 Technical Report</a></h3>
                    <p><strong>Authors:</strong> Boxun Li, Yadong Li, Zhiyuan Li, Congyi Liu, Weilin Liu, Guowei Niu, Zheyue Tan, Haiyang Xu, Zhuyu Yao, Tao Yuan, Dong Zhou, Yueqing Zhuang, Bo Zhao, Guohao Dai, Yu Wang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We present Megrez2, a novel lightweight and high-performance language model architecture optimized for device native deployment. Megrez2 introduces a novel cross-layer expert sharing mechanism, which significantly reduces total parameter count by reusing expert modules across adjacent transformer layers while maintaining most of the models capacity. It also incorporates pre-gated routing, enabling memory-efficient expert loading and faster inference. As the first instantiation of the Megrez2 architecture, we introduce the Megrez2-Preview model, which is pre-trained on a 5-trillion-token corpus and further enhanced through supervised fine-tuning and reinforcement learning with verifiable rewards. With only 3B activated and 7.5B stored parameters, Megrez2-Preview demonstrates competitive or superior performance compared to larger models on a wide range of tasks, including language understanding, instruction following, mathematical reasoning, and code generation. These results highlight the effectiveness of the Megrez2 architecture to achieve a balance between accuracy, efficiency, and deployability, making it a strong candidate for real-world, resource-constrained applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17727v1" target="_blank">CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation</a></h3>
                    <p><strong>Authors:</strong> Robel Mamo, Taeyeong Choi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> State-of-the-art visual under-canopy navigation methods are designed with deep learning-based perception models to distinguish traversable space from crop rows. While these models have demonstrated successful performance, they require large amounts of training data to ensure reliability in real-world field deployment. However, data collection is costly, demanding significant human resources for in-field sampling and annotation. To address this challenge, various data augmentation techniques are commonly employed during model training, such as color jittering, Gaussian blur, and horizontal flip, to diversify training data and enhance model robustness. In this paper, we hypothesize that utilizing only these augmentation techniques may lead to suboptimal performance, particularly in complex under-canopy environments with frequent occlusions, debris, and non-uniform spacing of crops. Instead, we propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut) which masks random regions out in input images that are spatially distributed around crop rows on the sides to encourage trained models to capture high-level contextual features even when fine-grained information is obstructed. Our extensive experiments with a public cornfield dataset demonstrate that masking-based augmentations are effective for simulating occlusions and significantly improving robustness in semantic keypoint predictions for visual navigation. In particular, we show that biasing the mask distribution toward crop rows in CA-Cut is critical for enhancing both prediction accuracy and generalizability across diverse environments achieving up to a 36.9% reduction in prediction error. In addition, we conduct ablation studies to determine the number of masks, the size of each mask, and the spatial distribution of masks to maximize overall performance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17725v1" target="_blank">On the Interaction of Compressibility and Adversarial Robustness</a></h3>
                    <p><strong>Authors:</strong> Melih Barsbey, AntÃ´nio H. Ribeiro, Umut ÅžimÅŸekli, Tolga Birdal</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV, stat.ML</p>
                    <p><strong>Summary:</strong> Modern neural networks are expected to simultaneously satisfy a host of desirable properties: accurate fitting to training data, generalization to unseen inputs, parameter and computational efficiency, and robustness to adversarial perturbations. While compressibility and robustness have each been studied extensively, a unified understanding of their interaction still remains elusive. In this work, we develop a principled framework to analyze how different forms of compressibility - such as neuron-level sparsity and spectral compressibility - affect adversarial robustness. We show that these forms of compression can induce a small number of highly sensitive directions in the representation space, which adversaries can exploit to construct effective perturbations. Our analysis yields a simple yet instructive robustness bound, revealing how neuron and spectral compressibility impact $L_\infty$ and $L_2$ robustness via their effects on the learned representations. Crucially, the vulnerabilities we identify arise irrespective of how compression is achieved - whether via regularization, architectural bias, or implicit learning dynamics. Through empirical evaluations across synthetic and realistic tasks, we confirm our theoretical predictions, and further demonstrate that these vulnerabilities persist under adversarial training and transfer learning, and contribute to the emergence of universal adversarial perturbations. Our findings show a fundamental tension between structured compressibility and robustness, and suggest new pathways for designing models that are both efficient and secure.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17724v1" target="_blank">Orthogonality relations and operators on bounded quasi-implication algebras</a></h3>
                    <p><strong>Authors:</strong> Joseph McDonald</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> math.LO</p>
                    <p><strong>Summary:</strong> In this note, we study various relational and algebraic aspects of the bounded quasi-implication algebras introduced by Hardegree. By generalizing the constructions given by MacLaren and Goldblatt within the setting of ortholattices, we construct various orthogonality relations from bounded quasi-implication algebras. We then introduce certain bounded quasi-implication algebras with an additional operator, which we call monadic quasi-implication algebras, and study them within the setting of quantum monadic algebras. A quantum monadic algebra is an orthomodular lattice equipped with a closure operator, known as a quantifier, whose closed elements form an orthomodular sub-lattice. It is shown that every quantum monadic algebra can be converted into a monadic quasi-implication algebra with the underlying magma structure being determined by the operation of Sasaki implication on the underlying orthomodular lattice. It is then conversely demonstrated that every monadic quasi-implication algebra can be converted into a quantum monadic algebra. These constructions are shown to induce an isomorphism between the category of quantum monadic algebras and the category of monadic quasi-implication algebras. Finally, by generalizing the constructions given by Harding as well as Harding, McDonald, and Peinado in the setting of monadic ortholattices, we construct various monadic orthoframes from monadic quasi-implication algebras.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17722v1" target="_blank">BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems</a></h3>
                    <p><strong>Authors:</strong> Malsha Ashani Mahawatta Dona, Beatriz Cabrero-Daniel, Yinan Yu, Christian Berger</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, I.4.m</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are growingly extended to process multimodal data such as text and video simultaneously. Their remarkable performance in understanding what is shown in images is surpassing specialized neural networks (NNs) such as Yolo that is supporting only a well-formed but very limited vocabulary, ie., objects that they are able to detect. When being non-restricted, LLMs and in particular state-of-the-art vision language models (VLMs) show impressive performance to describe even complex traffic situations. This is making them potentially suitable components for automotive perception systems to support the understanding of complex traffic situations or edge case situation. However, LLMs and VLMs are prone to hallucination, which mean to either potentially not seeing traffic agents such as vulnerable road users who are present in a situation, or to seeing traffic agents who are not there in reality. While the latter is unwanted making an ADAS or autonomous driving systems (ADS) to unnecessarily slow down, the former could lead to disastrous decisions from an ADS. In our work, we are systematically assessing the performance of 3 state-of-the-art VLMs on a diverse subset of traffic situations sampled from the Waymo Open Dataset to support safety guardrails for capturing such hallucinations in VLM-supported perception systems. We observe that both, proprietary and open VLMs exhibit remarkable image understanding capabilities even paying thorough attention to fine details sometimes difficult to spot for us humans. However, they are also still prone to making up elements in their descriptions to date requiring hallucination detection strategies such as BetterCheck that we propose in our work.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17721v1" target="_blank">Inflation from a generalized exponential plateau: towards extra suppressed tensor-to-scalar ratios</a></h3>
                    <p><strong>Authors:</strong> Gerasimos Kouniatalis, Emmanuel N. Saridakis</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc</p>
                    <p><strong>Summary:</strong> We investigate a standard minimally-coupled scalar-field inflationary scenario, which is based on a new potential, with suitably generalized plateau features, that leads to extra small tensor-to-scalar ratios. In particular, we consider a specific three-parameter potential, which has a flatter plateau and a steeper well compared to the Starobinsky potential in the Einstein frame. We study the inflationary realization and we show that it guarantees a prolonged period of slow-roll inflation and a successful exit. Additionally, the steeper minimum leads to significantly suppressed tensor perturbations, and thus to an extra-small tensor-to-scalar ratio $r$, and we show that we are able to obtain $r$ values less than $10^{-5}$. Moreover, we calculate the reheating temperature showing that in order to be in agreement with observations one of the potential parameters should remain within specific bounds. Finally, performing an inverse conformal transformation to the Jordan frame we show that the considered potential corresponds to higher-order corrections to Starobinsky potential in the Einstein frame, and these corrections are the reason for the improved behavior of the tensor-to-scalar ratio.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17720v1" target="_blank">Simulating the interplay of dipolar and quadrupolar interactions in NMR by spin dynamic mean-field theory</a></h3>
                    <p><strong>Authors:</strong> Timo GrÃ¤ÃŸer, GÃ¶tz S. Uhrig</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> The simulation of nuclear magnetic resonance (NMR) experiments is a notoriously difficult task, if many spins participate in the dynamics. The recently established dynamic mean-field theory for high-temperature spin systems (spinDMFT) represents an efficient yet accurate method to deal with this scenario. SpinDMFT reduces a complex lattice system to a time-dependent single-site problem, which can be solved numerically with small computational effort. Since the approach retains local quantum degrees of freedom, a quadrupolar term can be exactly incorporated. This allows us to study the interplay of dipolar and quadrupolar interactions for any parameter range, i.e., without the need for a perturbative treatment. We highlight the relevance of local quantum effects by a comparison with the classical analogue system.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17718v1" target="_blank">AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer</a></h3>
                    <p><strong>Authors:</strong> Danny D. Leybzon, Shreyas Tirumala, Nishant Jain, Summer Gillen, Michael Jackson, Cameron McPhee, Jennifer Schmidt</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> With the rise of voice-enabled artificial intelligence (AI) systems, quantitative survey researchers have access to a new data-collection mode: AI telephone surveying. By using AI to conduct phone interviews, researchers can scale quantitative studies while balancing the dual goals of human-like interactivity and methodological rigor. Unlike earlier efforts that used interactive voice response (IVR) technology to automate these surveys, voice AI enables a more natural and adaptive respondent experience as it is more robust to interruptions, corrections, and other idiosyncrasies of human speech. We built and tested an AI system to conduct quantitative surveys based on large language models (LLM), automatic speech recognition (ASR), and speech synthesis technologies. The system was specifically designed for quantitative research, and strictly adhered to research best practices like question order randomization, answer order randomization, and exact wording. To validate the systems effectiveness, we deployed it to conduct two pilot surveys with the SSRS Opinion Panel and followed-up with a separate human-administered survey to assess respondent experiences. We measured three key metrics: the survey completion rates, break-off rates, and respondent satisfaction scores. Our results suggest that shorter instruments and more responsive AI interviewers may contribute to improvements across all three metrics studied.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17717v1" target="_blank">From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes</a></h3>
                    <p><strong>Authors:</strong> Karen Zhou, John Giorgi, Pranav Mani, Peng Xu, Davis Liang, Chenhao Tan</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> AI-generated clinical notes are increasingly used in healthcare, but evaluating their quality remains a challenge due to high subjectivity and limited scalability of expert review. Existing automated metrics often fail to align with real-world physician preferences. To address this, we propose a pipeline that systematically distills real user feedback into structured checklists for note evaluation. These checklists are designed to be interpretable, grounded in human feedback, and enforceable by LLM-based evaluators. Using deidentified data from over 21,000 clinical encounters, prepared in accordance with the HIPAA safe harbor standard, from a deployed AI medical scribe system, we show that our feedback-derived checklist outperforms baseline approaches in our offline evaluations in coverage, diversity, and predictive power for human ratings. Extensive experiments confirm the checklists robustness to quality-degrading perturbations, significant alignment with clinician preferences, and practical value as an evaluation methodology. In offline research settings, the checklist can help identify notes likely to fall below our chosen quality thresholds.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17716v1" target="_blank">Layout optimization for the LUXE-NPOD experiment</a></h3>
                    <p><strong>Authors:</strong> Melissa Almanza Soto, Oleksandr Borysov, Torben Ferber, Shan Huang, AdriÃ¡n Irles, Markus Klute, JesÃºs P. MÃ¡rquez HernÃ¡ndez, Josep PÃ©rez Segura, Raquel Quishpe, Yotam Soreq, Noam Tal Hod, NicolÃ² Trevisani</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> hep-ex, hep-ph</p>
                    <p><strong>Summary:</strong> Beam dump experiments represent an effective way to probe new physics in a parameter space, where new particles have feeble couplings to the Standard Model sector and masses below the GeV scale. The LUXE experiment, designed primarily to study strong-field quantum electrodynamics, can be used also as a photon beam dump experiment with a unique reach for new spin-0 particles in the $10-350~\mathrm{MeV}$ mass and $10^{-6}-10^{-3}~\mathrm{GeV}^{-1}$ couplings to photons ranges. This is achieved via the ``New Physics search with Optical Dump (NPOD) concept. While prior estimations were obtained with a simplified model of the experimental setup, in this work we present a systematic study of the new physics reach in the full, realistic experimental apparatus, including an existing detector to be used in the LUXE NPOD context. We furthermore investigate updated scenarios of LUXEs experimental plan and confirm that our results are in agreement with the original estimations of a background-free operation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17713v1" target="_blank">Sequential Bayesian Design for Efficient Surrogate Construction in the Inversion of Darcy Flows</a></h3>
                    <p><strong>Authors:</strong> Hongji Wang, Hongqiao Wang, Jinyong Ying, Qingping Zhou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Inverse problems governed by partial differential equations (PDEs) play a crucial role in various fields, including computational science, image processing, and engineering. Particularly, Darcy flow equation is a fundamental equation in fluid mechanics, which plays a crucial role in understanding fluid flow through porous media. Bayesian methods provide an effective approach for solving PDEs inverse problems, while their numerical implementation requires numerous evaluations of computationally expensive forward solvers. Therefore, the adoption of surrogate models with lower computational costs is essential. However, constructing a globally accurate surrogate model for high-dimensional complex problems demands high model capacity and large amounts of data. To address this challenge, this study proposes an efficient locally accurate surrogate that focuses on the high-probability regions of the true likelihood in inverse problems, with relatively low model complexity and few training data requirements. Additionally, we introduce a sequential Bayesian design strategy to acquire the proposed surrogate since the high-probability region of the likelihood is unknown. The strategy treats the posterior evolution process of sequential Bayesian design as a Gaussian process, enabling algorithmic acceleration through one-step ahead prior. The complete algorithmic framework is referred to as Sequential Bayesian design for locally accurate surrogate (SBD-LAS). Finally, three experiments based the Darcy flow equation demonstrate the advantages of the proposed method in terms of both inversion accuracy and computational speed.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17712v1" target="_blank">Quantum Software Security Challenges within Shared Quantum Computing Environments</a></h3>
                    <p><strong>Authors:</strong> Samuel Ovaskainen, Majid Haghparast, Tommi Mikkonen</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.CR</p>
                    <p><strong>Summary:</strong> The number of qubits in quantum computers keeps growing, but most quantum programs remain relatively small because of the noisy nature of the underlying quantum hardware. This might lead quantum cloud providers to explore increased hardware utilization, and thus profitability through means such as multi-programming, which would allow the execution of multiple programs in parallel. The adoption of such technology would bring entirely new challenges to the field of quantum software security. This article explores and reports the key challenges identified in quantum software security within shared quantum computing environments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17711v1" target="_blank">Reasoning about Rare-Event Reachability in Stochastic Vector Addition Systems via Affine Vector Spaces</a></h3>
                    <p><strong>Authors:</strong> Joshua Jeppson, Landon Taylor, Bingqing Hu, Zhen Zhang</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.FL</p>
                    <p><strong>Summary:</strong> Rare events in Stochastic Vector Addition System (VAS) are of significant interest because, while extremely unlikely, they may represent undesirable behavior that can have adverse effects. Their low probabilities and potentially extremely large state spaces challenge existing probabilistic model checking and stochastic rare-event simulation techniques. In particular, in Chemical Reaction Networks (CRNs), a chemical kinetic language often represented as VAS, rare event effects may be pathological. We present two novel heuristics for priority-first partial state space expansion and trace generation tuned to the transient analysis of rare-event probability in VAS: Iterative Subspace Reduction (ISR) and Single Distance Priority (SDP). Both methods construct a closed vector space containing all solution states. SDP then simply prioritizes shorter distances to this ``solution space, while ISR constructs a set of nested subspaces, where short and highly-probable satisfying traces are likely to pass through in sequence. The resulting partial state graph from each method contains likely traces to rare-event states, allowing efficient probabilistic model checking to compute a lower-bound probability of a rare event of interest. These methods are deterministic, fast, and demonstrate marked performance on challenging CRN models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17709v1" target="_blank">TyDi QA-WANA: A Benchmark for Information-Seeking Question Answering in Languages of West Asia and North Africa</a></h3>
                    <p><strong>Authors:</strong> Parker Riley, Siamak Shakeri, Waleed Ammar, Jonathan H. Clark</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> We present TyDi QA-WANA, a question-answering dataset consisting of 28K examples divided among 10 language varieties of western Asia and northern Africa. The data collection process was designed to elicit information-seeking questions, where the asker is genuinely curious to know the answer. Each question in paired with an entire article that may or may not contain the answer; the relatively large size of the articles results in a task suitable for evaluating models abilities to utilize large text contexts in answering questions. Furthermore, the data was collected directly in each language variety, without the use of translation, in order to avoid issues of cultural relevance. We present performance of two baseline models, and release our code and data to facilitate further improvement by the research community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17702v1" target="_blank">Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models</a></h3>
                    <p><strong>Authors:</strong> Changxin Tian, Kunlong Chen, Jia Liu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CL, I.2.7</p>
                    <p><strong>Summary:</strong> Mixture-of-Experts (MoE) has become a dominant architecture for scaling Large Language Models (LLMs) efficiently by decoupling total parameters from computational cost. However, this decoupling creates a critical challenge: predicting the model capacity of a given MoE configurations (e.g., expert activation ratio and granularity) remains an unresolved problem. To address this gap, we introduce Efficiency Leverage (EL), a metric quantifying the computational advantage of an MoE model over a dense equivalent. We conduct a large-scale empirical study, training over 300 models up to 28B parameters, to systematically investigate the relationship between MoE architectural configurations and EL. Our findings reveal that EL is primarily driven by the expert activation ratio and the total compute budget, both following predictable power laws, while expert granularity acts as a non-linear modulator with a clear optimal range. We integrate these discoveries into a unified scaling law that accurately predicts the EL of an MoE architecture based on its configuration. To validate our derived scaling laws, we designed and trained Ling-mini-beta, a pilot model for Ling-2.0 series with only 0.85B active parameters, alongside a 6.1B dense model for comparison. When trained on an identical 1T high-quality token dataset, Ling-mini-beta matched the performance of the 6.1B dense model while consuming over 7x fewer computational resources, thereby confirming the accuracy of our scaling laws. This work provides a principled and empirically-grounded foundation for the scaling of efficient MoE models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17700v1" target="_blank">From Atoms to Dynamics: Learning the Committor Without Collective Variables</a></h3>
                    <p><strong>Authors:</strong> Sergio Contreras Arredondo, Chenyu Tang, Radu A. Talmazan, Alberto MegÃ­as, Cheng Giuseppe Chen, Christophe Chipot</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph, cond-mat.stat-mech, physics.data-an</p>
                    <p><strong>Summary:</strong> This Brief Communication introduces a graph-neural-network architecture built on geometric vector perceptrons to predict the committor function directly from atomic coordinates, bypassing the need for hand-crafted collective variables (CVs). The method offers atom-level interpretability, pinpointing the key atomic players in complex transitions without relying on prior assumptions. Applied across diverse molecular systems, the method accurately infers the committor function and highlights the importance of each heavy atom in the transition mechanism. It also yields precise estimates of the rate constants for the underlying processes. The proposed approach opens new avenues for understanding and modeling complex dynamics, by enabling CV-free learning and automated identification of physically meaningful reaction coordinates of complex molecular processes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17695v1" target="_blank">Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks</a></h3>
                    <p><strong>Authors:</strong> Ilias Chatzistefanidis, Navid Nikaein</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.NI</p>
                    <p><strong>Summary:</strong> Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLMs input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17692v1" target="_blank">Joint Asymmetric Loss for Learning with Noisy Labels</a></h3>
                    <p><strong>Authors:</strong> Jialiang Wang, Xianming Liu, Xiong Zhou, Gangfeng Hu, Deming Zhai, Junjun Jiang, Xiangyang Ji</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CV</p>
                    <p><strong>Summary:</strong> Learning with noisy labels is a crucial task for training accurate deep neural networks. To mitigate label noise, prior studies have proposed various robust loss functions, particularly symmetric losses. Nevertheless, symmetric losses usually suffer from the underfitting issue due to the overly strict constraint. To address this problem, the Active Passive Loss (APL) jointly optimizes an active and a passive loss to mutually enhance the overall fitting ability. Within APL, symmetric losses have been successfully extended, yielding advanced robust loss functions. Despite these advancements, emerging theoretical analyses indicate that asymmetric losses, a new class of robust loss functions, possess superior properties compared to symmetric losses. However, existing asymmetric losses are not compatible with advanced optimization frameworks such as APL, limiting their potential and applicability. Motivated by this theoretical gap and the prospect of asymmetric losses, we extend the asymmetric loss to the more complex passive loss scenario and propose the Asymetric Mean Square Error (AMSE), a novel asymmetric loss. We rigorously establish the necessary and sufficient condition under which AMSE satisfies the asymmetric condition. By substituting the traditional symmetric passive loss in APL with our proposed AMSE, we introduce a novel robust loss framework termed Joint Asymmetric Loss (JAL). Extensive experiments demonstrate the effectiveness of our method in mitigating label noise. Code available at: https://github.com/cswjl/joint-asymmetric-loss</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17689v1" target="_blank">Impedance-tuned microwave loop for fast, homogeneous Rabi oscillations of a dense ensemble of NV-diamond electronic spins</a></h3>
                    <p><strong>Authors:</strong> Han Sae Jung, Johannes Cremer, Aoyang Zhang, Sangha Kim, Guang Yang, Ronald L. Walsworth, Donhee Ham</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Obtaining a high Rabi oscillation frequency homogeneously across a spatially-extended population of nitrogen-vacancy (NV) center electronic spins in diamond is useful for efficient spin-state manipulation of the NV ensemble and in using NVs to detect ensembles of other spin species. Here, we achieve a high, homogeneous Rabi frequency for a dense NV ensemble by enhancing the microwave magnetic fields in the center region of a diamond-coupled planar metallic loop via systematic engineering that increases the microwave current driving of the loop, while avoiding off-center proximity to the loop that gives strong but inhomogeneous microwave fields. With such enhanced microwave fields at 2.55 GHz, we achieve a 136.3 MHz NV Rabi frequency with 1.5% inhomogeneity over a 40 $\times$ 40 $\mu m^{2}$ diamond area; and use the NV ensemble to detect a ~30-MHz magnetic signal, similar to a nuclear magnetic resonance signal at a tesla-scale bias magnetic field, with Hz-scale spectral resolution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17686v1" target="_blank">Debiased maximum-likelihood estimators for hazard ratios under machine-learning adjustment</a></h3>
                    <p><strong>Authors:</strong> Takashi Hayakawa, Satoshi Asai</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG</p>
                    <p><strong>Summary:</strong> Previous studies have shown that hazard ratios between treatment groups estimated with the Cox model are uninterpretable because the indefinite baseline hazard of the model fails to identify temporal change in the risk set composition due to treatment assignment and unobserved factors among multiple, contradictory scenarios. To alleviate this problem, especially in studies based on observational data with uncontrolled dynamic treatment and real-time measurement of many covariates, we propose abandoning the baseline hazard and using machine learning to explicitly model the change in the risk set with or without latent variables. For this framework, we clarify the context in which hazard ratios can be causally interpreted, and then develop a method based on Neyman orthogonality to compute debiased maximum-likelihood estimators of hazard ratios. Computing the constructed estimators is more efficient than computing those based on weighted regression with marginal structural Cox models. Numerical simulations confirm that the proposed method identifies the ground truth with minimal bias. These results lay the foundation for developing a useful, alternative method for causal inference with uncontrolled, observational data in modern epidemiology.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17685v1" target="_blank">Data assimilation using a global Girsanov nudged particle filter</a></h3>
                    <p><strong>Authors:</strong> Maneesh Kumar Singh, Joshua Hope-Collins, Colin J. Cotter, Dan Crisan</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> We present a particle filtering algorithm for stochastic models on infinite dimensional state space, making use of Girsanov perturbations to nudge the ensemble of particles into regions of higher likelihood. We argue that the optimal control problem needs to couple control variables for all of the particles to maintain an ensemble with good effective sample size (ESS). We provide an optimisation formulation that separates the problem into three stages, separating the nonlinearity in the ESS term in the functional with the nonlinearity due to the forward problem, and allowing independent parallel computation for each particle when calculations are performed over control variable space. The particle filter is applied to the stochastic Kuramoto-Sivashinsky equation, and compared with the temper-jitter particle filter approach. We observe that whilst the nudging filter is over spread compared to the temper-jitter filter, it responds to extreme events in the assimilated data more quickly and robustly.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17683v1" target="_blank">Spaces of homomorphisms, formality and Hochschild homology</a></h3>
                    <p><strong>Authors:</strong> Simon Gritschacher</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> math.AT</p>
                    <p><strong>Summary:</strong> Let $G$ be a discrete group. The topological category of finite dimensional unitary representations of $G$ is symmetric monoidal under direct sum and has an associated $\mathbb{E}_\infty$-space $\mathcal{K}^{\mathrm{def}}(G)$. We show that if $G$ and $A$ are finitely generated groups and $A$ is abelian, then $\mathcal{K}^{\mathrm{def}}(G\times A)\simeq \mathcal{K}^{\mathrm{def}}(G)\otimes \widehat{A}$ as $\mathbb{E}_\infty$-spaces, where $\widehat{A}$ is the Pontryagin dual of $A$. We deduce a homology stability result for the homomorphism varieties $\mathrm{Hom}(G\times \mathbb{Z}^r,U(n))$ using the local-to-global principle for homology stability of Kupers--Miller. For a finitely generated free group $F$ and a field $k$ of characteristic zero, we show that the singular $k$-chains in $\mathcal{K}^{\mathrm{def}}(F)$ are formal as an $\mathbb{E}_\infty$-$k$-algebra. Using this we describe the equivariant homology of $\mathrm{Hom}(F \times A,U(n))$ for every $n$ in terms of higher Hochschild homology of an explicitly determined commutative $k$-algebra. As an example we show that $\mathrm{Hom}(F\times \mathbb{Z}^r,U(2))$ is $U(2)$-equivariantly formal for every $r$ and we compute the Poincar{\e} polynomial.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17682v1" target="_blank">Audio-Vision Contrastive Learning for Phonological Class Recognition</a></h3>
                    <p><strong>Authors:</strong> Daiqi Liu, TomÃ¡s Arias-Vergara, Jana Hutter, Andreas Maier, Paula Andrea PÃ©rez-Toro</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.SD, cs.CV, cs.MM, eess.AS</p>
                    <p><strong>Summary:</strong> Accurate classification of articulatory-phonological features plays a vital role in understanding human speech production and developing robust speech technologies, particularly in clinical contexts where targeted phonemic analysis and therapy can improve disease diagnosis accuracy and personalized rehabilitation. In this work, we propose a multimodal deep learning framework that combines real-time magnetic resonance imaging (rtMRI) and speech signals to classify three key articulatory dimensions: manner of articulation, place of articulation, and voicing. We perform classification on 15 phonological classes derived from the aforementioned articulatory dimensions and evaluate the system with four audio/vision configurations: unimodal rtMRI, unimodal audio signals, multimodal middle fusion, and contrastive learning-based audio-vision fusion. Experimental results on the USC-TIMIT dataset show that our contrastive learning-based approach achieves state-of-the-art performance, with an average F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal baseline. The results confirm the effectiveness of contrastive representation learning for multimodal articulatory analysis. Our code and processed dataset will be made publicly available at https://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17680v1" target="_blank">Simulating multiple human perspectives in socio-ecological systems using large language models</a></h3>
                    <p><strong>Authors:</strong> Yongchao Zeng, Calum Brown, Ioannis Kyriakou, Ronja Hotz, Mark Rounsevell</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> Understanding socio-ecological systems requires insights from diverse stakeholder perspectives, which are often hard to access. To enable alternative, simulation-based exploration of different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) to represent various stakeholders; users can step into the agent roles to experience perspectival differences. A simulation protocol serves as a scaffold to streamline multiple perspective-taking simulations, supporting users in reflecting on, transitioning between, and integrating across perspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional dynamics and land use change, enabling both narrative-driven and numerical experiments. In an illustrative experiment, a user successively adopts the perspectives of a system observer and a researcher - a role that analyses data from the embedded land use model to inform evidence-based decision-making for other LLM agents representing various institutions. Despite the users effort to recommend technically sound policies, discrepancies persist between the policy recommendation and implementation due to stakeholders competing advocacies, mirroring real-world misalignment between researcher and policymaker perspectives. The users reflection highlights the subjective feelings of frustration and disappointment as a researcher, especially due to the challenge of maintaining political neutrality while attempting to gain political influence. Despite this, the user exhibits high motivation to experiment with alternative narrative framing strategies, suggesting the systems potential in exploring different perspectives. Further system and protocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-ecological simulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17678v1" target="_blank">MCM: Mamba-based Cardiac Motion Tracking using Sequential Images in MRI</a></h3>
                    <p><strong>Authors:</strong> Jiahui Yin, Xinxing Cheng, Jinming Duan, Yan Pang, Declan ORegan, Hadrien Reynaud, Qingjie Meng</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Myocardial motion tracking is important for assessing cardiac function and diagnosing cardiovascular diseases, for which cine cardiac magnetic resonance (CMR) has been established as the gold standard imaging modality. Many existing methods learn motion from single image pairs consisting of a reference frame and a randomly selected target frame from the cardiac cycle. However, these methods overlook the continuous nature of cardiac motion and often yield inconsistent and non-smooth motion estimations. In this work, we propose a novel Mamba-based cardiac motion tracking network (MCM) that explicitly incorporates target image sequence from the cardiac cycle to achieve smooth and temporally consistent motion tracking. By developing a bi-directional Mamba block equipped with a bi-directional scanning mechanism, our method facilitates the estimation of plausible deformation fields. With our proposed motion decoder that integrates motion information from frames adjacent to the target frame, our method further enhances temporal coherence. Moreover, by taking advantage of Mambas structured state-space formulation, the proposed method learns the continuous dynamics of the myocardium from sequential images without increasing computational complexity. We evaluate the proposed method on two public datasets. The experimental results demonstrate that the proposed method quantitatively and qualitatively outperforms both conventional and state-of-the-art learning-based cardiac motion tracking methods. The code is available at https://github.com/yjh-0104/MCM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17674v1" target="_blank">Scattering Angle Dependence of Fano Resonance Profiles in Cold Atomic Collisions Analyzed with the Complex Valued $w$ Parameter</a></h3>
                    <p><strong>Authors:</strong> Tanmay Singh, Raj Aryan Singh, Fumihiro Koike, Masatomi Iizawa, Yoshiro Azuma</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph, physics.chem-ph, quant-ph</p>
                    <p><strong>Summary:</strong> The scattering angle dependence of Fano resonance profiles in cold atomic collisions has been theoretically studied. A complex-valued parameter $ w $ with an analytical formula describing the asymmetry of the resonance profile is proposed as a new development from previous work on electron resonance scattering from atoms [F. Koike, J. Phys. $\mathbf{B10}$, 2883 (1977)]. It serves as the general formulation which leads to the angle-dependence of Fanos $ q $ parameter. Calculations for the case of cold elastic collisions of hydrogen atoms with krypton atoms have been accomplished. The strong angle dependence of the resonance profile asymmetry in the differential scattering cross section due to the interference with non-resonant partial waves is demonstrated. The scattering angle dependence of the resonance profile and thus the newly proposed asymmetry parameter is highly sensitive to the inter-atomic interaction potentials. This is likely to prove useful for the study of interaction potentials themselves.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17673v1" target="_blank">Stable Iterative Solvers for Ill-conditioned Linear Systems</a></h3>
                    <p><strong>Authors:</strong> Vasileios Kalantzis, Mark S. Squillante, Chai Wah Wu</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.DS, cs.NA, 65F22, F.2.1</p>
                    <p><strong>Summary:</strong> Iterative solvers for large-scale linear systems such as Krylov subspace methods can diverge when the linear system is ill-conditioned, thus significantly reducing the applicability of these iterative methods in practice for high-performance computing solutions of such large-scale linear systems. To address this fundamental problem, we propose general algorithmic frameworks to modify Krylov subspace iterative solution methods which ensure that the algorithms are stable and do not diverge. We then apply our general frameworks to current implementations of the corresponding iterative methods in SciPy and demonstrate the efficacy of our stable iterative approach with respect to numerical experiments across a wide range of synthetic and real-world ill-conditioned linear systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17672v1" target="_blank">Coupling all-electron full-potential density functional theory with grid-based continuum embeddings</a></h3>
                    <p><strong>Authors:</strong> Jakob Filser, Edan Bainglass, Karsten Reuter, Oliviero Andreussi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph</p>
                    <p><strong>Summary:</strong> Recent advances in continuum embedding models have enabled the incorporation of solvent and electrolyte effects into density functional theory (DFT) simulations of material surfaces, significantly benefiting electrochemistry, catalysis, and other applications. To extend the simulation of diverse systems and properties, the implementation of continuum embedding models into the Environ library adopts a modular programming paradigm, offering a flexible interface for communication with various DFT programs. The speed and scalability of the current implementation rely on a smooth definition of the key physical properties of the atomistic system, in particular of its electronic density. This has hindered the coupling of Environ with all-electron simulation packages, as the sharp electron density peaks near atomic nuclei are difficult to represent on regular grids. In this work, we introduce a novel smoothing scheme that transforms atom-centered electron densities into a regular grid representation while preserving the accuracy of electrostatic calculations. This approach enables a minimal and generic interface, facilitating seamless interoperability between Environ and all-electron DFT programs. We demonstrate this development through the coupling of Environ with the FHI-aims package and present benchmark simulations that validate the proposed method.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17665v1" target="_blank">Perspective-Invariant 3D Object Detection</a></h3>
                    <p><strong>Authors:</strong> Ao Liang, Lingdong Kong, Dongyue Lu, Youquan Liu, Jian Fang, Huaici Zhao, Wei Tsang Ooi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> With the rise of robotics, LiDAR-based 3D object detection has garnered significant attention in both academia and industry. However, existing datasets and methods predominantly focus on vehicle-mounted platforms, leaving other autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET, the first benchmark featuring LiDAR data and 3D bounding box annotations collected from multiple platforms: vehicle, quadruped, and drone, thereby facilitating research in 3D object detection for non-vehicle platforms as well as cross-platform 3D detection. Based on Pi3DET, we propose a novel cross-platform adaptation framework that transfers knowledge from the well-studied vehicle platform to other platforms. This framework achieves perspective-invariant 3D detection through robust alignment at both geometric and feature levels. Additionally, we establish a benchmark to evaluate the resilience and robustness of current 3D detectors in cross-platform scenarios, providing valuable insights for developing adaptive 3D perception systems. Extensive experiments validate the effectiveness of our approach on challenging cross-platform tasks, demonstrating substantial gains over existing adaptation methods. We hope this work paves the way for generalizable and unified 3D perception systems across diverse and complex environments. Our Pi3DET dataset, cross-platform benchmark suite, and annotation toolkit have been made publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17664v1" target="_blank">Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras</a></h3>
                    <p><strong>Authors:</strong> Lingdong Kong, Dongyue Lu, Ao Liang, Rong Li, Yuhao Dong, Tianshuai Hu, Lai Xing Ng, Wei Tsang Ooi, Benoit R. Cottereau</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Event cameras offer microsecond-level latency and robustness to motion blur, making them ideal for understanding dynamic environments. Yet, connecting these asynchronous streams to human language remains an open challenge. We introduce Talk2Event, the first large-scale benchmark for language-driven object grounding in event-based perception. Built from real-world driving data, we provide over 30,000 validated referring expressions, each enriched with four grounding attributes -- appearance, status, relation to viewer, and relation to other objects -- bridging spatial, temporal, and relational reasoning. To fully exploit these cues, we propose EventRefer, an attribute-aware grounding framework that dynamically fuses multi-attribute representations through a Mixture of Event-Attribute Experts (MoEE). Our method adapts to different modalities and scene dynamics, achieving consistent gains over state-of-the-art baselines in event-only, frame-only, and event-frame fusion settings. We hope our dataset and approach will establish a foundation for advancing multimodal, temporally-aware, and language-driven perception in real-world robotics and autonomy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17662v1" target="_blank">Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography</a></h3>
                    <p><strong>Authors:</strong> Farnoush Bayatmakou, Reza Taleei, Nicole Simone, Arash Mohammadi</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Breast cancer (BC) remains one of the leading causes of cancer-related mortality among women, despite recent advances in Computer-Aided Diagnosis (CAD) systems. Accurate and efficient interpretation of multi-view mammograms is essential for early detection, driving a surge of interest in Artificial Intelligence (AI)-powered CAD models. While state-of-the-art multi-view mammogram classification models are largely based on Transformer architectures, their computational complexity scales quadratically with the number of image patches, highlighting the need for more efficient alternatives. To address this challenge, we propose Mammo-Mamba, a novel framework that integrates Selective State-Space Models (SSMs), transformer-based attention, and expert-driven feature refinement into a unified architecture. Mammo-Mamba extends the MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE) mechanism through its customized SecMamba block. The SecMamba is a modified MambaVision block that enhances representation learning in high-resolution mammographic images by enabling content-adaptive feature refinement. These blocks are integrated into the deeper stages of MambaVision, allowing the model to progressively adjust feature emphasis through dynamic expert gating, effectively mitigating the limitations of traditional Transformer models. Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior classification performance across all key metrics while maintaining computational efficiency.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17661v1" target="_blank">Monocular Semantic Scene Completion via Masked Recurrent Networks</a></h3>
                    <p><strong>Authors:</strong> Xuzhi Wang, Xinran Wu, Song Wang, Lingdong Kong, Ziping Zhao</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Monocular Semantic Scene Completion (MSSC) aims to predict the voxel-wise occupancy and semantic category from a single-view RGB image. Existing methods adopt a single-stage framework that aims to simultaneously achieve visible region segmentation and occluded region hallucination, while also being affected by inaccurate depth estimation. Such methods often achieve suboptimal performance, especially in complex scenes. We propose a novel two-stage framework that decomposes MSSC into coarse MSSC followed by the Masked Recurrent Network. Specifically, we propose the Masked Sparse Gated Recurrent Unit (MS-GRU) which concentrates on the occupied regions by the proposed mask updating mechanism, and a sparse GRU design is proposed to reduce the computation cost. Additionally, we propose the distance attention projection to reduce projection errors by assigning different attention scores according to the distance to the observed surface. Experimental results demonstrate that our proposed unified framework, MonoMRN, effectively supports both indoor and outdoor scenes and achieves state-of-the-art performance on the NYUv2 and SemanticKITTI datasets. Furthermore, we conduct robustness analysis under various disturbances, highlighting the role of the Masked Recurrent Network in enhancing the models resilience to such challenges. The source code is publicly available.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17659v1" target="_blank">See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering</a></h3>
                    <p><strong>Authors:</strong> Junjie Wang, Yunhan Tang, Yijie Wang, Zhihao Yuan, Huan Wang, Yangfan He, Bin Li</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Multimodal Large Language Models (MLLMs) have pushed the frontiers of Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is fundamentally bottlenecked by a reliance on uni-dimensional evidence. This seeing only the trees, but not the forest approach prevents robust, multi-faceted understanding. Inspired by the principle of seeing both the forest and trees, we propose Synergos-VQA, a novel synergistic reasoning framework. At its core, Synergos-VQA concurrently generates and fuses three complementary evidence streams at inference time: (1) Holistic Evidence to perceive the entire scene (the forest), (2) Structural Evidence from a prototype-driven module to identify key objects (the trees), and (3) Causal Evidence from a counterfactual probe to ensure the reasoning is robustly grounded. By synergistically fusing this multi-faceted evidence, our framework achieves a more comprehensive and reliable reasoning process. Extensive experiments show that Synergos-VQA decisively establishes a new state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA. Furthermore, our approach demonstrates strong plug-and-play capabilities, significantly boosting various open-source MLLMs and proving that superior methodological design can outperform sheer model scale.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17658v1" target="_blank">Resource-efficient Variational Block-Encoding</a></h3>
                    <p><strong>Authors:</strong> Leon RullkÃ¶tter, Sebastian Weber, Vamshi Mohan Katukuri, Christian Tutschku, Bharadwaj Chowdary Mummaneni</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Block-encoding operators are one of the essential components in quantum algorithms based on Quantum Signal Processing. Their gate complexity largely determines the overall gate complexity of the full algorithm. Using variational methods, we aim to compile block-encoding unitaries with near-optimal resource requirements for a large range of input matrices. We find that the number of variational parameters in the parameterized quantum circuit approaches the number of free parameters in the input matrices, depending on whether they are real, complex and/or hermitian. Additionally, symmetries present in the input matrix can be incorporated into the ansatz circuit, reducing the parameter count further and making optimization possible for up to n=8 qubits. While determining variational block-encodings ceases to be computationally feasible for large system sizes, the constructed operators can be used as components of larger block-encodings via a linear combination of block-encodings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17657v1" target="_blank">Attention (as Discrete-Time Markov) Chains</a></h3>
                    <p><strong>Authors:</strong> Yotam Erel, Olaf DÃ¼nkel, Rishabh Dabral, Vladislav Golyanik, Christian Theobalt, Amit H. Bermano</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce a new interpretation of the attention matrix as a discrete-time Markov chain. Our interpretation sheds light on common operations involving attention scores such as selection, summation, and averaging in a unified framework. It further extends them by considering indirect attention, propagated through the Markov chain, as opposed to previous studies that only model immediate effects. Our main observation is that tokens corresponding to semantically similar regions form a set of metastable states, where the attention clusters, while noisy attention scores tend to disperse. Metastable states and their prevalence can be easily computed through simple matrix multiplication and eigenanalysis, respectively. Using these lightweight tools, we demonstrate state-of-the-art zero-shot segmentation. Lastly, we define TokenRank -- the steady state vector of the Markov chain, which measures global token importance. We demonstrate that using it brings improvements in unconditional image generation. We believe our framework offers a fresh view of how tokens are being attended in modern visual transformers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17656v1" target="_blank">Fragility of Topology under Electronic Correlations in Iron Chalcogenides</a></h3>
                    <p><strong>Authors:</strong> Younsik Kim, Junseo Yoo, Sehoon Kim, Kiyohisa Tanaka, Li Yu, Minjae Kim, Changyoung Kim</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el</p>
                    <p><strong>Summary:</strong> The interplay between electronic correlations and topology is a central topic in the study of quantum materials. In this work, we investigate the impact of the orbital-selective Mott phase (OSMP) on the topological properties of FeTe1-xSex (FTS), an iron chalcogenide superconductor known to host both non-trivial Z2 topology and strong electronic correlations. Using angle-resolved photoemission spectroscopy, we track the evolution of topological surface states across various doping levels and temperatures. We identify a topological phase transition between trivial and non-trivial topology as a function of selenium content, with critical behavior observed between x = 0.04 and x = 0.09. Additionally, we find that at elevated temperatures, the coherence of the topological surface state deteriorates due to the emergence of OSMP, despite the topological invariant remaining intact. Our results demonstrate that the non-trivial topology in iron chalcogenide is fragile under strong electronic correlations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17655v1" target="_blank">Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses</a></h3>
                    <p><strong>Authors:</strong> Shams Shaikh, Trima P. Fernandes e Fizardo</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.NI, cs.SE, C.2.4; D.4.6; E.3; E.5; K.6.5</p>
                    <p><strong>Summary:</strong> As organizations rapidly migrate to the cloud, the security of cryptographic key management has become a growing concern. Hardware Security Modules (HSMs) and Trusted Platform Modules (TPMs), traditionally seen as the gold standard for securing encryption keys and digital trust, are increasingly challenged by cloud-native threats. Real-world breaches have exposed weaknesses in cloud deployments, including misconfigurations, API abuse, and privilege escalations, allowing attackers to access sensitive key material and bypass protections. These incidents reveal that while the hardware remains secure, the surrounding cloud ecosystem introduces systemic vulnerabilities. This paper analyzes notable security failures involving HSMs and TPMs, identifies common attack vectors, and questions longstanding assumptions about their effectiveness in distributed environments. We explore alternative approaches such as confidential computing, post-quantum cryptography, and decentralized key management. Our findings highlight that while HSMs and TPMs still play a role, modern cloud security requires more adaptive, layered architectures. By evaluating both current weaknesses and emerging models, this research equips cloud architects and security engineers with strategies to reinforce cryptographic trust in the evolving threat landscape.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17654v1" target="_blank">On Function-Correcting Codes in the Lee Metric</a></h3>
                    <p><strong>Authors:</strong> Gyanendra K. Verma, Abhay Kumar Singh</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.DM, cs.IR, math.IT</p>
                    <p><strong>Summary:</strong> Function-correcting codes are a coding framework designed to minimize redundancy while ensuring that specific functions or computations of encoded data can be reliably recovered, even in the presence of errors. The choice of metric is crucial in designing such codes, as it determines which computations must be protected and how errors are measured and corrected. Previous work by Liu and Liu [6] studied function-correcting codes over $\mathbb{Z}_{2^l},\ l\geq 2$ using the homogeneous metric, which coincides with the Lee metric over $\mathbb{Z}_4$. In this paper, we extend the study to codes over $\mathbb{Z}_m,$ for any positive integer $m\geq 2$ under the Lee metric and aim to determine their optimal redundancy. To achieve this, we introduce irregular Lee distance codes and derive upper and lower bounds on the optimal redundancy by characterizing the shortest possible length of such codes. These general bounds are then simplified and applied to specific classes of functions, including Lee-local functions, Lee weight functions, and Lee weight distribution functions, leading to improved some bounds compared to those of Liu and Liu [6] over $\mathbb{Z}_4$ and generalize the other bounds over $\mathbb{Z}_m$ in the Lee metric.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17652v1" target="_blank">Parity violation in MÃ¸ller scattering within low-energy effective field theory</a></h3>
                    <p><strong>Authors:</strong> Sophie Kollatzsch, Daniel Moreno, David Radic, Adrian Signer</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> hep-ph</p>
                    <p><strong>Summary:</strong> We include electroweak effects in Moller scattering at low energies in an effective field theory approach and compute the left-right parity-violating asymmetry. The calculation using low-energy effective field theory provides a solid framework to integrate out heavy particles with masses of the order of the electroweak scale, allowing the resummation of all large logarithms between the electroweak scale and the scale, where QCD perturbation theory breaks down. The NLO electroweak corrections with leading logarithmic resummation, combined with QED corrections at NNLO and hadronic effects are implemented into the Monte Carlo framework McMule. Thus, we obtain a fully differential description and present results adapted to the MOLLER experiment. The potential impact of large logarithms at the next-to-leading logarithmic level is investigated.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.17651v1" target="_blank">CNS-Bench: Benchmarking Image Classifier Robustness Under Continuous Nuisance Shifts</a></h3>
                    <p><strong>Authors:</strong> Olaf DÃ¼nkel, Artur Jesslen, Jiahao Xie, Christian Theobalt, Christian Rupprecht, Adam Kortylewski</p>
                    <p><strong>Published:</strong> 7/23/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> An important challenge when using computer vision models in the real world is to evaluate their performance in potential out-of-distribution (OOD) scenarios. While simple synthetic corruptions are commonly applied to test OOD robustness, they often fail to capture nuisance shifts that occur in the real world. Recently, diffusion models have been applied to generate realistic images for benchmarking, but they are restricted to binary nuisance shifts. In this work, we introduce CNS-Bench, a Continuous Nuisance Shift Benchmark to quantify OOD robustness of image classifiers for continuous and realistic generative nuisance shifts. CNS-Bench allows generating a wide range of individual nuisance shifts in continuous severities by applying LoRA adapters to diffusion models. To address failure cases, we propose a filtering mechanism that outperforms previous methods, thereby enabling reliable benchmarking with generative models. With the proposed benchmark, we perform a large-scale study to evaluate the robustness of more than 40 classifiers under various nuisance shifts. Through carefully designed comparisons and analyses, we find that model rankings can change for varying shifts and shift scales, which cannot be captured when applying common binary shifts. Additionally, we show that evaluating the model performance on a continuous scale allows the identification of model failure points, providing a more nuanced understanding of model robustness. Project page including code and data: https://genintel.github.io/CNS.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

