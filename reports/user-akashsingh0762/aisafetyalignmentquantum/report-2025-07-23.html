
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-07-23<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 150
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The landscape of AI safety research is rapidly evolving, with several key trends and breakthroughs emerging from recent studies. A notable trend is the exploration of cognitive behaviors in AI, such as the study The Other Mind: How Language Models Exhibit Human Temporal Cognition, which reveals that large language models (LLMs) can exhibit human-like temporal cognition patterns not explicitly programmed into them. This suggests a need for deeper understanding of AI cognition to ensure safe and predictable AI behavior, especially as AI systems become more autonomous and integrated into decision-making processes.

Another critical area of AI safety research focuses on the robustness and trustworthiness of AI systems. For instance, the paper Challenges of Trustworthy Federated Learning addresses the alignment of federated learning with trustworthy AI principles. This involves overcoming significant privacy and security challenges, emphasizing the importance of developing AI systems that are not only effective but also aligned with ethical and societal norms. Additionally, the study Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems highlights security vulnerabilities in AI models, specifically how adversaries can exploit LLMs to exfiltrate sensitive information, underscoring the necessity for advanced security measures in AI deployment. Collectively, these studies illustrate a growing emphasis on understanding and mitigating the risks associated with AI, ensuring that technological advancements do not compromise safety and ethical standards.

*Based on 50 research papers*

---

## ai alignment research

The research papers you provided cover a wide range of topics, but some have aspects relevant to AI alignment research, which focuses on ensuring AI systems act in accordance with human values and intentions. A few notable trends and breakthroughs emerge from these works:

1. **Human-AI Interaction and Collaboration**: Papers like Interaction as Intelligence and Towards physician-centered oversight of conversational diagnostic AI emphasize the importance of designing AI systems that facilitate meaningful interactions with humans. These works suggest that incorporating human oversight and collaboration into AI systems can enhance their alignment with human values, particularly in high-stakes environments like healthcare. By redefining interaction as a core component of AI intelligence, these papers highlight the potential for AI systems to better understand and align with complex human intentions.

2. **Ethical and Contextual Considerations in AI Systems**: The research on Challenges of Trustworthy Federated Learning addresses the ethical, legal, and technical challenges in aligning federated learning systems with human values. Similarly, papers like Operationalizing AI for Good discuss the practical deployment of AI models in humanitarian contexts, underscoring the necessity for AI alignment with ethical standards a...</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2507.15851v1" target="_blank">The Other Mind: How Language Models Exhibit Human Temporal Cognition</a></h3>
                    <p><strong>Authors:</strong> Lingyu Li, Yang Yao, Yixu Wang, Chubo Li, Yan Teng, Yingchun Wang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> As Large Language Models (LLMs) continue to advance, they exhibit certain cognitive patterns similar to those of humans that are not directly specified in training data. This study investigates this phenomenon by focusing on temporal cognition in LLMs. Leveraging the similarity judgment task, we find that larger models spontaneously establish a subjective temporal reference point and adhere to the Weber-Fechner law, whereby the perceived distance logarithmically compresses as years recede from this reference point. To uncover the mechanisms behind this behavior, we conducted multiple analyses across neuronal, representational, and informational levels. We first identify a set of temporal-preferential neurons and find that this group exhibits minimal activation at the subjective reference point and implements a logarithmic coding scheme convergently found in biological systems. Probing representations of years reveals a hierarchical construction process, where years evolve from basic nu...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15850v1" target="_blank">3LM: Bridging Arabic, STEM, and Code through Benchmarking</a></h3>
                    <p><strong>Authors:</strong> Basma El Amel Boussaha, Leen AlQadi, Mugariya Farooq, Shaikha Alsuwaidi, Giulia Campesan, Ahmed Alzubaidi, Mohammed Alyafeai, Hakim Hacid</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Arabic is one of the most widely spoken languages in the world, yet efforts to develop and evaluate Large Language Models (LLMs) for Arabic remain relatively limited. Most existing Arabic benchmarks focus on linguistic, cultural, or religious content, leaving a significant gap in domains like STEM and code which are increasingly relevant for real-world LLM applications. To help bridge this gap, we present 3LM, a suite of three benchmarks designed specifically for Arabic. The first is a set of STEM-related question-answer pairs, naturally sourced from Arabic textbooks and educational worksheets. The second consists of synthetically generated STEM questions, created using the same sources. The third benchmark focuses on code generation, built through a careful translation of two widely used code benchmarks, incorporating a human-in-the-loop process with several rounds of review to ensure high-quality and faithful translations. We release all three benchmarks publicly to support the growt...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15840v1" target="_blank">TASI/CERN/KITP Lecture Notes on Toward Quantum Computing Gauge Theories of Nature</a></h3>
                    <p><strong>Authors:</strong> Zohreh Davoudi</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> hep-lat, hep-ph, nucl-th, quant-ph</p>
                    <p><strong>Summary:</strong> A hallmark of the computational campaign in nuclear and particle physics is the lattice-gauge-theory program. It continues to enable theoretical predictions for a range of phenomena in nature from the underlying Standard Model. The emergence of a new computational paradigm based on quantum computing, therefore, can introduce further advances in this program. In particular, it is believed that quantum computing will make possible first-principles studies of matter at extreme densities, and in and out of equilibrium, hence improving our theoretical description of early universe, astrophysical environments, and high-energy particle collisions. Developing and advancing a quantum-computing based lattice-gauge-theory program, therefore, is a vibrant and fast-moving area of research in theoretical nuclear and particle physics. These lecture notes introduce the topic of quantum computing lattice gauge theories in a pedagogical manner, with an emphasis on theoretical and algorithmic aspects of ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15839v1" target="_blank">FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs</a></h3>
                    <p><strong>Authors:</strong> Anh Nguyen, Sam Schafft, Nicholas Hale, John Alfaro</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Synthetic data generation has emerged as an invaluable solution in scenarios where real-world data collection and usage are limited by cost and scarcity. Large language models (LLMs) have demonstrated remarkable capabilities in producing high-fidelity, domain-relevant samples across various fields. However, existing approaches that directly use LLMs to generate each record individually impose prohibitive time and cost burdens, particularly when large volumes of synthetic data are required. In this work, we propose a fast, cost-effective method for realistic tabular data synthesis that leverages LLMs to infer and encode each fields distribution into a reusable sampling script. By automatically classifying fields into numerical, categorical, or free-text types, the LLM generates distribution-based scripts that can efficiently produce diverse, realistic datasets at scale without continuous model inference. Experimental results show that our approach outperforms traditional direct methods ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15831v1" target="_blank">Observing Fine-Grained Changes in Jupyter Notebooks During Development Time</a></h3>
                    <p><strong>Authors:</strong> Sergey Titov, Konstantin Grotov, Cristina Sarasua, Yaroslav Golubev, Dhivyabharathi Ramasamy, Alberto Bacchelli, Abraham Bernstein, Timofey Bryksin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> In software engineering, numerous studies have focused on the analysis of fine-grained logs, leading to significant innovations in areas such as refactoring, security, and code completion. However, no similar studies have been conducted for computational notebooks in the context of data science. To help bridge this research gap, we make three scientific contributions: we (1) introduce a toolset for collecting code changes in Jupyter notebooks during development time; (2) use it to collect more than 100 hours of work related to a data analysis task and a machine learning task (carried out by 20 developers with different levels of expertise), resulting in a dataset containing 2,655 cells and 9,207 cell executions; and (3) use this dataset to investigate the dynamic nature of the notebook development process and the changes that take place in the notebooks. In our analysis of the collected data, we classified the changes made to the cells between executions and found that a significant nu...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15828v1" target="_blank">Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering</a></h3>
                    <p><strong>Authors:</strong> Mauro Marcelino, Marcos Alves, Bianca Trinkenreich, Bruno Cartaxo, SÃ©rgio Soares, Simone D. J. Barbosa, Marcos Kalinowski</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> [Context] An evidence briefing is a concise and objective transfer medium that can present the main findings of a study to software engineers in the industry. Although practitioners and researchers have deemed Evidence Briefings useful, their production requires manual labor, which may be a significant challenge to their broad adoption. [Goal] The goal of this registered report is to describe an experimental protocol for evaluating LLM-generated evidence briefings for secondary studies in terms of content fidelity, ease of understanding, and usefulness, as perceived by researchers and practitioners, compared to human-made briefings. [Method] We developed an RAG-based LLM tool to generate evidence briefings. We used the tool to automatically generate two evidence briefings that had been manually generated in previous research efforts. We designed a controlled experiment to evaluate how the LLM-generated briefings compare to the human-made ones regarding perceived content fidelity, ease ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15823v1" target="_blank">Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work</a></h3>
                    <p><strong>Authors:</strong> Anton Abilov, Ke Zhang, Hemank Lamba, Elizabeth M. Olson, Joel R. Tetreault, Alejandro Jaimes</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.SI</p>
                    <p><strong>Summary:</strong> Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15822v1" target="_blank">Do AI models help produce verified bug fixes?</a></h3>
                    <p><strong>Authors:</strong> Li Huang, Ilgiz Mustafin, Marco Piccioni, Alessandro Schena, Reto Weber, Bertrand Meyer</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills? To answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15821v1" target="_blank">Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks</a></h3>
                    <p><strong>Authors:</strong> Hope Schroeder, Deb Roy, Jad Kabbara</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> LLM use in annotation is becoming widespread, and given LLMs overall promising performance and speed, simply reviewing LLM annotations in interpretive tasks can be tempting. In subjective annotation tasks with multiple plausible answers, reviewing LLM outputs can change the label distribution, impacting both the evaluation of LLM performance, and analysis using these labels in a social science task downstream. We conducted a pre-registered experiment with 410 unique annotators and over 7,000 annotations testing three AI assistance conditions against controls, using two models, and two datasets. We find that presenting crowdworkers with LLM-generated annotation suggestions did not make them faster, but did improve their self-reported confidence in the task. More importantly, annotators strongly took the LLM suggestions, significantly changing the label distribution compared to the baseline. When these labels created with LLM assistance are used to evaluate LLM performance, reported mode...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15819v1" target="_blank">Euclid preparation: Expected constraints on initial conditions</a></h3>
                    <p><strong>Authors:</strong> Euclid Collaboration, F. Finelli, Y. Akrami, A. Andrews, M. Ballardini, S. Casas, D. Karagiannis, Z. Sakr, J. Valiviita, G. Alestas, N. Bartolo, J. R. Bermejo-Climent, S. Nesseris, D. Paoletti, D. Sapone, I. Tutusaus, A. AchÃºcarro, G. CaÃ±as-Herrera, J. Jasche, G. Lavaux, N. Aghanim, B. Altieri, A. Amara, L. Amendola, S. Andreon, N. Auricchio, C. Baccigalupi, D. Bagot, M. Baldi, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, S. Camera, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, S. de la Torre, G. De Lucia, A. M. Di Giorgio, H. Dole, M. Douspis, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, F. Faustini, S. Ferriol, P. Fosalba, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. KeihÃ¤nen, S. Kermiche, A. Kiessling, B. Kubik, M. KÃ¼mmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, B. Sartoris, M. Schirmer, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, P. Simon, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-CrespÃ­, D. Tavagnacco, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, L. Valenziano, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, V. Allevato, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, J. MartÃ­n-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. A. Nucita, A. Pezzotta, M. PÃ¶ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, I. T. Andika, M. Archidiacono, F. Atrio-Barandela, S. Avila, A. Balaguera-Antolinez, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, H. BÃ¶hringer, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, S. Davini, F. De Paolis, G. Desprez, A. DÃ­az-SÃ¡nchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, J. GarcÃ­a-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, A. Gruppuso, M. Guidi, C. M. Gutierrez, S. Hemmati, C. HernÃ¡ndez-Monteagudo, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, Y. Kang, V. Kansal, K. Kiiveri, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, V. Le Brun, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, J. Macias-Perez, G. Maggio, M. Magliocchetti, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Migliaccio, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, A. Navarro-Alsina, L. Pagano, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, P. Reimberg, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. SahlÃ©n, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, F. Vernizzi, G. Verza, P. Vielzeuf, N. A. Walton</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> The Euclid mission of the European Space Agency will deliver galaxy and cosmic shear surveys, which will be used to constrain initial conditions and statistics of primordial fluctuations. We present highlights for the Euclid scientific capability to test initial conditions beyond LCDM with the main probes, i.e. 3D galaxy clustering from the spectroscopic survey, the tomographic approach to 3x2pt statistics from photometric galaxy survey, and their combination. We provide Fisher forecasts from the combination of Euclid spectroscopic and photometric surveys for spatial curvature, running of the spectral index of the power spectrum of curvature perturbations, isocurvature perturbations, and primordial features. For the parameters of these models we also provide the combination of Euclid forecasts (pessimistic and optimistic) with current and future measurements of the cosmic microwave background (CMB) anisotropies., i.e. Planck, the Simons Observatory (SO), and CMB-S4. We provide Fisher f...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15798v1" target="_blank">Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models</a></h3>
                    <p><strong>Authors:</strong> Lilian Hollard, Lucas Mohimont, Nathalie Gaveau, Luiz-Angelo Steffenel</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The paper investigates the performance of state-of-the-art low-parameter deep neural networks for computer vision, focusing on bottleneck architectures and their behavior using superlinear activation functions. We address interference in feature maps, a phenomenon associated with superposition, where neurons simultaneously encode multiple characteristics. Our research suggests that limiting interference can enhance scaling and accuracy in very low-scaled networks (under 1.5M parameters). We identify key design elements that reduce interference by examining various bottleneck architectures, leading to a more efficient neural network. Consequently, we propose a proof-of-concept architecture named NoDepth Bottleneck built on mechanistic insights from our experiments, demonstrating robust scaling accuracy on the ImageNet dataset. These findings contribute to more efficient and scalable neural networks for the low-parameter range and advance the understanding of bottlenecks in computer visi...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15796v1" target="_blank">Challenges of Trustworthy Federated Learning: Whats Done, Current Trends and Remaining Work</a></h3>
                    <p><strong>Authors:</strong> Nuria RodrÃ­guez-Barroso, Mario GarcÃ­a-MÃ¡rquez, M. Victoria LuzÃ³n, Francisco Herrera</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> In recent years, the development of Trustworthy Artificial Intelligence (TAI) has emerged as a critical objective in the deployment of AI systems across sensitive and high-risk domains. TAI frameworks articulate a comprehensive set of ethical, legal, and technical requirements to ensure that AI technologies are aligned with human values, rights, and societal expectations. Among the various AI paradigms, Federated Learning (FL) presents a promising solution to pressing privacy concerns. However, aligning FL with the rest of the requirements of TAI presents a series of challenges, most of which arise from its inherently distributed nature. In this work, we adopt the requirements TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. Specifically, we classify and examine the key obstacles to aligning FL with TAI, providing a detailed exploration of what has been done, the trends, and the remaining work within each of the identified challenges.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15795v1" target="_blank">Quantum gravity black holes as dark matter?</a></h3>
                    <p><strong>Authors:</strong> Bernard Carr, Piero Nicolini, Athanasios G. Tzikas</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> One of the major problems in quantum gravity research is the lack of signals at the reach of present or near-future experimental facilities. In this paper, we show that this is not the case. Contrary to previous claims, the quantum decay of de Sitter space into black hole spacetimes can be significant even after inflation and can be observed on galactic scales. Using the instanton formalism within the no-boundary proposal for a class of short-scale, quantum-gravity-improved black holes, we show that de Sitter space decay would result in the production of $10^{60}$ stable Planck-size black hole remnants within the current Hubble horizon, which is the number required to explain dark matter.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15793v1" target="_blank">Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation</a></h3>
                    <p><strong>Authors:</strong> Ghassen Baklouti, Julio Silva-RodrÃ­guez, Jose Dolz, Houda Bahig, Ismail Ben Ayed</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is increasingly attracting interest in medical imaging due to its effectiveness and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA) is a notable approach based on the assumption that the adaptation inherently occurs in a low-dimensional subspace. While it has shown good performance, its implementation requires a fixed and unalterable rank, which might be challenging to select given the unique complexities and requirements of each medical imaging downstream task. Inspired by advancements in natural image processing, we introduce a novel approach for medical image segmentation that dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank representation of the trainable weight matrices as a singular value decomposition, we introduce an l_1 sparsity regularizer to the loss function, and tackle it with a proximal optimizer. The regularizer could be viewed as a penalty on t...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15784v1" target="_blank">Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets</a></h3>
                    <p><strong>Authors:</strong> Zihang Ma, Qitian Yin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Graph node classification is a fundamental task in graph neural networks (GNNs), aiming to assign predefined class labels to nodes. On the PubMed citation network dataset, we observe significant classification difficulty disparities, with Category 2 achieving only 74.4% accuracy in traditional GCN, 7.5% lower than Category 1. To address this, we propose a Wasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM), training specialized GNN models for Categories 0/1 (with layer normalization and residual connections) and Multi-hop Graph Attention Networks (GAT) for Category 2. The WR distance metric optimizes representation similarity between models, particularly focusing on improving Category 2 performance. Our adaptive fusion strategy dynamically weights models based on category-specific performance, with Category 2 assigned a GAT weight of 0.8. WR distance further guides the fusion process by measuring distributional differences between model representations, enabling ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15782v1" target="_blank">Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs</a></h3>
                    <p><strong>Authors:</strong> Ruochu Yang, Yu Zhou, Fumin Zhang, Mengxue Hou</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Household robots have been a longstanding research topic, but they still lack human-like intelligence, particularly in manipulating open-set objects and navigating large environments efficiently and accurately. To push this boundary, we consider a generalized multi-object collection problem in large scene graphs, where the robot needs to pick up and place multiple objects across multiple locations in a long mission of multiple human commands. This problem is extremely challenging since it requires long-horizon planning in a vast action-state space under high uncertainties. To this end, we propose a novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a multimodal action cost similarity function, our algorithm can both reflect the history and look into the future to optimize plans, striking a good balance of quality and efficiency. Simulation experiments demonstrate that compared with latest works, our algorithm improves the overall mission performance by 30% in t...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15777v1" target="_blank">Label tree semantic losses for rich multi-class medical image segmentation</a></h3>
                    <p><strong>Authors:</strong> Junwen Wang, Oscar MacCormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Rich and accurate medical image segmentation is poised to underpin the next generation of AI-defined clinical practice by delineating critical anatomy for pre-operative planning, guiding real-time intra-operative navigation, and supporting precise post-operative assessment. However, commonly used learning methods for medical and surgical imaging segmentation tasks penalise all errors equivalently and thus fail to exploit any inter-class semantics in the labels space. This becomes particularly problematic as the cardinality and richness of labels increases to include subtly different classes. In this work, we propose two tree-based semantic loss functions which take advantage of a hierarchical organisation of the labels. We further incorporate our losses in a recently proposed approach for training with sparse, background-free annotations to extend the applicability of our proposed losses. Extensive experiments are reported on two medical and surgical image segmentation tasks, namely he...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15772v1" target="_blank">Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis</a></h3>
                    <p><strong>Authors:</strong> Anoop C. Patil, Benny Jian Rong Sng, Yu-Wei Chang, Joana B. Pereira, Chua Nam-Hai, Rajani Sarojam, Gajendra Pratap Singh, In-Cheol Jang, Giovanni Volpe</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, q-bio.BM</p>
                    <p><strong>Summary:</strong> Detecting stress in plants is crucial for both open-farm and controlled-environment agriculture. Biomolecules within plants serve as key stress indicators, offering vital markers for continuous health monitoring and early disease detection. Raman spectroscopy provides a powerful, non-invasive means to quantify these biomolecules through their molecular vibrational signatures. However, traditional Raman analysis relies on customized data-processing workflows that require fluorescence background removal and prior identification of Raman peaks of interest-introducing potential biases and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis), a fully automated workflow based on a variational autoencoder. Unlike conventional approaches, DIVA processes native Raman spectra-including fluorescence backgrounds-without manual preprocessing, identifying and quantifying significant spectral features in an unbiased manner...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15771v1" target="_blank">Left Leaning Models: AI Assumptions on Economic Policy</a></h3>
                    <p><strong>Authors:</strong> Maxim Chupilkin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> How does AI think about economic policy? While the use of large language models (LLMs) in economics is growing exponentially, their assumptions on economic issues remain a black box. This paper uses a conjoint experiment to tease out the main factors influencing LLMs evaluation of economic policy. It finds that LLMs are most sensitive to unemployment, inequality, financial stability, and environmental harm and less sensitive to traditional macroeconomic concerns such as economic growth, inflation, and government debt. The results are remarkably consistent across scenarios and across models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15770v1" target="_blank">A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining</a></h3>
                    <p><strong>Authors:</strong> Yifan Shen, Zihan Zhao, Xiao Xue, Yuwei Guo, Qun Ma, Deyu Zhou, Ming Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15761v1" target="_blank">GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts</a></h3>
                    <p><strong>Authors:</strong> Jingyi Zheng, Zifan Peng, Yule Liu, Junfeng Wang, Yifan Liao, Wenhan Dong, Xinlei He</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15760v1" target="_blank">Fourier Plane Tomographic Spectroscopy Reveals Orientation-Dependent Multipolar Plasmon Modes in Micrometer-Scale Janus Particles</a></h3>
                    <p><strong>Authors:</strong> Felix H. Patzschke, Frank Cichos</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> physics.optics, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Plasmonic Janus particles, comprising dielectric cores with thin metallic caps, exhibit complex optical properties due to their asymmetric structure. Despite applications in active matter research, their orientation-dependent scattering properties remain largely unexplored. We introduce Fourier plane tomographic spectroscopy for simultaneous four-dimensional characterization of scattering from individual micrometer-scale particles across wavelength, incident angle, scattering angle, and polarization. Combining measurements with finite-element simulations, we identify discrete spectral markers in visible and near-infrared regions that evolve predictably with cap orientation. Spherical-harmonics decomposition reveals these markers arise from three distinct multipolar modes up to fifth order: axial-propagating transverse-electric, transverse-propagating transverse-electric, and transverse-propagating axial-electric, with retardation-induced splitting. We observe progressive red-shifts and...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15759v1" target="_blank">Interaction as Intelligence: Deep Research With Human-AI Partnership</a></h3>
                    <p><strong>Authors:</strong> Lyumanshan Ye, Xiaojie Cai, Xinkai Wang, Junfei Wang, Xiangkun Hu, Jiadi Su, Yang Nan, Sihan Wang, Bohan Zhang, Xiaoze Fan, Jinbin Luo, Yuxiang Zheng, Tianze Xu, Dayuan Fu, Yunze Wu, Pengrui Lu, Zengzhi Wang, Yiwei Qin, Zhen Huang, Yan Ma, Zhulin Hu, Haoyang Zou, Tiantian Mi, Yixin Ye, Ethan Chern, Pengfei Liu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper introduces Interaction as Intelligence research series, presenting a reconceptualization of human-AI relationships in deep research tasks. Traditional approaches treat interaction merely as an interface for accessing AI capabilities-a conduit between human intent and machine output. We propose that interaction itself constitutes a fundamental dimension of intelligence. As AI systems engage in extended thinking processes for research tasks, meaningful interaction transitions from an optional enhancement to an essential component of effective intelligence. Current deep research systems adopt an input-wait-output paradigm where users initiate queries and receive results after black-box processing. This approach leads to error cascade effects, inflexible research boundaries that prevent question refinement during investigation, and missed opportunities for expertise integration. To address these limitations, we introduce Deep Cognition, a system that transforms the human role fr...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15752v1" target="_blank">DialogueForge: LLM Simulation of Human-Chatbot Dialogue</a></h3>
                    <p><strong>Authors:</strong> Ruizhe Zhu, Hao Zhu, Yaxuan Li, Syang Zhou, Shijing Cai, Malgorzata Lazuka, Elliott Ash</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Collecting human-chatbot dialogues typically demands substantial manual effort and is time-consuming, which limits and poses challenges for research on conversational AI. In this work, we propose DialogueForge - a framework for generating AI-simulated conversations in human-chatbot style. To initialize each generated conversation, DialogueForge uses seed prompts extracted from real human-chatbot interactions. We test a variety of LLMs to simulate the human chatbot user, ranging from state-of-the-art proprietary models to small-scale open-source LLMs, and generate multi-turn dialogues tailored to specific tasks. In addition, we explore fine-tuning techniques to enhance the ability of smaller models to produce indistinguishable human-like dialogues. We evaluate the quality of the simulated conversations and compare different models using the UniEval and GTEval evaluation protocols. Our experiments show that large proprietary models (e.g., GPT-4o) generally outperform others in generating...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15743v1" target="_blank">Towards physician-centered oversight of conversational diagnostic AI</a></h3>
                    <p><strong>Authors:</strong> Elahe Vedadi, David Barrett, Natalie Harris, Ellery Wulczyn, Shashir Reddy, Roma Ruparel, Mike Schaekermann, Tim Strother, Ryutaro Tanno, Yash Sharma, Jihyeon Lee, CÃ­an Hughes, Dylan Slack, Anil Palepu, Jan Freyberg, Khaled Saab, Valentin LiÃ©vin, Wei-Hung Weng, Tao Tu, Yun Liu, Nenad Tomasev, Kavita Kulkarni, S. Sara Mahdavi, Kelvin Guu, JoÃ«lle Barral, Dale R. Webster, James Manyika, Avinatan Hassidim, Katherine Chou, Yossi Matias, Pushmeet Kohli, Adam Rodman, Vivek Natarajan, Alan Karthikesalingam, David Stutz</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchro...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15736v1" target="_blank">Understanding Large Language Models Ability on Interdisciplinary Research</a></h3>
                    <p><strong>Authors:</strong> Yuanhao Shen, Daniel Xavier de Sousa, Ricardo MarÃ§al, Ali Asad, Hongyu Guo, Xiaodan Zhu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models (LLMs) have revealed their impressive ability to perform multi-step, logic-driven reasoning across complex domains, positioning them as powerful tools and collaborators in scientific discovery while challenging the long-held view that inspiration-driven ideation is uniquely human. However, the lack of a dedicated benchmark that evaluates LLMs ability to develop ideas in Interdisciplinary Research (IDR) settings poses a critical barrier to fully understanding their strengths and limitations. To address this gap, we introduce IDRBench -- a pioneering benchmark featuring an expert annotated dataset and a suite of tasks tailored to evaluate LLMs capabilities in proposing valuable research ideas from different scientific domains for interdisciplinary research. This benchmark aims to provide a systematic framework for assessing LLM performance in complex, cross-domain scientific research. Our dataset consists of scientific publications sourced fro...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15734v1" target="_blank">TONUS: Neuromorphic human pose estimation for artistic sound co-creation</a></h3>
                    <p><strong>Authors:</strong> Jules Lecomte, Konrad Zinner, Michael Neumeier, Axel von Arnim</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.NE</p>
                    <p><strong>Summary:</strong> Human machine interaction is a huge source of inspiration in todays media art and digital design, as machines and humans merge together more and more. Its place in art reflects its growing applications in industry, such as robotics. However, those interactions often remains too technical and machine-driven for people to really engage into. On the artistic side, new technologies are often not explored in their full potential and lag a bit behind, so that state-of-the-art research does not make its way up to museums and exhibitions. Machines should support peoples imagination and poetry in a seamless interface to their body or soul. We propose an artistic sound installation featuring neuromorphic body sensing to support a direct yet non intrusive interaction with the visitor with the purpose of creating sound scapes together with the machine. We design a neuromorphic multihead human pose estimation neural sensor that shapes sound scapes and visual output with fine body movement control. ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15724v1" target="_blank">A Practical Investigation of Spatially-Controlled Image Generation with Transformers</a></h3>
                    <p><strong>Authors:</strong> Guoxuan Xia, Harleen Hanspal, Petru-Daniel Tudosiu, Shifeng Zhang, Sarah Parisot</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Enabling image generation models to be spatially controlled is an important area of research, empowering users to better generate images according to their own fine-grained specifications via e.g. edge maps, poses. Although this task has seen impressive improvements in recent times, a focus on rapidly producing stronger models has come at the cost of detailed and fair scientific comparison. Differing training data, model architectures and generation paradigms make it difficult to disentangle the factors contributing to performance. Meanwhile, the motivations and nuances of certain approaches become lost in the literature. In this work, we aim to provide clear takeaways across generation paradigms for practitioners wishing to develop transformer-based systems for spatially-controlled generation, clarifying the literature and addressing knowledge gaps. We perform controlled experiments on ImageNet across diffusion-based/flow-based and autoregressive (AR) models. First, we establish contr...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15717v1" target="_blank">BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning</a></h3>
                    <p><strong>Authors:</strong> Sahana Srinivasan, Xuguang Ai, Thaddaeus Wai Soon Lo, Aidan Gilson, Minjie Zou, Ke Zou, Hyunjae Kim, Mingjia Yang, Krithi Pushpanathan, Samantha Yew, Wan Ting Loke, Jocelyn Goh, Yibing Chen, Yiming Kong, Emily Yuelei Fu, Michelle Ongyong Hui, Kristen Nwanyanwu, Amisha Dave, Kelvin Zhenghao Li, Chen-Hsin Sun, Mark Chia, Gabriel Dawei Yang, Wendy Meihua Wong, David Ziyou Chen, Dianbo Liu, Maxwell Singer, Fares Antaki, Lucian V Del Priore, Jost Jonas, Ron Adelman, Qingyu Chen, Yih-Chung Tham</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Current benchmarks evaluating large language models (LLMs) in ophthalmology are limited in scope and disproportionately prioritise accuracy. We introduce BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive evaluation benchmark developed through multiple rounds of expert checking by 13 ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset underwent multiple rounds of expert checking. Duplicate and substandard questions were systematically removed. Ten ophthalmologists refined the explanations of each MCQs correct answer. This was further adjudicated by three senior ophthalmologists. To illustrate BELOs utility, we evaluated six LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro) using a...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15715v1" target="_blank">From Queries to Criteria: Understanding How Astronomers Evaluate LLMs</a></h3>
                    <p><strong>Authors:</strong> Alina Hyk, Kiera McCormick, Mian Zhong, Ioana CiucÄƒ, Sanjib Sharma, John F Wu, J. E. G. Peek, Kartheik G. Iyer, Ziang Xiao, Anjalie Field</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, astro-ph.IM</p>
                    <p><strong>Summary:</strong> There is growing interest in leveraging LLMs to aid in astronomy and other scientific research, but benchmarks for LLM evaluation in general have not kept pace with the increasingly diverse ways that real people evaluate and use these models. In this study, we seek to improve evaluation procedures by building an understanding of how users evaluate LLMs. We focus on a particular use case: an LLM-powered retrieval-augmented generation bot for engaging with astronomical literature, which we deployed via Slack. Our inductive coding of 368 queries to the bot over four weeks and our follow-up interviews with 11 astronomers reveal how humans evaluated this system, including the types of questions asked and the criteria for judging responses. We synthesize our findings into concrete recommendations for building better benchmarks, which we then employ in constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our work offers ways to improve LLM evaluation and ultimately usab...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15714v1" target="_blank">Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Models Capability of Emotion Perception using Contrastive Learning</a></h3>
                    <p><strong>Authors:</strong> Tian Li, Yujian Sun, Huizhi Liang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection, introduces an emotion recognition challenge spanning over 28 languages. This competition encourages researchers to explore more advanced approaches to address the challenges posed by the diversity of emotional expressions and background variations. It features two tracks: multi-label classification (Track A) and emotion intensity prediction (Track B), covering six emotion categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we systematically explore the benefits of two contrastive learning approaches: sample-based (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO) contrastive learning. The sample-based contrastive approach trains the model by comparing two samples to generate more reliable predictions. The generation-based contrastive approach trains the model to differentiate between correct and incorrect generations, refining its prediction. All models are fine-tuned f...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15693v1" target="_blank">Strong, Accurate, and Low-Cost Robot Manipulator</a></h3>
                    <p><strong>Authors:</strong> Georges Chebly, Spencer Little, Nisal Perera, Aliya Abedeen, Ken Suzuki, Donghyun Kim</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach, and sub-millimeter repeatability - at a material cost under $215. As an accessible robot for broad applications across classroom education to AI experiments, Forte pushes forward the performance limitations of existing low-cost educational arms. We introduce a cost-effective mechanical design that combines capstan-based cable drives, timing belts, simple tensioning mechanisms, and lightweight 3D-printed structures, along with topology optimization for structural stiffness. Through careful drivetrain engineering, we minimize backlash and maintain control fidelity without relying on high-power electronics or expensive manufacturing processes. Experimental validation demonstrates that Forte achieves high repeatability and load capacity, offering a compelling robotic platform for both classroom instruction and advanced robotics research.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3663547.3746393" target="_blank">Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions</a></h3>
                    <p><strong>Authors:</strong> Meng Chen, Akhil Iyer, Amy Pavel</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users ability t...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15686v1" target="_blank">LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression</a></h3>
                    <p><strong>Authors:</strong> Wenjie Huang, Qi Yang, Shuting Xia, He Huang, Zhu Li, Yiling Xu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, i...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15676v1" target="_blank">Agentic AI for autonomous anomaly management in complex systems</a></h3>
                    <p><strong>Authors:</strong> Reza Vatankhah Barenji, Sina Khoshgoftar</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.ET</p>
                    <p><strong>Summary:</strong> This paper explores the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems, emphasizing its ability to transform traditional, human-dependent anomaly management methods.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.comnet.2025.111365" target="_blank">Vehicular Cloud Computing: A cost-effective alternative to Edge Computing in 5G networks</a></h3>
                    <p><strong>Authors:</strong> Rosario PatanÃ¨, Nadjib Achir, Andrea Araldo, Lila Boukhatem</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> Edge Computing (EC) is a computational paradigm that involves deploying resources such as CPUs and GPUs near end-users, enabling low-latency applications like augmented reality and real-time gaming. However, deploying and maintaining a vast network of EC nodes is costly, which can explain its limited deployment today. A new paradigm called Vehicular Cloud Computing (VCC) has emerged and inspired interest among researchers and industry. VCC opportunistically utilizes existing and idle vehicular computational resources for external task offloading. This work is the first to systematically address the following question: Can VCC replace EC for low-latency applications? Answering this question is highly relevant for Network Operators (NOs), as VCC could eliminate costs associated with EC given that it requires no infrastructural investment. Despite its potential, no systematic study has yet explored the conditions under which VCC can effectively support low-latency applications without rel...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15650v1" target="_blank">Chapter 11 Students interaction with and appreciation of automated informative tutoring feedback</a></h3>
                    <p><strong>Authors:</strong> Gerben van der Hoek, Bastiaan Heeren, Rogier Bos, Paul Drijvers, Johan Jeuring</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Computer aided formative assessment can be used to enhance a learning process, for instance by providing feedback. There are many design choices for delivering feedback, that lead to a feedback strategy. In an informative feedback strategy, students do not immediately receive information about the correct response, but are offered the opportunity to retry a task to apply feedback information. In this small-scale qualitative study, we explore an informative feedback strategy designed to offer a balance between room for exploration and mitigation of learning barriers. The research questions concern the ways in which students interact with the feedback strategy and their appreciation of error-specific feedback as opposed to worked-out solutions. To answer these questions, twenty-five 15-to-17-year-old senior general secondary education students worked for approximately 20 minutes on linear and exponential extrapolation tasks in an online environment. Data included screen captures of stude...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15649v1" target="_blank">EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation</a></h3>
                    <p><strong>Authors:</strong> Haocheng Xu, Haodong Zhang, Zhenghan Chen, Rong Xiong</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> To support humanoid robots in performing manipulation tasks, it is essential to study stable standing while accommodating upper-body motions. However, the limited controllable range of humanoid robots in a standing position affects the stability of the entire body. Thus we introduce a reinforcement learning based framework for humanoid robots to imitate human upper-body motions while maintaining overall stability. Our approach begins with designing a retargeting network that generates a large-scale upper-body motion dataset for training the reinforcement learning (RL) policy, which enables the humanoid robot to track upper-body motion targets, employing domain randomization for enhanced robustness. To avoid exceeding the robots execution capability and ensure safety and stability, we propose an Executable Motion Prior (EMP) module, which adjusts the input target movements based on the robots current state. This adjustment improves standing stability while minimizing changes to motion a...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15641v1" target="_blank">Leveraging Context for Multimodal Fallacy Classification in Political Debates</a></h3>
                    <p><strong>Authors:</strong> Alessio Pittiglio</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> In this paper, we present our submission to the MM-ArgFallacy2025 shared task, which aims to advance research in multimodal argument mining, focusing on logical fallacies in political debates. Our approach uses pretrained Transformer-based models and proposes several ways to leverage context. In the fallacy classification subtask, our models achieved macro F1-scores of 0.4444 (text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed performance comparable to the text-only model, suggesting potential for improvements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15639v1" target="_blank">Brain rhythms in cognition -- controversies and future directions</a></h3>
                    <p><strong>Authors:</strong> Anne Keitel, Christian Keitel, Mohsen Alavash, Karin Bakardjian, Christopher S. Y. Benwell, Sophie Bouton, Niko A. Busch, Antonio Criscuolo, Keith B. Doelling, Laura Dugue, Laetitia Grabot, Joachim Gross, Simon Hanslmayr, Laura-Isabelle Klatt, Daniel S. Kluger, Gemma Learmonth, Raquel E. London, Christina Lubinus, Andrea E. Martin, Jonas Obleser, Johanna M. Rimmele, Vincenzo Romei, Manuela Ruzzoli, Felix Siebenhuhner, Sophie Slaats, Eelke Spaak, Luca Tarasi, Gregor Thut, Jelena Trajkovic, Danying Wang, Malte Wostmann, Benedikt Zoefel, Satu Palva, Paul Sauseng, Sonja A. Kotz</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC</p>
                    <p><strong>Summary:</strong> Brain rhythms seem central to understanding the neurophysiological basis of human cognition. Yet, despite significant advances, key questions remain unresolved. In this comprehensive position paper, we review the current state of the art on oscillatory mechanisms and their cognitive relevance. The paper critically examines physiological underpinnings, from phase-related dynamics like cyclic excitability, to amplitude-based phenomena, such as gating by inhibition, and their interactions, such as phase-amplitude coupling, as well as frequency dynamics, like sampling mechanisms. We also critically evaluate future research directions, including travelling waves and brain-body interactions. We then provide an in-depth analysis of the role of brain rhythms across cognitive domains, including perception, attention, memory, and communication, emphasising ongoing debates and open questions in each area. By summarising current theories and highlighting gaps, this position paper offers a roadmap ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15633v1" target="_blank">Experimenting active and sequential learning in a medieval music manuscript</a></h3>
                    <p><strong>Authors:</strong> Sachin Sharma, Federico Simonetta, Michele Flammini</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, I.2.10; I.4.8; H.3.3</p>
                    <p><strong>Summary:</strong> Optical Music Recognition (OMR) is a cornerstone of music digitization initiatives in cultural heritage, yet it remains limited by the scarcity of annotated data and the complexity of historical manuscripts. In this paper, we present a preliminary study of Active Learning (AL) and Sequential Learning (SL) tailored for object detection and layout recognition in an old medieval music manuscript. Leveraging YOLOv8, our system selects samples with the highest uncertainty (lowest prediction confidence) for iterative labeling and retraining. Our approach starts with a single annotated image and successfully boosts performance while minimizing manual labeling. Experimental results indicate that comparable accuracy to fully supervised training can be achieved with significantly fewer labeled examples. We test the methodology as a preliminary investigation on a novel dataset offered to the community by the Anonymous project, which studies laude, a poetical-musical genre spread across Italy duri...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15624v1" target="_blank">Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow</a></h3>
                    <p><strong>Authors:</strong> Yusuf Sulistyo Nugroho, Ganno Tribuana Kurniaji, Syful Islam, Mohammed Humayun Kabir, Vanesya Aura Ardity, Md. Kamal Uddin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> React is a JavaScript library used to build user interfaces for single-page applications. Although recent studies have shown the popularity and advantages of React in web development, the specific challenges users face remain unknown. Thus, this study aims to analyse the React-related questions shared on Stack Overflow. The study utilizes an exploratory data analysis to investigate the most frequently discussed keywords, error classification, and user reputation-based errors, which is the novelty of this work. The results show the top eight most frequently used keywords on React-related questions, namely, code, link, vir, href, connect, azure, windows, and website. The error classification of questions from the sample shows that algorithmic error is the most frequent issue faced by all groups of users, where mid-reputation users contribute the most, accounting for 55.77%. This suggests the need for the community to provide guidance materials in solving algorithm-related problems. We ex...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15619v1" target="_blank">Dynamic Investigation of the New Quantum-Control-Assisted Reverse uncertainty relation</a></h3>
                    <p><strong>Authors:</strong> Qiyi Li, Shaoqiang Ma, Sansheng Wang, Xiao Zheng, Guofeng Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Recently, a new interesting concept of reverse uncertainty relation is introduced. Different from the normal uncertainty relation, the reverse one indicates that one cannot only prepare quantum states with joint small uncertainty, but also with joint great uncertainty for incompatible observables. We in this work construct a new quantum-control-assisted reverse uncertainty relation and investigate the corresponding dynamic evolution in the Heisenberg model with Dzyaloshinskii-Moriya interaction. The obtained relation indicates that the reverse uncertainty can be broken with help of the quantum control system. The dynamic investigation reveals that there exists an interesting single-value relationship between new uncertainty relation and the mixedness of the system, indicating that the tightness and upper bound of the uncertainty relation can be written as functional form of the mixedness. By comparing the existing research in [Physica Scripta 2023, 98(6), 065113], we show that the sing...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15618v1" target="_blank">TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II</a></h3>
                    <p><strong>Authors:</strong> Weiyu Ma, Jiwen Jiang, Haobo Fu, Haifeng Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We present an adapter-based approach for tactical conditioning of StarCraft II AI agents. Current agents, while powerful, lack the ability to adapt their strategies based on high-level tactical directives. Our method freezes a pre-trained policy network (DI-Star) and attaches lightweight adapter modules to each action head, conditioned on a tactical tensor that encodes strategic preferences. By training these adapters with KL divergence constraints, we ensure the policy maintains core competencies while exhibiting tactical variations. Experimental results show our approach successfully modulates agent behavior across tactical dimensions including aggression, expansion patterns, and technology preferences, while maintaining competitive performance. Our method enables flexible tactical control with minimal computational overhead, offering practical strategy customization for complex real-time strategy games.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15617v1" target="_blank">Why cant Epidemiology be automated (yet)?</a></h3>
                    <p><strong>Authors:</strong> David Bann, Ed Lowther, Liam Wright, Yevgeniya Kovalchuk</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advances in artificial intelligence (AI) - particularly generative AI - present new opportunities to accelerate, or even automate, epidemiological research. Unlike disciplines based on physical experimentation, a sizable fraction of Epidemiology relies on secondary data analysis and thus is well-suited for such augmentation. Yet, it remains unclear which specific tasks can benefit from AI interventions or where roadblocks exist. Awareness of current AI capabilities is also mixed. Here, we map the landscape of epidemiological tasks using existing datasets - from literature review to data access, analysis, writing up, and dissemination - and identify where existing AI tools offer efficiency gains. While AI can increase productivity in some areas such as coding and administrative tasks, its utility is constrained by limitations of existing AI models (e.g. hallucinations in literature reviews) and human systems (e.g. barriers to accessing datasets). Through examples of AI-generated ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15613v1" target="_blank">Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems</a></h3>
                    <p><strong>Authors:</strong> Andrii Balashov, Olena Ponomarova, Xiaohua Zhai</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) deployed in enterprise settings (e.g., as Microsoft 365 Copilot) face novel security challenges. One critical threat is prompt inference attacks: adversaries chain together seemingly benign prompts to gradually extract confidential data. In this paper, we present a comprehensive study of multi-stage prompt inference attacks in an enterprise LLM context. We simulate realistic attack scenarios where an attacker uses mild-mannered queries and indirect prompt injections to exploit an LLM integrated with private corporate data. We develop a formal threat model for these multi-turn inference attacks and analyze them using probability theory, optimization frameworks, and information-theoretic leakage bounds. The attacks are shown to reliably exfiltrate sensitive information from the LLMs context (e.g., internal SharePoint documents or emails), even when standard safety measures are in place. We propose and evaluate defenses to counter such attacks, including stati...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15605v1" target="_blank">Unconventional photon blockade in a hybrid optomechanical system with an embedded spin-triplet</a></h3>
                    <p><strong>Authors:</strong> Yao Dong, Jing-jing Wang, Guo-Feng Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> The research article studies the unconventional photon blockade effect in a hybrid optomechanical system with an embedded spin-triplet state. The interaction between the optomechanical system and the spin state generates new transition paths for the destructive quantum interference of the two-photon excitation state. By analytically solving the Schrodinger equation and numerically simulating the master equation, it can be found that the modulated mechanical dissipation is essential for achieving the strong photon blockade in our system. Unlike the conventional cavity optomechanical system, the second-order correlation function g(2)(0) =0 can be obtained with the weak single-photon optomechanical coupling. By adjusting the system parameters, the strong photon blockade and the single-photon resonance can coincide, which indicates the hybrid system has the potential to be a high-quality and efficient single-photon source. Finally, the influence of the thermal noise on photon blockade is i...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15594v1" target="_blank">Improving Functional Reliability of Near-Field Monitoring for Emergency Braking in Autonomous Vehicles</a></h3>
                    <p><strong>Authors:</strong> Junnan Pan, Prodromos Sotiriadis, Vladislav Nenchev, Ferdinand Englberger</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.RO, cs.SY</p>
                    <p><strong>Summary:</strong> Autonomous vehicles require reliable hazard detection. However, primary sensor systems may miss near-field obstacles, resulting in safety risks. Although a dedicated fast-reacting near-field monitoring system can mitigate this, it typically suffers from false positives. To mitigate these, in this paper, we introduce three monitoring strategies based on dynamic spatial properties, relevant object sizes, and motion-aware prediction. In experiments in a validated simulation, we compare the initial monitoring strategy against the proposed improvements. The results demonstrate that the proposed strategies can significantly improve the reliability of near-field monitoring systems.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3748336.3748340" target="_blank">Drafting the Landscape of Computational Musicology Tools: a Survey-Based Approach</a></h3>
                    <p><strong>Authors:</strong> Jorge Junior Morgado Vega, Sachin Sharma, Federico Simonetta</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.DL, J.5</p>
                    <p><strong>Summary:</strong> Since the 60s, musicology has been increasingly impacted by computational tools in various ways, from systematic analysis approaches to modeling of creativity. This article presents a comprehensive assessment of the current state of Computational Musicology tools based on survey data collected from practitioners in the field. We gathered information on tool usage patterns, common analytical tasks, user satisfaction levels, data characteristics, and prioritized features across four distinct domains: symbolic music, music-related imagery, audio, and text. Our findings reveal significant gaps between current tooling capabilities and user needs, highlighting some limitations of these tools across all domains. This assessment contributes to the ongoing dialogue between tool developers and music scholars, aiming to enhance the effectiveness and accessibility of computational methods in musicological research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15587v1" target="_blank">Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario</a></h3>
                    <p><strong>Authors:</strong> Yinsong Chen, Kaifeng Wang, Xiaoqiang Meng, Xueyuan Li, Zirui Li, Xin Gao</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Current research on decision-making in safety-critical scenarios often relies on inefficient data-driven scenario generation or specific modeling approaches, which fail to capture corner cases in real-world contexts. To address this issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework, where background vehicles with interference capabilities are treated as red-team agents. Through active interference and exploration, red-team vehicles can uncover corner cases outside the data distribution. The framework uses a Constraint Graph Representation Markov Decision Process, ensuring that red-team vehicles comply with safety rules while continuously disrupting the autonomous vehicles (AVs). A policy threat zone model is constructed to quantify the threat posed by red-team vehicles to AVs, inducing more extreme actions to increase the danger level of the scenario. Experimental results show that the proposed framework significantly impacts AVs decision-making safety and gener...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15856v1" target="_blank">Latent Denoising Makes Good Visual Tokenizers</a></h3>
                    <p><strong>Authors:</strong> Jiawei Yang, Tianhong Li, Lijie Fan, Yonglong Tian, Yue Wang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Despite their fundamental role, it remains unclear what properties could make visual tokenizers more effective for generative modeling. We observe that modern generative models share a conceptually similar training objective -- reconstructing clean signals from corrupted inputs such as Gaussian noise or masking -- a process we term denoising. Motivated by this insight, we propose aligning tokenizer embeddings directly with the downstream denoising objective, encouraging latent embeddings to be more easily reconstructed even when heavily corrupted. To achieve this, we introduce the Latent Denoising Tokenizer (l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images from latent embeddings corrupted by interpolative noise and random masking. Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer consistently outperforms standard tokenizers across six representative generative models. Our findings highlight denoising as a fundamental design principle...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15851v1" target="_blank">The Other Mind: How Language Models Exhibit Human Temporal Cognition</a></h3>
                    <p><strong>Authors:</strong> Lingyu Li, Yang Yao, Yixu Wang, Chubo Li, Yan Teng, Yingchun Wang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> As Large Language Models (LLMs) continue to advance, they exhibit certain cognitive patterns similar to those of humans that are not directly specified in training data. This study investigates this phenomenon by focusing on temporal cognition in LLMs. Leveraging the similarity judgment task, we find that larger models spontaneously establish a subjective temporal reference point and adhere to the Weber-Fechner law, whereby the perceived distance logarithmically compresses as years recede from this reference point. To uncover the mechanisms behind this behavior, we conducted multiple analyses across neuronal, representational, and informational levels. We first identify a set of temporal-preferential neurons and find that this group exhibits minimal activation at the subjective reference point and implements a logarithmic coding scheme convergently found in biological systems. Probing representations of years reveals a hierarchical construction process, where years evolve from basic nu...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15850v1" target="_blank">3LM: Bridging Arabic, STEM, and Code through Benchmarking</a></h3>
                    <p><strong>Authors:</strong> Basma El Amel Boussaha, Leen AlQadi, Mugariya Farooq, Shaikha Alsuwaidi, Giulia Campesan, Ahmed Alzubaidi, Mohammed Alyafeai, Hakim Hacid</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Arabic is one of the most widely spoken languages in the world, yet efforts to develop and evaluate Large Language Models (LLMs) for Arabic remain relatively limited. Most existing Arabic benchmarks focus on linguistic, cultural, or religious content, leaving a significant gap in domains like STEM and code which are increasingly relevant for real-world LLM applications. To help bridge this gap, we present 3LM, a suite of three benchmarks designed specifically for Arabic. The first is a set of STEM-related question-answer pairs, naturally sourced from Arabic textbooks and educational worksheets. The second consists of synthetically generated STEM questions, created using the same sources. The third benchmark focuses on code generation, built through a careful translation of two widely used code benchmarks, incorporating a human-in-the-loop process with several rounds of review to ensure high-quality and faithful translations. We release all three benchmarks publicly to support the growt...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15846v2" target="_blank">GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding</a></h3>
                    <p><strong>Authors:</strong> Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL, cs.CV, cs.HC</p>
                    <p><strong>Summary:</strong> Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism tha...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15844v2" target="_blank">Hierarchical Budget Policy Optimization for Adaptive Reasoning</a></h3>
                    <p><strong>Authors:</strong> Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet exhibit significant computational inefficiency by applying uniform reasoning strategies regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. HBPO addresses the fundamental challenge of exploration space collapse in efficiency-oriented training, where penalties on long output length systematically bias models away from necessary long reasoning paths. Through hierarchical budget exploration, our approach partitions rollout samples into multiple subgroups with distinct token budgets, aiming to enable efficient resource allocation while preventing degradation of capability. We introduce differentiated reward mechanisms that create budget-aware incentives aligned with the complexity of the problem, allowing models to dis...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15840v1" target="_blank">TASI/CERN/KITP Lecture Notes on Toward Quantum Computing Gauge Theories of Nature</a></h3>
                    <p><strong>Authors:</strong> Zohreh Davoudi</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> hep-lat, hep-ph, nucl-th, quant-ph</p>
                    <p><strong>Summary:</strong> A hallmark of the computational campaign in nuclear and particle physics is the lattice-gauge-theory program. It continues to enable theoretical predictions for a range of phenomena in nature from the underlying Standard Model. The emergence of a new computational paradigm based on quantum computing, therefore, can introduce further advances in this program. In particular, it is believed that quantum computing will make possible first-principles studies of matter at extreme densities, and in and out of equilibrium, hence improving our theoretical description of early universe, astrophysical environments, and high-energy particle collisions. Developing and advancing a quantum-computing based lattice-gauge-theory program, therefore, is a vibrant and fast-moving area of research in theoretical nuclear and particle physics. These lecture notes introduce the topic of quantum computing lattice gauge theories in a pedagogical manner, with an emphasis on theoretical and algorithmic aspects of ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15839v1" target="_blank">FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs</a></h3>
                    <p><strong>Authors:</strong> Anh Nguyen, Sam Schafft, Nicholas Hale, John Alfaro</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Synthetic data generation has emerged as an invaluable solution in scenarios where real-world data collection and usage are limited by cost and scarcity. Large language models (LLMs) have demonstrated remarkable capabilities in producing high-fidelity, domain-relevant samples across various fields. However, existing approaches that directly use LLMs to generate each record individually impose prohibitive time and cost burdens, particularly when large volumes of synthetic data are required. In this work, we propose a fast, cost-effective method for realistic tabular data synthesis that leverages LLMs to infer and encode each fields distribution into a reusable sampling script. By automatically classifying fields into numerical, categorical, or free-text types, the LLM generates distribution-based scripts that can efficiently produce diverse, realistic datasets at scale without continuous model inference. Experimental results show that our approach outperforms traditional direct methods ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15831v1" target="_blank">Observing Fine-Grained Changes in Jupyter Notebooks During Development Time</a></h3>
                    <p><strong>Authors:</strong> Sergey Titov, Konstantin Grotov, Cristina Sarasua, Yaroslav Golubev, Dhivyabharathi Ramasamy, Alberto Bacchelli, Abraham Bernstein, Timofey Bryksin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> In software engineering, numerous studies have focused on the analysis of fine-grained logs, leading to significant innovations in areas such as refactoring, security, and code completion. However, no similar studies have been conducted for computational notebooks in the context of data science. To help bridge this research gap, we make three scientific contributions: we (1) introduce a toolset for collecting code changes in Jupyter notebooks during development time; (2) use it to collect more than 100 hours of work related to a data analysis task and a machine learning task (carried out by 20 developers with different levels of expertise), resulting in a dataset containing 2,655 cells and 9,207 cell executions; and (3) use this dataset to investigate the dynamic nature of the notebook development process and the changes that take place in the notebooks. In our analysis of the collected data, we classified the changes made to the cells between executions and found that a significant nu...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15828v1" target="_blank">Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering</a></h3>
                    <p><strong>Authors:</strong> Mauro Marcelino, Marcos Alves, Bianca Trinkenreich, Bruno Cartaxo, SÃ©rgio Soares, Simone D. J. Barbosa, Marcos Kalinowski</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> [Context] An evidence briefing is a concise and objective transfer medium that can present the main findings of a study to software engineers in the industry. Although practitioners and researchers have deemed Evidence Briefings useful, their production requires manual labor, which may be a significant challenge to their broad adoption. [Goal] The goal of this registered report is to describe an experimental protocol for evaluating LLM-generated evidence briefings for secondary studies in terms of content fidelity, ease of understanding, and usefulness, as perceived by researchers and practitioners, compared to human-made briefings. [Method] We developed an RAG-based LLM tool to generate evidence briefings. We used the tool to automatically generate two evidence briefings that had been manually generated in previous research efforts. We designed a controlled experiment to evaluate how the LLM-generated briefings compare to the human-made ones regarding perceived content fidelity, ease ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15823v1" target="_blank">Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work</a></h3>
                    <p><strong>Authors:</strong> Anton Abilov, Ke Zhang, Hemank Lamba, Elizabeth M. Olson, Joel R. Tetreault, Alejandro Jaimes</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.SI</p>
                    <p><strong>Summary:</strong> Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15822v1" target="_blank">Do AI models help produce verified bug fixes?</a></h3>
                    <p><strong>Authors:</strong> Li Huang, Ilgiz Mustafin, Marco Piccioni, Alessandro Schena, Reto Weber, Bertrand Meyer</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI</p>
                    <p><strong>Summary:</strong> Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills? To answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15821v1" target="_blank">Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks</a></h3>
                    <p><strong>Authors:</strong> Hope Schroeder, Deb Roy, Jad Kabbara</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> LLM use in annotation is becoming widespread, and given LLMs overall promising performance and speed, simply reviewing LLM annotations in interpretive tasks can be tempting. In subjective annotation tasks with multiple plausible answers, reviewing LLM outputs can change the label distribution, impacting both the evaluation of LLM performance, and analysis using these labels in a social science task downstream. We conducted a pre-registered experiment with 410 unique annotators and over 7,000 annotations testing three AI assistance conditions against controls, using two models, and two datasets. We find that presenting crowdworkers with LLM-generated annotation suggestions did not make them faster, but did improve their self-reported confidence in the task. More importantly, annotators strongly took the LLM suggestions, significantly changing the label distribution compared to the baseline. When these labels created with LLM assistance are used to evaluate LLM performance, reported mode...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15819v1" target="_blank">Euclid preparation: Expected constraints on initial conditions</a></h3>
                    <p><strong>Authors:</strong> Euclid Collaboration, F. Finelli, Y. Akrami, A. Andrews, M. Ballardini, S. Casas, D. Karagiannis, Z. Sakr, J. Valiviita, G. Alestas, N. Bartolo, J. R. Bermejo-Climent, S. Nesseris, D. Paoletti, D. Sapone, I. Tutusaus, A. AchÃºcarro, G. CaÃ±as-Herrera, J. Jasche, G. Lavaux, N. Aghanim, B. Altieri, A. Amara, L. Amendola, S. Andreon, N. Auricchio, C. Baccigalupi, D. Bagot, M. Baldi, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, S. Camera, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, S. de la Torre, G. De Lucia, A. M. Di Giorgio, H. Dole, M. Douspis, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, F. Faustini, S. Ferriol, P. Fosalba, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. KeihÃ¤nen, S. Kermiche, A. Kiessling, B. Kubik, M. KÃ¼mmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, B. Sartoris, M. Schirmer, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, P. Simon, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-CrespÃ­, D. Tavagnacco, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, L. Valenziano, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, V. Allevato, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, J. MartÃ­n-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. A. Nucita, A. Pezzotta, M. PÃ¶ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, I. T. Andika, M. Archidiacono, F. Atrio-Barandela, S. Avila, A. Balaguera-Antolinez, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, H. BÃ¶hringer, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, S. Davini, F. De Paolis, G. Desprez, A. DÃ­az-SÃ¡nchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, J. GarcÃ­a-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, A. Gruppuso, M. Guidi, C. M. Gutierrez, S. Hemmati, C. HernÃ¡ndez-Monteagudo, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, Y. Kang, V. Kansal, K. Kiiveri, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, V. Le Brun, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, J. Macias-Perez, G. Maggio, M. Magliocchetti, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Migliaccio, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, A. Navarro-Alsina, L. Pagano, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, P. Reimberg, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. SahlÃ©n, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, F. Vernizzi, G. Verza, P. Vielzeuf, N. A. Walton</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> The Euclid mission of the European Space Agency will deliver galaxy and cosmic shear surveys, which will be used to constrain initial conditions and statistics of primordial fluctuations. We present highlights for the Euclid scientific capability to test initial conditions beyond LCDM with the main probes, i.e. 3D galaxy clustering from the spectroscopic survey, the tomographic approach to 3x2pt statistics from photometric galaxy survey, and their combination. We provide Fisher forecasts from the combination of Euclid spectroscopic and photometric surveys for spatial curvature, running of the spectral index of the power spectrum of curvature perturbations, isocurvature perturbations, and primordial features. For the parameters of these models we also provide the combination of Euclid forecasts (pessimistic and optimistic) with current and future measurements of the cosmic microwave background (CMB) anisotropies., i.e. Planck, the Simons Observatory (SO), and CMB-S4. We provide Fisher f...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15804v1" target="_blank">1D Vlasov Simulations of QED Cascades Over Pulsar Polar Caps</a></h3>
                    <p><strong>Authors:</strong> Dingyi Ye, Alexander Y. Chen</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE</p>
                    <p><strong>Summary:</strong> Recent developments in the study of pulsar radio emission revealed that the microphysics of quantum electrodynamic (QED) pair cascades at pulsar polar caps may be responsible for generating the observed coherent radio waves. However, modeling the pair cascades in the polar cap region poses significant challenges, particularly under conditions of high plasma multiplicity. Traditional Particle-in-Cell (PIC) methods often face rapidly increasing computational costs as the multiplicity grows exponentially. To address this issue, we present a new simulation code using the Vlasov method, which efficiently simulates the evolution of charged particle distribution functions in phase space without a proportional increase in computational expense at high multiplicities. We apply this code to study $e^\pm$ pair cascades in 1D, incorporating key physical processes such as curvature radiation, radiative cooling, and magnetic pair production. We study both the Ruderman-Sutherland (RS) and the Space-c...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15798v1" target="_blank">Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models</a></h3>
                    <p><strong>Authors:</strong> Lilian Hollard, Lucas Mohimont, Nathalie Gaveau, Luiz-Angelo Steffenel</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The paper investigates the performance of state-of-the-art low-parameter deep neural networks for computer vision, focusing on bottleneck architectures and their behavior using superlinear activation functions. We address interference in feature maps, a phenomenon associated with superposition, where neurons simultaneously encode multiple characteristics. Our research suggests that limiting interference can enhance scaling and accuracy in very low-scaled networks (under 1.5M parameters). We identify key design elements that reduce interference by examining various bottleneck architectures, leading to a more efficient neural network. Consequently, we propose a proof-of-concept architecture named NoDepth Bottleneck built on mechanistic insights from our experiments, demonstrating robust scaling accuracy on the ImageNet dataset. These findings contribute to more efficient and scalable neural networks for the low-parameter range and advance the understanding of bottlenecks in computer visi...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15796v1" target="_blank">Challenges of Trustworthy Federated Learning: Whats Done, Current Trends and Remaining Work</a></h3>
                    <p><strong>Authors:</strong> Nuria RodrÃ­guez-Barroso, Mario GarcÃ­a-MÃ¡rquez, M. Victoria LuzÃ³n, Francisco Herrera</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> In recent years, the development of Trustworthy Artificial Intelligence (TAI) has emerged as a critical objective in the deployment of AI systems across sensitive and high-risk domains. TAI frameworks articulate a comprehensive set of ethical, legal, and technical requirements to ensure that AI technologies are aligned with human values, rights, and societal expectations. Among the various AI paradigms, Federated Learning (FL) presents a promising solution to pressing privacy concerns. However, aligning FL with the rest of the requirements of TAI presents a series of challenges, most of which arise from its inherently distributed nature. In this work, we adopt the requirements TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. Specifically, we classify and examine the key obstacles to aligning FL with TAI, providing a detailed exploration of what has been done, the trends, and the remaining work within each of the identified challenges.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15795v1" target="_blank">Quantum gravity black holes as dark matter?</a></h3>
                    <p><strong>Authors:</strong> Bernard Carr, Piero Nicolini, Athanasios G. Tzikas</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> One of the major problems in quantum gravity research is the lack of signals at the reach of present or near-future experimental facilities. In this paper, we show that this is not the case. Contrary to previous claims, the quantum decay of de Sitter space into black hole spacetimes can be significant even after inflation and can be observed on galactic scales. Using the instanton formalism within the no-boundary proposal for a class of short-scale, quantum-gravity-improved black holes, we show that de Sitter space decay would result in the production of $10^{60}$ stable Planck-size black hole remnants within the current Hubble horizon, which is the number required to explain dark matter.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15794v1" target="_blank">Chasing the formation history of the Galactic metal-poor disc</a></h3>
                    <p><strong>Authors:</strong> Xiaokun Hou, Ruizhi Zhang, Haining Li, Gang Zhao</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> In our previous work, we identified $\sim100,000$ metal-poor stars ([Fe/H] $$ -1.5; (2) debris stars from the progenitor galaxy of Gaia-Sausage-Enceladus (GSE), but now residing in the Galactic disc; (3) the metal-poor tail of the metal-rich, high-$\alpha$ disc formed 10-12 Gyr ago, with metallicity lower limit extending to -2.0; (4) the metal-poor tail of the metal-rich, low-$\alpha$ disc younger than 8 Gyr, reaching a lower metallicity limit of -1.8. These results reveal the presence of a primordial disc and show that both high-$\alpha$ and low-$\alpha$ discs reach lower metallicities than previously thought. Analysis of merger debris reveals that Wukong, with extremely low metallicity, likely originate from merger events distinct from GSE. Additionally, three new substructures are identified: ShangGu-1, characterized by unusual [Fe/H]-eccentricity correlations; ShangGu-2, possibly heated disc stars; and ShangGu-3, which can be divided into four subgroups based on differing orbital d...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15793v1" target="_blank">Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation</a></h3>
                    <p><strong>Authors:</strong> Ghassen Baklouti, Julio Silva-RodrÃ­guez, Jose Dolz, Houda Bahig, Ismail Ben Ayed</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is increasingly attracting interest in medical imaging due to its effectiveness and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA) is a notable approach based on the assumption that the adaptation inherently occurs in a low-dimensional subspace. While it has shown good performance, its implementation requires a fixed and unalterable rank, which might be challenging to select given the unique complexities and requirements of each medical imaging downstream task. Inspired by advancements in natural image processing, we introduce a novel approach for medical image segmentation that dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank representation of the trainable weight matrices as a singular value decomposition, we introduce an l_1 sparsity regularizer to the loss function, and tackle it with a proximal optimizer. The regularizer could be viewed as a penalty on t...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15786v1" target="_blank">A Robust COTS Objective for Diffraction-Limited, High-NA, Long Front Working Distance Imaging</a></h3>
                    <p><strong>Authors:</strong> Jiafeng Cui, Gilles Buchs, Christopher M. Seck</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph, physics.optics, quant-ph</p>
                    <p><strong>Summary:</strong> We present a robust objective lens optimized for applications requiring both high numerical aperture (NA) and long front working distance imaging comprised of all commercial-off-the-shelf (COTS) singlet lenses. Unlike traditional designs that require separate collimation and refocusing stages, our approach directly converges imaged light to the back focal plane using a single lens group. Our configuration corrects spherical aberrations and efficiently collects light to achieve diffraction-limited performance across a wide range of wavelengths while simplifying alignment and assembly. Using this approach, we design and construct an example objective lens that features a long front working distance of 61 mm and a clipped NA of 0.30 (limited by an aperture in our experimental setup). We experimentally verify that it achieves monochromatic diffraction-limited resolution at wavelengths from 375 nm to 866 nm without requiring replacement of the lenses or changing the inter-lens spacings, and...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15784v1" target="_blank">Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets</a></h3>
                    <p><strong>Authors:</strong> Zihang Ma, Qitian Yin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Graph node classification is a fundamental task in graph neural networks (GNNs), aiming to assign predefined class labels to nodes. On the PubMed citation network dataset, we observe significant classification difficulty disparities, with Category 2 achieving only 74.4% accuracy in traditional GCN, 7.5% lower than Category 1. To address this, we propose a Wasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM), training specialized GNN models for Categories 0/1 (with layer normalization and residual connections) and Multi-hop Graph Attention Networks (GAT) for Category 2. The WR distance metric optimizes representation similarity between models, particularly focusing on improving Category 2 performance. Our adaptive fusion strategy dynamically weights models based on category-specific performance, with Category 2 assigned a GAT weight of 0.8. WR distance further guides the fusion process by measuring distributional differences between model representations, enabling ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15782v1" target="_blank">Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs</a></h3>
                    <p><strong>Authors:</strong> Ruochu Yang, Yu Zhou, Fumin Zhang, Mengxue Hou</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Household robots have been a longstanding research topic, but they still lack human-like intelligence, particularly in manipulating open-set objects and navigating large environments efficiently and accurately. To push this boundary, we consider a generalized multi-object collection problem in large scene graphs, where the robot needs to pick up and place multiple objects across multiple locations in a long mission of multiple human commands. This problem is extremely challenging since it requires long-horizon planning in a vast action-state space under high uncertainties. To this end, we propose a novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a multimodal action cost similarity function, our algorithm can both reflect the history and look into the future to optimize plans, striking a good balance of quality and efficiency. Simulation experiments demonstrate that compared with latest works, our algorithm improves the overall mission performance by 30% in t...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15777v1" target="_blank">Label tree semantic losses for rich multi-class medical image segmentation</a></h3>
                    <p><strong>Authors:</strong> Junwen Wang, Oscar MacCormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Rich and accurate medical image segmentation is poised to underpin the next generation of AI-defined clinical practice by delineating critical anatomy for pre-operative planning, guiding real-time intra-operative navigation, and supporting precise post-operative assessment. However, commonly used learning methods for medical and surgical imaging segmentation tasks penalise all errors equivalently and thus fail to exploit any inter-class semantics in the labels space. This becomes particularly problematic as the cardinality and richness of labels increases to include subtly different classes. In this work, we propose two tree-based semantic loss functions which take advantage of a hierarchical organisation of the labels. We further incorporate our losses in a recently proposed approach for training with sparse, background-free annotations to extend the applicability of our proposed losses. Extensive experiments are reported on two medical and surgical image segmentation tasks, namely he...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15772v1" target="_blank">Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis</a></h3>
                    <p><strong>Authors:</strong> Anoop C. Patil, Benny Jian Rong Sng, Yu-Wei Chang, Joana B. Pereira, Chua Nam-Hai, Rajani Sarojam, Gajendra Pratap Singh, In-Cheol Jang, Giovanni Volpe</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, q-bio.BM</p>
                    <p><strong>Summary:</strong> Detecting stress in plants is crucial for both open-farm and controlled-environment agriculture. Biomolecules within plants serve as key stress indicators, offering vital markers for continuous health monitoring and early disease detection. Raman spectroscopy provides a powerful, non-invasive means to quantify these biomolecules through their molecular vibrational signatures. However, traditional Raman analysis relies on customized data-processing workflows that require fluorescence background removal and prior identification of Raman peaks of interest-introducing potential biases and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis), a fully automated workflow based on a variational autoencoder. Unlike conventional approaches, DIVA processes native Raman spectra-including fluorescence backgrounds-without manual preprocessing, identifying and quantifying significant spectral features in an unbiased manner...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15771v1" target="_blank">Left Leaning Models: AI Assumptions on Economic Policy</a></h3>
                    <p><strong>Authors:</strong> Maxim Chupilkin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> How does AI think about economic policy? While the use of large language models (LLMs) in economics is growing exponentially, their assumptions on economic issues remain a black box. This paper uses a conjoint experiment to tease out the main factors influencing LLMs evaluation of economic policy. It finds that LLMs are most sensitive to unemployment, inequality, financial stability, and environmental harm and less sensitive to traditional macroeconomic concerns such as economic growth, inflation, and government debt. The results are remarkably consistent across scenarios and across models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15770v1" target="_blank">A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining</a></h3>
                    <p><strong>Authors:</strong> Yifan Shen, Zihan Zhao, Xiao Xue, Yuwei Guo, Qun Ma, Deyu Zhou, Ming Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15761v1" target="_blank">GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts</a></h3>
                    <p><strong>Authors:</strong> Jingyi Zheng, Zifan Peng, Yule Liu, Junfeng Wang, Yifan Liao, Wenhan Dong, Xinlei He</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15760v1" target="_blank">Fourier Plane Tomographic Spectroscopy Reveals Orientation-Dependent Multipolar Plasmon Modes in Micrometer-Scale Janus Particles</a></h3>
                    <p><strong>Authors:</strong> Felix H. Patzschke, Frank Cichos</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> physics.optics, cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> Plasmonic Janus particles, comprising dielectric cores with thin metallic caps, exhibit complex optical properties due to their asymmetric structure. Despite applications in active matter research, their orientation-dependent scattering properties remain largely unexplored. We introduce Fourier plane tomographic spectroscopy for simultaneous four-dimensional characterization of scattering from individual micrometer-scale particles across wavelength, incident angle, scattering angle, and polarization. Combining measurements with finite-element simulations, we identify discrete spectral markers in visible and near-infrared regions that evolve predictably with cap orientation. Spherical-harmonics decomposition reveals these markers arise from three distinct multipolar modes up to fifth order: axial-propagating transverse-electric, transverse-propagating transverse-electric, and transverse-propagating axial-electric, with retardation-induced splitting. We observe progressive red-shifts and...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15759v1" target="_blank">Interaction as Intelligence: Deep Research With Human-AI Partnership</a></h3>
                    <p><strong>Authors:</strong> Lyumanshan Ye, Xiaojie Cai, Xinkai Wang, Junfei Wang, Xiangkun Hu, Jiadi Su, Yang Nan, Sihan Wang, Bohan Zhang, Xiaoze Fan, Jinbin Luo, Yuxiang Zheng, Tianze Xu, Dayuan Fu, Yunze Wu, Pengrui Lu, Zengzhi Wang, Yiwei Qin, Zhen Huang, Yan Ma, Zhulin Hu, Haoyang Zou, Tiantian Mi, Yixin Ye, Ethan Chern, Pengfei Liu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This paper introduces Interaction as Intelligence research series, presenting a reconceptualization of human-AI relationships in deep research tasks. Traditional approaches treat interaction merely as an interface for accessing AI capabilities-a conduit between human intent and machine output. We propose that interaction itself constitutes a fundamental dimension of intelligence. As AI systems engage in extended thinking processes for research tasks, meaningful interaction transitions from an optional enhancement to an essential component of effective intelligence. Current deep research systems adopt an input-wait-output paradigm where users initiate queries and receive results after black-box processing. This approach leads to error cascade effects, inflexible research boundaries that prevent question refinement during investigation, and missed opportunities for expertise integration. To address these limitations, we introduce Deep Cognition, a system that transforms the human role fr...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15752v1" target="_blank">DialogueForge: LLM Simulation of Human-Chatbot Dialogue</a></h3>
                    <p><strong>Authors:</strong> Ruizhe Zhu, Hao Zhu, Yaxuan Li, Syang Zhou, Shijing Cai, Malgorzata Lazuka, Elliott Ash</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Collecting human-chatbot dialogues typically demands substantial manual effort and is time-consuming, which limits and poses challenges for research on conversational AI. In this work, we propose DialogueForge - a framework for generating AI-simulated conversations in human-chatbot style. To initialize each generated conversation, DialogueForge uses seed prompts extracted from real human-chatbot interactions. We test a variety of LLMs to simulate the human chatbot user, ranging from state-of-the-art proprietary models to small-scale open-source LLMs, and generate multi-turn dialogues tailored to specific tasks. In addition, we explore fine-tuning techniques to enhance the ability of smaller models to produce indistinguishable human-like dialogues. We evaluate the quality of the simulated conversations and compare different models using the UniEval and GTEval evaluation protocols. Our experiments show that large proprietary models (e.g., GPT-4o) generally outperform others in generating...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15743v1" target="_blank">Towards physician-centered oversight of conversational diagnostic AI</a></h3>
                    <p><strong>Authors:</strong> Elahe Vedadi, David Barrett, Natalie Harris, Ellery Wulczyn, Shashir Reddy, Roma Ruparel, Mike Schaekermann, Tim Strother, Ryutaro Tanno, Yash Sharma, Jihyeon Lee, CÃ­an Hughes, Dylan Slack, Anil Palepu, Jan Freyberg, Khaled Saab, Valentin LiÃ©vin, Wei-Hung Weng, Tao Tu, Yun Liu, Nenad Tomasev, Kavita Kulkarni, S. Sara Mahdavi, Kelvin Guu, JoÃ«lle Barral, Dale R. Webster, James Manyika, Avinatan Hassidim, Katherine Chou, Yossi Matias, Pushmeet Kohli, Adam Rodman, Vivek Natarajan, Alan Karthikesalingam, David Stutz</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchro...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15736v1" target="_blank">Understanding Large Language Models Ability on Interdisciplinary Research</a></h3>
                    <p><strong>Authors:</strong> Yuanhao Shen, Daniel Xavier de Sousa, Ricardo MarÃ§al, Ali Asad, Hongyu Guo, Xiaodan Zhu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Recent advancements in Large Language Models (LLMs) have revealed their impressive ability to perform multi-step, logic-driven reasoning across complex domains, positioning them as powerful tools and collaborators in scientific discovery while challenging the long-held view that inspiration-driven ideation is uniquely human. However, the lack of a dedicated benchmark that evaluates LLMs ability to develop ideas in Interdisciplinary Research (IDR) settings poses a critical barrier to fully understanding their strengths and limitations. To address this gap, we introduce IDRBench -- a pioneering benchmark featuring an expert annotated dataset and a suite of tasks tailored to evaluate LLMs capabilities in proposing valuable research ideas from different scientific domains for interdisciplinary research. This benchmark aims to provide a systematic framework for assessing LLM performance in complex, cross-domain scientific research. Our dataset consists of scientific publications sourced fro...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15734v1" target="_blank">TONUS: Neuromorphic human pose estimation for artistic sound co-creation</a></h3>
                    <p><strong>Authors:</strong> Jules Lecomte, Konrad Zinner, Michael Neumeier, Axel von Arnim</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.NE</p>
                    <p><strong>Summary:</strong> Human machine interaction is a huge source of inspiration in todays media art and digital design, as machines and humans merge together more and more. Its place in art reflects its growing applications in industry, such as robotics. However, those interactions often remains too technical and machine-driven for people to really engage into. On the artistic side, new technologies are often not explored in their full potential and lag a bit behind, so that state-of-the-art research does not make its way up to museums and exhibitions. Machines should support peoples imagination and poetry in a seamless interface to their body or soul. We propose an artistic sound installation featuring neuromorphic body sensing to support a direct yet non intrusive interaction with the visitor with the purpose of creating sound scapes together with the machine. We design a neuromorphic multihead human pose estimation neural sensor that shapes sound scapes and visual output with fine body movement control. ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15724v1" target="_blank">A Practical Investigation of Spatially-Controlled Image Generation with Transformers</a></h3>
                    <p><strong>Authors:</strong> Guoxuan Xia, Harleen Hanspal, Petru-Daniel Tudosiu, Shifeng Zhang, Sarah Parisot</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Enabling image generation models to be spatially controlled is an important area of research, empowering users to better generate images according to their own fine-grained specifications via e.g. edge maps, poses. Although this task has seen impressive improvements in recent times, a focus on rapidly producing stronger models has come at the cost of detailed and fair scientific comparison. Differing training data, model architectures and generation paradigms make it difficult to disentangle the factors contributing to performance. Meanwhile, the motivations and nuances of certain approaches become lost in the literature. In this work, we aim to provide clear takeaways across generation paradigms for practitioners wishing to develop transformer-based systems for spatially-controlled generation, clarifying the literature and addressing knowledge gaps. We perform controlled experiments on ImageNet across diffusion-based/flow-based and autoregressive (AR) models. First, we establish contr...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15717v1" target="_blank">BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning</a></h3>
                    <p><strong>Authors:</strong> Sahana Srinivasan, Xuguang Ai, Thaddaeus Wai Soon Lo, Aidan Gilson, Minjie Zou, Ke Zou, Hyunjae Kim, Mingjia Yang, Krithi Pushpanathan, Samantha Yew, Wan Ting Loke, Jocelyn Goh, Yibing Chen, Yiming Kong, Emily Yuelei Fu, Michelle Ongyong Hui, Kristen Nwanyanwu, Amisha Dave, Kelvin Zhenghao Li, Chen-Hsin Sun, Mark Chia, Gabriel Dawei Yang, Wendy Meihua Wong, David Ziyou Chen, Dianbo Liu, Maxwell Singer, Fares Antaki, Lucian V Del Priore, Jost Jonas, Ron Adelman, Qingyu Chen, Yih-Chung Tham</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Current benchmarks evaluating large language models (LLMs) in ophthalmology are limited in scope and disproportionately prioritise accuracy. We introduce BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive evaluation benchmark developed through multiple rounds of expert checking by 13 ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset underwent multiple rounds of expert checking. Duplicate and substandard questions were systematically removed. Ten ophthalmologists refined the explanations of each MCQs correct answer. This was further adjudicated by three senior ophthalmologists. To illustrate BELOs utility, we evaluated six LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro) using a...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15715v1" target="_blank">From Queries to Criteria: Understanding How Astronomers Evaluate LLMs</a></h3>
                    <p><strong>Authors:</strong> Alina Hyk, Kiera McCormick, Mian Zhong, Ioana CiucÄƒ, Sanjib Sharma, John F Wu, J. E. G. Peek, Kartheik G. Iyer, Ziang Xiao, Anjalie Field</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, astro-ph.IM</p>
                    <p><strong>Summary:</strong> There is growing interest in leveraging LLMs to aid in astronomy and other scientific research, but benchmarks for LLM evaluation in general have not kept pace with the increasingly diverse ways that real people evaluate and use these models. In this study, we seek to improve evaluation procedures by building an understanding of how users evaluate LLMs. We focus on a particular use case: an LLM-powered retrieval-augmented generation bot for engaging with astronomical literature, which we deployed via Slack. Our inductive coding of 368 queries to the bot over four weeks and our follow-up interviews with 11 astronomers reveal how humans evaluated this system, including the types of questions asked and the criteria for judging responses. We synthesize our findings into concrete recommendations for building better benchmarks, which we then employ in constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our work offers ways to improve LLM evaluation and ultimately usab...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15714v1" target="_blank">Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Models Capability of Emotion Perception using Contrastive Learning</a></h3>
                    <p><strong>Authors:</strong> Tian Li, Yujian Sun, Huizhi Liang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection, introduces an emotion recognition challenge spanning over 28 languages. This competition encourages researchers to explore more advanced approaches to address the challenges posed by the diversity of emotional expressions and background variations. It features two tracks: multi-label classification (Track A) and emotion intensity prediction (Track B), covering six emotion categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we systematically explore the benefits of two contrastive learning approaches: sample-based (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO) contrastive learning. The sample-based contrastive approach trains the model by comparing two samples to generate more reliable predictions. The generation-based contrastive approach trains the model to differentiate between correct and incorrect generations, refining its prediction. All models are fine-tuned f...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15694v1" target="_blank">Using stochastic thermodynamics with internal variables to capture orientational spreading in cell populations undergoing cyclic stretch</a></h3>
                    <p><strong>Authors:</strong> Rohan Abeyaratne, Sanjay Dharmaravan, Giuseppe Saccomandi, Giuseppe Tomassetti</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cond-mat.stat-mech, cond-mat.soft, math-ph, math.MP, math.PR, 60H10, 35Q92, 92C10</p>
                    <p><strong>Summary:</strong> We revisit the modeling framework introduced in [N. Loy and L. Preziosi: Bull. Math. Bio., 85, 2023] to describe the dynamics of cell orientation under cyclic stretch. We propose a reformulation based on the principles of Stochastic Thermodynamics with Internal Variables introduced in [T. Leadbetter, P. Purohit, and C. Reina: PNAS Nexus, 2, 2023]. This approach allows us to describe not only the evolution of the orientation distribution, but also the observed spreading phenomenon. The insight provided by our model reveals an interesting phenomenon, which we call two-stage reorientation: when cells begin aligned with an energy maximum, their orientations spread before concentrating at the energy minimum. This theoretical prediction suggests a new experiment to test this modeling framework.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15693v1" target="_blank">Strong, Accurate, and Low-Cost Robot Manipulator</a></h3>
                    <p><strong>Authors:</strong> Georges Chebly, Spencer Little, Nisal Perera, Aliya Abedeen, Ken Suzuki, Donghyun Kim</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach, and sub-millimeter repeatability - at a material cost under $215. As an accessible robot for broad applications across classroom education to AI experiments, Forte pushes forward the performance limitations of existing low-cost educational arms. We introduce a cost-effective mechanical design that combines capstan-based cable drives, timing belts, simple tensioning mechanisms, and lightweight 3D-printed structures, along with topology optimization for structural stiffness. Through careful drivetrain engineering, we minimize backlash and maintain control fidelity without relying on high-power electronics or expensive manufacturing processes. Experimental validation demonstrates that Forte achieves high repeatability and load capacity, offering a compelling robotic platform for both classroom instruction and advanced robotics research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15686v1" target="_blank">LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression</a></h3>
                    <p><strong>Authors:</strong> Wenjie Huang, Qi Yang, Shuting Xia, He Huang, Zhu Li, Yiling Xu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, i...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15676v1" target="_blank">Agentic AI for autonomous anomaly management in complex systems</a></h3>
                    <p><strong>Authors:</strong> Reza Vatankhah Barenji, Sina Khoshgoftar</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.ET</p>
                    <p><strong>Summary:</strong> This paper explores the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems, emphasizing its ability to transform traditional, human-dependent anomaly management methods.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.comnet.2025.111365" target="_blank">Vehicular Cloud Computing: A cost-effective alternative to Edge Computing in 5G networks</a></h3>
                    <p><strong>Authors:</strong> Rosario PatanÃ¨, Nadjib Achir, Andrea Araldo, Lila Boukhatem</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> Edge Computing (EC) is a computational paradigm that involves deploying resources such as CPUs and GPUs near end-users, enabling low-latency applications like augmented reality and real-time gaming. However, deploying and maintaining a vast network of EC nodes is costly, which can explain its limited deployment today. A new paradigm called Vehicular Cloud Computing (VCC) has emerged and inspired interest among researchers and industry. VCC opportunistically utilizes existing and idle vehicular computational resources for external task offloading. This work is the first to systematically address the following question: Can VCC replace EC for low-latency applications? Answering this question is highly relevant for Network Operators (NOs), as VCC could eliminate costs associated with EC given that it requires no infrastructural investment. Despite its potential, no systematic study has yet explored the conditions under which VCC can effectively support low-latency applications without rel...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15650v1" target="_blank">Chapter 11 Students interaction with and appreciation of automated informative tutoring feedback</a></h3>
                    <p><strong>Authors:</strong> Gerben van der Hoek, Bastiaan Heeren, Rogier Bos, Paul Drijvers, Johan Jeuring</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Computer aided formative assessment can be used to enhance a learning process, for instance by providing feedback. There are many design choices for delivering feedback, that lead to a feedback strategy. In an informative feedback strategy, students do not immediately receive information about the correct response, but are offered the opportunity to retry a task to apply feedback information. In this small-scale qualitative study, we explore an informative feedback strategy designed to offer a balance between room for exploration and mitigation of learning barriers. The research questions concern the ways in which students interact with the feedback strategy and their appreciation of error-specific feedback as opposed to worked-out solutions. To answer these questions, twenty-five 15-to-17-year-old senior general secondary education students worked for approximately 20 minutes on linear and exponential extrapolation tasks in an online environment. Data included screen captures of stude...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15641v1" target="_blank">Leveraging Context for Multimodal Fallacy Classification in Political Debates</a></h3>
                    <p><strong>Authors:</strong> Alessio Pittiglio</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> In this paper, we present our submission to the MM-ArgFallacy2025 shared task, which aims to advance research in multimodal argument mining, focusing on logical fallacies in political debates. Our approach uses pretrained Transformer-based models and proposes several ways to leverage context. In the fallacy classification subtask, our models achieved macro F1-scores of 0.4444 (text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed performance comparable to the text-only model, suggesting potential for improvements.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15640v1" target="_blank">Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training</a></h3>
                    <p><strong>Authors:</strong> Kailai Yang, Xiao Liu, Lei Ji, Hao Li, Yeyun Gong, Peng Cheng, Mao Yang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Continual pre-training on small-scale task-specific data is an effective method for improving large language models in new target fields, yet it risks catastrophic forgetting of their original capabilities. A common solution is to re-weight training data mixtures from source and target fields on a domain space to achieve balanced performance. Previous domain reweighting strategies rely on manual designation with certain heuristics based on human intuition or empirical results. In this work, we prove that more general heuristics can be parameterized by proposing Data Mixing Agent, the first model-based, end-to-end framework that learns to re-weight domains. The agent learns generalizable heuristics through reinforcement learning on large quantities of data mixing trajectories with corresponding feedback from an evaluation environment. Experiments in continual pre-training on math reasoning show that Data Mixing Agent outperforms strong baselines in achieving balanced performance across ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15639v1" target="_blank">Brain rhythms in cognition -- controversies and future directions</a></h3>
                    <p><strong>Authors:</strong> Anne Keitel, Christian Keitel, Mohsen Alavash, Karin Bakardjian, Christopher S. Y. Benwell, Sophie Bouton, Niko A. Busch, Antonio Criscuolo, Keith B. Doelling, Laura Dugue, Laetitia Grabot, Joachim Gross, Simon Hanslmayr, Laura-Isabelle Klatt, Daniel S. Kluger, Gemma Learmonth, Raquel E. London, Christina Lubinus, Andrea E. Martin, Jonas Obleser, Johanna M. Rimmele, Vincenzo Romei, Manuela Ruzzoli, Felix Siebenhuhner, Sophie Slaats, Eelke Spaak, Luca Tarasi, Gregor Thut, Jelena Trajkovic, Danying Wang, Malte Wostmann, Benedikt Zoefel, Satu Palva, Paul Sauseng, Sonja A. Kotz</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC</p>
                    <p><strong>Summary:</strong> Brain rhythms seem central to understanding the neurophysiological basis of human cognition. Yet, despite significant advances, key questions remain unresolved. In this comprehensive position paper, we review the current state of the art on oscillatory mechanisms and their cognitive relevance. The paper critically examines physiological underpinnings, from phase-related dynamics like cyclic excitability, to amplitude-based phenomena, such as gating by inhibition, and their interactions, such as phase-amplitude coupling, as well as frequency dynamics, like sampling mechanisms. We also critically evaluate future research directions, including travelling waves and brain-body interactions. We then provide an in-depth analysis of the role of brain rhythms across cognitive domains, including perception, attention, memory, and communication, emphasising ongoing debates and open questions in each area. By summarising current theories and highlighting gaps, this position paper offers a roadmap ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15633v1" target="_blank">Experimenting active and sequential learning in a medieval music manuscript</a></h3>
                    <p><strong>Authors:</strong> Sachin Sharma, Federico Simonetta, Michele Flammini</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, I.2.10; I.4.8; H.3.3</p>
                    <p><strong>Summary:</strong> Optical Music Recognition (OMR) is a cornerstone of music digitization initiatives in cultural heritage, yet it remains limited by the scarcity of annotated data and the complexity of historical manuscripts. In this paper, we present a preliminary study of Active Learning (AL) and Sequential Learning (SL) tailored for object detection and layout recognition in an old medieval music manuscript. Leveraging YOLOv8, our system selects samples with the highest uncertainty (lowest prediction confidence) for iterative labeling and retraining. Our approach starts with a single annotated image and successfully boosts performance while minimizing manual labeling. Experimental results indicate that comparable accuracy to fully supervised training can be achieved with significantly fewer labeled examples. We test the methodology as a preliminary investigation on a novel dataset offered to the community by the Anonymous project, which studies laude, a poetical-musical genre spread across Italy duri...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15629v1" target="_blank">Gaussian Splatting with Discretized SDF for Relightable Assets</a></h3>
                    <p><strong>Authors:</strong> Zuo-Liang Zhu, Jian Yang, Beibei Wang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV</p>
                    <p><strong>Summary:</strong> 3D Gaussian splatting (3DGS) has shown its detailed expressive ability and highly efficient rendering speed in the novel view synthesis (NVS) task. The application to inverse rendering still faces several challenges, as the discrete nature of Gaussian primitives makes it difficult to apply geometry constraints. Recent works introduce the signed distance field (SDF) as an extra continuous representation to regularize the geometry defined by Gaussian primitives. It improves the decomposition quality, at the cost of increasing memory usage and complicating training. Unlike these works, we introduce a discretized SDF to represent the continuous SDF in a discrete manner by encoding it within each Gaussian using a sampled value. This approach allows us to link the SDF with the Gaussian opacity through an SDF-to-opacity transformation, enabling rendering the SDF via splatting and avoiding the computational cost of ray marching.The key challenge is to regularize the discrete samples to be cons...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15624v1" target="_blank">Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow</a></h3>
                    <p><strong>Authors:</strong> Yusuf Sulistyo Nugroho, Ganno Tribuana Kurniaji, Syful Islam, Mohammed Humayun Kabir, Vanesya Aura Ardity, Md. Kamal Uddin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> React is a JavaScript library used to build user interfaces for single-page applications. Although recent studies have shown the popularity and advantages of React in web development, the specific challenges users face remain unknown. Thus, this study aims to analyse the React-related questions shared on Stack Overflow. The study utilizes an exploratory data analysis to investigate the most frequently discussed keywords, error classification, and user reputation-based errors, which is the novelty of this work. The results show the top eight most frequently used keywords on React-related questions, namely, code, link, vir, href, connect, azure, windows, and website. The error classification of questions from the sample shows that algorithmic error is the most frequent issue faced by all groups of users, where mid-reputation users contribute the most, accounting for 55.77%. This suggests the need for the community to provide guidance materials in solving algorithm-related problems. We ex...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15619v1" target="_blank">Dynamic Investigation of the New Quantum-Control-Assisted Reverse uncertainty relation</a></h3>
                    <p><strong>Authors:</strong> Qiyi Li, Shaoqiang Ma, Sansheng Wang, Xiao Zheng, Guofeng Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Recently, a new interesting concept of reverse uncertainty relation is introduced. Different from the normal uncertainty relation, the reverse one indicates that one cannot only prepare quantum states with joint small uncertainty, but also with joint great uncertainty for incompatible observables. We in this work construct a new quantum-control-assisted reverse uncertainty relation and investigate the corresponding dynamic evolution in the Heisenberg model with Dzyaloshinskii-Moriya interaction. The obtained relation indicates that the reverse uncertainty can be broken with help of the quantum control system. The dynamic investigation reveals that there exists an interesting single-value relationship between new uncertainty relation and the mixedness of the system, indicating that the tightness and upper bound of the uncertainty relation can be written as functional form of the mixedness. By comparing the existing research in [Physica Scripta 2023, 98(6), 065113], we show that the sing...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15857v1" target="_blank">Diffusion Beats Autoregressive in Data-Constrained Settings</a></h3>
                    <p><strong>Authors:</strong> Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Autoregressive (AR) models have long dominated the landscape of large language models, driving progress across a wide range of tasks. Recently, diffusion-based language models have emerged as a promising alternative, though their advantages over AR models remain underexplored. In this paper, we systematically study masked diffusion models in data-constrained settings-where training involves repeated passes over limited data-and find that they significantly outperform AR models when compute is abundant but data is scarce. Diffusion models make better use of repeated data, achieving lower validation loss and superior downstream performance. We interpret this advantage as implicit data augmentation: masked diffusion exposes the model to a diverse distribution of token orderings and prediction tasks, unlike ARs fixed left-to-right factorization. We find new scaling laws for diffusion models and derive a closed-form expression for the critical compute threshold at which diffusion begins to ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15856v1" target="_blank">Latent Denoising Makes Good Visual Tokenizers</a></h3>
                    <p><strong>Authors:</strong> Jiawei Yang, Tianhong Li, Lijie Fan, Yonglong Tian, Yue Wang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Despite their fundamental role, it remains unclear what properties could make visual tokenizers more effective for generative modeling. We observe that modern generative models share a conceptually similar training objective -- reconstructing clean signals from corrupted inputs such as Gaussian noise or masking -- a process we term denoising. Motivated by this insight, we propose aligning tokenizer embeddings directly with the downstream denoising objective, encouraging latent embeddings to be more easily reconstructed even when heavily corrupted. To achieve this, we introduce the Latent Denoising Tokenizer (l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images from latent embeddings corrupted by interpolative noise and random masking. Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer consistently outperforms standard tokenizers across six representative generative models. Our findings highlight denoising as a fundamental design principle...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15852v2" target="_blank">SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction</a></h3>
                    <p><strong>Authors:</strong> Zhixiong Zhang, Shuangrui Ding, Xiaoyi Dong, Songxin He, Jianfan Lin, Junsong Tang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Video Object Segmentation (VOS) is a core task in computer vision, requiring models to track and segment target objects across video frames. Despite notable advances with recent efforts, current techniques still lag behind human capabilities in handling drastic visual variations, occlusions, and complex scene changes. This limitation arises from their reliance on appearance matching, neglecting the human-like conceptual understanding of objects that enables robust identification across temporal dynamics. Motivated by this gap, we propose Segment Concept (SeC), a concept-driven segmentation framework that shifts from conventional feature matching to the progressive construction and utilization of high-level, object-centric representations. SeC employs Large Vision-Language Models (LVLMs) to integrate visual cues across diverse frames, constructing robust conceptual priors. During inference, SeC forms a comprehensive semantic representation of the target based on processed frames, realiz...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15850v1" target="_blank">3LM: Bridging Arabic, STEM, and Code through Benchmarking</a></h3>
                    <p><strong>Authors:</strong> Basma El Amel Boussaha, Leen AlQadi, Mugariya Farooq, Shaikha Alsuwaidi, Giulia Campesan, Ahmed Alzubaidi, Mohammed Alyafeai, Hakim Hacid</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Arabic is one of the most widely spoken languages in the world, yet efforts to develop and evaluate Large Language Models (LLMs) for Arabic remain relatively limited. Most existing Arabic benchmarks focus on linguistic, cultural, or religious content, leaving a significant gap in domains like STEM and code which are increasingly relevant for real-world LLM applications. To help bridge this gap, we present 3LM, a suite of three benchmarks designed specifically for Arabic. The first is a set of STEM-related question-answer pairs, naturally sourced from Arabic textbooks and educational worksheets. The second consists of synthetically generated STEM questions, created using the same sources. The third benchmark focuses on code generation, built through a careful translation of two widely used code benchmarks, incorporating a human-in-the-loop process with several rounds of review to ensure high-quality and faithful translations. We release all three benchmarks publicly to support the growt...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15849v1" target="_blank">The Impact of Language Mixing on Bilingual LLM Reasoning</a></h3>
                    <p><strong>Authors:</strong> Yihao Li, Jiayi Xin, Miranda Muqing Miao, Qi Long, Lyle Ungar</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Proficient multilingual speakers often intentionally switch languages in the middle of a conversation. Similarly, recent reasoning-focused bilingual large language models (LLMs) with strong capabilities in both languages exhibit language mixing--alternating languages within their chain of thought. Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy, suggesting that language mixing may benefit reasoning. In this work, we study language switching in Chinese-English bilingual reasoning models. We identify reinforcement learning with verifiable rewards (RLVR) as the critical training stage that leads to language mixing. We demonstrate that language mixing can enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6 percentage points on math reasoning tasks. Additionally, a lightweight probe can be trained to predict whether a potential language switch would benefit or harm reasoning, and when used to guide decoding, increases accuracy by up to 6.25 perc...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15846v2" target="_blank">GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding</a></h3>
                    <p><strong>Authors:</strong> Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL, cs.CV, cs.HC</p>
                    <p><strong>Summary:</strong> Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism tha...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15845v1" target="_blank">Quantum computational sensing using quantum signal processing, quantum neural networks, and Hamiltonian engineering</a></h3>
                    <p><strong>Authors:</strong> Saeed A. Khan, Sridhar Prabhu, Logan G. Wright, Peter L. McMahon</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Combining quantum sensing with quantum computing can lead to quantum computational sensors that are able to more efficiently extract task-specific information from physical signals than is possible otherwise. Early examples of quantum computational sensing (QCS) have largely focused on protocols where only a single sensing operation appears before measurement -- with an exception being the recent application of Grovers algorithm to signal detection. In this paper we present, in theory and numerical simulations, the application of two quantum algorithms -- quantum signal processing and quantum neural networks -- to various binary and multiclass machine-learning classification tasks in sensing. Here sensing operations are interleaved with computing operations, giving rise to nonlinear functions of the sensed signals. We have evaluated tasks based on static and time-varying signals, including spatiotemporal signals. Our approach to optimizing the circuit parameters in a QCS protocol takes...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15844v2" target="_blank">Hierarchical Budget Policy Optimization for Adaptive Reasoning</a></h3>
                    <p><strong>Authors:</strong> Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet exhibit significant computational inefficiency by applying uniform reasoning strategies regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. HBPO addresses the fundamental challenge of exploration space collapse in efficiency-oriented training, where penalties on long output length systematically bias models away from necessary long reasoning paths. Through hierarchical budget exploration, our approach partitions rollout samples into multiple subgroups with distinct token budgets, aiming to enable efficient resource allocation while preventing degradation of capability. We introduce differentiated reward mechanisms that create budget-aware incentives aligned with the complexity of the problem, allowing models to dis...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15841v1" target="_blank">Some Lagrangian quiver Grassmannians for the equioriented cycle</a></h3>
                    <p><strong>Authors:</strong> Matteo Micheli</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> math.RT, math.AG, math.CO, 16G20 (Primary) 14M15 (Secondary)</p>
                    <p><strong>Summary:</strong> The goal of this paper is to better understand a family of linear degenerations of the classical Lagrangian Grassmannians $\Lambda(2n)$. It is the special case for $k=n$ of the varieties $X(k,2n)^{sp}$, introduced in previous joint work with Evgeny Feigin, Martina Lanini and Alexander P\utz. These varieties are obtained as isotropic subvarieties of a family of quiver Grassmannians $X(n,2n)$, and are acted on by a linear degeneration of the algebraic group $Sp_{2n}$. We prove a conjecture proposed in the paper above for this particular case, which states that the ordering on the set of orbits in $X(n,2n)^{sp}$ given by closure-inclusion coincides with a combinatorially defined order on what are called symplectic $(n,2n)$-juggling patterns, much in the same way that the $Sp_{2n}$ orbits in $\Lambda(2n)$ are parametrized by a type C Weyl group with the Bruhat order. The dimension of such orbits is computed via the combinatorics of bounded affine permutations, and it coincides with the len...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15840v1" target="_blank">TASI/CERN/KITP Lecture Notes on Toward Quantum Computing Gauge Theories of Nature</a></h3>
                    <p><strong>Authors:</strong> Zohreh Davoudi</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> hep-lat, hep-ph, nucl-th, quant-ph</p>
                    <p><strong>Summary:</strong> A hallmark of the computational campaign in nuclear and particle physics is the lattice-gauge-theory program. It continues to enable theoretical predictions for a range of phenomena in nature from the underlying Standard Model. The emergence of a new computational paradigm based on quantum computing, therefore, can introduce further advances in this program. In particular, it is believed that quantum computing will make possible first-principles studies of matter at extreme densities, and in and out of equilibrium, hence improving our theoretical description of early universe, astrophysical environments, and high-energy particle collisions. Developing and advancing a quantum-computing based lattice-gauge-theory program, therefore, is a vibrant and fast-moving area of research in theoretical nuclear and particle physics. These lecture notes introduce the topic of quantum computing lattice gauge theories in a pedagogical manner, with an emphasis on theoretical and algorithmic aspects of ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15837v1" target="_blank">Data-driven optimal approximation on Hardy spaces in simply connected domains</a></h3>
                    <p><strong>Authors:</strong> Alessandro Borghi, Tobias Breiten</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, math.OC</p>
                    <p><strong>Summary:</strong> We consider optimal interpolation of functions analytic in simply connected domains in the complex plane. By choosing a specific structure for the approximant, we show that the resulting first order optimality conditions can be interpreted as optimal $\mathcal{H}_2$ interpolation conditions for discrete-time dynamical systems. Connections to the implicit Euler method, the midpoint method, and backward differentiation methods are also established. A data-driven algorithm is developed to compute a (locally) optimal approximant. Our method is tested on three numerical experiments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15835v1" target="_blank">Gauge dependence of momentum running in higher-derivative gravity</a></h3>
                    <p><strong>Authors:</strong> Diego Buccio, Gustavo P. De Brito, Luca Parente</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> hep-th, gr-qc</p>
                    <p><strong>Summary:</strong> Recent works have argued that improved one-loop beta-functions capturing the physical momentum dependence of one-loop corrected higher-derivative gravity theories are the most suitable to describe their high-energy behaviour. This work critically tests the validity of this claim. We compute the explicit gauge dependence of the one-loop momentum running of curvature-squared operators in quadratic gravity and conformal gravity using the background field method. We find them to be gauge dependent, and we discuss the implications of this result for the theory and its physical predictivity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15833v1" target="_blank">Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers</a></h3>
                    <p><strong>Authors:</strong> Ian Chuang, Andrew Lee, Dechen Gao, Jinyu Zou, Iman Soltani</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Human vision is a highly active process driven by gaze, which directs attention and fixation to task-relevant regions and dramatically reduces visual processing. In contrast, robot learning systems typically rely on passive, uniform processing of raw camera images. In this work, we explore how incorporating human-like active gaze into robotic policies can enhance both efficiency and performance. We build on recent advances in foveated image processing and apply them to an Active Vision robot system that emulates both human head movement and eye tracking. Extending prior work on the AV-ALOHA robot simulation platform, we introduce a framework for simultaneously collecting eye-tracking data and robot demonstrations from a human operator as well as a simulation benchmark and dataset for training robot policies that incorporate human gaze. Given the widespread use of Vision Transformers (ViTs) in robot learning, we integrate gaze information into ViTs using a foveated patch tokenization sc...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15831v1" target="_blank">Observing Fine-Grained Changes in Jupyter Notebooks During Development Time</a></h3>
                    <p><strong>Authors:</strong> Sergey Titov, Konstantin Grotov, Cristina Sarasua, Yaroslav Golubev, Dhivyabharathi Ramasamy, Alberto Bacchelli, Abraham Bernstein, Timofey Bryksin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> In software engineering, numerous studies have focused on the analysis of fine-grained logs, leading to significant innovations in areas such as refactoring, security, and code completion. However, no similar studies have been conducted for computational notebooks in the context of data science. To help bridge this research gap, we make three scientific contributions: we (1) introduce a toolset for collecting code changes in Jupyter notebooks during development time; (2) use it to collect more than 100 hours of work related to a data analysis task and a machine learning task (carried out by 20 developers with different levels of expertise), resulting in a dataset containing 2,655 cells and 9,207 cell executions; and (3) use this dataset to investigate the dynamic nature of the notebook development process and the changes that take place in the notebooks. In our analysis of the collected data, we classified the changes made to the cells between executions and found that a significant nu...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15824v1" target="_blank">Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models</a></h3>
                    <p><strong>Authors:</strong> Enes Sanli, Baris Sarper Tezcan, Aykut Erdem, Erkut Erdem</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Recent progress in text-to-video (T2V) generation has enabled the synthesis of visually compelling and temporally coherent videos from natural language. However, these models often fall short in basic physical commonsense, producing outputs that violate intuitive expectations around causality, object behavior, and tool use. Addressing this gap, we present PhysVidBench, a benchmark designed to evaluate the physical reasoning capabilities of T2V systems. The benchmark includes 383 carefully curated prompts, emphasizing tool use, material properties, and procedural interactions, and domains where physical plausibility is crucial. For each prompt, we generate videos using diverse state-of-the-art models and adopt a three-stage evaluation pipeline: (1) formulate grounded physics questions from the prompt, (2) caption the generated video with a vision-language model, and (3) task a language model to answer several physics-involved questions using only the caption. This indirect strategy circ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15823v1" target="_blank">Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work</a></h3>
                    <p><strong>Authors:</strong> Anton Abilov, Ke Zhang, Hemank Lamba, Elizabeth M. Olson, Joel R. Tetreault, Alejandro Jaimes</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.SI</p>
                    <p><strong>Summary:</strong> Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15821v1" target="_blank">Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks</a></h3>
                    <p><strong>Authors:</strong> Hope Schroeder, Deb Roy, Jad Kabbara</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> LLM use in annotation is becoming widespread, and given LLMs overall promising performance and speed, simply reviewing LLM annotations in interpretive tasks can be tempting. In subjective annotation tasks with multiple plausible answers, reviewing LLM outputs can change the label distribution, impacting both the evaluation of LLM performance, and analysis using these labels in a social science task downstream. We conducted a pre-registered experiment with 410 unique annotators and over 7,000 annotations testing three AI assistance conditions against controls, using two models, and two datasets. We find that presenting crowdworkers with LLM-generated annotation suggestions did not make them faster, but did improve their self-reported confidence in the task. More importantly, annotators strongly took the LLM suggestions, significantly changing the label distribution compared to the baseline. When these labels created with LLM assistance are used to evaluate LLM performance, reported mode...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15819v1" target="_blank">Euclid preparation: Expected constraints on initial conditions</a></h3>
                    <p><strong>Authors:</strong> Euclid Collaboration, F. Finelli, Y. Akrami, A. Andrews, M. Ballardini, S. Casas, D. Karagiannis, Z. Sakr, J. Valiviita, G. Alestas, N. Bartolo, J. R. Bermejo-Climent, S. Nesseris, D. Paoletti, D. Sapone, I. Tutusaus, A. AchÃºcarro, G. CaÃ±as-Herrera, J. Jasche, G. Lavaux, N. Aghanim, B. Altieri, A. Amara, L. Amendola, S. Andreon, N. Auricchio, C. Baccigalupi, D. Bagot, M. Baldi, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, S. Camera, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, M. Cropper, A. Da Silva, H. Degaudenzi, S. de la Torre, G. De Lucia, A. M. Di Giorgio, H. Dole, M. Douspis, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, F. Faustini, S. Ferriol, P. Fosalba, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. KeihÃ¤nen, S. Kermiche, A. Kiessling, B. Kubik, M. KÃ¼mmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, B. Sartoris, M. Schirmer, T. Schrabback, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, P. Simon, C. Sirignano, G. Sirri, A. Spurio Mancini, L. Stanco, J. Steinwagner, P. Tallada-CrespÃ­, D. Tavagnacco, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, L. Valenziano, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, V. Allevato, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, J. MartÃ­n-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. A. Nucita, A. Pezzotta, M. PÃ¶ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, I. T. Andika, M. Archidiacono, F. Atrio-Barandela, S. Avila, A. Balaguera-Antolinez, D. Bertacca, M. Bethermin, A. Blanchard, L. Blot, H. BÃ¶hringer, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, F. Cogato, S. Conseil, A. R. Cooray, S. Davini, F. De Paolis, G. Desprez, A. DÃ­az-SÃ¡nchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, J. GarcÃ­a-Bellido, T. Gasparetto, V. Gautard, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, A. Gruppuso, M. Guidi, C. M. Gutierrez, S. Hemmati, C. HernÃ¡ndez-Monteagudo, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, Y. Kang, V. Kansal, K. Kiiveri, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, V. Le Brun, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, J. Macias-Perez, G. Maggio, M. Magliocchetti, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Migliaccio, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, A. Navarro-Alsina, L. Pagano, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, P. Reimberg, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. SahlÃ©n, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, F. Vernizzi, G. Verza, P. Vielzeuf, N. A. Walton</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO</p>
                    <p><strong>Summary:</strong> The Euclid mission of the European Space Agency will deliver galaxy and cosmic shear surveys, which will be used to constrain initial conditions and statistics of primordial fluctuations. We present highlights for the Euclid scientific capability to test initial conditions beyond LCDM with the main probes, i.e. 3D galaxy clustering from the spectroscopic survey, the tomographic approach to 3x2pt statistics from photometric galaxy survey, and their combination. We provide Fisher forecasts from the combination of Euclid spectroscopic and photometric surveys for spatial curvature, running of the spectral index of the power spectrum of curvature perturbations, isocurvature perturbations, and primordial features. For the parameters of these models we also provide the combination of Euclid forecasts (pessimistic and optimistic) with current and future measurements of the cosmic microwave background (CMB) anisotropies., i.e. Planck, the Simons Observatory (SO), and CMB-S4. We provide Fisher f...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15816v1" target="_blank">Federated Split Learning with Improved Communication and Storage Efficiency</a></h3>
                    <p><strong>Authors:</strong> Yujia Mu, Cong Shen</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.IT, cs.NI, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> Federated learning (FL) is one of the popular distributed machine learning (ML) solutions but incurs significant communication and computation costs at edge devices. Federated split learning (FSL) can train sub-models in parallel and reduce the computational burden of edge devices by splitting the model architecture. However, it still requires a high communication overhead due to transmitting the smashed data and gradients between clients and the server in every global round. Furthermore, the server must maintain separate partial models for every client, leading to a significant storage requirement. To address these challenges, this paper proposes a novel communication and storage efficient federated split learning method, termed CSE-FSL, which utilizes an auxiliary network to locally update the weights of the clients while keeping a single model at the server, hence avoiding frequent transmissions of gradients from the server and greatly reducing the storage requirement of the server....</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1016/j.euromechsol.2025.105782" target="_blank">Hyperelastic nature of the Hoek-Brown criterion</a></h3>
                    <p><strong>Authors:</strong> Ilaria Fontana, Goustan Bacquaert, Daniele A. Di Pietro, Kyrylo Kazymyrenko</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph, cs.CE, physics.class-ph</p>
                    <p><strong>Summary:</strong> We propose a nonlinear elasto-plastic model, for which a specific class of hyperbolic elasticity arises as a straight consequence of the yield criterion invariance on the plasticity level. We superimpose this nonlinear elastic (or hyperelastic) behavior with plasticity obeying the associated flow rule. Interestingly, we find that a linear yield criterion on the thermodynamical force associated with plasticity results in a quadratic yield criterion in the stress space. This suggests a specific hyperelastic connection between Mohr-Coulomb and Hoek-Brown (or alternatively between Drucker-Prager and Pan-Hudson) yield criteria. We compare the elasto-plastic responses of standard tests for the Drucker-Prager yield criterion using either linear or the suggested hyperbolic elasticity. Notably, the nonlinear case stands out due to dilatancy saturation observed during cyclic loading in the triaxial compression test. We conclude this study with structural finite element simulations that clearly d...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15812v1" target="_blank">The Inflationary Quartic Hilltop Model in a Modified Gravity and Its Comparison with the Observations</a></h3>
                    <p><strong>Authors:</strong> Feyzollah Younesizadeh, Davoud Kamani</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> gr-qc</p>
                    <p><strong>Summary:</strong> We investigate the inflation for the quartic hilltop model via a certain type of modified gravity. Precisely, we analyze the $F(\phi) T$ term in the Einsteins gravity to examine the quartic hilltop inflation model. $T$ is the trace of the energy-momentum tensor, and $\phi$ is the inflaton field. Next, we calculate the inflation dynamics for the foregoing model and obtain the slow-roll parameters, i.e., the scalar spectral index ``$n_s$ and the tensor-to-scale ratio ``$r$, which these parameters exhibit high sensitivity to the $F(\phi) T$ term. This modified form of the gravity is not only in accordance with the predictions of the original model but also allows for better prediction of the Planck/BICEP/Keck data.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15811v1" target="_blank">Mpemba effect in self-contained quantum refrigerators: accelerated cooling</a></h3>
                    <p><strong>Authors:</strong> Sayan Mondal, Ujjwal Sen</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We consider the qubit-qutrit model of self-contained quantum refrigerator and observe the quantum Mpemba effect in its cooling. In this system, the qutrit acts as the refrigerator while the qubit is to be cooled. The entire system is coupled to three bosonic heat baths, due to which the dynamics of the system is governed by a Gorini-Kossakoswski-Sudarshan-Lindblad master equation. We investigate the Liouvillian that generates the dynamics of the system and find that it has a block diagonal form. The dynamics of each element of the systems density matrix can be determined by solving the dynamical equation of the corresponding block that contains it. We find that the steady state belongs to the block containing only the diagonal elements in the energy basis. We numerically solve for the steady state and investigate the steady-state cooling over a significant region of the parameter space. Moreover, we demonstrate the quantum Mpemba effect in the refrigerator: a Mpemba state obtained by a...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15809v1" target="_blank">Diffusion models for multivariate subsurface generation and efficient probabilistic inversion</a></h3>
                    <p><strong>Authors:</strong> Roberto Miele, Niklas Linde</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG, physics.geo-ph, stat.AP</p>
                    <p><strong>Summary:</strong> Diffusion models offer stable training and state-of-the-art performance for deep generative modeling tasks. Here, we consider their use in the context of multivariate subsurface modeling and probabilistic inversion. We first demonstrate that diffusion models enhance multivariate modeling capabilities compared to variational autoencoders and generative adversarial networks. In diffusion modeling, the generative process involves a comparatively large number of time steps with update rules that can be modified to account for conditioning data. We propose different corrections to the popular Diffusion Posterior Sampling approach by Chung et al. (2023). In particular, we introduce a likelihood approximation accounting for the noise-contamination that is inherent in diffusion modeling. We assess performance in a multivariate geological scenario involving facies and correlated acoustic impedance. Conditional modeling is demonstrated using both local hard data (well logs) and nonlinear geophys...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15807v1" target="_blank">True Multimodal In-Context Learning Needs Attention to the Visual Context</a></h3>
                    <p><strong>Authors:</strong> Shuo Chen, Jianzhe Liu, Zhen Han, Yan Xia, Daniel Cremers, Philip Torr, Volker Tresp, Jindong Gu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Multimodal Large Language Models (MLLMs), built on powerful language backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new tasks from a few multimodal demonstrations consisting of images, questions, and answers. Despite showing noticeable improvement on standard vision-language datasets, current MLLMs struggle to leverage visual information in the demonstrations. Specifically, they tend to neglect visual cues and over-rely on textual patterns, leading to mere text imitation rather than genuine multimodal adaptation. This behavior makes MICL still unimodal and largely restricts its practical utility. More importantly, this limitation is often concealed by the improved performance on tasks that do not require understanding the visual context. As a result, how to effectively enhance MICL ability and reliably evaluate the MICL performance remains underexplored. To address these issues, we first introduce Dynamic Attention Reallocation (DARA), an efficient fine-tunin...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15804v1" target="_blank">1D Vlasov Simulations of QED Cascades Over Pulsar Polar Caps</a></h3>
                    <p><strong>Authors:</strong> Dingyi Ye, Alexander Y. Chen</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE</p>
                    <p><strong>Summary:</strong> Recent developments in the study of pulsar radio emission revealed that the microphysics of quantum electrodynamic (QED) pair cascades at pulsar polar caps may be responsible for generating the observed coherent radio waves. However, modeling the pair cascades in the polar cap region poses significant challenges, particularly under conditions of high plasma multiplicity. Traditional Particle-in-Cell (PIC) methods often face rapidly increasing computational costs as the multiplicity grows exponentially. To address this issue, we present a new simulation code using the Vlasov method, which efficiently simulates the evolution of charged particle distribution functions in phase space without a proportional increase in computational expense at high multiplicities. We apply this code to study $e^\pm$ pair cascades in 1D, incorporating key physical processes such as curvature radiation, radiative cooling, and magnetic pair production. We study both the Ruderman-Sutherland (RS) and the Space-c...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15803v1" target="_blank">ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction</a></h3>
                    <p><strong>Authors:</strong> Danhui Chen, Ziquan Liu, Chuxi Yang, Dan Wang, Yan Yan, Yi Xu, Xiangyang Ji</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Pixel-level vision tasks, such as semantic segmentation, require extensive and high-quality annotated data, which is costly to obtain. Semi-supervised semantic segmentation (SSSS) has emerged as a solution to alleviate the labeling burden by leveraging both labeled and unlabeled data through self-training techniques. Meanwhile, the advent of foundational segmentation models pre-trained on massive data, has shown the potential to generalize across domains effectively. This work explores whether a foundational segmentation model can address label scarcity in the pixel-level vision task as an annotator for unlabeled images. Specifically, we investigate the efficacy of using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual input, to generate predictive masks for unlabeled data. To address the shortcomings of using SEEM-generated masks as supervision, we propose ConformalSAM, a novel SSSS framework which first calibrates the foundation model using the target domains label...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15802v1" target="_blank">Hypergraphs on high dimensional time series sets using signature transform</a></h3>
                    <p><strong>Authors:</strong> RÃ©mi Vaucher, Paul Minchella</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG, stat.CO</p>
                    <p><strong>Summary:</strong> In recent decades, hypergraphs and their analysis through Topological Data Analysis (TDA) have emerged as powerful tools for understanding complex data structures. Various methods have been developed to construct hypergraphs -- referred to as simplicial complexes in the TDA framework -- over datasets, enabling the formation of edges between more than two vertices. This paper addresses the challenge of constructing hypergraphs from collections of multivariate time series. While prior work has focused on the case of a single multivariate time series, we extend this framework to handle collections of such time series. Our approach generalizes the method proposed in Chretien and al. by leveraging the properties of signature transforms to introduce controlled randomness, thereby enhancing the robustness of the construction process. We validate our method on synthetic datasets and present promising results.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15800v1" target="_blank">Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications</a></h3>
                    <p><strong>Authors:</strong> Yinchao Yang, Jingxuan Zhou, Zhaohui Yang, Mohammad Shikh-Bahaei</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> eess.SP, cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> The integration of sensing and communication (ISAC) is a key enabler for next-generation technologies. With high-frequency bands and large-scale antenna arrays, the Rayleigh distance extends, necessitating near-field (NF) models where waves are spherical. Although NF-ISAC improves both sensing and communication, it also poses challenges such as high data volume and potential privacy risks. To address these, we propose a novel framework: near-field integrated sensing, computing, and semantic communication (NF-ISCSC), which leverages semantic communication to transmit contextual information only, thereby reducing data overhead and improving efficiency. However, semantic communication is sensitive to channel variations, requiring adaptive mechanisms. To this end, fluid antennas (FAs) are introduced to support the NF-ISCSC system, enabling dynamic adaptability to changing channels. The proposed FA-enabled NF-ISCSC framework considers multiple communication users and extended targets compri...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15799v1" target="_blank">Quantum logic operations and algorithms in a single 25-level atomic qudit</a></h3>
                    <p><strong>Authors:</strong> Pei Jiang Low, Nicholas C. F. Zutt, Gaurav A. Tathed, Crystal Senko</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> Scaling quantum computers remains a substantial scientific and technological challenge. Leveraging the full range of intrinsic degrees of freedom in quantum systems offers a promising route towards enhanced algorithmic performance and hardware efficiency. We experimentally study the use of $^{137}$Ba$^+$ ions for quantum information processing, achieving high-fidelity state preparation and readout of up to 25 internal levels, thus forming a 25-dimensional qudit. By probing superpositions of up to 24 states, we investigate how errors scale with qudit dimension $d$ and identify the primary error sources affecting quantum coherence. Additionally, we demonstrate high-dimensional qudit operations by implementing a 3-qubit Bernstein-Vazirani algorithm and a 4-qubit Toffoli gate with a single ion. Our findings suggest that quantum computing architectures based on large-dimensional qudits hold significant promise.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15798v1" target="_blank">Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models</a></h3>
                    <p><strong>Authors:</strong> Lilian Hollard, Lucas Mohimont, Nathalie Gaveau, Luiz-Angelo Steffenel</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The paper investigates the performance of state-of-the-art low-parameter deep neural networks for computer vision, focusing on bottleneck architectures and their behavior using superlinear activation functions. We address interference in feature maps, a phenomenon associated with superposition, where neurons simultaneously encode multiple characteristics. Our research suggests that limiting interference can enhance scaling and accuracy in very low-scaled networks (under 1.5M parameters). We identify key design elements that reduce interference by examining various bottleneck architectures, leading to a more efficient neural network. Consequently, we propose a proof-of-concept architecture named NoDepth Bottleneck built on mechanistic insights from our experiments, demonstrating robust scaling accuracy on the ImageNet dataset. These findings contribute to more efficient and scalable neural networks for the low-parameter range and advance the understanding of bottlenecks in computer visi...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15797v1" target="_blank">Deterministic Quantum Search via Recursive Oracle Expansion</a></h3>
                    <p><strong>Authors:</strong> John Burke, Ciaran McGoldrick</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.ET, 81P68 (Primary), 68Q12 68Q25 (Secondary), F.1.2</p>
                    <p><strong>Summary:</strong> We introduce a novel deterministic quantum search algorithm that provides a practical alternative to conventional probabilistic search approaches. Our scheme eliminates the inherent uncertainty of quantum search without relying on arbitrary phase rotations, a key limitation of other deterministic methods. The algorithm achieves certainty by recursively expanding the base oracle so that it marks all states prefixed by the same two bits as the target, encompassing exactly one-quarter of the search space. This enables a step-by-step reduction of the superposition until the target state can be measured with certainty. The algorithm achieves deterministic success with a query complexity of $O(N^{\log_2(3)/2}) \approx O(N^{0.7925})$, falling between Grovers $O(\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively on two-qubit nearest-neighbour diffusion operators, avoiding global diffusion entirely. We show that, despite the increased query complexity, this design redu...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15795v1" target="_blank">Quantum gravity black holes as dark matter?</a></h3>
                    <p><strong>Authors:</strong> Bernard Carr, Piero Nicolini, Athanasios G. Tzikas</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> gr-qc, hep-th</p>
                    <p><strong>Summary:</strong> One of the major problems in quantum gravity research is the lack of signals at the reach of present or near-future experimental facilities. In this paper, we show that this is not the case. Contrary to previous claims, the quantum decay of de Sitter space into black hole spacetimes can be significant even after inflation and can be observed on galactic scales. Using the instanton formalism within the no-boundary proposal for a class of short-scale, quantum-gravity-improved black holes, we show that de Sitter space decay would result in the production of $10^{60}$ stable Planck-size black hole remnants within the current Hubble horizon, which is the number required to explain dark matter.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15793v1" target="_blank">Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation</a></h3>
                    <p><strong>Authors:</strong> Ghassen Baklouti, Julio Silva-RodrÃ­guez, Jose Dolz, Houda Bahig, Ismail Ben Ayed</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is increasingly attracting interest in medical imaging due to its effectiveness and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA) is a notable approach based on the assumption that the adaptation inherently occurs in a low-dimensional subspace. While it has shown good performance, its implementation requires a fixed and unalterable rank, which might be challenging to select given the unique complexities and requirements of each medical imaging downstream task. Inspired by advancements in natural image processing, we introduce a novel approach for medical image segmentation that dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank representation of the trainable weight matrices as a singular value decomposition, we introduce an l_1 sparsity regularizer to the loss function, and tackle it with a proximal optimizer. The regularizer could be viewed as a penalty on t...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15792v1" target="_blank">Enhanced Superconductivity and Vortex Dynamics in One-Dimensional TaS2 Nanowires</a></h3>
                    <p><strong>Authors:</strong> Mathew Pollard, Visakha Ho, Clarissa Wisner, Eric Bohannan, Yew San Hor</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cond-mat.supr-con, cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.str-el</p>
                    <p><strong>Summary:</strong> We report the synthesis of high-quality 2H-TaS2 nanowires via a controlled two-step conversion process from TaS3 precursors, achieving robust superconductivity with a transition temperature Tc ~ 3.6 K which is significantly higher than bulk 2H-TaS2 (Tc ~ 0.8 K). Structural and compositional analyses confirm phase purity and preserved 1D morphology, while magnetotransport measurements reveal an enhanced upper critical field {\mu}oHc2 (2 K) ~ 5 T, far exceeding the bulk value ({\mu}oHc2 (0) ~ 1.17 T), attributed to dimensional confinement and suppression of charge density wave order. Magnetic characterization demonstrates complex vortex dynamics, including flux jumps and a second magnetization peak, indicative of strong pinning and crossover from elastic to plastic vortex regimes. These findings establish TaS2 nanowires as a versatile platform for studying superconductivity in reduced dimensions and exploiting confinement-driven quantum phenomena for advanced applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15791v1" target="_blank">\texttt{GWBird}: a toolkit for the characterization of the Stochastic Gravitational Wave Background for Ground, Space, and Pulsar Timing Array detectors</a></h3>
                    <p><strong>Authors:</strong> Ilaria Caporali, Angelo Ricciardone</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM, astro-ph.CO, gr-qc</p>
                    <p><strong>Summary:</strong> The detection of the Stochastic Gravitational Wave Background (SGWB) is one of the most challenging tasks for both current and next-generation detectors. Successfully distinguishing the SGWB from instrumental noise and environmental effects requires accurate and flexible analysis tools capable of detecting the signal and determining its origin. In this paper, we introduce a unified framework and a user-friendly tool for SGWB characterization: \texttt{GWBird} (Gravitational Wave Background Inventory of Response functions for Detectors). This code enables the computation of overlap reduction functions (ORFs), power-law integrated sensitivity curves (PLS), angular response functions, and angular PLS (APLS). It supports the full range of gravitational wave polarization modes (tensor, scalar, and vector), allowing for the characterization of both isotropic and anisotropic SGWB components for all the polarizations. Additionally, the code includes functions for circular polarization character...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15788v1" target="_blank">Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Sneheel Sarangi, Hanan Salam</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Recent advancements in large language models (LLMs) have demonstrated emergent capabilities in complex reasoning, largely spurred by rule-based Reinforcement Learning (RL) techniques applied during the post-training. This has raised the question of whether similar methods can instill more nuanced, human-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This paper investigates whether small-scale LLMs can acquire a robust and generalizable ToM capability through RL with verifiable rewards (RLVR). We conduct a systematic evaluation by training models on various combinations of prominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for generalization on held-out datasets (e.g., OpenToM). Our findings indicate that small LLMs struggle to develop a generic ToM capability. While performance on in-distribution tasks improves, this capability fails to transfer to unseen ToM tasks with different characteristics. Furthermore, we demonstrate that prolonged RL training lea...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15787v1" target="_blank">Missing Physics Discovery through Fully Differentiable Finite Element-Based Machine Learning</a></h3>
                    <p><strong>Authors:</strong> Ado Farsi, Nacime Bouziani, David A Ham</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CE</p>
                    <p><strong>Summary:</strong> Although many problems in science and engineering are modelled by well-established PDEs, they often involve unknown or incomplete relationships, such as material constitutive laws or thermal response, that limit accuracy and generality. Existing surrogate-modelling approaches directly approximate PDE solutions but remain tied to a specific geometry, boundary conditions, and set of physical constraints. To address these limitations, we introduce a fully differentiable finite element-based machine learning (FEBML) framework that embeds trainable operators for unknown physics within a state-of-the-art, general FEM solver, enabling true end-to-end differentiation. At its core, FEBML represents each unknown operator as an encode-process-decode pipeline over finite-element degrees of freedom: field values are projected to nodal coefficients, transformed by a neural network, and then lifted back to a continuous FE function, ensuring the learned physics respects the variational structure. We d...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15786v1" target="_blank">A Robust COTS Objective for Diffraction-Limited, High-NA, Long Front Working Distance Imaging</a></h3>
                    <p><strong>Authors:</strong> Jiafeng Cui, Gilles Buchs, Christopher M. Seck</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> physics.atom-ph, physics.optics, quant-ph</p>
                    <p><strong>Summary:</strong> We present a robust objective lens optimized for applications requiring both high numerical aperture (NA) and long front working distance imaging comprised of all commercial-off-the-shelf (COTS) singlet lenses. Unlike traditional designs that require separate collimation and refocusing stages, our approach directly converges imaged light to the back focal plane using a single lens group. Our configuration corrects spherical aberrations and efficiently collects light to achieve diffraction-limited performance across a wide range of wavelengths while simplifying alignment and assembly. Using this approach, we design and construct an example objective lens that features a long front working distance of 61 mm and a clipped NA of 0.30 (limited by an aperture in our experimental setup). We experimentally verify that it achieves monochromatic diffraction-limited resolution at wavelengths from 375 nm to 866 nm without requiring replacement of the lenses or changing the inter-lens spacings, and...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15785v1" target="_blank">Toric intersections</a></h3>
                    <p><strong>Authors:</strong> Anargyros Katsabekis, Apostolos Thoma</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> math.AC, math.AG, 14M25, 13F65, 05C25, 05E40</p>
                    <p><strong>Summary:</strong> Let $I_A \subset K[x_1,\ldots,x_n]$ be a toric ideal. In this paper, we provide a necessary and sufficient condition for the toric variety $V(I_A)$, over an algebraically closed field, to be expressed as the set-theoretic intersection of other toric varieties. We also introduce the invariant ${\rm Split}_{\rm rad}(I_A)$, defined as the smallest integer $r$ for which there exist toric ideals $I_{A_1}, \dots, I_{A_r}$ satisfying $I_A = {\rm rad}(I_{A_1} + \cdots + I_{A_r})$ and $I_{A_i} \neq I_A$ for all $1 \leq i \leq r$. We then compute its exact value in several cases, including the case in which $I_A$ is the toric ideal of a complete bipartite graph. Additionally, we show that ${\rm Split}_{\rm rad}(I_A)$ is equal to the binomial arithmetical rank of $I_A$ when the height of $I_A$ is equal to 2.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15783v2" target="_blank">Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance</a></h3>
                    <p><strong>Authors:</strong> Mohammad Matt Namvarpour, Brandon Brofsky, Jessica Medina, Mamtaj Akter, Afsaneh Razi</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.CY</p>
                    <p><strong>Summary:</strong> As Generative Artificial Intelligence (GenAI) driven chatbots like Character.AI become embedded in adolescent life, they raise concerns about emotional dependence and digital overreliance. While studies have investigated the overreliance of adults on these chatbots, they have not investigated teens interactions with chatbots with customizable personas. We analyzed 318 Reddit posts made by users self-reported as 13-17 years old on the Character.AI subreddit to understand patterns of overreliance. We found teens commonly begin using chatbots for emotional support or creative expression, but many develop strong attachments that interfere with offline relationships and daily routines. Their posts revealed recurring signs of psychological distress, cycles of relapse, and difficulty disengaging. Teens reported that their overreliance often ended when they reflect on the harm, return to in-person social settings, or become frustrated by platform restrictions. Based on the implications of our ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15780v1" target="_blank">Pairs of intertwined integer sequences</a></h3>
                    <p><strong>Authors:</strong> Christian Kassel, Christophe Reutenauer</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> math.NT, math.CO, 11T55, 14N10</p>
                    <p><strong>Summary:</strong> In previous work we computed the number $C_n(q)$ of ideals of codimension $n$ of the algebra ${\mathbb{F}}_q[x,y,x^{-1}, y^{-1}]$ of two-variable Laurent polynomials over a finite field: it turned out that $C_n(q)$ is a palindromic polynomial of degree $2n$ in $q$, divisible by $(q-1)^2$. The quotient $P_n(q) = C_n(q)/(q-1)^2$ is a palindromic polynomial of degree $2n-2$. For each $n\geq 1$ there is a unique degree $n-1$ polynomial ${\overline{P}}_n(X) \in {\mathbb{Z}}[X]$ such that ${\overline{P}}_n(q+q^{-1}) = P_n(q)/q^{n-1}$. In this note we show that for any integer $N$ the integer value ${\overline{P}}_n(N)$ is close to the value at $N$ of the degree $n-1$ polynomial $F_{n-1}(X) = 1 + \sum_{k=1}^{n-1} \, {\overline{T}}_k(X)$, which is a sum of monic versions ${\overline{T}}_k(X)$ of Chebyshev polynomials of the first kind. We give a precise formula for ${\overline{P}}_n(X)$ as a linear combination of $F_k(X)$s, each appearance of the latter being parametrized by an odd divisor of ...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15779v1" target="_blank">Reservoir Computing as a Language Model</a></h3>
                    <p><strong>Authors:</strong> Felix KÃ¶ster, Atsushi Uchida</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLM) have dominated the science and media landscape duo to their impressive performance on processing large chunks of data and produce human-like levels of text. Nevertheless, their huge energy demand and slow processing still a bottleneck for further increasing quality while also making the models accessible to everyone. To solve this bottleneck, we will investigate how reservoir computing performs on natural text processing, which could enable fast and energy efficient hardware implementations. Studies investigating the use of reservoir computing as a language model remain sparse. In this paper, we compare three distinct approaches for character-level language modeling, two different reservoir computing approaches, where only an output layer is trainable, and the well-known transformer-based architectures, which fully learn an attention-based sequence representation. We explore the performance, computational cost and prediction accuracy for both paradigms by eq...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15778v1" target="_blank">Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR</a></h3>
                    <p><strong>Authors:</strong> Jiakang Wang, Runze Liu, Fuzheng Zhang, Xiu Li, Guorui Zhou</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective post-training method for improving the reasoning abilities of Large Language Models (LLMs), mainly by shaping higher-order behaviors such as reflection and planning. However, previous RLVR algorithms often apply uniform training signals to all tokens, without considering the different roles of low-entropy knowledge-related tokens and high-entropy reasoning-related tokens. Some recent methods try to separate these token types by gradient masking or asynchronous updates, but these approaches may break semantic dependencies in the model output and hinder effective learning. In this work, we propose Archer, an entropy-aware RLVR approach with dual-token constraints and synchronous updates. Specifically, our method applies weaker KL regularization and higher clipping thresholds to reasoning tokens to encourage exploration, while using stronger constraints on knowledge tokens to maintain factual knowledge. Experime...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15777v1" target="_blank">Label tree semantic losses for rich multi-class medical image segmentation</a></h3>
                    <p><strong>Authors:</strong> Junwen Wang, Oscar MacCormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Rich and accurate medical image segmentation is poised to underpin the next generation of AI-defined clinical practice by delineating critical anatomy for pre-operative planning, guiding real-time intra-operative navigation, and supporting precise post-operative assessment. However, commonly used learning methods for medical and surgical imaging segmentation tasks penalise all errors equivalently and thus fail to exploit any inter-class semantics in the labels space. This becomes particularly problematic as the cardinality and richness of labels increases to include subtly different classes. In this work, we propose two tree-based semantic loss functions which take advantage of a hierarchical organisation of the labels. We further incorporate our losses in a recently proposed approach for training with sparse, background-free annotations to extend the applicability of our proposed losses. Extensive experiments are reported on two medical and surgical image segmentation tasks, namely he...</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1080/17588928.2025.2532604" target="_blank">Dissociating model architectures from inference computations</a></h3>
                    <p><strong>Authors:</strong> Noor Sajid, Johan Medrano</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Parr et al., 2025 examines how auto-regressive and deep temporal models differ in their treatment of non-Markovian sequence modelling. Building on this, we highlight the need for dissociating model architectures, i.e., how the predictive distribution factorises, from the computations invoked at inference. We demonstrate that deep temporal computations are mimicked by autoregressive models by structuring context access during iterative inference. Using a transformer trained on next-token prediction, we show that inducing hierarchical temporal factorisation during iterative inference maintains predictive capacity while instantiating fewer computations. This emphasises that processes for constructing and refining predictions are not necessarily bound to their underlying model architectures.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15775v1" target="_blank">Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity</a></h3>
                    <p><strong>Authors:</strong> Mingyuan Sun, Zheng Fang, Jiaxu Wang, Kunyi Zhang, Qiang Zhang, Renjing Xu</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.IM, cs.AI</p>
                    <p><strong>Summary:</strong> We present GravLensX, an innovative method for rendering black holes with gravitational lensing effects using neural networks. The methodology involves training neural networks to fit the spacetime around black holes and then employing these trained models to generate the path of light rays affected by gravitational lensing. This enables efficient and scalable simulations of black holes with optically thin accretion disks, significantly decreasing the time required for rendering compared to traditional methods. We validate our approach through extensive rendering of multiple black hole systems with superposed Kerr metric, demonstrating its capability to produce accurate visualizations with significantly $15\times$ reduced computational time. Our findings suggest that neural networks offer a promising alternative for rendering complex astrophysical phenomena, potentially paving a new path to astronomical visualization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15773v2" target="_blank">Supernova: Achieving More with Less in Transformer Architectures</a></h3>
                    <p><strong>Authors:</strong> Andrei-Valentin Tanase, Elena Pelican</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> We present Supernova, a 650M-parameter decoder-only transformer that demonstrates how careful architectural design and tokenization innovation can achieve the performance of larger models while maintaining computational efficiency. Our architecture combines Rotary Positional Embeddings (RoPE), Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for computational efficiency, and SwiGLU activation functions. A critical innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which achieves state-of-the-art compression performance. Through detailed analysis, we show that Supernova achieves 90% of the performance of 1B-parameter models while using 35% fewer parameters and requiring only 100B training tokens--an order of magnitude less than competing models. Our findings challenge the prevailing scaling paradigm, demonstrating that architectural efficiency and tokenization quality can compensate for reduced parameter counts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15771v1" target="_blank">Left Leaning Models: AI Assumptions on Economic Policy</a></h3>
                    <p><strong>Authors:</strong> Maxim Chupilkin</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> How does AI think about economic policy? While the use of large language models (LLMs) in economics is growing exponentially, their assumptions on economic issues remain a black box. This paper uses a conjoint experiment to tease out the main factors influencing LLMs evaluation of economic policy. It finds that LLMs are most sensitive to unemployment, inequality, financial stability, and environmental harm and less sensitive to traditional macroeconomic concerns such as economic growth, inflation, and government debt. The results are remarkably consistent across scenarios and across models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15770v1" target="_blank">A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining</a></h3>
                    <p><strong>Authors:</strong> Yifan Shen, Zihan Zhao, Xiao Xue, Yuwei Guo, Qun Ma, Deyu Zhou, Ming Zhang</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments...</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2507.15769v1" target="_blank">Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks</a></h3>
                    <p><strong>Authors:</strong> Ahmad M. Nazar, Abdulkadir Celik, Mohamed Y. Selim, Asmaa Abdallah, Daji Qiao, Ahmed M. Eltawil</p>
                    <p><strong>Published:</strong> 7/21/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Vehicular communication systems operating in the millimeter wave (mmWave) band are highly susceptible to signal blockage from dynamic obstacles such as vehicles, pedestrians, and infrastructure. To address this challenge, we propose a proactive blockage prediction framework that utilizes multi-modal sensing, including camera, GPS, LiDAR, and radar inputs in an infrastructure-to-vehicle (I2V) setting. This approach uses modality-specific deep learning models to process each sensor stream independently and fuses their outputs using a softmax-weighted ensemble strategy based on validation performance. Our evaluations, for up to 1.5s in advance, show that the camera-only model achieves the best standalone trade-off with an F1-score of 97.1% and an inference time of 89.8ms. A camera+radar configuration further improves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness and efficiency of multi-modal sensing for mmWave blockage prediction and provide a pathway for proactive...</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

