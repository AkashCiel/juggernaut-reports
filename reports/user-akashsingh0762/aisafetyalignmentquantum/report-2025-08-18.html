
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-18<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 125
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

The research papers provided cover a broad range of topics, many of which do not directly pertain to AI safety research. However, within this set, several papers provide insights into trends, breakthroughs, and implications relevant to AI safety. 

One notable trend is the increasing concern over the ethical implications and biases inherent in AI systems, as seen in the studies on speciesism in AI models and the user-centered approach to AI ethics. The paper on speciesism in AI uncovers biases in large language models (LLMs) against non-human animals, emphasizing the need to expand fairness frameworks to address such biases. The study on AI ethics highlights the importance of understanding user preferences for ethical principles, revealing cultural and contextual variations. This suggests a move towards more nuanced, user-driven ethical frameworks in AI. Additionally, the paper on deepfake scams targeting older adults underscores the growing sophistication of AI-driven threats and the importance of intergenerational support systems to enhance resilience. Another significant development is the exploration of strategies to mitigate over-refusals in LLMs, where safety mechanisms reject benign prompts. This is addressed by the development of the SafeConstellations approach, which optimizes task-specific pathways to reduce unnecessary refusals, thereby balancing safety and utility in AI applications.

Collectively, these studies highlight the ongoing challenges and advancements in ensuring AI systems are safe, ethical, and aligned with human values. Researchers are increasingly focusing on addressing biases, improving ethical frameworks, and enhancing the resilience of AI systems against misuse and exploitation. These efforts are crucial for fostering trust and ensuring that AI technologies are responsibly integrated into society.

*Based on 50 research papers*

---

## ai alignment research

The provided list of research papers does not directly focus on AI alignment research, which typically examines how to ensure that artificial intelligence systems operate in accordance with human intentions and ethical guidelines. However, certain papers within the list tangentially relate to AI alignment concepts, particularly those involving value systems, ethical considerations, and the interpretability of AI models.

For instance, the paper Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models investigates biases within AI systems, which is a crucial aspect of AI alignment. It explores how large language models (LLMs) may exhibit speciesist biases, reflecting the need for expanding AI fairness frameworks to include non-human moral considerations. This aligns with broader efforts in AI alignment to ensure fairness and ethical decision-making across diverse scenarios. Similarly, the study Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions explores modifying AI systems value alignment through targeted training, which directly pertains to aligning AI behavior with desired human values. Lastly, the paper Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis addresses the challenge of aligning AI systems with expert clinical reasoning, ensuring transparency and trustworthiness in sensitive applications like mental health. These papers collectively indicate a trend towards addressing biases, enhancing interpretability, and aligning AI systems with complex human values and ethical standards.

*Based on 50 research papers*

---

## quantum computing

The provided research papers do not directly address quantum computing as their primary focus. However, one paper, Quantum Simulation of Collective Neutrino Oscillations in Dense Neutrino Environment, is relevant to quantum computing through the use of quantum simulators to model complex quantum systems. This study utilizes a quantum simulator and a quantum processor to explore neutrino oscillations, employing quantum circuits to simulate these interactions. It highlights the application of quantum computing techniques, such as the Trotter-Suzuki approximation, to decompose complex quantum interactions into simpler components for simulation. This paper underscores the potential of quantum computing to advance our understanding of fundamental quantum phenomena, demonstrating its utility in simulating systems that are otherwise difficult to model classically.

In the broader context of current trends and breakthroughs in quantum computing, this approach exemplifies how quantum simulators can tackle specific quantum mechanical problems, such as particle interactions in high-energy physics. The use of quantum computing to model complex systems suggests a growing trend of leveraging these technologies for scientific research beyond traditional computing capabilities. This aligns with the fields ongoing exploration of quantum systems for practical applications, including materials science, cryptography, and optimization problems. While the specific focus on neutrino oscillations is niche, it illustrates the expanding frontier of quantum computing applications in scientific research, potentially paving the way for breakthroughs in understanding and harnessing quantum mechanics in diverse fields.

*Based on 25 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.11618v1" target="_blank">Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective</a></h3>
                    <p><strong>Authors:</strong> Jungang Chen, Seyyed A. Hosseini</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Carbon capture and storage (CCS) projects typically involve a diverse array of stakeholders or players from public, private, and regulatory sectors, each with different objectives and responsibilities. Given the complexity, scale, and long-term nature of CCS operations, determining whether individual stakeholders can independently maximize their interests or whether collaborative coalition agreements are needed remains a central question for effective CCS project planning and management. CCS projects are often implemented in geologically connected sites, where shared geological features such as pressure space and reservoir pore capacity can lead to competitive behavior among stakeholders. Furthermore, CO2 storage sites are often located in geologically mature basins that previously served as sites for hydrocarbon extraction or wastewater disposal in order to leverage existing infrastructures, which makes unilateral optimization even more complicated and unrealistic. In this work, we propose a paradigm based on Markov games to quantitatively investigate how different coalition structures affect the goals of stakeholders. We frame this multi-stakeholder multi-site problem as a multi-agent reinforcement learning problem with safety constraints. Our approach enables agents to learn optimal strategies while compliant with safety regulations. We present an example where multiple operators are injecting CO2 into their respective project areas in a geologically connected basin. To address the high computational cost of repeated simulations of high-fidelity models, a previously developed surrogate model based on the Embed-to-Control (E2C) framework is employed. Our results demonstrate the effectiveness of the proposed framework in addressing optimal management of CO2 storage when multiple stakeholders with various objectives and goals are involved.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11613v1" target="_blank">Adaptive Cardio Load Targets for Improving Fitness and Performance</a></h3>
                    <p><strong>Authors:</strong> Justin Phillips, Daniel Roggen, Cathy Speed, Robert Harle</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Cardio Load, introduced by Google in 2024, is a measure of cardiovascular work (also known as training load) resulting from all the users activities across the day. It is based on heart rate reserve and captures both activity intensity and duration. Thanks to feedback from users and internal research, we introduce adaptive and personalized targets which will be set weekly. This feature will be available in the Public Preview of the Fitbit app after September 2025. This white paper provides a comprehensive overview of Cardio Load (CL) and how weekly CL targets are established, with examples shown to illustrate the effect of varying CL on the weekly target. We compare Cardio Load and Active Zone Minutes (AZMs), highlighting their distinct purposes, i.e. AZMs for health guidelines and CL for performance measurement. We highlight that CL is accumulated both during active workouts and incidental daily activities, so users are able top-up their CL score with small bouts of activity across the day.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11607v1" target="_blank">TinyTim: A Family of Language Models for Divergent Generation</a></h3>
                    <p><strong>Authors:</strong> Christopher J. Agostino</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This work introduces TinyTim, a family of large language models fine-tuned on James Joyces `Finnegans Wake. Through quantitative evaluation against baseline models, we demonstrate that TinyTim V1 produces a statistically distinct generative profile characterized by high lexical diversity and low semantic coherence. These findings are interpreted through theories of creativity and complex problem-solving, arguing that such specialized models can function as divergent knowledge sources within more extensive creative architectures, powering automated discovery mechanisms in diverse settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11605v1" target="_blank">Dataset Creation for Visual Entailment using Generative AI</a></h3>
                    <p><strong>Authors:</strong> Rob Reijtenbach, Suzan Verberne, Gijs Wijnholds</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In this paper we present and validate a new synthetic dataset for training visual entailment models. Existing datasets for visual entailment are small and sparse compared to datasets for textual entailment. Manually creating datasets is labor-intensive. We base our synthetic dataset on the SNLI dataset for textual entailment. We take the premise text from SNLI as input prompts in a generative image model, Stable Diffusion, creating an image to replace each textual premise. We evaluate our dataset both intrinsically and extrinsically. For extrinsic evaluation, we evaluate the validity of the generated images by using them as training data for a visual entailment classifier based on CLIP feature vectors. We find that synthetic training data only leads to a slight drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when trained on real data. We also compare the quality of our generated training data to original training data on another dataset: SICK-VTE. Again, there is only a slight drop in F-score: from 0.400 to 0.384. These results indicate that in settings with data sparsity, synthetic data can be a promising solution for training visual entailment models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11581v1" target="_blank">Stabilizing and Tuning Superconductivity in La$_3$Ni$_2$O$_{7-Î´}$ Films: Oxygen Recycling Protocol Reveals Hole-Doping Analogue</a></h3>
                    <p><strong>Authors:</strong> Lifen Xiang, Siyi Lei, Xiaolin Ren, Ziao Han, Zijian Xu, X. J. Zhou, Zhihai Zhu</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> The recent achievement of superconductivity in La$_3$Ni$_2$O$_{7-\delta}$ with transition temperatures exceeding 40 K in thin films under compressive strain and 80 K in bulk crystals under high pressure opens new avenues for research on high-temperature superconductivity. The realization of superconductivity in thin films requires delicate control of growth conditions, which presents significant challenges in the synthesis process. Furthermore, the stability of superconducting La$_3$Ni$_2$O$_{7-\delta}$ films is compromised by oxygen loss, which complicates their characterization. We introduce an effective recycling protocol that involves oxygen removal in a precursor phase followed by ozone-assisted annealing, which restores superconducting properties. By tuning the oxygen content, we construct an electronic phase diagram that highlights oxygen addition as a potential analogue to hole doping via La substitution with Sr, providing insights into the doping mechanism and guiding future material optimization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11579v1" target="_blank">Intergenerational Support for Deepfake Scams Targeting Older Adults</a></h3>
                    <p><strong>Authors:</strong> Karina LaRubbio, Alyssa Lanter, Seihyun Lee, Mahima Ramesh, Diana Freed</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> AI-enhanced scams now employ deepfake technology to produce convincing audio and visual impersonations of trusted family members, often grandchildren, in real time. These attacks fabricate urgent scenarios, such as legal or medical emergencies, to socially engineer older adults into transferring money. The realism of these AI-generated impersonations undermines traditional cues used to detect fraud, making them a powerful tool for financial exploitation. In this study, we explore older adults perceptions of these emerging threats and their responses, with a particular focus on the role of youth, who may also be impacted by having their identities exploited, in supporting older family members online safety. We conducted focus groups with 37 older adults (ages 65+) to examine their understanding of deepfake impersonation scams and the value of intergenerational technology support. Findings suggest that older adults frequently rely on trusted relationships to detect scams and develop protective practices. Based on this, we identify opportunities to engage youth as active partners in enhancing resilience across generations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11571v1" target="_blank">Temporal Network Analysis of Microservice Architectural Degradation</a></h3>
                    <p><strong>Authors:</strong> Alexander Bakhtin</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.DM</p>
                    <p><strong>Summary:</strong> Microservice architecture can be modeled as a network of microservices making calls to each other, commonly known as the service dependency graph. Network Science can provide methods to study such networks. In particular, temporal network analysis is a branch of Network Science that analyzes networks evolving with time. In microservice systems, temporal networks can arise if we examine the architecture of the system across releases or monitor a deployed system using tracing. In this research summary paper, I discuss the challenges in obtaining temporal networks from microservice systems and analyzing them with the temporal network methods. In particular, the most complete temporal network that we could obtain contains 7 time instances and 42 microservices, which limits the potential analysis that could be applied.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11551v1" target="_blank">ADMIRE-BayesOpt: Accelerated Data MIxture RE-weighting for Language Models with Bayesian Optimization</a></h3>
                    <p><strong>Authors:</strong> Shengzhuang Chen, Xu Ouyang, Michael Arthur Leopold Pearce, Thomas Hartvigsen, Jonathan Richard Schwarz</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Determining the optimal data mixture for large language model training remains a challenging problem with an outsized impact on performance. In practice, language model developers continue to rely on heuristic exploration since no learning-based approach has emerged as a reliable solution. In this work, we propose to view the selection of training data mixtures as a black-box hyperparameter optimization problem, for which Bayesian Optimization is a well-established class of appropriate algorithms. Firstly, we cast data mixture learning as a sequential decision-making problem, in which we aim to find a suitable trade-off between the computational cost of training exploratory (proxy-) models and final mixture performance. Secondly, we systematically explore the properties of transferring mixtures learned at a small scale to larger-scale experiments, providing insights and highlighting opportunities for research at a modest scale. By proposing Multi-fidelity Bayesian Optimization as a suitable method in this common scenario, we introduce a natural framework to balance experiment cost with model fit, avoiding the risks of overfitting to smaller scales while minimizing the number of experiments at high cost. We present results for pre-training and instruction finetuning across models ranging from 1 million to 7 billion parameters, varying from simple architectures to state-of-the-art models and benchmarks spanning dozens of datasets. We demonstrate consistently strong results relative to a wide range of benchmarks, showingspeed-ups of over 500% in determining the best data mixture on our largest experiments relative to recent baselines. In addition, we broaden access to research by sharing ADMIRE IFT Runs, a dataset of 460 full training  evaluation runs across various model sizes worth over 13,000 GPU hours, greatly reducing the cost of conducting research in this area.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11548v1" target="_blank">Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends</a></h3>
                    <p><strong>Authors:</strong> Zhenhua Xu, Xubin Yue, Zhebo Wang, Qichen Liu, Xixiang Zhao, Jingxuan Zhang, Wenjun Zeng, Wengpeng Xing, Dezhang Kong, Changting Lin, Meng Han</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Copyright protection for large language models is of critical importance, given their substantial development costs, proprietary value, and potential for misuse. Existing surveys have predominantly focused on techniques for tracing LLM-generated content-namely, text watermarking-while a systematic exploration of methods for protecting the models themselves (i.e., model watermarking and model fingerprinting) remains absent. Moreover, the relationships and distinctions among text watermarking, model watermarking, and model fingerprinting have not been comprehensively clarified. This work presents a comprehensive survey of the current state of LLM copyright protection technologies, with a focus on model fingerprinting, covering the following aspects: (1) clarifying the conceptual connection from text watermarking to model watermarking and fingerprinting, and adopting a unified terminology that incorporates model watermarking into the broader fingerprinting framework; (2) providing an overview and comparison of diverse text watermarking techniques, highlighting cases where such methods can function as model fingerprinting; (3) systematically categorizing and comparing existing model fingerprinting approaches for LLM copyright protection; (4) presenting, for the first time, techniques for fingerprint transfer and fingerprint removal; (5) summarizing evaluation metrics for model fingerprints, including effectiveness, harmlessness, robustness, stealthiness, and reliability; and (6) discussing open challenges and future research directions. This survey aims to offer researchers a thorough understanding of both text watermarking and model fingerprinting technologies in the era of LLMs, thereby fostering further advances in protecting their intellectual property.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11544v1" target="_blank">Grand Challenge: Mediating Between Confirmatory and Exploratory Research Cultures in Health Sciences and Visual Analytics</a></h3>
                    <p><strong>Authors:</strong> Viktor von Wyl, JÃ¼rgen Bernard</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Collaboration between health science and visual analytics research is often hindered by different, sometimes incompatible approaches to research design. Health science often follows hypothesis-driven protocols, registered in advance, and focuses on reproducibility and risk mitigation. Visual analytics, in contrast, relies on iterative data exploration, prioritizing insight generation and analytic refinement through user interaction. These differences create challenges in interdisciplinary projects, including misaligned terminology, unrealistic expectations about data readiness, divergent validation norms, or conflicting explainability requirements. To address these persistent tensions, we identify seven research needs and actions: (1) guidelines for broader community adoption, (2) agreement on quality and validation benchmarks, (3) frameworks for aligning research tasks, (4) integrated workflows combining confirmatory and exploratory stages, (5) tools for harmonizing terminology across disciplines, (6) dedicated bridging roles for transdisciplinary work, and (7) cultural adaptation and mutual recognition. We organize these needs in a framework with three areas: culture, standards, and processes. They can constitute a research agenda for developing reliable, reproducible, and clinically relevant data-centric methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11534v1" target="_blank">Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Monika JotautaitÄ—, Lucius Caviola, David A. Brewster, Thilo Hagendorff</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) become more widely deployed, it is crucial to examine their ethical tendencies. Building on research on fairness and discrimination in AI, we investigate whether LLMs exhibit speciesist bias -- discrimination based on species membership -- and how they value non-human animals. We systematically examine this issue across three paradigms: (1) SpeciesismBench, a 1,003-item benchmark assessing recognition and moral evaluation of speciesist statements; (2) established psychological measures comparing model responses with those of human participants; (3) text-generation tasks probing elaboration on, or resistance to, speciesist rationalizations. In our benchmark, LLMs reliably detected speciesist statements but rarely condemned them, often treating speciesist attitudes as morally acceptable. On psychological measures, results were mixed: LLMs expressed slightly lower explicit speciesism than people, yet in direct trade-offs they more often chose to save one human over multiple animals. A tentative interpretation is that LLMs may weight cognitive capacity rather than species per se: when capacities were equal, they showed no species preference, and when an animal was described as more capable, they tended to prioritize it over a less capable human. In open-ended text generation tasks, LLMs frequently normalized or rationalized harm toward farmed animals while refusing to do so for non-farmed animals. These findings suggest that while LLMs reflect a mixture of progressive and mainstream human views, they nonetheless reproduce entrenched cultural norms around animal exploitation. We argue that expanding AI fairness and alignment frameworks to explicitly include non-human moral patients is essential for reducing these biases and preventing the entrenchment of speciesist attitudes in AI systems and the societies they influence.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11529v1" target="_blank">A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow</a></h3>
                    <p><strong>Authors:</strong> George Paterakis, Andrea Castellani, George Papoutsoglou, Tobias Rodemann, Ioannis Tsamardinos</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Artificial intelligence is reshaping science and industry, yet many users still regard its models as opaque black boxes. Conventional explainable artificial-intelligence methods clarify individual predictions but overlook the upstream decisions and downstream quality checks that determine whether insights can be trusted. In this work, we present Holistic Explainable Artificial Intelligence (HXAI), a user-centric framework that embeds explanation into every stage of the data-analysis workflow and tailors those explanations to users. HXAI unifies six components (data, analysis set-up, learning process, model output, model quality, communication channel) into a single taxonomy and aligns each component with the needs of domain experts, data analysts and data scientists. A 112-item question bank covers these needs; our survey of contemporary tools highlights critical coverage gaps. Grounded in theories of human explanation, principles from human-computer interaction and findings from empirical user studies, HXAI identifies the characteristics that make explanations clear, actionable and cognitively manageable. A comprehensive taxonomy operationalises these insights, reducing terminological ambiguity and enabling rigorous coverage analysis of existing toolchains. We further demonstrate how AI agents that embed large-language models can orchestrate diverse explanation techniques, translating technical artifacts into stakeholder-specific narratives that bridge the gap between AI developers and domain experts. Departing from traditional surveys or perspective articles, this work melds concepts from multiple disciplines, lessons from real-world projects and a critical synthesis of the literature to advance a novel, end-to-end viewpoint on transparency, trustworthiness and responsible AI deployment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11524v1" target="_blank">Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Wenkai Yu, Jianhang Tang, Yang Zhang, Shanjiang Tang, Kebing Jin, Hankz Hankui Zhuo</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Addressing large-scale planning problems has become one of the central challenges in the planning community, deriving from the state-space explosion caused by growing objects and actions. Recently, researchers have explored the effectiveness of leveraging Large Language Models (LLMs) to generate helpful actions and states to prune the search space. However, prior works have largely overlooked integrating LLMs with domain-specific knowledge to ensure valid plans. In this paper, we propose a novel LLM-assisted planner integrated with problem decomposition, which first decomposes large planning problems into multiple simpler sub-tasks. Then we explore two novel paradigms to utilize LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where LLM4Inspire provides heuristic guidance according to general knowledge and LLM4Predict employs domain-specific knowledge to infer intermediate conditions. We empirically validate the effectiveness of our planner across multiple domains, demonstrating the ability of search space partition when solving large-scale planning problems. The experimental results show that LLMs effectively locate feasible solutions when pruning the search space, where infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds particular promise compared with LLM4Inspire, which offers general knowledge within LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11517v1" target="_blank">A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11</a></h3>
                    <p><strong>Authors:</strong> Shaoze Huang, Qi Liu, Chao Chen, Yuhang Chen</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Accelerated aging of transportation infrastructure in the rapidly developing Yangtze River Delta region necessitates efficient concrete crack detection, as crack deterioration critically compromises structural integrity and regional economic growth. To overcome the limitations of inefficient manual inspection and the suboptimal performance of existing deep learning models, particularly for small-target crack detection within complex backgrounds, this paper proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and segmentation model based on the YOLOv11n architecture. The proposed model integrates a three-stage optimization framework: (1) Embedding dynamic KernelWarehouse convolution (KWConv) within the backbone network to enhance feature representation through a dynamic kernel sharing mechanism; (2) Incorporating a triple attention mechanism (TA) into the feature pyramid to strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU loss function to facilitate adaptive bounding box regression penalization. Experimental validation demonstrates that the enhanced model achieves significant performance improvements over the baseline, attaining 91.3% precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the synergistic efficacy of the proposed modules. Furthermore, robustness tests indicate stable performance under conditions of data scarcity and noise interference. This research delivers an efficient computer vision solution for automated infrastructure inspection, exhibiting substantial practical engineering value.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11515v1" target="_blank">Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations</a></h3>
                    <p><strong>Authors:</strong> Qipeng Kuang, VÃ¡clav KÅ¯la, OndÅ™ej KuÅ¾elka, Yuanhong Wang, Yuyi Wang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI, 03C13, 68T27, F.4.0</p>
                    <p><strong>Summary:</strong> The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. The boundary between fragments for which WFOMC can be computed in polynomial time relative to the domain size lies between the two-variable fragment ($\text{FO}^2$) and the three-variable fragment ($\text{FO}^3$). It is known that WFOMC for \FOthree{} is $\mathsf{\#P_1}$-hard while polynomial-time algorithms exist for computing WFOMC for $\text{FO}^2$ and $\text{C}^2$, possibly extended by certain axioms such as the linear order axiom, the acyclicity axiom, and the connectedness axiom. All existing research has concentrated on extending the fragment with axioms on a single distinguished relation, leaving a gap in understanding the complexity boundary of axioms on multiple relations. In this study, we explore the extension of the two-variable fragment by axioms on two relations, presenting both negative and positive results. We show that WFOMC for $\text{FO}^2$ with two linear order relations and $\text{FO}^2$ with two acyclic relations are $\mathsf{\#P_1}$-hard. Conversely, we provide an algorithm in time polynomial in the domain size for WFOMC of $\text{C}^2$ with a linear order relation, its successor relation and another successor relation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11514v1" target="_blank">DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality</a></h3>
                    <p><strong>Authors:</strong> Qitong Chu, Yufeng Yue, Danya Yao, Huaxin Pei</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> The growing deployment of decision-making agents in dynamic environments increases the demand for safety verification. While critical testing scenario generation has emerged as an appealing verification methodology, effectively balancing diversity and criticality remains a key challenge for existing methods, particularly due to local optima entrapment in high-dimensional scenario spaces. To address this limitation, we propose a dual-space guided testing framework that coordinates scenario parameter space and agent behavior space, aiming to generate testing scenarios considering diversity and criticality. Specifically, in the scenario parameter space, a hierarchical representation framework combines dimensionality reduction and multi-dimensional subspace evaluation to efficiently localize diverse and critical subspaces. This guides dynamic coordination between two generation modes: local perturbation and global exploration, optimizing critical scenario quantity and diversity. Complementarily, in the agent behavior space, agent-environment interaction data are leveraged to quantify behavioral criticality/diversity and adaptively support generation mode switching, forming a closed feedback loop that continuously enhances scenario characterization and exploration within the parameter space. Experiments show our framework improves critical scenario generation by an average of 56.23\% and demonstrates greater diversity under novel parameter-behavior co-driven metrics when tested on five decision-making agents, outperforming state-of-the-art baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11504v1" target="_blank">Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection</a></h3>
                    <p><strong>Authors:</strong> Andrea Castellani, Zacharias Papadovasilakis, Giorgos Papoutsoglou, Mary Cole, Brian Bautsch, Tobias Rodemann, Ioannis Tsamardinos, Angela Harden</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CY</p>
                    <p><strong>Summary:</strong> Motor vehicle crashes remain a leading cause of injury and death worldwide, necessitating data-driven approaches to understand and mitigate crash severity. This study introduces a curated dataset of more than 3 million people involved in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3 million vehicle-level records for predictive analysis. The primary contribution is a transparent and reproducible methodology that combines Automated Machine Learning (AutoML) and explainable artificial intelligence (AI) to identify and interpret key risk factors associated with severe crashes. Using the JADBio AutoML platform, predictive models were constructed to distinguish between severe and non-severe crash outcomes. The models underwent rigorous feature selection across stratified training subsets, and their outputs were interpreted using SHapley Additive exPlanations (SHAP) to quantify the contribution of individual features. A final Ridge Logistic Regression model achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test set, with 17 features consistently identified as the most influential predictors. Key features spanned demographic, environmental, vehicle, human, and operational categories, including location type, posted speed, minimum occupant age, and pre-crash action. Notably, certain traditionally emphasized factors, such as alcohol or drug impairment, were less influential in the final model compared to environmental and contextual variables. Emphasizing methodological rigor and interpretability over mere predictive performance, this study offers a scalable framework to support Vision Zero with aligned interventions and advanced data-informed traffic safety policy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11484v1" target="_blank">CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Xiaoxue Wu, Bingjie Gao, Yu Qiao, Yaohui Wang, Xinyuan Chen</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Despite significant advances in video synthesis, research into multi-shot video generation remains in its infancy. Even with scaled-up models and massive datasets, the shot transition capabilities remain rudimentary and unstable, largely confining generated videos to single-shot sequences. In this work, we introduce CineTrans, a novel framework for generating coherent multi-shot videos with cinematic, film-style transitions. To facilitate insights into the film editing style, we construct a multi-shot video-text dataset Cine250K with detailed shot annotations. Furthermore, our analysis of existing video diffusion models uncovers a correspondence between attention maps in the diffusion model and shot boundaries, which we leverage to design a mask-based control mechanism that enables transitions at arbitrary positions and transfers effectively in a training-free setting. After fine-tuning on our dataset with the mask mechanism, CineTrans produces cinematic multi-shot sequences while adhering to the film editing style, avoiding unstable transitions or naive concatenations. Finally, we propose specialized evaluation metrics for transition control, temporal consistency and overall quality, and demonstrate through extensive experiments that CineTrans significantly outperforms existing baselines across all criteria.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11482v1" target="_blank">OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring</a></h3>
                    <p><strong>Authors:</strong> Ruoxin Xiong, Yanyu Wang, Jiannan Cai, Kaijian Liu, Yuansheng Zhu, Pingbo Tang, Nora El-Gohary</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The construction industry increasingly relies on visual data to support Artificial Intelligence (AI) and Machine Learning (ML) applications for site monitoring. High-quality, domain-specific datasets, comprising images, videos, and point clouds, capture site geometry and spatiotemporal dynamics, including the location and interaction of objects, workers, and materials. However, despite growing interest in leveraging visual datasets, existing resources vary widely in sizes, data modalities, annotation quality, and representativeness of real-world construction conditions. A systematic review to categorize their data characteristics and application contexts is still lacking, limiting the communitys ability to fully understand the dataset landscape, identify critical gaps, and guide future directions toward more effective, reliable, and scalable AI applications in construction. To address this gap, this study conducts an extensive search of academic databases and open-data platforms, yielding 51 publicly available visual datasets that span the 2005-2024 period. These datasets are categorized using a structured data schema covering (i) data fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv) downstream application domains (e.g., progress tracking). This study synthesizes these findings into an open-source catalog, OpenConstruction, supporting data-driven method development. Furthermore, the study discusses several critical limitations in the existing construction dataset landscape and presents a roadmap for future data infrastructure anchored in the Findability, Accessibility, Interoperability, and Reusability (FAIR) principles. By reviewing the current landscape and outlining strategic priorities, this study supports the advancement of data-centric solutions in the construction sector.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11469v1" target="_blank">CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation</a></h3>
                    <p><strong>Authors:</strong> Hongjin Fang, Daniel ReisenbÃ¼chler, Kenji Ikemura, Mert R. Sabuncu, Yihe Yang, Ruining Deng</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Accurate segmentation of the glomerular basement membrane (GBM) in electron microscopy (EM) images is fundamental for quantifying membrane thickness and supporting the diagnosis of various kidney diseases. While supervised deep learning approaches achieve high segmentation accuracy, their reliance on extensive pixel-level annotation renders them impractical for clinical workflows. Few-shot learning can reduce this annotation burden but often struggles to capture the fine structural details necessary for GBM analysis. In this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot segmentation pipeline designed for GBM delineation in EM images. CoFi first trains a lightweight neural network using only three annotated images to produce an initial coarse segmentation mask. This mask is then automatically processed to generate high-quality point prompts with morphology-aware pruning, which are subsequently used to guide SAM in refining the segmentation. The proposed method achieved exceptional GBM segmentation performance, with a Dice coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that CoFi not only alleviates the annotation and computational burdens associated with conventional methods, but also achieves accurate and reliable segmentation results. The pipelines speed and annotation efficiency make it well-suited for research and hold strong potential for clinical applications in renal pathology. The pipeline is publicly available at: https://github.com/ddrrnn123/CoFi.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11464v1" target="_blank">Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge</a></h3>
                    <p><strong>Authors:</strong> Xiaoya Zhu, Yibing Nan, Shiguo Lian</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the rapid development of technology in the field of AI, deepfake technology has emerged as a double-edged sword. It has not only created a large amount of AI-generated content but also posed unprecedented challenges to digital security. The task of the competition is to determine whether a face image is a Deepfake image and output its probability score of being a Deepfake image. In the image track competition, our approach is based on the Swin Transformer V2-B classification network. And online data augmentation and offline sample generation methods are employed to enrich the diversity of training samples and increase the generalization ability of the model. Finally, we got the award of excellence in Deepfake image detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11460v1" target="_blank">Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models</a></h3>
                    <p><strong>Authors:</strong> Aurora Grefsrud, Nello Blaser, Trygve Buanes</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, stat.ML</p>
                    <p><strong>Summary:</strong> Rigorous statistical methods, including parameter estimation with accompanying uncertainties, underpin the validity of scientific discovery, especially in the natural sciences. With increasingly complex data models such as deep learning techniques, uncertainty quantification has become exceedingly difficult and a plethora of techniques have been proposed. In this case study, we use the unifying framework of approximate Bayesian inference combined with empirical tests on carefully created synthetic classification datasets to investigate qualitative properties of six different probabilistic machine learning algorithms for class probability and uncertainty estimation: (i) a neural network ensemble, (ii) neural network ensemble with conflictual loss, (iii) evidential deep learning, (iv) a single neural network with Monte Carlo Dropout, (v) Gaussian process classification and (vi) a Dirichlet process mixture model. We check if the algorithms produce uncertainty estimates which reflect commonly desired properties, such as being well calibrated and exhibiting an increase in uncertainty for out-of-distribution data points. Our results indicate that all algorithms are well calibrated, but none of the deep learning based algorithms provide uncertainties that consistently reflect lack of experimental evidence for out-of-distribution data points. We hope our study may serve as a clarifying example for researchers developing new methods of uncertainty estimation for scientific data-driven modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11454v1" target="_blank">Reference Points in LLM Sentiment Analysis: The Role of Structured Context</a></h3>
                    <p><strong>Authors:</strong> Junichiro Niimi</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are now widely used across many fields, including marketing research. Sentiment analysis, in particular, helps firms understand consumer preferences. While most NLP studies classify sentiment from review text alone, marketing theories, such as prospect theory and expectation--disconfirmation theory, point out that customer evaluations are shaped not only by the actual experience but also by additional reference points. This study therefore investigates how the content and format of such supplementary information affect sentiment analysis using LLMs. We compare natural language (NL) and JSON-formatted prompts using a lightweight 3B parameter model suitable for practical marketing applications. Experiments on two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with additional information outperforms all baselines without fine-tuning: Macro-F1 rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it deployable in resource-constrained edge devices. Furthermore, a follow-up analysis confirms that performance gains stem from genuine contextual reasoning rather than label proxying. This work demonstrates that structured prompting can enable smaller models to achieve competitive performance, offering a practical alternative to large-scale model deployment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11452v1" target="_blank">Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps</a></h3>
                    <p><strong>Authors:</strong> Kangyu Wang, Hongliang He, Lin Liu, Ruiqi Liang, Zhenzhong Lan, Jianguo Li</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.HC</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have ushered in a new era of AI capabilities, demonstrating near-human-level performance across diverse scenarios. While numerous benchmarks (e.g., MMLU) and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the development of LLMs and MLLMs, most rely on static datasets or crowdsourced general-domain prompts, often falling short of reflecting performance in real-world applications. To bridge this critical gap, we present Inclusion Arena, a live leaderboard that ranks models based on human feedback collected directly from AI-powered applications. Our platform integrates pairwise model comparisons into natural user interactions, ensuring evaluations reflect practical usage scenarios. For robust model ranking, we employ the Bradley-Terry model augmented with two key innovations: (1) Placement Matches, a cold-start mechanism to quickly estimate initial ratings for newly integrated models, and (2) Proximity Sampling, an intelligent comparison strategy that prioritizes battles between models of similar capabilities to maximize information gain and enhance rating stability. Extensive empirical analyses and simulations demonstrate that Inclusion Arena yields reliable and stable rankings, exhibits higher data transitivity compared to general crowdsourced datasets, and significantly mitigates the risk of malicious manipulation. By fostering an open alliance between foundation models and real-world applications, Inclusion Arena aims to accelerate the development of LLMs and MLLMs truly optimized for practical, user-centric deployments. The platform is publicly accessible at https://doraemon.alipay.com/model-ranking.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1007/978-3-031-98694-9_12" target="_blank">Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer</a></h3>
                    <p><strong>Authors:</strong> Augustine X. W. Lee, Pak-Hei Yeung, Jagath C. Rajapakse</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Subcortical segmentation in neuroimages plays an important role in understanding brain anatomy and facilitating computer-aided diagnosis of traumatic brain injuries and neurodegenerative disorders. However, training accurate automatic models requires large amounts of labelled data. Despite the availability of publicly available subcortical segmentation datasets for Magnetic Resonance Imaging (MRI), a significant gap exists for Computed Tomography (CT). This paper proposes an automatic ensemble framework to generate high-quality subcortical segmentation labels for CT scans by leveraging existing MRI-based models. We introduce a robust ensembling pipeline to integrate them and apply it to unannotated paired MRI-CT data, resulting in a comprehensive CT subcortical segmentation dataset. Extensive experiments on multiple public datasets demonstrate the superior performance of our proposed framework. Furthermore, using our generated CT dataset, we train segmentation models that achieve improved performance on related segmentation tasks. To facilitate future research, we make our source code, generated dataset, and trained models publicly available at https://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation, marking the first open-source release for CT subcortical segmentation to the best of our knowledge.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11441v1" target="_blank">Informative Post-Hoc Explanations Only Exist for Simple Functions</a></h3>
                    <p><strong>Authors:</strong> Eric GÃ¼nther, BalÃ¡zs Szabados, Robi Bhattacharjee, Sebastian Bordt, Ulrike von Luxburg</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Many researchers have suggested that local post-hoc explanation algorithms can be used to gain insights into the behavior of complex machine learning models. However, theoretical guarantees about such algorithms only exist for simple decision functions, and it is unclear whether and under which assumptions similar results might exist for complex models. In this paper, we introduce a general, learning-theory-based framework for what it means for an explanation to provide information about a decision function. We call an explanation informative if it serves to reduce the complexity of the space of plausible decision functions. With this approach, we show that many popular explanation algorithms are not informative when applied to complex decision functions, providing a rigorous mathematical rejection of the idea that it should be possible to explain any model. We then derive conditions under which different explanation algorithms become informative. These are often stronger than what one might expect. For example, gradient explanations and counterfactual explanations are non-informative with respect to the space of differentiable functions, and SHAP and anchor explanations are not informative with respect to the space of decision trees. Based on these results, we discuss how explanation algorithms can be modified to become informative. While the proposed analysis of explanation algorithms is mathematical, we argue that it holds strong implications for the practical applicability of these algorithms, particularly for auditing, regulation, and high-risk applications of AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11429v1" target="_blank">HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor</a></h3>
                    <p><strong>Authors:</strong> Shivam Dubey</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Automated humor generation with Large Language Models (LLMs) often yields jokes that feel generic, repetitive, or tone-deaf because humor is deeply situated and hinges on the listeners cultural background, mindset, and immediate context. We introduce HumorPlanSearch, a modular pipeline that explicitly models context through: (1) Plan-Search for diverse, topic-tailored strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt high-performing historical strategies; (4) novelty filtering via semantic embeddings; and (5) an iterative judge-driven revision loop. To evaluate context sensitivity and comedic quality, we propose the Humor Generation Score (HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates, and topic relevance. In experiments across nine topics with feedback from 13 human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent (p  0.05) over a strong baseline. By foregrounding context at every stage from strategy planning to multi-signal evaluation, HumorPlanSearch advances AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11425v1" target="_blank">Tapas are free! Training-Free Adaptation of Programmatic Agents via LLM-Guided Program Synthesis in Dynamic Environments</a></h3>
                    <p><strong>Authors:</strong> Jinwei Hu, Yi Dong, Youcheng Sun, Xiaowei Huang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.MA</p>
                    <p><strong>Summary:</strong> Autonomous agents in safety-critical applications must continuously adapt to dynamic conditions without compromising performance and reliability. This work introduces TAPA (Training-free Adaptation of Programmatic Agents), a novel framework that positions large language models (LLMs) as intelligent moderators of the symbolic action space. Unlike prior programmatic agents that typically generate a monolithic policy program or rely on fixed symbolic action sets, TAPA synthesizes and adapts modular programs for individual high-level actions, referred to as logical primitives. By decoupling strategic intent from execution, TAPA enables meta-agents to operate over an abstract, interpretable action space while the LLM dynamically generates, composes, and refines symbolic programs tailored to each primitive. Extensive experiments across cybersecurity and swarm intelligence domains validate TAPAs effectiveness. In autonomous DDoS defense scenarios, TAPA achieves 77.7% network uptime while maintaining near-perfect detection accuracy in unknown dynamic environments. In swarm intelligence formation control under environmental and adversarial disturbances, TAPA consistently preserves consensus at runtime where baseline methods fail completely. This work promotes a paradigm shift for autonomous system design in evolving environments, from policy adaptation to dynamic action adaptation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11408v1" target="_blank">On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting</a></h3>
                    <p><strong>Authors:</strong> Wenhao Zhang, Yuexiang Xie, Yuchang Sun, Yanxi Chen, Guoyin Wang, Yaliang Li, Bolin Ding, Jingren Zhou</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms for refining the capabilities and aligning the behavior of Large Language Models (LLMs). Existing approaches that integrate SFT and RL often face the risk of disrupting established model patterns and inducing overfitting to expert data. To address this, we present a novel investigation into the unified view of SFT and RL through an off-policy versus on-policy lens. We propose CHORD, a framework for the Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting, which reframes SFT not as a separate stage but as a dynamically weighted auxiliary objective within the on-policy RL process. Based on an analysis of off-policy expert datas influence at both holistic and granular levels, we incorporate a dual-control mechanism in CHORD. Specifically, the framework first employs a global coefficient to holistically guide the transition from off-policy imitation to on-policy exploration, and then applies a token-wise weighting function that enables granular learning from expert tokens, which preserves on-policy exploration and mitigates disruption from off-policy data. We conduct extensive experiments on widely used benchmarks, providing empirical evidence that CHORD achieves a stable and efficient learning process. By effectively harmonizing off-policy expert data with on-policy exploration, CHORD demonstrates significant improvements over baselines. We release the implementation at https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to inspire further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11406v1" target="_blank">Open, Reproducible and Trustworthy Robot-Based Experiments with Virtual Labs and Digital-Twin-Based Execution Tracing</a></h3>
                    <p><strong>Authors:</strong> Benjamin Alt, Mareike Picklum, Sorin Arion, Franklin Kenghagho Kenfack, Michael Beetz</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, 68T40, I.2.9</p>
                    <p><strong>Summary:</strong> We envision a future in which autonomous robots conduct scientific experiments in ways that are not only precise and repeatable, but also open, trustworthy, and transparent. To realize this vision, we present two key contributions: a semantic execution tracing framework that logs sensor data together with semantically annotated robot belief states, ensuring that automated experimentation is transparent and replicable; and the AICOR Virtual Research Building (VRB), a cloud-based platform for sharing, replicating, and validating robot task executions at scale. Together, these tools enable reproducible, robot-driven science by integrating deterministic execution, semantic memory, and open knowledge representation, laying the foundation for autonomous systems to participate in scientific discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11404v1" target="_blank">An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration</a></h3>
                    <p><strong>Authors:</strong> Junyeon Kim, Tianshu Ruan, Cesar Alan Contreras, Manolis Chiou</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Structural inspection in nuclear facilities is vital for maintaining operational safety and integrity. Traditional methods of manual inspection pose significant challenges, including safety risks, high cognitive demands, and potential inaccuracies due to human limitations. Recent advancements in Artificial Intelligence (AI) and robotic technologies have opened new possibilities for safer, more efficient, and accurate inspection methodologies. Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms equipped with advanced detection algorithms, promises significant improvements in inspection outcomes and reductions in human workload. This study explores the effectiveness of AI-assisted visual crack detection integrated into a mobile Jackal robot platform. The experiment results indicate that HRC enhances inspection accuracy and reduces operator workload, resulting in potential superior performance outcomes compared to traditional manual methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11403v1" target="_blank">The Effect of Flow Parameters and Wall Models on Gas-Surface Interactions: A Numerical Investigation of dsmcFoam</a></h3>
                    <p><strong>Authors:</strong> M. B. Agir, N. H. Crisp, K. L. Smith, P. C. E. Roberts, M. Newsam, M. Griffiths, S Vaidya</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Atmosphere-breathing electric propulsion systems harness atmospheric particles as propellant, enabling efficient operation across diverse environmental conditions. To accurately simulate the captured gas flow through the modules, particle-surface interactions must be carefully modelled. To initiate this research, a parametric study is conducted using an extensive simulation matrix to investigate the effects of flow parameters, such as velocity, temperature, species, and angle of attack, and wall model parameters (diffuse fraction/accommodation coefficient) on gas-surface interactions. A simplified test geometry was created to run 2D simulations, where the flow interacts with an adjacent wall positioned perpendicular to one of the inlet patches. In this study, changes in reflection patterns, force density on the surface, and flow properties in the vicinity of the wall are investigated under varying flow and wall conditions using the current boundary conditions of the dsmcFoam solver. Furthermore, the capabilities of dsmcFoams default boundary conditions in predicting gas-surface interaction physics are evaluated using the results of the simulation matrix. The findings highlight the need for new boundary conditions to accurately replicate interaction physics across various aspects.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11401v1" target="_blank">FACET:Teacher-Centred LLM-Based Multi-Agent Systems-Towards Personalized Educational Worksheets</a></h3>
                    <p><strong>Authors:</strong> Jana Gonnermann-MÃ¼ller, Jennifer Haase, Konstantin Fackeldey, Sebastian Pokutta</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.MA</p>
                    <p><strong>Summary:</strong> The increasing heterogeneity of student populations poses significant challenges for teachers, particularly in mathematics education, where cognitive, motivational, and emotional differences strongly influence learning outcomes. While AI-driven personalization tools have emerged, most remain performance-focused, offering limited support for teachers and neglecting broader pedagogical needs. This paper presents the FACET framework, a teacher-facing, large language model (LLM)-based multi-agent system designed to generate individualized classroom materials that integrate both cognitive and motivational dimensions of learner profiles. The framework comprises three specialized agents: (1) learner agents that simulate diverse profiles incorporating topic proficiency and intrinsic motivation, (2) a teacher agent that adapts instructional content according to didactical principles, and (3) an evaluator agent that provides automated quality assurance. We tested the system using authentic grade 8 mathematics curriculum content and evaluated its feasibility through a) automated agent-based assessment of output quality and b) exploratory feedback from K-12 in-service teachers. Results from ten internal evaluations highlighted high stability and alignment between generated materials and learner profiles, and teacher feedback particularly highlighted structure and suitability of tasks. The findings demonstrate the potential of multi-agent LLM architectures to provide scalable, context-aware personalization in heterogeneous classroom settings, and outline directions for extending the framework to richer learner profiles and real-world classroom trials.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11398v1" target="_blank">Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis</a></h3>
                    <p><strong>Authors:</strong> Mithat Can Ozgun, Jiahuan Pei, Koen Hindriks, Lucia Donatelli, Qingzhi Liu, Xin Sun, Junxiao Wang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> LLM-based agents have emerged as transformative tools capable of executing complex tasks through iterative planning and action, achieving significant advancements in understanding and addressing user needs. Yet, their effectiveness remains limited in specialized domains such as mental health diagnosis, where they underperform compared to general applications. Current approaches to integrating diagnostic capabilities into LLMs rely on scarce, highly sensitive mental health datasets, which are challenging to acquire. These methods also fail to emulate clinicians proactive inquiry skills, lack multi-turn conversational comprehension, and struggle to align outputs with expert clinical reasoning. To address these gaps, we propose DSM5AgentFlow, the first LLM-based agent workflow designed to autonomously generate DSM-5 Level-1 diagnostic questionnaires. By simulating therapist-client dialogues with specific client profiles, the framework delivers transparent, step-by-step disorder predictions, producing explainable and trustworthy results. This workflow serves as a complementary tool for mental health diagnosis, ensuring adherence to ethical and legal standards. Through comprehensive experiments, we evaluate leading LLMs across three critical dimensions: conversational realism, diagnostic accuracy, and explainability. Our datasets and implementations are fully open-sourced.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11374v1" target="_blank">Does the Skeleton-Recall Loss Really Work?</a></h3>
                    <p><strong>Authors:</strong> Devansh Arora, Nitin Kumar, Sukrit Gupta</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Image segmentation is an important and widely performed task in computer vision. Accomplishing effective image segmentation in diverse settings often requires custom model architectures and loss functions. A set of models that specialize in segmenting thin tubular structures are topology preservation-based loss functions. These models often utilize a pixel skeletonization process claimed to generate more precise segmentation masks of thin tubes and better capture the structures that other models often miss. One such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite {kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark tubular datasets. In this work, we performed a theoretical analysis of the gradients for the SRL loss. Upon comparing the performance of the proposed method on some of the tubular datasets (used in the original work, along with some additional datasets), we found that the performance of SRL-based segmentation models did not exceed traditional baseline models. By providing both a theoretical explanation and empirical evidence, this work critically evaluates the limitations of topology-based loss functions, offering valuable insights for researchers aiming to develop more effective segmentation models for complex tubular structures.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/ISCSLP63861.2024.10800612" target="_blank">Speech Emotion Recognition Using Fine-Tuned DWFormer:A Study on Track 1 of the IERPChallenge 2024</a></h3>
                    <p><strong>Authors:</strong> Honghong Wang, Xupeng Jia, Jing Deng, Rong Zheng</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> The field of artificial intelligence has a strong interest in the topic of emotion recognition. The majority of extant emotion recognition models are oriented towards enhancing the precision of discrete emotion label prediction. Given the direct relationship between human personality and emotion, as well as the significant inter-individual differences in subjective emotional expression, the IERP Challenge 2024 incorporates personality traits into emotion recognition research. This paper presents the Fosafer submissions to the Track 1 of the IERP Challenge 2024. This task primarily concerns the recognition of emotions in audio, while also providing text and audio features. In Track 1, we utilized exclusively audio-based features and fine-tuned a pre-trained speech emotion recognition model, DWFormer, through the integration of data augmentation and score fusion strategies, thereby achieving the first place among the participating teams.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11368v1" target="_blank">A solution of the quantum time of arrival problem via mathematical probability theory</a></h3>
                    <p><strong>Authors:</strong> Maik Reddiger</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> quant-ph, 81P15 (Primary) 81P05, 81S99, 82D99 (Secondary)</p>
                    <p><strong>Summary:</strong> Time of arrival refers to the time a particle takes after emission to impinge upon a suitably idealized detector surface. Within quantum theory, no generally accepted solution exists so far for the corresponding probability distribution of arrival times. In this work we derive a general solution for a single body without spin impacting on a so called ideal detector in the absence of any other forces or obstacles. A solution of the so called screen problem for this case is also given. We construct the ideal detector model via mathematical probability theory, which in turn suggests an adaption of the Madelung equations in this instance. This detector model assures that the probability flux through the detector surface is always positive, so that the corresponding distributions can be derived via an approach originally suggested by Daumer, D\urr, Goldstein, and Zangh\`i. The resulting dynamical model is, strictly speaking, not compatible with quantum mechanics, yet it is well-described within geometric quantum theory. Geometric quantum theory is a novel adaption of quantum mechanics, which makes the latter consistent with mathematical probability theory. Implications to the general theory of measurement and avenues for future research are also provided. Future mathematical work should focus on finding an appropriate distributional formulation of the evolution equations and studying the well-posedness of the corresponding Cauchy problem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11364v1" target="_blank">Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning</a></h3>
                    <p><strong>Authors:</strong> Sylvio RÃ¼dian, Yassin Elsir, Marvin Kretschmer, Sabine Cayrou, Niels Pinkwart</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Automated feedback generation has the potential to enhance students learning progress by providing timely and targeted feedback. Moreover, it can assist teachers in optimizing their time, allowing them to focus on more strategic and personalized aspects of teaching. To generate high-quality, information-rich formative feedback, it is essential first to extract relevant indicators, as these serve as the foundation upon which the feedback is constructed. Teachers often employ feedback criteria grids composed of various indicators that they evaluate systematically. This study examines the initial phase of extracting such indicators from students submissions of a language learning course using the large language model Llama 3.1. Accordingly, the alignment between indicators generated by the LLM and human ratings across various feedback criteria is investigated. The findings demonstrate statistically significant strong correlations, even in cases involving unanticipated combinations of indicators and criteria. The methodology employed in this paper offers a promising foundation for extracting indicators from students submissions using LLMs. Such indicators can potentially be utilized to auto-generate explainable and transparent formative feedback in future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11359v1" target="_blank">Can We Tell if ChatGPT is a Parasite? Studying Human-AI Symbiosis with Game Theory</a></h3>
                    <p><strong>Authors:</strong> Jiejun Hu-Bolz, James Stovold</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.GT</p>
                    <p><strong>Summary:</strong> This work asks whether a human interacting with a generative AI system can merge into a single individual through iterative, information-driven interactions. We model the interactions between a human, a generative AI system, and the humans wider environment as a three-player stochastic game. We use information-theoretic measures (entropy, mutual information, and transfer entropy) to show that our modelled human and generative AI are able to form an aggregate individual in the sense of Krakauer et al. (2020). The model we present is able to answer interesting questions around the symbiotic nature of humans and AI systems, including whether LLM-driven chatbots are acting as parasites, feeding on the information provided by humans.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11357v1" target="_blank">PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding</a></h3>
                    <p><strong>Authors:</strong> Changhong Jing, Yan Liu, Shuqiang Wang, Bruce X. B. Yu, Gong Chen, Zhejing Hu, Zhi Zhang, Yanyan Shen</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Cross-subject electroencephalography (EEG) decoding remains a fundamental challenge in brain-computer interface (BCI) research due to substantial inter-subject variability and the scarcity of subject-invariant representations. This paper proposed PTSM (Physiology-aware and Task-invariant Spatio-temporal Modeling), a novel framework for interpretable and robust EEG decoding across unseen subjects. PTSM employs a dual-branch masking mechanism that independently learns personalized and shared spatio-temporal patterns, enabling the model to preserve individual-specific neural characteristics while extracting task-relevant, population-shared features. The masks are factorized across temporal and spatial dimensions, allowing fine-grained modulation of dynamic EEG patterns with low computational overhead. To further address representational entanglement, PTSM enforces information-theoretic constraints that decompose latent embeddings into orthogonal task-related and subject-related subspaces. The model is trained end-to-end via a multi-objective loss integrating classification, contrastive, and disentanglement objectives. Extensive experiments on cross-subject motor imagery datasets demonstrate that PTSM achieves strong zero-shot generalization, outperforming state-of-the-art baselines without subject-specific calibration. Results highlight the efficacy of disentangled neural representations for achieving both personalized and transferable decoding in non-stationary neurophysiological settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11337v1" target="_blank">Geometric Quantization by Paths -- Part I: The Simply Connected Case</a></h3>
                    <p><strong>Authors:</strong> Patrick Iglesias-Zemmour</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> math-ph, math.MP, Primary 53D50, 58A05, Secondary 22A22, 55R65, 58A10</p>
                    <p><strong>Summary:</strong> For any connected and simply connected parasymplectic space $(\mathrm{X},\omega)$ with group of periods $\mathrm{P}_\omega \subsetneq \mathbf{R}$, we construct a prequantum groupoid $\pmb{\mathrm{T}}_\omega$ as a diffeological quotient of the space $\mathrm{Paths}(\mathrm{X})$ of paths in $\mathrm{X}$. This object, built from the geometry of the classical system, serves as a unified structure for prequantization. The groupoid $\pmb{\mathrm{T}}_\omega$ has $\mathrm{X}$ as its objects, and its space of morphisms $\mathcal{Y}$ carries a canonical left-right invariant $1$-form $\pmb{\lambda}$ whose curvature encodes $\omega$. A key property is that the isotropy group $\pmb{\mathrm{T}}_{\omega,x}$ at any point $x$, naturally arising as a quotient of the space of loops, is isomorphic to the torus of periods $\mathrm{T}_\omega = \mathbf{R}/\mathrm{P}_\omega$. Furthermore, the entire symmetry group $\mathrm{Diff}(\mathrm{X}, \omega)$ acts as faithful automorphisms of $(\pmb{\mathrm{T}}_\omega, \pmb{\lambda})$ without central extensions at this level. Built within the framework of diffeology, this construction generalizes classical prequantization by applying to broad classes of spaces, including those with singularities or infinite-dimensional aspects, and by accommodating generalized (e.g., irrational) tori of periods. This paper focuses on the simply connected case; the construction will be extended to general diffeological spaces in a subsequent publication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11334v1" target="_blank">GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition</a></h3>
                    <p><strong>Authors:</strong> Md Asgor Hossain Reaj, Rajan Das Gupta, Md Yeasin Rahat, Nafiz Fahad, Md Jawadul Hasan, Tze Hui Liew</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce GANDiff FR, the first synthetic framework that precisely controls demographic and environmental factors to measure, explain, and reduce bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based identity-preserving generation with diffusion-based attribute control, enabling fine-grained manipulation of pose around 30 degrees, illumination (four directions), and expression (five levels) under ceteris paribus conditions. We synthesize 10,000 demographically balanced faces across five cohorts validated for realism via automated detection (98.2%) and human review (89%) to isolate and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under matched operating points shows AdaFace reduces inter-group TPR disparity by 60% (2.5% vs. 6.3%), with illumination accounting for 42% of residual bias. Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead relative to pure GANs, GANDiff FR yields three times more attribute-conditioned variants, establishing a reproducible, regulation-aligned (EU AI Act) standard for fairness auditing. Code and data are released to support transparent, scalable bias evaluation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11327v1" target="_blank">The User-first Approach to AI Ethics: Preferences for Ethical Principles in AI Systems across Cultures and Contexts</a></h3>
                    <p><strong>Authors:</strong> Benjamin J. Carroll, Jianlong Zhou, Paul F. Burke, Sabine Ammon</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> As AI systems increasingly permeate everyday life, designers and developers face mounting pressure to balance innovation with ethical design choices. To date, the operationalisation of AI ethics has predominantly depended on frameworks that prescribe which ethical principles should be embedded within AI systems. However, the extent to which users value these principles remains largely unexplored in the existing literature. In a discrete choice experiment conducted in four countries, we quantify user preferences for 11 ethical principles. Our findings indicate that, while users generally prioritise privacy, justice  fairness, and transparency, their preferences exhibit significant variation based on culture and application context. Latent class analysis further revealed four distinct user cohorts, the largest of which is ethically disengaged and defers to regulatory oversight. Our findings offer (1) empirical evidence of uneven user prioritisation of AI ethics principles, (2) actionable guidance for operationalising ethics tailored to culture and context, (3) support for the development of robust regulatory mechanisms, and (4) a foundation for advancing a user-centred approach to AI ethics, motivated independently from abstract moral theory.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11301v1" target="_blank">Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study</a></h3>
                    <p><strong>Authors:</strong> Jiarong Li, Imad Ali Shah, Enda Ward, Martin Glavin, Edward Jones, Brian Deegan</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Pedestrian segmentation in automotive perception systems faces critical safety challenges due to metamerism in RGB imaging, where pedestrians and backgrounds appear visually indistinguishable.. This study investigates the potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We compared standard RGB against two dimensionality-reduction approaches by converting 128-channel HSI data into three-channel representations: Principal Component Analysis (PCA) and optimal band selection using Contrast Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM). Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25% F1-score improvements. These improved performance results from enhanced spectral discrimination of optimally selected HSI bands effectively reducing false positives. This study demonstrates robust pedestrian segmentation through optimal HSI band selection, showing significant potential for safety-critical automotive applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11290v1" target="_blank">SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory</a></h3>
                    <p><strong>Authors:</strong> Utsav Maskey, Sumit Yadav, Mark Dras, Usman Naseem</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> LLMs increasingly exhibit over-refusal behavior, where safety mechanisms cause models to reject benign instructions that superficially resemble harmful content. This phenomena diminishes utility in production applications that repeatedly rely on common prompt templates or applications that frequently rely on LLMs for specific tasks (e.g. sentiment analysis, language translation). Through comprehensive evaluation, we demonstrate that LLMs still tend to refuse responses to harmful instructions when those instructions are reframed to appear as benign tasks. Our mechanistic analysis reveal that LLMs follow distinct constellation patterns in embedding space as representations traverse layers, with each task maintaining consistent trajectories that shift predictably between refusal and non-refusal cases. We introduce SafeConstellations, an inference-time trajectory-shifting approach that tracks task-specific trajectory patterns and guides representations toward non-refusal pathways. By selectively guiding model behavior only on tasks prone to over-refusal, and by preserving general model behavior, our method reduces over-refusal rates by up to 73% with minimal impact on utility-offering a principled approach to mitigating over-refusals.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11287v1" target="_blank">CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems</a></h3>
                    <p><strong>Authors:</strong> Xuran Liu, Nan Xue, Rui Bao, Yaping Sun, Zhiyong Chen, Meixia Tao, Xiaodong Xu, Shuguang Cui</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.IT, cs.AI, cs.LG, math.IT</p>
                    <p><strong>Summary:</strong> While deploying large language models on edge devices promises low-latency and privacy-preserving AI services, it is hindered by limited device resources. Although pipeline parallelism facilitates distributed inference, existing approaches often ignore the cold-start latency caused by on-demand model loading. In this paper, we propose a latency-aware scheduling framework that overlaps model loading with computation and communication to minimize total inference latency. Based on device and model parameters, the framework dynamically adjusts layer partitioning and allocation to effectively hide loading time, thereby eliminating as many idle periods as possible. We formulate the problem as a Mixed-Integer Non-Linear Program and design an efficient dynamic programming algorithm to optimize model partitioning and device assignment. Experimental results show that the proposed method significantly reduces cold-start latency compared to baseline strategies.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11285v1" target="_blank">AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models Responses to Depression, Anxiety, and Stress Queries</a></h3>
                    <p><strong>Authors:</strong> Arya VarastehNezhad, Reza Tavasoli, Soroush Elyasi, MohammadHossein LotfiNia, Hamed Farbeh</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Depression, anxiety, and stress are widespread mental health concerns that increasingly drive individuals to seek information from Large Language Models (LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty pragmatic questions about depression, anxiety, and stress when those questions are framed for six user profiles (baseline, woman, man, young, old, and university student). The models generated 2,880 answers, which we scored for sentiment and emotions using state-of-the-art tools. Our analysis revealed that optimism, fear, and sadness dominated the emotional landscape across all outputs, with neutral sentiment maintaining consistently high values. Gratitude, joy, and trust appeared at moderate levels, while emotions such as anger, disgust, and love were rarely expressed. The choice of LLM significantly influenced emotional expression patterns. Mixtral exhibited the highest levels of negative emotions including disapproval, annoyance, and sadness, while Llama demonstrated the most optimistic and joyful responses. The type of mental health condition dramatically shaped emotional responses: anxiety prompts elicited extraordinarily high fear scores (0.974), depression prompts generated elevated sadness (0.686) and the highest negative sentiment, while stress-related queries produced the most optimistic responses (0.755) with elevated joy and trust. In contrast, demographic framing of queries produced only marginal variations in emotional tone. Statistical analyses confirmed significant model-specific and condition-specific differences, while demographic influences remained minimal. These findings highlight the critical importance of model selection in mental health applications, as each LLM exhibits a distinct emotional signature that could significantly impact user experience and outcomes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11281v1" target="_blank">ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection</a></h3>
                    <p><strong>Authors:</strong> Axel Delaval, Shujian Yang, Haicheng Wang, Han Qiu, Jialiang Lu</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.CY, 68T50, I.2.7</p>
                    <p><strong>Summary:</strong> Detecting toxic content using language models is crucial yet challenging. While substantial progress has been made in English, toxicity detection in French remains underdeveloped, primarily due to the lack of culturally relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new public benchmark of 53,622 French online comments, constructed via a semi-automated annotation pipeline that reduces manual labeling to only 10% through high-confidence LLM-based pre-annotation and human verification. Then, we benchmark a broad range of models and uncover a counterintuitive insight: Small Language Models (SLMs) outperform many larger models in robustness and generalization under the toxicity detection task. Motivated by this finding, we propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic weighted loss that progressively emphasizes the models final decision, significantly improving faithfulness. Our fine-tuned 4B model achieves state-of-the-art performance, improving its F1 score by 13% over its baseline and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a cross-lingual toxicity benchmark demonstrates strong multilingual ability, suggesting that our methodology can be effectively extended to other languages and safety-critical classification tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11278v1" target="_blank">Is General-Purpose AI Reasoning Sensitive to Data-Induced Cognitive Biases? Dynamic Benchmarking on Typical Software Engineering Dilemmas</a></h3>
                    <p><strong>Authors:</strong> Francesco Sovrano, Gabriele Dominici, Rita Sevastjanova, Alessandra Stramiglio, Alberto Bacchelli</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.SE</p>
                    <p><strong>Summary:</strong> Human cognitive biases in software engineering can lead to costly errors. While general-purpose AI (GPAI) systems may help mitigate these biases due to their non-human nature, their training on human-generated data raises a critical question: Do GPAI systems themselves exhibit cognitive biases? To investigate this, we present the first dynamic benchmarking framework to evaluate data-induced cognitive biases in GPAI within software engineering workflows. Starting with a seed set of 16 hand-crafted realistic tasks, each featuring one of 8 cognitive biases (e.g., anchoring, framing) and corresponding unbiased variants, we test whether bias-inducing linguistic cues unrelated to task logic can lead GPAI systems from correct to incorrect conclusions. To scale the benchmark and ensure realism, we develop an on-demand augmentation pipeline relying on GPAI systems to generate task variants that preserve bias-inducing cues while varying surface details. This pipeline ensures correctness (88--99% on average, according to human evaluation), promotes diversity, and controls reasoning complexity by leveraging Prolog-based reasoning and LLM-as-a-judge validation. It also verifies that the embedded biases are both harmful and undetectable by logic-based, unbiased reasoners. We evaluate leading GPAI systems (GPT, LLaMA, DeepSeek) and find a consistent tendency to rely on shallow linguistic heuristics over deep reasoning. All systems exhibit cognitive biases (ranging from 5.9% to 35% across types), with bias sensitivity increasing sharply with task complexity (up to 49%), highlighting critical risks in real-world software engineering deployments.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11276v1" target="_blank">Measurement of the Born cross section for $e^+e^- \to p K^- K^- \barÎž^+$ at $\sqrt{s} =$ 3.5-4.9 GeV</a></h3>
                    <p><strong>Authors:</strong> BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. HÃ¼sken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. KÃ¼hn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> Using $e^+ e^-$ collision data corresponding to a total integrated luminosity of 20 ${\rm fb}^{-1}$ collected with the BESIII detector at the BEPCII collider, we present a measurement of the Born cross section for the process $e^+e^- \to p K^-K^-\bar{\Xi}^{+}$ at 39 center-of-mass energies between 3.5 and 4.9 GeV with a partial reconstruction technique. By performing a fit to the dressed cross section of $e^{+}e^{-}\to p K^- K^-\bar{\Xi}^{+}$ with a power law function for continuum production and one resonance at a time for the $\psi(3770)$, $\psi(4040)$, $\psi(4160)$, $\psi(4230)$, $\psi(4360)$, $\psi(4415)$ or $\psi(4660)$, respectively, the upper limits for the product of partial electronic width and branching fraction into the final state $p K^- K^- \bar{\Xi}^+$ for these resonances are determined at the $90\%$ confidence level.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11631v1" target="_blank">Laser Interferometer Lunar Antenna (LILA): Advancing the U.S. Priorities in Gravitational-wave and Lunar Science</a></h3>
                    <p><strong>Authors:</strong> Karan Jani, Matthew Abernathy, Emanuele Berti, Valerio Boschi, Sukanya Chakrabarti, Alice Cocoros, John W. Conklin, Teviet Creighton, Simone DellAgnello, Jean-Claude Diels, Stephen Eikenberry, T. Marshall Eubanks, Kiranjyot Gill, Jonathan E. Grindlay, Kris Izquierdo, Jaesung Lee, Abraham Loeb, Philippe LognonnÃ©, Francesco Longo, Manuel Pichardo Marcano, Mark Panning, Paula do Vale Pereira, Volker Quetschke, Ashique Rahman, Massimiliano Razzano, Robert Reed, Brett Shapiro, David Shoemaker, William Smith, James Trippe, Eric Van Stryland, Wan Wu, Anjali B. Yelikar</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.HE, astro-ph.IM</p>
                    <p><strong>Summary:</strong> The Laser Interferometer Lunar Antenna (LILA) is a next-generation gravitational-wave (GW) facility on the Moon. By harnessing the Moons unique environment, LILA fills a critical observational gap in the mid-band GW spectrum ($0.1 - 10$ Hz) between terrestrial detectors (LIGO, Virgo, KAGRA) and the future space mission LISA. Observations enabled by LILA will fundamentally transform multi-messenger astrophysics and GW probes of fundamental physics. LILA will measure the lunar deep interior better than any existing planetary seismic instruments. The LILA mission is designed for phased development aligned with capabilities of the U.S.s Commercial Lunar Payload Services and Artemis programs. LILA is a unique collaboration between universities, space industries, U.S. government laboratories, and international partners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11617v1" target="_blank">Coherent Structure Dynamics of Heat Transfer in Wakes of an Inclined Elliptical Cylinder: A Novel Lagrangian Framework</a></h3>
                    <p><strong>Authors:</strong> Pratham Singh, Raghav Singhal, Jiten C. Kalita</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn</p>
                    <p><strong>Summary:</strong> This work introduces a novel Lagrangian-based framework to analyze forced convective heat transfer in the unsteady wake of a heated elliptical cylinder inclined at angles ranging from $\theta = 0^\circ$ to $90^\circ$, in $15^\circ$ increments with $Pr = 0.71$ at a fixed Reynolds number of $Re = 100$. The framework correlates the temporal evolution of the surface-averaged Nusselt number with the dynamic behavior of Lagrangian saddle points, formed at the intersection of repelling and attracting Lagrangian Coherent Structures (LCSs) extracted via Finite-Time Lyapunov Exponent (FTLE) fields.The study is carried out within a precisely constructed observational domain, a previously unreported influential region in the near-wake, where the trajectory analysis of the newly defined key saddle points (active saddle points) consistently aligns with the trends in surface heat transfer. This domain enables predictive identification of key transitional events in the Nusselt number profile, including local extrema and slope inflections, across all inclination angles. The analysis reveals that oblique displacement of active saddle points enhances heat transfer by promoting the shedding of repelling LCSs, while parallel displacement leads to weakened heat transfer due to the delayed detachment of repelling coherent structures. The proposed framework enables the construction of a temporal function that closely replicates the monotonicity and transitional features of the Nusselt number evolution. Furthermore, threshold displacement metrics are defined for dominant repelling LCSs to correspond with peak heat transfer efficiency. The proposed methodology not only generalizes across a wide range of inclination angles but also provides a physically interpretable framework for predicting heat transfer enhancement based on coherent structure evolution in unsteady flows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11613v1" target="_blank">Adaptive Cardio Load Targets for Improving Fitness and Performance</a></h3>
                    <p><strong>Authors:</strong> Justin Phillips, Daniel Roggen, Cathy Speed, Robert Harle</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Cardio Load, introduced by Google in 2024, is a measure of cardiovascular work (also known as training load) resulting from all the users activities across the day. It is based on heart rate reserve and captures both activity intensity and duration. Thanks to feedback from users and internal research, we introduce adaptive and personalized targets which will be set weekly. This feature will be available in the Public Preview of the Fitbit app after September 2025. This white paper provides a comprehensive overview of Cardio Load (CL) and how weekly CL targets are established, with examples shown to illustrate the effect of varying CL on the weekly target. We compare Cardio Load and Active Zone Minutes (AZMs), highlighting their distinct purposes, i.e. AZMs for health guidelines and CL for performance measurement. We highlight that CL is accumulated both during active workouts and incidental daily activities, so users are able top-up their CL score with small bouts of activity across the day.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11607v1" target="_blank">TinyTim: A Family of Language Models for Divergent Generation</a></h3>
                    <p><strong>Authors:</strong> Christopher J. Agostino</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This work introduces TinyTim, a family of large language models fine-tuned on James Joyces `Finnegans Wake. Through quantitative evaluation against baseline models, we demonstrate that TinyTim V1 produces a statistically distinct generative profile characterized by high lexical diversity and low semantic coherence. These findings are interpreted through theories of creativity and complex problem-solving, arguing that such specialized models can function as divergent knowledge sources within more extensive creative architectures, powering automated discovery mechanisms in diverse settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11605v1" target="_blank">Dataset Creation for Visual Entailment using Generative AI</a></h3>
                    <p><strong>Authors:</strong> Rob Reijtenbach, Suzan Verberne, Gijs Wijnholds</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In this paper we present and validate a new synthetic dataset for training visual entailment models. Existing datasets for visual entailment are small and sparse compared to datasets for textual entailment. Manually creating datasets is labor-intensive. We base our synthetic dataset on the SNLI dataset for textual entailment. We take the premise text from SNLI as input prompts in a generative image model, Stable Diffusion, creating an image to replace each textual premise. We evaluate our dataset both intrinsically and extrinsically. For extrinsic evaluation, we evaluate the validity of the generated images by using them as training data for a visual entailment classifier based on CLIP feature vectors. We find that synthetic training data only leads to a slight drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when trained on real data. We also compare the quality of our generated training data to original training data on another dataset: SICK-VTE. Again, there is only a slight drop in F-score: from 0.400 to 0.384. These results indicate that in settings with data sparsity, synthetic data can be a promising solution for training visual entailment models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11603v1" target="_blank">CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion</a></h3>
                    <p><strong>Authors:</strong> Zhe Zhu, Honghua Chen, Peng Li, Mingqiang Wei</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-driven 3D editing seeks to modify 3D scenes according to textual descriptions, and most existing approaches tackle this by adapting pre-trained 2D image editors to multi-view inputs. However, without explicit control over multi-view information exchange, they often fail to maintain cross-view consistency, leading to insufficient edits and blurry details. We introduce CoreEditor, a novel framework for consistent text-to-3D editing. The key innovation is a correspondence-constrained attention mechanism that enforces precise interactions between pixels expected to remain consistent throughout the diffusion denoising process. Beyond relying solely on geometric alignment, we further incorporate semantic similarity estimated during denoising, enabling more reliable correspondence modeling and robust multi-view editing. In addition, we design a selective editing pipeline that allows users to choose preferred results from multiple candidates, offering greater flexibility and user control. Extensive experiments show that CoreEditor produces high-quality, 3D-consistent edits with sharper details, significantly outperforming prior methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11582v1" target="_blank">Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Qiguang Chen, Dengyun Peng, Jinhao Liu, HuiKang Su, Jiannan Guan, Libo Qin, Wanxiang Che</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Recent advancements in large language models (LLMs) have greatly improved their capabilities on complex reasoning tasks through Long Chain-of-Thought (CoT). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. To improve the efficiency, current methods often rely on human-defined difficulty priors, which do not align with the LLMs self-awared difficulty, leading to inefficiencies. In this paper, we introduce the Dynamic Reasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models to dynamically assess and adjust their reasoning depth in response to problem complexity. DR. SAF integrates three key components: Boundary Self-Awareness Alignment, Adaptive Reward Management, and a Boundary Preservation Mechanism. These components allow models to optimize their reasoning processes, balancing efficiency and accuracy without compromising performance. Our experimental results demonstrate that DR. SAF achieves a 49.27% reduction in total response tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain in token efficiency and a 5x reduction in training time, making it well-suited to resource-limited settings. During extreme training, DR. SAF can even surpass traditional instruction-based models in token efficiency with more than 16% accuracy improvement.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11581v1" target="_blank">Stabilizing and Tuning Superconductivity in La$_3$Ni$_2$O$_{7-Î´}$ Films: Oxygen Recycling Protocol Reveals Hole-Doping Analogue</a></h3>
                    <p><strong>Authors:</strong> Lifen Xiang, Siyi Lei, Xiaolin Ren, Ziao Han, Zijian Xu, X. J. Zhou, Zhihai Zhu</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cond-mat.supr-con</p>
                    <p><strong>Summary:</strong> The recent achievement of superconductivity in La$_3$Ni$_2$O$_{7-\delta}$ with transition temperatures exceeding 40 K in thin films under compressive strain and 80 K in bulk crystals under high pressure opens new avenues for research on high-temperature superconductivity. The realization of superconductivity in thin films requires delicate control of growth conditions, which presents significant challenges in the synthesis process. Furthermore, the stability of superconducting La$_3$Ni$_2$O$_{7-\delta}$ films is compromised by oxygen loss, which complicates their characterization. We introduce an effective recycling protocol that involves oxygen removal in a precursor phase followed by ozone-assisted annealing, which restores superconducting properties. By tuning the oxygen content, we construct an electronic phase diagram that highlights oxygen addition as a potential analogue to hole doping via La substitution with Sr, providing insights into the doping mechanism and guiding future material optimization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11579v1" target="_blank">Intergenerational Support for Deepfake Scams Targeting Older Adults</a></h3>
                    <p><strong>Authors:</strong> Karina LaRubbio, Alyssa Lanter, Seihyun Lee, Mahima Ramesh, Diana Freed</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> AI-enhanced scams now employ deepfake technology to produce convincing audio and visual impersonations of trusted family members, often grandchildren, in real time. These attacks fabricate urgent scenarios, such as legal or medical emergencies, to socially engineer older adults into transferring money. The realism of these AI-generated impersonations undermines traditional cues used to detect fraud, making them a powerful tool for financial exploitation. In this study, we explore older adults perceptions of these emerging threats and their responses, with a particular focus on the role of youth, who may also be impacted by having their identities exploited, in supporting older family members online safety. We conducted focus groups with 37 older adults (ages 65+) to examine their understanding of deepfake impersonation scams and the value of intergenerational technology support. Findings suggest that older adults frequently rely on trusted relationships to detect scams and develop protective practices. Based on this, we identify opportunities to engage youth as active partners in enhancing resilience across generations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11578v1" target="_blank">Propagation of Precessing Jet in Envelope of Tidal Disruption Events</a></h3>
                    <p><strong>Authors:</strong> Hao-Yu Yuan, Hong-Zhou Wu, Wei-Hua Lei</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE</p>
                    <p><strong>Summary:</strong> It is likely that the disk of a tidal disruption event (TDE) is misaligned with respect to the equatorial plane of the spinning supermassive black hole (SMBH), since the initial stellar orbit before disruption is most likely has an inclined orbital plane. Such misaligned disk undergoes Lense-Thirring precession around the SMBH spin axis, leading to a precessing jet if launched in the vicinity of the SMBH and aligned with the disk angular momentum. The bound debris can also build a thick envelope which powers optical emission. In this work, we study the propagation of the precessing jet in the TDE envelope. We adopt a ``zero-Bernoulli accretion (ZEBRA) envelope model. A episodic jet will be observed if the line of sight is just at the envelope pole direction and $\theta_{\rm LT}=\theta_{\rm env}$, since the jet can freely escape from this low density rotation funnel, where $\theta_{\rm LT}$ and $\theta_{\rm env}$ are the jet precessing angle and the angle between the envelope polar axis and the SMBH spin axis, respectively. The jet will be choked at other directions. For $\theta_{\rm LT}  \theta_{\rm env}$, the jets can also break out of the envelope for very small precession angle $\theta_{\rm LT}$ or if the jet is aligned with SMBH spin. If the jet is choked within the envelope, the radiation produced during cocoon shock breakout will imprint characteris</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11571v1" target="_blank">Temporal Network Analysis of Microservice Architectural Degradation</a></h3>
                    <p><strong>Authors:</strong> Alexander Bakhtin</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.DM</p>
                    <p><strong>Summary:</strong> Microservice architecture can be modeled as a network of microservices making calls to each other, commonly known as the service dependency graph. Network Science can provide methods to study such networks. In particular, temporal network analysis is a branch of Network Science that analyzes networks evolving with time. In microservice systems, temporal networks can arise if we examine the architecture of the system across releases or monitor a deployed system using tracing. In this research summary paper, I discuss the challenges in obtaining temporal networks from microservice systems and analyzing them with the temporal network methods. In particular, the most complete temporal network that we could obtain contains 7 time instances and 42 microservices, which limits the potential analysis that could be applied.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11563v1" target="_blank">Pushing the Limits of Frequency Analysis in Leakage Abuse Attacks</a></h3>
                    <p><strong>Authors:</strong> Nathaniel Moyer, Charalampos Papamanthou, Evgenios Kornaropoulos</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Searchable encryption (SE) is the most scalable cryptographic primitive for searching on encrypted data. Typical SE constructions often allow access-pattern leakage, revealing which encrypted records are retrieved in the servers responses. All the known generic cryptanalyses assume either that the queries are issued uniformly at random or that the attacker observes the search-pattern leakage. It remains unclear what can be reconstructed when using only the access-pattern leakage and knowledge of the query distribution. In this work, we focus on the cryptanalytic technique of frequency analysis in the context of leakage-abuse attacks on schemes that support encrypted range queries. Frequency analysis matches the frequency of retrieval of an encrypted record with a plaintext value based on its probability of retrieval that follows from the knowledge of the query distribution. We generalize this underexplored cryptanalytic technique and introduce a generic attack framework called Leakage-Abuse via Matching (LAMA) that works even on high-dimensional encrypted data. We identify a parameterization of LAMA that brings frequency analysis to its limit -- that is, we prove that there is no additional frequency matching that an attacker can perform to refine the result. Furthermore, we show that our results hold for any class of convex queries, and not just axis-aligned rectangles, which is the assumption in all other attacks on range schemes. Using these results, we identify query distributions that make frequency analysis challenging for the attacker and, thus, can act as a mitigation mechanism. Finally, we implement and benchmark LAMA and reconstruct, for the first time, plaintext data from encrypted range queries spanning up to four dimensions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11551v1" target="_blank">ADMIRE-BayesOpt: Accelerated Data MIxture RE-weighting for Language Models with Bayesian Optimization</a></h3>
                    <p><strong>Authors:</strong> Shengzhuang Chen, Xu Ouyang, Michael Arthur Leopold Pearce, Thomas Hartvigsen, Jonathan Richard Schwarz</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Determining the optimal data mixture for large language model training remains a challenging problem with an outsized impact on performance. In practice, language model developers continue to rely on heuristic exploration since no learning-based approach has emerged as a reliable solution. In this work, we propose to view the selection of training data mixtures as a black-box hyperparameter optimization problem, for which Bayesian Optimization is a well-established class of appropriate algorithms. Firstly, we cast data mixture learning as a sequential decision-making problem, in which we aim to find a suitable trade-off between the computational cost of training exploratory (proxy-) models and final mixture performance. Secondly, we systematically explore the properties of transferring mixtures learned at a small scale to larger-scale experiments, providing insights and highlighting opportunities for research at a modest scale. By proposing Multi-fidelity Bayesian Optimization as a suitable method in this common scenario, we introduce a natural framework to balance experiment cost with model fit, avoiding the risks of overfitting to smaller scales while minimizing the number of experiments at high cost. We present results for pre-training and instruction finetuning across models ranging from 1 million to 7 billion parameters, varying from simple architectures to state-of-the-art models and benchmarks spanning dozens of datasets. We demonstrate consistently strong results relative to a wide range of benchmarks, showingspeed-ups of over 500% in determining the best data mixture on our largest experiments relative to recent baselines. In addition, we broaden access to research by sharing ADMIRE IFT Runs, a dataset of 460 full training  evaluation runs across various model sizes worth over 13,000 GPU hours, greatly reducing the cost of conducting research in this area.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11548v1" target="_blank">Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends</a></h3>
                    <p><strong>Authors:</strong> Zhenhua Xu, Xubin Yue, Zhebo Wang, Qichen Liu, Xixiang Zhao, Jingxuan Zhang, Wenjun Zeng, Wengpeng Xing, Dezhang Kong, Changting Lin, Meng Han</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Copyright protection for large language models is of critical importance, given their substantial development costs, proprietary value, and potential for misuse. Existing surveys have predominantly focused on techniques for tracing LLM-generated content-namely, text watermarking-while a systematic exploration of methods for protecting the models themselves (i.e., model watermarking and model fingerprinting) remains absent. Moreover, the relationships and distinctions among text watermarking, model watermarking, and model fingerprinting have not been comprehensively clarified. This work presents a comprehensive survey of the current state of LLM copyright protection technologies, with a focus on model fingerprinting, covering the following aspects: (1) clarifying the conceptual connection from text watermarking to model watermarking and fingerprinting, and adopting a unified terminology that incorporates model watermarking into the broader fingerprinting framework; (2) providing an overview and comparison of diverse text watermarking techniques, highlighting cases where such methods can function as model fingerprinting; (3) systematically categorizing and comparing existing model fingerprinting approaches for LLM copyright protection; (4) presenting, for the first time, techniques for fingerprint transfer and fingerprint removal; (5) summarizing evaluation metrics for model fingerprints, including effectiveness, harmlessness, robustness, stealthiness, and reliability; and (6) discussing open challenges and future research directions. This survey aims to offer researchers a thorough understanding of both text watermarking and model fingerprinting technologies in the era of LLMs, thereby fostering further advances in protecting their intellectual property.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11544v1" target="_blank">Grand Challenge: Mediating Between Confirmatory and Exploratory Research Cultures in Health Sciences and Visual Analytics</a></h3>
                    <p><strong>Authors:</strong> Viktor von Wyl, JÃ¼rgen Bernard</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Collaboration between health science and visual analytics research is often hindered by different, sometimes incompatible approaches to research design. Health science often follows hypothesis-driven protocols, registered in advance, and focuses on reproducibility and risk mitigation. Visual analytics, in contrast, relies on iterative data exploration, prioritizing insight generation and analytic refinement through user interaction. These differences create challenges in interdisciplinary projects, including misaligned terminology, unrealistic expectations about data readiness, divergent validation norms, or conflicting explainability requirements. To address these persistent tensions, we identify seven research needs and actions: (1) guidelines for broader community adoption, (2) agreement on quality and validation benchmarks, (3) frameworks for aligning research tasks, (4) integrated workflows combining confirmatory and exploratory stages, (5) tools for harmonizing terminology across disciplines, (6) dedicated bridging roles for transdisciplinary work, and (7) cultural adaptation and mutual recognition. We organize these needs in a framework with three areas: culture, standards, and processes. They can constitute a research agenda for developing reliable, reproducible, and clinically relevant data-centric methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11539v1" target="_blank">Two-loop BSM contributions to Higgs pair production in the aligned THDM</a></h3>
                    <p><strong>Authors:</strong> Giuseppe Degrassi, Ramona GrÃ¶ber, Pietro Slavich</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> hep-ph</p>
                    <p><strong>Summary:</strong> We study the impact of the two-loop corrections controlled by the BSM Higgs couplings on the cross section for the production of a pair of SM-like Higgs bosons via gluon fusion in the aligned THDM. To this aim, we reassess the two-loop calculation of $\lambda_{hhh}$, we compute for the first time the two-loop corrections to $\lambda_{hhH}$, and we include the relevant corrections to the Higgs-gluon couplings and to the s-channel propagators entering the $gg \rightarrow hh$ amplitude. We discuss the numerical impact of the two-loop BSM contributions, first on the individual couplings and then on the prediction for the pair-production cross section, in two benchmark scenarios for the aligned THDM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11538v1" target="_blank">Reinforcing Video Reasoning Segmentation to Think Before It Segments</a></h3>
                    <p><strong>Authors:</strong> Sitong Gong, Lu Zhang, Yunzhi Zhuge, Xu Jia, Pingping Zhang, Huchuan Lu</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Video reasoning segmentation (VRS) endeavors to delineate referred objects in videos guided by implicit instructions that encapsulate human intent and temporal logic. Previous approaches leverage large vision language models (LVLMs) to encode object semantics into  tokens for mask prediction. However, this paradigm suffers from limited interpretability during inference and suboptimal performance due to inadequate spatiotemporal reasoning. Drawing inspiration from seminal breakthroughs in reinforcement learning, we introduce Veason-R1, a specialized LVLM for VRS that emphasizes structured reasoning in segmentation. Veason-R1 is trained through Group Relative Policy Optimization (GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, we curate high-quality CoT training data to instill structured reasoning trajectories, bridging video-level semantics and frame-level spatial grounding, yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPO fine-tuning encourages efficient exploration of the reasoning space by optimizing reasoning chains. To this end, we incorporate a holistic reward mechanism that synergistically enhances spatial alignment and temporal consistency, bolstering keyframe localization and fine-grained grounding. Comprehensive empirical evaluations demonstrate that Veason-R1 achieves state-of-the-art performance on multiple benchmarks, surpassing prior art by significant margins (e.g., +1.3 J F in ReVOS and +10.0 J F in ReasonVOS), while exhibiting robustness to hallucinations (+8.8 R). Our code and model weights will be available at Veason-R1.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11536v1" target="_blank">Language models align with brain regions that represent concepts across modalities</a></h3>
                    <p><strong>Authors:</strong> Maria Ryskina, Greta Tuckute, Alexander Fung, Ashley Malkin, Evelina Fedorenko</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Cognitive science and neuroscience have long faced the challenge of disentangling representations of language from representations of conceptual meaning. As the same problem arises in todays language models (LMs), we investigate the relationship between LM--brain alignment and two neural metrics: (1) the level of brain activation during processing of sentences, targeting linguistic processing, and (2) a novel measure of meaning consistency across input modalities, which quantifies how consistently a brain region responds to the same concept across paradigms (sentence, word cloud, image) using an fMRI dataset (Pereira et al., 2018). Our experiments show that both language-only and language-vision models predict the signal better in more meaning-consistent areas of the brain, even when these areas are not strongly sensitive to language processing, suggesting that LMs might internally represent cross-modal conceptual meaning.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11534v1" target="_blank">Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Monika JotautaitÄ—, Lucius Caviola, David A. Brewster, Thilo Hagendorff</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.CY</p>
                    <p><strong>Summary:</strong> As large language models (LLMs) become more widely deployed, it is crucial to examine their ethical tendencies. Building on research on fairness and discrimination in AI, we investigate whether LLMs exhibit speciesist bias -- discrimination based on species membership -- and how they value non-human animals. We systematically examine this issue across three paradigms: (1) SpeciesismBench, a 1,003-item benchmark assessing recognition and moral evaluation of speciesist statements; (2) established psychological measures comparing model responses with those of human participants; (3) text-generation tasks probing elaboration on, or resistance to, speciesist rationalizations. In our benchmark, LLMs reliably detected speciesist statements but rarely condemned them, often treating speciesist attitudes as morally acceptable. On psychological measures, results were mixed: LLMs expressed slightly lower explicit speciesism than people, yet in direct trade-offs they more often chose to save one human over multiple animals. A tentative interpretation is that LLMs may weight cognitive capacity rather than species per se: when capacities were equal, they showed no species preference, and when an animal was described as more capable, they tended to prioritize it over a less capable human. In open-ended text generation tasks, LLMs frequently normalized or rationalized harm toward farmed animals while refusing to do so for non-farmed animals. These findings suggest that while LLMs reflect a mixture of progressive and mainstream human views, they nonetheless reproduce entrenched cultural norms around animal exploitation. We argue that expanding AI fairness and alignment frameworks to explicitly include non-human moral patients is essential for reducing these biases and preventing the entrenchment of speciesist attitudes in AI systems and the societies they influence.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11529v1" target="_blank">A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow</a></h3>
                    <p><strong>Authors:</strong> George Paterakis, Andrea Castellani, George Papoutsoglou, Tobias Rodemann, Ioannis Tsamardinos</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Artificial intelligence is reshaping science and industry, yet many users still regard its models as opaque black boxes. Conventional explainable artificial-intelligence methods clarify individual predictions but overlook the upstream decisions and downstream quality checks that determine whether insights can be trusted. In this work, we present Holistic Explainable Artificial Intelligence (HXAI), a user-centric framework that embeds explanation into every stage of the data-analysis workflow and tailors those explanations to users. HXAI unifies six components (data, analysis set-up, learning process, model output, model quality, communication channel) into a single taxonomy and aligns each component with the needs of domain experts, data analysts and data scientists. A 112-item question bank covers these needs; our survey of contemporary tools highlights critical coverage gaps. Grounded in theories of human explanation, principles from human-computer interaction and findings from empirical user studies, HXAI identifies the characteristics that make explanations clear, actionable and cognitively manageable. A comprehensive taxonomy operationalises these insights, reducing terminological ambiguity and enabling rigorous coverage analysis of existing toolchains. We further demonstrate how AI agents that embed large-language models can orchestrate diverse explanation techniques, translating technical artifacts into stakeholder-specific narratives that bridge the gap between AI developers and domain experts. Departing from traditional surveys or perspective articles, this work melds concepts from multiple disciplines, lessons from real-world projects and a critical synthesis of the literature to advance a novel, end-to-end viewpoint on transparency, trustworthiness and responsible AI deployment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11524v1" target="_blank">Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Wenkai Yu, Jianhang Tang, Yang Zhang, Shanjiang Tang, Kebing Jin, Hankz Hankui Zhuo</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Addressing large-scale planning problems has become one of the central challenges in the planning community, deriving from the state-space explosion caused by growing objects and actions. Recently, researchers have explored the effectiveness of leveraging Large Language Models (LLMs) to generate helpful actions and states to prune the search space. However, prior works have largely overlooked integrating LLMs with domain-specific knowledge to ensure valid plans. In this paper, we propose a novel LLM-assisted planner integrated with problem decomposition, which first decomposes large planning problems into multiple simpler sub-tasks. Then we explore two novel paradigms to utilize LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where LLM4Inspire provides heuristic guidance according to general knowledge and LLM4Predict employs domain-specific knowledge to infer intermediate conditions. We empirically validate the effectiveness of our planner across multiple domains, demonstrating the ability of search space partition when solving large-scale planning problems. The experimental results show that LLMs effectively locate feasible solutions when pruning the search space, where infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds particular promise compared with LLM4Inspire, which offers general knowledge within LLMs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11517v1" target="_blank">A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11</a></h3>
                    <p><strong>Authors:</strong> Shaoze Huang, Qi Liu, Chao Chen, Yuhang Chen</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Accelerated aging of transportation infrastructure in the rapidly developing Yangtze River Delta region necessitates efficient concrete crack detection, as crack deterioration critically compromises structural integrity and regional economic growth. To overcome the limitations of inefficient manual inspection and the suboptimal performance of existing deep learning models, particularly for small-target crack detection within complex backgrounds, this paper proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and segmentation model based on the YOLOv11n architecture. The proposed model integrates a three-stage optimization framework: (1) Embedding dynamic KernelWarehouse convolution (KWConv) within the backbone network to enhance feature representation through a dynamic kernel sharing mechanism; (2) Incorporating a triple attention mechanism (TA) into the feature pyramid to strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU loss function to facilitate adaptive bounding box regression penalization. Experimental validation demonstrates that the enhanced model achieves significant performance improvements over the baseline, attaining 91.3% precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the synergistic efficacy of the proposed modules. Furthermore, robustness tests indicate stable performance under conditions of data scarcity and noise interference. This research delivers an efficient computer vision solution for automated infrastructure inspection, exhibiting substantial practical engineering value.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11515v1" target="_blank">Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations</a></h3>
                    <p><strong>Authors:</strong> Qipeng Kuang, VÃ¡clav KÅ¯la, OndÅ™ej KuÅ¾elka, Yuanhong Wang, Yuyi Wang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LO, cs.AI, 03C13, 68T27, F.4.0</p>
                    <p><strong>Summary:</strong> The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. The boundary between fragments for which WFOMC can be computed in polynomial time relative to the domain size lies between the two-variable fragment ($\text{FO}^2$) and the three-variable fragment ($\text{FO}^3$). It is known that WFOMC for \FOthree{} is $\mathsf{\#P_1}$-hard while polynomial-time algorithms exist for computing WFOMC for $\text{FO}^2$ and $\text{C}^2$, possibly extended by certain axioms such as the linear order axiom, the acyclicity axiom, and the connectedness axiom. All existing research has concentrated on extending the fragment with axioms on a single distinguished relation, leaving a gap in understanding the complexity boundary of axioms on multiple relations. In this study, we explore the extension of the two-variable fragment by axioms on two relations, presenting both negative and positive results. We show that WFOMC for $\text{FO}^2$ with two linear order relations and $\text{FO}^2$ with two acyclic relations are $\mathsf{\#P_1}$-hard. Conversely, we provide an algorithm in time polynomial in the domain size for WFOMC of $\text{C}^2$ with a linear order relation, its successor relation and another successor relation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11504v1" target="_blank">Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection</a></h3>
                    <p><strong>Authors:</strong> Andrea Castellani, Zacharias Papadovasilakis, Giorgos Papoutsoglou, Mary Cole, Brian Bautsch, Tobias Rodemann, Ioannis Tsamardinos, Angela Harden</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.CY</p>
                    <p><strong>Summary:</strong> Motor vehicle crashes remain a leading cause of injury and death worldwide, necessitating data-driven approaches to understand and mitigate crash severity. This study introduces a curated dataset of more than 3 million people involved in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3 million vehicle-level records for predictive analysis. The primary contribution is a transparent and reproducible methodology that combines Automated Machine Learning (AutoML) and explainable artificial intelligence (AI) to identify and interpret key risk factors associated with severe crashes. Using the JADBio AutoML platform, predictive models were constructed to distinguish between severe and non-severe crash outcomes. The models underwent rigorous feature selection across stratified training subsets, and their outputs were interpreted using SHapley Additive exPlanations (SHAP) to quantify the contribution of individual features. A final Ridge Logistic Regression model achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test set, with 17 features consistently identified as the most influential predictors. Key features spanned demographic, environmental, vehicle, human, and operational categories, including location type, posted speed, minimum occupant age, and pre-crash action. Notably, certain traditionally emphasized factors, such as alcohol or drug impairment, were less influential in the final model compared to environmental and contextual variables. Emphasizing methodological rigor and interpretability over mere predictive performance, this study offers a scalable framework to support Vision Zero with aligned interventions and advanced data-informed traffic safety policy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11502v1" target="_blank">AIM: Amending Inherent Interpretability via Self-Supervised Masking</a></h3>
                    <p><strong>Authors:</strong> Eyad Alshami, Shashank Agnihotri, Bernt Schiele, Margret Keuper</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> It has been observed that deep neural networks (DNNs) often use both genuine as well as spurious features. In this work, we propose Amending Inherent Interpretability via Self-Supervised Masking (AIM), a simple yet interestingly effective method that promotes the networks utilization of genuine features over spurious alternatives without requiring additional annotations. In particular, AIM uses features at multiple encoding stages to guide a self-supervised, sample-specific feature-masking process. As a result, AIM enables the training of well-performing and inherently interpretable models that faithfully summarize the decision process. We validate AIM across a diverse range of challenging datasets that test both out-of-distribution generalization and fine-grained visual understanding. These include general-purpose classification benchmarks such as ImageNet100, HardImageNet, and ImageWoof, as well as fine-grained classification datasets such as Waterbirds, TravelingBirds, and CUB-200. AIM demonstrates significant dual benefits: interpretability improvements, as measured by the Energy Pointing Game (EPG) score, and accuracy gains over strong baselines. These consistent gains across domains and architectures provide compelling evidence that AIM promotes the use of genuine and meaningful features that directly contribute to improved generalization and human-aligned interpretability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11484v1" target="_blank">CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Xiaoxue Wu, Bingjie Gao, Yu Qiao, Yaohui Wang, Xinyuan Chen</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Despite significant advances in video synthesis, research into multi-shot video generation remains in its infancy. Even with scaled-up models and massive datasets, the shot transition capabilities remain rudimentary and unstable, largely confining generated videos to single-shot sequences. In this work, we introduce CineTrans, a novel framework for generating coherent multi-shot videos with cinematic, film-style transitions. To facilitate insights into the film editing style, we construct a multi-shot video-text dataset Cine250K with detailed shot annotations. Furthermore, our analysis of existing video diffusion models uncovers a correspondence between attention maps in the diffusion model and shot boundaries, which we leverage to design a mask-based control mechanism that enables transitions at arbitrary positions and transfers effectively in a training-free setting. After fine-tuning on our dataset with the mask mechanism, CineTrans produces cinematic multi-shot sequences while adhering to the film editing style, avoiding unstable transitions or naive concatenations. Finally, we propose specialized evaluation metrics for transition control, temporal consistency and overall quality, and demonstrate through extensive experiments that CineTrans significantly outperforms existing baselines across all criteria.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11482v1" target="_blank">OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring</a></h3>
                    <p><strong>Authors:</strong> Ruoxin Xiong, Yanyu Wang, Jiannan Cai, Kaijian Liu, Yuansheng Zhu, Pingbo Tang, Nora El-Gohary</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The construction industry increasingly relies on visual data to support Artificial Intelligence (AI) and Machine Learning (ML) applications for site monitoring. High-quality, domain-specific datasets, comprising images, videos, and point clouds, capture site geometry and spatiotemporal dynamics, including the location and interaction of objects, workers, and materials. However, despite growing interest in leveraging visual datasets, existing resources vary widely in sizes, data modalities, annotation quality, and representativeness of real-world construction conditions. A systematic review to categorize their data characteristics and application contexts is still lacking, limiting the communitys ability to fully understand the dataset landscape, identify critical gaps, and guide future directions toward more effective, reliable, and scalable AI applications in construction. To address this gap, this study conducts an extensive search of academic databases and open-data platforms, yielding 51 publicly available visual datasets that span the 2005-2024 period. These datasets are categorized using a structured data schema covering (i) data fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv) downstream application domains (e.g., progress tracking). This study synthesizes these findings into an open-source catalog, OpenConstruction, supporting data-driven method development. Furthermore, the study discusses several critical limitations in the existing construction dataset landscape and presents a roadmap for future data infrastructure anchored in the Findability, Accessibility, Interoperability, and Reusability (FAIR) principles. By reviewing the current landscape and outlining strategic priorities, this study supports the advancement of data-centric solutions in the construction sector.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11476v1" target="_blank">SPG: Style-Prompting Guidance for Style-Specific Content Creation</a></h3>
                    <p><strong>Authors:</strong> Qian Liang, Zichong Chen, Yang Zhou, Hui Huang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.GR, cs.CV</p>
                    <p><strong>Summary:</strong> Although recent text-to-image (T2I) diffusion models excel at aligning generated images with textual prompts, controlling the visual style of the output remains a challenging task. In this work, we propose Style-Prompting Guidance (SPG), a novel sampling strategy for style-specific image generation. SPG constructs a style noise vector and leverages its directional deviation from unconditional noise to guide the diffusion process toward the target style distribution. By integrating SPG with Classifier-Free Guidance (CFG), our method achieves both semantic fidelity and style consistency. SPG is simple, robust, and compatible with controllable frameworks like ControlNet and IPAdapter, making it practical and widely applicable. Extensive experiments demonstrate the effectiveness and generality of our approach compared to state-of-the-art methods. Code is available at https://github.com/Rumbling281441/SPG.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11469v1" target="_blank">CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation</a></h3>
                    <p><strong>Authors:</strong> Hongjin Fang, Daniel ReisenbÃ¼chler, Kenji Ikemura, Mert R. Sabuncu, Yihe Yang, Ruining Deng</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Accurate segmentation of the glomerular basement membrane (GBM) in electron microscopy (EM) images is fundamental for quantifying membrane thickness and supporting the diagnosis of various kidney diseases. While supervised deep learning approaches achieve high segmentation accuracy, their reliance on extensive pixel-level annotation renders them impractical for clinical workflows. Few-shot learning can reduce this annotation burden but often struggles to capture the fine structural details necessary for GBM analysis. In this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot segmentation pipeline designed for GBM delineation in EM images. CoFi first trains a lightweight neural network using only three annotated images to produce an initial coarse segmentation mask. This mask is then automatically processed to generate high-quality point prompts with morphology-aware pruning, which are subsequently used to guide SAM in refining the segmentation. The proposed method achieved exceptional GBM segmentation performance, with a Dice coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that CoFi not only alleviates the annotation and computational burdens associated with conventional methods, but also achieves accurate and reliable segmentation results. The pipelines speed and annotation efficiency make it well-suited for research and hold strong potential for clinical applications in renal pathology. The pipeline is publicly available at: https://github.com/ddrrnn123/CoFi.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11464v1" target="_blank">Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge</a></h3>
                    <p><strong>Authors:</strong> Xiaoya Zhu, Yibing Nan, Shiguo Lian</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the rapid development of technology in the field of AI, deepfake technology has emerged as a double-edged sword. It has not only created a large amount of AI-generated content but also posed unprecedented challenges to digital security. The task of the competition is to determine whether a face image is a Deepfake image and output its probability score of being a Deepfake image. In the image track competition, our approach is based on the Swin Transformer V2-B classification network. And online data augmentation and offline sample generation methods are employed to enrich the diversity of training samples and increase the generalization ability of the model. Finally, we got the award of excellence in Deepfake image detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11460v1" target="_blank">Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models</a></h3>
                    <p><strong>Authors:</strong> Aurora Grefsrud, Nello Blaser, Trygve Buanes</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, stat.ML</p>
                    <p><strong>Summary:</strong> Rigorous statistical methods, including parameter estimation with accompanying uncertainties, underpin the validity of scientific discovery, especially in the natural sciences. With increasingly complex data models such as deep learning techniques, uncertainty quantification has become exceedingly difficult and a plethora of techniques have been proposed. In this case study, we use the unifying framework of approximate Bayesian inference combined with empirical tests on carefully created synthetic classification datasets to investigate qualitative properties of six different probabilistic machine learning algorithms for class probability and uncertainty estimation: (i) a neural network ensemble, (ii) neural network ensemble with conflictual loss, (iii) evidential deep learning, (iv) a single neural network with Monte Carlo Dropout, (v) Gaussian process classification and (vi) a Dirichlet process mixture model. We check if the algorithms produce uncertainty estimates which reflect commonly desired properties, such as being well calibrated and exhibiting an increase in uncertainty for out-of-distribution data points. Our results indicate that all algorithms are well calibrated, but none of the deep learning based algorithms provide uncertainties that consistently reflect lack of experimental evidence for out-of-distribution data points. We hope our study may serve as a clarifying example for researchers developing new methods of uncertainty estimation for scientific data-driven modeling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11457v1" target="_blank">Importance-Aware Robust Semantic Transmission for LEO Satellite-Ground Communication</a></h3>
                    <p><strong>Authors:</strong> Hui Cao, Rui Meng, Xiaodong Xu, Shujun Han, Ping Zhang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> Satellite-ground semantic communication is anticipated to serve a critical role in the forthcoming 6G era. Nonetheless, task-oriented data transmission in such systems remains a formidable challenge, primarily due to the dynamic nature of signal-to-noise ratio (SNR) fluctuations and the stringent bandwidth limitations inherent to low Earth orbit (LEO) satellite channels. In response to these constraints, we propose an importance-aware robust semantic transmission (IRST) framework, specifically designed for scenarios characterized by bandwidth scarcity and channel variability. The IRST scheme begins by applying a segmentation model enhancement algorithm to improve the granularity and accuracy of semantic segmentation. Subsequently, a task-driven semantic selection method is employed to prioritize the transmission of semantically vital content based on real-time channel state information. Furthermore, the framework incorporates a stack-based, SNR-aware channel codec capable of executing adaptive channel coding in alignment with SNR variations. Comparative evaluations across diverse operating conditions demonstrate the superior performance and resilience of the IRST model relative to existing benchmarks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11454v1" target="_blank">Reference Points in LLM Sentiment Analysis: The Role of Structured Context</a></h3>
                    <p><strong>Authors:</strong> Junichiro Niimi</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are now widely used across many fields, including marketing research. Sentiment analysis, in particular, helps firms understand consumer preferences. While most NLP studies classify sentiment from review text alone, marketing theories, such as prospect theory and expectation--disconfirmation theory, point out that customer evaluations are shaped not only by the actual experience but also by additional reference points. This study therefore investigates how the content and format of such supplementary information affect sentiment analysis using LLMs. We compare natural language (NL) and JSON-formatted prompts using a lightweight 3B parameter model suitable for practical marketing applications. Experiments on two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with additional information outperforms all baselines without fine-tuning: Macro-F1 rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it deployable in resource-constrained edge devices. Furthermore, a follow-up analysis confirms that performance gains stem from genuine contextual reasoning rather than label proxying. This work demonstrates that structured prompting can enable smaller models to achieve competitive performance, offering a practical alternative to large-scale model deployment.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11452v1" target="_blank">Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps</a></h3>
                    <p><strong>Authors:</strong> Kangyu Wang, Hongliang He, Lin Liu, Ruiqi Liang, Zhenzhong Lan, Jianguo Li</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL, cs.HC</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have ushered in a new era of AI capabilities, demonstrating near-human-level performance across diverse scenarios. While numerous benchmarks (e.g., MMLU) and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the development of LLMs and MLLMs, most rely on static datasets or crowdsourced general-domain prompts, often falling short of reflecting performance in real-world applications. To bridge this critical gap, we present Inclusion Arena, a live leaderboard that ranks models based on human feedback collected directly from AI-powered applications. Our platform integrates pairwise model comparisons into natural user interactions, ensuring evaluations reflect practical usage scenarios. For robust model ranking, we employ the Bradley-Terry model augmented with two key innovations: (1) Placement Matches, a cold-start mechanism to quickly estimate initial ratings for newly integrated models, and (2) Proximity Sampling, an intelligent comparison strategy that prioritizes battles between models of similar capabilities to maximize information gain and enhance rating stability. Extensive empirical analyses and simulations demonstrate that Inclusion Arena yields reliable and stable rankings, exhibits higher data transitivity compared to general crowdsourced datasets, and significantly mitigates the risk of malicious manipulation. By fostering an open alliance between foundation models and real-world applications, Inclusion Arena aims to accelerate the development of LLMs and MLLMs truly optimized for practical, user-centric deployments. The platform is publicly accessible at https://doraemon.alipay.com/model-ranking.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1007/978-3-031-98694-9_12" target="_blank">Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer</a></h3>
                    <p><strong>Authors:</strong> Augustine X. W. Lee, Pak-Hei Yeung, Jagath C. Rajapakse</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> Subcortical segmentation in neuroimages plays an important role in understanding brain anatomy and facilitating computer-aided diagnosis of traumatic brain injuries and neurodegenerative disorders. However, training accurate automatic models requires large amounts of labelled data. Despite the availability of publicly available subcortical segmentation datasets for Magnetic Resonance Imaging (MRI), a significant gap exists for Computed Tomography (CT). This paper proposes an automatic ensemble framework to generate high-quality subcortical segmentation labels for CT scans by leveraging existing MRI-based models. We introduce a robust ensembling pipeline to integrate them and apply it to unannotated paired MRI-CT data, resulting in a comprehensive CT subcortical segmentation dataset. Extensive experiments on multiple public datasets demonstrate the superior performance of our proposed framework. Furthermore, using our generated CT dataset, we train segmentation models that achieve improved performance on related segmentation tasks. To facilitate future research, we make our source code, generated dataset, and trained models publicly available at https://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation, marking the first open-source release for CT subcortical segmentation to the best of our knowledge.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11441v1" target="_blank">Informative Post-Hoc Explanations Only Exist for Simple Functions</a></h3>
                    <p><strong>Authors:</strong> Eric GÃ¼nther, BalÃ¡zs Szabados, Robi Bhattacharjee, Sebastian Bordt, Ulrike von Luxburg</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Many researchers have suggested that local post-hoc explanation algorithms can be used to gain insights into the behavior of complex machine learning models. However, theoretical guarantees about such algorithms only exist for simple decision functions, and it is unclear whether and under which assumptions similar results might exist for complex models. In this paper, we introduce a general, learning-theory-based framework for what it means for an explanation to provide information about a decision function. We call an explanation informative if it serves to reduce the complexity of the space of plausible decision functions. With this approach, we show that many popular explanation algorithms are not informative when applied to complex decision functions, providing a rigorous mathematical rejection of the idea that it should be possible to explain any model. We then derive conditions under which different explanation algorithms become informative. These are often stronger than what one might expect. For example, gradient explanations and counterfactual explanations are non-informative with respect to the space of differentiable functions, and SHAP and anchor explanations are not informative with respect to the space of decision trees. Based on these results, we discuss how explanation algorithms can be modified to become informative. While the proposed analysis of explanation algorithms is mathematical, we argue that it holds strong implications for the practical applicability of these algorithms, particularly for auditing, regulation, and high-risk applications of AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11433v1" target="_blank">MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation</a></h3>
                    <p><strong>Authors:</strong> Qian Liang, Yujia Wu, Kuncheng Li, Jiwei Wei, Shiyuan He, Jinyu Guo, Ning Xie</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Multimodal Large Language Models (MLLMs) with unified architectures excel across a wide range of vision-language tasks, yet aligning them with personalized image generation remains a significant challenge. Existing methods for MLLMs are frequently subject-specific, demanding a data-intensive fine-tuning process for every new subject, which limits their scalability. In this paper, we introduce MM-R1, a framework that integrates a cross-modal Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of unified MLLMs for personalized image generation. Specifically, we structure personalization as an integrated visual reasoning and generation process: (1) grounding subject concepts by interpreting and understanding user-provided images and contextual cues, and (2) generating personalized images conditioned on both the extracted subject representations and user prompts. To further enhance the reasoning capability, we adopt Grouped Reward Proximal Policy Optimization (GRPO) to explicitly align the generation. Experiments demonstrate that MM-R1 unleashes the personalization capability of unified MLLMs to generate images with high subject fidelity and strong text alignment in a zero-shot manner.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11429v1" target="_blank">HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor</a></h3>
                    <p><strong>Authors:</strong> Shivam Dubey</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Automated humor generation with Large Language Models (LLMs) often yields jokes that feel generic, repetitive, or tone-deaf because humor is deeply situated and hinges on the listeners cultural background, mindset, and immediate context. We introduce HumorPlanSearch, a modular pipeline that explicitly models context through: (1) Plan-Search for diverse, topic-tailored strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt high-performing historical strategies; (4) novelty filtering via semantic embeddings; and (5) an iterative judge-driven revision loop. To evaluate context sensitivity and comedic quality, we propose the Humor Generation Score (HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates, and topic relevance. In experiments across nine topics with feedback from 13 human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent (p  0.05) over a strong baseline. By foregrounding context at every stage from strategy planning to multi-signal evaluation, HumorPlanSearch advances AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11414v1" target="_blank">Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions</a></h3>
                    <p><strong>Authors:</strong> Shangrui Nie, Florian Mai, David KaczÃ©r, Charles Welch, Zhixue Zhao, Lucie Flek</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large language models implicitly encode preferences over human values, yet steering them often requires large training data. In this work, we investigate a simple approach: Can we reliably modify a models value system in downstream behavior by training it to answer value survey questions accordingly? We first construct value profiles of several open-source LLMs by asking them to rate a series of value-related descriptions spanning 20 distinct human values, which we use as a baseline for subsequent experiments. We then investigate whether the value system of a model can be governed by fine-tuning on the value surveys. We evaluate the effect of finetuning on the models behavior in two ways; first, we assess how answers change on in-domain, held-out survey questions. Second, we evaluate whether the models behavior changes in out-of-domain settings (situational scenarios). To this end, we construct a contextualized moral judgment dataset based on Reddit posts and evaluate changes in the models behavior in text-based adventure games. We demonstrate that our simple approach can not only change the models answers to in-domain survey questions, but also produces substantial shifts (value alignment) in implicit downstream task behavior.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11408v1" target="_blank">On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting</a></h3>
                    <p><strong>Authors:</strong> Wenhao Zhang, Yuexiang Xie, Yuchang Sun, Yanxi Chen, Guoyin Wang, Yaliang Li, Bolin Ding, Jingren Zhou</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                    <p><strong>Summary:</strong> Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms for refining the capabilities and aligning the behavior of Large Language Models (LLMs). Existing approaches that integrate SFT and RL often face the risk of disrupting established model patterns and inducing overfitting to expert data. To address this, we present a novel investigation into the unified view of SFT and RL through an off-policy versus on-policy lens. We propose CHORD, a framework for the Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting, which reframes SFT not as a separate stage but as a dynamically weighted auxiliary objective within the on-policy RL process. Based on an analysis of off-policy expert datas influence at both holistic and granular levels, we incorporate a dual-control mechanism in CHORD. Specifically, the framework first employs a global coefficient to holistically guide the transition from off-policy imitation to on-policy exploration, and then applies a token-wise weighting function that enables granular learning from expert tokens, which preserves on-policy exploration and mitigates disruption from off-policy data. We conduct extensive experiments on widely used benchmarks, providing empirical evidence that CHORD achieves a stable and efficient learning process. By effectively harmonizing off-policy expert data with on-policy exploration, CHORD demonstrates significant improvements over baselines. We release the implementation at https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to inspire further research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11406v1" target="_blank">Open, Reproducible and Trustworthy Robot-Based Experiments with Virtual Labs and Digital-Twin-Based Execution Tracing</a></h3>
                    <p><strong>Authors:</strong> Benjamin Alt, Mareike Picklum, Sorin Arion, Franklin Kenghagho Kenfack, Michael Beetz</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, 68T40, I.2.9</p>
                    <p><strong>Summary:</strong> We envision a future in which autonomous robots conduct scientific experiments in ways that are not only precise and repeatable, but also open, trustworthy, and transparent. To realize this vision, we present two key contributions: a semantic execution tracing framework that logs sensor data together with semantically annotated robot belief states, ensuring that automated experimentation is transparent and replicable; and the AICOR Virtual Research Building (VRB), a cloud-based platform for sharing, replicating, and validating robot task executions at scale. Together, these tools enable reproducible, robot-driven science by integrating deterministic execution, semantic memory, and open knowledge representation, laying the foundation for autonomous systems to participate in scientific discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11404v1" target="_blank">An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration</a></h3>
                    <p><strong>Authors:</strong> Junyeon Kim, Tianshu Ruan, Cesar Alan Contreras, Manolis Chiou</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Structural inspection in nuclear facilities is vital for maintaining operational safety and integrity. Traditional methods of manual inspection pose significant challenges, including safety risks, high cognitive demands, and potential inaccuracies due to human limitations. Recent advancements in Artificial Intelligence (AI) and robotic technologies have opened new possibilities for safer, more efficient, and accurate inspection methodologies. Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms equipped with advanced detection algorithms, promises significant improvements in inspection outcomes and reductions in human workload. This study explores the effectiveness of AI-assisted visual crack detection integrated into a mobile Jackal robot platform. The experiment results indicate that HRC enhances inspection accuracy and reduces operator workload, resulting in potential superior performance outcomes compared to traditional manual methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11403v1" target="_blank">The Effect of Flow Parameters and Wall Models on Gas-Surface Interactions: A Numerical Investigation of dsmcFoam</a></h3>
                    <p><strong>Authors:</strong> M. B. Agir, N. H. Crisp, K. L. Smith, P. C. E. Roberts, M. Newsam, M. Griffiths, S Vaidya</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Atmosphere-breathing electric propulsion systems harness atmospheric particles as propellant, enabling efficient operation across diverse environmental conditions. To accurately simulate the captured gas flow through the modules, particle-surface interactions must be carefully modelled. To initiate this research, a parametric study is conducted using an extensive simulation matrix to investigate the effects of flow parameters, such as velocity, temperature, species, and angle of attack, and wall model parameters (diffuse fraction/accommodation coefficient) on gas-surface interactions. A simplified test geometry was created to run 2D simulations, where the flow interacts with an adjacent wall positioned perpendicular to one of the inlet patches. In this study, changes in reflection patterns, force density on the surface, and flow properties in the vicinity of the wall are investigated under varying flow and wall conditions using the current boundary conditions of the dsmcFoam solver. Furthermore, the capabilities of dsmcFoams default boundary conditions in predicting gas-surface interaction physics are evaluated using the results of the simulation matrix. The findings highlight the need for new boundary conditions to accurately replicate interaction physics across various aspects.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11401v1" target="_blank">FACET:Teacher-Centred LLM-Based Multi-Agent Systems-Towards Personalized Educational Worksheets</a></h3>
                    <p><strong>Authors:</strong> Jana Gonnermann-MÃ¼ller, Jennifer Haase, Konstantin Fackeldey, Sebastian Pokutta</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.MA</p>
                    <p><strong>Summary:</strong> The increasing heterogeneity of student populations poses significant challenges for teachers, particularly in mathematics education, where cognitive, motivational, and emotional differences strongly influence learning outcomes. While AI-driven personalization tools have emerged, most remain performance-focused, offering limited support for teachers and neglecting broader pedagogical needs. This paper presents the FACET framework, a teacher-facing, large language model (LLM)-based multi-agent system designed to generate individualized classroom materials that integrate both cognitive and motivational dimensions of learner profiles. The framework comprises three specialized agents: (1) learner agents that simulate diverse profiles incorporating topic proficiency and intrinsic motivation, (2) a teacher agent that adapts instructional content according to didactical principles, and (3) an evaluator agent that provides automated quality assurance. We tested the system using authentic grade 8 mathematics curriculum content and evaluated its feasibility through a) automated agent-based assessment of output quality and b) exploratory feedback from K-12 in-service teachers. Results from ten internal evaluations highlighted high stability and alignment between generated materials and learner profiles, and teacher feedback particularly highlighted structure and suitability of tasks. The findings demonstrate the potential of multi-agent LLM architectures to provide scalable, context-aware personalization in heterogeneous classroom settings, and outline directions for extending the framework to richer learner profiles and real-world classroom trials.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11398v1" target="_blank">Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis</a></h3>
                    <p><strong>Authors:</strong> Mithat Can Ozgun, Jiahuan Pei, Koen Hindriks, Lucia Donatelli, Qingzhi Liu, Xin Sun, Junxiao Wang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.AI, cs.IR</p>
                    <p><strong>Summary:</strong> LLM-based agents have emerged as transformative tools capable of executing complex tasks through iterative planning and action, achieving significant advancements in understanding and addressing user needs. Yet, their effectiveness remains limited in specialized domains such as mental health diagnosis, where they underperform compared to general applications. Current approaches to integrating diagnostic capabilities into LLMs rely on scarce, highly sensitive mental health datasets, which are challenging to acquire. These methods also fail to emulate clinicians proactive inquiry skills, lack multi-turn conversational comprehension, and struggle to align outputs with expert clinical reasoning. To address these gaps, we propose DSM5AgentFlow, the first LLM-based agent workflow designed to autonomously generate DSM-5 Level-1 diagnostic questionnaires. By simulating therapist-client dialogues with specific client profiles, the framework delivers transparent, step-by-step disorder predictions, producing explainable and trustworthy results. This workflow serves as a complementary tool for mental health diagnosis, ensuring adherence to ethical and legal standards. Through comprehensive experiments, we evaluate leading LLMs across three critical dimensions: conversational realism, diagnostic accuracy, and explainability. Our datasets and implementations are fully open-sourced.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.18653/v1/2024.emnlp-main.664" target="_blank">Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training</a></h3>
                    <p><strong>Authors:</strong> Marc Brinner, Sina ZarrieÃŸ</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> We propose an end-to-end differentiable training paradigm for stable training of a rationalized transformer classifier. Our approach results in a single model that simultaneously classifies a sample and scores input tokens based on their relevance to the classification. To this end, we build on the widely-used three-player-game for training rationalized models, which typically relies on training a rationale selector, a classifier and a complement classifier. We simplify this approach by making a single model fulfill all three roles, leading to a more efficient training paradigm that is not susceptible to the common training instabilities that plague existing approaches. Further, we extend this paradigm to produce class-wise rationales while incorporating recent advances in parameterizing and regularizing the resulting rationales, thus leading to substantially improved and state-of-the-art alignment with human annotations without any explicit supervision.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11376v1" target="_blank">Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition</a></h3>
                    <p><strong>Authors:</strong> Durgesh Mishra, Rishabh Uikey</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Knowledge Distillation is crucial for optimizing face recognition models for deployment in computationally limited settings, such as edge devices. Traditional KD methods, such as Raw L2 Feature Distillation or Feature Consistency loss, often fail to capture both fine-grained instance-level details and complex relational structures, leading to suboptimal performance. We propose a unified approach that integrates two novel loss functions, Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity Distillation. Instance-Level Embedding Distillation focuses on aligning individual feature embeddings by leveraging a dynamic hard mining strategy, thereby enhancing learning from challenging examples. Relation-Based Pairwise Similarity Distillation captures relational information through pairwise similarity relationships, employing a memory bank mechanism and a sample mining strategy. This unified framework ensures both effective instance-level alignment and preservation of geometric relationships between samples, leading to a more comprehensive distillation process. Our unified framework outperforms state-of-the-art distillation methods across multiple benchmark face recognition datasets, as demonstrated by extensive experimental evaluations. Interestingly, when using strong teacher networks compared to the student, our unified KD enables the student to even surpass the teachers accuracy.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11374v1" target="_blank">Does the Skeleton-Recall Loss Really Work?</a></h3>
                    <p><strong>Authors:</strong> Devansh Arora, Nitin Kumar, Sukrit Gupta</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Image segmentation is an important and widely performed task in computer vision. Accomplishing effective image segmentation in diverse settings often requires custom model architectures and loss functions. A set of models that specialize in segmenting thin tubular structures are topology preservation-based loss functions. These models often utilize a pixel skeletonization process claimed to generate more precise segmentation masks of thin tubes and better capture the structures that other models often miss. One such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite {kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark tubular datasets. In this work, we performed a theoretical analysis of the gradients for the SRL loss. Upon comparing the performance of the proposed method on some of the tubular datasets (used in the original work, along with some additional datasets), we found that the performance of SRL-based segmentation models did not exceed traditional baseline models. By providing both a theoretical explanation and empirical evidence, this work critically evaluates the limitations of topology-based loss functions, offering valuable insights for researchers aiming to develop more effective segmentation models for complex tubular structures.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1109/ISCSLP63861.2024.10800612" target="_blank">Speech Emotion Recognition Using Fine-Tuned DWFormer:A Study on Track 1 of the IERPChallenge 2024</a></h3>
                    <p><strong>Authors:</strong> Honghong Wang, Xupeng Jia, Jing Deng, Rong Zheng</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> The field of artificial intelligence has a strong interest in the topic of emotion recognition. The majority of extant emotion recognition models are oriented towards enhancing the precision of discrete emotion label prediction. Given the direct relationship between human personality and emotion, as well as the significant inter-individual differences in subjective emotional expression, the IERP Challenge 2024 incorporates personality traits into emotion recognition research. This paper presents the Fosafer submissions to the Track 1 of the IERP Challenge 2024. This task primarily concerns the recognition of emotions in audio, while also providing text and audio features. In Track 1, we utilized exclusively audio-based features and fine-tuned a pre-trained speech emotion recognition model, DWFormer, through the integration of data augmentation and score fusion strategies, thereby achieving the first place among the participating teams.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11368v1" target="_blank">A solution of the quantum time of arrival problem via mathematical probability theory</a></h3>
                    <p><strong>Authors:</strong> Maik Reddiger</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> quant-ph, 81P15 (Primary) 81P05, 81S99, 82D99 (Secondary)</p>
                    <p><strong>Summary:</strong> Time of arrival refers to the time a particle takes after emission to impinge upon a suitably idealized detector surface. Within quantum theory, no generally accepted solution exists so far for the corresponding probability distribution of arrival times. In this work we derive a general solution for a single body without spin impacting on a so called ideal detector in the absence of any other forces or obstacles. A solution of the so called screen problem for this case is also given. We construct the ideal detector model via mathematical probability theory, which in turn suggests an adaption of the Madelung equations in this instance. This detector model assures that the probability flux through the detector surface is always positive, so that the corresponding distributions can be derived via an approach originally suggested by Daumer, D\urr, Goldstein, and Zangh\`i. The resulting dynamical model is, strictly speaking, not compatible with quantum mechanics, yet it is well-described within geometric quantum theory. Geometric quantum theory is a novel adaption of quantum mechanics, which makes the latter consistent with mathematical probability theory. Implications to the general theory of measurement and avenues for future research are also provided. Future mathematical work should focus on finding an appropriate distributional formulation of the evolution equations and studying the well-posedness of the corresponding Cauchy problem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11631v1" target="_blank">Laser Interferometer Lunar Antenna (LILA): Advancing the U.S. Priorities in Gravitational-wave and Lunar Science</a></h3>
                    <p><strong>Authors:</strong> Karan Jani, Matthew Abernathy, Emanuele Berti, Valerio Boschi, Sukanya Chakrabarti, Alice Cocoros, John W. Conklin, Teviet Creighton, Simone DellAgnello, Jean-Claude Diels, Stephen Eikenberry, T. Marshall Eubanks, Kiranjyot Gill, Jonathan E. Grindlay, Kris Izquierdo, Jaesung Lee, Abraham Loeb, Philippe LognonnÃ©, Francesco Longo, Manuel Pichardo Marcano, Mark Panning, Paula do Vale Pereira, Volker Quetschke, Ashique Rahman, Massimiliano Razzano, Robert Reed, Brett Shapiro, David Shoemaker, William Smith, James Trippe, Eric Van Stryland, Wan Wu, Anjali B. Yelikar</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.HE, astro-ph.IM</p>
                    <p><strong>Summary:</strong> The Laser Interferometer Lunar Antenna (LILA) is a next-generation gravitational-wave (GW) facility on the Moon. By harnessing the Moons unique environment, LILA fills a critical observational gap in the mid-band GW spectrum ($0.1 - 10$ Hz) between terrestrial detectors (LIGO, Virgo, KAGRA) and the future space mission LISA. Observations enabled by LILA will fundamentally transform multi-messenger astrophysics and GW probes of fundamental physics. LILA will measure the lunar deep interior better than any existing planetary seismic instruments. The LILA mission is designed for phased development aligned with capabilities of the U.S.s Commercial Lunar Payload Services and Artemis programs. LILA is a unique collaboration between universities, space industries, U.S. government laboratories, and international partners.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11630v1" target="_blank">Thyme: Think Beyond Images</a></h3>
                    <p><strong>Authors:</strong> Yi-Fan Zhang, Xingyu Lu, Shukang Yin, Chaoyou Fu, Wei Chen, Xiao Hu, Bin Wen, Kaiyu Jiang, Changyi Liu, Tianke Zhang, Haonan Fan, Kaibing Chen, Jiankang Chen, Haojie Ding, Kaiyu Tang, Zhang Zhang, Liang Wang, Fan Yang, Tingting Gao, Guorui Zhou</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Following OpenAIs introduction of the ``thinking with images concept, recent efforts have explored stimulating the use of visual information in the reasoning process to enhance model performance in perception and reasoning tasks. However, to the best of our knowledge, no open-source work currently offers a feature set as rich as proprietary models (O3), which can perform diverse image manipulations and simultaneously enhance logical reasoning capabilities through code. In this paper, we make a preliminary attempt in this direction by introducing Thyme (Think Beyond Images), a novel paradigm for enabling MLLMs to transcend existing ``think with images approaches by autonomously generating and executing diverse image processing and computational operations via executable code. This approach not only facilitates a rich, on-the-fly set of image manipulations (e.g., cropping, rotation, contrast enhancement) but also allows for mathematical computations, all while maintaining high autonomy in deciding when and how to apply these operations. We activate this capability through a two-stage training strategy: an initial SFT on a curated dataset of 500K samples to teach code generation, followed by a RL phase to refine decision-making. For the RL stage, we manually collect and design high-resolution question-answer pairs to increase the learning difficulty, and we propose GRPO-ATS (Group Relative Policy Optimization with Adaptive Temperature Sampling), an algorithm that applies distinct temperatures to text and code generation to balance reasoning exploration with code execution precision. We conduct extensive experimental analysis and ablation studies. Comprehensive evaluations on nearly 20 benchmarks show that Thyme yields significant and consistent performance gains, particularly in challenging high-resolution perception and complex reasoning tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11628v1" target="_blank">Is ChatGPT-5 Ready for Mammogram VQA?</a></h3>
                    <p><strong>Authors:</strong> Qiang Li, Shansong Wang, Mingzhe Hu, Mojtaba Safari, Zachary Eidex, Xiaofeng Yang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Mammogram visual question answering (VQA) integrates image interpretation with clinical reasoning and has potential to support breast cancer screening. We systematically evaluated the GPT-5 family and GPT-4o model on four public mammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment, abnormality detection, and malignancy classification tasks. GPT-5 consistently was the best performing model but lagged behind both human experts and domain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scores among GPT variants in density (56.8%), distortion (52.5%), mass (64.5%), calcification (63.5%), and malignancy (52.8%) classification. On InBreast, it attained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0% malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detection and 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADS accuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Compared with human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) and specificity (52.3%). While GPT-5 exhibits promising capabilities for screening tasks, its performance remains insufficient for high-stakes clinical imaging applications without targeted domain adaptation and optimization. However, the tremendous improvements in performance from GPT-4o to GPT-5 show a promising trend in the potential for general large language models (LLMs) to assist with mammography VQA tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11626v1" target="_blank">A string based model with Hagedorn temperature of $T_H\sim 300~$MeV describes the spectrum of mesons and glueballs</a></h3>
                    <p><strong>Authors:</strong> MichaÅ‚ Marczenko, GyÅ‘zÅ‘ KovÃ¡cs, Larry McLerran, Krzysztof Redlich</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> hep-ph</p>
                    <p><strong>Summary:</strong> We consider the thermodynamics of a color-confined phase of quantum chromodynamics (QCD) and pure gauge theory within a string-inspired model, corresponding to a physical spatial dimension, d = 3. We show that the physical mass spectrum of massive mesons--in both the strange and non-strange sectors separately--is reasonably well described and extended by the exponential mass spectrum of open strings, $\rho(m)$, characterized by a unique Hagedorn temperature, $T_H = \sqrt{3\sigma/2\pi}$, expressed by the string tension, $\sigma$. This $T_H$ is the value appropriate for d = 3 spatial dimensions, and is of order $T_H \sim 300~\rm MeV$ for typical values of the string tension. It is much larger than the values of $T_H$, which have been phenomenologically extracted \green{so far} to describe the meson spectrum. Glueball states in pure gauge theory, modeled by closed strings, exhibit a similarly large Hagedorn temperature, highlighting a universal feature of the exponential spectrum. We further analyze the thermodynamic properties of the equation of state at finite temperature and demonstrate that, in the confined phase, the string models agree with lattice QCD results. This lends further support to the recent interpretation of the QCD phase diagram that incorporates strings as relevant degrees of freedom.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11624v1" target="_blank">LoRAtorio: An intrinsic approach to LoRA Skill Composition</a></h3>
                    <p><strong>Authors:</strong> Niki Foteinopoulou, Ignas Budvytis, Stephan Liwicki</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Low-Rank Adaptation (LoRA) has become a widely adopted technique in text-to-image diffusion models, enabling the personalisation of visual concepts such as characters, styles, and objects. However, existing approaches struggle to effectively compose multiple LoRA adapters, particularly in open-ended settings where the number and nature of required skills are not known in advance. In this work, we present LoRAtorio, a novel train-free framework for multi-LoRA composition that leverages intrinsic model behaviour. Our method is motivated by two key observations: (1) LoRA adapters trained on narrow domains produce denoised outputs that diverge from the base model, and (2) when operating out-of-distribution, LoRA outputs show behaviour closer to the base model than when conditioned in distribution. The balance between these two observations allows for exceptional performance in the single LoRA scenario, which nevertheless deteriorates when multiple LoRAs are loaded. Our method operates in the latent space by dividing it into spatial patches and computing cosine similarity between each patchs predicted noise and that of the base model. These similarities are used to construct a spatially-aware weight matrix, which guides a weighted aggregation of LoRA outputs. To address domain drift, we further propose a modification to classifier-free guidance that incorporates the base models unconditional score into the composition. We extend this formulation to a dynamic module selection setting, enabling inference-time selection of relevant LoRA adapters from a large pool. LoRAtorio achieves state-of-the-art performance, showing up to a 1.3% improvement in ClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generalises effectively to multiple latent diffusion models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11623v1" target="_blank">Robust Topology and the Hausdorff-Smyth Monad on Metric Spaces over Continuous Quantales</a></h3>
                    <p><strong>Authors:</strong> Francesco Dagnino, Amin Farjudian Eugenio Moggi</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LO, 06B35, 06F07, F.3.2</p>
                    <p><strong>Summary:</strong> We define a (preorder-enriched) category $\mathsf{Met}$ of quantale-valued metric spaces and uniformly continuous maps, with the essential requirement that the quantales are continuous. For each object $(X,d,Q)$ in this category, where $X$ is the carrier set, $Q$ is a continuous quantale, and $d: X \times X \to Q$ is the metric, we consider a topology $\tau_d$ on $X$, which generalizes the open ball topology, and a topology $\tau_{d,R}$ on the powerset $\mathsf{P}(X)$, called the robust topology, which captures robustness with respect to small perturbations of parameters. We define a (preorder-enriched) monad $\mathsf{P}_S$ on $\mathsf{Met}$, called the Hausdorff-Smyth monad, which captures the robust topology, in the sense that the open ball topology of the object $\mathsf{P}_S(X,d,Q)$ coincides with the robust topology $\tau_{d,R}$ for the object $(X,d,Q)$. We prove that every topology arises from a quantale-valued metric. As such, our framework provides a foundation for quantitative reasoning about imprecision and robustness in a wide range of computational and physical systems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11621v1" target="_blank">Higher Zariski Geometry</a></h3>
                    <p><strong>Authors:</strong> Ko Aoki, Tobias Barthel, Anish Chedalavada, Tomer Schlank, Greg Stevenson</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> math.AG, math.AT, math.CT, math.RT</p>
                    <p><strong>Summary:</strong> We revisit the classical constructions of tensor-triangular geometry in the setting of stably symmetric monoidal idempotent-complete $\infty$-categories, henceforth referred to as 2-rings. In this setting, we produce a Zariski topology, a Zariski spectrum, a category of locally 2-ringed spaces (more generally $\infty$-topoi), and an affine spectrum-global sections adjunction, based on the framework of ``$\infty$-topoi with geometric structure as developed by Lurie in \cite{LurieDAG5}. Using work of Kock and Pitsch, we compute that the underlying space of the Zariski spectrum of a 2-ring recovers the Balmer spectrum of its homotopy category. These constructions mirror the analogous structures in the classical Zariski geometry of commutative rings (and commutative ring spectra), and we also demonstrate additional compatibility between classical Zariski and higher Zariski geometry. For rigid 2-rings, we show that the descent results of Balmer and Favi admit coherent enhancements. As a corollary, we obtain that the Zariski spectrum fully faithfully embeds rigid 2-rings into locally 2-ringed $\infty$-topoi. In an appendix, we prove a ``stalk-locality principle for the telescope conjecture in the rigid setting, extending earlier work of Hrbek.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3749469" target="_blank">Grab-n-Go: On-the-Go Microgesture Recognition with Objects in Hand</a></h3>
                    <p><strong>Authors:</strong> Chi-Jung Lee, Jiaxin Li, Tianhong Catherine Yu, Ruidong Zhang, Vipin Gunda, FranÃ§ois GuimbretiÃ¨re, Cheng Zhang</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> As computing devices become increasingly integrated into daily life, there is a growing need for intuitive, always-available interaction methods, even when users hands are occupied. In this paper, we introduce Grab-n-Go, the first wearable device that leverages active acoustic sensing to recognize subtle hand microgestures while holding various objects. Unlike prior systems that focus solely on free-hand gestures or basic hand-object activity recognition, Grab-n-Go simultaneously captures information about hand microgestures, grasping poses, and object geometries using a single wristband, enabling the recognition of fine-grained hand movements occurring within activities involving occupied hands. A deep learning framework processes these complex signals to identify 30 distinct microgestures, with 6 microgestures for each of the 5 grasping poses. In a user study with 10 participants and 25 everyday objects, Grab-n-Go achieved an average recognition accuracy of 92.0%. A follow-up study further validated Grab-n-Gos robustness against 10 more challenging, deformable objects. These results underscore the potential of Grab-n-Go to provide seamless, unobtrusive interactions without requiring modifications to existing objects. The complete dataset, comprising data from 18 participants performing 30 microgestures with 35 distinct objects, is publicly available at https://github.com/cjlisalee/Grab-n-Go_Data with the DOI: https://doi.org/10.7298/7kbd-vv75.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11618v1" target="_blank">Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective</a></h3>
                    <p><strong>Authors:</strong> Jungang Chen, Seyyed A. Hosseini</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Carbon capture and storage (CCS) projects typically involve a diverse array of stakeholders or players from public, private, and regulatory sectors, each with different objectives and responsibilities. Given the complexity, scale, and long-term nature of CCS operations, determining whether individual stakeholders can independently maximize their interests or whether collaborative coalition agreements are needed remains a central question for effective CCS project planning and management. CCS projects are often implemented in geologically connected sites, where shared geological features such as pressure space and reservoir pore capacity can lead to competitive behavior among stakeholders. Furthermore, CO2 storage sites are often located in geologically mature basins that previously served as sites for hydrocarbon extraction or wastewater disposal in order to leverage existing infrastructures, which makes unilateral optimization even more complicated and unrealistic. In this work, we propose a paradigm based on Markov games to quantitatively investigate how different coalition structures affect the goals of stakeholders. We frame this multi-stakeholder multi-site problem as a multi-agent reinforcement learning problem with safety constraints. Our approach enables agents to learn optimal strategies while compliant with safety regulations. We present an example where multiple operators are injecting CO2 into their respective project areas in a geologically connected basin. To address the high computational cost of repeated simulations of high-fidelity models, a previously developed surrogate model based on the Embed-to-Control (E2C) framework is employed. Our results demonstrate the effectiveness of the proposed framework in addressing optimal management of CO2 storage when multiple stakeholders with various objectives and goals are involved.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11616v1" target="_blank">Controlling Multimodal LLMs via Reward-guided Decoding</a></h3>
                    <p><strong>Authors:</strong> Oscar MaÃ±as, Pierluca DOro, Koustuv Sinha, Adriana Romero-Soriano, Michal Drozdzal, Aishwarya Agrawal</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> As Multimodal Large Language Models (MLLMs) gain widespread applicability, it is becoming increasingly desirable to adapt them for diverse user needs. In this paper, we study the adaptation of MLLMs through controlled decoding. To achieve this, we introduce the first method for reward-guided decoding of MLLMs and demonstrate its application in improving their visual grounding. Our method involves building reward models for visual grounding and using them to guide the MLLMs decoding process. Concretely, we build two separate reward models to independently control the degree of object precision and recall in the models output. Our approach enables on-the-fly controllability of an MLLMs inference process in two ways: first, by giving control over the relative importance of each reward function during decoding, allowing a user to dynamically trade off object precision for recall in image captioning tasks; second, by giving control over the breadth of the search during decoding, allowing the user to control the trade-off between the amount of test-time compute and the degree of visual grounding. We evaluate our method on standard object hallucination benchmarks, showing that it provides significant controllability over MLLM inference, while consistently outperforming existing hallucination mitigation methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11614v1" target="_blank">Bulk viscous cosmological models with cosmological constant: Observational constraints</a></h3>
                    <p><strong>Authors:</strong> R. NoemÃ­ Villalobos, Yerko VÃ¡squez, Norman Cruz, Carlos H. LÃ³pez-Caraballo</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc</p>
                    <p><strong>Summary:</strong> We investigate whether viscous cold dark matter (vCDM) in a $\Lambda$-dominated FLRW universe can alleviate the Hubble tension while satisfying thermodynamic constraints, examining both flat and curved geometries. We model vCDM with bulk viscosity $\zeta = \zeta_0\,(\Omega_{vc}/\Omega_{vc0})^m$, where $m$ determines the viscosity evolution and $\Omega_{vc}$ is the density parameter of vCDM. We explore two particular scenarios: constant viscosity ($m=0$), and variable viscosity ($m$ free). Using Bayesian inference, we constrain these models with the latest datasets: the Pantheon+ SN Ia sample (both with SH0ES calibration, PPS, and without it, PP), $H(z)$ measurements from CC and BAO as separate datasets, and a Gaussian prior on $H_0$ from 2022 SH0ES baseline, $H_0=73.04 \pm 1.04$ km/s/Mpc (R22 prior). We compare the models via information criteria such as AIC, BIC, DIC, and Bayesian evidence. Our results reveal that the Hubble tension persists, although it shows partial alleviation ($\sim 1\sigma$ tension) in all investigated scenarios when local measurements are included. For the flat $m=0$ case, the joint analysis yields $H_0 = 71.05^{+0.62}_{-0.60}$ km/s/Mpc. Curved model initially favors $\Omega_{K0}  0$ (at more than $2\sigma$), but this preference shifts toward flatness once the PPS+R22 prior are included. Notably, the current viscosity is constrained to $\zeta_0 \sim 10^6$ Pa s in all scenarios, in agreement with the thermodynamic requirements. Although model selection via BIC and Bayesian evidence favors $\Lambda$CDM, AIC and DIC show mild support for viscous models in some datasets. Bulk viscous models moderately improve fits but neither resolve the Hubble tension nor outperform the $\Lambda$CDM model. To achieve more robust constraints, future analyses should incorporate CMB observations, which are expected to break parameter degeneracies involving $m$ and $\tilde{\zeta}_0$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11612v1" target="_blank">Two-Impulse Trajectory Design in Two-Body Systems With Riemannian Geometry</a></h3>
                    <p><strong>Authors:</strong> Samuel G. Gessow, James Tseng, Eden Zafran, Brett T. Lopez</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> This work presents a new method for generating impulsive trajectories in restricted two-body systems by leveraging Riemannian geometry. The proposed method transforms the standard trajectory optimization problem into a purely geometric one that involves computing a set of geodesics for a suitable Riemannian metric. This transformation is achieved by defining a metric, specifically the Jacobi metric, that embeds the dynamics directly into the metric, so any geodesic of the metric is also a dynamically feasible trajectory. The method finds the fuel-optimal transfer trajectory by sampling candidate energy ($\Delta V$) changes for different points on the current and desired orbit, and efficiently computing and evaluating each candidate geodesic, which are equivalent to candidate orbit transfer trajectories via the Jacobi metric. The method bypasses the known issues of optimization-based methods, e.g., sensitivity to the initial guess, and can be applied to more complex two-body systems. The approach is demonstrated on the minimum-$\Delta V$ two-impulse phase-free orbit transfer problem, first on a Keplerian system and second on a system with a modeled $J_2$ perturbation. The proposed method is shown to meet or exceed the state-of-the-art methods in the minimum-$\Delta V$ problem in the Keplerian system. The generality and versatility of the approach is demonstrated by seamlessly including the $J_2$ perturbation, a case that many existing methods cannot handle. Numerical simulations and performance comparisons showcase the effectiveness of the approach.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11611v1" target="_blank">Exponentiable virtual double categories and presheaves for double categories</a></h3>
                    <p><strong>Authors:</strong> Nathanael Arkor</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> math.CT, 18D15, 18D20, 18D60, 18M65, 18N10</p>
                    <p><strong>Summary:</strong> Given a pair of pseudo double categories $\mathbb A$ and $\mathbb B$, the lax functors from $\mathbb A$ to $\mathbb B$, along with their transformations, modules, and multimodulations, assemble into a virtual double category $\mathbf{\mathbb Lax}(\mathbb A, \mathbb B)$. We exhibit a universal property of this construction by observing that it arises naturally from the consideration of exponentiability for virtual double categories. In particular, we show that every pseudo double category is exponentiable as a virtual double category, whereby the virtual double category $\mathbf{\mathbb Lax}(\mathbb A, \mathbb B)$ of lax functors arises as the virtual double category $\mathbf{\mathbb Mod}(\mathbb B^{\mathbb A})$ of monads and modules in the exponential $\mathbb B^{\mathbb A}$. We explore some consequences of this characterisation, demonstrating that it facilitates simple proofs of statements that heretofore required unwieldy computations. For instance, we deduce that the 2-category of pseudo double categories and lax functors is enriched in the 2-category of normal virtual double categories, and demonstrate that several aspects of the Yoneda theory of pseudo double categories - such as the correspondence between presheaves and discrete fibrations - are substantially simplified by this perspective.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11610v1" target="_blank">Quantum Simulation of Collective Neutrino Oscillations in Dense Neutrino Environment</a></h3>
                    <p><strong>Authors:</strong> Shvetaank Tripathi, Sandeep Joshi, Garima Rajpoot, Prashant Shukla</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> quant-ph, hep-ph, nucl-th</p>
                    <p><strong>Summary:</strong> Inside dense neutrino gases, such as neutron star mergers or core-collapse supernovae, collective neutrino effects cause the transformation of one neutrino flavour into another. Due to strong neutrino self-interactions in these environments, there is prevalence of flavour swapping. Considering these environments to be isotropic and homogeneous, we present a study of collective neutrino oscillations by simulating such a system on a noisy quantum simulator (Qiskit AerSimulator) and a quantum processor (ibm\_brisbane). We model the effective Hamiltonian governing neutrino interactions and by applying the Trotter-Suzuki approximation, decompose it into a tractable form suitable for quantum circuit implementation of the time-evolution propagator. Encoding the neutrino state for a system of two- and three-neutrinos onto qubits, we compute the time evolution of the inversion probability relative to the initial product state. Furthermore, we present quantum circuits to evaluate the concurrence as a measure of entanglement between the neutrinos.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11608v1" target="_blank">A multigrid method for CutFEM and its implementation on GPU</a></h3>
                    <p><strong>Authors:</strong> Cu Cui, Guido Kanschat</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA, 65N55, 65Y05, 65Y10</p>
                    <p><strong>Summary:</strong> We present a multigrid method for an unfitted finite element discretization of the Dirichlet boundary value problem. The discretization employs Nitsches method to implement the boundary condition and additional face based ghost penalties for stabilization. We apply standard intergrid operators, relying on the fact that the relevant domain of computation does not grow under mesh refinement. The smoother is a parallel implementation of the multiplicative vertex-patch smoother with inconsistent treatment of ghost penalties. Our computational results show that we obtain a fast converging method. Furthermore, runtime comparison to fitted methods show that the losses are moderate although many optimizations for Cartesian vertex patches cannot be applied on cut patches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11607v1" target="_blank">TinyTim: A Family of Language Models for Divergent Generation</a></h3>
                    <p><strong>Authors:</strong> Christopher J. Agostino</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This work introduces TinyTim, a family of large language models fine-tuned on James Joyces `Finnegans Wake. Through quantitative evaluation against baseline models, we demonstrate that TinyTim V1 produces a statistically distinct generative profile characterized by high lexical diversity and low semantic coherence. These findings are interpreted through theories of creativity and complex problem-solving, arguing that such specialized models can function as divergent knowledge sources within more extensive creative architectures, powering automated discovery mechanisms in diverse settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11606v1" target="_blank">Dependence of the recoherence times and recoherence increments on the state of phonon bath in a single qubit dephasing model</a></h3>
                    <p><strong>Authors:</strong> V. V. Ignatyuk, Ch. Samorodov</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> The recoherence times $t^*$ and the maximum values of the recoherence increments $\gamma_{\rm extr}$ are studied as functions of the bath parameters for a single qubit dephasing model, prepared initially by a special kind of the non-selective measurements. The recoherence/decoherence events (RDE), occurring at the initial stage of the system evolution, are found to be both similar and different from the system dynamics at large times. For instance, in contrast to the RDE observed on large time scales, the sub-Ohmic and Ohmic coupling regimes are more favourable for the short-time recoherence than the super-Ohmic one. On the other hand, the short-time behaviour of the recoherence and the long-time dynamics of the decoherence are closely related: the domain of the ohmicity indexes, where the decoherence changes its type (from the complete to incomplete one), is, simultaneously, that of the weakest recoherence. The obtained results give us some hints about the basic characteristics of the environment, which might provide the most optimal values of $t^*$ and $\gamma_{\rm extr}$ in some sense.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11605v1" target="_blank">Dataset Creation for Visual Entailment using Generative AI</a></h3>
                    <p><strong>Authors:</strong> Rob Reijtenbach, Suzan Verberne, Gijs Wijnholds</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> In this paper we present and validate a new synthetic dataset for training visual entailment models. Existing datasets for visual entailment are small and sparse compared to datasets for textual entailment. Manually creating datasets is labor-intensive. We base our synthetic dataset on the SNLI dataset for textual entailment. We take the premise text from SNLI as input prompts in a generative image model, Stable Diffusion, creating an image to replace each textual premise. We evaluate our dataset both intrinsically and extrinsically. For extrinsic evaluation, we evaluate the validity of the generated images by using them as training data for a visual entailment classifier based on CLIP feature vectors. We find that synthetic training data only leads to a slight drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when trained on real data. We also compare the quality of our generated training data to original training data on another dataset: SICK-VTE. Again, there is only a slight drop in F-score: from 0.400 to 0.384. These results indicate that in settings with data sparsity, synthetic data can be a promising solution for training visual entailment models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11603v1" target="_blank">CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion</a></h3>
                    <p><strong>Authors:</strong> Zhe Zhu, Honghua Chen, Peng Li, Mingqiang Wei</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-driven 3D editing seeks to modify 3D scenes according to textual descriptions, and most existing approaches tackle this by adapting pre-trained 2D image editors to multi-view inputs. However, without explicit control over multi-view information exchange, they often fail to maintain cross-view consistency, leading to insufficient edits and blurry details. We introduce CoreEditor, a novel framework for consistent text-to-3D editing. The key innovation is a correspondence-constrained attention mechanism that enforces precise interactions between pixels expected to remain consistent throughout the diffusion denoising process. Beyond relying solely on geometric alignment, we further incorporate semantic similarity estimated during denoising, enabling more reliable correspondence modeling and robust multi-view editing. In addition, we design a selective editing pipeline that allows users to choose preferred results from multiple candidates, offering greater flexibility and user control. Extensive experiments show that CoreEditor produces high-quality, 3D-consistent edits with sharper details, significantly outperforming prior methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11601v1" target="_blank">A non-Hermitian Su-Schrieffer-Heeger model with the energy levels of free parafermions</a></h3>
                    <p><strong>Authors:</strong> Edward McCann</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.str-el, quant-ph</p>
                    <p><strong>Summary:</strong> Using a parent Hermitian tight-binding model on a bipartite lattice with chiral symmetry, we theoretically generate non-Hermitian models for free fermions with $p$ orbitals per unit cell satisfying a complex generalization of chiral symmetry. The $p$ complex energy bands in $k$ space are given by a common $k$-dependent real factor, determined by the bands of the parent model, multiplied by the $p$th roots of unity. When the parent model is the Su-Schrieffer-Heeger (SSH) model, the single-particle energy levels are the same as those of free parafermion solutions to Baxters non-Hermitian clock model. This construction relies on fully unidirectional hopping to create Bloch Hamiltonians with the form of generalized permutation matrices, but we also describe the effect of partial unidirectional hopping. For fully bidirectional hopping, the Bloch Hamiltonians are Hermitian and may be separated into even and odd parity blocks with respect to inversion of the orbitals within the unit cell. Partially unidirectional hopping breaks the inversion symmetry and mixes the even and odd blocks, and the real energy spectrum evolves into a complex one as the degree of unidirectionality increases, with details determined by the topology of the parent model and the number of orbitals per unit cell, $p$. We describe this process in detail for $p=3$ and $p=4$ with the SSH model. We also apply our approach to graphene, and show that $AA$-stacked bilayer graphene evolves into a square root Hamiltonian of monolayer graphene with the introduction of unidirectional hopping. We show that higher-order exceptional points occur at edge states and solitons in the non-Hermitian SSH model, and at the Dirac point of non-Hermitian graphene.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11598v1" target="_blank">Representing Speech Through Autoregressive Prediction of Cochlear Tokens</a></h3>
                    <p><strong>Authors:</strong> Greta Tuckute, Klemen Kotar, Evelina Fedorenko, Daniel L. K. Yamins</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.SD, eess.AS</p>
                    <p><strong>Summary:</strong> We introduce AuriStream, a biologically inspired model for encoding speech via a two-stage framework inspired by the human auditory processing hierarchy. The first stage transforms raw audio into a time-frequency representation based on the human cochlea, from which we extract discrete \textbf{cochlear tokens}. The second stage applies an autoregressive sequence model over the cochlear tokens. AuriStream learns meaningful phoneme and word representations, and state-of-the-art lexical semantics. AuriStream shows competitive performance on diverse downstream SUPERB speech tasks. Complementing AuriStreams strong representational capabilities, it generates continuations of audio which can be visualized in a spectrogram space and decoded back into audio, providing insights into the models predictions. In summary, we present a two-stage framework for speech representation learning to advance the development of more human-like models that efficiently handle a range of speech-based tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11596v1" target="_blank">Breaking the Strings: the signatures of Cosmic String Loop Fragmentation</a></h3>
                    <p><strong>Authors:</strong> Pierre Auclair</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, gr-qc</p>
                    <p><strong>Summary:</strong> We study the impact of fragmentation on the cosmic string loop number density, using an approach inspired by the three-scale model and a Boltzmann equation. We build a new formulation designed to be more amenable to numerical resolution and present two complementary numerical methods to obtain the full loop distribution including the effect of fragmentation and gravitational radiation. We show that fragmentation generically predicts a decay of the loop number density on large scales and a deviation from a pure power-law. We expect fragmentation to be crucial for the calibration of loop distribution models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11594v1" target="_blank">Its not a FAD: first results in using Flows for unsupervised Anomaly Detection at 40 MHz at the Large Hadron Collider</a></h3>
                    <p><strong>Authors:</strong> Francesco Vaselli, Maurizio Pierini, Maciej Mikolaj Glowacki, Thea Aarrestad, Katya Govorkova, Vladimir Loncar, Dimitrios Danopoulos, Felice Pantaleo</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> hep-ex, physics.comp-ph</p>
                    <p><strong>Summary:</strong> We present the first implementation of a Continuous Normalizing Flow (CNF) model for unsupervised anomaly detection within the realistic, high-rate environment of the Large Hadron Colliders L1 trigger systems. While CNFs typically define an anomaly score via a probabilistic likelihood, calculating this score requires solving an Ordinary Differential Equation, a procedure too complex for FPGA deployment. To overcome this, we propose a novel, hardware-friendly anomaly score defined as the squared norm of the models vector field output. This score is based on the intuition that anomalous events require a larger transformation by the flow. Our model, trained via Flow Matching on Standard Model-like data, is synthesized for an FPGA using the hls4ml library. We demonstrate that our approach effectively identifies a variety of beyond-the-Standard-Model signatures with performance comparable to existing machine learning-based triggers. The algorithm achieves a latency of a few hundred nanoseconds and requires minimal FPGA resources, establishing CNFs as a viable new tool for real-time, data-driven discovery at 40 MHz.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11592v1" target="_blank">Holography at Finite N: Breakdown of Bulk Reconstruction for Subregions</a></h3>
                    <p><strong>Authors:</strong> Seiji Terashima</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> hep-th</p>
                    <p><strong>Summary:</strong> Within AdS/CFT, focusing on the AdS-Rindler wedge, we show that when $N$ is large but finite, correlation functions of reconstructed bulk operators grow exponentially with bulk momentum, overwhelming the usual $1/N$ suppression. The growth starts when the smeared operators ultraviolet scale goes beyond a critical value $\Lambda_{crit} = \frac{2}{\pi}\ln N$, which is far below the Planck scale. Above this logarithmic threshold, the large $N$ expansion ceases to be reliable, and the would-be bulk operators cannot be consistently defined as observables in the full quantum gravity theory. Since the AdS-Rindler wedge describes the near-horizon region of black holes, this result implies a sharp $\ln N$ cutoff for reconstructing bulk operators across horizons. This has a direct impact on whether and how information from the black hole interior is encoded-a central question in the black hole information paradox.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.11591v1" target="_blank">DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring</a></h3>
                    <p><strong>Authors:</strong> Durga Joshi, Chandi Witharana, Robert Fahey, Thomas Worthley, Zhe Zhu, Diego Cerrai</p>
                    <p><strong>Published:</strong> 8/15/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.ET</p>
                    <p><strong>Summary:</strong> Our study introduces a novel, low-cost, and reproducible framework for real-time, object-level structural assessment and geolocation of roadside vegetation and infrastructure with commonly available but underutilized dashboard camera (dashcam) video data. We developed an end-to-end pipeline that combines monocular depth estimation, depth error correction, and geometric triangulation to generate accurate spatial and structural data from street-level video streams from vehicle-mounted dashcams. Depth maps were first estimated using a state-of-the-art monocular depth model, then refined via a gradient-boosted regression framework to correct underestimations, particularly for distant objects. The depth correction model achieved strong predictive performance (R2 = 0.92, MAE = 0.31 on transformed scale), significantly reducing bias beyond 15 m. Further, object locations were estimated using GPS-based triangulation, while object heights were calculated using pin hole camera geometry. Our method was evaluated under varying conditions of camera placement and vehicle speed. Low-speed vehicle with inside camera gave the highest accuracy, with mean geolocation error of 2.83 m, and mean absolute error (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. To the best of our knowledge, it is the first framework to combine monocular depth modeling, triangulated GPS-based geolocation, and real-time structural assessment for urban vegetation and infrastructure using consumer-grade video data. Our approach complements conventional RS methods, such as LiDAR and image by offering a fast, real-time, and cost-effective solution for object-level monitoring of vegetation risks and infrastructure exposure, making it especially valuable for utility companies, and urban planners aiming for scalable and frequent assessments in dynamic urban environments.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

