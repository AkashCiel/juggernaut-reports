
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-08-28<br>
            <strong>Topics:</strong> ai safety research, ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 60
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <p>## ai safety research

Certainly! Here is a high-level summary of the provided research papers, structured into trends, breakthroughs, and implications specific to AI safety research:

### Most Important Trends
1. **AI Interoperability and Integration**: There is a strong trend towards creating unified frameworks and protocols to integrate diverse AI systems, as seen in adaptive transport systems and federated learning models. These efforts aim to enhance semantic interoperability and address fragmentation issues.
2. **Human-AI Interaction**: Several studies focus on improving human-AI interfaces, whether through generative interfaces for language models or through frameworks for smarter interaction in clinical settings. This trend highlights the importance of making AI systems more accessible and user-friendly.
3. **Robustness and Safety**: There is a significant emphasis on assessing and improving AI robustness, especially in safety-critical applications like automated vehicles and healthcare. This includes developing new metrics and frameworks for evaluating AI reliability and safety.

### Breakthroughs
1. **Unified Frameworks for AI Tasks**: The development of frameworks like MATRIX for clinical dialogue systems and SuperSimpleNet for surface defect detection represent significant advances in creating systems that can handle diverse data and scenarios while maintaining high performance and safety.
2. **Innovative AI Models and Methodologies**: The introduction of models like StepWiser for reasoning and APT-LLM for accelerating language models demonstrates breakthroughs in improving the efficiency and accuracy of AI systems. These innovations help mitigate issues like high computational demands and enhance AI reasoning capabilities.
3. **Generative AI in Practical Applications**: Systems like ZeST for navigation and generative interfaces for map-making reflect breakthroughs in applying generative AI to real-world problems, enhancing the safety and practicality of AI applications.

### Implications
1. **Enhanced AI Safety and Reliability**: The focus on robust control barrier functions and probabilistic robustness measures suggests that future AI systems will be more reliable and safer, particularly in environments where safety is critical, such as healthcare and autonomous vehicles.
2. **Improved User Experience and Trust**: By developing more responsive and intuitive AI interfaces, users can engage more effectively with AI systems, increasing trust and adoption of AI technologies in everyday applications.
3. **Broader Adoption of AI Technologies**: As AI systems become more robust and user-friendly, their adoption in various fields, from healthcare to transportation, will likely increase. This broad adoption will require ongoing research into AI safety and ethical considerations to ensure these technologies are used responsibly and beneficially.

In conclusion, these papers collectively highlight the importance of integrating safety, robustness, and usability into AI systems. They underscore the ongoing need for research and innovation to ensure AI technologies are developed and deployed safely, benefiting both individuals and society as a whole.

*Based on 50 research papers*

---

## ai alignment research

### Most Important Trends
1. **Benchmarking and Standardization**: Style4D-Bench underscores a growing trend towards creating standardized benchmarks for emerging AI research areas, such as 4D stylization. This trend facilitates consistent evaluation and comparison of new methods, promoting progress in the field.
   
2. **Zero-Shot and Training-Free Approaches**: Articulate3D highlights a shift towards developing AI methods that do not require extensive training data, exemplified by its zero-shot text-driven 3D object posing technique. This trend is significant as it reduces resource requirements and increases accessibility.

3. **Unified Protocols in Adaptive Systems**: The survey on Model Context Protocols indicates a trend towards unifying fragmented adaptive systems through standardized protocols, particularly in transport systems, which enhances interoperability and context-aware decision-making.

4. **Casual Gaming Insights**: Research on casual gaming performance evaluation reflects a trend in exploring non-competitive contexts to gain insights different from those obtained in competitive environments, broadening the understanding of player behavior and evaluation.

5. **Generative Reasoning Models**: StepWiser exemplifies a trend towards developing models that not only make decisions but also generate reasoning for their decisions, moving beyond simple classification to more nuanced, explanation-based AI systems.

### Breakthroughs
1. **4D Stylization Benchmark**: Style4D-Bench provides a comprehensive benchmark for 4D stylization, introducing novel evaluation protocols and a strong baseline framework (Style4D) that achieves state-of-the-art results in maintaining spatio-temporal consistency and stylistic fidelity.

2. **Language-Controlled 3D Posing**: Articulate3D introduces a novel method for posing 3D objects using natural language instructions without prior training, utilizing a self-attention rewiring mechanism to maintain object identity across poses.

3. **Model Context Protocol Framework**: The survey identifies and categorizes efforts towards Model Context Protocols as a unifying architecture for adaptive transport systems, highlighting its potential as a foundational paradigm for future intelligent transport infrastructures.

4. **Insights into Casual Gaming**: The study on casual gaming reveals that players evaluate teammates through relative comparison rather than absolute metrics, challenging existing frameworks derived from competitive gaming and suggesting new directions for casual game design and evaluation.

5. **Stepwise Generative Judges**: StepWiser represents a breakthrough in reasoning, employing a generative approach to evaluate intermediate steps in multi-step reasoning tasks, demonstrating improved accuracy and the ability to refine policy models both during training and inference.

### Implications
1. **Advancement in 4D Graphics**: The introduction of Style4D-Bench is poised to accelerate advancements in 4D graphics, enabling more realistic and consistent rendering in dynamic scenes, with potential applications in gaming, film, and virtual reality.

2. **Enhanced AI Accessibility**: Articulate3Ds approach could democratize AI tools by reducing the need for large datasets and training, making sophisticated 3D manipulation more accessible to developers and artists.

3. **Interoperability in Transport Systems**: The Model Context Protocol framework could significantly enhance interoperability and efficiency in adaptive transport systems, paving the way for more seamless integration of AI-driven transport solutions.

4. **Revisiting Game Design**: The findings from casual gaming research could lead to the development of new performance evaluation systems in games, focusing on relative performance and player satisfaction rather than traditional competitive metrics.

5. **Improved AI Decision-Making**: StepWisers generative reasoning approach could lead to more transparent and trustworthy AI systems, as it not only enhances decision accuracy but also provides insights into the reasoning process, fostering better human-AI interaction.

*Based on 5 research papers*

---

## quantum computing

Certainly! Here is a high-level summary of the provided research papers with a focus on trends, breakthroughs, and implications in the context of quantum computing:

### Most Important Trends
1. **Quantum Spin Systems and Disorder Effects**: The study on Pr$_2$Sn$_2$O$_7$ highlights ongoing interest in understanding quantum spin ice systems and how disorder can influence quantum phases. This trend reflects a broader effort to explore complex quantum states that could have implications for quantum information storage or processing.

2. **Advancements in Quantum Error Correction**: The development of new quantum error-correcting codes indicates a significant trend towards enhancing the reliability and efficiency of quantum computing systems. This is crucial for scaling quantum computers to practical sizes.

3. **Cross-disciplinary Innovations**: Papers like VoxHammer, Style4D-Bench, and Articulate3D, while not directly related to quantum computing, illustrate a growing trend of leveraging advanced computational techniques (e.g., AI, 3D modeling) that could eventually intersect with quantum technologies for enhanced data processing and modeling.

### Breakthroughs
1. **Identification of Quantum Spin Ice Phase**: The breakthrough in identifying a disorder-induced quantum spin ice phase in Pr$_2$Sn$_2$O$_7$ offers a new perspective on how quantum spin liquids can be manipulated, potentially leading to novel states that could be harnessed in quantum computing.

2. **Novel Quantum Error-Correcting Codes**: The creation of a new family of quantum error-correcting codes using topological concepts represents a significant breakthrough. These codes are designed to improve logical error rates and can be tailored to various hardware configurations, promising more robust quantum computing systems.

3. **3D Editing and Stylization Techniques**: Despite being outside traditional quantum computing, advances like VoxHammer and Style4D-Bench demonstrate cutting-edge techniques in precise 3D editing and stylization. These innovations could inspire new ways of visualizing and simulating quantum phenomena in three dimensions.

### Implications
1. **Enhanced Quantum Material Understanding**: The insights from studying Pr$_2$Sn$_2$O$_7$ contribute to a deeper understanding of quantum materials, potentially aiding in the development of new materials for quantum technologies.

2. **Improved Quantum Computing Reliability**: The new quantum error-correcting codes could lead to more reliable quantum computers by reducing error rates, which is essential for performing complex calculations and ensuring the fidelity of quantum information.

3. **Potential for Interdisciplinary Applications**: Techniques from computational models and AI, as seen in VoxHammer and Articulate3D, could eventually integrate with quantum computing for applications such as enhanced simulation capabilities, modeling of quantum systems, and improved human-computer interaction interfaces.

Overall, these research papers collectively highlight the dynamic advancements in quantum computing and related fields, showcasing how cross-disciplinary approaches are driving innovation and paving the way for practical applications of quantum technologies.

*Based on 5 research papers*</p>
            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2508.19243v1" target="_blank">Style4D-Bench: A Benchmark Suite for 4D Stylization</a></h3>
                    <p><strong>Authors:</strong> Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, 2) a strong baseline that make an initial attempt for 4D stylization, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes. Project page: https://becky-catherine.github.io/Style4D . Code: https://github.com/Becky-catherine/Style4D-Bench .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19239v1" target="_blank">Model Context Protocols in Adaptive Transport Systems: A Survey</a></h3>
                    <p><strong>Authors:</strong> Gaurab Chhetri, Shriyank Somvanshi, Md Monzurul Islam, Shamyo Brotee, Mahmuda Sultana Mimi, Dipti Koirala, Biplov Pandey, Subasish Das</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The rapid expansion of interconnected devices, autonomous systems, and AI applications has created severe fragmentation in adaptive transport systems, where diverse protocols and context sources remain isolated. This survey provides the first systematic investigation of the Model Context Protocol (MCP) as a unifying paradigm, highlighting its ability to bridge protocol-level adaptation with context-aware decision making. Analyzing established literature, we show that existing efforts have implicitly converged toward MCP-like architectures, signaling a natural evolution from fragmented solutions to standardized integration frameworks. We propose a five-category taxonomy covering adaptive mechanisms, context-aware frameworks, unification models, integration strategies, and MCP-enabled architectures. Our findings reveal three key insights: traditional transport protocols have reached the limits of isolated adaptation, MCPs client-server and JSON-RPC structure enables semantic interoperability, and AI-driven transport demands integration paradigms uniquely suited to MCP. Finally, we present a research roadmap positioning MCP as a foundation for next-generation adaptive, context-aware, and intelligent transport infrastructures.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3744736.3749343" target="_blank">Beyond Competitive Gaming: How Casual Players Evaluate and Respond to Teammate Performance</a></h3>
                    <p><strong>Authors:</strong> Kaushall Senthil Nathan, Jieun Lee, Derrick M. Wang, Geneva M. Smith, Eugene Kukshinov, Daniel Harley, Lennart E. Nacke</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Teammate performance evaluation fundamentally shapes intervention design in video games. However, our current understanding stems primarily from competitive E-Sports contexts where individual performance directly impacts outcomes. This research addresses whether performance evaluation mechanisms and behavioural responses identified in competitive games generalize to casual cooperative games. We investigated how casual players evaluate teammate competence and respond behaviourally in a controlled between-subjects experiment (N=23). We manipulated confederate performance in Overcooked 2, combining observations, NASA TLX self-reports, and interviews. We present two key findings. (1) Observations revealed frustration behaviours completely absent in self-report data. Thus, these instruments assess fundamentally distinct constructs. (2) Participants consistently evaluated teammate performance through relative comparison rather than absolute metrics. This contradicts task-performance operationalizations dominant in competitive gaming research. Hence, performance evaluation frameworks from competitive contexts cannot be directly applied to casual cooperative games. We provide empirical evidence that performance evaluation in casual games requires a comparative operationalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19229v2" target="_blank">StepWiser: Stepwise Generative Judges for Wiser Reasoning</a></h3>
                    <p><strong>Authors:</strong> Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As models increasingly leverage multi-step reasoning strategies to solve complex problems, supervising the logical validity of these intermediate steps has become a critical research challenge. Process reward models address this by providing step-by-step feedback, but current approaches have two major drawbacks: they typically function as classifiers without providing explanations, and their reliance on supervised fine-tuning with static datasets limits generalization. Inspired by recent advances, we reframe stepwise reward modeling from a classification task to a reasoning task itself. We thus propose a generative judge that reasons about the policy models reasoning steps (i.e., meta-reasons), outputting thinking tokens before delivering a final verdict. Our model, StepWiser, is trained by reinforcement learning using relative outcomes of rollouts. We show it provides (i) better judgment accuracy on intermediate steps than existing methods; (ii) can be used to improve the policy model at training time; and (iii) improves inference-time search.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19227v1" target="_blank">Generative Interfaces for Language Models</a></h3>
                    <p><strong>Authors:</strong> Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn, information-dense, and exploratory tasks. To address these limitations, we propose Generative Interfaces for Language Models, a paradigm in which LLMs respond to user queries by proactively generating user interfaces (UIs) that enable more adaptive and interactive engagement. Our framework leverages structured interface-specific representations and iterative refinements to translate user queries into task-specific UIs. For systematic evaluation, we introduce a multidimensional assessment framework that compares generative interfaces with traditional chat-based ones across diverse tasks, interaction patterns, and query types, capturing functional, interactive, and emotional aspects of user experience. Results show that generative interfaces consistently outperform conversational ones, with humans preferring them in over 70% of cases. These findings clarify when and why users favor generative interfaces, paving the way for future advancements in human-AI interaction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19200v1" target="_blank">The Ramon Llulls Thinking Machine for Automated Ideation</a></h3>
                    <p><strong>Authors:</strong> Xinran Zhao, Boyuan Zheng, Chenglei Si, Haofei Yu, Ken Liu, Runlong Zhou, Ruochen Li, Tong Chen, Xiang Li, Yiming Zhang, Tongshuang Wu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> This paper revisits Ramon Llulls Ars combinatoria - a medieval framework for generating knowledge through symbolic recombination - as a conceptual foundation for building a modern Llulls thinking machine for research ideation. Our approach defines three compositional axes: Theme (e.g., efficiency, adaptivity), Domain (e.g., question answering, machine translation), and Method (e.g., adversarial training, linear attention). These elements represent high-level abstractions common in scientific work - motivations, problem settings, and technical approaches - and serve as building blocks for LLM-driven exploration. We mine elements from human experts or conference papers and show that prompting LLMs with curated combinations produces research ideas that are diverse, relevant, and grounded in current literature. This modern thinking machine offers a lightweight, interpretable tool for augmenting scientific creativity and suggests a path toward collaborative ideation between humans and AI.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.2139/ssrn.5006698" target="_blank">Profit-Aware Graph Framework for Cross-Platform Ride-Sharing: Analyzing Allocation Mechanisms and Efficiency Gains</a></h3>
                    <p><strong>Authors:</strong> Xin Dong, Jose Ventura, Vikash V. Gayah</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> econ.GN, q-fin.EC</p>
                    <p><strong>Summary:</strong> Ride-hailing platforms (e.g., Uber, Lyft) have transformed urban mobility by enabling ride-sharing, which holds considerable promise for reducing both travel costs and total vehicle miles traveled (VMT). However, the fragmentation of these platforms impedes system-wide efficiency by restricting ride-matching to intra-platform requests. Cross-platform collaboration could unlock substantial efficiency gains, but its realization hinges on fair and sustainable profit allocation mechanisms that can align the incentives of competing platforms. This study introduces a graph-theoretic framework that embeds profit-aware constraints into network optimization, facilitating equitable and efficient cross-platform ride-sharing. Within this framework, we evaluate three allocation schemes -- equal-profit-based, market-share-based, and Shapley-value-based -- through large-scale simulations. Results show that the Shapley-value-based mechanism consistently outperforms the alternatives across six key metrics. Notably, system efficiency and rider service quality improve with increasing demand, reflecting clear economies of scale. The observed economies of scale, along with their diminishing returns, can be understood with the structural evolution of rider-request graphs, where super-linear edge growth expands feasible matches and sub-linear degree scaling limits per-rider connectivity.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3746252.3761039" target="_blank">Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness</a></h3>
                    <p><strong>Authors:</strong> Wenchuan Mu, Kwan Hui Lim</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> In safety-critical deep learning applications, robustness measures the ability of neural models that handle imperceptible perturbations in input data, which may lead to potential safety hazards. Existing pre-deployment robustness assessment methods typically suffer from significant trade-offs between computational cost and measurement precision, limiting their practical utility. To address these limitations, this paper conducts a comprehensive comparative analysis of existing robustness definitions and associated assessment methodologies. We propose tower robustness to evaluate robustness, which is a novel, practical metric based on hypothesis testing to quantitatively evaluate probabilistic robustness, enabling more rigorous and efficient pre-deployment assessments. Our extensive comparative evaluation illustrates the advantages and applicability of our proposed approach, thereby advancing the systematic understanding and enhancement of model robustness in safety-critical deep learning applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19182v1" target="_blank">SoccerNet 2025 Challenges Results</a></h3>
                    <p><strong>Authors:</strong> Silvio Giancola, Anthony Cioppa, Marc GutiÃ©rrez-PÃ©rez, Jan Held, Carlos Hinojosa, Victor Joos, Arnaud Leduc, Floriane Magera, Karen Sanchez, Vladimir Somers, Artur Xarles, Antonio Agudo, Alexandre Alahi, Olivier Barnich, Albert ClapÃ©s, Christophe De Vleeschouwer, Sergio Escalera, Bernard Ghanem, Thomas B. Moeslund, Marc Van Droogenbroeck, Tomoki Abe, Saad Alotaibi, Faisal Altawijri, Steven Araujo, Xiang Bai, Xiaoyang Bi, Jiawang Cao, Vanyi Chao, Kamil CzarnogÃ³rski, Fabian Deuser, Mingyang Du, Tianrui Feng, Patrick Frenzel, Mirco Fuchs, Jorge GarcÃ­a, Konrad Habel, Takaya Hashiguchi, Sadao Hirose, Xinting Hu, Yewon Hwang, Ririko Inoue, Riku Itsuji, Kazuto Iwai, Hongwei Ji, Yangguang Ji, Licheng Jiao, Yuto Kageyama, Yuta Kamikawa, Yuuki Kanasugi, Hyungjung Kim, Jinwook Kim, Takuya Kurihara, Bozheng Li, Lingling Li, Xian Li, Youxing Lian, Dingkang Liang, Hongkai Lin, Jiadong Lin, Jian Liu, Liang Liu, Shuaikun Liu, Zhaohong Liu, Yi Lu, Federico MÃ©ndez, Huadong Ma, Wenping Ma, Jacek Maksymiuk, Henry Mantilla, Ismail Mathkour, Daniel Matthes, Ayaha Motomochi, Amrulloh Robbani Muhammad, Haruto Nakayama, Joohyung Oh, Yin May Oo, Marcelo Ortega, Norbert Oswald, Rintaro Otsubo, Fabian Perez, Mengshi Qi, Cristian Rey, Abel Reyes-Angulo, Oliver Rose, Hoover Rueda-ChacÃ³n, Hideo Saito, Jose Sarmiento, Kanta Sawafuji, Atom Scott, Xi Shen, Pragyan Shrestha, Jae-Young Sim, Long Sun, Yuyang Sun, Tomohiro Suzuki, Licheng Tang, Masato Tonouchi, Ikuma Uchida, Henry O. Velesaca, Tiancheng Wang, Rio Watanabe, Jay Wu, Yongliang Wu, Shunzo Yamagishi, Di Yang, Xu Yang, Yuxin Yang, Hao Ye, Xinyu Ye, Calvin Yeung, Xuanlong Yu, Chao Zhang, Dingyuan Zhang, Kexing Zhang, Zhe Zhao, Xin Zhou, Wenbo Zhu, Julian Ziegler</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This years challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, targeting the recovery of scene geometry from single-camera broadcast clips through relative depth estimation for each pixel; (3) Multi-View Foul Recognition, requiring the analysis of multiple synchronized camera views to classify fouls and their severity; and (4) Game State Reconstruction, aimed at localizing and identifying all players from a broadcast video to reconstruct the game state on a 2D top-view of the field. Across all tasks, participants were provided with large-scale annotated datasets, unified evaluation protocols, and strong baselines as starting points. This report presents the results of each challenge, highlights the top-performing solutions, and provides insights into the progress made by the community. The SoccerNet Challenges continue to serve as a driving force for reproducible, open research at the intersection of computer vision, artificial intelligence, and sports. Detailed information about the tasks, challenges, and leaderboards can be found at https://www.soccer-net.org, with baselines and development kits available at https://github.com/SoccerNet.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19173v1" target="_blank">Leveraging Evolutionary Surrogate-Assisted Prescription in Multi-Objective Chlorination Control Systems</a></h3>
                    <p><strong>Authors:</strong> Rivaaj Monsia, Olivier Francon, Daniel Young, Risto Miikkulainen</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.NE, cs.LG</p>
                    <p><strong>Summary:</strong> This short, written report introduces the idea of Evolutionary Surrogate-Assisted Prescription (ESP) and presents preliminary results on its potential use in training real-world agents as a part of the 1st AI for Drinking Water Chlorination Challenge at IJCAI-2025. This work was done by a team from Project Resilience, an organization interested in bridging AI to real-world problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19172v2" target="_blank">From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity</a></h3>
                    <p><strong>Authors:</strong> Luca Grillotti, Lisa Coiffard, Oscar Pang, Maxence Faldor, Antoine Cully</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Autonomous skill discovery aims to enable robots to acquire diverse behaviors without explicit supervision. Learning such behaviors directly on physical hardware remains challenging due to safety and data efficiency constraints. Existing methods, including Quality-Diversity Actor-Critic (QDAC), require manually defined skill spaces and carefully tuned heuristics, limiting real-world applicability. We propose Unsupervised Real-world Skill Acquisition (URSA), an extension of QDAC that enables robots to autonomously discover and master diverse, high-performing skills directly in the real world. We demonstrate that URSA successfully discovers diverse locomotion skills on a Unitree A1 quadruped in both simulation and the real world. Our approach supports both heuristic-driven skill discovery and fully unsupervised settings. We also show that the learned skill repertoire can be reused for downstream tasks such as real-world damage adaptation, where URSA outperforms all baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios. Our results establish a new framework for real-world robot learning that enables continuous skill discovery with limited human intervention, representing a significant step toward more autonomous and adaptable robotic systems. Demonstration videos are available at https://adaptive-intelligent-robotics.github.io/URSA.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19170v1" target="_blank">Stellar Mass Assembly History of Massive Quiescent Galaxies since $z\sim4$: Insights from Spatially Resolved SED Fitting with JWST Data</a></h3>
                    <p><strong>Authors:</strong> Novan Saputra Haryana, Masayuki Akiyama, Abdurrouf, Hesti Retno Tri Wulandari, Juan Pablo Alfonzo, Kianhong Lee, Naoki Matsumoto, Ryo Albert Sutanto, Muhammad Nur Ihsan Effendi, Itsna Khoirul Fitriana, Ibnu Nurul Huda, Anton Timur Jaelani, Sultan Hadi Kusuma, Lucky Puspitarini, Dian Puspita Triani</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> Massive quiescent galaxies at high redshift show significantly more compact morphology than their local counterparts. To examine their internal structure across a wide redshift range and investigate potential redshift dependence, we performed spatially resolved SED fitting using pixedfit software on massive $(\log(M_*/M_\odot)\sim11)$ quiescent galaxies at $0 4$ kpc), while the central regions ($r \sim 1$ kpc) remain largely unchanged, with stellar mass surface density similar to local quiescent galaxies. The estimated star formation rates are too low to explain the stellar mass growth, indicating an additional stellar mass accumulation process, such as mergers, is necessary. We parameterize the size-mass relation of the most massive galaxies in our sample as $\log(R_{e,mass}) \propto \alpha \log(M_*)$, and find $\alpha = 2.67^{+1.14}_{-1.17}$ for $z\lessapprox2$, consistent with growth dominated by minor mergers, and $\alpha = 0.91^{+0.20}_{-0.16}$ for $z\gtrapprox2$, consistent with growth dominated by major mergers. These results indicate that massive quiescent galaxies originate from compact quenched systems and grow through combinations of minor and major mergers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19163v1" target="_blank">MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation</a></h3>
                    <p><strong>Authors:</strong> Ernest Lim, Yajie Vera He, Jared Joselowitz, Kate Preston, Mohita Chowdhury, Louis Williams, Aisling Higham, Katrina Mason, Mariane Melo, Tom Lawton, Yan Jia, Ibrahim Habli</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.HC, cs.MA, 68T50, 68T42, 92C50, 68Q60, I.2.0; J.3</p>
                    <p><strong>Summary:</strong> Despite the growing use of large language models (LLMs) in clinical dialogue systems, existing evaluations focus on task completion or fluency, offering little insight into the behavioral and risk management requirements essential for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation), a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents. MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical scenarios, expected system behaviors and failure modes derived through structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator for detecting safety-relevant dialogue failures, validated against expert clinician annotations; and (3) PatBot, a simulated patient agent capable of producing diverse, scenario-conditioned responses, evaluated for realism and behavioral fidelity with human factors expertise, and a patient-preference study. Across three experiments, we show that MATRIX enables systematic, scalable safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded assessment of 240 dialogues. We also conducted one of the first realism analyses of LLM-based patient simulation, showing that PatBot reliably simulates realistic patient behavior in quantitative and qualitative evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios and 10 clinical domains. MATRIX is the first framework to unify structured safety engineering with scalable, validated conversational AI evaluation, enabling regulator-aligned safety auditing. We release all evaluation tools, prompts, structured scenarios, and datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19159v1" target="_blank">Safe Navigation under State Uncertainty: Online Adaptation for Robust Control Barrier Functions</a></h3>
                    <p><strong>Authors:</strong> Ersin Das, Rahal Nanayakkara, Xiao Tan, Ryan M. Bena, Joel W. Burdick, Paulo Tabuada, Aaron D. Ames</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.RO, cs.SY</p>
                    <p><strong>Summary:</strong> Measurements and state estimates are often imperfect in control practice, posing challenges for safety-critical applications, where safety guarantees rely on accurate state information. In the presence of estimation errors, several prior robust control barrier function (R-CBF) formulations have imposed strict conditions on the input. These methods can be overly conservative and can introduce issues such as infeasibility, high control effort, etc. This work proposes a systematic method to improve R-CBFs, and demonstrates its advantages on a tracked vehicle that navigates among multiple obstacles. A primary contribution is a new optimization-based online parameter adaptation scheme that reduces the conservativeness of existing R-CBFs. In order to reduce the complexity of the parameter optimization, we merge several safety constraints into one unified numerical CBF via Poissons equation. We further address the dual relative degree issue that typically causes difficulty in vehicle tracking. Experimental trials demonstrate the overall performance improvement of our approach over existing formulations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19152v1" target="_blank">Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games</a></h3>
                    <p><strong>Authors:</strong> Chiu-Chou Lin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG, cs.MA, cs.SC</p>
                    <p><strong>Summary:</strong> Contemporary artificial intelligence (AI) development largely centers on rational decision-making, valued for its measurability and suitability for objective evaluation. Yet in real-world contexts, an intelligent agents decisions are shaped not only by logic but also by deeper influences such as beliefs, values, and preferences. The diversity of human decision-making styles emerges from these differences, highlighting that style is an essential but often overlooked dimension of intelligence. This dissertation introduces playstyle as an alternative lens for observing and analyzing the decision-making behavior of intelligent agents, and examines its foundational meaning and historical context from a philosophical perspective. By analyzing how beliefs and values drive intentions and actions, we construct a two-tier framework for style formation: the external interaction loop with the environment and the internal cognitive loop of deliberation. On this basis, we formalize style-related characteristics and propose measurable indicators such as style capacity, style popularity, and evolutionary dynamics. The study focuses on three core research directions: (1) Defining and measuring playstyle, proposing a general playstyle metric based on discretized state spaces, and extending it to quantify strategic diversity and competitive balance; (2) Expressing and generating playstyle, exploring how reinforcement learning and imitation learning can be used to train agents exhibiting specific stylistic tendencies, and introducing a novel approach for human-like style learning and modeling; and (3) Practical applications, analyzing the potential of these techniques in domains such as game design and interactive entertainment. Finally, the dissertation outlines future extensions, including the role of style as a core element in building artificial general intelligence (AGI).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19145v1" target="_blank">Echoes of the past: A unified perspective on fading memory and echo states</a></h3>
                    <p><strong>Authors:</strong> Juan-Pablo Ortega, Florian Rossmannek</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.LG, math.DS, 37N35, 68T05, 93B03</p>
                    <p><strong>Summary:</strong> Recurrent neural networks (RNNs) have become increasingly popular in information processing tasks involving time series and temporal data. A fundamental property of RNNs is their ability to create reliable input/output responses, often linked to how the network handles its memory of the information it processed. Various notions have been proposed to conceptualize the behavior of memory in RNNs, including steady states, echo states, state forgetting, input forgetting, and fading memory. Although these notions are often used interchangeably, their precise relationships remain unclear. This work aims to unify these notions in a common language, derive new implications and equivalences between them, and provide alternative proofs to some existing results. By clarifying the relationships between these concepts, this research contributes to a deeper understanding of RNNs and their temporal information processing capabilities.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19136v1" target="_blank">Using Machine Learning to Generate, Clarify, and Improve Economic Models</a></h3>
                    <p><strong>Authors:</strong> Annie Liang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> econ.TH</p>
                    <p><strong>Summary:</strong> Machine learning algorithms can now outperform classic economic models in predicting quantities ranging from bargaining outcomes, to choice under uncertainty, to an individuals future jobs and wages. Yet this predictive accuracy comes at a cost: most machine learning algorithms function as black boxes, offering little insight into \emph{why} outcomes occur. This article asks whether machine learning can guide the development of new economic theories. Economic models serve an important purpose beyond prediction -- they uncover the general mechanisms behind observed behaviors. A model that identifies the causal pathways of economic development is more valuable than one that merely predicts which countries will escape poverty, because it enables policymakers to encourage that development in countries where it might not have happened otherwise. Similarly, a model that predicts imperfectly across many domains can be more valuable than one that is highly accurate in a specific domain, since the former allows insights and data obtained from one setting to inform decisions and policy in another. Applying machine learning algorithms off-the-shelf is unlikely to yield such models. But recent work shows that, when reconceived with the aims of an economic modeler in mind, machine learning methods can improve both prediction and understanding. These approaches range from adversarially training algorithms to expose the limits of existing models, to imposing economic theory as a constraint on algorithmic search. Advances in large language models complement these strategies and open new research directions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19131v1" target="_blank">ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments</a></h3>
                    <p><strong>Authors:</strong> Shreya Gummadi, Mateus V. Gasparino, Gianluca Capezzuto, Marcelo Becker, Girish Chowdhary</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> The advancement of robotics and autonomous navigation systems hinges on the ability to accurately predict terrain traversability. Traditional methods for generating datasets to train these prediction models often involve putting robots into potentially hazardous environments, posing risks to equipment and safety. To solve this problem, we present ZeST, a novel approach leveraging visual reasoning capabilities of Large Language Models (LLMs) to create a traversability map in real-time without exposing robots to danger. Our approach not only performs zero-shot traversability and mitigates the risks associated with real-world data collection but also accelerates the development of advanced navigation systems, offering a cost-effective and scalable solution. To support our findings, we present navigation results, in both controlled indoor and unstructured outdoor environments. As shown in the experiments, our method provides safer navigation when compared to other state-of-the-art methods, constantly reaching the final goal.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1515/ms-2025-0015" target="_blank">Comparison of Topologies on Fundamental Groups with Subgroup Topology Viewpoint</a></h3>
                    <p><strong>Authors:</strong> Naghme Shahami, Behrooz Mashayekhy</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.AT, 57M05, 55Q05, 57M07, 57M10, 57M12</p>
                    <p><strong>Summary:</strong> In order to make the fundamental group, one of the most well known invariants in algebraic topology, more useful and powerful some researchers have introduced and studied various topologies on the fundamental group from the beginning of the 21st century onwards. In this paper by reviewing these topologies, using the concept of subgroup topology, we are going to compare these topologies in order to present some results on topologized fundamental groups.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19121v1" target="_blank">Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings</a></h3>
                    <p><strong>Authors:</strong> Xiaolin He, Zirui Li, Xinwei Wang, Riender Happee, Meng Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Perceived risk in automated vehicles (AVs) can create the very danger that automation is meant to prevent: a frightened rider may hesitate when seconds matter, misjudge hazards, or disengage. However, measuring how perceived risk evolves in real time during driving remains challenging, leaving a gap in decoding such hidden psychological states. Here, we present a novel method to time-continuously measure and decode perceived risk. We conducted a controlled experiment where 2,164 participants viewed high-fidelity videos of common highway driving scenes and provided 141,628 discrete safety ratings. Through continuous-signal reconstruction of the discrete ratings, we obtained 236 hours of time-continuous perceived risk data - the largest perceived risk dataset to date. Leveraging this dataset, we trained deep neural networks that predict moment-by-moment perceived risk from vehicle kinematics with a mean relative error below $3\%$. Explainable AI analysis uncovers which factors determine perceived risk in real time. Our findings demonstrate a new paradigm for quantifying dynamic passenger experience and psychological constructs in real time. These findings can guide the design of AVs and other machines that operate in close proximity to people, adjusting behaviour before trust erodes, and help realise automations benefits in transport, healthcare, and service robotics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19115v1" target="_blank">SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications</a></h3>
                    <p><strong>Authors:</strong> Joshua Lee, Ali Arastehfard, Weiran Liu, Xuegang Ban, Yuan Hong</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AI, E.3; I.2.6; I.5.1; F.1.2</p>
                    <p><strong>Summary:</strong> Autonomous driving and V2X technologies have developed rapidly in the past decade, leading to improved safety and efficiency in modern transportation. These systems interact with extensive networks of vehicles, roadside infrastructure, and cloud resources to support their machine learning capabilities. However, the widespread use of machine learning in V2X systems raises issues over the privacy of the data involved. This is particularly concerning for smart-transit and driver safety applications which can implicitly reveal user locations or explicitly disclose medical data such as EEG signals. To resolve these issues, we propose SecureV2X, a scalable, multi-agent system for secure neural network inferences deployed between the server and each vehicle. Under this setting, we study two multi-agent V2X applications: secure drowsiness detection, and secure red-light violation detection. Our system achieves strong performance relative to baselines, and scales efficiently to support a large number of secure computation interactions simultaneously. For instance, SecureV2X is $9.4 \times$ faster, requires $143\times$ fewer computational rounds, and involves $16.6\times$ less communication on drowsiness detection compared to other secure systems. Moreover, it achieves a runtime nearly $100\times$ faster than state-of-the-art benchmarks in object detection tasks for red light violation detection.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19099v1" target="_blank">Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic</a></h3>
                    <p><strong>Authors:</strong> Thomas Compton</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Quantitative Discourse Analysis has seen growing adoption with the rise of Large Language Models and computational tools. However, reliance on black box software such as MAXQDA and NVivo risks undermining methodological transparency and alignment with research goals. This paper presents a hybrid, transparent framework for QDA that combines lexical and semantic methods to enable triangulation, reproducibility, and interpretability. Drawing from a case study in historical political discourse, we demonstrate how custom Python pipelines using NLTK, spaCy, and Sentence Transformers allow fine-grained control over preprocessing, lemmatisation, and embedding generation. We further detail our iterative BERTopic modelling process, incorporating UMAP dimensionality reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised through parameter tuning and multiple runs to enhance topic coherence and coverage. By juxtaposing precise lexical searches with context-aware semantic clustering, we argue for a multi-layered approach that mitigates the limitations of either method in isolation. Our workflow underscores the importance of code-level transparency, researcher agency, and methodological triangulation in computational discourse studies. Code and supplementary materials are available via GitHub.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19097v1" target="_blank">Reasoning LLMs in the Medical Domain: A Literature Survey</a></h3>
                    <p><strong>Authors:</strong> Armin Berger, Sarthak Khanna, David Berghaus, Rafet Sifa</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The emergence of advanced reasoning capabilities in Large Language Models (LLMs) marks a transformative development in healthcare applications. Beyond merely expanding functional capabilities, these reasoning mechanisms enhance decision transparency and explainability-critical requirements in medical contexts. This survey examines the transformation of medical LLMs from basic information retrieval tools to sophisticated clinical reasoning systems capable of supporting complex healthcare decisions. We provide a thorough analysis of the enabling technological foundations, with a particular focus on specialized prompting techniques like Chain-of-Thought and recent breakthroughs in Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates purpose-built medical frameworks while also examining emerging paradigms such as multi-agent collaborative systems and innovative prompting architectures. The survey critically assesses current evaluation methodologies for medical validation and addresses persistent challenges in field interpretation limitations, bias mitigation strategies, patient safety frameworks, and integration of multimodal clinical data. Through this survey, we seek to establish a roadmap for developing reliable LLMs that can serve as effective partners in clinical practice and medical research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19096v1" target="_blank">Trustworthy Agents for Electronic Health Records through Confidence Estimation</a></h3>
                    <p><strong>Authors:</strong> Yongwoo Song, Minbyul Jeong, Mujeen Sung</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) show promise for extracting information from Electronic Health Records (EHR) and supporting clinical decisions. However, deployment in clinical settings faces challenges due to hallucination risks. We propose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric quantifying the accuracy-reliability trade-off at varying confidence thresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating stepwise confidence estimation for clinical question answering. Experiments on MIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under strict reliability constraints, achieving improvements of 44.23%p and 25.34%p at HCAcc@70% while baseline methods fail at these thresholds. These results highlight limitations of traditional accuracy metrics in evaluating healthcare AI agents. Our work contributes to developing trustworthy clinical agents that deliver accurate information or transparently express uncertainty when confidence is low.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19093v1" target="_blank">Retrieval-Augmented Generation for Natural Language Art Provenance Searches in the Getty Provenance Index</a></h3>
                    <p><strong>Authors:</strong> Mathew Henrickson</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> This research presents a Retrieval-Augmented Generation (RAG) framework for art provenance studies, focusing on the Getty Provenance Index. Provenance research establishes the ownership history of artworks, which is essential for verifying authenticity, supporting restitution and legal claims, and understanding the cultural and historical context of art objects. The process is complicated by fragmented, multilingual archival data that hinders efficient retrieval. Current search portals require precise metadata, limiting exploratory searches. Our method enables natural-language and multilingual searches through semantic retrieval and contextual summarization, reducing dependence on metadata structures. We assess RAGs capability to retrieve and summarize auction records using a 10,000-record sample from the Getty Provenance Index - German Sales. The results show this approach provides a scalable solution for navigating art market archives, offering a practical tool for historians and cultural heritage professionals conducting historically sensitive research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19092v1" target="_blank">Measurement of the branching fraction of $\psip \to Ï‰Î·Î·$</a></h3>
                    <p><strong>Authors:</strong> BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. Chen, Z. J. Chen, Z. K. Chen, J. C. Cheng, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. HÃ¼sken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. KÃ¼hn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. C. Liu, Lu Liu, M. H. Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. L. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, Heng Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, Zirong Song, S. Sosio, S. Spataro, S Stansilaus, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, S. H. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, Zhang, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> Using a sample of (2.712 $\pm$ 0.014)$\times 10^{9}$ $\psip$ events collected with the BESIII detector at the BEPCII collider in 2009, 2012, and 2021, the decay $\psip \to \omega \eta \eta $ is observed for the first time. The branching fraction of the $\psi(3686)\to\omega\eta\eta$ decay is measured to be (1.65 $\pm$ 0.02 $\pm$ 0.21)$\times 10^{-5}$, where the first uncertainty is statistical and the second systematic. Clear structures associated with the well-established $\omega(1420)$ and $f_{0}(1710)$ resonances are observed in the $\omega\eta$ and $\eta\eta$ invariant-mass spectra, respectively.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19090v1" target="_blank">Building an Open CGRA Ecosystem for Agile Innovation</a></h3>
                    <p><strong>Authors:</strong> Rohan Juneja, Pranav Dangi, Thilini Kaushalya Bandara, Zhaoying Li, Dhananjaya Wijerathne, Li-Shiuan Peh, Tulika Mitra</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> Modern computing workloads, particularly in AI and edge applications, demand hardware-software co-design to meet aggressive performance and energy targets. Such co-design benefits from open and agile platforms that replace closed, vertically integrated development with modular, community-driven ecosystems. Coarse-Grained Reconfigurable Architectures (CGRAs), with their unique balance of flexibility and efficiency are particularly well-suited for this paradigm. When built on open-source hardware generators and software toolchains, CGRAs provide a compelling foundation for architectural exploration, cross-layer optimization, and real-world deployment. In this paper, we will present an open CGRA ecosystem that we have developed to support agile innovation across the stack. Our contributions include HyCUBE, a CGRA with a reconfigurable single-cycle multi-hop interconnect for efficient data movement; PACE, which embeds a power-efficient HyCUBE within a RISC-V SoC targeting edge computing; and Morpher, a fully open-source, architecture-adaptive CGRA design framework that supports design space exploration, compilation, simulation, and validation. By embracing openness at every layer, we aim to lower barriers to innovation, enable reproducible research, and demonstrate how CGRAs can anchor the next wave of agile hardware development. We will conclude with a call for a unified abstraction layer for CGRAs and spatial accelerators, one that decouples hardware specialization from software development. Such a representation would unlock architectural portability, compiler innovation, and a scalable, open foundation for spatial computing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19087v1" target="_blank">APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration</a></h3>
                    <p><strong>Authors:</strong> Shaobo Ma, Chao Fang, Haikuo Shao, Zhongfeng Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.AR</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup over CUTLASS integer baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19060v1" target="_blank">No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes</a></h3>
                    <p><strong>Authors:</strong> BlaÅ¾ Rolih, Matic FuÄka, Danijel SkoÄaj</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Surface defect detection is a critical task across numerous industries, aimed at efficiently identifying and localising imperfections or irregularities on manufactured components. While numerous methods have been proposed, many fail to meet industrial demands for high performance, efficiency, and adaptability. Existing approaches are often constrained to specific supervision scenarios and struggle to adapt to the diverse data annotations encountered in real-world manufacturing processes, such as unsupervised, weakly supervised, mixed supervision, and fully supervised settings. To address these challenges, we propose SuperSimpleNet, a highly efficient and adaptable discriminative model built on the foundation of SimpleNet. SuperSimpleNet incorporates a novel synthetic anomaly generation process, an enhanced classification head, and an improved learning procedure, enabling efficient training in all four supervision scenarios, making it the first model capable of fully leveraging all available data annotations. SuperSimpleNet sets a new standard for performance across all scenarios, as demonstrated by its results on four challenging benchmark datasets. Beyond accuracy, it is very fast, achieving an inference time below 10 ms. With its ability to unify diverse supervision paradigms while maintaining outstanding speed and reliability, SuperSimpleNet represents a promising step forward in addressing real-world manufacturing challenges and bridging the gap between academic research and industrial applications. Code: https://github.com/blaz-r/SuperSimpleNet</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19042v1" target="_blank">A Concurrent Modular Agent: Framework for Autonomous LLM Agents</a></h3>
                    <p><strong>Authors:</strong> Norihiro Maruyama, Takahide Yoshida, Hiroki Sato, Atsushi Masumori, Johnsmith, Takashi Ikegami</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> We introduce the Concurrent Modular Agent (CMA), a framework that orchestrates multiple Large-Language-Model (LLM)-based modules that operate fully asynchronously yet maintain a coherent and fault-tolerant behavioral loop. This framework addresses long-standing difficulties in agent architectures by letting intention emerge from language-mediated interactions among autonomous processes. This approach enables flexible, adaptive, and context-dependent behavior through the combination of concurrently executed modules that offload reasoning to an LLM, inter-module communication, and a single shared global state.We consider this approach to be a practical realization of Minskys Society of Mind theory. We demonstrate the viability of our system through two practical use-case studies. The emergent properties observed in our system suggest that complex cognitive phenomena like self-awareness may indeed arise from the organized interaction of simpler processes, supporting Minsky-Society of Mind concept and opening new avenues for artificial intelligence research. The source code for our work is available at: https://github.com/AlternativeMachine/concurrent-modular-agent.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19036v1" target="_blank">Of the People, By the Algorithm: How AI Transforms Democratic Representation</a></h3>
                    <p><strong>Authors:</strong> Yuval Rymon</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CY</p>
                    <p><strong>Summary:</strong> This review examines how AI technologies are transforming democratic representation, focusing on citizen participation and algorithmic decision-making. The analysis reveals that AI technologies are reshaping democratic processes in fundamental ways: enabling mass-scale deliberation, changing how citizens access and engage with political information, and transforming how representatives make and implement decisions. While AI offers unprecedented opportunities for enhancing democratic participation and governance efficiency, it also presents significant challenges to democratic legitimacy and accountability. Social media platforms AI-driven algorithms currently mediate much political discourse, creating concerns about information manipulation and privacy. Large Language Models introduce both epistemic challenges and potential tools for improving democratic dialogue. The emergence of Mass Online Deliberation platforms suggests possibilities for scaling up meaningful citizen participation, while Algorithmic Decision-Making systems promise more efficient policy implementation but face limitations in handling complex political trade-offs. As these systems become prevalent, representatives may assume the role of architects of automated decision frameworks, responsible for guiding the translation of politically contested concepts into technical parameters and metrics. Advanced deliberation platforms offering real-time insights into citizen preferences will challenge traditional representative independence and discretion to interpret public will. The institutional integration of these participation mechanisms requires frameworks that balance the benefits with democratic stability through hybrid systems weighting different forms of democratic expression.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19029v1" target="_blank">When recalling in-context, Transformers are not SSMs</a></h3>
                    <p><strong>Authors:</strong> Destiny Okpekpe, Antonio Orvieto</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Despite the advantageous subquadratic complexity of modern recurrent deep learning models -- such as state-space models (SSMs) -- recent studies have highlighted their potential shortcomings compared to transformers on reasoning and memorization tasks. In this paper, we dive deeper into one of such benchmarks: associative recall (AR), which has been shown to correlate well with language modeling performance, and inspect in detail the effects of scaling and optimization issues in recently proposed token mixing strategies. We first demonstrate that, unlike standard transformers, the choice of learning rate plays a critical role in the performance of modern recurrent models: an issue that can severely affect reported performance in previous works and suggests further research is needed to stabilize training. Next, we show that recurrent and attention-based models exhibit contrasting benefits when scaling in width as opposed to depth, with attention being notably unable to solve AR when limited to a single layer. We then further inspect 1-layer transformers, revealing that despite their poor performance, their training dynamics surprisingly resemble the formation of induction heads, a phenomenon previously observed only in their 2-layer counterparts. Finally, through architectural ablations, we study how components affects Transformer and Mambas performance and optimization stability.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19026v1" target="_blank">MovieCORE: COgnitive REasoning in Movies</a></h3>
                    <p><strong>Authors:</strong> Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at https://joslefaure.github.io/assets/html/moviecore.html.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19021v1" target="_blank">MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis</a></h3>
                    <p><strong>Authors:</strong> Riju Marwah, Riya Arora, Navneet Yadav, Himank Arora</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> With the prevalence of plastics exceeding 368 million tons yearly, microplastic pollution has grown to an extent where air, water, soil, and living organisms have all tested positive for microplastic presence. These particles, which are smaller than 5 millimeters in size, are no less harmful to humans than to the environment. Toxicity research on microplastics has shown that exposure may cause liver infection, intestinal injuries, and gut flora imbalance, leading to numerous potential health hazards. This paper presents a new model, MicroDetect-Net (MDN), which applies fluorescence microscopy with Nile Red dye staining and deep learning to scan blood samples for microplastics. Although clam blood has certain limitations in replicating real human blood, this study opens avenues for applying the approach to human samples, which are more consistent for preliminary data collection. The MDN model integrates dataset preparation, fluorescence imaging, and segmentation using a convolutional neural network to localize and count microplastic fragments. The combination of convolutional networks and Nile Red dye for segmentation produced strong image detection and accuracy. MDN was evaluated on a dataset of 276 Nile Red-stained fluorescent blood images and achieved an accuracy of ninety two percent. Robust performance was observed with an Intersection over Union of 87.4 percent, F1 score of 92.1 percent, Precision of 90.6 percent, and Recall of 93.7 percent. These metrics demonstrate the effectiveness of MDN in the detection of microplastics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19016v1" target="_blank">Working My Way Back to You: Resource-Centric Next-Activity Prediction</a></h3>
                    <p><strong>Authors:</strong> Kelly Kurowski, Xixi Lu, Hajo A Reijers</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Predictive Process Monitoring (PPM) aims to train models that forecast upcoming events in process executions. These predictions support early bottleneck detection, improved scheduling, proactive interventions, and timely communication with stakeholders. While existing research adopts a control-flow perspective, we investigate next-activity prediction from a resource-centric viewpoint, which offers additional benefits such as improved work organization, workload balancing, and capacity forecasting. Although resource information has been shown to enhance tasks such as process performance analysis, its role in next-activity prediction remains unexplored. In this study, we evaluate four prediction models and three encoding strategies across four real-life datasets. Compared to the baseline, our results show that LightGBM and Transformer models perform best with an encoding based on 2-gram activity transitions, while Random Forest benefits most from an encoding that combines 2-gram transitions and activity repetition features. This combined encoding also achieves the highest average accuracy. This resource-centric approach could enable smarter resource allocation, strategic workforce planning, and personalized employee support by analyzing individual behavior rather than case-level progression. The findings underscore the potential of resource-centric next-activity prediction, opening up new venues for research on PPM.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19009v2" target="_blank">FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning</a></h3>
                    <p><strong>Authors:</strong> Md Anwar Hossen, Fatema Siddika, Wensheng Zhang, Anuj Sharma, Ali Jannesari</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.DC</p>
                    <p><strong>Summary:</strong> Heterogeneous Federated Learning (HFL) has gained attention for its ability to accommodate diverse models and heterogeneous data across clients. Prototype-based HFL methods emerge as a promising solution to address statistical heterogeneity and privacy challenges, paving the way for new advancements in HFL research. This method focuses on sharing only class-representative prototypes among heterogeneous clients. However, these prototypes are often aggregated on the server using weighted averaging, leading to sub-optimal global knowledge; these cause the shrinking of aggregated prototypes, which negatively affects the model performance in scenarios when models are heterogeneous and data distributions are extremely non-IID. We propose FedProtoKD in a Heterogeneous Federated Learning setting, using an enhanced dual-knowledge distillation mechanism to improve the system performance with clients logits and prototype feature representation. We aim to resolve the prototype margin-shrinking problem using a contrastive learning-based trainable server prototype by leveraging a class-wise adaptive prototype margin. Furthermore, we assess the importance of public samples using the closeness of the samples prototype to its class representative prototypes, which enhances learning performance. FedProtoKD achieved average improvements of 1.13% up to 34.13% accuracy across various settings and significantly outperforms existing state-of-the-art HFL methods.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19008v1" target="_blank">Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI</a></h3>
                    <p><strong>Authors:</strong> Marcin Moskalewicz, Anna Sterna, Marek Pokropski, Paula Flores</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This study examines the capacity of large language models (LLMs) to support phenomenological qualitative analysis of first-person experience in Borderline Personality Disorder (BPD), understood as a disorder of temporality and selfhood. Building on a prior human-led thematic analysis of 24 inpatients life-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5 Pro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the original investigators. The models were evaluated with blinded and non-blinded expert judges in phenomenology and clinical psychology. Assessments included semantic congruence, Jaccard coefficients, and multidimensional validity ratings (credibility, coherence, substantiveness, and groundness in data). Results showed variable overlap with the human analysis, from 0 percent in GPT to 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient (0.21-0.28). However, the models recovered themes omitted by humans. Geminis output most closely resembled the human analysis, with validity scores significantly higher than GPT and Claude (p  0.78) with the quantity of text and words per theme, highlighting both the variability and potential of AI-augmented thematic analysis to mitigate human interpretative bias.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19005v1" target="_blank">Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark</a></h3>
                    <p><strong>Authors:</strong> Yuxuan Cai, Yipeng Hao, Jie Zhou, Hang Yan, Zhikai Lei, Rui Zhen, Zhenhua Han, Yutao Yang, Junsong Li, Qianjun Pan, Tianyu Huai, Qin Chen, Xin Li, Kai Chen, Bo Zhang, Xipeng Qiu, Liang He</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as second nature. We also introduce StuLife, a benchmark dataset for ELL that simulates a students holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around three key paradigm shifts: From Passive to Proactive, From Context to Memory, and From Imitation to Learning. In this dynamic environment, agents must acquire and distill practical skills and maintain persistent memory to make decisions based on evolving state variables. StuLife provides a comprehensive platform for evaluating lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior. Beyond evaluating SOTA LLMs on the StuLife benchmark, we also explore the role of context engineering in advancing AGI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19006v1" target="_blank">Is attention truly all we need? An empirical study of asset pricing in pretrained RNN sparse and global attention models</a></h3>
                    <p><strong>Authors:</strong> Shanyan Lai</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> q-fin.PR, cs.LG, econ.EM, q-fin.CP, 62M10, 62P20, 91G70, 68T07, I.2.6; I.5.1; J.4; G.3</p>
                    <p><strong>Summary:</strong> This study investigates the pretrained RNN attention models with the mainstream attention mechanisms such as additive attention, Luongs three attentions, global self-attention (Self-att) and sliding window sparse attention (Sparse-att) for the empirical asset pricing research on top 420 large-cap US stocks. This is the first paper on the large-scale state-of-the-art (SOTA) attention mechanisms applied in the asset pricing context. They overcome the limitations of the traditional machine learning (ML) based asset pricing, such as mis-capturing the temporal dependency and short memory. Moreover, the enforced causal masks in the attention mechanisms address the future data leaking issue ignored by the more advanced attention-based models, such as the classic Transformer. The proposed attention models also consider the temporal sparsity characteristic of asset pricing data and mitigate potential overfitting issues by deploying the simplified model structures. This provides some insights for future empirical economic research. All models are examined in three periods, which cover pre-COVID-19 (mild uptrend), COVID-19 (steep uptrend with a large drawdown) and one year post-COVID-19 (sideways movement with high fluctuations), for testing the stability of these models under extreme market conditions. The study finds that in value-weighted portfolio back testing, Model Self-att and Model Sparse-att exhibit great capabilities in deriving the absolute returns and hedging downside risks, while they achieve an annualized Sortino ratio of 2.0 and 1.80 respectively in the period with COVID-19. And Model Sparse-att performs more stably than Model Self-att from the perspective of absolute portfolio returns with respect to the size of stocks market capitalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19004v1" target="_blank">AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms</a></h3>
                    <p><strong>Authors:</strong> Pontus Strimling, Simon Karlsson, Irina Vartanova, Kimmo Eriksson</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> A fundamental question in cognitive science concerns how social norms are acquired and represented. While humans typically learn norms through embodied social experience, we investigated whether large language models can achieve sophisticated norm understanding through statistical learning alone. Across two studies, we systematically evaluated multiple AI systems ability to predict human social appropriateness judgments for 555 everyday scenarios by examining how closely they predicted the average judgment compared to each human participant. In Study 1, GPT-4.5s accuracy in predicting the collective judgment on a continuous scale exceeded that of every human participant (100th percentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7% of humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive power, all models showed systematic, correlated errors. These findings demonstrate that sophisticated models of social cognition can emerge from statistical learning over linguistic data alone, challenging strong versions of theories emphasizing the exclusive necessity of embodied experience for cultural competence. The systematic nature of AI limitations across different architectures indicates potential boundaries of pattern-based social understanding, while the models ability to outperform nearly all individual humans in this predictive task suggests that language serves as a remarkably rich repository for cultural knowledge transmission.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19001v1" target="_blank">Bayesian Joint Modeling of Zero-Inflated Longitudinal Data and Survival with a Cure Fraction: Application to AIDS Data</a></h3>
                    <p><strong>Authors:</strong> Taban Baghfalaki, Mojtaba Ganjali</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.AP</p>
                    <p><strong>Summary:</strong> We propose a comprehensive Bayesian joint modeling framework for zero-inflated longitudinal count data and time-to-event outcomes, explicitly incorporating a cure fraction to account for subjects who never experience the event. The longitudinal sub-model employs a flexible mixed-effects Hurdle model, with distributional options including zero-inflated Poisson and zero-inflated negative binomial, accommodating excess zeros and overdispersion common in count data. The survival component is modeled using a Cox proportional hazards model combined with a mixture cure model to distinguish cured from susceptible individuals. To link the longitudinal and survival processes, we include a linear combination of current longitudinal values as predictors in the survival model. Inference is performed via Hamiltonian Monte Carlo, enabling efficient and robust parameter estimation. The joint model supports dynamic predictions, facilitating real-time risk assessment and personalized medicine. Model performance and estimation accuracy are validated through simulation studies. Finally, we illustrate the methodology using a real-world HIV cohort dataset, demonstrating its practical utility in predicting patient survival outcomes and supporting personalized treatment decisions. Our results highlight the benefits of integrating complex longitudinal count data with survival information in clinical research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18997v1" target="_blank">CarathÃ©odory-type selection and random fixed point theorems for discontinuous correspondences</a></h3>
                    <p><strong>Authors:</strong> Anuj Bhowmik, Nicholas C. Yannelis</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> math.GN, math.PR</p>
                    <p><strong>Summary:</strong> Research in Economics and Game theory has necessitated results on Carath\eodory-type selections. In particular, one has to obtain Carath\eodory type-selections from correspondences that need not be continuous (neither lower-semicontinuous nor upper-semicontinuous). We provide new theorems on Carath\eodory type-selections that include as corollaries the results in Kim-Prikry-Yannelis \cite{KPY:87}. We also, obtain new random fixed-point theorems, random maximal elements, random (Nash) equilibrium and Bayesian equilibrium extending and generalizing theorems of Browder \cite{Browder:68}, Fan \cite{Fan:52} and Nash \cite{Nash}, among others.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18992v1" target="_blank">Automatic Prompt Optimization with Prompt Distillation</a></h3>
                    <p><strong>Authors:</strong> Viktor N. Zhuravlev, Artur R. Khairullin, Ernest A. Dyagin, Alena N. Sitkina, Nikita I. Kulin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Autoprompting is the process of automatically selecting optimized prompts for language models, which is gaining popularity due to the rapid development of prompt engineering driven by extensive research in the field of large language models (LLMs). This paper presents DistillPrompt -- a novel autoprompting method based on large language models that employs a multi-stage integration of task-specific information into prompts using training data. DistillPrompt utilizes distillation, compression, and aggregation operations to explore the prompt space more thoroughly. The method was tested on different datasets for text classification and generation tasks using the t-lite-instruct-0.1 language model. The results demonstrate a significant average improvement (e.g., 20.12% across the entire dataset compared to Grips) in key metrics over existing methods in the field, establishing DistillPrompt as one of the most effective non-gradient approaches in autoprompting.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18988v1" target="_blank">Interpretable by AI Mother Tongue: Native Symbolic Reasoning in Neural Models</a></h3>
                    <p><strong>Authors:</strong> Hung Ming Liu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> We present a framework where neural models develop an AI Mother Tongue, a native symbolic language that simultaneously supports intuitive reasoning, compositional symbol chains, and inherent interpretability. Unlike post-hoc explanation methods, our approach embeds reasoning directly into the models representations: symbols capture meaningful semantic patterns, chains trace decision paths, and gated induction mechanisms guide selective focus, yielding transparent yet flexible reasoning. We introduce complementary training objectives to enhance symbol purity and decision sparsity, and employ a sequential specialization strategy to first build broad symbolic competence and then refine intuitive judgments. Experiments on AI tasks demonstrate competitive accuracy alongside verifiable reasoning traces, showing that AI Mother Tongue can serve as a unified mechanism for interpretability, intuition, and symbolic reasoning in neural models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18975v1" target="_blank">Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data</a></h3>
                    <p><strong>Authors:</strong> Jan Nikolas Morshuis, Matthias Hein, Christian F. Baumgartner</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV</p>
                    <p><strong>Summary:</strong> MR imaging is a valuable diagnostic tool allowing to non-invasively visualize patient anatomy and pathology with high soft-tissue contrast. However, MRI acquisition is typically time-consuming, leading to patient discomfort and increased costs to the healthcare system. Recent years have seen substantial research effort into the development of methods that allow for accelerated MRI acquisition while still obtaining a reconstruction that appears similar to the fully-sampled MR image. However, for many applications a perfectly reconstructed MR image may not be necessary, particularly, when the primary goal is a downstream task such as segmentation. This has led to growing interest in methods that aim to perform segmentation directly on accelerated MRI data. Despite recent advances, existing methods have largely been developed in isolation, without direct comparison to one another, often using separate or private datasets, and lacking unified evaluation standards. To date, no high-quality, comprehensive comparison of these methods exists, and the optimal strategy for segmenting accelerated MR data remains unknown. This paper provides the first unified benchmark for the segmentation of undersampled MRI data comparing 7 approaches. A particular focus is placed on comparing \textit{one-stage approaches}, that combine reconstruction and segmentation into a unified model, with \textit{two-stage approaches}, that utilize established MRI reconstruction methods followed by a segmentation network. We test these methods on two MRI datasets that include multi-coil k-space data as well as a human-annotated segmentation ground-truth. We find that simple two-stage methods that consider data-consistency lead to the best segmentation scores, surpassing complex specialized methods that are developed specifically for this task.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18966v1" target="_blank">USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning</a></h3>
                    <p><strong>Authors:</strong> Shaojin Wu, Mengqi Huang, Yufeng Cheng, Wenxu Wu, Jiahe Tian, Yiming Luo, Fei Ding, Qian He</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Existing literature typically treats style-driven and subject-driven generation as two disjoint tasks: the former prioritizes stylistic similarity, whereas the latter insists on subject consistency, resulting in an apparent antagonism. We argue that both objectives can be unified under a single framework because they ultimately concern the disentanglement and re-composition of content and style, a long-standing theme in style-driven research. To this end, we present USO, a Unified Style-Subject Optimized customization model. First, we construct a large-scale triplet dataset consisting of content images, style images, and their corresponding stylized content images. Second, we introduce a disentangled learning scheme that simultaneously aligns style features and disentangles content from style through two complementary objectives, style-alignment training and content-style disentanglement training. Third, we incorporate a style reward-learning paradigm denoted as SRL to further enhance the models performance. Finally, we release USO-Bench, the first benchmark that jointly evaluates style similarity and subject fidelity across multiple metrics. Extensive experiments demonstrate that USO achieves state-of-the-art performance among open-source models along both dimensions of subject consistency and style similarity. Code and model: https://github.com/bytedance/USO</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3748636.3764154" target="_blank">Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers</a></h3>
                    <p><strong>Authors:</strong> Claudio Affolter, Sidi Wu, Yizi Chen, Lorenz Hurni</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Traditional map-making relies heavily on Geographic Information Systems (GIS), requiring domain expertise and being time-consuming, especially for repetitive tasks. Recent advances in generative AI (GenAI), particularly image diffusion models, offer new opportunities for automating and democratizing the map-making process. However, these models struggle with accurate map creation due to limited control over spatial composition and semantic layout. To address this, we integrate vector data to guide map generation in different styles, specified by the textual prompts. Our model is the first to generate accurate maps in controlled styles, and we have integrated it into a web application to improve its usability and accessibility. We conducted a user study with professional cartographers to assess the fidelity of generated maps, the usability of the web application, and the implications of ever-emerging GenAI in map-making. The findings have suggested the potential of our developed application and, more generally, the GenAI models in helping both non-expert users and professionals in creating maps more efficiently. We have also outlined further technical improvements and emphasized the new role of cartographers to advance the paradigm of AI-assisted map-making.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18955v1" target="_blank">Interleaving Large Language Models for Compiler Testing</a></h3>
                    <p><strong>Authors:</strong> Yunbo Ni, Shaohua Li</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.SE</p>
                    <p><strong>Summary:</strong> Testing compilers with AI models, especially large language models (LLMs), has shown great promise. However, current approaches struggle with two key problems: The generated programs for testing compilers are often too simple, and extensive testing with the LLMs is computationally expensive. In this paper, we propose a novel compiler testing framework that decouples the testing process into two distinct phases: an offline phase and an online phase. In the offline phase, we use LLMs to generate a collection of small but feature-rich code pieces. In the online phase, we reuse these code pieces by strategically combining them to build high-quality and valid test programs, which are then used to test compilers. We implement this idea in a tool, LegoFuzz, for testing C compilers. The results are striking: we found 66 bugs in GCC and LLVM, the most widely used C compilers. Almost half of the bugs are miscompilation bugs, which are serious and hard-to-find bugs that none of the existing LLM-based tools could find. We believe this efficient design opens up new possibilities for using AI models in software testing beyond just C compilers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18954v1" target="_blank">On the Generalisation of Koopman Representations for Chaotic System Control</a></h3>
                    <p><strong>Authors:</strong> Kyriakos Hjikakou, Juan Diego Cardenas Cartagena, Matthia Sabatelli</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> This paper investigates the generalisability of Koopman-based representations for chaotic dynamical systems, focusing on their transferability across prediction and control tasks. Using the Lorenz system as a testbed, we propose a three-stage methodology: learning Koopman embeddings through autoencoding, pre-training a transformer on next-state prediction, and fine-tuning for safety-critical control. Our results show that Koopman embeddings outperform both standard and physics-informed PCA baselines, achieving accurate and data-efficient performance. Notably, fixing the pre-trained transformer weights during fine-tuning leads to no performance degradation, indicating that the learned representations capture reusable dynamical structure rather than task-specific patterns. These findings support the use of Koopman embeddings as a foundation for multi-task learning in physics-informed machine learning. A project page is available at https://kikisprdx.github.io/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.18953v1" target="_blank">Novel Approaches to Artificial Intelligence Development Based on the Nearest Neighbor Method</a></h3>
                    <p><strong>Authors:</strong> I. I. Priezzhev, D. A. Danko, A. V. Shubin</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, I.2.6; I.2.8; I.5.1</p>
                    <p><strong>Summary:</strong> Modern neural network technologies, including large language models, have achieved remarkable success in various applied artificial intelligence applications, however, they face a range of fundamental limitations. Among them are hallucination effects, high computational complexity of training and inference, costly fine-tuning, and catastrophic forgetting issues. These limitations significantly hinder the use of neural networks in critical areas such as medicine, industrial process management, and scientific research. This article proposes an alternative approach based on the nearest neighbors method with hierarchical clustering structures. Employing the k-nearest neighbors algorithm significantly reduces or completely eliminates hallucination effects while simplifying model expansion and fine-tuning without the need for retraining the entire network. To overcome the high computational load of the k-nearest neighbors method, the paper proposes using tree-like data structures based on Kohonen self-organizing maps, thereby greatly accelerating nearest neighbor searches. Tests conducted on handwritten digit recognition and simple subtitle translation tasks confirmed the effectiveness of the proposed approach. With only a slight reduction in accuracy, the nearest neighbor search time was reduced hundreds of times compared to exhaustive search methods. The proposed method features transparency and interpretability, closely aligns with human cognitive mechanisms, and demonstrates potential for extensive use in tasks requiring high reliability and explainable results.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19243v1" target="_blank">Style4D-Bench: A Benchmark Suite for 4D Stylization</a></h3>
                    <p><strong>Authors:</strong> Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, 2) a strong baseline that make an initial attempt for 4D stylization, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes. Project page: https://becky-catherine.github.io/Style4D . Code: https://github.com/Becky-catherine/Style4D-Bench .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19244v1" target="_blank">Articulate3D: Zero-Shot Text-Driven 3D Object Posing</a></h3>
                    <p><strong>Authors:</strong> Oishi Deb, Anjun Hu, Ashkan Khakzar, Philip Torr, Christian Rupprecht</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We propose a training-free method, Articulate3D, to pose a 3D asset through language control. Despite advances in vision and language models, this task remains surprisingly challenging. To achieve this goal, we decompose the problem into two steps. We modify a powerful image-generator to create target images conditioned on the input image and a text instruction. We then align the mesh to the target images through a multi-view pose optimisation step. In detail, we introduce a self-attention rewiring mechanism (RSActrl) that decouples the source structure from pose within an image generative model, allowing it to maintain a consistent structure across varying poses. We observed that differentiable rendering is an unreliable signal for articulation optimisation; instead, we use keypoints to establish correspondences between input and target images. The effectiveness of Articulate3D is demonstrated across a diverse range of 3D objects and free-form text prompts, successfully manipulating poses while maintaining the original identity of the mesh. Quantitative evaluations and a comparative user study, in which our method was preferred over 85\% of the time, confirm its superiority over existing approaches. Project page:https://odeb1.github.io/articulate3d_page_deb/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19239v1" target="_blank">Model Context Protocols in Adaptive Transport Systems: A Survey</a></h3>
                    <p><strong>Authors:</strong> Gaurab Chhetri, Shriyank Somvanshi, Md Monzurul Islam, Shamyo Brotee, Mahmuda Sultana Mimi, Dipti Koirala, Biplov Pandey, Subasish Das</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> The rapid expansion of interconnected devices, autonomous systems, and AI applications has created severe fragmentation in adaptive transport systems, where diverse protocols and context sources remain isolated. This survey provides the first systematic investigation of the Model Context Protocol (MCP) as a unifying paradigm, highlighting its ability to bridge protocol-level adaptation with context-aware decision making. Analyzing established literature, we show that existing efforts have implicitly converged toward MCP-like architectures, signaling a natural evolution from fragmented solutions to standardized integration frameworks. We propose a five-category taxonomy covering adaptive mechanisms, context-aware frameworks, unification models, integration strategies, and MCP-enabled architectures. Our findings reveal three key insights: traditional transport protocols have reached the limits of isolated adaptation, MCPs client-server and JSON-RPC structure enables semantic interoperability, and AI-driven transport demands integration paradigms uniquely suited to MCP. Finally, we present a research roadmap positioning MCP as a foundation for next-generation adaptive, context-aware, and intelligent transport infrastructures.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.1145/3744736.3749343" target="_blank">Beyond Competitive Gaming: How Casual Players Evaluate and Respond to Teammate Performance</a></h3>
                    <p><strong>Authors:</strong> Kaushall Senthil Nathan, Jieun Lee, Derrick M. Wang, Geneva M. Smith, Eugene Kukshinov, Daniel Harley, Lennart E. Nacke</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Teammate performance evaluation fundamentally shapes intervention design in video games. However, our current understanding stems primarily from competitive E-Sports contexts where individual performance directly impacts outcomes. This research addresses whether performance evaluation mechanisms and behavioural responses identified in competitive games generalize to casual cooperative games. We investigated how casual players evaluate teammate competence and respond behaviourally in a controlled between-subjects experiment (N=23). We manipulated confederate performance in Overcooked 2, combining observations, NASA TLX self-reports, and interviews. We present two key findings. (1) Observations revealed frustration behaviours completely absent in self-report data. Thus, these instruments assess fundamentally distinct constructs. (2) Participants consistently evaluated teammate performance through relative comparison rather than absolute metrics. This contradicts task-performance operationalizations dominant in competitive gaming research. Hence, performance evaluation frameworks from competitive contexts cannot be directly applied to casual cooperative games. We provide empirical evidence that performance evaluation in casual games requires a comparative operationalization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19229v2" target="_blank">StepWiser: Stepwise Generative Judges for Wiser Reasoning</a></h3>
                    <p><strong>Authors:</strong> Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> As models increasingly leverage multi-step reasoning strategies to solve complex problems, supervising the logical validity of these intermediate steps has become a critical research challenge. Process reward models address this by providing step-by-step feedback, but current approaches have two major drawbacks: they typically function as classifiers without providing explanations, and their reliance on supervised fine-tuning with static datasets limits generalization. Inspired by recent advances, we reframe stepwise reward modeling from a classification task to a reasoning task itself. We thus propose a generative judge that reasons about the policy models reasoning steps (i.e., meta-reasons), outputting thinking tokens before delivering a final verdict. Our model, StepWiser, is trained by reinforcement learning using relative outcomes of rollouts. We show it provides (i) better judgment accuracy on intermediate steps than existing methods; (ii) can be used to improve the policy model at training time; and (iii) improves inference-time search.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19248v1" target="_blank">Disorder-induced proximate quantum spin ice phase in Pr$_2$Sn$_2$O$_7$</a></h3>
                    <p><strong>Authors:</strong> Yi Luo, Joseph A. M. Paddison, Brenden R. Ortiz, Miles Knudtson, Stephen D. Wilson, Jue Liu, Benjamin A. Frandsen, Si Athena Chen, Matthias Frontzek, Andrey Podlesnyak, Adam A. Aczel</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.mtrl-sci</p>
                    <p><strong>Summary:</strong> We report a comprehensive bulk characterization and neutron scattering investigation of single-crystalline Pr$_2$Sn$_2$O$_7$, a magnetic pyrochlore synthesized via a flux-growth method. Unpolarized neutron diffuse scattering reveals the emergence of spin-ice correlations below $T \sim 1$ K, evidenced by the development of anisotropic pinch-point features that are consistent with quantum-spin-ice (QSI) behavior. A.C. susceptibility measurements indicate a progressive slowing of spin dynamics in this regime, culminating in complete spin freezing below $T_f \approx 0.15$ K. Inelastic neutron scattering at $T = 0.5$ K reveals a broad spectrum of quasi-elastic magnetic excitations, with intensity in the low-energy range $[0, 0.2]$ meV significantly suppressed below $T_f$. Meanwhile, an incipient (100)-type magnetic order begins to nucleate, and a gapped excitation centered at $\hbar\omega = 0.23$ meV persists. We further identify two distinct dynamical timescales above $T_f$, a slow component $\tau_{\mathrm{slow}} \sim 10^{-5}$ s and a fast component $\tau_{\mathrm{fast}} \sim 10^{-10}$ s, in quantitative agreement with theoretical predictions for QSI systems. Taken together, these results indicate that Pr$_2$Sn$_2$O$_7$ enters a disorder-induced spin-frozen phase below $T_f$, lying in close proximity to a $U(1)$ quantum spin liquid.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19247v1" target="_blank">VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space</a></h3>
                    <p><strong>Authors:</strong> Lin Li, Zehuan Huang, Haoran Feng, Gengxiong Zhuang, Rui Chen, Chunchao Guo, Lu Sheng</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> 3D local editing of specified regions is crucial for game industry and robot interaction. Recent methods typically edit rendered multi-view images and then reconstruct 3D models, but they face challenges in precisely preserving unedited regions and overall coherence. Inspired by structured 3D generative models, we propose VoxHammer, a novel training-free approach that performs precise and coherent editing in 3D latent space. Given a 3D model, VoxHammer first predicts its inversion trajectory and obtains its inverted latents and key-value tokens at each timestep. Subsequently, in the denoising and editing phase, we replace the denoising features of preserved regions with the corresponding inverted latents and cached key-value tokens. By retaining these contextual features, this approach ensures consistent reconstruction of preserved areas and coherent integration of edited parts. To evaluate the consistency of preserved regions, we constructed Edit3D-Bench, a human-annotated dataset comprising hundreds of samples, each with carefully labeled 3D editing regions. Experiments demonstrate that VoxHammer significantly outperforms existing methods in terms of both 3D consistency of preserved regions and overall quality. Our method holds promise for synthesizing high-quality edited paired data, thereby laying the data foundation for in-context 3D generation. See our project page at https://huanngzh.github.io/VoxHammer-Page/.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19245v1" target="_blank">New Twists on Topological Quantum Error Correcting Codes</a></h3>
                    <p><strong>Authors:</strong> Mohamad Mousa, Amit Jamadagni, Eugene Dumitrescu</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.other, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We derive a new family of quantum error-correcting codes. The main technical tool used to do so is the physically intuitive concept of condensation, which is employed to create new domain walls between the quantum double of $\Z_4$ and an instance of the doubled semion phase. Specifically, we provide explicit constructions, first at the lattice-level and then subsequently at the macroscopic logical-level. To provide intuition, we provide a series of explicit examples using the derived topological interfaces. We discuss the codes utility in the burgeoning area of quantum error-correction with an emphasis on the interplay between logical error rates and decoding. We conclude by outlining how such codes representation and design can be automated. We expect our results, which provide explicit step-by-step instructions in the form of algorithms, to pave the path for new higher-algebraic-dimensional codes to be discovered and implemented in configurations that take advantage of various hardwares distinct strengths.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19243v1" target="_blank">Style4D-Bench: A Benchmark Suite for 4D Stylization</a></h3>
                    <p><strong>Authors:</strong> Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, 2) a strong baseline that make an initial attempt for 4D stylization, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes. Project page: https://becky-catherine.github.io/Style4D . Code: https://github.com/Becky-catherine/Style4D-Bench .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2508.19244v1" target="_blank">Articulate3D: Zero-Shot Text-Driven 3D Object Posing</a></h3>
                    <p><strong>Authors:</strong> Oishi Deb, Anjun Hu, Ashkan Khakzar, Philip Torr, Christian Rupprecht</p>
                    <p><strong>Published:</strong> 8/26/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We propose a training-free method, Articulate3D, to pose a 3D asset through language control. Despite advances in vision and language models, this task remains surprisingly challenging. To achieve this goal, we decompose the problem into two steps. We modify a powerful image-generator to create target images conditioned on the input image and a text instruction. We then align the mesh to the target images through a multi-view pose optimisation step. In detail, we introduce a self-attention rewiring mechanism (RSActrl) that decouples the source structure from pose within an image generative model, allowing it to maintain a consistent structure across varying poses. We observed that differentiable rendering is an unreliable signal for articulation optimisation; instead, we use keypoints to establish correspondences between input and target images. The effectiveness of Articulate3D is demonstrated across a diverse range of 3D objects and free-form text prompts, successfully manipulating poses while maintaining the original identity of the mesh. Quantitative evaluations and a comparative user study, in which our method was preferred over 85\% of the time, confirm its superiority over existing approaches. Project page:https://odeb1.github.io/articulate3d_page_deb/</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

