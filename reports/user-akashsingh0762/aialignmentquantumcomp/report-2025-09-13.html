
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-09-13<br>
            <strong>Topics:</strong> ai alignment research, quantum computing<br>
            <strong>Papers Found:</strong> 75
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <h2>ai alignment research</h2>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Large-Scale Datasets and Benchmarks</strong>: There is a significant trend towards developing large-scale datasets and comprehensive benchmarks to advance AI model capabilities. Examples include FLUX-Reason-6M for text-to-image reasoning and SpatialVID for video data with spatial annotations. These resources are crucial for improving model performance and alignment.</p>
</li>
<li><p><strong>AI Safety and Trustworthiness</strong>: Research is increasingly focusing on AI alignment with human values, addressing safety concerns, and ensuring trustworthiness. Examples include the development of mechanisms for better confidence elicitation (GrACE) and benchmarks for hallucination detection (HumbleBench).</p>
</li>
<li><p><strong>Integration of AI with Domain-Specific Applications</strong>: There is a trend towards integrating AI with specific domains such as finance, healthcare, and law, addressing unique challenges like hallucinations in legal contexts and language barriers in education.</p>
</li>
<li><p><strong>Interdisciplinary Approaches</strong>: Combining AI with other fields such as quantum computing (Variational Quantum Circuits) and neuroscience (Explainable AI in Microstructure Imaging) to enhance AI capabilities and interpretability.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Enhanced Dataset Creation</strong>: The introduction of datasets like FLUX-Reason-6M and SpatialVID marks a breakthrough in providing the research community with resources that were previously only available to large industrial labs, thus democratizing access to high-quality data.</p>
</li>
<li><p><strong>AI Steering and Safety</strong>: The development of frameworks like SteerMoE that allow for the steering of AI model behavior without retraining showcases a breakthrough in enhancing model safety and alignment with human values.</p>
</li>
<li><p><strong>Explainable AI Models</strong>: Innovations in explainable AI, such as the SHAP-Guided Protocol for MRI imaging and SmartDetector for smart contracts, represent breakthroughs in making AI models more interpretable and trustworthy.</p>
</li>
<li><p><strong>Advanced AI Integration Techniques</strong>: The advancement of frameworks like MOAT for multi-agent systems, which enable better collaboration among AI agents, marks a significant improvement in addressing capability gaps and enhancing task performance.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Catalyzing AI Model Development</strong>: The release of large-scale datasets and benchmarks could significantly accelerate the development of AI models that are better aligned with human reasoning and capable of complex tasks.</p>
</li>
<li><p><strong>Improving AI Trust and Safety</strong>: By focusing on AI safety, alignment, and trustworthiness, the research community is addressing critical concerns that are essential for deploying AI in real-world, high-stakes environments.</p>
</li>
<li><p><strong>Enhancing Domain-Specific AI Applications</strong>: The integration of AI with domain-specific challenges, such as legal and educational applications, could lead to more effective and contextually aware AI solutions, thereby expanding the impact of AI technologies across various sectors.</p>
</li>
<li><p><strong>Promoting Interdisciplinary Collaboration</strong>: The combination of AI with other scientific disciplines will likely lead to innovative solutions and a deeper understanding of AIs potential, fostering novel applications and insights.</p>
</li>
</ol>
<p>These trends, breakthroughs, and implications collectively highlight the significant progress made in AI alignment research, emphasizing the importance of safety, trust, and interdisciplinary approaches in the development and deployment of AI technologies.</p>
<p><em>Based on 50 research papers</em></p>

<h2>quantum computing</h2>
<p>Based on the provided summaries of the research papers, I will extract and focus on those that have direct or indirect implications for quantum computing. Here is a high-level summary structured into trends, breakthroughs, and implications specifically relevant to quantum computing:</p>
<h3>Most Important Trends</h3>
<ul>
<li><strong>Quantum Data Center Networks</strong>: There is a growing trend towards developing network architectures that can support quantum data centers. The focus is on modular approaches that cluster small quantum computers to overcome technological and financial barriers to large-scale quantum computing.</li>
<li><strong>Quantum Operations and Symmetry</strong>: Research is examining the phases and behaviors of quantum states under different symmetries, with an emphasis on understanding mixed-state quantum phases and their transitions.</li>
</ul>
<h3>Breakthroughs</h3>
<ul>
<li><strong>Quantum Data Center Network Architecture</strong>: The proposed three-layer fat-tree network architecture for quantum data centers is a significant step forward. It addresses challenges in network scalability, entanglement generation, and quantum memory management, demonstrating scalability and effectiveness in maintaining high entanglement fidelity.</li>
<li><strong>Quantum Symmetry Breaking</strong>: The study on strong-to-weak symmetry breaking phases in quantum operations provides new insights into the stability of these phases under various quantum operations. This exploration of symmetry and phase transitions could inform new quantum computing paradigms.</li>
</ul>
<h3>Implications</h3>
<ul>
<li><strong>Scalability of Quantum Networks</strong>: The advancements in quantum data center network architecture suggest a pathway to scale quantum computing infrastructure. This could accelerate the development and deployment of quantum computers by making them more accessible and efficient.</li>
<li><strong>Understanding Quantum State Dynamics</strong>: The research on symmetry breaking in quantum operations may lead to more robust quantum algorithms and error correction methods. By understanding how symmetries behave in quantum systems, we can design better quantum circuits and improve the reliability of quantum computations.</li>
<li><strong>Potential for Quantum Information Processing</strong>: The exploration of quantum phases and symmetry transitions has implications for quantum information theory. It could lead to new methods for storing and processing quantum information, potentially influencing the development of quantum communication protocols and quantum cryptography.</li>
</ul>
<p>These findings and trends highlight important directions in quantum computing research, addressing both theoretical foundations and practical implementations that are critical for advancing the field.</p>
<p><em>Based on 25 research papers</em></p>

            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2509.09680v1" target="_blank">FLUX-Reason-6M  PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark</a></h3>
                    <p><strong>Authors:</strong> Rongyao Fang, Aldrich Yu, Chengqi Duan, Linjiang Huang, Shuai Bai, Yuxuan Cai, Kun Wang, Si Liu, Xihui Liu, Hongsheng Li</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL</p>
                    <p><strong>Summary:</strong> The advancement of open-source text-to-image (T2I) models has been hindered by the absence of large-scale, reasoning-focused datasets and comprehensive evaluation benchmarks, resulting in a performance gap compared to leading closed-source systems. To address this challenge, We introduce FLUX-Reason-6M and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark). FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality FLUX-generated images and 20 million bilingual (English and Chinese) descriptions specifically designed to teach complex reasoning. The image are organized according to six key characteristics: Imagination, Entity, Text rendering, Style, Affection, and Composition, and design explicit Generation Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation steps. The whole data curation takes 15,000 A100 GPU days, providing the community with a resource previously unattainable outside of large industrial labs. PRISM-Bench offers a novel evaluation standard with seven distinct tracks, including a formidable Long Text challenge using GCoT. Through carefully designed prompts, it utilizes advanced vision-language models for nuanced human-aligned assessment of prompt-image alignment and image aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench reveals critical performance gaps and highlights specific areas requiring improvement. Our dataset, benchmark, and evaluation code are released to catalyze the next wave of reasoning-oriented T2I generation. Project page: https://flux-reason-6m.github.io/ .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09676v1" target="_blank">SpatialVID: A Large-Scale Video Dataset with Spatial Annotations</a></h3>
                    <p><strong>Authors:</strong> Jiahao Wang, Yufeng Yuan, Rujie Zheng, Youtian Lin, Jian Gao, Lin-Zhuo Chen, Yajie Bao, Yi Zhang, Chang Zeng, Yanxi Zhou, Xiaoxiao Long, Hao Zhu, Zhaoxiang Zhang, Xun Cao, Yao Yao</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Significant progress has been made in spatial intelligence, spanning both spatial reconstruction and world exploration. However, the scalability and real-world fidelity of current models remain severely constrained by the scarcity of large-scale, high-quality training data. While several datasets provide camera pose information, they are typically limited in scale, diversity, and annotation richness, particularly for real-world dynamic scenes with ground-truth camera motion. To this end, we collect \textbf{SpatialVID}, a dataset consists of a large corpus of in-the-wild videos with diverse scenes, camera movements and dense 3D annotations such as per-frame camera poses, depth, and motion instructions. Specifically, we collect more than 21,000 hours of raw video, and process them into 2.7 million clips through a hierarchical filtering pipeline, totaling 7,089 hours of dynamic content. A subsequent annotation pipeline enriches these clips with detailed spatial and semantic information, including camera poses, depth maps, dynamic masks, structured captions, and serialized motion instructions. Analysis of SpatialVIDs data statistics reveals a richness and diversity that directly foster improved model generalization and performance, establishing it as a key asset for the video and 3D vision research community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09660v1" target="_blank">Steering MoE LLMs via Expert (De)Activation</a></h3>
                    <p><strong>Authors:</strong> Mohsen Fayyaz, Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Ryan Rossi, Trung Bui, Hinrich SchÃ¼tze, Nanyun Peng</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token through a subset of specialized Feed-Forward Networks (FFN), known as experts. We present SteerMoE, a framework for steering MoE models by detecting and controlling behavior-linked experts. Our detection method identifies experts with distinct activation patterns across paired inputs exhibiting contrasting behaviors. By selectively (de)activating such experts during inference, we control behaviors like faithfulness and safety without retraining or modifying weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to +20% and faithfulness by +27%. In adversarial attack mode, it drops safety by -41% alone, and -100% when combined with existing jailbreak methods, bypassing all safety guardrails and exposing a new dimension of alignment faking hidden within experts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09658v1" target="_blank">Measuring Epistemic Humility in Multimodal Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Bingkui Tong, Jiaer Xia, Sifeng Shang, Kaiyang Zhou</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Hallucinations in multimodal large language models (MLLMs) -- where the model generates content inconsistent with the input image -- pose significant risks in real-world applications, from misinformation in visual question answering to unsafe errors in decision-making. Existing benchmarks primarily test recognition accuracy, i.e., evaluating whether models can select the correct answer among distractors. This overlooks an equally critical capability for trustworthy AI: recognizing when none of the provided options are correct, a behavior reflecting epistemic humility. We present HumbleBench, a new hallucination benchmark designed to evaluate MLLMs ability to reject plausible but incorrect answers across three hallucination types: object, relation, and attribute. Built from a panoptic scene graph dataset, we leverage fine-grained scene graph annotations to extract ground-truth entities and relations, and prompt GPT-4-Turbo to generate multiple-choice questions, followed by a rigorous manual filtering process. Each question includes a None of the above option, requiring models not only to recognize correct visual information but also to identify when no provided answer is valid. We evaluate a variety of state-of-the-art MLLMs -- including both general-purpose and specialized reasoning models -- on HumbleBench and share valuable findings and insights with the community. By incorporating explicit false-option rejection, HumbleBench fills a key gap in current evaluation suites, providing a more realistic measure of MLLM reliability in safety-critical settings. Our code and dataset are released publicly and can be accessed at https://github.com/maifoundations/HumbleBench.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09645v1" target="_blank">Explaining the Reputational Risks of AI-Mediated Communication: Messages Labeled as AI-Assisted Are Viewed as Less Diagnostic of the Senders Moral Character</a></h3>
                    <p><strong>Authors:</strong> Pranav Khadpe, Kimi Wenzel, George Loewenstein, Geoff Kaufman</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY, cs.ET</p>
                    <p><strong>Summary:</strong> When someone sends us a thoughtful message, we naturally form judgments about their character. But what happens when that message carries a label indicating it was written with the help of AI? This paper investigates how the appearance of AI assistance affects our perceptions of message senders. Adding nuance to previous research, through two studies (N=399) featuring vignette scenarios, we find that AI-assistance labels dont necessarily make people view senders negatively. Rather, they dampen the strength of character signals in communication. We show that when someone sends a warmth-signalling message (like thanking or apologizing) without AI help, people more strongly categorize the sender as warm. At the same time, when someone sends a coldness-signalling message (like bragging or blaming) without assistance, people more confidently categorize them as cold. Interestingly, AI labels weaken both these associations: An AI-assisted apology makes the sender appear less warm than if they had written it themselves, and an AI-assisted blame makes the sender appear less cold than if they had composed it independently. This supports our signal diagnosticity explanation: messages labeled as AI-assisted are viewed as less diagnostic than messages which seem unassisted. We discuss how our findings shed light on the causal origins of previously reported observations in AI-Mediated Communication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09638v1" target="_blank">CryptoGuard: An AI-Based Cryptojacking Detection Dashboard Prototype</a></h3>
                    <p><strong>Authors:</strong> Amitabh Chakravorty, Jess Kropczynski, Nelly Elsayed</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.HC</p>
                    <p><strong>Summary:</strong> With the widespread adoption of cryptocurrencies, cryptojacking has become a significant security threat to crypto wallet users. This paper presents a front-end prototype of an AI-powered security dashboard, namely, CryptoGuard. Developed through a user-centered design process, the prototype was constructed as a high-fidelity, click-through model from Figma mockups to simulate key user interactions. It is designed to assist users in monitoring their login and transaction activity, identifying any suspicious behavior, and enabling them to take action directly within the wallet interface. The dashboard is designed for a general audience, prioritizing an intuitive user experience for non-technical individuals. Although its AI functionality is conceptual, the prototype demonstrates features like visual alerts and reporting. This work is positioned explicitly as a design concept, bridging cryptojacking detection research with human-centered interface design. This paper also demonstrates how usability heuristics can directly inform a tools ability to support rapid and confident decision-making under real-world threats. This paper argues that practical security tools require not only robust backend functionality but also a user-centric design that communicates risk and empowers users to take meaningful action.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09630v1" target="_blank">I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection</a></h3>
                    <p><strong>Authors:</strong> Zhenguang Liu, Lixun Ma, Zhongzheng Mu, Chengkun Wei, Xiaojun Xu, Yingying Jiao, Kui Ren</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.CR</p>
                    <p><strong>Summary:</strong> Widespread reuse of open-source code in smart contract development boosts programming efficiency but significantly amplifies bug propagation across contracts, while dedicated methods for detecting similar smart contract functions remain very limited. Conventional abstract-syntax-tree (AST) based methods for smart contract similarity detection face challenges in handling intricate tree structures, which impedes detailed semantic comparison of code. Recent deep-learning based approaches tend to overlook code syntax and detection interpretability, resulting in suboptimal performance. To fill this research gap, we introduce SmartDetector, a novel approach for computing similarity between smart contract functions, explainable at the fine-grained statement level. Technically, SmartDetector decomposes the AST of a smart contract function into a series of smaller statement trees, each reflecting a structural element of the source code. Then, SmartDetector uses a classifier to compute the similarity score of two functions by comparing each pair of their statement trees. To address the infinite hyperparameter space of the classifier, we mathematically derive a cosine-wise diffusion process to efficiently search optimal hyperparameters. Extensive experiments conducted on three large real-world datasets demonstrate that SmartDetector outperforms current state-of-the-art methods by an average improvement of 14.01% in F1-score, achieving an overall average F1-score of 95.88%.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09629v1" target="_blank">Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems</a></h3>
                    <p><strong>Authors:</strong> Minghang Zhu, Zhengliang Shi, Zhiwei Xu, Shiguang Wu, Lingjie Wang, Pengjie Ren, Zhaochun Ren, Zhumin Chen</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The advancement of large language models (LLMs) has enabled the construction of multi-agent systems to solve complex tasks by dividing responsibilities among specialized agents, such as a planning agent for subgoal generation and a grounding agent for executing tool-use actions. Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment. MOAT alternates between two key stages: (1) Planning Agent Alignment, which optimizes the planning agent to generate subgoal sequences that better guide the grounding agent; and (2) Grounding Agent Improving, which fine-tunes the grounding agent using diverse subgoal-action pairs generated by the agent itself to enhance its generalization capablity. Theoretical analysis proves that MOAT ensures a non-decreasing and progressively convergent training process. Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09628v1" target="_blank">Arctic Oscillation Modulation of Winter Air-Sea Coupling in the East/Japan Sea: Persistence, Timescales, and Extremes</a></h3>
                    <p><strong>Authors:</strong> Gyuchang Lim, JongJin Park</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> physics.ao-ph</p>
                    <p><strong>Summary:</strong> The winter climate of the East/Japan Sea (EJS) is strongly affected by the Arctic Oscillation (AO), yet how AO polarity reshapes the memory, coupling patterns, and predictability of sea-surface temperature anomalies (SSTA) remains poorly quantified. Using 30 winters (1993--2022) of daily OISST and ERA5 fields, we combine multivariate Maximum Covariance Analysis (MCA) with an Ornstein--Uhlenbeck (OU)-like integration of atmospheric principal components (PCs). The leading coupled mode explains 87% (+AO) and 75% (-AO) of squared covariance, with SSTA hot spots in East Korea Bay and along the subpolar front. Zero-lag correlations between the SSTA PC and OU-integrated atmospheric PCs reveal characteristic memory timescales ($\tau$) of $\sim$18--25 days for wind-stress curl (CurlTau), $\sim$15--30 days for near-surface air temperature (ATMP) and zonal winds, and $\sim$30--50 days for sea-level pressure (SLP) and meridional winds -- longer under -AO. Detrended Fluctuation Analysis (DFA) shows SSTA persistence $H \approx 1.3$--$1.4$ and that integrated atmospheric responses acquire ocean-like persistence, validating Hasselmanns stochastic framework for winter EJS. AO-phase contrasts align with a curl$\rightarrow$Ekman pumping$\rightarrow$eddy/SSH$\rightarrow$SST pathway: +AO favors anticyclonic/downwelling responses and warmer SSTA, whereas -AO favors cyclonic/upwelling and cooler SSTA. These diagnostics identify phase-specific predictor windows (e.g., 3-week OU-integrated CurlTau/ATMP; 4--7-week SLP/V-wind under -AO) to initialize subseasonal extremes prediction (marine heatwaves and cold-surge-impacted SST). The approach quantifies memory scales and spatial coupling that were not explicitly resolved by previous composite analyses, offering a tractable foundation for probabilistic forecast models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09619v1" target="_blank">Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction</a></h3>
                    <p><strong>Authors:</strong> Roshan Balaji, Joe Bobby, Nirav Pravinbhai Bhatt</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Molecular property prediction using deep learning (DL) models has accelerated drug and materials discovery, but the resulting DL models often lack interpretability, hindering their adoption by chemists. This work proposes developing molecule representations using the concept of Functional Groups (FG) in chemistry. We introduce the Functional Group Representation (FGR) framework, a novel approach to encoding molecules based on their fundamental chemical substructures. Our method integrates two types of functional groups: those curated from established chemical knowledge (FG), and those mined from a large molecular corpus using sequential pattern mining (MFG). The resulting FGR framework encodes molecules into a lower-dimensional latent space by leveraging pre-training on a large dataset of unlabeled molecules. Furthermore, the proposed framework allows the inclusion of 2D structure-based descriptors of molecules. We demonstrate that the FGR framework achieves state-of-the-art performance on a diverse range of 33 benchmark datasets spanning physical chemistry, biophysics, quantum mechanics, biological activity, and pharmacokinetics while enabling chemical interpretability. Crucially, the models representations are intrinsically aligned with established chemical principles, allowing chemists to directly link predicted properties to specific functional groups and facilitating novel insights into structure-property relationships. Our work presents a significant step toward developing high-performing, chemically interpretable DL models for molecular discovery.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09610v1" target="_blank">Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth</a></h3>
                    <p><strong>Authors:</strong> Daria Laslo, Efthymios Georgiou, Marius George Linguraru, Andreas Rauschecker, Sabine Muller, Catherine R. Jutzeler, Sarah Bruningk</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Predicting the spatio-temporal progression of brain tumors is essential for guiding clinical decisions in neuro-oncology. We propose a hybrid mechanistic learning framework that combines a mathematical tumor growth model with a guided denoising diffusion implicit model (DDIM) to synthesize anatomically feasible future MRIs from preceding scans. The mechanistic model, formulated as a system of ordinary differential equations, captures temporal tumor dynamics including radiotherapy effects and estimates future tumor burden. These estimates condition a gradient-guided DDIM, enabling image synthesis that aligns with both predicted growth and patient anatomy. We train our model on the BraTS adult and pediatric glioma datasets and evaluate on 60 axial slices of in-house longitudinal pediatric diffuse midline glioma (DMG) cases. Our framework generates realistic follow-up scans based on spatial similarity metrics. It also introduces tumor growth probability maps, which capture both clinically relevant extent and directionality of tumor growth as shown by 95th percentile Hausdorff Distance. The method enables biologically informed image generation in data-limited scenarios, offering generative-space-time predictions that account for mechanistic priors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09606v1" target="_blank">A Multi-Scale Feature Extraction and Fusion UNet for Pathloss Prediction in UAV-Assisted mmWave Radio Networks</a></h3>
                    <p><strong>Authors:</strong> Sajjad Hussain</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> eess.SP</p>
                    <p><strong>Summary:</strong> Accurate pathloss prediction is essential for the design and optimization of UAV-assisted millimeter-wave (mmWave) networks. While deep learning approaches have shown strong potential, their generalization across diverse environments, robustness to noisy inputs, and sensitivity to UAV altitude remain underexplored. To address these challenges, we propose a UNet-based deep learning architecture that combines multi-scale feature extraction, convolution-based feature fusion, and an atrous spatial pyramid pooling (ASPP) bottleneck for efficient context aggregation. The model predicts pathloss maps from log-distance, line-of-sight (LOS) mask, and building mask inputs. In addition, we develop a fully vectorized LOS mask computation algorithm that significantly accelerates pre-processing and enables large-scale dataset generation. Extensive evaluations on both in-house ray-tracing data and the RadioMapSeer benchmark demonstrate that the proposed model outperforms several state-of-the-art baselines in accuracy and efficiency. All source code is publicly released to support reproducibility and future research.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09602v1" target="_blank">LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination</a></h3>
                    <p><strong>Authors:</strong> Yiqun T. Chen, Tyler H. McCormick, Li Liu, Abhirup Datta</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, stat.AP</p>
                    <p><strong>Summary:</strong> Verbal autopsy (VA) is a critical tool for estimating causes of death in resource-limited settings where medical certification is unavailable. This study presents LA-VA, a proof-of-concept pipeline that combines Large Language Models (LLMs) with traditional algorithmic approaches and embedding-based classification for improved cause-of-death prediction. Using the Population Health Metrics Research Consortium (PHMRC) dataset across three age categories (Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches: GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles. Our results demonstrate that GPT-5 achieves the highest individual performance with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5% (Neonate), outperforming traditional statistical machine learning baselines by 5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches could substantially improve verbal autopsy accuracy, with important implications for global health surveillance in low-resource settings.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09601v1" target="_blank">Are arXiv submissions on Wednesday better cited? Introducing Big Data methods in undergraduate courses on scientific computing</a></h3>
                    <p><strong>Authors:</strong> StÃ©phane Delorme, Leon Mach, Hubert Paszkiewicz, Richard Ruiz</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> physics.ed-ph, hep-ex, physics.comp-ph</p>
                    <p><strong>Summary:</strong> Extracting information from big data sets, both real and simulated, is a modern hallmark of the physical sciences. In practice, students face barriers to learning ``Big Data methods in undergraduate physics and astronomy curricula. As an attempt to alleviate some of these challenges, we present a simple, farm-to-table data analysis pipeline that can collect, process, and plot data from the 800k entries common to the arXiv preprint repository and the bibliographical database inSpireHEP. The pipeline employs contemporary research practices and can be implemented using open-sourced Python libraries common to undergraduate courses on Scientific Computing. To support the use such pipelines in classroom contexts, we make public an example implementation, authored by two undergraduate physics students, that runs on off-the-shelf laptops. For advanced students, we discuss applications of the pipeline, including for online DAQ monitoring and commercialization.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09597v1" target="_blank">Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication</a></h3>
                    <p><strong>Authors:</strong> Maysam Behmanesh, Erkan Turan, Maks Ovsjanikov</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CV</p>
                    <p><strong>Summary:</strong> Graph alignment-the problem of identifying corresponding nodes across multiple graphs-is fundamental to numerous applications. Most existing unsupervised methods embed node features into latent representations to enable cross-graph comparison without ground-truth correspondences. However, these methods suffer from two critical limitations: the degradation of node distinctiveness due to oversmoothing in GNN-based embeddings, and the misalignment of latent spaces across graphs caused by structural noise, feature heterogeneity, and training instability, ultimately leading to unreliable node correspondences. We propose a novel graph alignment framework that simultaneously enhances node distinctiveness and enforces geometric consistency across latent spaces. Our approach introduces a dual-pass encoder that combines low-pass and high-pass spectral filters to generate embeddings that are both structure-aware and highly discriminative. To address latent space misalignment, we incorporate a geometry-aware functional map module that learns bijective and isometric transformations between graph embeddings, ensuring consistent geometric relationships across different representations. Extensive experiments on graph benchmarks demonstrate that our method consistently outperforms existing unsupervised alignment baselines, exhibiting superior robustness to structural inconsistencies and challenging alignment scenarios. Additionally, comprehensive evaluation on vision-language benchmarks using diverse pretrained models shows that our framework effectively generalizes beyond graph domains, enabling unsupervised alignment of vision and language representations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09593v1" target="_blank">Fluent but Unfeeling: The Emotional Blind Spots of Language Models</a></h3>
                    <p><strong>Authors:</strong> Bangzhao Shu, Isha Joshi, Melissa Karnaze, Anh C. Pham, Ishita Kakkar, Sindhu Kothe, Arpine Hovasapian, Mai ElSherief</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The versatility of Large Language Models (LLMs) in natural language understanding has made them increasingly popular in mental health research. While many studies explore LLMs capabilities in emotion recognition, a critical gap remains in evaluating whether LLMs align with human emotions at a fine-grained level. Existing research typically focuses on classifying emotions into predefined, limited categories, overlooking more nuanced expressions. To address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit communities featuring 251 fine-grained, self-disclosed emotion labels. Our comprehensive evaluation framework examines predicted emotion terms and decomposes them into eight basic emotions using established emotion theories, enabling a fine-grained comparison. Systematic testing of prevalent LLMs under various prompt settings reveals that accurately predicting emotions that align with human self-disclosed emotions remains challenging. Qualitative analysis further shows that while certain LLMs generate emotion terms consistent with established emotion theories and definitions, they sometimes fail to capture contextual cues as effectively as human self-disclosures. These findings highlight the limitations of LLMs in fine-grained emotion alignment and offer insights for future research aimed at enhancing their contextual understanding.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09592v1" target="_blank">Bridging the Gap in Phishing Detection: A Comprehensive Phishing Dataset Collector</a></h3>
                    <p><strong>Authors:</strong> Aditya Kulkarni, Shahil Manishbhai Patel, Shivam Pradip Tirmare, Vivek Balachandran, Tamal Das</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> To combat phishing attacks -- aimed at luring web users to divulge their sensitive information -- various phishing detection approaches have been proposed. As attackers focus on devising new tactics to bypass existing detection solutions, researchers have adapted by integrating machine learning and deep learning into phishing detection. Phishing dataset collection is vital to developing effective phishing detection approaches, which highly depend on the diversity of the gathered datasets. The lack of diversity in the dataset results in a biased model. Since phishing websites are often short-lived, collecting them is also a challenge. Consequently, very few phishing webpage dataset repositories exist to date. No single repository comprehensively consolidates all phishing elements corresponding to a phishing webpage, namely, URL, webpage source code, screenshot, and related webpage resources. This paper introduces a resource collection tool designed to gather various resources associated with a URL, such as CSS, Javascript, favicons, webpage images, and screenshots. Our tool leverages PhishTank as the primary source for obtaining active phishing URLs. Our tool fetches several additional webpage resources compared to PyWebCopy Python library, which provides webpage content for a given URL. Additionally, we share a sample dataset generated using our tool comprising 4,056 legitimate and 5,666 phishing URLs along with their associated resources. We also remark on the top correlated phishing features with their associated class label found in our dataset. Our tool offers a comprehensive resource set that can aid researchers in developing effective phishing detection approaches.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09591v1" target="_blank">Numerical modelling of a partially loaded intermodal container freight train passing through a tunnel</a></h3>
                    <p><strong>Authors:</strong> Zhen Liu, David Soper, Hassan Hemida, Boyang Chen</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> physics.flu-dyn, physics.comp-ph</p>
                    <p><strong>Summary:</strong> The bluff nature of a freight train locomotive, coupled with large gaps created between different wagon formations and loaded goods, influence the overall pressure wave pattern generated as the train passes through a tunnel. Typically, 1D models are used to predict the patterns and properties of tunnel pressure wave formations. However, accurate modelling of regions of separation at the head of the blunted containers and at unloaded gap sections is essential for precise predictions of pressure magnitudes. This has traditionally been difficult to capture with 1D models. Furthermore, achieving this accuracy through 3D computational methods demands exceptional mesh quality, significant computational resources, and the careful selection of numerical models. This paper evaluates various numerical models to capture these complexities within regions of flow separation. Findings have supported the development of a new 1D programme to calculate the pressure wave generated by a freight locomotive entering a tunnel, and is here further extended to consider the discontinuities of the train body created by intermodal container loading patterns, by implementing new mesh system and boundary conditions into the 1D programme. A parameterisation study for different loading configurations is also presented to improve the overall programme adaptability, and the relationship between predetermined parameters and gap length is investigated. We validate the effectiveness of the improved 1D model through comprehensive Large Eddy Simulation (LES) results and conduct an extensive parameterisation study to enhance its applicability across various loading configurations. Consequently, this research bridges the gap in freight train tunnel aerodynamics, offering a versatile 1D numerical tool for accurate pressure wave prediction.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09584v1" target="_blank">Visual Grounding from Event Cameras</a></h3>
                    <p><strong>Authors:</strong> Lingdong Kong, Dongyue Lu, Ao Liang, Rong Li, Yuhao Dong, Tianshuai Hu, Lai Xing Ng, Wei Tsang Ooi, Benoit R. Cottereau</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.RO</p>
                    <p><strong>Summary:</strong> Event cameras capture changes in brightness with microsecond precision and remain reliable under motion blur and challenging illumination, offering clear advantages for modeling highly dynamic scenes. Yet, their integration with natural language understanding has received little attention, leaving a gap in multimodal perception. To address this, we introduce Talk2Event, the first large-scale benchmark for language-driven object grounding using event data. Built on real-world driving scenarios, Talk2Event comprises 5,567 scenes, 13,458 annotated objects, and more than 30,000 carefully validated referring expressions. Each expression is enriched with four structured attributes -- appearance, status, relation to the viewer, and relation to surrounding objects -- that explicitly capture spatial, temporal, and relational cues. This attribute-centric design supports interpretable and compositional grounding, enabling analysis that moves beyond simple object recognition to contextual reasoning in dynamic environments. We envision Talk2Event as a foundation for advancing multimodal and temporally-aware perception, with applications spanning robotics, human-AI interaction, and so on.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09581v1" target="_blank">Programmable 200 GOPS Hopfield-inspired photonic Ising machine</a></h3>
                    <p><strong>Authors:</strong> Nayem AL-Kayed, Charles St-Arnault, Hugh Morison, A. Aadhi, Chaoran Huang, Alexander N. Tait, David V. Plant, Bhavin J. Shastri</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> physics.optics, physics.app-ph</p>
                    <p><strong>Summary:</strong> Ising machines offer a compelling approach to addressing NP-hard problems, but physical realizations that are simultaneously scalable, reconfigurable, fast, and stable remain elusive. Quantum annealers, like D-Waves cryogenic hardware, target combinatorial optimization tasks, but quadratic scaling of qubit requirements with problem size limits their scalability on dense graphs. Here, we introduce a programmable, stable, room-temperature optoelectronic oscillator (OEO)-based Ising machine with linear scaling in spin representation. Inspired by Hopfield networks, our architecture solves fully-connected problems with up to 256 spins (65,536 couplings), and $$41,000 spins (205,000+ couplings) if sparse. Our system leverages cascaded thin-film lithium niobate modulators, a semiconductor optical amplifier, and a digital signal processing (DSP) engine in a recurrent time-encoded loop, demonstrating potential $$200 giga-operations per second for spin coupling and nonlinearity. This platform achieves the largest spin configuration in an OEO-based photonic Ising machine, enabled by high intrinsic speed. We experimentally demonstrate best-in-class solution quality for Max-Cut problems of arbitrary graph topologies (2,000 and 20,000 spins) among photonic Ising machines and obtain ground-state solutions for number partitioning and lattice protein folding - benchmarks previously unaddressed by photonic systems. Our system leverages inherent noise from high baud rates to escape local minima and accelerate convergence. Finally, we show that embedding DSP - traditionally used in optical communications - within optical computation enhances convergence and solution quality, opening new frontiers in scalable, ultrafast computing for optimization, neuromorphic processing, and analog AI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09576v1" target="_blank">Build-up and survival of the disc: From numerical models of galaxy formation to the Milky Way</a></h3>
                    <p><strong>Authors:</strong> Matthew D. A. Orkney, Chervin F. P. Laporte</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> astro-ph.GA</p>
                    <p><strong>Summary:</strong> We study the build-up and survival of angular momentum in the stellar disc using a statistical suite of cosmological simulations of Milky Way-mass galaxies. Our results show that stellar kinematics at $z=0$ rarely recover the true times of disc spin-up, due to the disruptive impact of massive radial merger events. The proto-disc (i.e. Aurora) and kicked-up disc stars (the Splash) become indistinguishable at low metallicities, and the local fraction of kicked-up disc stars remains $ 0.75$. This places strong constraints on the merger ratio between the proto-Milky Way and its last significant merger (Gaia-Sausage Enceladus, GSE), favouring values of $\lesssim 1:7$. We present the age-metallicity relation for the stellar halo and estimate the interaction epoch at $\tau_{\rm{spin\text{-}up}}\simeq\tau_{\rm{GSE}}\sim11\,\rm{Gyr}$. We note an abrupt dearth of halo and Splash stars after a lookback time of $10\,\rm{Gyr}$, marking the end of the merger interaction. Finally, we show that Globular Clusters in the metallicity range $-0.8\rm{[Fe/H]}-0.3$ align with a formation time of $\tau_{\rm{starburst}}\sim11\,\rm{Gyr}$, which we interpret as a signature of a starburst triggered by the first pericentric interaction of the GSE. This is remarkable corroboration between our GSE interaction and starburst times of $\tau_{\rm GSE}=\tau_{\rm starburst} \sim 11\,$Gyr.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09560v1" target="_blank">Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution</a></h3>
                    <p><strong>Authors:</strong> Shulai Zhang, Ao Xu, Quan Chen, Han Zhao, Weihao Cui, Ningxin Zheng, Haibin Lin, Xin Liu, Minyi Guo</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Embodied AI systems operate in dynamic environments, requiring seamless integration of perception and generation modules to process high-frequency input and output demands. Traditional sequential computation patterns, while effective in ensuring accuracy, face significant limitations in achieving the necessary thinking frequency for real-world applications. In this work, we present Auras, an algorithm-system co-designed inference framework to optimize the inference frequency of embodied AI agents. Auras disaggregates the perception and generation and provides controlled pipeline parallelism for them to achieve high and stable throughput. Faced with the data staleness problem that appears when the parallelism is increased, Auras establishes a public context for perception and generation to share, thereby promising the accuracy of embodied agents. Experimental results show that Auras improves throughput by 2.54x on average while achieving 102.7% of the original accuracy, demonstrating its efficacy in overcoming the constraints of sequential computation and providing high throughput.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09555v1" target="_blank">InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation</a></h3>
                    <p><strong>Authors:</strong> Sirui Xu, Dongting Li, Yucheng Zhang, Xiyan Xu, Qi Long, Ziyin Wang, Yunzhi Lu, Shuchang Dong, Hezi Jiang, Akshat Gupta, Yu-Xiong Wang, Liang-Yan Gui</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> While large-scale human motion capture datasets have advanced human motion generation, modeling and generating dynamic 3D human-object interactions (HOIs) remain challenging due to dataset limitations. Existing datasets often lack extensive, high-quality motion and annotation and exhibit artifacts such as contact penetration, floating, and incorrect hand motions. To address these issues, we introduce InterAct, a large-scale 3D HOI benchmark featuring dataset and methodological advancements. First, we consolidate and standardize 21.81 hours of HOI data from diverse sources, enriching it with detailed textual annotations. Second, we propose a unified optimization framework to enhance data quality by reducing artifacts and correcting hand motions. Leveraging the principle of contact invariance, we maintain human-object relationships while introducing motion variations, expanding the dataset to 30.70 hours. Third, we define six benchmarking tasks and develop a unified HOI generative modeling perspective, achieving state-of-the-art performance. Extensive experiments validate the utility of our dataset as a foundational resource for advancing 3D human-object interaction generation. To support continued research in this area, the dataset is publicly available at https://github.com/wzyabcas/InterAct, and will be actively maintained.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09547v1" target="_blank">Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders</a></h3>
                    <p><strong>Authors:</strong> Dohun Lee, Hyeonho Jeong, Jiwook Kim, Duygu Ceylan, Jong Chul Ye</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Video diffusion models have advanced rapidly in the recent years as a result of series of architectural innovations (e.g., diffusion transformers) and use of novel training objectives (e.g., flow matching). In contrast, less attention has been paid to improving the feature representation power of such models. In this work, we show that training video diffusion models can benefit from aligning the intermediate features of the video generator with feature representations of pre-trained vision encoders. We propose a new metric and conduct an in-depth analysis of various vision encoders to evaluate their discriminability and temporal consistency, thereby assessing their suitability for video feature alignment. Based on the analysis, we present Align4Gen which provides a novel multi-feature fusion and alignment method integrated into video diffusion model training. We evaluate Align4Gen both for unconditional and class-conditional video generation tasks and show that it results in improved video generation as quantified by various metrics. Full video results are available on our project page: https://align4gen.github.io/align4gen/</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09544v1" target="_blank">Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)</a></h3>
                    <p><strong>Authors:</strong> Paolo Pedinotti, Peter Baumann, Nathan Jessurun, Leslie Barrett, Enrico Santus</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling new tasks and driving a proliferation of datasets and diversification of data sources. Yet, this transformation has outpaced traditional surveys. In this paper, we present MetaGraph, a generalizable methodology for extracting knowledge graphs from scientific literature and analyzing them to obtain a structured, queryable view of research trends. We define an ontology for financial NLP research and apply an LLM-based extraction pipeline to 681 papers (2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals three key phases: early LLM adoption and task/dataset innovation; critical reflection on LLM limitations; and growing integration of peripheral techniques into modular systems. This structured view offers both practitioners and researchers a clear understanding of how financial NLP has evolved - highlighting emerging trends, shifting priorities, and methodological shifts-while also demonstrating a reusable approach for mapping scientific progress in other domains.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09541v1" target="_blank">Compositional Concept Generalization with Variational Quantum Circuits</a></h3>
                    <p><strong>Authors:</strong> Hala Hawashin, Mina Abbaszadeh, Nicholas Joseph, Beth Pearson, Martha Lewis, Mehrnoosh sadrzadeh</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Compositional generalization is a key facet of human cognition, but lacking in current AI tools such as vision-language models. Previous work examined whether a compositional tensor-based sentence semantics can overcome the challenge, but led to negative results. We conjecture that the increased training efficiency of quantum models will improve performance in these tasks. We interpret the representations of compositional tensor-based models in Hilbert spaces and train Variational Quantum Circuits to learn these representations on an image captioning task requiring compositional generalization. We used two image encoding techniques: a multi-hot encoding (MHE) on binary image vectors and an angle/amplitude encoding on image vectors taken from the vision-language model CLIP. We achieve good proof-of-concept results using noisy MHE encodings. Performance on CLIP image vectors was more mixed, but still outperformed classical compositional models.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09537v1" target="_blank">PARROT: Portable Android Reproducible traffic Observation Tool</a></h3>
                    <p><strong>Authors:</strong> Andrea Jimenez-Berenguel, Celeste Campo, Marta Moure-Garrido, Carlos Garcia-Rubio, Daniel DÃ­az-Sanchez, Florina Almenares</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.NI</p>
                    <p><strong>Summary:</strong> The rapid evolution of mobile security protocols and limited availability of current datasets constrains research in app traffic analysis. This paper presents PARROT, a reproducible and portable traffic capture system for systematic app traffic collection using Android Virtual Devices. The system provides automated environment setup, configurable Android versions, traffic recording management, and labeled captures extraction with human-in-the-loop app interaction. PARROT integrates mitmproxy for optional traffic decryption with automated SSL/TLS key extraction, supporting flexible capture modes with or without traffic interception. We collected a dataset of 80 apps selected from the MAppGraph dataset list, providing traffic captures with corresponding SSL keys for decryption analysis. Our comparative analysis between the MAppGraph dataset (2021) and our dataset (2025) reveals app traffic pattern evolution across 50 common apps. Key findings include migration from TLSv1.2 to TLSv1.3 protocol, with TLSv1.3 comprising 90.0\% of TCP encrypted traffic in 2025 compared to 6.7\% in 2021. QUIC protocol adoption increased substantially, with all 50 common apps generating QUIC traffic under normal network conditions compared to 30 apps in 2021. DNS communications evolved from predominantly unencrypted Do53 protocol (91.0\% in 2021) to encrypted DoT protocol (81.1\% in 2025). The open-source PARROT system enables reproducible app traffic capture for research community adoption and provides insights into app security protocol evolution.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09532v1" target="_blank">XUV fluorescence as a probe of interatomic Coulombic decay of resonantly excited He nanodroplets</a></h3>
                    <p><strong>Authors:</strong> Keshav Sishodia, Ltaief Ben Ltaief, Niklas Scheel, IstvÃ¡n B. FÃ¶ldes, Andreas Hult Roos, Martin Albrecht, MatyÃ¡Å¡ StanÄ›k, Lucie JurkoviÄovÃ¡, Ondrej Hort, Jaroslav Nejdl, Ernesto GarcÃ­a-Alfonso, Nadine Halberstadt, Jakob Andreasson, Eva KlimeÅ¡ovÃ¡, Maria Krikunova, Sivarama Krishnan, Andreas Heidenreich, Marcel Mudrich</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> physics.atm-clus</p>
                    <p><strong>Summary:</strong> Superfluid He nanodroplets resonantly excited by extreme ultraviolet (XUV) pulses exhibit complex relaxation dynamics, including the formation of metastable excited He$^*$ atoms trapped in bubbles, the desorption of excited atoms from the droplet surface, and autoionization via interatomic Coulombic decay (ICD). Irradiation with intense infrared pulses can trigger avalanche ionization, leading to the formation and subsequent expansion of a He nanoplasma. Here, we introduce a novel approach to probe the ICD dynamics over timescales spanning femtoseconds to nanoseconds. Our method exploits the efficient ignition of a nanoplasma through tunnel ionization of excited helium atoms attached to the droplets and the detection of XUV fluorescence emitted from the resulting nanoplasma. Using quantum mechanical and classical calculations, we interpret the nanosecond fluorescence decay as a signature of ICD mediated by He$^*$ freely roaming on the nanodroplet surface.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09522v1" target="_blank">Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs</a></h3>
                    <p><strong>Authors:</strong> Vadim Zadykian, Bruno Andrade, Haithem Afli</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> Semantic Textual Relatedness (STR) captures nuanced relationships between texts that extend beyond superficial lexical similarity. In this study, we investigate STR in the context of job title matching - a key challenge in resume recommendation systems, where overlapping terms are often limited or misleading. We introduce a self-supervised hybrid architecture that combines dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to improve both semantic alignment and explainability. Unlike previous work that evaluated models on aggregate performance, our approach emphasizes data stratification by partitioning the STR score continuum into distinct regions: low, medium, and high semantic relatedness. This stratified evaluation enables a fine-grained analysis of model performance across semantically meaningful subspaces. We evaluate several embedding models, both with and without KG integration via graph neural networks. The results show that fine-tuned SBERT models augmented with KGs produce consistent improvements in the high-STR region, where the RMSE is reduced by 25% over strong baselines. Our findings highlight not only the benefits of combining KGs with text embeddings, but also the importance of regional performance analysis in understanding model behavior. This granular approach reveals strengths and weaknesses hidden by global metrics, and supports more targeted model selection for use in Human Resources (HR) systems and applications where fairness, explainability, and contextual matching are essential.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09513v1" target="_blank">Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner</a></h3>
                    <p><strong>Authors:</strong> Quentin Uhl, Tommaso Pavan, Julianna Gerold, Kwok-Shing Chan, Yohan Jun, Shohei Fujita, Aneri Bhatt, Yixin Ma, Qiaochu Wang, Hong-Hsi Lee, Susie Y. Huang, Berkin Bilgic, Ileana Jelescu</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> physics.med-ph, cs.AI, cs.CV, cs.LG, eess.IV, J.3</p>
                    <p><strong>Summary:</strong> The diffusion MRI Neurite Exchange Imaging model offers a promising framework for probing gray matter microstructure by estimating parameters such as compartment sizes, diffusivities, and inter-compartmental water exchange time. However, existing protocols require long scan times. This study proposes a reduced acquisition scheme for the Connectome 2.0 scanner that preserves model accuracy while substantially shortening scan duration. We developed a data-driven framework using explainable artificial intelligence with a guided recursive feature elimination strategy to identify an optimal 8-feature subset from a 15-feature protocol. The performance of this optimized protocol was validated in vivo and benchmarked against the full acquisition and alternative reduction strategies. Parameter accuracy, preservation of anatomical contrast, and test-retest reproducibility were assessed. The reduced protocol yielded parameter estimates and cortical maps comparable to the full protocol, with low estimation errors in synthetic data and minimal impact on test-retest variability. Compared to theory-driven and heuristic reduction schemes, the optimized protocol demonstrated superior robustness, reducing the deviation in water exchange time estimates by over two-fold. In conclusion, this hybrid optimization framework enables viable imaging of neurite exchange in 14 minutes without loss of parameter fidelity. This approach supports the broader application of exchange-sensitive diffusion magnetic resonance imaging in neuroscience and clinical research, and offers a generalizable method for designing efficient acquisition protocols in biophysical parameter mapping.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09512v1" target="_blank">PIPES: A Meta-dataset of Machine Learning Pipelines</a></h3>
                    <p><strong>Authors:</strong> Cynthia Moreira Maia, Lucas B. V. de Amorim, George D. C. Cavalcanti, Rafael M. O. Cruz</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Solutions to the Algorithm Selection Problem (ASP) in machine learning face the challenge of high computational costs associated with evaluating various algorithms performances on a given dataset. To mitigate this cost, the meta-learning field can leverage previously executed experiments shared in online repositories such as OpenML. OpenML provides an extensive collection of machine learning experiments. However, an analysis of OpenMLs records reveals limitations. It lacks diversity in pipelines, specifically when exploring data preprocessing steps/blocks, such as scaling or imputation, resulting in limited representation. Its experiments are often focused on a few popular techniques within each pipeline block, leading to an imbalanced sample. To overcome the observed limitations of OpenML, we propose PIPES, a collection of experiments involving multiple pipelines designed to represent all combinations of the selected sets of techniques, aiming at diversity and completeness. PIPES stores the results of experiments performed applying 9,408 pipelines to 300 datasets. It includes detailed information on the pipeline blocks, training and testing times, predictions, performances, and the eventual error messages. This comprehensive collection of results allows researchers to perform analyses across diverse and representative pipelines and datasets. PIPES also offers potential for expansion, as additional data and experiments can be incorporated to support the meta-learning community further. The data, code, supplementary material, and all experiments can be found at https://github.com/cynthiamaia/PIPES.git.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09510v1" target="_blank">Cognitive Affordances in Visualization: Related Constructs, Design Factors, and Framework</a></h3>
                    <p><strong>Authors:</strong> Racquel Fygenson, Lace Padilla, Enrico Bertini</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> Classically, affordance research investigates how the shape of objects communicates actions to potential users. Cognitive affordances, a subset of this research, characterize how the design of objects influences cognitive actions, such as information processing. Within visualization, cognitive affordances inform how graphs design decisions communicate information to their readers. Although several related concepts exist in visualization, a formal translation of affordance theory to visualization is still lacking. In this paper, we review and translate affordance theory to visualization by formalizing how cognitive affordances operate within a visualization context. We also review common methods and terms, and compare related constructs to cognitive affordances in visualization. Based on a synthesis of research from psychology, human computer interaction, and visualization, we propose a framework of cognitive affordances in visualization that enumerates design decisions and reader characteristics that influence a visualizations hierarchy of communicated information. Finally, we demonstrate how this framework can guide the evaluation and redesign of visualizations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09509v1" target="_blank">SMapper: A Multi-Modal Data Acquisition Platform for SLAM Benchmarking</a></h3>
                    <p><strong>Authors:</strong> Pedro Miguel Bastos Soares, Ali Tourani, Miguel Fernandez-Cortizas, Asier Bikandi Noya, Jose Luis Sanchez-Lopez, Holger Voos</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Advancing research in fields like Simultaneous Localization and Mapping (SLAM) and autonomous navigation critically depends on reliable and reproducible multimodal datasets. While several influential datasets have driven progress in these domains, they often suffer from limitations in sensing modalities, environmental diversity, and the reproducibility of the underlying hardware setups. To address these challenges, this paper introduces SMapper, a novel open-hardware, multi-sensor platform designed explicitly for, though not limited to, SLAM research. The device integrates synchronized LiDAR, multi-camera, and inertial sensing, supported by a robust calibration and synchronization pipeline that ensures precise spatio-temporal alignment across modalities. Its open and replicable design allows researchers to extend its capabilities and reproduce experiments across both handheld and robot-mounted scenarios. To demonstrate its practicality, we additionally release SMapper-light, a publicly available SLAM dataset containing representative indoor and outdoor sequences. The dataset includes tightly synchronized multimodal data and ground-truth trajectories derived from offline LiDAR-based SLAM with sub-centimeter accuracy, alongside dense 3D reconstructions. Furthermore, the paper contains benchmarking results on state-of-the-art LiDAR and visual SLAM frameworks using the SMapper-light dataset. By combining open-hardware design, reproducible data collection, and comprehensive benchmarking, SMapper establishes a robust foundation for advancing SLAM algorithm development, evaluation, and reproducibility.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09508v1" target="_blank">Incorporating AI Incident Reporting into Telecommunications Law and Policy: Insights from India</a></h3>
                    <p><strong>Authors:</strong> Avinash Agarwal, Manisha J. Nene</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CY, cs.AI, cs.HC</p>
                    <p><strong>Summary:</strong> The integration of artificial intelligence (AI) into telecommunications infrastructure introduces novel risks, such as algorithmic bias and unpredictable system behavior, that fall outside the scope of traditional cybersecurity and data protection frameworks. This paper introduces a precise definition and a detailed typology of telecommunications AI incidents, establishing them as a distinct category of risk that extends beyond conventional cybersecurity and data protection breaches. It argues for their recognition as a distinct regulatory concern. Using India as a case study for jurisdictions that lack a horizontal AI law, the paper analyzes the countrys key digital regulations. The analysis reveals that Indias existing legal instruments, including the Telecommunications Act, 2023, the CERT-In Rules, and the Digital Personal Data Protection Act, 2023, focus on cybersecurity and data breaches, creating a significant regulatory gap for AI-specific operational incidents, such as performance degradation and algorithmic bias. The paper also examines structural barriers to disclosure and the limitations of existing AI incident repositories. Based on these findings, the paper proposes targeted policy recommendations centered on integrating AI incident reporting into Indias existing telecom governance. Key proposals include mandating reporting for high-risk AI failures, designating an existing government body as a nodal agency to manage incident data, and developing standardized reporting frameworks. These recommendations aim to enhance regulatory clarity and strengthen long-term resilience, offering a pragmatic and replicable blueprint for other nations seeking to govern AI risks within their existing sectoral frameworks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09505v1" target="_blank">Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference</a></h3>
                    <p><strong>Authors:</strong> Haoran Wu, Can Xiao, Jiayi Nie, Xuan Guo, Binglei Lou, Jeffrey T. H. Wong, Zhiwen Mo, Cheng Zhang, Przemyslaw Forys, Wayne Luk, Hongxiang Fan, Jianyi Cheng, Timothy M. Jones, Rika Antonova, Robert Mullins, Aaron Zhao</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> LLMs now form the backbone of AI agents for a diverse array of applications, including tool use, command-line agents, and web or computer use agents. These agentic LLM inference tasks are fundamentally different from chatbot-focused inference -- they often have much larger context lengths to capture complex, prolonged inputs, such as entire webpage DOMs or complicated tool call trajectories. This, in turn, generates significant off-chip memory traffic for the underlying hardware at the inference stage and causes the workload to be constrained by two memory walls, namely the bandwidth and capacity memory walls, preventing the on-chip compute units from achieving high utilization. In this paper, we introduce PLENA, a hardware-software co-designed system that applies three core optimization pathways to tackle these challenges. PLENA includes an efficient hardware implementation of compute and memory units supporting an asymmetric quantization scheme. PLENA also features a novel flattened systolic array architecture that has native support for FlashAttention to tackle these memory walls in the scenario of inference serving for long-context LLMs. Additionally, PLENA is developed with a complete stack, including a custom ISA, a compiler, a cycle-emulated simulator, and an automated design space exploration flow. The simulated results show that PLENA achieves up to 8.5x higher utilization than existing accelerators, and delivers 2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the TPU v6e, under the same multiplier count and memory settings. The full PLENA system will also be open-sourced.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09499v1" target="_blank">Mixture of Semantics Transmission for Generative AI-Enabled Semantic Communication Systems</a></h3>
                    <p><strong>Authors:</strong> Junjie Ni, Tong Wu, Zhiyong Chen, Yin Xu, Meixia Tao, Wenjun Zhang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.IT, math.IT</p>
                    <p><strong>Summary:</strong> In this paper, we propose a mixture of semantics (MoS) transmission strategy for wireless semantic communication systems based on generative artificial intelligence (AI). At the transmitter, we divide an image into regions of interest (ROI) and reigons of non-interest (RONI) to extract their semantic information respectively. Semantic information of ROI can be allocated more bandwidth, while RONI can be represented in a compact form for transmission. At the receiver, a diffusion model reconstructs the full image using the received semantic information of ROI and RONI. Compared to existing generative AI-based methods, MoS enables more efficient use of channel resources by balancing visual fidelity and semantic relevance. Experimental results demonstrate that appropriate ROI-RONI allocation is critical. The MoS achieves notable performance gains in peak signal-to-noise ratio (PSNR) of ROI and CLIP score of RONI.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09498v1" target="_blank">SEDM: Scalable Self-Evolving Distributed Memory for Agents</a></h3>
                    <p><strong>Authors:</strong> Haoran Xu, Jiacong Hu, Ke Zhang, Lei Yu, Yuxin Tang, Xinyuan Song, Yiqun Duan, Lynn Ai, Bill Shi</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Long-term multi-agent systems inevitably generate vast amounts of trajectories and historical interactions, which makes efficient memory management essential for both performance and scalability. Existing methods typically depend on vector retrieval and hierarchical storage, yet they are prone to noise accumulation, uncontrolled memory expansion, and limited generalization across domains. To address these challenges, we present SEDM, Self-Evolving Distributed Memory, a verifiable and adaptive framework that transforms memory from a passive repository into an active, self-optimizing component. SEDM integrates verifiable write admission based on reproducible replay, a self-scheduling memory controller that dynamically ranks and consolidates entries according to empirical utility, and cross-domain knowledge diffusion that abstracts reusable insights to support transfer across heterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM improves reasoning accuracy while reducing token overhead compared with strong memory baselines, and further enables knowledge distilled from fact verification to enhance multi-hop reasoning. The results highlight SEDM as a scalable and sustainable memory mechanism for open-ended multi-agent collaboration. The code will be released in the later stage of this project.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09495v1" target="_blank">OpenFake: An Open Dataset and Platform Toward Large-Scale Deepfake Detection</a></h3>
                    <p><strong>Authors:</strong> Victor Livernoche, Akshatha Arodi, Andreea Musulan, Zachary Yang, Adam Salvail, GaÃ©tan Marceau Caron, Jean-FranÃ§ois Godbout, Reihaneh Rabbany</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI, cs.LG, I.4.9; I.5.4; I.2.10</p>
                    <p><strong>Summary:</strong> Deepfakes, synthetic media created using advanced AI techniques, have intensified the spread of misinformation, particularly in politically sensitive contexts. Existing deepfake detection datasets are often limited, relying on outdated generation methods, low realism, or single-face imagery, restricting the effectiveness for general synthetic image detection. By analyzing social media posts, we identify multiple modalities through which deepfakes propagate misinformation. Furthermore, our human perception study demonstrates that recently developed proprietary models produce synthetic images increasingly indistinguishable from real ones, complicating accurate identification by the general public. Consequently, we present a comprehensive, politically-focused dataset specifically crafted for benchmarking detection against modern generative models. This dataset contains three million real images paired with descriptive captions, which are used for generating 963k corresponding high-quality synthetic images from a mix of proprietary and open-source models. Recognizing the continual evolution of generative techniques, we introduce an innovative crowdsourced adversarial platform, where participants are incentivized to generate and submit challenging synthetic images. This ongoing community-driven initiative ensures that deepfake detection methods remain robust and adaptive, proactively safeguarding public discourse from sophisticated misinformation threats.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09494v1" target="_blank">In-Loop Filtering Using Learned Look-Up Tables for Video Coding</a></h3>
                    <p><strong>Authors:</strong> Zhuoyuan Li, Jiacheng Li, Yao Li, Jialin Li, Li Li, Dong Liu, Feng Wu</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> eess.IV, cs.CV, cs.MM</p>
                    <p><strong>Summary:</strong> In-loop filtering (ILF) is a key technology in video coding standards to reduce artifacts and enhance visual quality. Recently, neural network-based ILF schemes have achieved remarkable coding gains, emerging as a powerful candidate for next-generation video coding standards. However, the use of deep neural networks (DNN) brings significant computational and time complexity or high demands for dedicated hardware, making it challenging for general use. To address this limitation, we study a practical ILF solution by adopting look-up tables (LUTs). After training a DNN with a restricted reference range for ILF, all possible inputs are traversed, and the output values of the DNN are cached into LUTs. During the coding process, the filtering process is performed by simply retrieving the filtered pixel through locating the input pixels and interpolating between the cached values, instead of relying on heavy inference computations. In this paper, we propose a universal LUT-based ILF framework, termed LUT-ILF++. First, we introduce the cooperation of multiple kinds of filtering LUTs and propose a series of customized indexing mechanisms to enable better filtering reference perception with limited storage consumption. Second, we propose the cross-component indexing mechanism to enable the filtering of different color components jointly. Third, in order to make our solution practical for coding uses, we propose the LUT compaction scheme to enable the LUT pruning, achieving a lower storage cost of the entire solution. The proposed framework is implemented in the VVC reference software. Experimental results show that the proposed framework achieves on average 0.82%/2.97%/1.63% and 0.85%/4.11%/2.06% bitrate reduction for common test sequences, under the AI and RA configurations, respectively. Compared to DNN-based solutions, our proposed solution has much lower time complexity and storage cost.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.21125/edulearn.2025.2268" target="_blank">Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation</a></h3>
                    <p><strong>Authors:</strong> Lucie PolÃ¡kovÃ¡, Martin Popel, VÄ›ra KloudovÃ¡, Michal NovÃ¡k, Mariia Anisimova, JiÅ™Ã­ Balhar</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The EdUKate project combines digital education, linguistics, translation studies, and machine translation to develop multilingual learning materials for Czech primary and secondary schools. Launched through collaboration between a major Czech academic institution and the countrys largest educational publisher, the project is aimed at translating up to 9,000 multimodal interactive exercises from Czech into Ukrainian, English, and German for an educational web portal. It emphasizes the development and evaluation of a direct Czech-Ukrainian machine translation system tailored to the educational domain, with special attention to processing formatted content such as XML and PDF and handling technical and scientific terminology. We present findings from an initial survey of Czech teachers regarding the needs of non-Czech-speaking students and describe the systems evaluation and implementation on the web portal. All resulting applications are freely available to students, educators, and researchers.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09470v1" target="_blank">AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings</a></h3>
                    <p><strong>Authors:</strong> Om Vishesh, Harshad Khadilkar, Deepak Akkil</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Keeping pace with the rapid growth of academia literature presents a significant challenge for researchers, funding bodies, and academic societies. To address the time-consuming manual effort required for scholarly discovery, we present a novel, fully automated system that transitions from data discovery to direct action. Our pipeline demonstrates how a specialized AI agent, Agent-E, can be tasked with identifying papers from specific geographic regions within conference proceedings and then executing a Robotic Process Automation (RPA) to complete a predefined action, such as submitting a nomination form. We validated our system on 586 papers from five different conferences, where it successfully identified every target paper with a recall of 100% and a near perfect accuracy of 99.4%. This demonstration highlights the potential of task-oriented AI agents to not only filter information but also to actively participate in and accelerate the workflows of the academic community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09469v1" target="_blank">Resource-Efficient Glioma Segmentation on Sub-Saharan MRI</a></h3>
                    <p><strong>Authors:</strong> Freedmore Sidume, Oumayma Soula, Joseph Muthui Wacira, YunFei Zhu, Abbas Rabiu Muhammad, Abderrazek Zeraii, Oluwaseun Kalejaye, Hajer Ibrahim, Olfa Gaddour, Brain Halubanza, Dong Zhang, Udunna C Anazodo, Confidence Raymond</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.AI</p>
                    <p><strong>Summary:</strong> Gliomas are the most prevalent type of primary brain tumors, and their accurate segmentation from MRI is critical for diagnosis, treatment planning, and longitudinal monitoring. However, the scarcity of high-quality annotated imaging data in Sub-Saharan Africa (SSA) poses a significant challenge for deploying advanced segmentation models in clinical workflows. This study introduces a robust and computationally efficient deep learning framework tailored for resource-constrained settings. We leveraged a 3D Attention UNet architecture augmented with residual blocks and enhanced through transfer learning from pre-trained weights on the BraTS 2021 dataset. Our model was evaluated on 95 MRI cases from the BraTS-Africa dataset, a benchmark for glioma segmentation in SSA MRI data. Despite the limited data quality and quantity, our approach achieved Dice scores of 0.76 for the Enhancing Tumor (ET), 0.80 for Necrotic and Non-Enhancing Tumor Core (NETC), and 0.85 for Surrounding Non-Functional Hemisphere (SNFH). These results demonstrate the generalizability of the proposed model and its potential to support clinical decision making in low-resource settings. The compact architecture, approximately 90 MB, and sub-minute per-volume inference time on consumer-grade hardware further underscore its practicality for deployment in SSA health systems. This work contributes toward closing the gap in equitable AI for global health by empowering underserved regions with high-performing and accessible medical imaging solutions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09467v1" target="_blank">Inteligencia Artificial jurÃ­dica y el desafÃ­o de la veracidad: anÃ¡lisis de alucinaciones, optimizaciÃ³n de RAG y principios para una integraciÃ³n responsable</a></h3>
                    <p><strong>Authors:</strong> Alex Dantart</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> This technical report analyzes the challenge of hallucinations (false information) in LLMs applied to law. It examines their causes, manifestations, and the effectiveness of the RAG mitigation strategy, highlighting its limitations and proposing holistic optimizations. The paper explores the ethical and regulatory implications, emphasizing human oversight as an irreplaceable role. It concludes that the solution lies not in incrementally improving generative models, but in adopting a consultative AI paradigm that prioritizes veracity and traceability, acting as a tool to amplify, not replace, professional judgment. -- Este informe t\ecnico analiza el desaf\io de las alucinaciones (informaci\on falsa) en los LLMs aplicados al derecho. Se examinan sus causas, manifestaciones y la efectividad de la estrategia de mitigaci\on RAG, exponiendo sus limitaciones y proponiendo optimizaciones hol\isticas. Se exploran las implicaciones \eticas y regulatorias, enfatizando la supervisi\on humana como un rol insustituible. El documento concluye que la soluci\on no reside en mejorar incrementalmente los modelos generativos, sino en adoptar un paradigma de IA consultiva que priorice la veracidad y la trazabilidad, actuando como una herramienta para amplificar, y no sustituir, el juicio profesional.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09459v1" target="_blank">Boosting Data Utilization for Multilingual Dense Retrieval</a></h3>
                    <p><strong>Authors:</strong> Chao Huang, Fengran Mo, Yufeng Chen, Changhao Guan, Zhenrui Yue, Xinyu Wang, Jinan Xu, Kaiyu Huang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.IR</p>
                    <p><strong>Summary:</strong> Multilingual dense retrieval aims to retrieve relevant documents across different languages based on a unified retriever model. The challenge lies in aligning representations of different languages in a shared vector space. The common practice is to fine-tune the dense retriever via contrastive learning, whose effectiveness highly relies on the quality of the negative sample and the efficacy of mini-batch data. Different from the existing studies that focus on developing sophisticated model architecture, we propose a method to boost data utilization for multilingual dense retrieval by obtaining high-quality hard negative samples and effective mini-batch data. The extensive experimental results on a multilingual retrieval benchmark, MIRACL, with 16 languages demonstrate the effectiveness of our method by outperforming several existing strong baselines.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09443v1" target="_blank">On realisations of the Steenrod algebras</a></h3>
                    <p><strong>Authors:</strong> Alexei Lebedev, Dimitry Leites</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> math.AG, 55S10</p>
                    <p><strong>Summary:</strong> The Steenrod algebra can not be realised as an enveloping of any Lie superalgebra. We list several problems that suggest a need to modify the definition of the enveloping algebra, for example, to get rid of certain strange deformations which we qualify as an artefact of the inadequate definition of the enveloping algebra in positive characteristic. P. Deligne appended our paper with his comments, hints and open problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09438v1" target="_blank">GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Zhaohan Zhang, Ziquan Liu, Ioannis Patras</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> Assessing the reliability of Large Language Models (LLMs) by confidence elicitation is a prominent approach to AI safety in high-stakes applications, such as healthcare and finance. Existing methods either require expensive computational overhead or suffer from poor calibration, making them impractical and unreliable for real-world deployment. In this work, we propose GrACE, a Generative Approach to Confidence Elicitation that enables scalable and reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in which the model expresses confidence by the similarity between the last hidden state and the embedding of a special token appended to the vocabulary, in real-time. We fine-tune the model for calibrating the confidence with calibration targets associated with accuracy. Experiments with three LLMs and two benchmark datasets show that the confidence produced by GrACE achieves the best discriminative capacity and calibration on open-ended generation tasks, outperforming six competing methods without resorting to additional sampling or an auxiliary model. Moreover, we propose two strategies for improving test-time scaling based on confidence induced by GrACE. Experimental results show that using GrACE not only improves the accuracy of the final decision but also significantly reduces the number of required samples in the test-time scaling scheme, indicating the potential of GrACE as a practical solution for deploying LLMs with scalable, reliable, and real-time confidence estimation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09429v1" target="_blank">Semantic Concentration for Self-Supervised Dense Representations Learning</a></h3>
                    <p><strong>Authors:</strong> Peisong Wen, Qianqian Xu, Siran Dai, Runmin Cong, Qingming Huang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.LG</p>
                    <p><strong>Summary:</strong> Recent advances in image-level self-supervised learning (SSL) have made significant progress, yet learning dense representations for patches remains challenging. Mainstream methods encounter an over-dispersion phenomenon that patches from the same instance/category scatter, harming downstream performance on dense tasks. This work reveals that image-level SSL avoids over-dispersion by involving implicit semantic concentration. Specifically, the non-strict spatial alignment ensures intra-instance consistency, while shared patterns, i.e., similar parts of within-class instances in the input space, ensure inter-image consistency. Unfortunately, these approaches are infeasible for dense SSL due to their spatial sensitivity and complicated scene-centric data. These observations motivate us to explore explicit semantic concentration for dense SSL. First, to break the strict spatial alignment, we propose to distill the patch correspondences. Facing noisy and imbalanced pseudo labels, we propose a noise-tolerant ranking loss. The core idea is extending the Average Precision (AP) loss to continuous targets, such that its decision-agnostic and adaptive focusing properties prevent the student model from being misled. Second, to discriminate the shared patterns from complicated scenes, we propose the object-aware filter to map the output space to an object-based space. Specifically, patches are represented by learnable prototypes of objects via cross-attention. Last but not least, empirical studies across various tasks soundly support the effectiveness of our method. Code is available in https://github.com/KID-7391/CoTAP.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09414v1" target="_blank">Were Still Doing It (All) Wrong: Recommender Systems, Fifteen Years Later</a></h3>
                    <p><strong>Authors:</strong> Alan Said, Maria Soledad Pera, Michael D. Ekstrand</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI</p>
                    <p><strong>Summary:</strong> In 2011, Xavier Amatriain sounded the alarm: recommender systems research was doing it all wrong [1]. His critique, rooted in statistical misinterpretation and methodological shortcuts, remains as relevant today as it was then. But rather than correcting course, we added new layers of sophistication on top of the same broken foundations. This paper revisits Amatriains diagnosis and argues that many of the conceptual, epistemological, and infrastructural failures he identified still persist, in more subtle or systemic forms. Drawing on recent work in reproducibility, evaluation methodology, environmental impact, and participatory design, we showcase how the fields accelerating complexity has outpaced its introspection. We highlight ongoing community-led initiatives that attempt to shift the paradigm, including workshops, evaluation frameworks, and calls for value-sensitive and participatory research. At the same time, we contend that meaningful change will require not only new metrics or better tooling, but a fundamental reframing of what recommender systems research is for, who it serves, and how knowledge is produced and validated. Our call is not just for technical reform, but for a recommender systems research agenda grounded in epistemic humility, human impact, and sustainable practice.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.5220/0013132600003912" target="_blank">Real-Time Kinematic Positioning and Optical See-Through Head-Mounted Display for Outdoor Tracking: Hybrid System and Preliminary Assessment</a></h3>
                    <p><strong>Authors:</strong> Muhannad Ismael, MaÃ«l Cornil</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC</p>
                    <p><strong>Summary:</strong> This paper presents an outdoor tracking system using Real-Time Kinematic (RTK) positioning and Optical See-Through Head Mounted Display(s) (OST-HMD(s)) in urban areas where the accurate tracking of objects is critical and where displaying occluded information is important for safety reasons. The approach presented here replaces 2D screens/tablets and offers distinct advantages, particularly in scenarios demanding hands-free operation. The integration of RTK, which provides centimeter-level accuracy of tracked objects, with OST-HMD represents a promising solution for outdoor applications. This paper provides valuable insights into leveraging the combined potential of RTK and OST-HMD for outdoor tracking tasks from the perspectives of systems integration, performance optimization, and usability. The main contributions of this paper are: \textbf{1)} a system for seamlessly merging RTK systems with OST-HMD to enable relatively precise and intuitive outdoor tracking, \textbf{2)} an approach to determine a global location to achieve the position relative to the world, \textbf{3)} an approach referred to as semi-dynamic for system assessment. Moreover, we offer insights into several relevant future research topics aimed at improving the OST-HMD and RTK hybrid system for outdoor tracking.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09397v1" target="_blank">Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift</a></h3>
                    <p><strong>Authors:</strong> Umaima Rahman, Raza Imam, Mohammad Yaqub, Dwarikanath Mahapatra</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Medical vision-language models (VLMs) offer promise for clinical decision support, yet their reliability under distribution shifts remains a major concern for safe deployment. These models often learn task-agnostic correlations due to variability in imaging protocols and free-text reports, limiting their generalizability and increasing the risk of failure in real-world settings. We propose DRiFt, a structured feature decoupling framework that explicitly separates clinically relevant signals from task-agnostic noise using parameter-efficient tuning (LoRA) and learnable prompt tokens. To enhance cross-modal alignment and reduce uncertainty, we curate high-quality, clinically grounded image-text pairs by generating captions for a diverse medical dataset. Our approach improves in-distribution performance by +11.4% Top-1 accuracy and +3.3% Macro-F1 over prior prompt-based methods, while maintaining strong robustness across unseen datasets. Ablation studies reveal that disentangling task-relevant features and careful alignment significantly enhance model generalization and reduce unpredictable behavior under domain shift. These insights contribute toward building safer, more trustworthy VLMs for clinical use. The code is available at https://github.com/rumaima/DRiFt.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09680v1" target="_blank">FLUX-Reason-6M  PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark</a></h3>
                    <p><strong>Authors:</strong> Rongyao Fang, Aldrich Yu, Chengqi Duan, Linjiang Huang, Shuai Bai, Yuxuan Cai, Kun Wang, Si Liu, Xihui Liu, Hongsheng Li</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV, cs.CL</p>
                    <p><strong>Summary:</strong> The advancement of open-source text-to-image (T2I) models has been hindered by the absence of large-scale, reasoning-focused datasets and comprehensive evaluation benchmarks, resulting in a performance gap compared to leading closed-source systems. To address this challenge, We introduce FLUX-Reason-6M and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark). FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality FLUX-generated images and 20 million bilingual (English and Chinese) descriptions specifically designed to teach complex reasoning. The image are organized according to six key characteristics: Imagination, Entity, Text rendering, Style, Affection, and Composition, and design explicit Generation Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation steps. The whole data curation takes 15,000 A100 GPU days, providing the community with a resource previously unattainable outside of large industrial labs. PRISM-Bench offers a novel evaluation standard with seven distinct tracks, including a formidable Long Text challenge using GCoT. Through carefully designed prompts, it utilizes advanced vision-language models for nuanced human-aligned assessment of prompt-image alignment and image aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench reveals critical performance gaps and highlights specific areas requiring improvement. Our dataset, benchmark, and evaluation code are released to catalyze the next wave of reasoning-oriented T2I generation. Project page: https://flux-reason-6m.github.io/ .</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09679v1" target="_blank">ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms</a></h3>
                    <p><strong>Authors:</strong> Bingxin Xu, Zhen Dong, Oussama Elachqar, Yuzhang Shang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Large language models require massive memory footprints, severely limiting deployment on consumer hardware. Quantization reduces memory through lower numerical precision, but extreme 2-bit quantization suffers from catastrophic performance loss due to outliers in activations. Rotation-based methods such as QuIP and QuaRot apply orthogonal transforms to eliminate outliers before quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} = (\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these methods use fixed transforms--Hadamard matrices achieving optimal worst-case coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight distributions. We identify that different transformer layers exhibit distinct outlier patterns, motivating layer-adaptive rotations rather than one-size-fits-all approaches. We propose ButterflyQuant, which replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles. Unlike Hadamards discrete $\{+1, -1\}$ entries that are non-differentiable and prohibit gradient-based learning, butterfly transforms continuous parameterization enables smooth optimization while guaranteeing orthogonality by construction. This orthogonal constraint ensures theoretical guarantees in outlier suppression while achieving $O(n \log n)$ computational complexity with only $\frac{n \log n}{2}$ learnable parameters. We further introduce a uniformity regularization on post-transformation activations to promote smoother distributions amenable to quantization. Learning requires only 128 calibration samples and converges in minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09678v1" target="_blank">Cosmic $Ï„$ensions Indirectly Correlate with Reionization Optical Depth</a></h3>
                    <p><strong>Authors:</strong> Itamar J. Allali, Lingfeng Li, Praniti Singh, JiJi Fan</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> astro-ph.CO, hep-ph</p>
                    <p><strong>Summary:</strong> The reionization optical depth $\tau_{\rm reio}$ has interesting connections to existing cosmological anomalies. As first studied in the context of the Hubble tension in our previous paper, a larger $\tau_{\rm reio}$, which could be achieved by removing the Planck low-$\ell$ polarization data, could boost $H_0$ slightly, resulting in a mild reduction of the tension between the early- and late-universe determinations of $H_0$. It has been shown later that a larger $\tau_{\rm reio}$ could also relieve other anomalies including: the tension between BAO and CMB data, the neutrino mass tension, and the latest DESI plus supernovae datas tension with the standard cosmological constant scenario. In this paper, we systematically analyze the correlations between $\tau_{\rm reio}$ and relevant cosmological parameters in the existing cosmic observation anomalies. In addition to Pearson correlation coefficients extracted directly from the covariance matrix, we also study partial correlation coefficients which measure intrinsic relationships between pairs of parameters removing the influence of other parameters. We show that $\tau_{\rm reio}$ has weak intrinsic correlations with the parameters responsible for the tensions and anomalies discussed. The large direct Pearson correlations that allow larger $\tau_{\rm reio}$ inferences to alleviate the cosmological tensions each arise from complicated networks through multiple parameters. As a result, the relationships between $\tau_{\rm reio}$ and each anomaly are not independent of each other. We also employ our method of computing correlations to clarify the impact of large scale polarization data, and comment also on the effects of CMB observations from ACT and SPT.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09677v1" target="_blank">The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs</a></h3>
                    <p><strong>Authors:</strong> Akshit Sinha, Arvindh Arun, Shashwat Goel, Steffen Staab, Jonas Geiping</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.AI</p>
                    <p><strong>Summary:</strong> Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09676v1" target="_blank">SpatialVID: A Large-Scale Video Dataset with Spatial Annotations</a></h3>
                    <p><strong>Authors:</strong> Jiahao Wang, Yufeng Yuan, Rujie Zheng, Youtian Lin, Jian Gao, Lin-Zhuo Chen, Yajie Bao, Yi Zhang, Chang Zeng, Yanxi Zhou, Xiaoxiao Long, Hao Zhu, Zhaoxiang Zhang, Xun Cao, Yao Yao</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Significant progress has been made in spatial intelligence, spanning both spatial reconstruction and world exploration. However, the scalability and real-world fidelity of current models remain severely constrained by the scarcity of large-scale, high-quality training data. While several datasets provide camera pose information, they are typically limited in scale, diversity, and annotation richness, particularly for real-world dynamic scenes with ground-truth camera motion. To this end, we collect \textbf{SpatialVID}, a dataset consists of a large corpus of in-the-wild videos with diverse scenes, camera movements and dense 3D annotations such as per-frame camera poses, depth, and motion instructions. Specifically, we collect more than 21,000 hours of raw video, and process them into 2.7 million clips through a hierarchical filtering pipeline, totaling 7,089 hours of dynamic content. A subsequent annotation pipeline enriches these clips with detailed spatial and semantic information, including camera poses, depth maps, dynamic masks, structured captions, and serialized motion instructions. Analysis of SpatialVIDs data statistics reveals a richness and diversity that directly foster improved model generalization and performance, establishing it as a key asset for the video and 3D vision research community.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09674v1" target="_blank">SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning</a></h3>
                    <p><strong>Authors:</strong> Haozhan Li, Yuxin Zuo, Jiale Yu, Yuhao Zhang, Zhaohui Yang, Kaiyan Zhang, Xuekai Zhu, Yuchen Zhang, Tianxing Chen, Ganqu Cui, Dehui Wang, Dingxiang Luo, Yuchen Fan, Youbang Sun, Jia Zeng, Jiangmiao Pang, Shanghang Zhang, Yu Wang, Yao Mu, Bowen Zhou, Ning Ding</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.AI, cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Vision-Language-Action (VLA) models have recently emerged as a powerful paradigm for robotic manipulation. Despite substantial progress enabled by large-scale pretraining and supervised fine-tuning (SFT), these models face two fundamental challenges: (i) the scarcity and high cost of large-scale human-operated robotic trajectories required for SFT scaling, and (ii) limited generalization to tasks involving distribution shift. Recent breakthroughs in Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can dramatically enhance step-by-step reasoning capabilities, raising a natural question: Can RL similarly improve the long-horizon step-by-step action planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL framework tailored for VLA models. Building upon veRL, we introduce VLA-specific trajectory sampling, scalable parallelization, multi-environment rendering, and optimized loss computation. When applied to OpenVLA-OFT, SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$ on RoboTwin 1.0\2.0 with the exploration-enhancing strategies we introduce. SimpleVLA-RL not only reduces dependence on large-scale data and enables robust generalization, but also remarkably surpasses SFT in real-world tasks. Moreover, we identify a novel phenomenon ``pushcut during RL training, wherein the policy discovers previously unseen patterns beyond those seen in the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09675v1" target="_blank">CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Runpeng Dai, Linfeng Song, Haolin Liu, Zhenwen Liang, Dian Yu, Haitao Mi, Zhaopeng Tu, Rui Liu, Tong Zheng, Hongtu Zhu, Dong Yu</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI, cs.LG</p>
                    <p><strong>Summary:</strong> Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm for enhancing the reasoning ability of Large Language Models (LLMs). Yet current RLVR methods often explore poorly, leading to premature convergence and entropy collapse. To address this challenge, we introduce Curiosity-Driven Exploration (CDE), a framework that leverages the models own intrinsic sense of curiosity to guide exploration. We formalize curiosity with signals from both the actor and the critic: for the actor, we use perplexity over its generated response, and for the critic, we use the variance of value estimates from a multi-head architecture. Both signals serve as an exploration bonus within the RLVR framework to guide the model. Our theoretical analysis shows that the actor-wise bonus inherently penalizes overconfident errors and promotes diversity among correct responses; moreover, we connect the critic-wise bonus to the well-established count-based exploration bonus in RL. Empirically, our method achieves an approximate +3 point improvement over standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a calibration collapse mechanism within RLVR, shedding light on common LLM failure modes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09672v1" target="_blank">Locality in Image Diffusion Models Emerges from Data Statistics</a></h3>
                    <p><strong>Authors:</strong> Artem Lukoianov, Chenyang Yuan, Justin Solomon, Vincent Sitzmann</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Among generative models, diffusion models are uniquely intriguing due to the existence of a closed-form optimal minimizer of their training objective, often referred to as the optimal denoiser. However, diffusion using this optimal denoiser merely reproduces images in the training set and hence fails to capture the behavior of deep diffusion models. Recent work has attempted to characterize this gap between the optimal denoiser and deep diffusion models, proposing analytical, training-free models that can generate images that resemble those generated by a trained UNet. The best-performing method hypothesizes that shift equivariance and locality inductive biases of convolutional neural networks are the cause of the performance gap, hence incorporating these assumptions into its analytical model. In this work, we present evidence that the locality in deep diffusion models emerges as a statistical property of the image dataset, not due to the inductive bias of convolutional neural networks. Specifically, we demonstrate that an optimal parametric linear denoiser exhibits similar locality properties to the deep neural denoisers. We further show, both theoretically and experimentally, that this locality arises directly from the pixel correlations present in natural image datasets. Finally, we use these insights to craft an analytical denoiser that better matches scores predicted by a deep diffusion model than the prior expert-crafted alternative.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09671v1" target="_blank">Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration</a></h3>
                    <p><strong>Authors:</strong> Sirui Xu, Yu-Wei Chao, Liuyu Bian, Arsalan Mousavian, Yu-Xiong Wang, Liang-Yan Gui, Wei Yang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.RO, cs.CV</p>
                    <p><strong>Summary:</strong> Hand-object motion-capture (MoCap) repositories offer large-scale, contact-rich demonstrations and hold promise for scaling dexterous robotic manipulation. Yet demonstration inaccuracies and embodiment gaps between human and robot hands limit the straightforward use of these data. Existing methods adopt a three-stage workflow, including retargeting, tracking, and residual correction, which often leaves demonstrations underused and compound errors across stages. We introduce Dexplore, a unified single-loop optimization that jointly performs retargeting and tracking to learn robot control policies directly from MoCap at scale. Rather than treating demonstrations as ground truth, we use them as soft guidance. From raw trajectories, we derive adaptive spatial scopes, and train with reinforcement learning to keep the policy in-scope while minimizing control effort and accomplishing the task. This unified formulation preserves demonstration intent, enables robot-specific strategies to emerge, improves robustness to noise, and scales to large demonstration corpora. We distill the scaled tracking policy into a vision-based, skill-conditioned generative controller that encodes diverse manipulation skills in a rich latent representation, supporting generalization across objects and real-world deployment. Taken together, these contributions position Dexplore as a principled bridge that transforms imperfect demonstrations into effective training signals for dexterous manipulation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09669v1" target="_blank">Strong-to-Weak Symmetry Breaking Phases in Steady States of Quantum Operations</a></h3>
                    <p><strong>Authors:</strong> Niklas Ziereis, Sanjay Moudgalya, Michael Knap</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.stat-mech, cond-mat.str-el, hep-th, math-ph, math.MP, quant-ph</p>
                    <p><strong>Summary:</strong> Mixed states can exhibit two distinct kinds of symmetries, either on the level of the individual states (strong symmetry), or only on the level of the ensemble (weak symmetry). Strong symmetries can be spontaneously broken down to weak ones, a mechanism referred to as Strong-to-Weak Spontaneous Symmetry Breaking (SW-SSB). In this work, we first show that maximally mixed symmetric density matrices, which appear, for example, as steady states of symmetric random quantum circuits have SW-SSB when the symmetry is an on-site representation of a compact Lie or finite group. We then show that this can be regarded as an isolated point within an entire SW-SSB phase that is stable to more general quantum operations such as measurements followed by weak postselection. With sufficiently strong postselection, a second-order transition can be driven to a phase where the steady state is strongly symmetric. We provide analytical and numerical results for such SW-SSB phases and their transitions for both abelian $\mathbb{Z}_2$ and non-abelian $S_3$ symmetries in the steady state of Brownian random quantum circuits with measurements. We also show that such continuous SW-SSB transitions are absent in the steady-state of general strongly symmetric, trace-preserving quantum channels (including unital, Brownian, or Lindbladian dynamics) by analyzing the degeneracies of the steady states in the presence of symmetries. Our results demonstrate robust SW-SSB phases and their transitions in the steady states of noisy quantum operations, and provide a framework for realizing various kinds of mixed-state quantum phases based on their symmetries.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09668v1" target="_blank">Magnetotransport across Weyl semimetal grain boundaries</a></h3>
                    <p><strong>Authors:</strong> Haoyang Tian, Vatsal Dwivedi, Adam Yanis Chaou, Maxim Breitkreiz</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall, cond-mat.dis-nn</p>
                    <p><strong>Summary:</strong> A clean interface between two Weyl semimetals features a universal, field-linear tunnel magnetoconductance of $(e^2/h)N_\mathrm{ho}$ per magnetic flux quantum, where $N_\mathrm{ho}$ is the number of chirality-preserving topological interface Fermi arcs. In this work we show that the linearity of the magnetoconductance is robust with to interface disorder. The slope of the magnetoconductance changes at a characteristic field strength $B_\mathrm{arc}$ -- the field strength for which the time taken to traverse the Fermi arc due to the Lorentz force is equal to the mean inter-arc scattering time. For fields much larger than $B_\mathrm{arc}$, the magnetoconductance is unaffected by disorder. For fields much smaller than $B_\mathrm{arc}$, the slope is no longer determined by $N_\mathrm{ho}$ but by the simple fraction $N_\mathrm{L} N_\mathrm{R}/(N_\mathrm{L}+N_\mathrm{R})$, where $N_\mathrm{L}$ and $N_\mathrm{R}$ are the numbers of Weyl-node pairs in the left and right Weyl semimetal, respectively. We also consider the effect of spatially correlated disorder potentials, where we find that $B_\mathrm{arc}$ decreases exponentially with increasing correlation length. Our results provide a possible explanation for the recently observed robustness of the negative linear magnetoresistance in grained Weyl semimetals.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09667v1" target="_blank">Geometric Neural Distance Fields for Learning Human Motion Priors</a></h3>
                    <p><strong>Authors:</strong> Zhengdi Yu, Simone Foti, Linguang Zhang, Amy Zhao, Cem Keskin, Stefanos Zafeiriou, Tolga Birdal</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> We introduce Neural Riemannian Motion Fields (NRMF), a novel 3D generative human motion prior that enables robust, temporally consistent, and physically plausible 3D motion recovery. Unlike existing VAE or diffusion-based methods, our higher-order motion prior explicitly models the human motion in the zero level set of a collection of neural distance fields (NDFs) corresponding to pose, transition (velocity), and acceleration dynamics. Our framework is rigorous in the sense that our NDFs are constructed on the product space of joint rotations, their angular velocities, and angular accelerations, respecting the geometry of the underlying articulations. We further introduce: (i) a novel adaptive-step hybrid algorithm for projecting onto the set of plausible motions, and (ii) a novel geometric integrator to roll out realistic motion trajectories during test-time-optimization and generation. Our experiments show significant and consistent gains: trained on the AMASS dataset, NRMF remarkably generalizes across multiple input modalities and to diverse tasks ranging from denoising to motion in-betweening and fitting to partial 2D / 3D observations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09666v1" target="_blank">Can Understanding and Generation Truly Benefit Together -- or Just Coexist?</a></h3>
                    <p><strong>Authors:</strong> Zhiyuan Yan, Kaiqing Lin, Zongjian Li, Junyan Ye, Hui Han, Zhendong Wang, Hao Liu, Bin Lin, Hao Li, Xue Xu, Xinyan Xiao, Jingdong Wang, Haifeng Wang, Li Yuan</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> In this paper, we introduce an insightful paradigm through the Auto-Encoder lens-understanding as the encoder (I2T) that compresses images into text, and generation as the decoder (T2I) that reconstructs images from that text. Using reconstruction fidelity as the unified training objective, we enforce the coherent bidirectional information flow between the understanding and generation processes, bringing mutual gains. To implement this, we propose UAE, a novel framework for unified multimodal learning. We begin by pre-training the decoder with large-scale long-context image captions to capture fine-grained semantic and complex spatial relationships. We then propose Unified-GRPO via reinforcement learning (RL), which covers three stages: (1) A cold-start phase to gently initialize both encoder and decoder with a semantic reconstruction loss; (2) Generation for Understanding, where the encoder is trained to generate informative captions that maximize the decoders reconstruction quality, enhancing its visual understanding; (3) Understanding for Generation, where the decoder is refined to reconstruct from these captions, forcing it to leverage every detail and improving its long-context instruction following and generation fidelity. For evaluation, we introduce Unified-Bench, the first benchmark tailored to assess the degree of unification of the UMMs. A surprising aha moment arises within the multimodal learning domain: as RL progresses, the encoder autonomously produces more descriptive captions, while the decoder simultaneously demonstrates a profound ability to understand these intricate descriptions, resulting in reconstructions of striking fidelity.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09663v1" target="_blank">Bogoliubov quasi-particles in superconductors are integer-charged particles inapplicable for braiding quantum information</a></h3>
                    <p><strong>Authors:</strong> Zhiyu Fan, Wei Ku</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cond-mat.str-el, cond-mat.supr-con, quant-ph</p>
                    <p><strong>Summary:</strong> We present a rigorous proof that under a number-conserving Hamiltonian, one-body quasi-particles generally possess quantized charge and inertial mass identical to the bare particles. It follows that, Bogoliubov zero modes in the vortex (or on the edge) of superconductors $\textit{cannot}$ be their own anti-particles capable of braiding quantum information. As such, the heavily pursued Majorana zero mode-based route for quantum computation requires a serious re-consideration. This study further reveals the conceptual challenge in preparing and manipulating braid-able quantum states via physical thermalization or slow external fields. These profound results should reignite the long-standing quest for a number-conserving theory of superconductivity and superfluidity without fictitiously breaking global U(1) symmetry.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09660v1" target="_blank">Steering MoE LLMs via Expert (De)Activation</a></h3>
                    <p><strong>Authors:</strong> Mohsen Fayyaz, Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Ryan Rossi, Trung Bui, Hinrich SchÃ¼tze, Nanyun Peng</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.LG</p>
                    <p><strong>Summary:</strong> Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token through a subset of specialized Feed-Forward Networks (FFN), known as experts. We present SteerMoE, a framework for steering MoE models by detecting and controlling behavior-linked experts. Our detection method identifies experts with distinct activation patterns across paired inputs exhibiting contrasting behaviors. By selectively (de)activating such experts during inference, we control behaviors like faithfulness and safety without retraining or modifying weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to +20% and faithfulness by +27%. In adversarial attack mode, it drops safety by -41% alone, and -100% when combined with existing jailbreak methods, bypassing all safety guardrails and exposing a new dimension of alignment faking hidden within experts.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09658v1" target="_blank">Measuring Epistemic Humility in Multimodal Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Bingkui Tong, Jiaer Xia, Sifeng Shang, Kaiyang Zhou</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Hallucinations in multimodal large language models (MLLMs) -- where the model generates content inconsistent with the input image -- pose significant risks in real-world applications, from misinformation in visual question answering to unsafe errors in decision-making. Existing benchmarks primarily test recognition accuracy, i.e., evaluating whether models can select the correct answer among distractors. This overlooks an equally critical capability for trustworthy AI: recognizing when none of the provided options are correct, a behavior reflecting epistemic humility. We present HumbleBench, a new hallucination benchmark designed to evaluate MLLMs ability to reject plausible but incorrect answers across three hallucination types: object, relation, and attribute. Built from a panoptic scene graph dataset, we leverage fine-grained scene graph annotations to extract ground-truth entities and relations, and prompt GPT-4-Turbo to generate multiple-choice questions, followed by a rigorous manual filtering process. Each question includes a None of the above option, requiring models not only to recognize correct visual information but also to identify when no provided answer is valid. We evaluate a variety of state-of-the-art MLLMs -- including both general-purpose and specialized reasoning models -- on HumbleBench and share valuable findings and insights with the community. By incorporating explicit false-option rejection, HumbleBench fills a key gap in current evaluation suites, providing a more realistic measure of MLLM reliability in safety-critical settings. Our code and dataset are released publicly and can be accessed at https://github.com/maifoundations/HumbleBench.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09657v1" target="_blank">Uniformity within Parameterized Circuit Classes</a></h3>
                    <p><strong>Authors:</strong> Steef Hegeman, Jan Martens, Alfons Laarman</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CC, cs.LO</p>
                    <p><strong>Summary:</strong> We study uniformity conditions for parameterized Boolean circuit families. Uniformity conditions require that the infinitely many circuits in a circuit family are in some sense easy to construct from one shared description. For shallow circuit families, logtime-uniformity is often desired but quite technical to prove. Despite that, proving it is often left as an exercise for the reader -- even for recently introduced classes in parameterized circuit complexity, where uniformity conditions have not yet been explicitly studied. We formally define parameterized versions of linear-uniformity, logtime-uniformity, and FO-uniformity, and prove that these result in equivalent complexity classes when imposed on $\text{para-}\textsf{AC}^0$ and $\text{para-}\textsf{AC}^{0\uparrow}$. Overall, we provide a convenient way to verify uniformity for shallow parameterized circuit classes, and thereby substantiate claims of uniformity in the literature.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09655v1" target="_blank">Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management</a></h3>
                    <p><strong>Authors:</strong> Sanjay Basu, Sadiq Y. Patel, Parth Sheth, Bhairavi Muralidharan, Namrata Elamaran, Aakriti Kinra, Rajaie Batniji</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.LO, stat.AP</p>
                    <p><strong>Summary:</strong> We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning (FG-FARL), an offline RL procedure that calibrates per-group safety thresholds to reduce harm while equalizing a chosen fairness target (coverage or harm) across protected subgroups. Using de-identified longitudinal trajectories from a Medicaid population health management program, we evaluate FG-FARL against behavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global conformal safety baseline). We report off-policy value estimates with bootstrap 95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL achieves comparable value to baselines while improving fairness metrics, demonstrating a practical path to safer and more equitable decision support.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09653v1" target="_blank">Towards A High-Performance Quantum Data Center Network Architecture</a></h3>
                    <p><strong>Authors:</strong> Yufeng Xin, Liang Zhang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cs.DC, cs.NI</p>
                    <p><strong>Summary:</strong> Quantum Data Centers (QDCs) are needed to support large-scale quantum processing for both academic and commercial applications. While large-scale quantum computers are constrained by technological and financial barriers, a modular approach that clusters small quantum computers offers an alternative. This approach, however, introduces new challenges in network scalability, entanglement generation, and quantum memory management. In this paper, we propose a three-layer fat-tree network architecture for QDCs, designed to address these challenges. Our architecture features a unique leaf switch and an advanced swapping spine switch design, optimized to handle high volumes of entanglement requests as well as a queue scheduling mechanism that efficiently manages quantum memory to prevent decoherence. Through queuing-theoretical models and simulations in NetSquid, we demonstrate the proposed architectures scalability and effectiveness in maintaining high entanglement fidelity, offering a practical path forward for modular QDC networks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09651v1" target="_blank">Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations</a></h3>
                    <p><strong>Authors:</strong> Zakaria El Kassimi, Fares Fourati, Mohamed-Slim Alouini</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI, cs.CL, cs.LG, eess.SP</p>
                    <p><strong>Summary:</strong> We study question answering in the domain of radio regulations, a legally sensitive and high-stakes area. We propose a telecom-specific Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge, the first multiple-choice evaluation set for this domain, constructed from authoritative sources using automated filtering and human validation. To assess retrieval quality, we define a domain-specific retrieval metric, under which our retriever achieves approximately 97% accuracy. Beyond retrieval, our approach consistently improves generation accuracy across all tested models. In particular, while naively inserting documents without structured retrieval yields only marginal gains for GPT-4o (less than 1%), applying our pipeline results in nearly a 12% relative improvement. These findings demonstrate that carefully targeted grounding provides a simple yet strong baseline and an effective domain-specific solution for regulatory question answering. All code and evaluation scripts, along with our derived question-answer dataset, are available at https://github.com/Zakaria010/Radio-RAG.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09650v1" target="_blank">All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens</a></h3>
                    <p><strong>Authors:</strong> Siddarth Mamidanna, Daking Rai, Ziyu Yao, Yilun Zhou</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.CL, I.2.7</p>
                    <p><strong>Summary:</strong> Large language models (LLMs) demonstrate proficiency across numerous computational tasks, yet their inner workings remain unclear. In theory, the combination of causal self-attention and multilayer perceptron layers allows every token to access and compute information based on all preceding tokens. In practice, to what extent are such operations present? In this paper, on mental math tasks (i.e., direct math calculation via next-token prediction without explicit reasoning), we investigate this question in three steps: inhibiting input-specific token computations in the initial layers, restricting the routes of information transfer across token positions in the next few layers, and forcing all computation to happen at the last token in the remaining layers. With two proposed techniques, Context-Aware Mean Ablation (CAMA) and Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with high accuracy on a wide variety of mental math tasks, where meaningful computation occurs very late (in terms of layer depth) and only at the last token, which receives information of other tokens in few specific middle layers. Experiments on a variety of models and arithmetic expressions show that this subgraph is sufficient and necessary for high model performance, transfers across different models, and works on a variety of input styles. Ablations on different CAMA and ABP alternatives reveal their unique advantages over other methods, which may be of independent interest.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09647v1" target="_blank">Reconstructing the origin of black hole mergers using sparse astrophysical models</a></h3>
                    <p><strong>Authors:</strong> V. Gayathri, Giuliano Iorio, Hiromichi Tagawa, Daniel Wysocki, Jeremiah Anglin, Imre Bartos, Shubhagata Bhaumik, Zoltan Haiman, Michela Mapelli, R. OShaughnessy, LingQin Xue</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, gr-qc</p>
                    <p><strong>Summary:</strong> The astrophysical origin of binary black hole mergers discovered by LIGO and Virgo remains uncertain. Efforts to reconstruct the processes that lead to mergers typically rely on either astrophysical models with fixed parameters, or continuous analytical models that can be fit to observations. Given the complexity of astrophysical formation mechanisms, these methods typically cannot fully take into account model uncertainties, nor can they fully capture the underlying processes. Here, we present a merger population analysis that can take a discrete set of simulated model distributions as its input to interpret observations. The analysis can take into account multiple formation scenarios as fractional contributors to the total set of observations, and can naturally account for model uncertainties. We apply this technique to investigate the origin of black hole mergers observed by LIGO Virgo. Specifically, we consider a model of AGN assisted black hole merger distributions, exploring a range of AGN parameters along with several {{SEVN}} population synthesis models that vary in common envelope efficiency parameter ($\alpha$) and metallicity ($Z$). We estimate the posterior distributions for AGN+SEVN models using $87$ BBH detections from the $O1--O3$ observation runs. The inferred total merger rate is $46.2 {Gpc}^{-3} {yr}^{-1}$, with the AGN sub-population contributing $21.2{Gpc}^{-3}{yr}^{-1}$ and the SEVN sub-population contributing $25.0 {Gpc}^{-3} {yr}^{-1}$.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09645v1" target="_blank">Explaining the Reputational Risks of AI-Mediated Communication: Messages Labeled as AI-Assisted Are Viewed as Less Diagnostic of the Senders Moral Character</a></h3>
                    <p><strong>Authors:</strong> Pranav Khadpe, Kimi Wenzel, George Loewenstein, Geoff Kaufman</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.CY, cs.ET</p>
                    <p><strong>Summary:</strong> When someone sends us a thoughtful message, we naturally form judgments about their character. But what happens when that message carries a label indicating it was written with the help of AI? This paper investigates how the appearance of AI assistance affects our perceptions of message senders. Adding nuance to previous research, through two studies (N=399) featuring vignette scenarios, we find that AI-assistance labels dont necessarily make people view senders negatively. Rather, they dampen the strength of character signals in communication. We show that when someone sends a warmth-signalling message (like thanking or apologizing) without AI help, people more strongly categorize the sender as warm. At the same time, when someone sends a coldness-signalling message (like bragging or blaming) without assistance, people more confidently categorize them as cold. Interestingly, AI labels weaken both these associations: An AI-assisted apology makes the sender appear less warm than if they had written it themselves, and an AI-assisted blame makes the sender appear less cold than if they had composed it independently. This supports our signal diagnosticity explanation: messages labeled as AI-assisted are viewed as less diagnostic than messages which seem unassisted. We discuss how our findings shed light on the causal origins of previously reported observations in AI-Mediated Communication.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09644v1" target="_blank">RSMA-Enhanced Data Collection in RIS-Assisted Intelligent Consumer Transportation Systems</a></h3>
                    <p><strong>Authors:</strong> Chunjie Wang, Xuhui Zhang, Wenchao Liu, Jinke Ren, Shuqiang Wang, Yanyan Shen, Kejiang Ye, Kim Fung Tsang</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> cs.IT, eess.SP, math.IT</p>
                    <p><strong>Summary:</strong> This paper investigates the data collection enhancement problem in a reconfigurable intelligent surface (RIS)-empowered intelligent consumer transportation system (ICTS). We propose a novel framework where a data center (DC) provides energy to pre-configured roadside unit (RSU) pairs during the downlink stage. While in the uplink stage, these RSU pairs utilize a hybrid rate-splitting multiple access (RSMA) and time-division multiple access (TDMA) protocol to transmit the processed data to the DC, while simultaneously performing local data processing using the harvested energy. Our objective is to maximize the minimal processed data volume of the RSU pairs by jointly optimizing the RIS downlink and uplink phase shifts, the transmit power of the DC and RSUs, the RSU computation resource allocation, and the time slot allocation. To address the formulated non-convex problem, we develop an efficient iterative algorithm integrating alternating optimization and sequential rank-one constraint relaxation methods. Extensive simulations demonstrate that the proposed algorithm significantly outperforms baseline schemes under diverse scenarios, validating its effectiveness in enhancing the data processing performance for intelligent transportation applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.09643v1" target="_blank">Ultralight Boson Ionization from Comparable-Mass Binary Black Holes</a></h3>
                    <p><strong>Authors:</strong> Yuhao Guo, Zhen Zhong, Yifan Chen, Vitor Cardoso, Taishi Ikeda, Lihang Zhou</p>
                    <p><strong>Published:</strong> 9/11/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.CO, astro-ph.HE, hep-ph</p>
                    <p><strong>Summary:</strong> Ultralight bosons around comparable-mass binaries can form gravitationally bound states analogous to molecules once the binary separation decreases below the bosons Bohr radius, with the inner region co-moving with the binary. We simulate the formation of these gravitational molecules, determine their co-moving regions, and compute ionization fluxes induced by orbital motion for various binary eccentricities. We develop semi-analytic formalisms to describe the ionization dynamics of both the co-moving and non-co-moving regions, demonstrating consistency with numerical simulation results. From ionization fluxes, we estimate their backreaction on binary orbital evolution. At early stages, molecule ionization can dominate over gravitational wave emission, producing a spectral turnover in the gravitational wave background. Additionally, ionization of the co-moving component occurs solely due to binary eccentricity, causing orbital circularization.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

