
    
        <h1>ðŸ¤– AI Research Report</h1>
        
            <strong>Date:</strong> 2025-09-05<br>
            <strong>Topics:</strong> post harvest storage techniques<br>
            <strong>Papers Found:</strong> 50
        
        
        
            
                <h2>ðŸ¤– AI Summary</h2>
                <h2>post harvest storage techniques</h2>
<p>The list of research papers provided does not directly relate to post-harvest storage techniques, which typically involve methods and technologies used to preserve the quality and extend the shelf life of agricultural products after they are harvested. However, I can provide a structured summary of the trends, breakthroughs, and implications based on the papers provided, even though they cover a wide range of topics unrelated to post-harvest storage. Hereâ€™s a general summary:</p>
<h3>Most Important Trends</h3>
<ol>
<li><p><strong>Advancements in AI and Machine Learning</strong>: Many papers focus on the application of AI and machine learning, such as enhancing image retrieval systems, improving language models, and developing novel frameworks for psychological counseling and speech recognition.</p>
</li>
<li><p><strong>Integration of Technology in Various Fields</strong>: From quantum optics and quantum metrology to robotics and industrial control systems, technology integration is transforming traditional methods and offering new capabilities.</p>
</li>
<li><p><strong>Focus on Real-time and Efficient Systems</strong>: There is a significant emphasis on developing systems that operate in real-time with enhanced efficiency, as seen in autonomous systems, distributed training, and machine learning model evaluation.</p>
</li>
</ol>
<h3>Breakthroughs</h3>
<ol>
<li><p><strong>Innovations in AI and Machine Learning</strong>: Novel frameworks and algorithms, such as Plotn Polish for story visualization and Delta Activations for model representation, are pushing the boundaries of what AI can achieve in creative and technical domains.</p>
</li>
<li><p><strong>Quantum and Optical Advancements</strong>: Papers like those on quantum metrology and X-ray ptychography present breakthroughs in measurement precision and imaging quality, offering new tools for scientific exploration.</p>
</li>
<li><p><strong>Enhanced Computational Techniques</strong>: Advances in computational methods, such as the use of FPGA for real-time processing and the development of efficient checkpointing systems for distributed training, highlight significant progress in computational efficiency.</p>
</li>
</ol>
<h3>Implications</h3>
<ol>
<li><p><strong>Cross-disciplinary Applications</strong>: The advancements in AI and machine learning have broad implications across various fields, from healthcare and education to industrial processes and space exploration, improving efficiency, accuracy, and capabilities.</p>
</li>
<li><p><strong>Potential for Improved Decision-Making</strong>: Enhanced data processing and visualization techniques, like panoramic incident summaries and efficient retrieval systems, improve decision-making processes in critical situations.</p>
</li>
<li><p><strong>Increased Accessibility and Scalability</strong>: By improving the efficiency and effectiveness of both hardware and software, these innovations pave the way for more widespread adoption of advanced technologies in everyday applications.</p>
</li>
</ol>
<p>While these papers do not directly address post-harvest storage techniques, they collectively highlight the broader trend of leveraging advanced technologies to improve efficiency, accuracy, and functionality in various domains. If you have specific papers related to post-harvest storage techniques, I can provide a more focused summary on that topic.</p>
<p><em>Based on 50 research papers</em></p>

            
        
        
        <h2>ðŸ“š Research Papers</h2>
        
                
                    <h3><a href="http://arxiv.org/abs/2509.04446v1" target="_blank">Plotn Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models</a></h3>
                    <p><strong>Authors:</strong> Kiymet Akdemir, Jing Shi, Kushal Kafle, Brian Price, Pinar Yanardag</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-image diffusion models have demonstrated significant capabilities to generate diverse and detailed visuals in various domains, and story visualization is emerging as a particularly promising application. However, as their use in real-world creative domains increases, the need for providing enhanced control, refinement, and the ability to modify images post-generation in a consistent manner becomes an important challenge. Existing methods often lack the flexibility to apply fine or coarse edits while maintaining visual and narrative consistency across multiple frames, preventing creators from seamlessly crafting and refining their visual stories. To address these challenges, we introduce Plotn Polish, a zero-shot framework that enables consistent story generation and provides fine-grained control over story visualizations at various levels of detail.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04444v1" target="_blank">One Flight Over the Gap: A Survey from Perspective to Panoramic Vision</a></h3>
                    <p><strong>Authors:</strong> Xin Lin, Xian Ge, Dizhe Zhang, Zhaoliang Wan, Xianshun Wang, Xiangtai Li, Wenjie Jiang, Bo Du, Dacheng Tao, Ming-Hsuan Yang, Lu Qi</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Driven by the demand for spatial intelligence and holistic scene perception, omnidirectional images (ODIs), which provide a complete 360\textdegree{} field of view, are receiving growing attention across diverse applications such as virtual reality, autonomous driving, and embodied robotics. Despite their unique characteristics, ODIs exhibit remarkable differences from perspective images in geometric projection, spatial distribution, and boundary continuity, making it challenging for direct domain adaption from perspective methods. This survey reviews recent panoramic vision techniques with a particular emphasis on the perspective-to-panorama adaptation. We first revisit the panoramic imaging pipeline and projection methods to build the prior knowledge required for analyzing the structural disparities. Then, we summarize three challenges of domain adaptation: severe geometric distortions near the poles, non-uniform sampling in Equirectangular Projection (ERP), and periodic boundary continuity. Building on this, we cover 20+ representative tasks drawn from more than 300 research papers in two dimensions. On one hand, we present a cross-method analysis of representative strategies for addressing panoramic specific challenges across different tasks. On the other hand, we conduct a cross-task comparison and classify panoramic vision into four major categories: visual quality enhancement and assessment, visual understanding, multimodal understanding, and visual generation. In addition, we discuss open challenges and future directions in data, models, and applications that will drive the advancement of panoramic vision research. We hope that our work can provide new insight and forward looking perspectives to advance the development of panoramic vision technologies. Our project page is https://insta360-research-team.github.io/Survey-of-Panorama</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04442v1" target="_blank">Delta Activations: A Representation for Finetuned Large Language Models</a></h3>
                    <p><strong>Authors:</strong> Zhiqiu Xu, Amish Sethi, Mayur Naik, Ser-Nam Lim</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL, cs.IR</p>
                    <p><strong>Summary:</strong> The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collection of post-trained models adapted to specific tasks and domains. However, navigating and understanding these models remains challenging due to inconsistent metadata and unstructured repositories. We introduce Delta Activations, a method to represent finetuned models as vector embeddings by measuring shifts in their internal activations relative to a base model. This representation allows for effective clustering by domain and task, revealing structure in the model landscape. Delta Activations also demonstrate desirable properties: it is robust across finetuning settings and exhibits an additive property when finetuning datasets are mixed. In addition, we show that Delta Activations can embed tasks via few-shot finetuning, and further explore its use for model selection and merging. We hope Delta Activations can facilitate the practice of reusing publicly available models. Code is available at https://github.com/OscarXZQ/delta_activations.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04430v1" target="_blank">Unveiling the Role of Data Uncertainty in Tabular Deep Learning</a></h3>
                    <p><strong>Authors:</strong> Nikolay Kartashev, Ivan Rubachev, Artem Babenko</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG</p>
                    <p><strong>Summary:</strong> Recent advancements in tabular deep learning have demonstrated exceptional practical performance, yet the field often lacks a clear understanding of why these techniques actually succeed. To address this gap, our paper highlights the importance of the concept of data uncertainty for explaining the effectiveness of the recent tabular DL methods. In particular, we reveal that the success of many beneficial design choices in tabular DL, such as numerical feature embeddings, retrieval-augmented models and advanced ensembling strategies, can be largely attributed to their implicit mechanisms for managing high data uncertainty. By dissecting these mechanisms, we provide a unifying understanding of the recent performance improvements. Furthermore, the insights derived from this data-uncertainty perspective directly allowed us to develop more effective numerical feature embeddings as an immediate practical outcome of our analysis. Overall, our work paves the way to foundational understanding of the benefits introduced by modern tabular methods that results in the concrete advancements of existing techniques and outlines future research directions for tabular DL.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04429v1" target="_blank">Toward an affordable density-based measure for the quality of a coupled cluster calculation</a></h3>
                    <p><strong>Authors:</strong> Gregory H. Jones, Kaila E. Weflen, Jan M. L. Martin</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.chem-ph</p>
                    <p><strong>Summary:</strong> We propose two new diagnostics for the degree to which static correlation impacts the quality of a coupled cluster calculation. The first is the change in the Matito static correlation diagnostic $\overline{I_{ND}}$ between CCSD and CCSD(T), $\Delta I_{ND}[\textrm{(T)}]=\overline{I_{ND}}[\textrm{CCSD(T)}]-\overline{I_{ND}}[\textrm{CCSD}]$. The second is the ratio of the same and of the corresponding change in the total correlation diagnostic $\overline{I_{T}}=\overline{I_{ND}}+\overline{I_{D}}$, i.e., $r_I[(T)]=\Delta I_{ND}[\textrm{(T)}]/\Delta I_{T}[\textrm{(T)}]$. The first diagnostic can be extended to higher-order improvements in the wave function, e.g., $\Delta I_{ND}[\textrm{(Q)}]=\overline{I_{ND}}[\textrm{CCSDT(Q)}]-\overline{I_{ND}}[\textrm{CCSDT}]$. In general, a small $\Delta I_{ND}$[\textrm{level$_1$}] value indicates that at this level$_1$ of theory, the density is converged and any further changes to the energy come from dynamical correlation, while larger $\Delta I_{ND}$[\textrm{level$_2$}] indicates that the density is still not converged at level$_2$ and some static correlation remains. $r_I[(T)]$ is found to be a moderately good predictor for the importance of post-CCSD(T) correlation effects.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04419v1" target="_blank">Towards a Unified View of Large Language Model Post-Training</a></h3>
                    <p><strong>Authors:</strong> Xingtai Lv, Yuxin Zuo, Youbang Sun, Hongyi Liu, Yuntian Wei, Zhekai Chen, Lixuan He, Xuekai Zhu, Kaiyan Zhang, Bingning Wang, Ning Ding, Bowen Zhou</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.LG, cs.AI, cs.CL</p>
                    <p><strong>Summary:</strong> Two major sources of training data exist for post-training modern language models: online (model-generated rollouts) data, and offline (human or other-model demonstrations) data. These two types of data are typically used by approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT), respectively. In this paper, we show that these approaches are not in contradiction, but are instances of a single optimization process. We derive a Unified Policy Gradient Estimator, and present the calculations of a wide spectrum of post-training approaches as the gradient of a common objective under different data distribution assumptions and various bias-variance tradeoffs. The gradient estimator is constructed with four interchangeable parts: stabilization mask, reference policy denominator, advantage estimate, and likelihood gradient. Motivated by our theoretical findings, we propose Hybrid Post-Training (HPT), an algorithm that dynamically selects different training signals. HPT is designed to yield both effective exploitation of demonstration and stable exploration without sacrificing learned reasoning patterns. We provide extensive experiments and ablation studies to verify the effectiveness of our unified theoretical framework and HPT. Across six mathematical reasoning benchmarks and two out-of-distribution suites, HPT consistently surpasses strong baselines across models of varying scales and families.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04402v1" target="_blank">Learning neural representations for X-ray ptychography reconstruction with unknown probes</a></h3>
                    <p><strong>Authors:</strong> Tingyou Li, Zixin Xu, Zirui Gao, Hanfei Yan, Xiaojing Huang, Jizhou Li</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> X-ray ptychography provides exceptional nanoscale resolution and is widely applied in materials science, biology, and nanotechnology. However, its full potential is constrained by the critical challenge of accurately reconstructing images when the illuminating probe is unknown. Conventional iterative methods and deep learning approaches are often suboptimal, particularly under the low-signal conditions inherent to low-dose and high-speed experiments. These limitations compromise reconstruction fidelity and restrict the broader adoption of the technique. In this work, we introduce the Ptychographic Implicit Neural Representation (PtyINR), a self-supervised framework that simultaneously addresses the object and probe recovery problem. By parameterizing both as continuous neural representations, PtyINR performs end-to-end reconstruction directly from raw diffraction patterns without requiring any pre-characterization of the probe. Extensive evaluations demonstrate that PtyINR achieves superior reconstruction quality on both simulated and experimental data, with remarkable robustness under challenging low-signal conditions. Furthermore, PtyINR offers a generalizable, physics-informed framework for addressing probe-dependent inverse problems, making it applicable to a wide range of computational microscopy problems.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04392v1" target="_blank">Denoising GER: A Noise-Robust Generative Error Correction with LLM for Speech Recognition</a></h3>
                    <p><strong>Authors:</strong> Yanyan Liu, Minqiang Xu, Yihao Chen, Liang He, Lei Fang, Sian Fang, Lin Liu</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.SD</p>
                    <p><strong>Summary:</strong> In recent years, large language models (LLM) have made significant progress in the task of generation error correction (GER) for automatic speech recognition (ASR) post-processing. However, in complex noisy environments, they still face challenges such as poor adaptability and low information utilization, resulting in limited effectiveness of GER. To address these issues, this paper proposes a noise-robust multi-modal GER framework (Denoising GER). The framework enhances the models adaptability to different noisy scenarios through a noise-adaptive acoustic encoder and optimizes the integration of multi-modal information via a heterogeneous feature compensation dynamic fusion (HFCDF) mechanism, improving the LLMs utilization of multi-modal information. Additionally, reinforcement learning (RL) training strategies are introduced to enhance the models predictive capabilities. Experimental results demonstrate that Denoising GER significantly improves accuracy and robustness in noisy environments and exhibits good generalization abilities in unseen noise scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04372v1" target="_blank">Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology</a></h3>
                    <p><strong>Authors:</strong> Yuchen Jiao, Yuxin Chen, Gen Li</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> stat.ML, cs.GL, cs.LG, math.ST, stat.TH</p>
                    <p><strong>Summary:</strong> In this note, we reflect on several fundamental connections among widely used post-training techniques. We clarify some intimate connections and equivalences between reinforcement learning with human feedback, reinforcement learning with internal feedback, and test-time scaling (particularly soft best-of-$N$ sampling), while also illuminating intrinsic links between diffusion guidance and test-time scaling. Additionally, we introduce a resampling approach for alignment and reward-directed diffusion models, sidestepping the need for explicit reinforcement learning techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04370v1" target="_blank">Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage</a></h3>
                    <p><strong>Authors:</strong> Dor Cohen, Inga Efrosman, Yehudit Aperstein, Alexander Apartsin</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> First responders widely adopt body-worn cameras to document incident scenes and support post-event analysis. However, reviewing lengthy video footage is impractical in time-critical situations. Effective situational awareness demands a concise visual summary that can be quickly interpreted. This work presents a computer vision pipeline that transforms body-camera footage into informative panoramic images summarizing the incident scene. Our method leverages monocular Simultaneous Localization and Mapping (SLAM) to estimate camera trajectories and reconstruct the spatial layout of the environment. Key viewpoints are identified by clustering camera poses along the trajectory, and representative frames from each cluster are selected. These frames are fused into spatially coherent panoramic images using multi-frame stitching techniques. The resulting summaries enable rapid understanding of complex environments and facilitate efficient decision-making and incident review.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04364v1" target="_blank">Lifting Frobenius splittings through geometric vertex decomposition</a></h3>
                    <p><strong>Authors:</strong> Emanuela De Negri, Elisa Gorla, Patricia Klein, Jenna Rajchgot, Lisa Seccia</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.AC, math.AG, 13A35, 13P10, 05E14</p>
                    <p><strong>Summary:</strong> Frobenius splitting, pioneered by Hochster and Roberts in the 1970s and Mehta and Ramanathan in the 1980s, is a technique in characteristic $p$ commutative algebra and algebraic geometry used to control singularities. In the aughts, Knutson showed that Frobenius splittings of a certain type descend through Gr\obner degeneration of a certain type, called geometric vertex decomposition. In the present paper, we give a partial converse to Knutsons result. We show that a Frobenius splitting that compatibly splits both link and deletion of a geometric vertex decomposition can, under an additional hypothesis on the form of the splitting, be lifted to a splitting that compatibly splits the original ideal. We discuss an example showing that the additional hypothesis cannot be removed. Our argument uses the relationship between geometric vertex decomposition and Gorenstein liaison developed by Klein and Rajchgot. Additionally, we show that Lis double determinantal varieties defined by maximal minors are Frobenius split.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04361v1" target="_blank">Precision measurement of neutrino oscillation parameters with 10 years of data from the NOvA experiment</a></h3>
                    <p><strong>Authors:</strong> The NOvA Collaboration, S. Abubakar, M. A. Acero, B. Acharya, P. Adamson, N. Anfimov, A. Antoshkin, E. Arrieta-Diaz, L. Asquith, A. Aurisano, D. Azevedo, A. Back, N. Balashov, P. Baldi, B. A. Bambah, E. F. Bannister, A. Barros, A. Bat, R. Bernstein, T. J. C. Bezerra, V. Bhatnagar, B. Bhuyan, J. Bian, A. C. Booth, R. Bowles, B. Brahma, C. Bromberg, N. Buchanan, A. Butkevich, S. Calvez, T. J. Carroll, E. Catano-Mur, J. P. Cesar, S. Chaudhary, R. Chirco, S. Choate, B. C. Choudhary, O. T. K. Chow, A. Christensen, M. F. Cicala, T. E. Coan, T. Contreras, A. Cooleybeck, D. Coveyou, L. Cremonesi, G. S. Davies, P. F. Derwent, P. Ding, Z. Djurcic, K. Dobbs, M. Dolce, D. Duenas Tonguino, E. C. Dukes, A. Dye, R. Ehrlich, E. Ewart, G. J. Feldman, P. Filip, M. J. Frank, H. R. Gallagher, F. Gao, A. Giri, R. A. Gomes, M. C. Goodman, R. Group, A. Habig, F. Hakl, J. Hartnell, R. Hatcher, J. M. Hays, M. He, K. Heller, V Hewes, A. Himmel, T. Horoho, X. Huang, A. Ivanova, B. Jargowsky, I. Kakorin, A. Kalitkina, D. M. Kaplan, A. Khanam, B. Kirezli, J. Kleykamp, O. Klimov, L. W. Koerner, L. Kolupaeva, R. Kralik, A. Kumar, C. D. Kuruppu, V. Kus, T. Lackey, K. Lang, J. Lesmeister, A. Lister, J. Liu, J. A. Lock, M. MacMahon, S. Magill, W. A. Mann, M. T. Manoharan, M. Manrique Plata, M. L. Marshak, M. Martinez-Casales, V. Matveev, A. Medhi, B. Mehta, M. D. Messier, H. Meyer, T. Miao, V. Mikola, W. H. Miller, S. R. Mishra, A. Mislivec, R. Mohanta, A. Moren, A. Morozova, W. Mu, L. Mualem, M. Muether, K. Mulder, C. Murthy, D. Myers, J. Nachtman, D. Naples, S. Nelleri, J. K. Nelson, O. Neogi, R. Nichol, E. Niner, A. Norman, A. Norrick, H. Oh, A. Olshevskiy, T. Olson, M. Ozkaynak, A. Pal, J. Paley, L. Panda, R. B. Patterson, G. Pawloski, R. Petti, R. K. Plunkett, L. R. Prais, A. Rafique, V. Raj, M. Rajaoalisoa, B. Ramson, B. Rebel, C. Reynolds, E. Robles, P. Roy, O. Samoylov, M. C. Sanchez, S. Sanchez Falero, P. Shanahan, P. Sharma, A. Sheshukov, A. Shmakov, W. Shorrock, S. Shukla, I. Singh, P. Singh, V. Singh, S. Singh Chhibra, D. K. Singha, E. Smith, J. Smolik, P. Snopok, N. Solomey, A. Sousa, K. Soustruznik, M. Strait, C. Sullivan, L. Suter, A. Sutton, S. K. Swain, A. Sztuc, N. Talukdar, P. Tas, T. Thakore, J. Thomas, E. Tiras, M. Titus, Y. Torun, D. Tran, J. Trokan-Tenorio, J. Urheim, B. Utt, P. Vahle, Z. Vallari, K. J. Vockerodt, A. V. Waldron, M. Wallbank, T. K. Warburton, C. Weber, M. Wetstein, D. Whittington, D. A. Wickremasinghe, J. Wolcott, S. Wu, W. Wu, W. Wu, Y. Xiao, B. Yaeggy, A. Yahaya, A. Yankelevich, K. Yonehara, S. Zadorozhnyy, J. Zalesak, R. Zwaska</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-ex</p>
                    <p><strong>Summary:</strong> This Letter reports measurements of muon-neutrino disappearance and electron-neutrino appearance and the corresponding antineutrino processes between the two NOvA detectors in the NuMI neutrino beam. These measurements use a dataset with double the neutrino mode beam exposure that was previously analyzed, along with improved simulation and analysis techniques. A joint fit to these samples in the three-flavor paradigm results in the most precise single-experiment constraint on the atmospheric neutrino mass-splitting, $\Delta m^2_{32}= 2.431^{+0.036}_{-0.034} (-2.479^{+0.036}_{-0.036}) \times 10^{-3}$~eV$^2$ if the mass ordering is Normal (Inverted). In both orderings, a region close to maximal mixing with $\sin^2\theta_{23}=0.55^{+0.06}_{-0.02}$ is preferred. The NOvA data show a mild preference for the Normal mass ordering with a Bayes factor of 2.4 (corresponding to 70\% of the posterior probability), indicating that the Normal ordering is 2.4 times more probable than the Inverted ordering. When incorporating a 2D $\Delta m^2_{32}\textrm{--}\sin^2 2\theta_{13}$ constraint based on Daya Bay data, this preference strengthens to a Bayes factor of 6.6 (87\%).</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04359v1" target="_blank">Assessing time-dependent temperature profile predictions using reduced transport models for high performing NSTX plasmas</a></h3>
                    <p><strong>Authors:</strong> J. B. Lestz, G. Avdeeva, T. F. Neiser, M. V. Gorelenkova, F. D. Halpern, S. M. Kaye, J. McClenaghan, A. Y. Pankin, K. E. Thome</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.plasm-ph</p>
                    <p><strong>Summary:</strong> Time-dependent, predictive simulations were performed with the 1.5D tokamak integrated modeling code TRANSP on a large set of well-analyzed, high performing discharges from the National Spherical Torus Experiment (NSTX) in order to evaluate how well modern reduced transport models can reproduce experimentally observed temperature profiles in spherical tokamaks. Overall, it is found that simulations using the Multi-Mode Model (MMM) more consistently agree with the NSTX observations than those using the Trapped Gyro-Landau Fluid (TGLF) model, despite TGLF requiring orders of magnitude greater computational cost. When considering all examined discharges, MMM has median overpredictions of electron temperature ($T_e$) and ion temperature ($T_i$) profiles of 28% and 27%, respectively, relative to the experiment. TGLF overpredicts $T_e$ by 46%, with much larger variance than MMM, and underpredicts $T_i$ by 25%. As $\beta$ is increased across NSTX discharges, TGLF predicts lower $T_e$ and significant flattening of the $T_i$ profile, conflicting with NSTX observations. When using an electrostatic version of TGLF, both $T_e$ and $T_i$ are substantially overpredicted, underscoring the importance of electromagnetic turbulence in the high $\beta$ spherical tokamak regime. Additionally, calculations with neural net surrogate models for TGLF were performed outside of TRANSP with a time slice flux matching transport solver, finding better agreement with experiment than the TRANSP simulations, highlighting the impact of different transport solvers and simulation techniques. Altogether, the reasonable agreement with experiment of temperature profiles predicted by MMM motivates a more detailed examination of the sensitivities of the TRANSP simulations with MMM to different NSTX plasma regimes in a companion paper, in preparation for self-consistent, time-dependent predictive modeling of NSTX-U scenarios.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04351v1" target="_blank">Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking</a></h3>
                    <p><strong>Authors:</strong> Dror Aiger, Bingyi Cao, Kaifeng Chen, Andre Araujo</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.CV</p>
                    <p><strong>Summary:</strong> The dominant paradigm in image retrieval systems today is to search large databases using global image features, and re-rank those initial results with local image feature matching techniques. This design, dubbed global-to-local, stems from the computational cost of local matching approaches, which can only be afforded for a small number of retrieved images. However, emerging efficient local feature search approaches have opened up new possibilities, in particular enabling detailed retrieval at large scale, to find partial matches which are often missed by global feature search. In parallel, global feature-based re-ranking has shown promising results with high computational efficiency. In this work, we leverage these building blocks to introduce a local-to-global retrieval paradigm, where efficient local feature search meets effective global feature re-ranking. Critically, we propose a re-ranking method where global features are computed on-the-fly, based on the local feature retrieval similarities. Such re-ranking-only global features leverage multidimensional scaling techniques to create embeddings which respect the local similarities obtained during search, enabling a significant re-ranking boost. Experimentally, we demonstrate solid retrieval performance, setting new state-of-the-art results on the Revisited Oxford and Paris datasets.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04315v1" target="_blank">We Have It Covered: A Resampling-based Method for Uplift Model Comparison</a></h3>
                    <p><strong>Authors:</strong> Yang Liu, Chaoyu Yuan</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> stat.ME, stat.ML</p>
                    <p><strong>Summary:</strong> Uplift models play a critical role in modern marketing applications to help understand the incremental benefits of interventions and identify optimal targeting strategies. A variety of techniques exist for building uplift models, and it is essential to understand the model differences in the context of intended applications. The uplift curve is a widely adopted tool for assessing uplift model performance on the selection universe when observations are available for the entire population. However, when it is uneconomical or infeasible to select the entire population, it becomes difficult or even impossible to estimate the uplift curve without appropriate sampling design. To the best of our knowledge, no prior work has addressed uncertainty quantification of uplift curve estimates, which is essential for model comparisons. We propose a two-step sampling procedure and a resampling-based approach to compare uplift models with uncertainty quantification, examine the proposed method via simulations and real data applications, and conclude with a discussion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04313v1" target="_blank">Ultrasound-Triggered Release of Anticancer Nanoparticles from Electrospun Fabrics Integrated with Soft Robotic Tentacles</a></h3>
                    <p><strong>Authors:</strong> Samuel C. T. Moorcroft, Benjamin CalmÃ©, Charles Brooker, Pietro Valdastri, Russell Harris, Stephen J. Russell, Giuseppe Tronci</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> The prompt identification of pancreatic cancer symptoms is an ongoing clinical challenge, often leading to late diagnosis and poor prognosis. Tumor hijacking of the pancreatic stromal structure limits the uptake of systemic chemotherapeutics. Localized drug delivery systems (DDS) using endoluminal techniques are widely utilized, with positive early results for improved control over tumor growth. There is a need for technologies that integrate endoluminal resources and intelligent material systems to better control the spatiotemporal delivery of chemotherapeutics. We demonstrate the ultrasound (US)-triggered localized release of therapeutics through the design of solvent traceless drug-loaded vinylbenzyl-functionalized gelatin (gel4vbc) nanoparticles (NPs) integrated with an electrospun fabric. Albumin-loaded NPs encapsulated into a poly(vinyl alcohol) (PVA) coating of a poly(epsilon-caprolactone) fabric evidence tunable triggered NP delivery controlled by regulating PVA concentration (0-1 wt.%) and US intensity (0-3 W/cm2). The fixation of the NP-coated fabric to a magnetic tentacle robot (MTR) enables the automated manipulation into a phantom pancreatic duct before the US-triggered release of NP-loaded albumin and MTR retraction. Albumin release is controlled by varying the surface area of the NP-loaded MTR-coating fabric. Herein we have designed a novel DDS capable of facile integration into soft robotics and US-triggered delivery of therapeutic-loaded NPs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04308v1" target="_blank">Learning Optimal Crew Dispatch for Grid Restoration Following an Earthquake</a></h3>
                    <p><strong>Authors:</strong> Farshad Amani, Faezeh Ardali, Amin Kargarian</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> eess.SY, cs.SY</p>
                    <p><strong>Summary:</strong> Post-disaster crew dispatch is a critical but computationally intensive task. Traditional mixed-integer linear programming methods often require minutes to several hours to compute solutions, leading to delays that hinder timely decision-making in highly dynamic restoration environments. To address this challenge, we propose a novel learning-based framework that integrates transformer architectures with deep reinforcement learning (DRL) to deliver near real-time decision support without compromising solution quality. Crew dispatch is formulated as a sequential decision-making problem under uncertainty, where transformers capture high-dimensional system states and temporal dependencies, while DRL enables adaptive and scalable decision-making. Earthquake-induced distribution network damage is first characterized using established seismic standards, followed by a scenario generation and reduction pipeline that aggregates probable outcomes into a single geospatial impact map. Conditioned on this map, the proposed framework generates second-level dispatch strategies, trained offline on simulated and historical events and deployed online for rapid response. In addition to substantial runtime improvements, the proposed method enhances system resilience by enabling faster and more effective recovery and restoration. Case studies, particularly on the 2869-bus European gas and power network, demonstrate that the method substantially accelerates restoration while maintaining high-quality solutions, underscoring its potential for practical deployment in large-scale disaster response.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04302v1" target="_blank">POEMMA-Balloon with Radio: An Overview</a></h3>
                    <p><strong>Authors:</strong> J. Eser, A. V. Olinto, G. Osteria</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.IM</p>
                    <p><strong>Summary:</strong> The POEMMA-Balloon with Radio (PBR) is an Ultra Long Duration Balloon payload scheduled for launch in Spring 2027 from Wanaka, New Zealand. It will circle over the Southern Ocean for a mission duration as long as 50 days, serving as a precursor to the dual satellite mission, Probe of Extreme Multi-Messenger Astrophysics (POEMMA). The PBR mission represents a significant step towards establishing a space-based multi-messenger observatory. Observations from space will enhance the statistics of the highest-energy cosmic rays and complement ground-based observatories by enabling simultaneous observations of both hemispheres with a single instrument. Additionally, POEMMA will facilitate the measurement of Very-High-Energy Neutrinos (VHENs) following multi-messenger alerts of astrophysical transient events, such as gamma-ray bursts. PBR is an adaptation of the POEMMA mission, featuring three primary science goals: 1. Observe Ultra-High-Energy Cosmic Rays (UHECRs) via the fluorescence technique from suborbital space. 2. Observe horizontal high-altitude air showers (HAHAs) with energies exceeding the cosmic ray knee (E  3 PeV) using optical and radio detection for the first time. 3. Follow astrophysical event alerts in the search for VHENs. This contribution provides an overview of the PBR payload and discusses the expected performance of its various detectors.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04300v1" target="_blank">Quantum metrology through spectral measurements in quantum optics</a></h3>
                    <p><strong>Authors:</strong> Alejandro Vivas-ViaÃ±a, Carlos SÃ¡nchez MuÃ±oz</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph, cond-mat.mes-hall, physics.optics</p>
                    <p><strong>Summary:</strong> Continuously monitored quantum systems are emerging as promising platforms for quantum metrology, where a central challenge is to identify measurement strategies that optimally extract information about unknown parameters encoded in the complex quantum state of emitted radiation. Different measurement strategies effectively access distinct temporal modes of the emitted field, and the resulting choice of mode can strongly impact the information available for parameter estimation. While a ubiquitous approach in quantum optics is to select frequency modes through spectral filtering, the metrological potential of this technique has not yet been systematically quantified. We develop a theoretical framework to assess this potential by modeling spectral detection as a cascaded quantum system, allowing us to reconstruct the full density matrix of frequency-filtered photonic modes and to compute their associated Fisher information. This framework provides a minimal yet general method to benchmark the performance of spectral measurements in quantum optics, allowing to identify optimal filtering strategies in terms of frequency selection, detector linewidth, and metrological gain accessible through higher-order frequency-resolved correlations and mean-field engineering. These results lay the groundwork for identifying and designing optimal sensing strategies in practical quantum-optical platforms.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04298v1" target="_blank">Noisy Label Refinement with Semantically Reliable Synthetic Images</a></h3>
                    <p><strong>Authors:</strong> Yingxuan Li, Jiafeng Mao, Yusuke Matsui</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Semantic noise in image classification datasets, where visually similar categories are frequently mislabeled, poses a significant challenge to conventional supervised learning approaches. In this paper, we explore the potential of using synthetic images generated by advanced text-to-image models to address this issue. Although these high-quality synthetic images come with reliable labels, their direct application in training is limited by domain gaps and diversity constraints. Unlike conventional approaches, we propose a novel method that leverages synthetic images as reliable reference points to identify and correct mislabeled samples in noisy datasets. Extensive experiments across multiple benchmark datasets show that our approach significantly improves classification accuracy under various noise conditions, especially in challenging scenarios with semantic label noise. Additionally, since our method is orthogonal to existing noise-robust learning techniques, when combined with state-of-the-art noise-robust training methods, it achieves superior performance, improving accuracy by 30% on CIFAR-10 and by 11% on CIFAR-100 under 70% semantic noise, and by 24% on ImageNet-100 under real-world noise conditions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04291v1" target="_blank">Enhanced Sampling in the Age of Machine Learning: Algorithms and Applications</a></h3>
                    <p><strong>Authors:</strong> Kai Zhu, Enrico Trizio, Jintu Zhang, Renling Hu, Linlong Jiang, Tingjun Hou, Luigi Bonati</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.comp-ph</p>
                    <p><strong>Summary:</strong> Molecular dynamics simulations hold great promise for providing insight into the microscopic behavior of complex molecular systems. However, their effectiveness is often constrained by long timescales associated with rare events. Enhanced sampling methods have been developed to address these challenges, and recent years have seen a growing integration with machine learning techniques. This review provides a comprehensive overview of how they are reshaping the field, with a particular focus on the data-driven construction of collective variables. Furthermore, these techniques have also improved biasing schemes and unlocked novel strategies via reinforcement learning and generative approaches. In addition to methodological advances, we highlight applications spanning different areas such as biomolecular processes, ligand binding, catalytic reactions, and phase transitions. We conclude by outlining future directions aimed at enabling more automated strategies for rare-event sampling.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04260v1" target="_blank">An Empirical Study of Vulnerabilities in Python Packages and Their Detection</a></h3>
                    <p><strong>Authors:</strong> Haowei Quan, Junjie Wang, Xinzhe Li, Terry Yue Zhuo, Xiao Chen, Xiaoning Du</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.SE, cs.AI, cs.CR</p>
                    <p><strong>Summary:</strong> In the rapidly evolving software development landscape, Python stands out for its simplicity, versatility, and extensive ecosystem. Python packages, as units of organization, reusability, and distribution, have become a pressing concern, highlighted by the considerable number of vulnerability reports. As a scripting language, Python often cooperates with other languages for performance or interoperability. This adds complexity to the vulnerabilities inherent to Python packages, and the effectiveness of current vulnerability detection tools remains underexplored. This paper addresses these gaps by introducing PyVul, the first comprehensive benchmark suite of Python-package vulnerabilities. PyVul includes 1,157 publicly reported, developer-verified vulnerabilities, each linked to its affected packages. To accommodate diverse detection techniques, it provides annotations at both commit and function levels. An LLM-assisted data cleansing method is incorporated to improve label accuracy, achieving 100% commit-level and 94% function-level accuracy, establishing PyVul as the most precise large-scale Python vulnerability benchmark. We further carry out a distribution analysis of PyVul, which demonstrates that vulnerabilities in Python packages involve multiple programming languages and exhibit a wide variety of types. Moreover, our analysis reveals that multi-lingual Python packages are potentially more susceptible to vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark reveals a significant discrepancy between the capabilities of existing tools and the demands of effectively identifying real-world security issues in Python packages. Additionally, we conduct an empirical review of the top-ranked CWEs observed in Python packages, to diagnose the fine-grained limitations of current detection tools and highlight the necessity for future advancements in the field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04257v1" target="_blank">Integrability and lattice discretizations of all Topological Defect Lines in minimal CFTs</a></h3>
                    <p><strong>Authors:</strong> Madhav Sinha, Thiago Silva Tavares, Ananda Roy, Hubert Saleur</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-th, cond-mat.stat-mech, math-ph, math.MP</p>
                    <p><strong>Summary:</strong> We discuss in this paper the lattice discretizations of all topological defect lines (TDLs) for diagonal, minimal CFTs, using integrable restricted solid-on-solid (RSOS) models. For these CFTs, the TDLs can be labeled by the Kac labels. In the case of $(1,s)$ TDLs, lines that are exactly topological on the lattice can be obtained using the centralizer of the underlying Temperley-Lieb algebra, all the other lines become topological in the continuum limit only. Our general construction relies on insertions of rows/columns of faces with modified spectral parameters, and can therefore be studied using integrability techniques. We determine the regions of spectral parameters realizing the different $(r,s)$ TDLs, and in particular calculate analytically all the associated eigenvalues (and degeneracy factors). We also show how fusion of TDLs can be obtained from fusion hierarchies in the algebraic approach to the Bethe-ansatz. All our results are checked numerically in detail for several minimal CFTs.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04244v1" target="_blank">Integrating Pruning with Quantization for Efficient Deep Neural Networks Compression</a></h3>
                    <p><strong>Authors:</strong> Sara Makenali, Babak Rokh, Ali Azarpeyvand</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.NE</p>
                    <p><strong>Summary:</strong> Deep Neural Networks (DNNs) have achieved significant advances in a wide range of applications. However, their deployment on resource-constrained devices remains a challenge due to the large number of layers and parameters, which result in considerable computational and memory demands. To address this issue, pruning and quantization are two widely used compression techniques, commonly applied individually in most studies to reduce model size and enhance processing speed. Nevertheless, combining these two techniques can yield even greater compression benefits. Effectively integrating pruning and quantization to harness their complementary advantages poses a challenging task, primarily due to their potential impact on model accuracy and the complexity of jointly optimizing both processes. In this paper, we propose two approaches that integrate similarity-based filter pruning with Adaptive Power-of-Two (APoT) quantization to achieve higher compression efficiency while preserving model accuracy. In the first approach, pruning and quantization are applied simultaneously during training. In the second approach, pruning is performed first to remove less important parameters, followed by quantization of the pruned model using low-bit representations. Experimental results demonstrate that our proposed approaches achieve effective model compression with minimal accuracy degradation, making them well-suited for deployment on devices with limited computational resources.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04235v1" target="_blank">Non-unique decompositions of mixed states and deterministic energy transfers</a></h3>
                    <p><strong>Authors:</strong> Zihan Wang, Fei Meng, Oscar Dahlsten</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> quant-ph</p>
                    <p><strong>Summary:</strong> We investigate the impact of non-unique decompositions of mixed states on energy transfer. Mixed states generally have non-unique decompositions into pure states in quantum theory and, by definition, in other non-classical probabilistic theories. We consider energy transfers constituting deterministic energy harvesting, wherein the source transfers energy to the harvester but not entropy. We use the possibility of non-unique decompositions to derive that if source states in a set jointly lead to deterministic energy harvesting for the given harvesting system and interaction, then that set can be expanded to include both mixtures and superpositions of the original states in the set. As a paradigmatic example, we model the source as an EM mode transferring energy to a 2-level system harvester via the Jaynes-Cummings model. We show that the set of coherent EM mode states with fixed $|\alpha|$ that jointly achieve deterministic energy transfer can be expanded to include all mixtures and superpositions of those states. More generally, the results link the defining feature of a non-classical probability theory with the ability to achieve energy transfer without entropy transfer.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04230v1" target="_blank">Backreaction of Halilsoy and Chandrasekhar waves</a></h3>
                    <p><strong>Authors:</strong> Sebastian J. Szybka, Adam A. Zychowicz, Dominika Hunik</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> gr-qc, astro-ph.CO, 83C35</p>
                    <p><strong>Summary:</strong> We calculate the high-frequency limit of the Halilsoy and Chandrasekhar standing gravitational wave solutions. We show that the backreaction effect is the same for these classes of solutions and we analyze the causal structure of the effective spacetime. In addition, we rederive both classes of solutions without referring to the Ernst equation and generation techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04223v1" target="_blank">Making neural networks understand internal heat transfer using Fourier-transformed thermal diffusion wave fields</a></h3>
                    <p><strong>Authors:</strong> Pengfei Zhu, Hai Zhang, Clemente Ibarra-Castanedo, Xavier Maldague, Andreas Mandelis</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.app-ph</p>
                    <p><strong>Summary:</strong> Heat propagation is governed by phonon interactions and mathematically described by partial differential equations (PDEs), which link thermal transport to the intrinsic properties of materials. Conventional experimental techniques infer thermal responses based on surface emissions, limiting their ability to fully resolve subsurface structures and internal heat distribution. Additionally, existing thermal tomographic techniques can only shoot one frame from each layer. Physics-informed neural networks (PINNs) have recently emerged as powerful tools for solving inverse problems in heat transfer by integrating observational data with physical constraints. However, standard PINNs are primarily focused on fitting the given external temperature data, without explicit knowledge of the unknown internal temperature distribution. In this study, we introduce a Helmholtz-informed neural network (HINN) to predict internal temperature distributions without requiring internal measurements. The time-domain heat diffusion equation was converted to the frequency-domain and becomes the pseudo-Helmholtz equation. HINN embeds this pseudo-Helmholtz equation into the learning framework, leveraging both real and imaginary components of the thermal field. Finally, an inverse Fourier transform brings real-part and imagery-part back to the time-domain and can be used to map 3D thermal fields with interior defects. Furthermore, a truncated operation was conducted to improve computational efficiency, and the principle of conjugate symmetry was employed for repairing the discarded data. This approach significantly enhances predictive accuracy and computational efficiency. Our results demonstrate that HINN outperforms state-of-the-art PINNs and inverse heat solvers, offering a novel solution for non-invasive thermography in applications spanning materials science, biomedical diagnostics, and nondestructive evaluation.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04214v1" target="_blank">An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline</a></h3>
                    <p><strong>Authors:</strong> Tyler Shumaker, Jessica Carpenter, David Saranchak, Nathaniel D. Bastian</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> Machine learning (ML) models have the potential to transform military battlefields, presenting a large external pressure to rapidly incorporate them into operational settings. However, it is well-established that these ML models are vulnerable to a number of adversarial attacks throughout the model deployment pipeline that threaten to negate battlefield advantage. One broad category is privacy attacks (such as model inversion) where an adversary can reverse engineer information from the model, such as the sensitive data used in its training. The ability to quantify the risk of model inversion attacks (MIAs) is not well studied, and there is a lack of automated developmental test and evaluation (DTE) tools and metrics to quantify the effectiveness of privacy loss of the MIA. The current DTE process is difficult because ML model inversions can be hard for a human to interpret, subjective when they are interpretable, and difficult to quantify in terms of inversion quality. Additionally, scaling the DTE process is challenging due to many ML model architectures and data modalities that need to be assessed. In this work, we present a novel DTE tool that quantifies the risk of data privacy loss from MIAs and introduces four adversarial risk dimensions to quantify privacy loss. Our DTE pipeline combines inversion with vision language models (VLMs) to improve effectiveness while enabling scalable analysis. We demonstrate effectiveness using multiple MIA techniques and VLMs configured for zero-shot classification and image captioning. We benchmark the pipeline using several state-of-the-art MIAs in the computer vision domain with an image classification task that is typical in military applications. In general, our innovative pipeline extends the current model inversion DTE capabilities by improving the effectiveness and scalability of the privacy loss analysis in an automated fashion.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04209v1" target="_blank">Quantum Hall Antidot as a Fractional Coulombmeter</a></h3>
                    <p><strong>Authors:</strong> Mario Di Luca, Emily Hajigeorgiou, Zekang Zhou, Tengyan Feng, Kenji Watanabe, Takashi Taniguchi, Mitali Banerjee</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cond-mat.mes-hall</p>
                    <p><strong>Summary:</strong> The detection of fractionally charged quasiparticles, which arise in the fractional quantum Hall regime, is of fundamental importance for probing their exotic quantum properties. While electronic interferometers have been central to probe their statistical properties, their interpretation is often complicated by bulk-edge interactions. Antidots, potential hills in the quantum Hall regime, are particularly valuable in this context, as they overcome the geometric limitations of conventional designs and act as controlled impurities within a quantum point contact. Furthermore, antidots allow for quasiparticle charge detection through straightforward conductance measurements, replacing the need for more demanding techniques. In this work, we employ a gate-defined bilayer graphene antidot operating in the Coulomb-dominated regime to study quasiparticle tunneling in both integer and fractional quantum Hall states. We show that the gate-voltage period and the oscillation slope directly reveal the charge of tunneling quasiparticles, providing a practical method to measure fractional charge in graphene. Moreover, we report the first measurement of the $e/3$ fractional charge in a graphene-based device. The simplicity and tunability of this design open a pathway to extend AD-based charge measurements to other van der Waals materials, establishing antidots as a powerful and broadly applicable platform to study the quantum Hall effect.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04202v1" target="_blank">Explicit and Implicit Data Augmentation for Social Event Detection</a></h3>
                    <p><strong>Authors:</strong> Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Qing Li, Hu Wang, Preslav Nakov</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.SI</p>
                    <p><strong>Summary:</strong> Social event detection involves identifying and categorizing important events from social media, which relies on labeled data, but annotation is costly and labor-intensive. To address this problem, we propose Augmentation framework for Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework, which combines explicit text-based and implicit feature-space augmentation to enhance data diversity and model robustness. The explicit augmentation utilizes large language models to enhance textual information through five diverse generation strategies. For implicit augmentation, we design five novel perturbation techniques that operate in the feature space on structural fused embeddings. These perturbations are crafted to keep the semantic and relational properties of the embeddings and make them more diverse. Specifically, SED-Aug outperforms the best baseline model by approximately 17.67% on the Twitter2012 dataset and by about 15.57% on the Twitter2018 dataset in terms of the average F1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04201v1" target="_blank">Nanometer-precision tracking of adipocyte dynamics via single lipid droplet whispering-gallery optical resonances</a></h3>
                    <p><strong>Authors:</strong> Rok Podlipec, Ana KriÅ¡elj, Maja Garvas Zorc, Petra Matjan Å tefin, Siegfried Usaar, MatjaÅ¾ Humar</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> physics.optics, cond-mat.soft, q-bio.CB</p>
                    <p><strong>Summary:</strong> Biophotonics-and more recently, biointegrated photonics-offer transformative tools for probing cellular processes with unprecedented precision. Among these, whispering gallery mode (WGM) resonators-optical microcavities formed in spherical structures-have emerged as powerful biosensors and intracellular barcodes. Lipid droplets (LDs), with their high refractive index and intrinsic spherical geometry, are ideal candidates for supporting intracellular lasing. Although lasing in LDs has been previously demonstrated, it has not yet been harnessed to study live cell biology. Here, we report the first use of WGM resonances in LDs of live primary adipocytes, employing a continuous-wave (CW) laser at powers below the biological damage threshold. By measuring these resonances, we achieved nanometer-scale precision in size estimation, enabling real-time observation of rapid LD dynamics and deformations on the minute scale, far beyond the spatio-temporal resolution of conventional microscopy. We systematically characterized this photonic sensing approach, demonstrating its ability to resolve adipocyte heterogeneity, monitor lipolytic responses to forskolin and isoproterenol, and detect early signs of cell viability loss, well before conventional assays. This proof-of-concept establishes intracellular LD WGM resonances as a robust platform for investigating live single-cell metabolism. The technique enables rapid, cost-effective assessment of adipocyte function, reveals cell-to-cell variability obscured by bulk assays, and lays the foundation for high-throughput analysis of metabolism- and obesity-related diseases at both cellular and tissue levels.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04189v1" target="_blank">On the geometric properties of multi-operator two-phase elliptic measure</a></h3>
                    <p><strong>Authors:</strong> Max Goering, Anna Skorobogatova</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.AP</p>
                    <p><strong>Summary:</strong> We provide a structural characterization of a given boundary using two-phase elliptic measure in a multi-operator setting, extending to this novel setting results of Kenig, Preiss  Toro, Toro  Zhao and Azzam  Mourgoglou, including a partial answer to Bishops question regarding the validity of Oksendals conjecture under the assumption of mutual absolute continuity of the elliptic measures. Our techniques rely on a reduction to a multi-operator two-phase free-boundary problem combined with an extension of the powerful tools introduced by Preiss in his Density Theorem.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04183v1" target="_blank">MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions</a></h3>
                    <p><strong>Authors:</strong> Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                    <p><strong>Summary:</strong> The growing demand for scalable psychological counseling highlights the need for fine-tuning open-source Large Language Models (LLMs) with high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. In addition, we address inconsistencies in prior evaluation protocols by proposing a unified evaluation framework integrating diverse automatic and expert metrics. Furthermore, we expand the expert evaluations from four aspects of counseling in previous works to nine aspects, enabling a more thorough and robust assessment of data quality. Empirical results show that MAGneT significantly outperforms existing methods in quality, diversity, and therapeutic alignment of the generated counseling sessions, improving general counseling skills by 3.2% and CBT-specific skills by 4.3% on average on cognitive therapy rating scale (CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases on average across all aspects. Moreover, fine-tuning an open-source model on MAGneT-generated sessions shows better performance, with improvements of 6.3% on general counseling skills and 7.3% on CBT-specific skills on average on CTRS over those fine-tuned with sessions generated by baseline methods. We also make our code and data public.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04177v1" target="_blank">Stellar occultations in support of the LUMIO orbit determination</a></h3>
                    <p><strong>Authors:</strong> Davide Banzi, Riccardo Lasagni Manghi, Marco Zannoni</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.EP, physics.space-ph</p>
                    <p><strong>Summary:</strong> This work investigates the use of stellar occultation measurements to enhance the orbit determination performance of the Lunar Meteoroid Impact Observer (LUMIO) mission, operating from a quasi-Halo orbit around the Earth-Moon L2 point. During science phases, when radiometric tracking is sparse and low illumination limits conventional optical navigation methods, occultation events, defined as precise timings of stellar appearances/disappearances behind the Moons limb, offer a suitable alternative. A simulation tool based on JPLs MONTE library was developed to identify valid occultation events, applying geometric and illumination constraints to exclude non-observable cases. These events were integrated into a batch least-squares orbit determination filter alongside conventional radiometric data. The covariance analysis shows that occultation observables reduce the transverse and normal position uncertainties of LUMIO by up to a factor of two, especially during tracking gaps or occultation-rich arcs. This uncertainty reduction is expected to facilitate station-keeping operations and constrain the surface localization of Lunar Impact Flashes (LIFs), enhancing the missions scientific return. Sensitivity analyses confirm that the orbit determination performance is primarily driven by the timing accuracy of occultation events, with limited dependence on lunar shape uncertainty below 100 m. These findings confirm the potential of occultation-based navigation to enhance spacecraft autonomy and robustness in low-visibility environments, making it a valuable complement to radiometric techniques for future lunar and deep-space missions.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04174v1" target="_blank">Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns</a></h3>
                    <p><strong>Authors:</strong> Christian Merz, Lukas Schach, Marie Luisa Fiedler, Jean-Luc Lugrin, Carolin Wienrich, Marc Erich Latoschik</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.HC, cs.LG</p>
                    <p><strong>Summary:</strong> This paper introduces an unobtrusive in-situ measurement method to detect user behavior changes during arbitrary exposures in XR systems. Here, such behavior changes are typically associated with the Proteus effect or bodily affordances elicited by different avatars that the users embody in XR. We present a biometric user model based on deep metric similarity learning, which uses high-dimensional embeddings as reference vectors to identify behavior changes of individual users. We evaluate our model against two alternative approaches: a (non-learned) motion analysis based on central tendencies of movement patterns and subjective post-exposure embodiment questionnaires frequently used in various XR exposures. In a within-subject study, participants performed a fruit collection task while embodying avatars of different body heights (short, actual-height, and tall). Subjective assessments confirmed the effective manipulation of perceived body schema, while the (non-learned) objective analyses of head and hand movements revealed significant differences across conditions. Our similarity learning model trained on the motion data successfully identified the elicited behavior change for various query and reference data pairings of the avatar conditions. The approach has several advantages in comparison to existing methods: 1) In-situ measurement without additional user input, 2) generalizable and scalable motion analysis for various use cases, 3) user-specific analysis on the individual level, and 4) with a trained model, users can be added and evaluated in real time to study how avatar changes affect behavior.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04167v1" target="_blank">On the local existence for the characteristic initial value problem for the Einstein-Dirac system</a></h3>
                    <p><strong>Authors:</strong> Peng Zhao, Xiaoning Wu</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.AP, gr-qc</p>
                    <p><strong>Summary:</strong> In this paper, we investigate the characteristic initial value problem for the Einstein-Dirac system, a model governing the interaction between gravity and spin-$1/2$ fields. We apply Luks strategy \cite{Luk12} and prove a semi-global existence result for this coupled Einstein-Dirac system without imposing symmetry conditions. More precisely, we construct smooth solutions in a rectangular region to the future of two intersecting null hypersurfaces, on which characteristic initial data are specified. The key novelty is to promote the symmetric spinorial derivatives of the Dirac field to independent variables and to derive a commuted Weyl-curvature-free evolution system for them. This eliminates the coupling to the curvature in the energy estimates and closes the bootstrap at the optimal derivative levels. The analysis relies on a double null foliation and incorporates spinor-specific techniques essential to handling the structure of the Dirac field.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04165v1" target="_blank">Galactic forcing increases origination of marine microplankton</a></h3>
                    <p><strong>Authors:</strong> PÃ©ter OzsvÃ¡rt, Emma Kun, Imre Bartos, Zsolt Gy. MÃ¡rka, Szabolcs MÃ¡rka</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> astro-ph.HE, astro-ph.EP, astro-ph.GA</p>
                    <p><strong>Summary:</strong> The continuous flux of Galactic cosmic rays that bombard Earths atmosphere creates ionizing radiation that can damage the DNA of living organisms. While this radiation on Earth is relatively constant in the short term, large and long-scale fluctuations are expected with a period of $\sim 63.5$ million years. As the Solar System moves above or below the Galactic plane during its oscillatory motion about the Galactic center, the Galactic magnetic shielding weakens, allowing more cosmic rays to reach Earth and trigger mutations in organisms. We identify a significant correlation (weighted global p-value: $1.25\times 10^{-4}$, or $3.72\sigma$) between the Solar Systems Galactic oscillations and the origination of marine zoo- and phyto-microplankton genera over the Phanerozoic. When we restrict the analysis to time intervals during which all four groups coexisted, a post-trial significance of $4.52\sigma$ emerges. Our findings suggest that changes in biodiversity have been significantly influenced by long-term Galactic forcing.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04155v1" target="_blank">An Approach to Sub-Gaussian Heat Kernel Estimates via Analysis on Metric Spaces</a></h3>
                    <p><strong>Authors:</strong> Riku Anttila</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.PR, math.FA, 31C25, 35K08, 31E05, 46E36</p>
                    <p><strong>Summary:</strong> In this work, we establish a new characterization of sub-Gaussian heat kernel estimates for Dirichlet forms on metric measure spaces. Our formulation is based on the newly introduced \emph{cutoff energy condition}, which provides a simpler and more transparent alternative for earlier technical energy inequalities, in particular the cutoff Sobolev inequality. The main idea of our approach is to reinterpret the cutoff Sobolev inequality as a certain Poincar\e type inequality, and analyze it using Haj{\l}asz--Koskela techniques from analysis on metric spaces. We present a broad class of new examples in which the sub-Gaussian heat kernel estimates are verified.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04153v1" target="_blank">Real Time FPGA Based CNNs for Detection, Classification, and Tracking in Autonomous Systems: State of the Art Designs and Optimizations</a></h3>
                    <p><strong>Authors:</strong> Safa Mohammed Sali, Mahmoud Meribout, Ashiyana Abdul Majeed</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.AR</p>
                    <p><strong>Summary:</strong> This paper presents a comprehensive review of recent advances in deploying convolutional neural networks (CNNs) for object detection, classification, and tracking on Field Programmable Gate Arrays (FPGAs). With the increasing demand for real-time computer vision applications in domains such as autonomous vehicles, robotics, and surveillance, FPGAs have emerged as a powerful alternative to GPUs and ASICs due to their reconfigurability, low power consumption, and deterministic latency. We critically examine state-of-the-art FPGA implementations of CNN-based vision tasks, covering algorithmic innovations, hardware acceleration techniques, and the integration of optimization strategies like pruning, quantization, and sparsity-aware methods to maximize performance within hardware constraints. This survey also explores the landscape of modern FPGA platforms, including classical LUT-DSP based architectures, System-on-Chip (SoC) FPGAs, and Adaptive Compute Acceleration Platforms (ACAPs), comparing their capabilities in handling deep learning workloads. Furthermore, we review available software development tools such as Vitis AI, FINN, and Intel FPGA AI Suite, which significantly streamline the design and deployment of AI models on FPGAs. The paper uniquely discusses hybrid architecture that combine GPUs and FPGAs for collaborative acceleration of AI inference, addressing challenges related to energy efficiency and throughput. Additionally, we highlight hardware-software co-design practices, dataflow optimizations, and pipelined processing techniques essential for real-time inference on resource-constrained devices. Through this survey, researchers and engineers are equipped with insights to develop next-generation, power-efficient, and high-performance vision systems optimized for FPGA deployment in edge and embedded applications.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04139v1" target="_blank">Enhancing Technical Documents Retrieval for RAG</a></h3>
                    <p><strong>Authors:</strong> Songjiang Lai, Tsun-Hin Cheung, Ka-Chun Fung, Kaiwen Xue, Kwan-Ho Lin, Yan-Ming Choi, Vincent Ng, Kin-Man Lam</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.IR, cs.AI</p>
                    <p><strong>Summary:</strong> In this paper, we introduce Technical-Embeddings, a novel framework designed to optimize semantic retrieval in technical documentation, with applications in both hardware and software development. Our approach addresses the challenges of understanding and retrieving complex technical content by leveraging the capabilities of Large Language Models (LLMs). First, we enhance user queries by generating expanded representations that better capture user intent and improve dataset diversity, thereby enriching the fine-tuning process for embedding models. Second, we apply summary extraction techniques to encode essential contextual information, refining the representation of technical documents. To further enhance retrieval performance, we fine-tune a bi-encoder BERT model using soft prompting, incorporating separate learning parameters for queries and document context to capture fine-grained semantic nuances. We evaluate our approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that Technical-Embeddings significantly outperforms baseline models in both precision and recall. Our findings highlight the effectiveness of integrating query expansion and contextual summarization to enhance information access and comprehension in technical domains. This work advances the state of Retrieval-Augmented Generation (RAG) systems, offering new avenues for efficient and accurate technical document retrieval in engineering and product development workflows.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04123v1" target="_blank">TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering</a></h3>
                    <p><strong>Authors:</strong> Ayan Banerjee, Josep LladÃ³s, Umapada Pal, Anjan Dutta</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CV</p>
                    <p><strong>Summary:</strong> Text-to-story visualization is challenging due to the need for consistent interaction among multiple characters across frames. Existing methods struggle with character consistency, leading to artifact generation and inaccurate dialogue rendering, which results in disjointed storytelling. In response, we introduce TaleDiffusion, a novel framework for generating multi-character stories with an iterative process, maintaining character consistency, and accurate dialogue assignment via postprocessing. Given a story, we use a pre-trained LLM to generate per-frame descriptions, character details, and dialogues via in-context learning, followed by a bounded attention-based per-box mask technique to control character interactions and minimize artifacts. We then apply an identity-consistent self-attention mechanism to ensure character consistency across frames and region-aware cross-attention for precise object placement. Dialogues are also rendered as bubbles and assigned to characters via CLIPSeg. Experimental results demonstrate that TaleDiffusion outperforms existing methods in consistency, noise reduction, and dialogue rendering.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04113v1" target="_blank">A unified stabilized virtual element method for the generalized Oseen equation: stability and robustness</a></h3>
                    <p><strong>Authors:</strong> Sudheer Mishra, E Natarajan</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> math.NA, cs.NA</p>
                    <p><strong>Summary:</strong> In this thesis, we investigate a novel local projection based stabilized conforming virtual element method for the generalized Oseen problem using equal-order element pairs on general polygonal meshes. To ensure the stability, particularly in the presence of convection-dominated regimes and the utilization of equal-order element pairs, we introduce local projections based stabilization techniques. We demonstrate the discrete inf-sup condition in the energy norm. Moreover, the stability of the proposed method also guarantees the stability properties for the Brinkman equation and the Stokes equation without introducing any additional conditions. Furthermore, we derive an optimal error estimates in the energy norm that underline the uniform convergence in the energy norm for the generalized Oseen problem with small diffusion. In addition, the error estimates remain valid and uniform for the Brinkman equation and the Stokes equation. Additionally, the convergence study shows that the proposed method is quasi-robust with respect to parameters. The proposed method offers several advantages, including simplicity in construction, easier implementation compared to residual-based stabilization techniques, and avoiding coupling between element pairs. We validate our theoretical findings through a series of numerical experiments, including diffusion-dominated and convection-dominated regimes.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04106v1" target="_blank">Optimal rate-variance coding due to firing threshold adaptation near criticality</a></h3>
                    <p><strong>Authors:</strong> Mauricio Girardi-Schappo, Leonard Maler, AndrÃ© Longtin</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> q-bio.NC, cond-mat.dis-nn, cond-mat.stat-mech, nlin.AO, physics.bio-ph</p>
                    <p><strong>Summary:</strong> Recurrently connected neuron populations play key roles in sensory perception and memory storage across various brain regions. While these populations are often assumed to encode information through firing rates, this method becomes unreliable with weak stimuli. We propose that in such cases, information can be transmitted via spatial spike patterns, employing a sparse or combinatorial coding based on firing rate variance. Around the critical point of a stochastic recurrent excitable network, we uncover a synergistic dual-coding scheme, enabled by single-cell threshold adaptation. This scheme optimizes variance coding for weak signals without compromising rate coding for stronger inputs, thus maximizing input/output mutual information. These optimizations are robust across adaptation rules and coupling strengths through self-suppression of internal noise, particularly around the networks phase transition, and are linked to threshold recovery times observed in hippocampal memory circuits (~$10^2$-$10^3$ms). In contrast, nonadaptive networks perform similarly only at criticality, suggesting that threshold adaptation is essential for reliable encoding of weak signals into diverse spatial patterns. Our results imply a fundamental role for near-critical latent adaptive dynamics enabled by dual coding in biological and artificial neural networks.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04105v1" target="_blank">Beyond the Starobinsky model after ACT</a></h3>
                    <p><strong>Authors:</strong> Dhong Yeon Cheong, Min Gi Park, Seong Chan Park</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> hep-ph, gr-qc</p>
                    <p><strong>Summary:</strong> We revisit higher order corrections to the Starobinsky inflationary model using the most recent P-ACT-LB-BK18 data, which exhibits a mild but definite tension with the predictions of the original model. Our results demonstrate how even small {higher order} deformations of the Ricci scalar (e.g. $R^3, R^4,\cdots$) can bring the model into better agreement with current data and impose nontrivial constraints on the post-inflationary dynamics.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04094v1" target="_blank">Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators</a></h3>
                    <p><strong>Authors:</strong> Fatih Dursun, Bruno Vilhena Adorno, Simon Watson, Wei Pan</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.RO</p>
                    <p><strong>Summary:</strong> Object reconstruction and inspection tasks play a crucial role in various robotics applications. Identifying paths that reveal the most unknown areas of the object becomes paramount in this context, as it directly affects efficiency, and this problem is known as the view path planning problem. Current methods often use sampling-based path planning techniques, evaluating potential views along the path to enhance reconstruction performance. However, these methods are computationally expensive as they require evaluating several candidate views on the path. To this end, we propose a computationally efficient solution that relies on calculating a focus point in the most informative (unknown) region and having the robot maintain this point in the camera field of view along the path. We incorporated this strategy into the whole-body control of a mobile manipulator employing a visibility constraint without the need for an additional path planner. We conducted comprehensive and realistic simulations using a large dataset of 114 diverse objects of varying sizes from 57 categories to compare our method with a sampling-based planning strategy using Bayesian data analysis. Furthermore, we performed real-world experiments with an 8-DoF mobile manipulator to demonstrate the proposed methods performance in practice. Our results suggest that there is no significant difference in object coverage and entropy. In contrast, our method is approximately nine times faster than the baseline sampling-based method in terms of the average time the robot spends between views.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04091v1" target="_blank">Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks</a></h3>
                    <p><strong>Authors:</strong> Jintao Gu, Haolang Lu, Guoshun Nan, Yihan Lin, Kun Wang, Yuchun Guo, Yigui Cao, Yang Liu</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR, 68M25, K.6.5; D.2.7</p>
                    <p><strong>Summary:</strong> Accurate detection of third-party libraries (TPLs) is fundamental to Android security, supporting vulnerability tracking, malware detection, and supply chain auditing. Despite many proposed tools, their real-world effectiveness remains unclear.We present the first large-scale empirical study of ten state-of-the-art TPL detection techniques across over 6,000 apps, enabled by a new ground truth dataset with precise version-level annotations for both remote and local dependencies.Our evaluation exposes tool fragility to R8-era transformations, weak version discrimination, inaccurate correspondence of candidate libraries, difficulty in generalizing similarity thresholds, and prohibitive runtime/memory overheads at scale.Beyond tool assessment, we further analyze how TPLs shape downstream tasks, including vulnerability analysis, malware detection, secret leakage assessment, and LLM-based evaluation. From this perspective, our study provides concrete insights into how TPL characteristics affect these tasks and informs future improvements in security analysis.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04084v1" target="_blank">LowDiff: Efficient Frequent Checkpointing via Low-Cost Differential for High-Performance Distributed Training Systems</a></h3>
                    <p><strong>Authors:</strong> Chenxuan Yao, Yuchong Hu, Feifan Liu, Zhengyu Liu, Dan Feng</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.DC</p>
                    <p><strong>Summary:</strong> Distributed training of large deep-learning models often leads to failures, so checkpointing is commonly employed for recovery. State-of-the-art studies focus on frequent checkpointing for fast recovery from failures. However, it generates numerous checkpoints, incurring substantial costs and thus degrading training performance. Recently, differential checkpointing has been proposed to reduce costs, but it is limited to recommendation systems, so its application to general distributed training systems remains unexplored. This paper proposes LowDiff, an efficient frequent checkpointing framework that \textit{reuses} compressed gradients, serving as differential checkpoints to reduce cost. Furthermore, LowDiff incorporates a batched gradient write optimization to persist these differentials to storage efficiently. It also dynamically tunes both the checkpoint frequency and the batching size to maximize performance. We further enhance LowDiff with a layer-wise gradient reusing and snapshotting approach and a CPU-based asynchronous persistence strategy, enabling frequent checkpointing without gradient compression. Experiments on various workloads show that LowDiff can achieve checkpointing frequency up to per iteration with less than 3.1\% runtime overhead.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04080v1" target="_blank">ICSLure: A Very High Interaction Honeynet for PLC-based Industrial Control Systems</a></h3>
                    <p><strong>Authors:</strong> Francesco Aurelio Pironti, Angelo Furfaro, Francesco Blefari, Carmelo Felicetti, Matteo Lupinacci, Francesco Romeo</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR</p>
                    <p><strong>Summary:</strong> The security of Industrial Control Systems (ICSs) is critical to ensuring the safety of industrial processes and personnel. The rapid adoption of Industrial Internet of Things (IIoT) technologies has expanded system functionality but also increased the attack surface, exposing ICSs to a growing range of cyber threats. Honeypots provide a means to detect and analyze such threats by emulating target systems and capturing attacker behavior. However, traditional ICS honeypots, often limited to software-based simulations of a single Programmable Logic Controller (PLC), lack the realism required to engage sophisticated adversaries. In this work, we introduce a modular honeynet framework named ICSLure. The framework has been designed to emulate realistic ICS environments. Our approach integrates physical PLCs interacting with live data sources via industrial protocols such as Modbus and Profinet RTU, along with virtualized network components including routers, switches, and Remote Terminal Units (RTUs). The system incorporates comprehensive monitoring capabilities to collect detailed logs of attacker interactions. We demonstrate that our framework enables coherent and high-fidelity emulation of real-world industrial plants. This high-interaction environment significantly enhances the quality of threat data collected and supports advanced analysis of ICS-specific attack strategies, contributing to more effective detection and mitigation techniques.</p>
                
            
                
                    <h3><a href="http://arxiv.org/abs/2509.04070v1" target="_blank">Error Detection Schemes for Barrett Reduction of CT-BU on FPGA in Post Quantum Cryptography</a></h3>
                    <p><strong>Authors:</strong> Paresh Baidya, Rourab Paul, Vikas Srivastava, Sumit Kumar Debnath</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CR, cs.AR</p>
                    <p><strong>Summary:</strong> A fault can occur naturally or intentionally. However, intentionally injecting faults into hardware accelerators of Post-Quantum Cryptographic (PQC) algorithms may leak sensitive information. This intentional fault injection in side-channel attacks compromises the reliability of PQC implementations. The recently NIST-standardized key encapsulation mechanism (KEM), Kyber may also leak information at the hardware implementation level. This work proposes three efficient and lightweight recomputation-based fault detection methods for Barrett Reduction in the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on a Field Programmable Gate Array (FPGA). The CT-BU and Barrett Reduction are fundamental components in structured lattice-based PQC algorithms, including Kyber, NTRU, Falcon, CRYSTALS-Dilithium, etc. This paper introduces a new algorithm, Recomputation with Swapped Operand (RESWO), for fault detection. While Recomputation with Negated Operand (RENO) and Recomputation with Shifted Operand (RESO) are existing methods used in other PQC hardware algorithms. To the best of our knowledge, RENO and RESO have never been used in Barrett Reduction before. The proposed RESWO method consumes a similar number of slices compared to RENO and RESO. However, RESWO shows lesser delay compared to both RENO and RESO. The fault detection efficiency of RESWO, RENO, and RESO is nearly 100%.</p>
                
            
                
                    <h3><a href="http://dx.doi.org/10.54988/uaj.000027.001" target="_blank">Arabic Chatbot Technologies in Education: An Overview</a></h3>
                    <p><strong>Authors:</strong> Hicham Bourhil, Yacine El Younoussi</p>
                    <p><strong>Published:</strong> 9/4/2025</p>
                    <p><strong>Categories:</strong> cs.CL</p>
                    <p><strong>Summary:</strong> The recent advancements in Artificial Intelligence (AI) in general, and in Natural Language Processing (NLP) in particular, and some of its applications such as chatbots, have led to their implementation in different domains like education, healthcare, tourism, and customer service. Since the COVID-19 pandemic, there has been an increasing interest in these digital technologies to allow and enhance remote access. In education, e-learning systems have been massively adopted worldwide. The emergence of Large Language Models (LLM) such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformers) made chatbots even more popular. In this study, we present a survey on existing Arabic chatbots in education and their different characteristics such as the adopted approaches, language variety, and metrics used to measure their performance. We were able to identified some research gaps when we discovered that, despite the success of chatbots in other languages such as English, only a few educational Arabic chatbots used modern techniques. Finally, we discuss future directions of research in this field.</p>
                
            
        
        
            <p><em>Generated by AI News Agent</em></p>
        
    

